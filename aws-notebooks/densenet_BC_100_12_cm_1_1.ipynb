{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense Net\n",
    "\n",
    " - Training Dataset:  CutMix, beta=1, cutmix_prob=1\n",
    " - Sagemaker Notebook must be of type, conda_pytorch_p36\n",
    " \n",
    "#### Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy \n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 1)) (1.18.1)\n",
      "Requirement already satisfied: torch>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 2)) (1.4.0)\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 3)) (0.5.0)\n",
      "Requirement already satisfied: fvcore in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (0.1.1.post20200711)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 5)) (4.44.1)\n",
      "Requirement already satisfied: yacs in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 6)) (0.1.7)\n",
      "Requirement already satisfied: apex from git+https://github.com/NVIDIA/apex.git#egg=apex in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 7)) (0.1)\n",
      "Requirement already satisfied: termcolor in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 8)) (1.1.0)\n",
      "Requirement already satisfied: thop<0.0.31.post2004070130 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 9)) (0.0.31.post2001170342)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 3)) (1.14.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 3)) (7.0.0)\n",
      "Requirement already satisfied: portalocker in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from fvcore->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (1.7.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from fvcore->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (5.3.1)\n",
      "Requirement already satisfied: tabulate in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from fvcore->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (0.8.7)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: tensorboard in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (2.2.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.7.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (3.2.2)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (3.12.2)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.30.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (2.23.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.18.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (46.1.3.post20200330)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.0.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.9.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.34.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.14.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.18.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (1.5.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (1.25.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.4.5.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard) (3.4.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard) (2.2.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r '/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt'\n",
    "\n",
    "# Need to add this to requirements.txt\n",
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-11 01:20:41] __main__ INFO: \u001b[0mdevice: cuda\n",
      "cudnn:\n",
      "  benchmark: True\n",
      "  deterministic: False\n",
      "dataset:\n",
      "  name: CIFAR10_CM_1\n",
      "  dataset_dir: ''\n",
      "  image_size: 32\n",
      "  n_channels: 3\n",
      "  n_classes: 10\n",
      "model:\n",
      "  type: cifar\n",
      "  name: densenet\n",
      "  init_mode: kaiming_fan_out\n",
      "  vgg:\n",
      "    n_channels: [64, 128, 256, 512, 512]\n",
      "    n_layers: [2, 2, 3, 3, 3]\n",
      "    use_bn: True\n",
      "  resnet:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "  resnet_preact:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "  wrn:\n",
      "    depth: 28\n",
      "    initial_channels: 16\n",
      "    widening_factor: 10\n",
      "    drop_rate: 0.0\n",
      "  densenet:\n",
      "    depth: 100\n",
      "    n_blocks: [6, 12, 24, 16]\n",
      "    block_type: bottleneck\n",
      "    growth_rate: 12\n",
      "    drop_rate: 0.0\n",
      "    compression_rate: 0.5\n",
      "  pyramidnet:\n",
      "    depth: 272\n",
      "    n_blocks: [3, 24, 36, 3]\n",
      "    initial_channels: 16\n",
      "    block_type: bottleneck\n",
      "    alpha: 200\n",
      "  resnext:\n",
      "    depth: 29\n",
      "    n_blocks: [3, 4, 6, 3]\n",
      "    initial_channels: 64\n",
      "    cardinality: 8\n",
      "    base_channels: 4\n",
      "  shake_shake:\n",
      "    depth: 26\n",
      "    initial_channels: 96\n",
      "    shake_forward: True\n",
      "    shake_backward: True\n",
      "    shake_image: True\n",
      "  se_resnet_preact:\n",
      "    depth: 110\n",
      "    initial_channels: 16\n",
      "    se_reduction: 16\n",
      "    block_type: basic\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "train:\n",
      "  checkpoint: ''\n",
      "  resume: False\n",
      "  precision: O0\n",
      "  batch_size: 64\n",
      "  subdivision: 1\n",
      "  optimizer: sgd\n",
      "  base_lr: 0.1\n",
      "  momentum: 0.9\n",
      "  nesterov: True\n",
      "  weight_decay: 0.0001\n",
      "  no_weight_decay_on_bn: False\n",
      "  gradient_clip: 0\n",
      "  start_epoch: 0\n",
      "  seed: 0\n",
      "  val_first: True\n",
      "  val_period: 1\n",
      "  val_ratio: 0.1\n",
      "  use_test_as_val: False\n",
      "  output_dir: /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_cm_1_1/exp00\n",
      "  log_period: 100\n",
      "  checkpoint_period: 100\n",
      "  use_tensorboard: True\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: True\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "  distributed: False\n",
      "  dist:\n",
      "    backend: nccl\n",
      "    init_method: env://\n",
      "    world_size: -1\n",
      "    node_rank: -1\n",
      "    local_rank: 0\n",
      "    use_sync_bn: False\n",
      "tensorboard:\n",
      "  train_images: False\n",
      "  val_images: False\n",
      "  model_params: False\n",
      "optim:\n",
      "  adam:\n",
      "    betas: (0.9, 0.999)\n",
      "  lars:\n",
      "    eps: 1e-09\n",
      "    threshold: 0.01\n",
      "  adabound:\n",
      "    betas: (0.9, 0.999)\n",
      "    final_lr: 0.1\n",
      "    gamma: 0.001\n",
      "scheduler:\n",
      "  epochs: 400\n",
      "  warmup:\n",
      "    type: none\n",
      "    epochs: 0\n",
      "    start_factor: 0.001\n",
      "    exponent: 4\n",
      "  type: multistep\n",
      "  milestones: [150, 225]\n",
      "  lr_decay: 0.1\n",
      "  lr_min_factor: 0.001\n",
      "  T0: 10\n",
      "  T_mul: 1.0\n",
      "validation:\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: False\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "augmentation:\n",
      "  use_random_crop: True\n",
      "  use_random_horizontal_flip: True\n",
      "  use_cutout: False\n",
      "  use_random_erasing: False\n",
      "  use_dual_cutout: False\n",
      "  use_mixup: False\n",
      "  use_ricap: False\n",
      "  use_cutmix: False\n",
      "  use_label_smoothing: False\n",
      "  random_crop:\n",
      "    padding: 4\n",
      "    fill: 0\n",
      "    padding_mode: constant\n",
      "  random_horizontal_flip:\n",
      "    prob: 0.5\n",
      "  cutout:\n",
      "    prob: 1.0\n",
      "    mask_size: 16\n",
      "    cut_inside: False\n",
      "    mask_color: 0\n",
      "    dual_cutout_alpha: 0.1\n",
      "  random_erasing:\n",
      "    prob: 0.5\n",
      "    area_ratio_range: [0.02, 0.4]\n",
      "    min_aspect_ratio: 0.3\n",
      "    max_attempt: 20\n",
      "  mixup:\n",
      "    alpha: 1.0\n",
      "  ricap:\n",
      "    beta: 0.3\n",
      "  cutmix:\n",
      "    alpha: 1.0\n",
      "  label_smoothing:\n",
      "    epsilon: 0.1\n",
      "tta:\n",
      "  use_resize: False\n",
      "  use_center_crop: False\n",
      "  resize: 256\n",
      "test:\n",
      "  checkpoint: ''\n",
      "  output_dir: ''\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    pin_memory: False\n",
      "\u001b[32m[2020-07-11 01:20:41] __main__ INFO: \u001b[0menv_info:\n",
      "  pytorch_version: 1.4.0\n",
      "  cuda_version: 10.1\n",
      "  cudnn_version: 7603\n",
      "  num_gpus: 1\n",
      "  gpu_name: Tesla K80\n",
      "  gpu_capability: 3.7\n",
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /home/ec2-user/.torch/datasets/CIFAR10/cifar-10-python.tar.gz\n",
      "170500096it [00:03, 53114603.69it/s]                                            \n",
      "Extracting /home/ec2-user/.torch/datasets/CIFAR10/cifar-10-python.tar.gz to /home/ec2-user/.torch/datasets/CIFAR10\n",
      "\u001b[32m[2020-07-11 01:21:37] __main__ INFO: \u001b[0mMACs  : 296.49M\n",
      "\u001b[32m[2020-07-11 01:21:37] __main__ INFO: \u001b[0m#params: 769.16K\n",
      "Selected optimization level O0:  Pure FP32 training.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n",
      "\u001b[32m[2020-07-11 01:21:37] __main__ INFO: \u001b[0mVal 0\n",
      "\u001b[32m[2020-07-11 01:21:49] __main__ INFO: \u001b[0mEpoch 0 loss 26263087.5488 acc@1 0.1012 acc@5 0.5040\n",
      "\u001b[32m[2020-07-11 01:21:49] __main__ INFO: \u001b[0mElapsed 11.47\n",
      "\u001b[32m[2020-07-11 01:21:49] __main__ INFO: \u001b[0mTrain 1 0\n",
      "\u001b[32m[2020-07-11 01:22:22] __main__ INFO: \u001b[0mEpoch 1 Step 100/703 lr 0.100000 loss 2.1331 (2.4485) acc@1 0.2629 (0.1790) acc@5 0.7145 (0.6611)\n",
      "\u001b[32m[2020-07-11 01:22:54] __main__ INFO: \u001b[0mEpoch 1 Step 200/703 lr 0.100000 loss 2.1105 (2.2931) acc@1 0.2184 (0.2047) acc@5 0.7274 (0.6943)\n",
      "\u001b[32m[2020-07-11 01:23:26] __main__ INFO: \u001b[0mEpoch 1 Step 300/703 lr 0.100000 loss 2.1235 (2.2263) acc@1 0.1876 (0.2159) acc@5 0.7494 (0.7101)\n",
      "\u001b[32m[2020-07-11 01:23:58] __main__ INFO: \u001b[0mEpoch 1 Step 400/703 lr 0.100000 loss 2.0901 (2.1846) acc@1 0.2083 (0.2270) acc@5 0.8013 (0.7205)\n",
      "\u001b[32m[2020-07-11 01:24:30] __main__ INFO: \u001b[0mEpoch 1 Step 500/703 lr 0.100000 loss 2.1405 (2.1549) acc@1 0.2019 (0.2361) acc@5 0.7477 (0.7300)\n",
      "\u001b[32m[2020-07-11 01:25:02] __main__ INFO: \u001b[0mEpoch 1 Step 600/703 lr 0.100000 loss 1.9643 (2.1330) acc@1 0.2646 (0.2431) acc@5 0.7842 (0.7368)\n",
      "\u001b[32m[2020-07-11 01:25:34] __main__ INFO: \u001b[0mEpoch 1 Step 700/703 lr 0.100000 loss 1.9477 (2.1120) acc@1 0.3019 (0.2503) acc@5 0.8279 (0.7438)\n",
      "\u001b[32m[2020-07-11 01:25:35] __main__ INFO: \u001b[0mEpoch 1 Step 703/703 lr 0.100000 loss 2.0178 (2.1115) acc@1 0.3125 (0.2504) acc@5 0.7982 (0.7439)\n",
      "\u001b[32m[2020-07-11 01:25:35] __main__ INFO: \u001b[0mElapsed 226.56\n",
      "\u001b[32m[2020-07-11 01:25:35] __main__ INFO: \u001b[0mVal 1\n",
      "\u001b[32m[2020-07-11 01:25:43] __main__ INFO: \u001b[0mEpoch 1 loss 1.5326 acc@1 0.4586 acc@5 0.9180\n",
      "\u001b[32m[2020-07-11 01:25:43] __main__ INFO: \u001b[0mElapsed 7.74\n",
      "\u001b[32m[2020-07-11 01:25:43] __main__ INFO: \u001b[0mTrain 2 703\n",
      "\u001b[32m[2020-07-11 01:26:15] __main__ INFO: \u001b[0mEpoch 2 Step 100/703 lr 0.100000 loss 2.0329 (1.9769) acc@1 0.2688 (0.2993) acc@5 0.7369 (0.7856)\n",
      "\u001b[32m[2020-07-11 01:26:47] __main__ INFO: \u001b[0mEpoch 2 Step 200/703 lr 0.100000 loss 1.9048 (1.9594) acc@1 0.3581 (0.3096) acc@5 0.7776 (0.7919)\n",
      "\u001b[32m[2020-07-11 01:27:19] __main__ INFO: \u001b[0mEpoch 2 Step 300/703 lr 0.100000 loss 1.9495 (1.9513) acc@1 0.2631 (0.3120) acc@5 0.7881 (0.7940)\n",
      "\u001b[32m[2020-07-11 01:27:51] __main__ INFO: \u001b[0mEpoch 2 Step 400/703 lr 0.100000 loss 1.9303 (1.9425) acc@1 0.3253 (0.3166) acc@5 0.8309 (0.7976)\n",
      "\u001b[32m[2020-07-11 01:28:23] __main__ INFO: \u001b[0mEpoch 2 Step 500/703 lr 0.100000 loss 1.9373 (1.9356) acc@1 0.2993 (0.3205) acc@5 0.8518 (0.8005)\n",
      "\u001b[32m[2020-07-11 01:28:55] __main__ INFO: \u001b[0mEpoch 2 Step 600/703 lr 0.100000 loss 1.8349 (1.9291) acc@1 0.3482 (0.3244) acc@5 0.8278 (0.8025)\n",
      "\u001b[32m[2020-07-11 01:29:27] __main__ INFO: \u001b[0mEpoch 2 Step 700/703 lr 0.100000 loss 1.8400 (1.9222) acc@1 0.3309 (0.3279) acc@5 0.8509 (0.8044)\n",
      "\u001b[32m[2020-07-11 01:29:28] __main__ INFO: \u001b[0mEpoch 2 Step 703/703 lr 0.100000 loss 1.9266 (1.9221) acc@1 0.3482 (0.3280) acc@5 0.8240 (0.8044)\n",
      "\u001b[32m[2020-07-11 01:29:28] __main__ INFO: \u001b[0mElapsed 225.39\n",
      "\u001b[32m[2020-07-11 01:29:28] __main__ INFO: \u001b[0mVal 2\n",
      "\u001b[32m[2020-07-11 01:29:36] __main__ INFO: \u001b[0mEpoch 2 loss 1.2711 acc@1 0.5690 acc@5 0.9416\n",
      "\u001b[32m[2020-07-11 01:29:36] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-11 01:29:36] __main__ INFO: \u001b[0mTrain 3 1406\n",
      "\u001b[32m[2020-07-11 01:30:08] __main__ INFO: \u001b[0mEpoch 3 Step 100/703 lr 0.100000 loss 1.7791 (1.8337) acc@1 0.3949 (0.3751) acc@5 0.8370 (0.8305)\n",
      "\u001b[32m[2020-07-11 01:30:41] __main__ INFO: \u001b[0mEpoch 3 Step 200/703 lr 0.100000 loss 1.8938 (1.8442) acc@1 0.3036 (0.3704) acc@5 0.8036 (0.8257)\n",
      "\u001b[32m[2020-07-11 01:31:13] __main__ INFO: \u001b[0mEpoch 3 Step 300/703 lr 0.100000 loss 1.7343 (1.8373) acc@1 0.3103 (0.3728) acc@5 0.8660 (0.8278)\n",
      "\u001b[32m[2020-07-11 01:31:45] __main__ INFO: \u001b[0mEpoch 3 Step 400/703 lr 0.100000 loss 1.8227 (1.8312) acc@1 0.3436 (0.3742) acc@5 0.8279 (0.8304)\n"
     ]
    }
   ],
   "source": [
    "# Train the model per the settings specified in the original paper\n",
    "os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "!python train.py --config configs/cifar/densenet.yaml \\\n",
    "    model.densenet.depth 100 \\\n",
    "    model.densenet.growth_rate 12 \\\n",
    "    train.batch_size 64 \\\n",
    "    train.base_lr 0.1 \\\n",
    "    dataset.name CIFAR10_CM_1 \\\n",
    "    train.output_dir /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_cm_1_1/exp00 \\\n",
    "    scheduler.epochs 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refine the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-13 11:37:43] __main__ INFO: \u001b[0mdevice: cuda\n",
      "cudnn:\n",
      "  benchmark: True\n",
      "  deterministic: False\n",
      "dataset:\n",
      "  name: CIFAR10\n",
      "  dataset_dir: ~/.torch/datasets/CIFAR10\n",
      "  image_size: 32\n",
      "  n_channels: 3\n",
      "  n_classes: 10\n",
      "model:\n",
      "  type: cifar\n",
      "  name: densenet\n",
      "  init_mode: kaiming_fan_out\n",
      "  vgg:\n",
      "    n_channels: [64, 128, 256, 512, 512]\n",
      "    n_layers: [2, 2, 3, 3, 3]\n",
      "    use_bn: True\n",
      "  resnet:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "  resnet_preact:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "  wrn:\n",
      "    depth: 28\n",
      "    initial_channels: 16\n",
      "    widening_factor: 10\n",
      "    drop_rate: 0.0\n",
      "  densenet:\n",
      "    depth: 100\n",
      "    n_blocks: [6, 12, 24, 16]\n",
      "    block_type: bottleneck\n",
      "    growth_rate: 12\n",
      "    drop_rate: 0.0\n",
      "    compression_rate: 0.5\n",
      "  pyramidnet:\n",
      "    depth: 272\n",
      "    n_blocks: [3, 24, 36, 3]\n",
      "    initial_channels: 16\n",
      "    block_type: bottleneck\n",
      "    alpha: 200\n",
      "  resnext:\n",
      "    depth: 29\n",
      "    n_blocks: [3, 4, 6, 3]\n",
      "    initial_channels: 64\n",
      "    cardinality: 8\n",
      "    base_channels: 4\n",
      "  shake_shake:\n",
      "    depth: 26\n",
      "    initial_channels: 96\n",
      "    shake_forward: True\n",
      "    shake_backward: True\n",
      "    shake_image: True\n",
      "  se_resnet_preact:\n",
      "    depth: 110\n",
      "    initial_channels: 16\n",
      "    se_reduction: 16\n",
      "    block_type: basic\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "train:\n",
      "  checkpoint: /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_cm_1_1/exp00/checkpoint_00400.pth\n",
      "  resume: False\n",
      "  precision: O0\n",
      "  batch_size: 64\n",
      "  subdivision: 1\n",
      "  optimizer: sgd\n",
      "  base_lr: 0.001\n",
      "  momentum: 0.9\n",
      "  nesterov: True\n",
      "  weight_decay: 0.0001\n",
      "  no_weight_decay_on_bn: False\n",
      "  gradient_clip: 0\n",
      "  start_epoch: 0\n",
      "  seed: 0\n",
      "  val_first: True\n",
      "  val_period: 1\n",
      "  val_ratio: 0.1\n",
      "  use_test_as_val: False\n",
      "  output_dir: /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_cm_1_1/exp00_resume400_50\n",
      "  log_period: 100\n",
      "  checkpoint_period: 100\n",
      "  use_tensorboard: True\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: True\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "  distributed: False\n",
      "  dist:\n",
      "    backend: nccl\n",
      "    init_method: env://\n",
      "    world_size: -1\n",
      "    node_rank: -1\n",
      "    local_rank: 0\n",
      "    use_sync_bn: False\n",
      "tensorboard:\n",
      "  train_images: False\n",
      "  val_images: False\n",
      "  model_params: False\n",
      "optim:\n",
      "  adam:\n",
      "    betas: (0.9, 0.999)\n",
      "  lars:\n",
      "    eps: 1e-09\n",
      "    threshold: 0.01\n",
      "  adabound:\n",
      "    betas: (0.9, 0.999)\n",
      "    final_lr: 0.1\n",
      "    gamma: 0.001\n",
      "scheduler:\n",
      "  epochs: 50\n",
      "  warmup:\n",
      "    type: none\n",
      "    epochs: 0\n",
      "    start_factor: 0.001\n",
      "    exponent: 4\n",
      "  type: multistep\n",
      "  milestones: [150, 225]\n",
      "  lr_decay: 0.1\n",
      "  lr_min_factor: 0.001\n",
      "  T0: 10\n",
      "  T_mul: 1.0\n",
      "validation:\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: False\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "augmentation:\n",
      "  use_random_crop: True\n",
      "  use_random_horizontal_flip: True\n",
      "  use_cutout: False\n",
      "  use_random_erasing: False\n",
      "  use_dual_cutout: False\n",
      "  use_mixup: False\n",
      "  use_ricap: False\n",
      "  use_cutmix: False\n",
      "  use_label_smoothing: False\n",
      "  random_crop:\n",
      "    padding: 4\n",
      "    fill: 0\n",
      "    padding_mode: constant\n",
      "  random_horizontal_flip:\n",
      "    prob: 0.5\n",
      "  cutout:\n",
      "    prob: 1.0\n",
      "    mask_size: 16\n",
      "    cut_inside: False\n",
      "    mask_color: 0\n",
      "    dual_cutout_alpha: 0.1\n",
      "  random_erasing:\n",
      "    prob: 0.5\n",
      "    area_ratio_range: [0.02, 0.4]\n",
      "    min_aspect_ratio: 0.3\n",
      "    max_attempt: 20\n",
      "  mixup:\n",
      "    alpha: 1.0\n",
      "  ricap:\n",
      "    beta: 0.3\n",
      "  cutmix:\n",
      "    alpha: 1.0\n",
      "  label_smoothing:\n",
      "    epsilon: 0.1\n",
      "tta:\n",
      "  use_resize: False\n",
      "  use_center_crop: False\n",
      "  resize: 256\n",
      "test:\n",
      "  checkpoint: ''\n",
      "  output_dir: ''\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    pin_memory: False\n",
      "\u001b[32m[2020-07-13 11:37:43] __main__ INFO: \u001b[0menv_info:\n",
      "  pytorch_version: 1.4.0\n",
      "  cuda_version: 10.1\n",
      "  cudnn_version: 7603\n",
      "  num_gpus: 1\n",
      "  gpu_name: Tesla K80\n",
      "  gpu_capability: 3.7\n",
      "Files already downloaded and verified\n",
      "\u001b[32m[2020-07-13 11:37:46] __main__ INFO: \u001b[0mMACs  : 296.49M\n",
      "\u001b[32m[2020-07-13 11:37:46] __main__ INFO: \u001b[0m#params: 769.16K\n",
      "Selected optimization level O0:  Pure FP32 training.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n",
      "\u001b[32m[2020-07-13 11:37:46] __main__ INFO: \u001b[0mVal 0\n",
      "\u001b[32m[2020-07-13 11:37:58] __main__ INFO: \u001b[0mEpoch 0 loss 0.4095 acc@1 0.9188 acc@5 0.9868\n",
      "\u001b[32m[2020-07-13 11:37:58] __main__ INFO: \u001b[0mElapsed 11.43\n",
      "\u001b[32m[2020-07-13 11:37:58] __main__ INFO: \u001b[0mTrain 1 0\n",
      "\u001b[32m[2020-07-13 11:38:32] __main__ INFO: \u001b[0mEpoch 1 Step 100/703 lr 0.001000 loss 0.0811 (0.1181) acc@1 0.9844 (0.9748) acc@5 1.0000 (0.9989)\n",
      "\u001b[32m[2020-07-13 11:39:03] __main__ INFO: \u001b[0mEpoch 1 Step 200/703 lr 0.001000 loss 0.0164 (0.1060) acc@1 1.0000 (0.9752) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-07-13 11:39:35] __main__ INFO: \u001b[0mEpoch 1 Step 300/703 lr 0.001000 loss 0.2545 (0.0948) acc@1 0.9375 (0.9767) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-07-13 11:40:07] __main__ INFO: \u001b[0mEpoch 1 Step 400/703 lr 0.001000 loss 0.1204 (0.0904) acc@1 0.9844 (0.9771) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-07-13 11:40:40] __main__ INFO: \u001b[0mEpoch 1 Step 500/703 lr 0.001000 loss 0.0382 (0.0874) acc@1 0.9688 (0.9771) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-07-13 11:41:12] __main__ INFO: \u001b[0mEpoch 1 Step 600/703 lr 0.001000 loss 0.0864 (0.0836) acc@1 0.9531 (0.9777) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-07-13 11:41:44] __main__ INFO: \u001b[0mEpoch 1 Step 700/703 lr 0.001000 loss 0.0178 (0.0815) acc@1 1.0000 (0.9780) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-07-13 11:41:45] __main__ INFO: \u001b[0mEpoch 1 Step 703/703 lr 0.001000 loss 0.0458 (0.0813) acc@1 0.9844 (0.9781) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-07-13 11:41:45] __main__ INFO: \u001b[0mElapsed 227.04\n",
      "\u001b[32m[2020-07-13 11:41:45] __main__ INFO: \u001b[0mVal 1\n",
      "\u001b[32m[2020-07-13 11:41:53] __main__ INFO: \u001b[0mEpoch 1 loss 0.1980 acc@1 0.9460 acc@5 0.9970\n",
      "\u001b[32m[2020-07-13 11:41:53] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-13 11:41:53] __main__ INFO: \u001b[0mTrain 2 703\n",
      "\u001b[32m[2020-07-13 11:42:25] __main__ INFO: \u001b[0mEpoch 2 Step 100/703 lr 0.001000 loss 0.0194 (0.0463) acc@1 1.0000 (0.9881) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-13 11:42:57] __main__ INFO: \u001b[0mEpoch 2 Step 200/703 lr 0.001000 loss 0.0243 (0.0499) acc@1 0.9844 (0.9851) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-13 11:43:29] __main__ INFO: \u001b[0mEpoch 2 Step 300/703 lr 0.001000 loss 0.0618 (0.0493) acc@1 0.9844 (0.9851) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-13 11:44:01] __main__ INFO: \u001b[0mEpoch 2 Step 400/703 lr 0.001000 loss 0.0147 (0.0488) acc@1 1.0000 (0.9853) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-13 11:44:33] __main__ INFO: \u001b[0mEpoch 2 Step 500/703 lr 0.001000 loss 0.0274 (0.0489) acc@1 0.9844 (0.9851) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-13 11:45:06] __main__ INFO: \u001b[0mEpoch 2 Step 600/703 lr 0.001000 loss 0.0107 (0.0488) acc@1 1.0000 (0.9851) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-13 11:45:38] __main__ INFO: \u001b[0mEpoch 2 Step 700/703 lr 0.001000 loss 0.0084 (0.0484) acc@1 1.0000 (0.9851) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 11:45:39] __main__ INFO: \u001b[0mEpoch 2 Step 703/703 lr 0.001000 loss 0.0164 (0.0483) acc@1 1.0000 (0.9852) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 11:45:39] __main__ INFO: \u001b[0mElapsed 226.03\n",
      "\u001b[32m[2020-07-13 11:45:39] __main__ INFO: \u001b[0mVal 2\n",
      "\u001b[32m[2020-07-13 11:45:47] __main__ INFO: \u001b[0mEpoch 2 loss 0.2116 acc@1 0.9458 acc@5 0.9964\n",
      "\u001b[32m[2020-07-13 11:45:47] __main__ INFO: \u001b[0mElapsed 7.82\n",
      "\u001b[32m[2020-07-13 11:45:47] __main__ INFO: \u001b[0mTrain 3 1406\n",
      "\u001b[32m[2020-07-13 11:46:19] __main__ INFO: \u001b[0mEpoch 3 Step 100/703 lr 0.001000 loss 0.1077 (0.0300) acc@1 0.9844 (0.9922) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 11:46:51] __main__ INFO: \u001b[0mEpoch 3 Step 200/703 lr 0.001000 loss 0.0048 (0.0344) acc@1 1.0000 (0.9895) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 11:47:23] __main__ INFO: \u001b[0mEpoch 3 Step 300/703 lr 0.001000 loss 0.0220 (0.0365) acc@1 1.0000 (0.9886) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-13 11:47:55] __main__ INFO: \u001b[0mEpoch 3 Step 400/703 lr 0.001000 loss 0.0450 (0.0367) acc@1 0.9844 (0.9882) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 11:48:27] __main__ INFO: \u001b[0mEpoch 3 Step 500/703 lr 0.001000 loss 0.0562 (0.0365) acc@1 0.9688 (0.9884) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 11:48:59] __main__ INFO: \u001b[0mEpoch 3 Step 600/703 lr 0.001000 loss 0.0137 (0.0366) acc@1 1.0000 (0.9886) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-13 11:49:31] __main__ INFO: \u001b[0mEpoch 3 Step 700/703 lr 0.001000 loss 0.0850 (0.0373) acc@1 0.9688 (0.9884) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-13 11:49:32] __main__ INFO: \u001b[0mEpoch 3 Step 703/703 lr 0.001000 loss 0.0109 (0.0372) acc@1 1.0000 (0.9884) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-13 11:49:32] __main__ INFO: \u001b[0mElapsed 225.35\n",
      "\u001b[32m[2020-07-13 11:49:32] __main__ INFO: \u001b[0mVal 3\n",
      "\u001b[32m[2020-07-13 11:49:40] __main__ INFO: \u001b[0mEpoch 3 loss 0.2134 acc@1 0.9472 acc@5 0.9966\n",
      "\u001b[32m[2020-07-13 11:49:40] __main__ INFO: \u001b[0mElapsed 7.75\n",
      "\u001b[32m[2020-07-13 11:49:40] __main__ INFO: \u001b[0mTrain 4 2109\n",
      "\u001b[32m[2020-07-13 11:50:12] __main__ INFO: \u001b[0mEpoch 4 Step 100/703 lr 0.001000 loss 0.0400 (0.0343) acc@1 0.9844 (0.9897) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 11:50:44] __main__ INFO: \u001b[0mEpoch 4 Step 200/703 lr 0.001000 loss 0.0252 (0.0312) acc@1 0.9844 (0.9901) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 11:51:16] __main__ INFO: \u001b[0mEpoch 4 Step 300/703 lr 0.001000 loss 0.0066 (0.0287) acc@1 1.0000 (0.9910) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 11:51:48] __main__ INFO: \u001b[0mEpoch 4 Step 400/703 lr 0.001000 loss 0.0552 (0.0304) acc@1 0.9844 (0.9904) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 11:52:20] __main__ INFO: \u001b[0mEpoch 4 Step 500/703 lr 0.001000 loss 0.0233 (0.0311) acc@1 1.0000 (0.9900) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 11:52:52] __main__ INFO: \u001b[0mEpoch 4 Step 600/703 lr 0.001000 loss 0.0056 (0.0310) acc@1 1.0000 (0.9901) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 11:53:23] __main__ INFO: \u001b[0mEpoch 4 Step 700/703 lr 0.001000 loss 0.0073 (0.0317) acc@1 1.0000 (0.9898) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 11:53:24] __main__ INFO: \u001b[0mEpoch 4 Step 703/703 lr 0.001000 loss 0.0092 (0.0317) acc@1 1.0000 (0.9899) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 11:53:24] __main__ INFO: \u001b[0mElapsed 224.77\n",
      "\u001b[32m[2020-07-13 11:53:24] __main__ INFO: \u001b[0mVal 4\n",
      "\u001b[32m[2020-07-13 11:53:32] __main__ INFO: \u001b[0mEpoch 4 loss 0.2123 acc@1 0.9458 acc@5 0.9962\n",
      "\u001b[32m[2020-07-13 11:53:32] __main__ INFO: \u001b[0mElapsed 7.75\n",
      "\u001b[32m[2020-07-13 11:53:32] __main__ INFO: \u001b[0mTrain 5 2812\n",
      "\u001b[32m[2020-07-13 11:54:04] __main__ INFO: \u001b[0mEpoch 5 Step 100/703 lr 0.001000 loss 0.0148 (0.0302) acc@1 1.0000 (0.9908) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 11:54:36] __main__ INFO: \u001b[0mEpoch 5 Step 200/703 lr 0.001000 loss 0.0239 (0.0279) acc@1 0.9844 (0.9912) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 11:55:08] __main__ INFO: \u001b[0mEpoch 5 Step 300/703 lr 0.001000 loss 0.0275 (0.0271) acc@1 0.9844 (0.9917) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 11:55:40] __main__ INFO: \u001b[0mEpoch 5 Step 400/703 lr 0.001000 loss 0.0744 (0.0274) acc@1 0.9844 (0.9917) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 11:56:12] __main__ INFO: \u001b[0mEpoch 5 Step 500/703 lr 0.001000 loss 0.0546 (0.0276) acc@1 0.9688 (0.9915) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 11:56:44] __main__ INFO: \u001b[0mEpoch 5 Step 600/703 lr 0.001000 loss 0.0038 (0.0276) acc@1 1.0000 (0.9915) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 11:57:16] __main__ INFO: \u001b[0mEpoch 5 Step 700/703 lr 0.001000 loss 0.0066 (0.0281) acc@1 1.0000 (0.9912) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 11:57:17] __main__ INFO: \u001b[0mEpoch 5 Step 703/703 lr 0.001000 loss 0.0403 (0.0281) acc@1 0.9844 (0.9912) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 11:57:17] __main__ INFO: \u001b[0mElapsed 225.01\n",
      "\u001b[32m[2020-07-13 11:57:17] __main__ INFO: \u001b[0mVal 5\n",
      "\u001b[32m[2020-07-13 11:57:25] __main__ INFO: \u001b[0mEpoch 5 loss 0.2246 acc@1 0.9446 acc@5 0.9968\n",
      "\u001b[32m[2020-07-13 11:57:25] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-13 11:57:25] __main__ INFO: \u001b[0mTrain 6 3515\n",
      "\u001b[32m[2020-07-13 11:57:57] __main__ INFO: \u001b[0mEpoch 6 Step 100/703 lr 0.001000 loss 0.0089 (0.0181) acc@1 1.0000 (0.9950) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 11:58:29] __main__ INFO: \u001b[0mEpoch 6 Step 200/703 lr 0.001000 loss 0.0122 (0.0206) acc@1 1.0000 (0.9938) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 11:59:01] __main__ INFO: \u001b[0mEpoch 6 Step 300/703 lr 0.001000 loss 0.0094 (0.0224) acc@1 1.0000 (0.9929) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-13 11:59:33] __main__ INFO: \u001b[0mEpoch 6 Step 400/703 lr 0.001000 loss 0.0127 (0.0223) acc@1 1.0000 (0.9927) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:00:05] __main__ INFO: \u001b[0mEpoch 6 Step 500/703 lr 0.001000 loss 0.0497 (0.0225) acc@1 0.9844 (0.9928) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:00:37] __main__ INFO: \u001b[0mEpoch 6 Step 600/703 lr 0.001000 loss 0.0085 (0.0226) acc@1 1.0000 (0.9928) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:01:09] __main__ INFO: \u001b[0mEpoch 6 Step 700/703 lr 0.001000 loss 0.1191 (0.0236) acc@1 0.9844 (0.9925) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:01:10] __main__ INFO: \u001b[0mEpoch 6 Step 703/703 lr 0.001000 loss 0.0043 (0.0236) acc@1 1.0000 (0.9926) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:01:10] __main__ INFO: \u001b[0mElapsed 225.00\n",
      "\u001b[32m[2020-07-13 12:01:10] __main__ INFO: \u001b[0mVal 6\n",
      "\u001b[32m[2020-07-13 12:01:18] __main__ INFO: \u001b[0mEpoch 6 loss 0.2223 acc@1 0.9446 acc@5 0.9978\n",
      "\u001b[32m[2020-07-13 12:01:18] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-13 12:01:18] __main__ INFO: \u001b[0mTrain 7 4218\n",
      "\u001b[32m[2020-07-13 12:01:50] __main__ INFO: \u001b[0mEpoch 7 Step 100/703 lr 0.001000 loss 0.0120 (0.0222) acc@1 1.0000 (0.9928) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:02:22] __main__ INFO: \u001b[0mEpoch 7 Step 200/703 lr 0.001000 loss 0.0047 (0.0227) acc@1 1.0000 (0.9927) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:02:54] __main__ INFO: \u001b[0mEpoch 7 Step 300/703 lr 0.001000 loss 0.0256 (0.0220) acc@1 0.9844 (0.9930) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:03:26] __main__ INFO: \u001b[0mEpoch 7 Step 400/703 lr 0.001000 loss 0.0276 (0.0218) acc@1 0.9844 (0.9930) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:03:58] __main__ INFO: \u001b[0mEpoch 7 Step 500/703 lr 0.001000 loss 0.0306 (0.0219) acc@1 0.9844 (0.9928) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:04:30] __main__ INFO: \u001b[0mEpoch 7 Step 600/703 lr 0.001000 loss 0.0041 (0.0221) acc@1 1.0000 (0.9927) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:05:02] __main__ INFO: \u001b[0mEpoch 7 Step 700/703 lr 0.001000 loss 0.0214 (0.0224) acc@1 1.0000 (0.9927) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:05:03] __main__ INFO: \u001b[0mEpoch 7 Step 703/703 lr 0.001000 loss 0.0218 (0.0224) acc@1 0.9844 (0.9927) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:05:03] __main__ INFO: \u001b[0mElapsed 225.27\n",
      "\u001b[32m[2020-07-13 12:05:03] __main__ INFO: \u001b[0mVal 7\n",
      "\u001b[32m[2020-07-13 12:05:11] __main__ INFO: \u001b[0mEpoch 7 loss 0.2233 acc@1 0.9418 acc@5 0.9972\n",
      "\u001b[32m[2020-07-13 12:05:11] __main__ INFO: \u001b[0mElapsed 7.75\n",
      "\u001b[32m[2020-07-13 12:05:11] __main__ INFO: \u001b[0mTrain 8 4921\n",
      "\u001b[32m[2020-07-13 12:05:43] __main__ INFO: \u001b[0mEpoch 8 Step 100/703 lr 0.001000 loss 0.0108 (0.0190) acc@1 1.0000 (0.9944) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:06:15] __main__ INFO: \u001b[0mEpoch 8 Step 200/703 lr 0.001000 loss 0.0739 (0.0184) acc@1 0.9688 (0.9950) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:06:47] __main__ INFO: \u001b[0mEpoch 8 Step 300/703 lr 0.001000 loss 0.0062 (0.0175) acc@1 1.0000 (0.9950) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:07:19] __main__ INFO: \u001b[0mEpoch 8 Step 400/703 lr 0.001000 loss 0.0213 (0.0177) acc@1 1.0000 (0.9948) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:07:51] __main__ INFO: \u001b[0mEpoch 8 Step 500/703 lr 0.001000 loss 0.0028 (0.0177) acc@1 1.0000 (0.9948) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:08:23] __main__ INFO: \u001b[0mEpoch 8 Step 600/703 lr 0.001000 loss 0.0205 (0.0186) acc@1 0.9844 (0.9943) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:08:55] __main__ INFO: \u001b[0mEpoch 8 Step 700/703 lr 0.001000 loss 0.0084 (0.0188) acc@1 1.0000 (0.9943) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:08:56] __main__ INFO: \u001b[0mEpoch 8 Step 703/703 lr 0.001000 loss 0.0248 (0.0189) acc@1 0.9844 (0.9942) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:08:56] __main__ INFO: \u001b[0mElapsed 224.99\n",
      "\u001b[32m[2020-07-13 12:08:56] __main__ INFO: \u001b[0mVal 8\n",
      "\u001b[32m[2020-07-13 12:09:03] __main__ INFO: \u001b[0mEpoch 8 loss 0.2277 acc@1 0.9430 acc@5 0.9974\n",
      "\u001b[32m[2020-07-13 12:09:03] __main__ INFO: \u001b[0mElapsed 7.73\n",
      "\u001b[32m[2020-07-13 12:09:03] __main__ INFO: \u001b[0mTrain 9 5624\n",
      "\u001b[32m[2020-07-13 12:09:36] __main__ INFO: \u001b[0mEpoch 9 Step 100/703 lr 0.001000 loss 0.0055 (0.0176) acc@1 1.0000 (0.9947) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:10:07] __main__ INFO: \u001b[0mEpoch 9 Step 200/703 lr 0.001000 loss 0.0062 (0.0190) acc@1 1.0000 (0.9941) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:10:39] __main__ INFO: \u001b[0mEpoch 9 Step 300/703 lr 0.001000 loss 0.0056 (0.0192) acc@1 1.0000 (0.9936) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:11:11] __main__ INFO: \u001b[0mEpoch 9 Step 400/703 lr 0.001000 loss 0.0077 (0.0193) acc@1 1.0000 (0.9938) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:11:43] __main__ INFO: \u001b[0mEpoch 9 Step 500/703 lr 0.001000 loss 0.0093 (0.0194) acc@1 1.0000 (0.9936) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:12:15] __main__ INFO: \u001b[0mEpoch 9 Step 600/703 lr 0.001000 loss 0.0024 (0.0191) acc@1 1.0000 (0.9938) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:12:47] __main__ INFO: \u001b[0mEpoch 9 Step 700/703 lr 0.001000 loss 0.0521 (0.0187) acc@1 0.9844 (0.9941) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:12:48] __main__ INFO: \u001b[0mEpoch 9 Step 703/703 lr 0.001000 loss 0.0025 (0.0186) acc@1 1.0000 (0.9941) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:12:48] __main__ INFO: \u001b[0mElapsed 224.82\n",
      "\u001b[32m[2020-07-13 12:12:48] __main__ INFO: \u001b[0mVal 9\n",
      "\u001b[32m[2020-07-13 12:12:56] __main__ INFO: \u001b[0mEpoch 9 loss 0.2342 acc@1 0.9426 acc@5 0.9960\n",
      "\u001b[32m[2020-07-13 12:12:56] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-13 12:12:56] __main__ INFO: \u001b[0mTrain 10 6327\n",
      "\u001b[32m[2020-07-13 12:13:28] __main__ INFO: \u001b[0mEpoch 10 Step 100/703 lr 0.001000 loss 0.0205 (0.0146) acc@1 0.9844 (0.9950) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:14:00] __main__ INFO: \u001b[0mEpoch 10 Step 200/703 lr 0.001000 loss 0.0017 (0.0159) acc@1 1.0000 (0.9946) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:14:32] __main__ INFO: \u001b[0mEpoch 10 Step 300/703 lr 0.001000 loss 0.0080 (0.0155) acc@1 1.0000 (0.9948) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:15:04] __main__ INFO: \u001b[0mEpoch 10 Step 400/703 lr 0.001000 loss 0.0094 (0.0159) acc@1 1.0000 (0.9948) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:15:36] __main__ INFO: \u001b[0mEpoch 10 Step 500/703 lr 0.001000 loss 0.0144 (0.0165) acc@1 1.0000 (0.9946) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:16:08] __main__ INFO: \u001b[0mEpoch 10 Step 600/703 lr 0.001000 loss 0.0186 (0.0170) acc@1 0.9844 (0.9947) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:16:40] __main__ INFO: \u001b[0mEpoch 10 Step 700/703 lr 0.001000 loss 0.0018 (0.0169) acc@1 1.0000 (0.9947) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:16:41] __main__ INFO: \u001b[0mEpoch 10 Step 703/703 lr 0.001000 loss 0.0365 (0.0171) acc@1 0.9844 (0.9946) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:16:41] __main__ INFO: \u001b[0mElapsed 225.32\n",
      "\u001b[32m[2020-07-13 12:16:41] __main__ INFO: \u001b[0mVal 10\n",
      "\u001b[32m[2020-07-13 12:16:49] __main__ INFO: \u001b[0mEpoch 10 loss 0.2359 acc@1 0.9470 acc@5 0.9958\n",
      "\u001b[32m[2020-07-13 12:16:49] __main__ INFO: \u001b[0mElapsed 7.75\n",
      "\u001b[32m[2020-07-13 12:16:49] __main__ INFO: \u001b[0mTrain 11 7030\n",
      "\u001b[32m[2020-07-13 12:17:21] __main__ INFO: \u001b[0mEpoch 11 Step 100/703 lr 0.001000 loss 0.0194 (0.0115) acc@1 0.9844 (0.9964) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:17:53] __main__ INFO: \u001b[0mEpoch 11 Step 200/703 lr 0.001000 loss 0.0028 (0.0123) acc@1 1.0000 (0.9964) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:18:25] __main__ INFO: \u001b[0mEpoch 11 Step 300/703 lr 0.001000 loss 0.0069 (0.0118) acc@1 1.0000 (0.9966) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:18:57] __main__ INFO: \u001b[0mEpoch 11 Step 400/703 lr 0.001000 loss 0.0095 (0.0120) acc@1 1.0000 (0.9966) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:19:29] __main__ INFO: \u001b[0mEpoch 11 Step 500/703 lr 0.001000 loss 0.0023 (0.0130) acc@1 1.0000 (0.9961) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:20:01] __main__ INFO: \u001b[0mEpoch 11 Step 600/703 lr 0.001000 loss 0.0110 (0.0131) acc@1 1.0000 (0.9962) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:20:33] __main__ INFO: \u001b[0mEpoch 11 Step 700/703 lr 0.001000 loss 0.0023 (0.0137) acc@1 1.0000 (0.9960) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:20:34] __main__ INFO: \u001b[0mEpoch 11 Step 703/703 lr 0.001000 loss 0.0043 (0.0137) acc@1 1.0000 (0.9960) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:20:34] __main__ INFO: \u001b[0mElapsed 224.89\n",
      "\u001b[32m[2020-07-13 12:20:34] __main__ INFO: \u001b[0mVal 11\n",
      "\u001b[32m[2020-07-13 12:20:42] __main__ INFO: \u001b[0mEpoch 11 loss 0.2304 acc@1 0.9430 acc@5 0.9964\n",
      "\u001b[32m[2020-07-13 12:20:42] __main__ INFO: \u001b[0mElapsed 7.83\n",
      "\u001b[32m[2020-07-13 12:20:42] __main__ INFO: \u001b[0mTrain 12 7733\n",
      "\u001b[32m[2020-07-13 12:21:14] __main__ INFO: \u001b[0mEpoch 12 Step 100/703 lr 0.001000 loss 0.0330 (0.0148) acc@1 0.9844 (0.9956) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:21:46] __main__ INFO: \u001b[0mEpoch 12 Step 200/703 lr 0.001000 loss 0.0070 (0.0134) acc@1 1.0000 (0.9958) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:22:18] __main__ INFO: \u001b[0mEpoch 12 Step 300/703 lr 0.001000 loss 0.0024 (0.0143) acc@1 1.0000 (0.9954) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:22:50] __main__ INFO: \u001b[0mEpoch 12 Step 400/703 lr 0.001000 loss 0.0034 (0.0142) acc@1 1.0000 (0.9954) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:23:22] __main__ INFO: \u001b[0mEpoch 12 Step 500/703 lr 0.001000 loss 0.0080 (0.0146) acc@1 1.0000 (0.9952) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:23:54] __main__ INFO: \u001b[0mEpoch 12 Step 600/703 lr 0.001000 loss 0.0026 (0.0143) acc@1 1.0000 (0.9953) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:24:26] __main__ INFO: \u001b[0mEpoch 12 Step 700/703 lr 0.001000 loss 0.0103 (0.0145) acc@1 1.0000 (0.9953) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:24:27] __main__ INFO: \u001b[0mEpoch 12 Step 703/703 lr 0.001000 loss 0.0074 (0.0146) acc@1 1.0000 (0.9953) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:24:27] __main__ INFO: \u001b[0mElapsed 224.81\n",
      "\u001b[32m[2020-07-13 12:24:27] __main__ INFO: \u001b[0mVal 12\n",
      "\u001b[32m[2020-07-13 12:24:34] __main__ INFO: \u001b[0mEpoch 12 loss 0.2327 acc@1 0.9452 acc@5 0.9962\n",
      "\u001b[32m[2020-07-13 12:24:34] __main__ INFO: \u001b[0mElapsed 7.74\n",
      "\u001b[32m[2020-07-13 12:24:34] __main__ INFO: \u001b[0mTrain 13 8436\n",
      "\u001b[32m[2020-07-13 12:25:06] __main__ INFO: \u001b[0mEpoch 13 Step 100/703 lr 0.001000 loss 0.0468 (0.0104) acc@1 0.9844 (0.9973) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:25:38] __main__ INFO: \u001b[0mEpoch 13 Step 200/703 lr 0.001000 loss 0.0026 (0.0106) acc@1 1.0000 (0.9974) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:26:10] __main__ INFO: \u001b[0mEpoch 13 Step 300/703 lr 0.001000 loss 0.0066 (0.0121) acc@1 1.0000 (0.9966) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:26:42] __main__ INFO: \u001b[0mEpoch 13 Step 400/703 lr 0.001000 loss 0.0050 (0.0122) acc@1 1.0000 (0.9965) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:27:14] __main__ INFO: \u001b[0mEpoch 13 Step 500/703 lr 0.001000 loss 0.0053 (0.0125) acc@1 1.0000 (0.9963) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:27:46] __main__ INFO: \u001b[0mEpoch 13 Step 600/703 lr 0.001000 loss 0.0058 (0.0127) acc@1 1.0000 (0.9963) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:28:19] __main__ INFO: \u001b[0mEpoch 13 Step 700/703 lr 0.001000 loss 0.0190 (0.0130) acc@1 0.9844 (0.9961) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:28:20] __main__ INFO: \u001b[0mEpoch 13 Step 703/703 lr 0.001000 loss 0.0040 (0.0129) acc@1 1.0000 (0.9961) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:28:20] __main__ INFO: \u001b[0mElapsed 225.09\n",
      "\u001b[32m[2020-07-13 12:28:20] __main__ INFO: \u001b[0mVal 13\n",
      "\u001b[32m[2020-07-13 12:28:27] __main__ INFO: \u001b[0mEpoch 13 loss 0.2418 acc@1 0.9464 acc@5 0.9960\n",
      "\u001b[32m[2020-07-13 12:28:27] __main__ INFO: \u001b[0mElapsed 7.83\n",
      "\u001b[32m[2020-07-13 12:28:27] __main__ INFO: \u001b[0mTrain 14 9139\n",
      "\u001b[32m[2020-07-13 12:29:00] __main__ INFO: \u001b[0mEpoch 14 Step 100/703 lr 0.001000 loss 0.0173 (0.0154) acc@1 1.0000 (0.9945) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:29:32] __main__ INFO: \u001b[0mEpoch 14 Step 200/703 lr 0.001000 loss 0.0048 (0.0136) acc@1 1.0000 (0.9958) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:30:04] __main__ INFO: \u001b[0mEpoch 14 Step 300/703 lr 0.001000 loss 0.0068 (0.0128) acc@1 1.0000 (0.9962) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:30:36] __main__ INFO: \u001b[0mEpoch 14 Step 400/703 lr 0.001000 loss 0.0039 (0.0124) acc@1 1.0000 (0.9963) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:31:08] __main__ INFO: \u001b[0mEpoch 14 Step 500/703 lr 0.001000 loss 0.0014 (0.0130) acc@1 1.0000 (0.9962) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:31:40] __main__ INFO: \u001b[0mEpoch 14 Step 600/703 lr 0.001000 loss 0.0024 (0.0124) acc@1 1.0000 (0.9963) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:32:12] __main__ INFO: \u001b[0mEpoch 14 Step 700/703 lr 0.001000 loss 0.0043 (0.0125) acc@1 1.0000 (0.9962) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:32:13] __main__ INFO: \u001b[0mEpoch 14 Step 703/703 lr 0.001000 loss 0.0047 (0.0125) acc@1 1.0000 (0.9962) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:32:13] __main__ INFO: \u001b[0mElapsed 225.37\n",
      "\u001b[32m[2020-07-13 12:32:13] __main__ INFO: \u001b[0mVal 14\n",
      "\u001b[32m[2020-07-13 12:32:20] __main__ INFO: \u001b[0mEpoch 14 loss 0.2439 acc@1 0.9458 acc@5 0.9960\n",
      "\u001b[32m[2020-07-13 12:32:20] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-13 12:32:20] __main__ INFO: \u001b[0mTrain 15 9842\n",
      "\u001b[32m[2020-07-13 12:32:53] __main__ INFO: \u001b[0mEpoch 15 Step 100/703 lr 0.001000 loss 0.0030 (0.0144) acc@1 1.0000 (0.9956) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:33:25] __main__ INFO: \u001b[0mEpoch 15 Step 200/703 lr 0.001000 loss 0.0097 (0.0146) acc@1 1.0000 (0.9956) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:33:57] __main__ INFO: \u001b[0mEpoch 15 Step 300/703 lr 0.001000 loss 0.0028 (0.0149) acc@1 1.0000 (0.9956) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:34:29] __main__ INFO: \u001b[0mEpoch 15 Step 400/703 lr 0.001000 loss 0.0026 (0.0140) acc@1 1.0000 (0.9957) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:35:01] __main__ INFO: \u001b[0mEpoch 15 Step 500/703 lr 0.001000 loss 0.0110 (0.0139) acc@1 1.0000 (0.9958) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:35:33] __main__ INFO: \u001b[0mEpoch 15 Step 600/703 lr 0.001000 loss 0.0022 (0.0136) acc@1 1.0000 (0.9959) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:36:05] __main__ INFO: \u001b[0mEpoch 15 Step 700/703 lr 0.001000 loss 0.0348 (0.0137) acc@1 0.9844 (0.9959) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:36:06] __main__ INFO: \u001b[0mEpoch 15 Step 703/703 lr 0.001000 loss 0.0016 (0.0137) acc@1 1.0000 (0.9960) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:36:06] __main__ INFO: \u001b[0mElapsed 225.57\n",
      "\u001b[32m[2020-07-13 12:36:06] __main__ INFO: \u001b[0mVal 15\n",
      "\u001b[32m[2020-07-13 12:36:14] __main__ INFO: \u001b[0mEpoch 15 loss 0.2382 acc@1 0.9474 acc@5 0.9968\n",
      "\u001b[32m[2020-07-13 12:36:14] __main__ INFO: \u001b[0mElapsed 7.75\n",
      "\u001b[32m[2020-07-13 12:36:14] __main__ INFO: \u001b[0mTrain 16 10545\n",
      "\u001b[32m[2020-07-13 12:36:46] __main__ INFO: \u001b[0mEpoch 16 Step 100/703 lr 0.001000 loss 0.0048 (0.0111) acc@1 1.0000 (0.9962) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:37:18] __main__ INFO: \u001b[0mEpoch 16 Step 200/703 lr 0.001000 loss 0.0025 (0.0109) acc@1 1.0000 (0.9965) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:37:50] __main__ INFO: \u001b[0mEpoch 16 Step 300/703 lr 0.001000 loss 0.0287 (0.0123) acc@1 0.9844 (0.9961) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:38:22] __main__ INFO: \u001b[0mEpoch 16 Step 400/703 lr 0.001000 loss 0.0050 (0.0119) acc@1 1.0000 (0.9963) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:38:54] __main__ INFO: \u001b[0mEpoch 16 Step 500/703 lr 0.001000 loss 0.0014 (0.0122) acc@1 1.0000 (0.9962) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:39:26] __main__ INFO: \u001b[0mEpoch 16 Step 600/703 lr 0.001000 loss 0.0285 (0.0128) acc@1 0.9844 (0.9960) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:39:58] __main__ INFO: \u001b[0mEpoch 16 Step 700/703 lr 0.001000 loss 0.0011 (0.0125) acc@1 1.0000 (0.9961) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:39:59] __main__ INFO: \u001b[0mEpoch 16 Step 703/703 lr 0.001000 loss 0.0019 (0.0125) acc@1 1.0000 (0.9961) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:39:59] __main__ INFO: \u001b[0mElapsed 225.16\n",
      "\u001b[32m[2020-07-13 12:39:59] __main__ INFO: \u001b[0mVal 16\n",
      "\u001b[32m[2020-07-13 12:40:07] __main__ INFO: \u001b[0mEpoch 16 loss 0.2377 acc@1 0.9466 acc@5 0.9972\n",
      "\u001b[32m[2020-07-13 12:40:07] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-13 12:40:07] __main__ INFO: \u001b[0mTrain 17 11248\n",
      "\u001b[32m[2020-07-13 12:40:39] __main__ INFO: \u001b[0mEpoch 17 Step 100/703 lr 0.001000 loss 0.0034 (0.0106) acc@1 1.0000 (0.9967) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:41:11] __main__ INFO: \u001b[0mEpoch 17 Step 200/703 lr 0.001000 loss 0.0185 (0.0114) acc@1 0.9844 (0.9963) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:41:43] __main__ INFO: \u001b[0mEpoch 17 Step 300/703 lr 0.001000 loss 0.0017 (0.0113) acc@1 1.0000 (0.9962) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:42:15] __main__ INFO: \u001b[0mEpoch 17 Step 400/703 lr 0.001000 loss 0.0123 (0.0119) acc@1 1.0000 (0.9961) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:42:47] __main__ INFO: \u001b[0mEpoch 17 Step 500/703 lr 0.001000 loss 0.0044 (0.0124) acc@1 1.0000 (0.9958) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:43:19] __main__ INFO: \u001b[0mEpoch 17 Step 600/703 lr 0.001000 loss 0.0038 (0.0123) acc@1 1.0000 (0.9958) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:43:51] __main__ INFO: \u001b[0mEpoch 17 Step 700/703 lr 0.001000 loss 0.0019 (0.0121) acc@1 1.0000 (0.9960) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:43:52] __main__ INFO: \u001b[0mEpoch 17 Step 703/703 lr 0.001000 loss 0.0016 (0.0121) acc@1 1.0000 (0.9960) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:43:52] __main__ INFO: \u001b[0mElapsed 225.40\n",
      "\u001b[32m[2020-07-13 12:43:52] __main__ INFO: \u001b[0mVal 17\n",
      "\u001b[32m[2020-07-13 12:44:00] __main__ INFO: \u001b[0mEpoch 17 loss 0.2348 acc@1 0.9458 acc@5 0.9968\n",
      "\u001b[32m[2020-07-13 12:44:00] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-13 12:44:00] __main__ INFO: \u001b[0mTrain 18 11951\n",
      "\u001b[32m[2020-07-13 12:44:32] __main__ INFO: \u001b[0mEpoch 18 Step 100/703 lr 0.001000 loss 0.0083 (0.0084) acc@1 1.0000 (0.9975) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:45:04] __main__ INFO: \u001b[0mEpoch 18 Step 200/703 lr 0.001000 loss 0.0027 (0.0088) acc@1 1.0000 (0.9969) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:45:36] __main__ INFO: \u001b[0mEpoch 18 Step 300/703 lr 0.001000 loss 0.0059 (0.0086) acc@1 1.0000 (0.9972) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:46:08] __main__ INFO: \u001b[0mEpoch 18 Step 400/703 lr 0.001000 loss 0.0032 (0.0090) acc@1 1.0000 (0.9971) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:46:40] __main__ INFO: \u001b[0mEpoch 18 Step 500/703 lr 0.001000 loss 0.0012 (0.0088) acc@1 1.0000 (0.9973) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:47:12] __main__ INFO: \u001b[0mEpoch 18 Step 600/703 lr 0.001000 loss 0.0101 (0.0089) acc@1 1.0000 (0.9973) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:47:44] __main__ INFO: \u001b[0mEpoch 18 Step 700/703 lr 0.001000 loss 0.0025 (0.0093) acc@1 1.0000 (0.9972) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:47:45] __main__ INFO: \u001b[0mEpoch 18 Step 703/703 lr 0.001000 loss 0.0105 (0.0092) acc@1 1.0000 (0.9972) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:47:45] __main__ INFO: \u001b[0mElapsed 225.01\n",
      "\u001b[32m[2020-07-13 12:47:45] __main__ INFO: \u001b[0mVal 18\n",
      "\u001b[32m[2020-07-13 12:47:53] __main__ INFO: \u001b[0mEpoch 18 loss 0.2354 acc@1 0.9484 acc@5 0.9960\n",
      "\u001b[32m[2020-07-13 12:47:53] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-13 12:47:53] __main__ INFO: \u001b[0mTrain 19 12654\n",
      "\u001b[32m[2020-07-13 12:48:25] __main__ INFO: \u001b[0mEpoch 19 Step 100/703 lr 0.001000 loss 0.0042 (0.0098) acc@1 1.0000 (0.9969) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:48:57] __main__ INFO: \u001b[0mEpoch 19 Step 200/703 lr 0.001000 loss 0.0052 (0.0093) acc@1 1.0000 (0.9971) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:49:29] __main__ INFO: \u001b[0mEpoch 19 Step 300/703 lr 0.001000 loss 0.0259 (0.0086) acc@1 0.9844 (0.9974) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:50:01] __main__ INFO: \u001b[0mEpoch 19 Step 400/703 lr 0.001000 loss 0.0203 (0.0093) acc@1 0.9844 (0.9971) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:50:33] __main__ INFO: \u001b[0mEpoch 19 Step 500/703 lr 0.001000 loss 0.0014 (0.0092) acc@1 1.0000 (0.9972) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:51:05] __main__ INFO: \u001b[0mEpoch 19 Step 600/703 lr 0.001000 loss 0.0019 (0.0091) acc@1 1.0000 (0.9974) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:51:37] __main__ INFO: \u001b[0mEpoch 19 Step 700/703 lr 0.001000 loss 0.0029 (0.0086) acc@1 1.0000 (0.9976) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:51:38] __main__ INFO: \u001b[0mEpoch 19 Step 703/703 lr 0.001000 loss 0.0018 (0.0087) acc@1 1.0000 (0.9975) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:51:38] __main__ INFO: \u001b[0mElapsed 225.20\n",
      "\u001b[32m[2020-07-13 12:51:38] __main__ INFO: \u001b[0mVal 19\n",
      "\u001b[32m[2020-07-13 12:51:46] __main__ INFO: \u001b[0mEpoch 19 loss 0.2402 acc@1 0.9478 acc@5 0.9960\n",
      "\u001b[32m[2020-07-13 12:51:46] __main__ INFO: \u001b[0mElapsed 7.75\n",
      "\u001b[32m[2020-07-13 12:51:46] __main__ INFO: \u001b[0mTrain 20 13357\n",
      "\u001b[32m[2020-07-13 12:52:18] __main__ INFO: \u001b[0mEpoch 20 Step 100/703 lr 0.001000 loss 0.0043 (0.0075) acc@1 1.0000 (0.9980) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:52:50] __main__ INFO: \u001b[0mEpoch 20 Step 200/703 lr 0.001000 loss 0.0038 (0.0076) acc@1 1.0000 (0.9979) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:53:22] __main__ INFO: \u001b[0mEpoch 20 Step 300/703 lr 0.001000 loss 0.0014 (0.0089) acc@1 1.0000 (0.9977) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:53:54] __main__ INFO: \u001b[0mEpoch 20 Step 400/703 lr 0.001000 loss 0.0013 (0.0085) acc@1 1.0000 (0.9975) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:54:26] __main__ INFO: \u001b[0mEpoch 20 Step 500/703 lr 0.001000 loss 0.0135 (0.0083) acc@1 1.0000 (0.9976) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:54:58] __main__ INFO: \u001b[0mEpoch 20 Step 600/703 lr 0.001000 loss 0.0179 (0.0085) acc@1 1.0000 (0.9976) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:55:30] __main__ INFO: \u001b[0mEpoch 20 Step 700/703 lr 0.001000 loss 0.0218 (0.0087) acc@1 1.0000 (0.9975) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:55:31] __main__ INFO: \u001b[0mEpoch 20 Step 703/703 lr 0.001000 loss 0.0047 (0.0087) acc@1 1.0000 (0.9975) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:55:31] __main__ INFO: \u001b[0mElapsed 225.58\n",
      "\u001b[32m[2020-07-13 12:55:31] __main__ INFO: \u001b[0mVal 20\n",
      "\u001b[32m[2020-07-13 12:55:39] __main__ INFO: \u001b[0mEpoch 20 loss 0.2364 acc@1 0.9476 acc@5 0.9974\n",
      "\u001b[32m[2020-07-13 12:55:39] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-13 12:55:39] __main__ INFO: \u001b[0mTrain 21 14060\n",
      "\u001b[32m[2020-07-13 12:56:11] __main__ INFO: \u001b[0mEpoch 21 Step 100/703 lr 0.001000 loss 0.0025 (0.0132) acc@1 1.0000 (0.9959) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:56:43] __main__ INFO: \u001b[0mEpoch 21 Step 200/703 lr 0.001000 loss 0.0234 (0.0116) acc@1 0.9844 (0.9962) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:57:15] __main__ INFO: \u001b[0mEpoch 21 Step 300/703 lr 0.001000 loss 0.0096 (0.0104) acc@1 1.0000 (0.9967) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:57:47] __main__ INFO: \u001b[0mEpoch 21 Step 400/703 lr 0.001000 loss 0.0022 (0.0094) acc@1 1.0000 (0.9971) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:58:19] __main__ INFO: \u001b[0mEpoch 21 Step 500/703 lr 0.001000 loss 0.0203 (0.0093) acc@1 0.9844 (0.9971) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:58:51] __main__ INFO: \u001b[0mEpoch 21 Step 600/703 lr 0.001000 loss 0.0009 (0.0094) acc@1 1.0000 (0.9970) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:59:23] __main__ INFO: \u001b[0mEpoch 21 Step 700/703 lr 0.001000 loss 0.0011 (0.0092) acc@1 1.0000 (0.9971) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:59:24] __main__ INFO: \u001b[0mEpoch 21 Step 703/703 lr 0.001000 loss 0.0021 (0.0092) acc@1 1.0000 (0.9970) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:59:24] __main__ INFO: \u001b[0mElapsed 225.27\n",
      "\u001b[32m[2020-07-13 12:59:24] __main__ INFO: \u001b[0mVal 21\n",
      "\u001b[32m[2020-07-13 12:59:32] __main__ INFO: \u001b[0mEpoch 21 loss 0.2523 acc@1 0.9456 acc@5 0.9960\n",
      "\u001b[32m[2020-07-13 12:59:32] __main__ INFO: \u001b[0mElapsed 7.75\n",
      "\u001b[32m[2020-07-13 12:59:32] __main__ INFO: \u001b[0mTrain 22 14763\n",
      "\u001b[32m[2020-07-13 13:00:04] __main__ INFO: \u001b[0mEpoch 22 Step 100/703 lr 0.001000 loss 0.0054 (0.0077) acc@1 1.0000 (0.9978) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:00:36] __main__ INFO: \u001b[0mEpoch 22 Step 200/703 lr 0.001000 loss 0.0015 (0.0082) acc@1 1.0000 (0.9978) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:01:08] __main__ INFO: \u001b[0mEpoch 22 Step 300/703 lr 0.001000 loss 0.0073 (0.0082) acc@1 1.0000 (0.9979) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:01:40] __main__ INFO: \u001b[0mEpoch 22 Step 400/703 lr 0.001000 loss 0.0064 (0.0085) acc@1 1.0000 (0.9978) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:02:12] __main__ INFO: \u001b[0mEpoch 22 Step 500/703 lr 0.001000 loss 0.0052 (0.0084) acc@1 1.0000 (0.9978) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:02:44] __main__ INFO: \u001b[0mEpoch 22 Step 600/703 lr 0.001000 loss 0.0019 (0.0080) acc@1 1.0000 (0.9979) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:03:16] __main__ INFO: \u001b[0mEpoch 22 Step 700/703 lr 0.001000 loss 0.0086 (0.0083) acc@1 1.0000 (0.9978) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:03:17] __main__ INFO: \u001b[0mEpoch 22 Step 703/703 lr 0.001000 loss 0.0302 (0.0083) acc@1 0.9844 (0.9978) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:03:17] __main__ INFO: \u001b[0mElapsed 225.36\n",
      "\u001b[32m[2020-07-13 13:03:17] __main__ INFO: \u001b[0mVal 22\n",
      "\u001b[32m[2020-07-13 13:03:25] __main__ INFO: \u001b[0mEpoch 22 loss 0.2531 acc@1 0.9436 acc@5 0.9960\n",
      "\u001b[32m[2020-07-13 13:03:25] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-13 13:03:25] __main__ INFO: \u001b[0mTrain 23 15466\n",
      "\u001b[32m[2020-07-13 13:03:57] __main__ INFO: \u001b[0mEpoch 23 Step 100/703 lr 0.001000 loss 0.0015 (0.0090) acc@1 1.0000 (0.9973) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:04:29] __main__ INFO: \u001b[0mEpoch 23 Step 200/703 lr 0.001000 loss 0.0018 (0.0084) acc@1 1.0000 (0.9976) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:05:01] __main__ INFO: \u001b[0mEpoch 23 Step 300/703 lr 0.001000 loss 0.0014 (0.0079) acc@1 1.0000 (0.9978) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:05:33] __main__ INFO: \u001b[0mEpoch 23 Step 400/703 lr 0.001000 loss 0.0427 (0.0073) acc@1 0.9844 (0.9980) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:06:05] __main__ INFO: \u001b[0mEpoch 23 Step 500/703 lr 0.001000 loss 0.0020 (0.0073) acc@1 1.0000 (0.9979) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:06:37] __main__ INFO: \u001b[0mEpoch 23 Step 600/703 lr 0.001000 loss 0.0045 (0.0074) acc@1 1.0000 (0.9979) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:07:09] __main__ INFO: \u001b[0mEpoch 23 Step 700/703 lr 0.001000 loss 0.0367 (0.0078) acc@1 0.9844 (0.9977) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:07:10] __main__ INFO: \u001b[0mEpoch 23 Step 703/703 lr 0.001000 loss 0.0019 (0.0078) acc@1 1.0000 (0.9977) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:07:10] __main__ INFO: \u001b[0mElapsed 225.16\n",
      "\u001b[32m[2020-07-13 13:07:10] __main__ INFO: \u001b[0mVal 23\n",
      "\u001b[32m[2020-07-13 13:07:18] __main__ INFO: \u001b[0mEpoch 23 loss 0.2562 acc@1 0.9428 acc@5 0.9976\n",
      "\u001b[32m[2020-07-13 13:07:18] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-13 13:07:18] __main__ INFO: \u001b[0mTrain 24 16169\n",
      "\u001b[32m[2020-07-13 13:07:50] __main__ INFO: \u001b[0mEpoch 24 Step 100/703 lr 0.001000 loss 0.0322 (0.0068) acc@1 0.9844 (0.9978) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:08:22] __main__ INFO: \u001b[0mEpoch 24 Step 200/703 lr 0.001000 loss 0.0021 (0.0080) acc@1 1.0000 (0.9973) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:08:54] __main__ INFO: \u001b[0mEpoch 24 Step 300/703 lr 0.001000 loss 0.0100 (0.0088) acc@1 1.0000 (0.9970) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:09:26] __main__ INFO: \u001b[0mEpoch 24 Step 400/703 lr 0.001000 loss 0.0297 (0.0099) acc@1 0.9844 (0.9967) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:09:58] __main__ INFO: \u001b[0mEpoch 24 Step 500/703 lr 0.001000 loss 0.0027 (0.0097) acc@1 1.0000 (0.9967) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:10:30] __main__ INFO: \u001b[0mEpoch 24 Step 600/703 lr 0.001000 loss 0.0098 (0.0094) acc@1 1.0000 (0.9969) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:11:02] __main__ INFO: \u001b[0mEpoch 24 Step 700/703 lr 0.001000 loss 0.0032 (0.0093) acc@1 1.0000 (0.9970) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:11:03] __main__ INFO: \u001b[0mEpoch 24 Step 703/703 lr 0.001000 loss 0.0025 (0.0093) acc@1 1.0000 (0.9970) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:11:03] __main__ INFO: \u001b[0mElapsed 225.27\n",
      "\u001b[32m[2020-07-13 13:11:03] __main__ INFO: \u001b[0mVal 24\n",
      "\u001b[32m[2020-07-13 13:11:11] __main__ INFO: \u001b[0mEpoch 24 loss 0.2481 acc@1 0.9438 acc@5 0.9972\n",
      "\u001b[32m[2020-07-13 13:11:11] __main__ INFO: \u001b[0mElapsed 7.75\n",
      "\u001b[32m[2020-07-13 13:11:11] __main__ INFO: \u001b[0mTrain 25 16872\n",
      "\u001b[32m[2020-07-13 13:11:43] __main__ INFO: \u001b[0mEpoch 25 Step 100/703 lr 0.001000 loss 0.0069 (0.0075) acc@1 1.0000 (0.9978) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:12:15] __main__ INFO: \u001b[0mEpoch 25 Step 200/703 lr 0.001000 loss 0.0050 (0.0073) acc@1 1.0000 (0.9980) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:12:47] __main__ INFO: \u001b[0mEpoch 25 Step 300/703 lr 0.001000 loss 0.0093 (0.0075) acc@1 1.0000 (0.9978) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:13:19] __main__ INFO: \u001b[0mEpoch 25 Step 400/703 lr 0.001000 loss 0.0022 (0.0072) acc@1 1.0000 (0.9979) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:13:51] __main__ INFO: \u001b[0mEpoch 25 Step 500/703 lr 0.001000 loss 0.0121 (0.0077) acc@1 1.0000 (0.9978) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:14:23] __main__ INFO: \u001b[0mEpoch 25 Step 600/703 lr 0.001000 loss 0.0086 (0.0079) acc@1 1.0000 (0.9978) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:14:55] __main__ INFO: \u001b[0mEpoch 25 Step 700/703 lr 0.001000 loss 0.0014 (0.0081) acc@1 1.0000 (0.9977) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:14:56] __main__ INFO: \u001b[0mEpoch 25 Step 703/703 lr 0.001000 loss 0.0045 (0.0081) acc@1 1.0000 (0.9977) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:14:56] __main__ INFO: \u001b[0mElapsed 225.22\n",
      "\u001b[32m[2020-07-13 13:14:56] __main__ INFO: \u001b[0mVal 25\n",
      "\u001b[32m[2020-07-13 13:15:04] __main__ INFO: \u001b[0mEpoch 25 loss 0.2447 acc@1 0.9452 acc@5 0.9970\n",
      "\u001b[32m[2020-07-13 13:15:04] __main__ INFO: \u001b[0mElapsed 7.79\n",
      "\u001b[32m[2020-07-13 13:15:04] __main__ INFO: \u001b[0mTrain 26 17575\n",
      "\u001b[32m[2020-07-13 13:15:36] __main__ INFO: \u001b[0mEpoch 26 Step 100/703 lr 0.001000 loss 0.0169 (0.0076) acc@1 0.9844 (0.9980) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:16:08] __main__ INFO: \u001b[0mEpoch 26 Step 200/703 lr 0.001000 loss 0.0013 (0.0069) acc@1 1.0000 (0.9982) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:16:41] __main__ INFO: \u001b[0mEpoch 26 Step 300/703 lr 0.001000 loss 0.0456 (0.0070) acc@1 0.9844 (0.9982) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:17:13] __main__ INFO: \u001b[0mEpoch 26 Step 400/703 lr 0.001000 loss 0.0009 (0.0067) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:17:45] __main__ INFO: \u001b[0mEpoch 26 Step 500/703 lr 0.001000 loss 0.0051 (0.0068) acc@1 1.0000 (0.9983) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:18:17] __main__ INFO: \u001b[0mEpoch 26 Step 600/703 lr 0.001000 loss 0.0014 (0.0069) acc@1 1.0000 (0.9983) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:18:49] __main__ INFO: \u001b[0mEpoch 26 Step 700/703 lr 0.001000 loss 0.0021 (0.0069) acc@1 1.0000 (0.9982) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:18:50] __main__ INFO: \u001b[0mEpoch 26 Step 703/703 lr 0.001000 loss 0.0059 (0.0069) acc@1 1.0000 (0.9982) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:18:50] __main__ INFO: \u001b[0mElapsed 225.45\n",
      "\u001b[32m[2020-07-13 13:18:50] __main__ INFO: \u001b[0mVal 26\n",
      "\u001b[32m[2020-07-13 13:18:57] __main__ INFO: \u001b[0mEpoch 26 loss 0.2593 acc@1 0.9466 acc@5 0.9968\n",
      "\u001b[32m[2020-07-13 13:18:57] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-13 13:18:57] __main__ INFO: \u001b[0mTrain 27 18278\n",
      "\u001b[32m[2020-07-13 13:19:30] __main__ INFO: \u001b[0mEpoch 27 Step 100/703 lr 0.001000 loss 0.0010 (0.0065) acc@1 1.0000 (0.9978) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:20:02] __main__ INFO: \u001b[0mEpoch 27 Step 200/703 lr 0.001000 loss 0.0044 (0.0070) acc@1 1.0000 (0.9981) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:20:34] __main__ INFO: \u001b[0mEpoch 27 Step 300/703 lr 0.001000 loss 0.0024 (0.0086) acc@1 1.0000 (0.9976) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:21:06] __main__ INFO: \u001b[0mEpoch 27 Step 400/703 lr 0.001000 loss 0.0092 (0.0079) acc@1 1.0000 (0.9978) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:21:38] __main__ INFO: \u001b[0mEpoch 27 Step 500/703 lr 0.001000 loss 0.0051 (0.0077) acc@1 1.0000 (0.9979) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:22:10] __main__ INFO: \u001b[0mEpoch 27 Step 600/703 lr 0.001000 loss 0.0069 (0.0078) acc@1 1.0000 (0.9978) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:22:42] __main__ INFO: \u001b[0mEpoch 27 Step 700/703 lr 0.001000 loss 0.0084 (0.0078) acc@1 1.0000 (0.9977) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:22:43] __main__ INFO: \u001b[0mEpoch 27 Step 703/703 lr 0.001000 loss 0.0010 (0.0077) acc@1 1.0000 (0.9977) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:22:43] __main__ INFO: \u001b[0mElapsed 225.50\n",
      "\u001b[32m[2020-07-13 13:22:43] __main__ INFO: \u001b[0mVal 27\n",
      "\u001b[32m[2020-07-13 13:22:51] __main__ INFO: \u001b[0mEpoch 27 loss 0.2457 acc@1 0.9480 acc@5 0.9976\n",
      "\u001b[32m[2020-07-13 13:22:51] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-13 13:22:51] __main__ INFO: \u001b[0mTrain 28 18981\n",
      "\u001b[32m[2020-07-13 13:23:23] __main__ INFO: \u001b[0mEpoch 28 Step 100/703 lr 0.001000 loss 0.0014 (0.0069) acc@1 1.0000 (0.9978) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:23:55] __main__ INFO: \u001b[0mEpoch 28 Step 200/703 lr 0.001000 loss 0.0021 (0.0070) acc@1 1.0000 (0.9978) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:24:27] __main__ INFO: \u001b[0mEpoch 28 Step 300/703 lr 0.001000 loss 0.0531 (0.0078) acc@1 0.9844 (0.9977) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:24:59] __main__ INFO: \u001b[0mEpoch 28 Step 400/703 lr 0.001000 loss 0.0018 (0.0074) acc@1 1.0000 (0.9978) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:25:31] __main__ INFO: \u001b[0mEpoch 28 Step 500/703 lr 0.001000 loss 0.0011 (0.0072) acc@1 1.0000 (0.9979) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:26:03] __main__ INFO: \u001b[0mEpoch 28 Step 600/703 lr 0.001000 loss 0.0019 (0.0073) acc@1 1.0000 (0.9979) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:26:35] __main__ INFO: \u001b[0mEpoch 28 Step 700/703 lr 0.001000 loss 0.0085 (0.0070) acc@1 1.0000 (0.9980) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:26:36] __main__ INFO: \u001b[0mEpoch 28 Step 703/703 lr 0.001000 loss 0.0085 (0.0070) acc@1 1.0000 (0.9980) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:26:36] __main__ INFO: \u001b[0mElapsed 225.64\n",
      "\u001b[32m[2020-07-13 13:26:36] __main__ INFO: \u001b[0mVal 28\n",
      "\u001b[32m[2020-07-13 13:26:44] __main__ INFO: \u001b[0mEpoch 28 loss 0.2497 acc@1 0.9484 acc@5 0.9970\n",
      "\u001b[32m[2020-07-13 13:26:44] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-13 13:26:44] __main__ INFO: \u001b[0mTrain 29 19684\n",
      "\u001b[32m[2020-07-13 13:27:16] __main__ INFO: \u001b[0mEpoch 29 Step 100/703 lr 0.001000 loss 0.0021 (0.0046) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:27:48] __main__ INFO: \u001b[0mEpoch 29 Step 200/703 lr 0.001000 loss 0.0015 (0.0060) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:28:20] __main__ INFO: \u001b[0mEpoch 29 Step 300/703 lr 0.001000 loss 0.0020 (0.0059) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:28:52] __main__ INFO: \u001b[0mEpoch 29 Step 400/703 lr 0.001000 loss 0.0199 (0.0069) acc@1 0.9844 (0.9981) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:29:24] __main__ INFO: \u001b[0mEpoch 29 Step 500/703 lr 0.001000 loss 0.0013 (0.0066) acc@1 1.0000 (0.9982) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:29:56] __main__ INFO: \u001b[0mEpoch 29 Step 600/703 lr 0.001000 loss 0.0340 (0.0069) acc@1 0.9844 (0.9980) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:30:29] __main__ INFO: \u001b[0mEpoch 29 Step 700/703 lr 0.001000 loss 0.0015 (0.0068) acc@1 1.0000 (0.9981) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:30:30] __main__ INFO: \u001b[0mEpoch 29 Step 703/703 lr 0.001000 loss 0.0024 (0.0068) acc@1 1.0000 (0.9981) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:30:30] __main__ INFO: \u001b[0mElapsed 225.52\n",
      "\u001b[32m[2020-07-13 13:30:30] __main__ INFO: \u001b[0mVal 29\n",
      "\u001b[32m[2020-07-13 13:30:37] __main__ INFO: \u001b[0mEpoch 29 loss 0.2413 acc@1 0.9514 acc@5 0.9970\n",
      "\u001b[32m[2020-07-13 13:30:37] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-13 13:30:37] __main__ INFO: \u001b[0mTrain 30 20387\n",
      "\u001b[32m[2020-07-13 13:31:10] __main__ INFO: \u001b[0mEpoch 30 Step 100/703 lr 0.001000 loss 0.0033 (0.0054) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:31:41] __main__ INFO: \u001b[0mEpoch 30 Step 200/703 lr 0.001000 loss 0.0012 (0.0056) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:32:14] __main__ INFO: \u001b[0mEpoch 30 Step 300/703 lr 0.001000 loss 0.0072 (0.0061) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:32:46] __main__ INFO: \u001b[0mEpoch 30 Step 400/703 lr 0.001000 loss 0.0052 (0.0061) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:33:18] __main__ INFO: \u001b[0mEpoch 30 Step 500/703 lr 0.001000 loss 0.0031 (0.0059) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:33:50] __main__ INFO: \u001b[0mEpoch 30 Step 600/703 lr 0.001000 loss 0.0022 (0.0060) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:34:22] __main__ INFO: \u001b[0mEpoch 30 Step 700/703 lr 0.001000 loss 0.0181 (0.0059) acc@1 0.9844 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:34:23] __main__ INFO: \u001b[0mEpoch 30 Step 703/703 lr 0.001000 loss 0.0019 (0.0060) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:34:23] __main__ INFO: \u001b[0mElapsed 225.39\n",
      "\u001b[32m[2020-07-13 13:34:23] __main__ INFO: \u001b[0mVal 30\n",
      "\u001b[32m[2020-07-13 13:34:31] __main__ INFO: \u001b[0mEpoch 30 loss 0.2453 acc@1 0.9514 acc@5 0.9964\n",
      "\u001b[32m[2020-07-13 13:34:31] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-13 13:34:31] __main__ INFO: \u001b[0mTrain 31 21090\n",
      "\u001b[32m[2020-07-13 13:35:03] __main__ INFO: \u001b[0mEpoch 31 Step 100/703 lr 0.001000 loss 0.0039 (0.0102) acc@1 1.0000 (0.9970) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:35:35] __main__ INFO: \u001b[0mEpoch 31 Step 200/703 lr 0.001000 loss 0.0426 (0.0078) acc@1 0.9844 (0.9977) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:36:07] __main__ INFO: \u001b[0mEpoch 31 Step 300/703 lr 0.001000 loss 0.0012 (0.0071) acc@1 1.0000 (0.9980) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:36:39] __main__ INFO: \u001b[0mEpoch 31 Step 400/703 lr 0.001000 loss 0.0512 (0.0068) acc@1 0.9844 (0.9979) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:37:11] __main__ INFO: \u001b[0mEpoch 31 Step 500/703 lr 0.001000 loss 0.0023 (0.0064) acc@1 1.0000 (0.9980) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:37:43] __main__ INFO: \u001b[0mEpoch 31 Step 600/703 lr 0.001000 loss 0.0015 (0.0065) acc@1 1.0000 (0.9981) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:38:15] __main__ INFO: \u001b[0mEpoch 31 Step 700/703 lr 0.001000 loss 0.0021 (0.0067) acc@1 1.0000 (0.9980) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:38:16] __main__ INFO: \u001b[0mEpoch 31 Step 703/703 lr 0.001000 loss 0.0030 (0.0066) acc@1 1.0000 (0.9980) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:38:16] __main__ INFO: \u001b[0mElapsed 225.44\n",
      "\u001b[32m[2020-07-13 13:38:16] __main__ INFO: \u001b[0mVal 31\n",
      "\u001b[32m[2020-07-13 13:38:24] __main__ INFO: \u001b[0mEpoch 31 loss 0.2724 acc@1 0.9434 acc@5 0.9960\n",
      "\u001b[32m[2020-07-13 13:38:24] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-13 13:38:24] __main__ INFO: \u001b[0mTrain 32 21793\n",
      "\u001b[32m[2020-07-13 13:38:56] __main__ INFO: \u001b[0mEpoch 32 Step 100/703 lr 0.001000 loss 0.0040 (0.0072) acc@1 1.0000 (0.9981) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-13 13:39:28] __main__ INFO: \u001b[0mEpoch 32 Step 200/703 lr 0.001000 loss 0.0111 (0.0063) acc@1 1.0000 (0.9984) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-13 13:40:00] __main__ INFO: \u001b[0mEpoch 32 Step 300/703 lr 0.001000 loss 0.0015 (0.0061) acc@1 1.0000 (0.9985) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-13 13:40:32] __main__ INFO: \u001b[0mEpoch 32 Step 400/703 lr 0.001000 loss 0.0012 (0.0061) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:41:04] __main__ INFO: \u001b[0mEpoch 32 Step 500/703 lr 0.001000 loss 0.0010 (0.0060) acc@1 1.0000 (0.9983) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:41:36] __main__ INFO: \u001b[0mEpoch 32 Step 600/703 lr 0.001000 loss 0.0022 (0.0060) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:42:08] __main__ INFO: \u001b[0mEpoch 32 Step 700/703 lr 0.001000 loss 0.0012 (0.0058) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:42:09] __main__ INFO: \u001b[0mEpoch 32 Step 703/703 lr 0.001000 loss 0.0008 (0.0058) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:42:09] __main__ INFO: \u001b[0mElapsed 225.32\n",
      "\u001b[32m[2020-07-13 13:42:09] __main__ INFO: \u001b[0mVal 32\n",
      "\u001b[32m[2020-07-13 13:42:17] __main__ INFO: \u001b[0mEpoch 32 loss 0.2535 acc@1 0.9496 acc@5 0.9960\n",
      "\u001b[32m[2020-07-13 13:42:17] __main__ INFO: \u001b[0mElapsed 7.81\n",
      "\u001b[32m[2020-07-13 13:42:17] __main__ INFO: \u001b[0mTrain 33 22496\n",
      "\u001b[32m[2020-07-13 13:42:49] __main__ INFO: \u001b[0mEpoch 33 Step 100/703 lr 0.001000 loss 0.0030 (0.0056) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:43:21] __main__ INFO: \u001b[0mEpoch 33 Step 200/703 lr 0.001000 loss 0.0010 (0.0057) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:43:53] __main__ INFO: \u001b[0mEpoch 33 Step 300/703 lr 0.001000 loss 0.0023 (0.0063) acc@1 1.0000 (0.9981) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:44:25] __main__ INFO: \u001b[0mEpoch 33 Step 400/703 lr 0.001000 loss 0.0017 (0.0063) acc@1 1.0000 (0.9981) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:44:58] __main__ INFO: \u001b[0mEpoch 33 Step 500/703 lr 0.001000 loss 0.0061 (0.0060) acc@1 1.0000 (0.9982) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:45:30] __main__ INFO: \u001b[0mEpoch 33 Step 600/703 lr 0.001000 loss 0.0154 (0.0062) acc@1 0.9844 (0.9982) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:46:02] __main__ INFO: \u001b[0mEpoch 33 Step 700/703 lr 0.001000 loss 0.0040 (0.0062) acc@1 1.0000 (0.9981) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:46:03] __main__ INFO: \u001b[0mEpoch 33 Step 703/703 lr 0.001000 loss 0.0028 (0.0061) acc@1 1.0000 (0.9981) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:46:03] __main__ INFO: \u001b[0mElapsed 226.13\n",
      "\u001b[32m[2020-07-13 13:46:03] __main__ INFO: \u001b[0mVal 33\n",
      "\u001b[32m[2020-07-13 13:46:11] __main__ INFO: \u001b[0mEpoch 33 loss 0.2505 acc@1 0.9472 acc@5 0.9952\n",
      "\u001b[32m[2020-07-13 13:46:11] __main__ INFO: \u001b[0mElapsed 7.85\n",
      "\u001b[32m[2020-07-13 13:46:11] __main__ INFO: \u001b[0mTrain 34 23199\n",
      "\u001b[32m[2020-07-13 13:46:43] __main__ INFO: \u001b[0mEpoch 34 Step 100/703 lr 0.001000 loss 0.0155 (0.0061) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:47:15] __main__ INFO: \u001b[0mEpoch 34 Step 200/703 lr 0.001000 loss 0.0023 (0.0053) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:47:47] __main__ INFO: \u001b[0mEpoch 34 Step 300/703 lr 0.001000 loss 0.0010 (0.0046) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:48:19] __main__ INFO: \u001b[0mEpoch 34 Step 400/703 lr 0.001000 loss 0.0015 (0.0049) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:48:52] __main__ INFO: \u001b[0mEpoch 34 Step 500/703 lr 0.001000 loss 0.0055 (0.0050) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:49:24] __main__ INFO: \u001b[0mEpoch 34 Step 600/703 lr 0.001000 loss 0.0040 (0.0056) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:49:56] __main__ INFO: \u001b[0mEpoch 34 Step 700/703 lr 0.001000 loss 0.0179 (0.0058) acc@1 0.9844 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:49:57] __main__ INFO: \u001b[0mEpoch 34 Step 703/703 lr 0.001000 loss 0.0032 (0.0058) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:49:57] __main__ INFO: \u001b[0mElapsed 226.17\n",
      "\u001b[32m[2020-07-13 13:49:57] __main__ INFO: \u001b[0mVal 34\n",
      "\u001b[32m[2020-07-13 13:50:05] __main__ INFO: \u001b[0mEpoch 34 loss 0.2530 acc@1 0.9496 acc@5 0.9968\n",
      "\u001b[32m[2020-07-13 13:50:05] __main__ INFO: \u001b[0mElapsed 7.85\n",
      "\u001b[32m[2020-07-13 13:50:05] __main__ INFO: \u001b[0mTrain 35 23902\n",
      "\u001b[32m[2020-07-13 13:50:37] __main__ INFO: \u001b[0mEpoch 35 Step 100/703 lr 0.001000 loss 0.0022 (0.0053) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:51:09] __main__ INFO: \u001b[0mEpoch 35 Step 200/703 lr 0.001000 loss 0.0033 (0.0076) acc@1 1.0000 (0.9977) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:51:41] __main__ INFO: \u001b[0mEpoch 35 Step 300/703 lr 0.001000 loss 0.0008 (0.0075) acc@1 1.0000 (0.9978) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:52:14] __main__ INFO: \u001b[0mEpoch 35 Step 400/703 lr 0.001000 loss 0.0017 (0.0070) acc@1 1.0000 (0.9979) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:52:46] __main__ INFO: \u001b[0mEpoch 35 Step 500/703 lr 0.001000 loss 0.0034 (0.0066) acc@1 1.0000 (0.9981) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:53:18] __main__ INFO: \u001b[0mEpoch 35 Step 600/703 lr 0.001000 loss 0.0019 (0.0067) acc@1 1.0000 (0.9981) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:53:50] __main__ INFO: \u001b[0mEpoch 35 Step 700/703 lr 0.001000 loss 0.0027 (0.0067) acc@1 1.0000 (0.9981) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:53:51] __main__ INFO: \u001b[0mEpoch 35 Step 703/703 lr 0.001000 loss 0.0066 (0.0067) acc@1 1.0000 (0.9981) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:53:51] __main__ INFO: \u001b[0mElapsed 226.02\n",
      "\u001b[32m[2020-07-13 13:53:51] __main__ INFO: \u001b[0mVal 35\n",
      "\u001b[32m[2020-07-13 13:53:59] __main__ INFO: \u001b[0mEpoch 35 loss 0.2540 acc@1 0.9470 acc@5 0.9964\n",
      "\u001b[32m[2020-07-13 13:53:59] __main__ INFO: \u001b[0mElapsed 7.84\n",
      "\u001b[32m[2020-07-13 13:53:59] __main__ INFO: \u001b[0mTrain 36 24605\n",
      "\u001b[32m[2020-07-13 13:54:31] __main__ INFO: \u001b[0mEpoch 36 Step 100/703 lr 0.001000 loss 0.0008 (0.0065) acc@1 1.0000 (0.9983) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:55:03] __main__ INFO: \u001b[0mEpoch 36 Step 200/703 lr 0.001000 loss 0.0008 (0.0060) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:55:35] __main__ INFO: \u001b[0mEpoch 36 Step 300/703 lr 0.001000 loss 0.0077 (0.0058) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:56:07] __main__ INFO: \u001b[0mEpoch 36 Step 400/703 lr 0.001000 loss 0.0008 (0.0060) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:56:40] __main__ INFO: \u001b[0mEpoch 36 Step 500/703 lr 0.001000 loss 0.0009 (0.0060) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:57:12] __main__ INFO: \u001b[0mEpoch 36 Step 600/703 lr 0.001000 loss 0.0010 (0.0061) acc@1 1.0000 (0.9983) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:57:44] __main__ INFO: \u001b[0mEpoch 36 Step 700/703 lr 0.001000 loss 0.0013 (0.0062) acc@1 1.0000 (0.9982) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:57:45] __main__ INFO: \u001b[0mEpoch 36 Step 703/703 lr 0.001000 loss 0.0058 (0.0062) acc@1 1.0000 (0.9982) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:57:45] __main__ INFO: \u001b[0mElapsed 226.06\n",
      "\u001b[32m[2020-07-13 13:57:45] __main__ INFO: \u001b[0mVal 36\n",
      "\u001b[32m[2020-07-13 13:57:53] __main__ INFO: \u001b[0mEpoch 36 loss 0.2500 acc@1 0.9464 acc@5 0.9976\n",
      "\u001b[32m[2020-07-13 13:57:53] __main__ INFO: \u001b[0mElapsed 7.83\n",
      "\u001b[32m[2020-07-13 13:57:53] __main__ INFO: \u001b[0mTrain 37 25308\n",
      "\u001b[32m[2020-07-13 13:58:25] __main__ INFO: \u001b[0mEpoch 37 Step 100/703 lr 0.001000 loss 0.0068 (0.0040) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:58:57] __main__ INFO: \u001b[0mEpoch 37 Step 200/703 lr 0.001000 loss 0.0017 (0.0050) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:59:29] __main__ INFO: \u001b[0mEpoch 37 Step 300/703 lr 0.001000 loss 0.0054 (0.0052) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:00:02] __main__ INFO: \u001b[0mEpoch 37 Step 400/703 lr 0.001000 loss 0.0020 (0.0050) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:00:34] __main__ INFO: \u001b[0mEpoch 37 Step 500/703 lr 0.001000 loss 0.0035 (0.0049) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:01:06] __main__ INFO: \u001b[0mEpoch 37 Step 600/703 lr 0.001000 loss 0.0009 (0.0049) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:01:38] __main__ INFO: \u001b[0mEpoch 37 Step 700/703 lr 0.001000 loss 0.0013 (0.0049) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:01:39] __main__ INFO: \u001b[0mEpoch 37 Step 703/703 lr 0.001000 loss 0.0009 (0.0049) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:01:39] __main__ INFO: \u001b[0mElapsed 226.40\n",
      "\u001b[32m[2020-07-13 14:01:39] __main__ INFO: \u001b[0mVal 37\n",
      "\u001b[32m[2020-07-13 14:01:47] __main__ INFO: \u001b[0mEpoch 37 loss 0.2594 acc@1 0.9466 acc@5 0.9962\n",
      "\u001b[32m[2020-07-13 14:01:47] __main__ INFO: \u001b[0mElapsed 7.85\n",
      "\u001b[32m[2020-07-13 14:01:47] __main__ INFO: \u001b[0mTrain 38 26011\n",
      "\u001b[32m[2020-07-13 14:02:19] __main__ INFO: \u001b[0mEpoch 38 Step 100/703 lr 0.001000 loss 0.0191 (0.0059) acc@1 0.9844 (0.9981) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:02:51] __main__ INFO: \u001b[0mEpoch 38 Step 200/703 lr 0.001000 loss 0.0147 (0.0048) acc@1 0.9844 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:03:23] __main__ INFO: \u001b[0mEpoch 38 Step 300/703 lr 0.001000 loss 0.0009 (0.0052) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:03:56] __main__ INFO: \u001b[0mEpoch 38 Step 400/703 lr 0.001000 loss 0.0011 (0.0051) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:04:28] __main__ INFO: \u001b[0mEpoch 38 Step 500/703 lr 0.001000 loss 0.0013 (0.0055) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:05:00] __main__ INFO: \u001b[0mEpoch 38 Step 600/703 lr 0.001000 loss 0.0026 (0.0055) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:05:32] __main__ INFO: \u001b[0mEpoch 38 Step 700/703 lr 0.001000 loss 0.0017 (0.0054) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:05:33] __main__ INFO: \u001b[0mEpoch 38 Step 703/703 lr 0.001000 loss 0.0274 (0.0055) acc@1 0.9844 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:05:33] __main__ INFO: \u001b[0mElapsed 225.87\n",
      "\u001b[32m[2020-07-13 14:05:33] __main__ INFO: \u001b[0mVal 38\n",
      "\u001b[32m[2020-07-13 14:05:41] __main__ INFO: \u001b[0mEpoch 38 loss 0.2510 acc@1 0.9474 acc@5 0.9964\n",
      "\u001b[32m[2020-07-13 14:05:41] __main__ INFO: \u001b[0mElapsed 7.81\n",
      "\u001b[32m[2020-07-13 14:05:41] __main__ INFO: \u001b[0mTrain 39 26714\n",
      "\u001b[32m[2020-07-13 14:06:13] __main__ INFO: \u001b[0mEpoch 39 Step 100/703 lr 0.001000 loss 0.0009 (0.0052) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:06:45] __main__ INFO: \u001b[0mEpoch 39 Step 200/703 lr 0.001000 loss 0.0009 (0.0053) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:07:17] __main__ INFO: \u001b[0mEpoch 39 Step 300/703 lr 0.001000 loss 0.0010 (0.0052) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:07:49] __main__ INFO: \u001b[0mEpoch 39 Step 400/703 lr 0.001000 loss 0.0028 (0.0051) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:08:21] __main__ INFO: \u001b[0mEpoch 39 Step 500/703 lr 0.001000 loss 0.0009 (0.0050) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:08:53] __main__ INFO: \u001b[0mEpoch 39 Step 600/703 lr 0.001000 loss 0.0142 (0.0049) acc@1 0.9844 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:09:25] __main__ INFO: \u001b[0mEpoch 39 Step 700/703 lr 0.001000 loss 0.0013 (0.0052) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:09:26] __main__ INFO: \u001b[0mEpoch 39 Step 703/703 lr 0.001000 loss 0.0010 (0.0052) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:09:26] __main__ INFO: \u001b[0mElapsed 225.57\n",
      "\u001b[32m[2020-07-13 14:09:26] __main__ INFO: \u001b[0mVal 39\n",
      "\u001b[32m[2020-07-13 14:09:34] __main__ INFO: \u001b[0mEpoch 39 loss 0.2446 acc@1 0.9476 acc@5 0.9968\n",
      "\u001b[32m[2020-07-13 14:09:34] __main__ INFO: \u001b[0mElapsed 7.82\n",
      "\u001b[32m[2020-07-13 14:09:34] __main__ INFO: \u001b[0mTrain 40 27417\n",
      "\u001b[32m[2020-07-13 14:10:06] __main__ INFO: \u001b[0mEpoch 40 Step 100/703 lr 0.001000 loss 0.0009 (0.0065) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:10:38] __main__ INFO: \u001b[0mEpoch 40 Step 200/703 lr 0.001000 loss 0.0011 (0.0055) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:11:10] __main__ INFO: \u001b[0mEpoch 40 Step 300/703 lr 0.001000 loss 0.0082 (0.0056) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:11:43] __main__ INFO: \u001b[0mEpoch 40 Step 400/703 lr 0.001000 loss 0.0010 (0.0057) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:12:15] __main__ INFO: \u001b[0mEpoch 40 Step 500/703 lr 0.001000 loss 0.0014 (0.0057) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:12:47] __main__ INFO: \u001b[0mEpoch 40 Step 600/703 lr 0.001000 loss 0.0012 (0.0059) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:13:19] __main__ INFO: \u001b[0mEpoch 40 Step 700/703 lr 0.001000 loss 0.0458 (0.0058) acc@1 0.9844 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:13:20] __main__ INFO: \u001b[0mEpoch 40 Step 703/703 lr 0.001000 loss 0.0010 (0.0058) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:13:20] __main__ INFO: \u001b[0mElapsed 225.77\n",
      "\u001b[32m[2020-07-13 14:13:20] __main__ INFO: \u001b[0mVal 40\n",
      "\u001b[32m[2020-07-13 14:13:28] __main__ INFO: \u001b[0mEpoch 40 loss 0.2592 acc@1 0.9462 acc@5 0.9968\n",
      "\u001b[32m[2020-07-13 14:13:28] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-13 14:13:28] __main__ INFO: \u001b[0mTrain 41 28120\n",
      "\u001b[32m[2020-07-13 14:14:00] __main__ INFO: \u001b[0mEpoch 41 Step 100/703 lr 0.001000 loss 0.0020 (0.0052) acc@1 1.0000 (0.9983) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:14:32] __main__ INFO: \u001b[0mEpoch 41 Step 200/703 lr 0.001000 loss 0.0009 (0.0045) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:15:04] __main__ INFO: \u001b[0mEpoch 41 Step 300/703 lr 0.001000 loss 0.0011 (0.0046) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:15:36] __main__ INFO: \u001b[0mEpoch 41 Step 400/703 lr 0.001000 loss 0.0151 (0.0045) acc@1 0.9844 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:16:08] __main__ INFO: \u001b[0mEpoch 41 Step 500/703 lr 0.001000 loss 0.0011 (0.0047) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:16:40] __main__ INFO: \u001b[0mEpoch 41 Step 600/703 lr 0.001000 loss 0.0009 (0.0049) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:17:12] __main__ INFO: \u001b[0mEpoch 41 Step 700/703 lr 0.001000 loss 0.0049 (0.0050) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:17:13] __main__ INFO: \u001b[0mEpoch 41 Step 703/703 lr 0.001000 loss 0.0016 (0.0050) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:17:13] __main__ INFO: \u001b[0mElapsed 225.83\n",
      "\u001b[32m[2020-07-13 14:17:13] __main__ INFO: \u001b[0mVal 41\n",
      "\u001b[32m[2020-07-13 14:17:21] __main__ INFO: \u001b[0mEpoch 41 loss 0.2544 acc@1 0.9442 acc@5 0.9966\n",
      "\u001b[32m[2020-07-13 14:17:21] __main__ INFO: \u001b[0mElapsed 7.90\n",
      "\u001b[32m[2020-07-13 14:17:21] __main__ INFO: \u001b[0mTrain 42 28823\n",
      "\u001b[32m[2020-07-13 14:17:53] __main__ INFO: \u001b[0mEpoch 42 Step 100/703 lr 0.001000 loss 0.0016 (0.0067) acc@1 1.0000 (0.9980) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:18:26] __main__ INFO: \u001b[0mEpoch 42 Step 200/703 lr 0.001000 loss 0.0014 (0.0060) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:18:58] __main__ INFO: \u001b[0mEpoch 42 Step 300/703 lr 0.001000 loss 0.0015 (0.0052) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:19:30] __main__ INFO: \u001b[0mEpoch 42 Step 400/703 lr 0.001000 loss 0.0060 (0.0052) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:20:02] __main__ INFO: \u001b[0mEpoch 42 Step 500/703 lr 0.001000 loss 0.0031 (0.0059) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:20:34] __main__ INFO: \u001b[0mEpoch 42 Step 600/703 lr 0.001000 loss 0.0010 (0.0059) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:21:06] __main__ INFO: \u001b[0mEpoch 42 Step 700/703 lr 0.001000 loss 0.0012 (0.0059) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:21:07] __main__ INFO: \u001b[0mEpoch 42 Step 703/703 lr 0.001000 loss 0.0008 (0.0059) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:21:07] __main__ INFO: \u001b[0mElapsed 226.18\n",
      "\u001b[32m[2020-07-13 14:21:07] __main__ INFO: \u001b[0mVal 42\n",
      "\u001b[32m[2020-07-13 14:21:15] __main__ INFO: \u001b[0mEpoch 42 loss 0.2608 acc@1 0.9484 acc@5 0.9968\n",
      "\u001b[32m[2020-07-13 14:21:15] __main__ INFO: \u001b[0mElapsed 7.88\n",
      "\u001b[32m[2020-07-13 14:21:15] __main__ INFO: \u001b[0mTrain 43 29526\n",
      "\u001b[32m[2020-07-13 14:21:48] __main__ INFO: \u001b[0mEpoch 43 Step 100/703 lr 0.001000 loss 0.0062 (0.0055) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:22:20] __main__ INFO: \u001b[0mEpoch 43 Step 200/703 lr 0.001000 loss 0.0038 (0.0059) acc@1 1.0000 (0.9980) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:22:52] __main__ INFO: \u001b[0mEpoch 43 Step 300/703 lr 0.001000 loss 0.0011 (0.0055) acc@1 1.0000 (0.9982) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:23:24] __main__ INFO: \u001b[0mEpoch 43 Step 400/703 lr 0.001000 loss 0.0015 (0.0053) acc@1 1.0000 (0.9983) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:23:56] __main__ INFO: \u001b[0mEpoch 43 Step 500/703 lr 0.001000 loss 0.0012 (0.0056) acc@1 1.0000 (0.9983) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:24:29] __main__ INFO: \u001b[0mEpoch 43 Step 600/703 lr 0.001000 loss 0.0013 (0.0054) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:25:01] __main__ INFO: \u001b[0mEpoch 43 Step 700/703 lr 0.001000 loss 0.0048 (0.0056) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:25:02] __main__ INFO: \u001b[0mEpoch 43 Step 703/703 lr 0.001000 loss 0.0021 (0.0056) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:25:02] __main__ INFO: \u001b[0mElapsed 226.22\n",
      "\u001b[32m[2020-07-13 14:25:02] __main__ INFO: \u001b[0mVal 43\n",
      "\u001b[32m[2020-07-13 14:25:09] __main__ INFO: \u001b[0mEpoch 43 loss 0.2605 acc@1 0.9480 acc@5 0.9960\n",
      "\u001b[32m[2020-07-13 14:25:09] __main__ INFO: \u001b[0mElapsed 7.89\n",
      "\u001b[32m[2020-07-13 14:25:09] __main__ INFO: \u001b[0mTrain 44 30229\n",
      "\u001b[32m[2020-07-13 14:25:42] __main__ INFO: \u001b[0mEpoch 44 Step 100/703 lr 0.001000 loss 0.0011 (0.0055) acc@1 1.0000 (0.9980) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:26:14] __main__ INFO: \u001b[0mEpoch 44 Step 200/703 lr 0.001000 loss 0.0017 (0.0057) acc@1 1.0000 (0.9980) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:26:46] __main__ INFO: \u001b[0mEpoch 44 Step 300/703 lr 0.001000 loss 0.0016 (0.0051) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:27:18] __main__ INFO: \u001b[0mEpoch 44 Step 400/703 lr 0.001000 loss 0.0018 (0.0052) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:27:50] __main__ INFO: \u001b[0mEpoch 44 Step 500/703 lr 0.001000 loss 0.0007 (0.0054) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:28:22] __main__ INFO: \u001b[0mEpoch 44 Step 600/703 lr 0.001000 loss 0.0034 (0.0054) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:28:55] __main__ INFO: \u001b[0mEpoch 44 Step 700/703 lr 0.001000 loss 0.0008 (0.0057) acc@1 1.0000 (0.9983) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:28:56] __main__ INFO: \u001b[0mEpoch 44 Step 703/703 lr 0.001000 loss 0.0425 (0.0057) acc@1 0.9844 (0.9983) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:28:56] __main__ INFO: \u001b[0mElapsed 226.17\n",
      "\u001b[32m[2020-07-13 14:28:56] __main__ INFO: \u001b[0mVal 44\n",
      "\u001b[32m[2020-07-13 14:29:03] __main__ INFO: \u001b[0mEpoch 44 loss 0.2682 acc@1 0.9470 acc@5 0.9966\n",
      "\u001b[32m[2020-07-13 14:29:03] __main__ INFO: \u001b[0mElapsed 7.83\n",
      "\u001b[32m[2020-07-13 14:29:03] __main__ INFO: \u001b[0mTrain 45 30932\n",
      "\u001b[32m[2020-07-13 14:29:36] __main__ INFO: \u001b[0mEpoch 45 Step 100/703 lr 0.001000 loss 0.0721 (0.0066) acc@1 0.9844 (0.9980) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:30:08] __main__ INFO: \u001b[0mEpoch 45 Step 200/703 lr 0.001000 loss 0.0107 (0.0061) acc@1 1.0000 (0.9982) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:30:40] __main__ INFO: \u001b[0mEpoch 45 Step 300/703 lr 0.001000 loss 0.0122 (0.0057) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:31:12] __main__ INFO: \u001b[0mEpoch 45 Step 400/703 lr 0.001000 loss 0.0023 (0.0056) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:31:44] __main__ INFO: \u001b[0mEpoch 45 Step 500/703 lr 0.001000 loss 0.0011 (0.0053) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:32:17] __main__ INFO: \u001b[0mEpoch 45 Step 600/703 lr 0.001000 loss 0.0019 (0.0051) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:32:49] __main__ INFO: \u001b[0mEpoch 45 Step 700/703 lr 0.001000 loss 0.0503 (0.0052) acc@1 0.9844 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:32:50] __main__ INFO: \u001b[0mEpoch 45 Step 703/703 lr 0.001000 loss 0.0015 (0.0052) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:32:50] __main__ INFO: \u001b[0mElapsed 226.34\n",
      "\u001b[32m[2020-07-13 14:32:50] __main__ INFO: \u001b[0mVal 45\n",
      "\u001b[32m[2020-07-13 14:32:58] __main__ INFO: \u001b[0mEpoch 45 loss 0.2535 acc@1 0.9494 acc@5 0.9962\n",
      "\u001b[32m[2020-07-13 14:32:58] __main__ INFO: \u001b[0mElapsed 7.85\n",
      "\u001b[32m[2020-07-13 14:32:58] __main__ INFO: \u001b[0mTrain 46 31635\n",
      "\u001b[32m[2020-07-13 14:33:30] __main__ INFO: \u001b[0mEpoch 46 Step 100/703 lr 0.001000 loss 0.0018 (0.0064) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:34:02] __main__ INFO: \u001b[0mEpoch 46 Step 200/703 lr 0.001000 loss 0.0010 (0.0049) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:34:34] __main__ INFO: \u001b[0mEpoch 46 Step 300/703 lr 0.001000 loss 0.0006 (0.0052) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:35:06] __main__ INFO: \u001b[0mEpoch 46 Step 400/703 lr 0.001000 loss 0.0013 (0.0048) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:35:39] __main__ INFO: \u001b[0mEpoch 46 Step 500/703 lr 0.001000 loss 0.0249 (0.0048) acc@1 0.9844 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:36:11] __main__ INFO: \u001b[0mEpoch 46 Step 600/703 lr 0.001000 loss 0.0013 (0.0046) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:36:43] __main__ INFO: \u001b[0mEpoch 46 Step 700/703 lr 0.001000 loss 0.0011 (0.0046) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:36:44] __main__ INFO: \u001b[0mEpoch 46 Step 703/703 lr 0.001000 loss 0.0068 (0.0046) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:36:44] __main__ INFO: \u001b[0mElapsed 226.16\n",
      "\u001b[32m[2020-07-13 14:36:44] __main__ INFO: \u001b[0mVal 46\n",
      "\u001b[32m[2020-07-13 14:36:52] __main__ INFO: \u001b[0mEpoch 46 loss 0.2607 acc@1 0.9488 acc@5 0.9958\n",
      "\u001b[32m[2020-07-13 14:36:52] __main__ INFO: \u001b[0mElapsed 7.79\n",
      "\u001b[32m[2020-07-13 14:36:52] __main__ INFO: \u001b[0mTrain 47 32338\n",
      "\u001b[32m[2020-07-13 14:37:24] __main__ INFO: \u001b[0mEpoch 47 Step 100/703 lr 0.001000 loss 0.0008 (0.0027) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:37:56] __main__ INFO: \u001b[0mEpoch 47 Step 200/703 lr 0.001000 loss 0.0013 (0.0047) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:38:28] __main__ INFO: \u001b[0mEpoch 47 Step 300/703 lr 0.001000 loss 0.0010 (0.0046) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:39:00] __main__ INFO: \u001b[0mEpoch 47 Step 400/703 lr 0.001000 loss 0.0073 (0.0049) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:39:32] __main__ INFO: \u001b[0mEpoch 47 Step 500/703 lr 0.001000 loss 0.0034 (0.0047) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:40:04] __main__ INFO: \u001b[0mEpoch 47 Step 600/703 lr 0.001000 loss 0.0050 (0.0052) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:40:36] __main__ INFO: \u001b[0mEpoch 47 Step 700/703 lr 0.001000 loss 0.0018 (0.0052) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:40:37] __main__ INFO: \u001b[0mEpoch 47 Step 703/703 lr 0.001000 loss 0.0024 (0.0052) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:40:37] __main__ INFO: \u001b[0mElapsed 225.81\n",
      "\u001b[32m[2020-07-13 14:40:37] __main__ INFO: \u001b[0mVal 47\n",
      "\u001b[32m[2020-07-13 14:40:45] __main__ INFO: \u001b[0mEpoch 47 loss 0.2651 acc@1 0.9462 acc@5 0.9970\n",
      "\u001b[32m[2020-07-13 14:40:45] __main__ INFO: \u001b[0mElapsed 7.81\n",
      "\u001b[32m[2020-07-13 14:40:45] __main__ INFO: \u001b[0mTrain 48 33041\n",
      "\u001b[32m[2020-07-13 14:41:17] __main__ INFO: \u001b[0mEpoch 48 Step 100/703 lr 0.001000 loss 0.0009 (0.0042) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:41:50] __main__ INFO: \u001b[0mEpoch 48 Step 200/703 lr 0.001000 loss 0.0009 (0.0037) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:42:22] __main__ INFO: \u001b[0mEpoch 48 Step 300/703 lr 0.001000 loss 0.0014 (0.0050) acc@1 1.0000 (0.9989) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-13 14:42:54] __main__ INFO: \u001b[0mEpoch 48 Step 400/703 lr 0.001000 loss 0.0799 (0.0048) acc@1 0.9844 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:43:26] __main__ INFO: \u001b[0mEpoch 48 Step 500/703 lr 0.001000 loss 0.0007 (0.0047) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:43:59] __main__ INFO: \u001b[0mEpoch 48 Step 600/703 lr 0.001000 loss 0.0019 (0.0048) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:44:31] __main__ INFO: \u001b[0mEpoch 48 Step 700/703 lr 0.001000 loss 0.0048 (0.0046) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:44:32] __main__ INFO: \u001b[0mEpoch 48 Step 703/703 lr 0.001000 loss 0.0008 (0.0046) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:44:32] __main__ INFO: \u001b[0mElapsed 226.41\n",
      "\u001b[32m[2020-07-13 14:44:32] __main__ INFO: \u001b[0mVal 48\n",
      "\u001b[32m[2020-07-13 14:44:39] __main__ INFO: \u001b[0mEpoch 48 loss 0.2560 acc@1 0.9442 acc@5 0.9970\n",
      "\u001b[32m[2020-07-13 14:44:39] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-13 14:44:39] __main__ INFO: \u001b[0mTrain 49 33744\n",
      "\u001b[32m[2020-07-13 14:45:12] __main__ INFO: \u001b[0mEpoch 49 Step 100/703 lr 0.001000 loss 0.0010 (0.0036) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:45:44] __main__ INFO: \u001b[0mEpoch 49 Step 200/703 lr 0.001000 loss 0.0062 (0.0036) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:46:16] __main__ INFO: \u001b[0mEpoch 49 Step 300/703 lr 0.001000 loss 0.0010 (0.0035) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:46:48] __main__ INFO: \u001b[0mEpoch 49 Step 400/703 lr 0.001000 loss 0.0020 (0.0037) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:47:20] __main__ INFO: \u001b[0mEpoch 49 Step 500/703 lr 0.001000 loss 0.0009 (0.0044) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:47:53] __main__ INFO: \u001b[0mEpoch 49 Step 600/703 lr 0.001000 loss 0.0010 (0.0041) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:48:25] __main__ INFO: \u001b[0mEpoch 49 Step 700/703 lr 0.001000 loss 0.0010 (0.0042) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:48:26] __main__ INFO: \u001b[0mEpoch 49 Step 703/703 lr 0.001000 loss 0.0009 (0.0041) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:48:26] __main__ INFO: \u001b[0mElapsed 226.26\n",
      "\u001b[32m[2020-07-13 14:48:26] __main__ INFO: \u001b[0mVal 49\n",
      "\u001b[32m[2020-07-13 14:48:34] __main__ INFO: \u001b[0mEpoch 49 loss 0.2602 acc@1 0.9468 acc@5 0.9970\n",
      "\u001b[32m[2020-07-13 14:48:34] __main__ INFO: \u001b[0mElapsed 7.88\n",
      "\u001b[32m[2020-07-13 14:48:34] __main__ INFO: \u001b[0mTrain 50 34447\n",
      "\u001b[32m[2020-07-13 14:49:06] __main__ INFO: \u001b[0mEpoch 50 Step 100/703 lr 0.001000 loss 0.0040 (0.0064) acc@1 1.0000 (0.9981) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:49:38] __main__ INFO: \u001b[0mEpoch 50 Step 200/703 lr 0.001000 loss 0.0032 (0.0050) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:50:10] __main__ INFO: \u001b[0mEpoch 50 Step 300/703 lr 0.001000 loss 0.0008 (0.0047) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:50:42] __main__ INFO: \u001b[0mEpoch 50 Step 400/703 lr 0.001000 loss 0.0018 (0.0051) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:51:15] __main__ INFO: \u001b[0mEpoch 50 Step 500/703 lr 0.001000 loss 0.0009 (0.0050) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:51:47] __main__ INFO: \u001b[0mEpoch 50 Step 600/703 lr 0.001000 loss 0.0056 (0.0048) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:52:19] __main__ INFO: \u001b[0mEpoch 50 Step 700/703 lr 0.001000 loss 0.0162 (0.0047) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:52:20] __main__ INFO: \u001b[0mEpoch 50 Step 703/703 lr 0.001000 loss 0.0015 (0.0046) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:52:20] __main__ INFO: \u001b[0mElapsed 226.18\n",
      "\u001b[32m[2020-07-13 14:52:20] __main__ INFO: \u001b[0mVal 50\n",
      "\u001b[32m[2020-07-13 14:52:28] __main__ INFO: \u001b[0mEpoch 50 loss 0.2608 acc@1 0.9468 acc@5 0.9968\n",
      "\u001b[32m[2020-07-13 14:52:28] __main__ INFO: \u001b[0mElapsed 7.85\n",
      "\u001b[32m[2020-07-13 14:52:28] fvcore.common.checkpoint INFO: \u001b[0mSaving checkpoint to /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_cm_1_1/exp00_resume400_50/checkpoint_00050.pth\n"
     ]
    }
   ],
   "source": [
    "# Resume training with the un-augmented data\n",
    "os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "!python train.py --config /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_cm_1_1/exp00/config.yaml \\\n",
    "    train.checkpoint /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_cm_1_1/exp00/checkpoint_00400.pth \\\n",
    "    dataset.name CIFAR10 \\\n",
    "    train.base_lr 0.001 \\\n",
    "    train.output_dir /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_cm_1_1/exp00_resume400_50 \\\n",
    "    scheduler.epochs 50\n",
    "\n",
    "#### Set LEARNING RATE based on ending LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-13 21:41:29] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_cm_1_1/exp00_resume400_50/checkpoint_00050.pth\n",
      "Files already downloaded and verified\n",
      "100%|| 157/157 [00:19<00:00,  8.08it/s]\n",
      "\u001b[32m[2020-07-13 21:41:50] __main__ INFO: \u001b[0mElapsed 19.44\n",
      "\u001b[32m[2020-07-13 21:41:50] __main__ INFO: \u001b[0mLoss 0.3269 Accuracy 0.9369\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10 test dataset \n",
    "# Right the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/densenet.yaml \\\n",
    "   model.densenet.depth 100 \\\n",
    "   model.densenet.growth_rate 12 \\\n",
    "   test.batch_size 64 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_cm_1_1/exp00_resume400_50/checkpoint_00050.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_cm_1_1/exp00_resume400_50/test_results_0050_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-13 21:42:06] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_cm_1_1/exp00_resume400_50/checkpoint_00050.pth\n",
      "CIFAR 10.1\n",
      "100%|| 32/32 [00:04<00:00,  7.66it/s]\n",
      "\u001b[32m[2020-07-13 21:42:10] __main__ INFO: \u001b[0mElapsed 4.18\n",
      "\u001b[32m[2020-07-13 21:42:10] __main__ INFO: \u001b[0mLoss 0.7624 Accuracy 0.8645\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10.1 test dataset \n",
    "# Right the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/densenet.yaml \\\n",
    "   model.densenet.depth 100 \\\n",
    "   model.densenet.growth_rate 12 \\\n",
    "   test.batch_size 64 \\\n",
    "   dataset.name CIFAR101 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_cm_1_1/exp00_resume400_50/checkpoint_00050.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_cm_1_1/exp00_resume400_50/test_results_0050_cifar101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-13 21:42:46] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_cm_1_1/exp00/checkpoint_00400.pth\n",
      "Files already downloaded and verified\n",
      "100%|| 157/157 [00:19<00:00,  8.08it/s]\n",
      "\u001b[32m[2020-07-13 21:43:07] __main__ INFO: \u001b[0mElapsed 19.44\n",
      "\u001b[32m[2020-07-13 21:43:07] __main__ INFO: \u001b[0mLoss 0.4507 Accuracy 0.9055\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10 test dataset \n",
    "# Right the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/densenet.yaml \\\n",
    "   model.densenet.depth 100 \\\n",
    "   model.densenet.growth_rate 12 \\\n",
    "   test.batch_size 64 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_cm_1_1/exp00/checkpoint_00400.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_cm_1_1/exp00/test_results_0400_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-13 21:43:35] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_cm_1_1/exp00/checkpoint_00400.pth\n",
      "CIFAR 10.1\n",
      "100%|| 32/32 [00:04<00:00,  7.67it/s]\n",
      "\u001b[32m[2020-07-13 21:43:40] __main__ INFO: \u001b[0mElapsed 4.17\n",
      "\u001b[32m[2020-07-13 21:43:40] __main__ INFO: \u001b[0mLoss 0.8656 Accuracy 0.8250\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10.1 test dataset \n",
    "# Right the results to the test output directory specified.\n",
    "os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "!python evaluate.py --config configs/cifar/densenet.yaml \\\n",
    "   model.densenet.depth 100 \\\n",
    "   model.densenet.growth_rate 12 \\\n",
    "   test.batch_size 64 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_cm_1_1/exp00/checkpoint_00400.pth \\\n",
    "   dataset.name CIFAR101 \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_cm_1_1/exp00/test_results_0400_cifar101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Record the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Testset</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Original_Accuracy</th>\n",
       "      <th>Original_CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>densenet_BC_100_12</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3681</td>\n",
       "      <td>0.8875</td>\n",
       "      <td>95.5</td>\n",
       "      <td>(95.1, 95.9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>densenet_BC_100_12</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>200</td>\n",
       "      <td>0.2279</td>\n",
       "      <td>0.9456</td>\n",
       "      <td>95.5</td>\n",
       "      <td>(95.1, 95.9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>densenet_BC_100_12</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>300</td>\n",
       "      <td>0.2223</td>\n",
       "      <td>0.9484</td>\n",
       "      <td>95.5</td>\n",
       "      <td>(95.1, 95.9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>densenet_BC_100_12</td>\n",
       "      <td>cifar10.1</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5098</td>\n",
       "      <td>0.8830</td>\n",
       "      <td>87.6</td>\n",
       "      <td>(86.1, 89.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model    Testset  Epoch    Loss  Accuracy  Original_Accuracy  \\\n",
       "0  densenet_BC_100_12    cifar10    100  0.3681    0.8875               95.5   \n",
       "1  densenet_BC_100_12    cifar10    200  0.2279    0.9456               95.5   \n",
       "2  densenet_BC_100_12    cifar10    300  0.2223    0.9484               95.5   \n",
       "3  densenet_BC_100_12  cifar10.1    300  0.5098    0.8830               87.6   \n",
       "\n",
       "    Original_CI  \n",
       "0  (95.1, 95.9)  \n",
       "1  (95.1, 95.9)  \n",
       "2  (95.1, 95.9)  \n",
       "3  (86.1, 89.0)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write the results to a CSV file so that we can analyze later.\n",
    "import pandas as pd\n",
    "\n",
    "results = {'Model': ['densenet_BC_100_12', 'densenet_BC_100_12', 'densenet_BC_100_12', 'densenet_BC_100_12'],\n",
    "           'Testset': ['cifar10', 'cifar10', 'cifar10', 'cifar10.1'],\n",
    "           'Epoch': [100, 200, 300, 300],\n",
    "           'Loss': [0.3681, 0.2279, 0.2223, 0.5098],\n",
    "           'Accuracy': [0.8875, 0.9456, 0.9484, 0.8830],\n",
    "           'Original_Accuracy': [95.5, 95.5, 95.5, 87.6],\n",
    "           'Original_CI': [(95.1, 95.9), (95.1, 95.9), (95.1, 95.9), (86.1, 89.0)]\n",
    "           }\n",
    "\n",
    "df = pd.DataFrame(results, columns = ['Model', 'Testset', 'Epoch', 'Loss', 'Accuracy', \n",
    "                                      'Original_Accuracy', 'Original_CI'])\n",
    "\n",
    "\n",
    "\n",
    "#df.to_csv('/home/ec2-user/SageMaker/experiments/wrn_28_10/exp00/results.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Testset</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Original_Accuracy</th>\n",
       "      <th>Original_CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>densenet_BC_100_12_cm_1_1</td>\n",
       "      <td>400</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>0.4507</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>95.5</td>\n",
       "      <td>(95.1, 95.9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>densenet_BC_100_12_cm_1_1</td>\n",
       "      <td>400</td>\n",
       "      <td>cifar10.1</td>\n",
       "      <td>0.8656</td>\n",
       "      <td>0.825</td>\n",
       "      <td>87.6</td>\n",
       "      <td>(86.1, 89.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>densenet_BC_100_12_cm_1_1_refined400</td>\n",
       "      <td>50</td>\n",
       "      <td>cifar10.1</td>\n",
       "      <td>0.7624</td>\n",
       "      <td>0.8645</td>\n",
       "      <td>87.6</td>\n",
       "      <td>(86.1, 89.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>densenet_BC_100_12_cm_1_1_refined400</td>\n",
       "      <td>50</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>0.3269</td>\n",
       "      <td>0.9369</td>\n",
       "      <td>95.5</td>\n",
       "      <td>(95.1, 95.9)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Model Epoch    Testset    Loss Accuracy  \\\n",
       "0             densenet_BC_100_12_cm_1_1   400    cifar10  0.4507   0.9055   \n",
       "1             densenet_BC_100_12_cm_1_1   400  cifar10.1  0.8656    0.825   \n",
       "2  densenet_BC_100_12_cm_1_1_refined400    50  cifar10.1  0.7624   0.8645   \n",
       "3  densenet_BC_100_12_cm_1_1_refined400    50    cifar10  0.3269   0.9369   \n",
       "\n",
       "   Original_Accuracy   Original_CI  \n",
       "0               95.5  (95.1, 95.9)  \n",
       "1               87.6  (86.1, 89.0)  \n",
       "2               87.6  (86.1, 89.0)  \n",
       "3               95.5  (95.1, 95.9)  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "model = 'densenet_BC_100_12_cm_1_1'\n",
    "model_refined = model + '_refined400'\n",
    "\n",
    "a = pd.Series([model, 400, 'cifar10', 0.4507, 0.9055])\n",
    "c = pd.Series([model, 400, 'cifar10.1', 0.8656, 0.8250])\n",
    "\n",
    "e = pd.Series([model_refined, 50, 'cifar10.1', 0.7624, 0.8645])\n",
    "f = pd.Series([model_refined, 50, 'cifar10', 0.3269, 0.9369])\n",
    "               \n",
    "df_results = pd.concat([a,c,e,f], axis=1).T\n",
    "df_results.columns = ['Model', 'Epoch', 'Testset', 'Loss', 'Accuracy']\n",
    "\n",
    "df_results['Original_Accuracy'] = df_results.apply((lambda row: 95.5 if row[2] == 'cifar10' else 87.6), axis=1)\n",
    "df_results['Original_CI'] = df_results.apply((lambda row: (95.1, 95.9) if row[2] == 'cifar10' else (86.1, 89.0)), axis=1)\n",
    "\n",
    "df_results.to_csv('/home/ec2-user/SageMaker/experiments/' + model + '/results.csv')\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the model checkpoints, configs, and results to S3 \n",
    "bucket='sagemaker-june29'\n",
    "prefix = 'sagemaker/results/original-models/densenet_BC_100_12_cm_1_1'\n",
    "path = '/home/ec2-user/SageMaker/experiments/densenet_BC_100_12_cm_1_1'\n",
    "\n",
    "s3_resource = boto3.resource(\"s3\", region_name=\"us-east-2\")\n",
    "\n",
    "def uploadDirectory(local_path,bucket_name,s3_prefix):\n",
    "\n",
    "    my_bucket = s3_resource.Bucket(bucket_name)\n",
    "    \n",
    "    for path, subdirs, files in os.walk(local_path):\n",
    "        path = path.replace(\"\\\\\",\"/\")\n",
    "        directory_name = path.replace(local_path,\"\")\n",
    "        for file in files:\n",
    "            #print(\"Local File:\", os.path.join(path, file))\n",
    "            #print(\"      Dest:\", s3_prefix+directory_name+'/'+file)\n",
    "            my_bucket.upload_file(os.path.join(path, file), s3_prefix+directory_name+'/'+file)\n",
    "    \n",
    "uploadDirectory(path,bucket,prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
