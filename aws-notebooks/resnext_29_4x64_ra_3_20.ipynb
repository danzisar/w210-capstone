{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNext 29 4x64\n",
    "\n",
    " - Training Dataset:  RandAugment, N=3, M=20\n",
    " - Sagemaker Notebook must be of type, conda_pytorch_p36\n",
    " \n",
    "#### Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy \n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without Containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 1)) (1.18.1)\n",
      "Requirement already satisfied: torch>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 2)) (1.4.0)\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 3)) (0.5.0)\n",
      "Collecting fvcore\n",
      "  Downloading fvcore-0.1.1.post20200623.tar.gz (32 kB)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 5)) (4.44.1)\n",
      "Collecting yacs\n",
      "  Downloading yacs-0.1.7-py3-none-any.whl (14 kB)\n",
      "Collecting apex\n",
      "  Cloning https://github.com/NVIDIA/apex.git to /tmp/pip-install-gskewhf0/apex\n",
      "  Running command git clone -q https://github.com/NVIDIA/apex.git /tmp/pip-install-gskewhf0/apex\n",
      "  Running command git submodule update --init --recursive -q\n",
      "Collecting termcolor\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting thop<0.0.31.post2004070130\n",
      "  Downloading thop-0.0.31.post2001170342-py3-none-any.whl (7.5 kB)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 3)) (1.14.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 3)) (7.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from fvcore->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (5.3.1)\n",
      "Collecting portalocker\n",
      "  Downloading portalocker-1.7.0-py2.py3-none-any.whl (14 kB)\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.8.7-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: fvcore, apex, termcolor\n",
      "  Building wheel for fvcore (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fvcore: filename=fvcore-0.1.1.post20200623-py3-none-any.whl size=41179 sha256=0d0aaa4ace3de166ef11214ea46eba085436aa50062d7349eb2e0afa46c9854b\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/27/fc/86/b29aea030f5468db673ec86033a9579cc50e02979aa0c78ebe\n",
      "  Building wheel for apex (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for apex: filename=apex-0.1-py3-none-any.whl size=192130 sha256=95369c882569b08fb0d3c8610e76f3c7508b1952ca61548c7f6599a23b28f474\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-__xt74d1/wheels/2a/45/23/6b4f2d6323a65ee0022d22a96d7bf580138e689f17cc48235c\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=2521e69be0aee9dee08f0c7dd6b7cff7e41cae1b0f8372ce92f2bb624efb3c7a\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n",
      "Successfully built fvcore apex termcolor\n",
      "Installing collected packages: yacs, portalocker, termcolor, tabulate, fvcore, apex, thop\n",
      "Successfully installed apex-0.1 fvcore-0.1.1.post20200623 portalocker-1.7.0 tabulate-0.8.7 termcolor-1.1.0 thop-0.0.31.post2001170342 yacs-0.1.7\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Sagemaker Notebook must be of type, conda_pytorch_p36\n",
    "\n",
    "!pip install -r '/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboard\n",
      "  Downloading tensorboard-2.2.2-py3-none-any.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (2.23.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.34.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.0.1)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.2.2-py3-none-any.whl (88 kB)\n",
      "\u001b[K     |████████████████████████████████| 88 kB 2.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.14.0)\n",
      "Collecting absl-py>=0.4\n",
      "  Downloading absl-py-0.9.0.tar.gz (104 kB)\n",
      "\u001b[K     |████████████████████████████████| 104 kB 30.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (46.1.3.post20200330)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.18.0-py2.py3-none-any.whl (90 kB)\n",
      "\u001b[K     |████████████████████████████████| 90 kB 1.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio>=1.24.3\n",
      "  Downloading grpcio-1.30.0-cp36-cp36m-manylinux2010_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 25.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\n",
      "\u001b[K     |████████████████████████████████| 779 kB 66.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.18.1)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (3.12.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.4.5.2)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (1.5.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard) (3.4.2)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 54.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.1.0-py3-none-any.whl (10 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard) (2.2.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 55.5 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: absl-py\n",
      "  Building wheel for absl-py (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for absl-py: filename=absl_py-0.9.0-py3-none-any.whl size=121931 sha256=676973d2208585efd2d403e4ae9b81cdfdb00be33eba02ac87572bfbd3cddd06\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/c3/af/84/3962a6af7b4ab336e951b7877dcfb758cf94548bb1771e0679\n",
      "Successfully built absl-py\n",
      "Installing collected packages: markdown, absl-py, pyasn1-modules, cachetools, google-auth, grpcio, tensorboard-plugin-wit, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard\n",
      "Successfully installed absl-py-0.9.0 cachetools-4.1.0 google-auth-1.18.0 google-auth-oauthlib-0.4.1 grpcio-1.30.0 markdown-3.2.2 oauthlib-3.1.0 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 tensorboard-2.2.2 tensorboard-plugin-wit-1.7.0\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Need to add this to requirements.txt\n",
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-06-28 15:43:18] __main__ INFO: \u001b[0mdevice: cuda\n",
      "cudnn:\n",
      "  benchmark: True\n",
      "  deterministic: False\n",
      "dataset:\n",
      "  name: CIFAR10_RA_3_20\n",
      "  dataset_dir: ''\n",
      "  image_size: 32\n",
      "  n_channels: 3\n",
      "  n_classes: 10\n",
      "model:\n",
      "  type: cifar\n",
      "  name: resnext\n",
      "  init_mode: kaiming_fan_out\n",
      "  vgg:\n",
      "    n_channels: [64, 128, 256, 512, 512]\n",
      "    n_layers: [2, 2, 3, 3, 3]\n",
      "    use_bn: True\n",
      "  resnet:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "  resnet_preact:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "  wrn:\n",
      "    depth: 28\n",
      "    initial_channels: 16\n",
      "    widening_factor: 10\n",
      "    drop_rate: 0.0\n",
      "  densenet:\n",
      "    depth: 100\n",
      "    n_blocks: [6, 12, 24, 16]\n",
      "    block_type: bottleneck\n",
      "    growth_rate: 12\n",
      "    drop_rate: 0.0\n",
      "    compression_rate: 0.5\n",
      "  pyramidnet:\n",
      "    depth: 272\n",
      "    n_blocks: [3, 24, 36, 3]\n",
      "    initial_channels: 16\n",
      "    block_type: bottleneck\n",
      "    alpha: 200\n",
      "  resnext:\n",
      "    depth: 29\n",
      "    n_blocks: [3, 4, 6, 3]\n",
      "    initial_channels: 64\n",
      "    cardinality: 4\n",
      "    base_channels: 64\n",
      "  shake_shake:\n",
      "    depth: 26\n",
      "    initial_channels: 96\n",
      "    shake_forward: True\n",
      "    shake_backward: True\n",
      "    shake_image: True\n",
      "  se_resnet_preact:\n",
      "    depth: 110\n",
      "    initial_channels: 16\n",
      "    se_reduction: 16\n",
      "    block_type: basic\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "train:\n",
      "  checkpoint: ''\n",
      "  resume: False\n",
      "  precision: O0\n",
      "  batch_size: 128\n",
      "  subdivision: 1\n",
      "  optimizer: sgd\n",
      "  base_lr: 0.1\n",
      "  momentum: 0.9\n",
      "  nesterov: True\n",
      "  weight_decay: 0.0005\n",
      "  no_weight_decay_on_bn: False\n",
      "  gradient_clip: 0\n",
      "  start_epoch: 0\n",
      "  seed: 0\n",
      "  val_first: True\n",
      "  val_period: 1\n",
      "  val_ratio: 0.1\n",
      "  use_test_as_val: False\n",
      "  output_dir: /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_ra_3_20/exp00\n",
      "  log_period: 100\n",
      "  checkpoint_period: 100\n",
      "  use_tensorboard: True\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: True\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "  distributed: False\n",
      "  dist:\n",
      "    backend: nccl\n",
      "    init_method: env://\n",
      "    world_size: -1\n",
      "    node_rank: -1\n",
      "    local_rank: 0\n",
      "    use_sync_bn: False\n",
      "tensorboard:\n",
      "  train_images: False\n",
      "  val_images: False\n",
      "  model_params: False\n",
      "optim:\n",
      "  adam:\n",
      "    betas: (0.9, 0.999)\n",
      "  lars:\n",
      "    eps: 1e-09\n",
      "    threshold: 0.01\n",
      "  adabound:\n",
      "    betas: (0.9, 0.999)\n",
      "    final_lr: 0.1\n",
      "    gamma: 0.001\n",
      "scheduler:\n",
      "  epochs: 400\n",
      "  warmup:\n",
      "    type: none\n",
      "    epochs: 0\n",
      "    start_factor: 0.001\n",
      "    exponent: 4\n",
      "  type: multistep\n",
      "  milestones: [150, 225]\n",
      "  lr_decay: 0.1\n",
      "  lr_min_factor: 0.001\n",
      "  T0: 10\n",
      "  T_mul: 1.0\n",
      "validation:\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: False\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "augmentation:\n",
      "  use_random_crop: True\n",
      "  use_random_horizontal_flip: True\n",
      "  use_cutout: False\n",
      "  use_random_erasing: False\n",
      "  use_dual_cutout: False\n",
      "  use_mixup: False\n",
      "  use_ricap: False\n",
      "  use_cutmix: False\n",
      "  use_label_smoothing: False\n",
      "  random_crop:\n",
      "    padding: 4\n",
      "    fill: 0\n",
      "    padding_mode: constant\n",
      "  random_horizontal_flip:\n",
      "    prob: 0.5\n",
      "  cutout:\n",
      "    prob: 1.0\n",
      "    mask_size: 16\n",
      "    cut_inside: False\n",
      "    mask_color: 0\n",
      "    dual_cutout_alpha: 0.1\n",
      "  random_erasing:\n",
      "    prob: 0.5\n",
      "    area_ratio_range: [0.02, 0.4]\n",
      "    min_aspect_ratio: 0.3\n",
      "    max_attempt: 20\n",
      "  mixup:\n",
      "    alpha: 1.0\n",
      "  ricap:\n",
      "    beta: 0.3\n",
      "  cutmix:\n",
      "    alpha: 1.0\n",
      "  label_smoothing:\n",
      "    epsilon: 0.1\n",
      "tta:\n",
      "  use_resize: False\n",
      "  use_center_crop: False\n",
      "  resize: 256\n",
      "test:\n",
      "  checkpoint: ''\n",
      "  output_dir: ''\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    pin_memory: False\n",
      "\u001b[32m[2020-06-28 15:43:18] __main__ INFO: \u001b[0menv_info:\n",
      "  pytorch_version: 1.4.0\n",
      "  cuda_version: 10.1\n",
      "  cudnn_version: 7603\n",
      "  num_gpus: 1\n",
      "  gpu_name: Tesla K80\n",
      "  gpu_capability: 3.7\n",
      "(50000, 32, 32, 3)\n",
      "\u001b[32m[2020-06-28 15:43:49] __main__ INFO: \u001b[0mMACs  : 2.75G\n",
      "\u001b[32m[2020-06-28 15:43:49] __main__ INFO: \u001b[0m#params: 17.56M\n",
      "Selected optimization level O0:  Pure FP32 training.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n",
      "\u001b[32m[2020-06-28 15:43:49] __main__ INFO: \u001b[0mVal 0\n",
      "\u001b[32m[2020-06-28 15:44:15] __main__ INFO: \u001b[0mEpoch 0 loss 6.8277 acc@1 0.1044 acc@5 0.5132\n",
      "\u001b[32m[2020-06-28 15:44:15] __main__ INFO: \u001b[0mElapsed 25.65\n",
      "\u001b[32m[2020-06-28 15:44:15] __main__ INFO: \u001b[0mTrain 1 0\n",
      "\u001b[32m[2020-06-28 15:46:43] __main__ INFO: \u001b[0mEpoch 1 Step 100/351 lr 0.100000 loss 2.6641 (8.3829) acc@1 0.0938 (0.0998) acc@5 0.5000 (0.5017)\n",
      "\u001b[32m[2020-06-28 15:49:03] __main__ INFO: \u001b[0mEpoch 1 Step 200/351 lr 0.100000 loss 2.3795 (5.6299) acc@1 0.1094 (0.1003) acc@5 0.5156 (0.5009)\n",
      "\u001b[32m[2020-06-28 15:51:23] __main__ INFO: \u001b[0mEpoch 1 Step 300/351 lr 0.100000 loss 2.4871 (4.6392) acc@1 0.1172 (0.0998) acc@5 0.5078 (0.5008)\n",
      "\u001b[32m[2020-06-28 15:52:34] __main__ INFO: \u001b[0mEpoch 1 Step 351/351 lr 0.100000 loss 2.9982 (4.3402) acc@1 0.1016 (0.1008) acc@5 0.4375 (0.5016)\n",
      "\u001b[32m[2020-06-28 15:52:34] __main__ INFO: \u001b[0mElapsed 499.04\n",
      "\u001b[32m[2020-06-28 15:52:34] __main__ INFO: \u001b[0mVal 1\n",
      "\u001b[32m[2020-06-28 15:52:51] __main__ INFO: \u001b[0mEpoch 1 loss 9.8725 acc@1 0.1022 acc@5 0.5006\n",
      "\u001b[32m[2020-06-28 15:52:51] __main__ INFO: \u001b[0mElapsed 17.42\n",
      "\u001b[32m[2020-06-28 15:52:51] __main__ INFO: \u001b[0mTrain 2 351\n",
      "\u001b[32m[2020-06-28 15:55:11] __main__ INFO: \u001b[0mEpoch 2 Step 100/351 lr 0.100000 loss 2.3926 (2.4652) acc@1 0.1094 (0.1020) acc@5 0.4844 (0.4889)\n",
      "\u001b[32m[2020-06-28 15:57:31] __main__ INFO: \u001b[0mEpoch 2 Step 200/351 lr 0.100000 loss 2.4574 (2.4425) acc@1 0.0859 (0.1021) acc@5 0.5078 (0.4957)\n",
      "\u001b[32m[2020-06-28 15:59:51] __main__ INFO: \u001b[0mEpoch 2 Step 300/351 lr 0.100000 loss 2.2883 (2.4212) acc@1 0.0859 (0.1018) acc@5 0.5391 (0.4995)\n",
      "\u001b[32m[2020-06-28 16:01:03] __main__ INFO: \u001b[0mEpoch 2 Step 351/351 lr 0.100000 loss 2.4373 (2.4105) acc@1 0.0938 (0.1015) acc@5 0.5078 (0.5011)\n",
      "\u001b[32m[2020-06-28 16:01:03] __main__ INFO: \u001b[0mElapsed 491.27\n",
      "\u001b[32m[2020-06-28 16:01:03] __main__ INFO: \u001b[0mVal 2\n",
      "\u001b[32m[2020-06-28 16:01:20] __main__ INFO: \u001b[0mEpoch 2 loss 2.3315 acc@1 0.1074 acc@5 0.5112\n",
      "\u001b[32m[2020-06-28 16:01:20] __main__ INFO: \u001b[0mElapsed 17.40\n",
      "\u001b[32m[2020-06-28 16:01:20] __main__ INFO: \u001b[0mTrain 3 702\n",
      "\u001b[32m[2020-06-28 16:03:40] __main__ INFO: \u001b[0mEpoch 3 Step 100/351 lr 0.100000 loss 2.3213 (2.3382) acc@1 0.0859 (0.1035) acc@5 0.4844 (0.5035)\n",
      "\u001b[32m[2020-06-28 16:06:00] __main__ INFO: \u001b[0mEpoch 3 Step 200/351 lr 0.100000 loss 2.2845 (2.3350) acc@1 0.1094 (0.1044) acc@5 0.5625 (0.5075)\n",
      "\u001b[32m[2020-06-28 16:08:20] __main__ INFO: \u001b[0mEpoch 3 Step 300/351 lr 0.100000 loss 2.3085 (2.3316) acc@1 0.1016 (0.1035) acc@5 0.5469 (0.5075)\n",
      "\u001b[32m[2020-06-28 16:09:32] __main__ INFO: \u001b[0mEpoch 3 Step 351/351 lr 0.100000 loss 2.3325 (2.3299) acc@1 0.0859 (0.1034) acc@5 0.4688 (0.5066)\n",
      "\u001b[32m[2020-06-28 16:09:32] __main__ INFO: \u001b[0mElapsed 491.52\n",
      "\u001b[32m[2020-06-28 16:09:32] __main__ INFO: \u001b[0mVal 3\n",
      "\u001b[32m[2020-06-28 16:09:49] __main__ INFO: \u001b[0mEpoch 3 loss 2.8683 acc@1 0.1092 acc@5 0.4970\n",
      "\u001b[32m[2020-06-28 16:09:49] __main__ INFO: \u001b[0mElapsed 17.38\n",
      "\u001b[32m[2020-06-28 16:09:49] __main__ INFO: \u001b[0mTrain 4 1053\n",
      "\u001b[32m[2020-06-28 16:12:09] __main__ INFO: \u001b[0mEpoch 4 Step 100/351 lr 0.100000 loss 2.3558 (2.3199) acc@1 0.0859 (0.1048) acc@5 0.4297 (0.5092)\n",
      "\u001b[32m[2020-06-28 16:14:29] __main__ INFO: \u001b[0mEpoch 4 Step 200/351 lr 0.100000 loss 2.2966 (2.3180) acc@1 0.1016 (0.1030) acc@5 0.4297 (0.5040)\n",
      "\u001b[32m[2020-06-28 16:16:50] __main__ INFO: \u001b[0mEpoch 4 Step 300/351 lr 0.100000 loss 2.3466 (2.3169) acc@1 0.1094 (0.1035) acc@5 0.5312 (0.5033)\n",
      "\u001b[32m[2020-06-28 16:18:01] __main__ INFO: \u001b[0mEpoch 4 Step 351/351 lr 0.100000 loss 2.2906 (2.3158) acc@1 0.1172 (0.1027) acc@5 0.5781 (0.5037)\n",
      "\u001b[32m[2020-06-28 16:18:01] __main__ INFO: \u001b[0mElapsed 491.94\n",
      "\u001b[32m[2020-06-28 16:18:01] __main__ INFO: \u001b[0mVal 4\n",
      "\u001b[32m[2020-06-28 16:18:18] __main__ INFO: \u001b[0mEpoch 4 loss 2.3431 acc@1 0.0952 acc@5 0.5072\n",
      "\u001b[32m[2020-06-28 16:18:18] __main__ INFO: \u001b[0mElapsed 17.43\n",
      "\u001b[32m[2020-06-28 16:18:18] __main__ INFO: \u001b[0mTrain 5 1404\n",
      "\u001b[32m[2020-06-28 16:20:38] __main__ INFO: \u001b[0mEpoch 5 Step 100/351 lr 0.100000 loss 2.2888 (2.3096) acc@1 0.1328 (0.0998) acc@5 0.5312 (0.5084)\n",
      "\u001b[32m[2020-06-28 16:22:58] __main__ INFO: \u001b[0mEpoch 5 Step 200/351 lr 0.100000 loss 2.3139 (2.3084) acc@1 0.1875 (0.1059) acc@5 0.4844 (0.5092)\n",
      "\u001b[32m[2020-06-28 16:25:19] __main__ INFO: \u001b[0mEpoch 5 Step 300/351 lr 0.100000 loss 2.3036 (2.3069) acc@1 0.1719 (0.1062) acc@5 0.5703 (0.5140)\n",
      "\u001b[32m[2020-06-28 16:26:30] __main__ INFO: \u001b[0mEpoch 5 Step 351/351 lr 0.100000 loss 2.2954 (2.3065) acc@1 0.1328 (0.1055) acc@5 0.4922 (0.5145)\n",
      "\u001b[32m[2020-06-28 16:26:30] __main__ INFO: \u001b[0mElapsed 491.57\n",
      "\u001b[32m[2020-06-28 16:26:30] __main__ INFO: \u001b[0mVal 5\n",
      "\u001b[32m[2020-06-28 16:26:47] __main__ INFO: \u001b[0mEpoch 5 loss 2.4035 acc@1 0.1094 acc@5 0.5294\n",
      "\u001b[32m[2020-06-28 16:26:47] __main__ INFO: \u001b[0mElapsed 17.40\n",
      "\u001b[32m[2020-06-28 16:26:47] __main__ INFO: \u001b[0mTrain 6 1755\n",
      "\u001b[32m[2020-06-28 16:29:07] __main__ INFO: \u001b[0mEpoch 6 Step 100/351 lr 0.100000 loss 2.2950 (2.3022) acc@1 0.1094 (0.1114) acc@5 0.5859 (0.5301)\n",
      "\u001b[32m[2020-06-28 16:31:27] __main__ INFO: \u001b[0mEpoch 6 Step 200/351 lr 0.100000 loss 2.3021 (2.3013) acc@1 0.1328 (0.1101) acc@5 0.5859 (0.5286)\n",
      "\u001b[32m[2020-06-28 16:33:48] __main__ INFO: \u001b[0mEpoch 6 Step 300/351 lr 0.100000 loss 2.3087 (2.3007) acc@1 0.1094 (0.1095) acc@5 0.5078 (0.5290)\n",
      "\u001b[32m[2020-06-28 16:34:59] __main__ INFO: \u001b[0mEpoch 6 Step 351/351 lr 0.100000 loss 2.2927 (2.3005) acc@1 0.1016 (0.1099) acc@5 0.5234 (0.5285)\n",
      "\u001b[32m[2020-06-28 16:34:59] __main__ INFO: \u001b[0mElapsed 491.59\n",
      "\u001b[32m[2020-06-28 16:34:59] __main__ INFO: \u001b[0mVal 6\n",
      "\u001b[32m[2020-06-28 16:35:16] __main__ INFO: \u001b[0mEpoch 6 loss 2.3147 acc@1 0.1038 acc@5 0.5148\n",
      "\u001b[32m[2020-06-28 16:35:16] __main__ INFO: \u001b[0mElapsed 17.39\n",
      "\u001b[32m[2020-06-28 16:35:16] __main__ INFO: \u001b[0mTrain 7 2106\n",
      "\u001b[32m[2020-06-28 16:37:37] __main__ INFO: \u001b[0mEpoch 7 Step 100/351 lr 0.100000 loss 2.2933 (2.3009) acc@1 0.1328 (0.1104) acc@5 0.5859 (0.5176)\n",
      "\u001b[32m[2020-06-28 16:39:57] __main__ INFO: \u001b[0mEpoch 7 Step 200/351 lr 0.100000 loss 2.3067 (2.2990) acc@1 0.0938 (0.1139) acc@5 0.5547 (0.5222)\n",
      "\u001b[32m[2020-06-28 16:42:17] __main__ INFO: \u001b[0mEpoch 7 Step 300/351 lr 0.100000 loss 2.3031 (2.2983) acc@1 0.1172 (0.1153) acc@5 0.5000 (0.5245)\n",
      "\u001b[32m[2020-06-28 16:43:28] __main__ INFO: \u001b[0mEpoch 7 Step 351/351 lr 0.100000 loss 2.2973 (2.2980) acc@1 0.0703 (0.1147) acc@5 0.5000 (0.5229)\n",
      "\u001b[32m[2020-06-28 16:43:28] __main__ INFO: \u001b[0mElapsed 491.63\n",
      "\u001b[32m[2020-06-28 16:43:28] __main__ INFO: \u001b[0mVal 7\n",
      "\u001b[32m[2020-06-28 16:43:45] __main__ INFO: \u001b[0mEpoch 7 loss 2.3013 acc@1 0.1098 acc@5 0.5222\n",
      "\u001b[32m[2020-06-28 16:43:45] __main__ INFO: \u001b[0mElapsed 17.40\n",
      "\u001b[32m[2020-06-28 16:43:45] __main__ INFO: \u001b[0mTrain 8 2457\n",
      "\u001b[32m[2020-06-28 16:46:06] __main__ INFO: \u001b[0mEpoch 8 Step 100/351 lr 0.100000 loss 2.2905 (2.2951) acc@1 0.1094 (0.1105) acc@5 0.5312 (0.5363)\n",
      "\u001b[32m[2020-06-28 16:48:25] __main__ INFO: \u001b[0mEpoch 8 Step 200/351 lr 0.100000 loss 2.3053 (2.2950) acc@1 0.1641 (0.1112) acc@5 0.5078 (0.5344)\n",
      "\u001b[32m[2020-06-28 16:50:46] __main__ INFO: \u001b[0mEpoch 8 Step 300/351 lr 0.100000 loss 2.3150 (2.2933) acc@1 0.0781 (0.1125) acc@5 0.5000 (0.5358)\n",
      "\u001b[32m[2020-06-28 16:51:57] __main__ INFO: \u001b[0mEpoch 8 Step 351/351 lr 0.100000 loss 2.3194 (2.2931) acc@1 0.0938 (0.1128) acc@5 0.5000 (0.5360)\n",
      "\u001b[32m[2020-06-28 16:51:57] __main__ INFO: \u001b[0mElapsed 491.85\n",
      "\u001b[32m[2020-06-28 16:51:57] __main__ INFO: \u001b[0mVal 8\n",
      "\u001b[32m[2020-06-28 16:52:15] __main__ INFO: \u001b[0mEpoch 8 loss 2.2922 acc@1 0.1118 acc@5 0.5236\n",
      "\u001b[32m[2020-06-28 16:52:15] __main__ INFO: \u001b[0mElapsed 17.39\n",
      "\u001b[32m[2020-06-28 16:52:15] __main__ INFO: \u001b[0mTrain 9 2808\n",
      "\u001b[32m[2020-06-28 16:54:35] __main__ INFO: \u001b[0mEpoch 9 Step 100/351 lr 0.100000 loss 2.3070 (2.2914) acc@1 0.0781 (0.1159) acc@5 0.5234 (0.5431)\n",
      "\u001b[32m[2020-06-28 16:56:55] __main__ INFO: \u001b[0mEpoch 9 Step 200/351 lr 0.100000 loss 2.2916 (2.2881) acc@1 0.1016 (0.1189) acc@5 0.4766 (0.5466)\n",
      "\u001b[32m[2020-06-28 16:59:15] __main__ INFO: \u001b[0mEpoch 9 Step 300/351 lr 0.100000 loss 2.2664 (2.2856) acc@1 0.1094 (0.1207) acc@5 0.6172 (0.5483)\n",
      "\u001b[32m[2020-06-28 17:00:27] __main__ INFO: \u001b[0mEpoch 9 Step 351/351 lr 0.100000 loss 2.2926 (2.2853) acc@1 0.1250 (0.1212) acc@5 0.5156 (0.5479)\n",
      "\u001b[32m[2020-06-28 17:00:27] __main__ INFO: \u001b[0mElapsed 492.14\n",
      "\u001b[32m[2020-06-28 17:00:27] __main__ INFO: \u001b[0mVal 9\n",
      "\u001b[32m[2020-06-28 17:00:44] __main__ INFO: \u001b[0mEpoch 9 loss 2.2788 acc@1 0.1116 acc@5 0.5618\n",
      "\u001b[32m[2020-06-28 17:00:44] __main__ INFO: \u001b[0mElapsed 17.41\n",
      "\u001b[32m[2020-06-28 17:00:44] __main__ INFO: \u001b[0mTrain 10 3159\n",
      "\u001b[32m[2020-06-28 17:03:04] __main__ INFO: \u001b[0mEpoch 10 Step 100/351 lr 0.100000 loss 2.3015 (2.2731) acc@1 0.0938 (0.1194) acc@5 0.5000 (0.5613)\n",
      "\u001b[32m[2020-06-28 17:05:25] __main__ INFO: \u001b[0mEpoch 10 Step 200/351 lr 0.100000 loss 2.2590 (2.2748) acc@1 0.1172 (0.1204) acc@5 0.5703 (0.5605)\n",
      "\u001b[32m[2020-06-28 17:07:45] __main__ INFO: \u001b[0mEpoch 10 Step 300/351 lr 0.100000 loss 2.2559 (2.2751) acc@1 0.1172 (0.1202) acc@5 0.6250 (0.5595)\n",
      "\u001b[32m[2020-06-28 17:08:57] __main__ INFO: \u001b[0mEpoch 10 Step 351/351 lr 0.100000 loss 2.3103 (2.2750) acc@1 0.0781 (0.1205) acc@5 0.4766 (0.5615)\n",
      "\u001b[32m[2020-06-28 17:08:57] __main__ INFO: \u001b[0mElapsed 492.45\n",
      "\u001b[32m[2020-06-28 17:08:57] __main__ INFO: \u001b[0mVal 10\n",
      "\u001b[32m[2020-06-28 17:09:14] __main__ INFO: \u001b[0mEpoch 10 loss 2.2825 acc@1 0.1188 acc@5 0.5428\n",
      "\u001b[32m[2020-06-28 17:09:14] __main__ INFO: \u001b[0mElapsed 17.39\n",
      "\u001b[32m[2020-06-28 17:09:14] __main__ INFO: \u001b[0mTrain 11 3510\n",
      "\u001b[32m[2020-06-28 17:11:34] __main__ INFO: \u001b[0mEpoch 11 Step 100/351 lr 0.100000 loss 2.2512 (2.2697) acc@1 0.1016 (0.1262) acc@5 0.6016 (0.5693)\n",
      "\u001b[32m[2020-06-28 17:13:55] __main__ INFO: \u001b[0mEpoch 11 Step 200/351 lr 0.100000 loss 2.2440 (2.2667) acc@1 0.1641 (0.1280) acc@5 0.6016 (0.5694)\n",
      "\u001b[32m[2020-06-28 17:16:15] __main__ INFO: \u001b[0mEpoch 11 Step 300/351 lr 0.100000 loss 2.2847 (2.2656) acc@1 0.1016 (0.1288) acc@5 0.5781 (0.5720)\n",
      "\u001b[32m[2020-06-28 17:17:27] __main__ INFO: \u001b[0mEpoch 11 Step 351/351 lr 0.100000 loss 2.2699 (2.2644) acc@1 0.1641 (0.1293) acc@5 0.6016 (0.5731)\n",
      "\u001b[32m[2020-06-28 17:17:27] __main__ INFO: \u001b[0mElapsed 492.66\n",
      "\u001b[32m[2020-06-28 17:17:27] __main__ INFO: \u001b[0mVal 11\n",
      "\u001b[32m[2020-06-28 17:17:44] __main__ INFO: \u001b[0mEpoch 11 loss 2.2598 acc@1 0.1324 acc@5 0.5670\n",
      "\u001b[32m[2020-06-28 17:17:44] __main__ INFO: \u001b[0mElapsed 17.41\n",
      "\u001b[32m[2020-06-28 17:17:44] __main__ INFO: \u001b[0mTrain 12 3861\n",
      "\u001b[32m[2020-06-28 17:20:05] __main__ INFO: \u001b[0mEpoch 12 Step 100/351 lr 0.100000 loss 2.2434 (2.2599) acc@1 0.1484 (0.1330) acc@5 0.5547 (0.5746)\n",
      "\u001b[32m[2020-06-28 17:22:25] __main__ INFO: \u001b[0mEpoch 12 Step 200/351 lr 0.100000 loss 2.2864 (2.2563) acc@1 0.1094 (0.1357) acc@5 0.6172 (0.5784)\n",
      "\u001b[32m[2020-06-28 17:24:45] __main__ INFO: \u001b[0mEpoch 12 Step 300/351 lr 0.100000 loss 2.2591 (2.2538) acc@1 0.1328 (0.1354) acc@5 0.5391 (0.5796)\n",
      "\u001b[32m[2020-06-28 17:25:57] __main__ INFO: \u001b[0mEpoch 12 Step 351/351 lr 0.100000 loss 2.2650 (2.2542) acc@1 0.1016 (0.1346) acc@5 0.5312 (0.5785)\n",
      "\u001b[32m[2020-06-28 17:25:57] __main__ INFO: \u001b[0mElapsed 492.99\n",
      "\u001b[32m[2020-06-28 17:25:57] __main__ INFO: \u001b[0mVal 12\n",
      "\u001b[32m[2020-06-28 17:26:15] __main__ INFO: \u001b[0mEpoch 12 loss 2.2924 acc@1 0.1230 acc@5 0.5570\n",
      "\u001b[32m[2020-06-28 17:26:15] __main__ INFO: \u001b[0mElapsed 17.41\n",
      "\u001b[32m[2020-06-28 17:26:15] __main__ INFO: \u001b[0mTrain 13 4212\n",
      "\u001b[32m[2020-06-28 17:28:35] __main__ INFO: \u001b[0mEpoch 13 Step 100/351 lr 0.100000 loss 2.2297 (2.2507) acc@1 0.1719 (0.1316) acc@5 0.6406 (0.5815)\n",
      "\u001b[32m[2020-06-28 17:30:55] __main__ INFO: \u001b[0mEpoch 13 Step 200/351 lr 0.100000 loss 2.2933 (2.2464) acc@1 0.1250 (0.1341) acc@5 0.5938 (0.5864)\n",
      "\u001b[32m[2020-06-28 17:33:15] __main__ INFO: \u001b[0mEpoch 13 Step 300/351 lr 0.100000 loss 2.2370 (2.2452) acc@1 0.1328 (0.1347) acc@5 0.5703 (0.5878)\n",
      "\u001b[32m[2020-06-28 17:34:27] __main__ INFO: \u001b[0mEpoch 13 Step 351/351 lr 0.100000 loss 2.2860 (2.2441) acc@1 0.1016 (0.1353) acc@5 0.5703 (0.5891)\n",
      "\u001b[32m[2020-06-28 17:34:27] __main__ INFO: \u001b[0mElapsed 492.55\n",
      "\u001b[32m[2020-06-28 17:34:27] __main__ INFO: \u001b[0mVal 13\n",
      "\u001b[32m[2020-06-28 17:34:44] __main__ INFO: \u001b[0mEpoch 13 loss 2.3683 acc@1 0.1372 acc@5 0.5736\n",
      "\u001b[32m[2020-06-28 17:34:44] __main__ INFO: \u001b[0mElapsed 17.38\n",
      "\u001b[32m[2020-06-28 17:34:44] __main__ INFO: \u001b[0mTrain 14 4563\n",
      "\u001b[32m[2020-06-28 17:37:05] __main__ INFO: \u001b[0mEpoch 14 Step 100/351 lr 0.100000 loss 2.2524 (2.2346) acc@1 0.1250 (0.1407) acc@5 0.5781 (0.6012)\n",
      "\u001b[32m[2020-06-28 17:39:25] __main__ INFO: \u001b[0mEpoch 14 Step 200/351 lr 0.100000 loss 2.1875 (2.2330) acc@1 0.1328 (0.1446) acc@5 0.6016 (0.6007)\n",
      "\u001b[32m[2020-06-28 17:41:45] __main__ INFO: \u001b[0mEpoch 14 Step 300/351 lr 0.100000 loss 2.2131 (2.2314) acc@1 0.1094 (0.1464) acc@5 0.5547 (0.6017)\n",
      "\u001b[32m[2020-06-28 17:42:57] __main__ INFO: \u001b[0mEpoch 14 Step 351/351 lr 0.100000 loss 2.2015 (2.2297) acc@1 0.2031 (0.1470) acc@5 0.6406 (0.6023)\n",
      "\u001b[32m[2020-06-28 17:42:57] __main__ INFO: \u001b[0mElapsed 492.44\n",
      "\u001b[32m[2020-06-28 17:42:57] __main__ INFO: \u001b[0mVal 14\n",
      "\u001b[32m[2020-06-28 17:43:14] __main__ INFO: \u001b[0mEpoch 14 loss 2.2573 acc@1 0.1354 acc@5 0.5928\n",
      "\u001b[32m[2020-06-28 17:43:14] __main__ INFO: \u001b[0mElapsed 17.40\n",
      "\u001b[32m[2020-06-28 17:43:14] __main__ INFO: \u001b[0mTrain 15 4914\n",
      "\u001b[32m[2020-06-28 17:45:35] __main__ INFO: \u001b[0mEpoch 15 Step 100/351 lr 0.100000 loss 2.2279 (2.2191) acc@1 0.1328 (0.1549) acc@5 0.5938 (0.6063)\n",
      "\u001b[32m[2020-06-28 17:47:55] __main__ INFO: \u001b[0mEpoch 15 Step 200/351 lr 0.100000 loss 2.2341 (2.2165) acc@1 0.1172 (0.1535) acc@5 0.6328 (0.6103)\n",
      "\u001b[32m[2020-06-28 17:50:15] __main__ INFO: \u001b[0mEpoch 15 Step 300/351 lr 0.100000 loss 2.1442 (2.2160) acc@1 0.1797 (0.1533) acc@5 0.6484 (0.6118)\n",
      "\u001b[32m[2020-06-28 17:51:27] __main__ INFO: \u001b[0mEpoch 15 Step 351/351 lr 0.100000 loss 2.1833 (2.2166) acc@1 0.2188 (0.1539) acc@5 0.5938 (0.6111)\n",
      "\u001b[32m[2020-06-28 17:51:27] __main__ INFO: \u001b[0mElapsed 492.62\n",
      "\u001b[32m[2020-06-28 17:51:27] __main__ INFO: \u001b[0mVal 15\n",
      "\u001b[32m[2020-06-28 17:51:44] __main__ INFO: \u001b[0mEpoch 15 loss 2.2255 acc@1 0.1438 acc@5 0.5962\n",
      "\u001b[32m[2020-06-28 17:51:44] __main__ INFO: \u001b[0mElapsed 17.38\n",
      "\u001b[32m[2020-06-28 17:51:44] __main__ INFO: \u001b[0mTrain 16 5265\n",
      "\u001b[32m[2020-06-28 17:54:05] __main__ INFO: \u001b[0mEpoch 16 Step 100/351 lr 0.100000 loss 2.2391 (2.2195) acc@1 0.1172 (0.1558) acc@5 0.5859 (0.6035)\n",
      "\u001b[32m[2020-06-28 17:56:25] __main__ INFO: \u001b[0mEpoch 16 Step 200/351 lr 0.100000 loss 2.1902 (2.2127) acc@1 0.1094 (0.1569) acc@5 0.5859 (0.6095)\n",
      "\u001b[32m[2020-06-28 17:58:45] __main__ INFO: \u001b[0mEpoch 16 Step 300/351 lr 0.100000 loss 2.2173 (2.2080) acc@1 0.1641 (0.1585) acc@5 0.6172 (0.6131)\n",
      "\u001b[32m[2020-06-28 17:59:57] __main__ INFO: \u001b[0mEpoch 16 Step 351/351 lr 0.100000 loss 2.2090 (2.2081) acc@1 0.1875 (0.1592) acc@5 0.6484 (0.6130)\n",
      "\u001b[32m[2020-06-28 17:59:57] __main__ INFO: \u001b[0mElapsed 492.29\n",
      "\u001b[32m[2020-06-28 17:59:57] __main__ INFO: \u001b[0mVal 16\n",
      "\u001b[32m[2020-06-28 18:00:14] __main__ INFO: \u001b[0mEpoch 16 loss 2.2485 acc@1 0.1568 acc@5 0.6004\n",
      "\u001b[32m[2020-06-28 18:00:14] __main__ INFO: \u001b[0mElapsed 17.38\n",
      "\u001b[32m[2020-06-28 18:00:14] __main__ INFO: \u001b[0mTrain 17 5616\n",
      "\u001b[32m[2020-06-28 18:02:34] __main__ INFO: \u001b[0mEpoch 17 Step 100/351 lr 0.100000 loss 2.1983 (2.1931) acc@1 0.1406 (0.1639) acc@5 0.6641 (0.6245)\n",
      "\u001b[32m[2020-06-28 18:04:54] __main__ INFO: \u001b[0mEpoch 17 Step 200/351 lr 0.100000 loss 2.1916 (2.1949) acc@1 0.1484 (0.1652) acc@5 0.6094 (0.6229)\n",
      "\u001b[32m[2020-06-28 18:07:14] __main__ INFO: \u001b[0mEpoch 17 Step 300/351 lr 0.100000 loss 2.1827 (2.1935) acc@1 0.1016 (0.1652) acc@5 0.6641 (0.6228)\n",
      "\u001b[32m[2020-06-28 18:08:25] __main__ INFO: \u001b[0mEpoch 17 Step 351/351 lr 0.100000 loss 2.1776 (2.1926) acc@1 0.1953 (0.1658) acc@5 0.6328 (0.6229)\n",
      "\u001b[32m[2020-06-28 18:08:25] __main__ INFO: \u001b[0mElapsed 491.41\n",
      "\u001b[32m[2020-06-28 18:08:25] __main__ INFO: \u001b[0mVal 17\n",
      "\u001b[32m[2020-06-28 18:08:43] __main__ INFO: \u001b[0mEpoch 17 loss 2.5655 acc@1 0.1376 acc@5 0.5750\n",
      "\u001b[32m[2020-06-28 18:08:43] __main__ INFO: \u001b[0mElapsed 17.38\n",
      "\u001b[32m[2020-06-28 18:08:43] __main__ INFO: \u001b[0mTrain 18 5967\n",
      "\u001b[32m[2020-06-28 18:11:03] __main__ INFO: \u001b[0mEpoch 18 Step 100/351 lr 0.100000 loss 2.1760 (2.1814) acc@1 0.1016 (0.1679) acc@5 0.6328 (0.6345)\n",
      "\u001b[32m[2020-06-28 18:13:23] __main__ INFO: \u001b[0mEpoch 18 Step 200/351 lr 0.100000 loss 2.2094 (2.1850) acc@1 0.1719 (0.1687) acc@5 0.6562 (0.6317)\n",
      "\u001b[32m[2020-06-28 18:15:43] __main__ INFO: \u001b[0mEpoch 18 Step 300/351 lr 0.100000 loss 2.1918 (2.1851) acc@1 0.1562 (0.1693) acc@5 0.6172 (0.6295)\n",
      "\u001b[32m[2020-06-28 18:16:54] __main__ INFO: \u001b[0mEpoch 18 Step 351/351 lr 0.100000 loss 2.1606 (2.1844) acc@1 0.2031 (0.1698) acc@5 0.6719 (0.6291)\n",
      "\u001b[32m[2020-06-28 18:16:54] __main__ INFO: \u001b[0mElapsed 491.63\n",
      "\u001b[32m[2020-06-28 18:16:54] __main__ INFO: \u001b[0mVal 18\n",
      "\u001b[32m[2020-06-28 18:17:12] __main__ INFO: \u001b[0mEpoch 18 loss 2.3128 acc@1 0.1574 acc@5 0.5986\n",
      "\u001b[32m[2020-06-28 18:17:12] __main__ INFO: \u001b[0mElapsed 17.36\n",
      "\u001b[32m[2020-06-28 18:17:12] __main__ INFO: \u001b[0mTrain 19 6318\n",
      "\u001b[32m[2020-06-28 18:19:32] __main__ INFO: \u001b[0mEpoch 19 Step 100/351 lr 0.100000 loss 2.2136 (2.1816) acc@1 0.1641 (0.1719) acc@5 0.5781 (0.6352)\n",
      "\u001b[32m[2020-06-28 18:21:52] __main__ INFO: \u001b[0mEpoch 19 Step 200/351 lr 0.100000 loss 2.1573 (2.1766) acc@1 0.2031 (0.1741) acc@5 0.7266 (0.6315)\n",
      "\u001b[32m[2020-06-28 18:24:12] __main__ INFO: \u001b[0mEpoch 19 Step 300/351 lr 0.100000 loss 2.1553 (2.1769) acc@1 0.1641 (0.1745) acc@5 0.7188 (0.6302)\n",
      "\u001b[32m[2020-06-28 18:25:23] __main__ INFO: \u001b[0mEpoch 19 Step 351/351 lr 0.100000 loss 2.2201 (2.1768) acc@1 0.1562 (0.1745) acc@5 0.6016 (0.6315)\n",
      "\u001b[32m[2020-06-28 18:25:23] __main__ INFO: \u001b[0mElapsed 491.29\n",
      "\u001b[32m[2020-06-28 18:25:23] __main__ INFO: \u001b[0mVal 19\n",
      "\u001b[32m[2020-06-28 18:25:40] __main__ INFO: \u001b[0mEpoch 19 loss 2.2291 acc@1 0.1630 acc@5 0.6106\n",
      "\u001b[32m[2020-06-28 18:25:40] __main__ INFO: \u001b[0mElapsed 17.34\n",
      "\u001b[32m[2020-06-28 18:25:40] __main__ INFO: \u001b[0mTrain 20 6669\n",
      "\u001b[32m[2020-06-28 18:28:00] __main__ INFO: \u001b[0mEpoch 20 Step 100/351 lr 0.100000 loss 2.2086 (2.1777) acc@1 0.1719 (0.1720) acc@5 0.5859 (0.6254)\n",
      "\u001b[32m[2020-06-28 18:30:21] __main__ INFO: \u001b[0mEpoch 20 Step 200/351 lr 0.100000 loss 2.2199 (2.1719) acc@1 0.1875 (0.1736) acc@5 0.6562 (0.6293)\n",
      "\u001b[32m[2020-06-28 18:32:40] __main__ INFO: \u001b[0mEpoch 20 Step 300/351 lr 0.100000 loss 2.2007 (2.1714) acc@1 0.1484 (0.1758) acc@5 0.5703 (0.6312)\n",
      "\u001b[32m[2020-06-28 18:33:52] __main__ INFO: \u001b[0mEpoch 20 Step 351/351 lr 0.100000 loss 2.1315 (2.1704) acc@1 0.2344 (0.1763) acc@5 0.6641 (0.6312)\n",
      "\u001b[32m[2020-06-28 18:33:52] __main__ INFO: \u001b[0mElapsed 491.54\n",
      "\u001b[32m[2020-06-28 18:33:52] __main__ INFO: \u001b[0mVal 20\n",
      "\u001b[32m[2020-06-28 18:34:09] __main__ INFO: \u001b[0mEpoch 20 loss 2.2342 acc@1 0.1638 acc@5 0.6158\n",
      "\u001b[32m[2020-06-28 18:34:09] __main__ INFO: \u001b[0mElapsed 17.36\n",
      "\u001b[32m[2020-06-28 18:34:09] __main__ INFO: \u001b[0mTrain 21 7020\n",
      "\u001b[32m[2020-06-28 18:36:29] __main__ INFO: \u001b[0mEpoch 21 Step 100/351 lr 0.100000 loss 2.2325 (2.1677) acc@1 0.1797 (0.1774) acc@5 0.6484 (0.6287)\n",
      "\u001b[32m[2020-06-28 18:38:49] __main__ INFO: \u001b[0mEpoch 21 Step 200/351 lr 0.100000 loss 2.2126 (2.1678) acc@1 0.1719 (0.1798) acc@5 0.6328 (0.6325)\n",
      "\u001b[32m[2020-06-28 18:41:09] __main__ INFO: \u001b[0mEpoch 21 Step 300/351 lr 0.100000 loss 2.2287 (2.1643) acc@1 0.1562 (0.1804) acc@5 0.6172 (0.6344)\n",
      "\u001b[32m[2020-06-28 18:42:21] __main__ INFO: \u001b[0mEpoch 21 Step 351/351 lr 0.100000 loss 2.2036 (2.1671) acc@1 0.1562 (0.1790) acc@5 0.7031 (0.6325)\n",
      "\u001b[32m[2020-06-28 18:42:21] __main__ INFO: \u001b[0mElapsed 491.25\n",
      "\u001b[32m[2020-06-28 18:42:21] __main__ INFO: \u001b[0mVal 21\n",
      "\u001b[32m[2020-06-28 18:42:38] __main__ INFO: \u001b[0mEpoch 21 loss 2.1871 acc@1 0.1532 acc@5 0.6210\n",
      "\u001b[32m[2020-06-28 18:42:38] __main__ INFO: \u001b[0mElapsed 17.36\n",
      "\u001b[32m[2020-06-28 18:42:38] __main__ INFO: \u001b[0mTrain 22 7371\n",
      "\u001b[32m[2020-06-28 18:44:58] __main__ INFO: \u001b[0mEpoch 22 Step 100/351 lr 0.100000 loss 2.2558 (2.1668) acc@1 0.1797 (0.1769) acc@5 0.6172 (0.6338)\n",
      "\u001b[32m[2020-06-28 18:47:18] __main__ INFO: \u001b[0mEpoch 22 Step 200/351 lr 0.100000 loss 2.0866 (2.1627) acc@1 0.1406 (0.1805) acc@5 0.6406 (0.6343)\n",
      "\u001b[32m[2020-06-28 18:49:38] __main__ INFO: \u001b[0mEpoch 22 Step 300/351 lr 0.100000 loss 2.1020 (2.1595) acc@1 0.2109 (0.1822) acc@5 0.7109 (0.6349)\n",
      "\u001b[32m[2020-06-28 18:50:49] __main__ INFO: \u001b[0mEpoch 22 Step 351/351 lr 0.100000 loss 2.1755 (2.1593) acc@1 0.1484 (0.1828) acc@5 0.5859 (0.6356)\n",
      "\u001b[32m[2020-06-28 18:50:49] __main__ INFO: \u001b[0mElapsed 490.98\n",
      "\u001b[32m[2020-06-28 18:50:49] __main__ INFO: \u001b[0mVal 22\n",
      "\u001b[32m[2020-06-28 18:51:06] __main__ INFO: \u001b[0mEpoch 22 loss 2.2196 acc@1 0.1504 acc@5 0.6158\n",
      "\u001b[32m[2020-06-28 18:51:06] __main__ INFO: \u001b[0mElapsed 17.32\n",
      "\u001b[32m[2020-06-28 18:51:06] __main__ INFO: \u001b[0mTrain 23 7722\n",
      "\u001b[32m[2020-06-28 18:53:26] __main__ INFO: \u001b[0mEpoch 23 Step 100/351 lr 0.100000 loss 2.1114 (2.1451) acc@1 0.1953 (0.1899) acc@5 0.6562 (0.6403)\n",
      "\u001b[32m[2020-06-28 18:55:46] __main__ INFO: \u001b[0mEpoch 23 Step 200/351 lr 0.100000 loss 2.1700 (2.1460) acc@1 0.1875 (0.1880) acc@5 0.6641 (0.6412)\n",
      "\u001b[32m[2020-06-28 18:58:05] __main__ INFO: \u001b[0mEpoch 23 Step 300/351 lr 0.100000 loss 2.1671 (2.1461) acc@1 0.1875 (0.1858) acc@5 0.5938 (0.6410)\n",
      "\u001b[32m[2020-06-28 18:59:17] __main__ INFO: \u001b[0mEpoch 23 Step 351/351 lr 0.100000 loss 2.1287 (2.1471) acc@1 0.1719 (0.1852) acc@5 0.6172 (0.6396)\n",
      "\u001b[32m[2020-06-28 18:59:17] __main__ INFO: \u001b[0mElapsed 490.49\n",
      "\u001b[32m[2020-06-28 18:59:17] __main__ INFO: \u001b[0mVal 23\n",
      "\u001b[32m[2020-06-28 18:59:34] __main__ INFO: \u001b[0mEpoch 23 loss 2.2471 acc@1 0.1654 acc@5 0.6192\n",
      "\u001b[32m[2020-06-28 18:59:34] __main__ INFO: \u001b[0mElapsed 17.34\n",
      "\u001b[32m[2020-06-28 18:59:34] __main__ INFO: \u001b[0mTrain 24 8073\n",
      "\u001b[32m[2020-06-28 19:01:54] __main__ INFO: \u001b[0mEpoch 24 Step 100/351 lr 0.100000 loss 2.1841 (2.1451) acc@1 0.1641 (0.1899) acc@5 0.6094 (0.6448)\n",
      "\u001b[32m[2020-06-28 19:04:14] __main__ INFO: \u001b[0mEpoch 24 Step 200/351 lr 0.100000 loss 2.2136 (2.1464) acc@1 0.1406 (0.1861) acc@5 0.5781 (0.6416)\n",
      "\u001b[32m[2020-06-28 19:06:33] __main__ INFO: \u001b[0mEpoch 24 Step 300/351 lr 0.100000 loss 2.1449 (2.1448) acc@1 0.1562 (0.1865) acc@5 0.6016 (0.6420)\n",
      "\u001b[32m[2020-06-28 19:07:44] __main__ INFO: \u001b[0mEpoch 24 Step 351/351 lr 0.100000 loss 2.1584 (2.1452) acc@1 0.1562 (0.1864) acc@5 0.5938 (0.6402)\n",
      "\u001b[32m[2020-06-28 19:07:44] __main__ INFO: \u001b[0mElapsed 490.46\n",
      "\u001b[32m[2020-06-28 19:07:44] __main__ INFO: \u001b[0mVal 24\n",
      "\u001b[32m[2020-06-28 19:08:02] __main__ INFO: \u001b[0mEpoch 24 loss 2.1930 acc@1 0.1744 acc@5 0.6168\n",
      "\u001b[32m[2020-06-28 19:08:02] __main__ INFO: \u001b[0mElapsed 17.33\n",
      "\u001b[32m[2020-06-28 19:08:02] __main__ INFO: \u001b[0mTrain 25 8424\n",
      "\u001b[32m[2020-06-28 19:10:22] __main__ INFO: \u001b[0mEpoch 25 Step 100/351 lr 0.100000 loss 2.1384 (2.1303) acc@1 0.1406 (0.1938) acc@5 0.6719 (0.6470)\n",
      "\u001b[32m[2020-06-28 19:12:41] __main__ INFO: \u001b[0mEpoch 25 Step 200/351 lr 0.100000 loss 2.1725 (2.1361) acc@1 0.2109 (0.1898) acc@5 0.6484 (0.6450)\n",
      "\u001b[32m[2020-06-28 19:15:01] __main__ INFO: \u001b[0mEpoch 25 Step 300/351 lr 0.100000 loss 2.1267 (2.1361) acc@1 0.1641 (0.1902) acc@5 0.6875 (0.6445)\n",
      "\u001b[32m[2020-06-28 19:16:12] __main__ INFO: \u001b[0mEpoch 25 Step 351/351 lr 0.100000 loss 2.1211 (2.1347) acc@1 0.1953 (0.1914) acc@5 0.6562 (0.6457)\n",
      "\u001b[32m[2020-06-28 19:16:12] __main__ INFO: \u001b[0mElapsed 490.10\n",
      "\u001b[32m[2020-06-28 19:16:12] __main__ INFO: \u001b[0mVal 25\n",
      "\u001b[32m[2020-06-28 19:16:29] __main__ INFO: \u001b[0mEpoch 25 loss 2.2125 acc@1 0.1554 acc@5 0.6120\n",
      "\u001b[32m[2020-06-28 19:16:29] __main__ INFO: \u001b[0mElapsed 17.32\n",
      "\u001b[32m[2020-06-28 19:16:29] __main__ INFO: \u001b[0mTrain 26 8775\n",
      "\u001b[32m[2020-06-28 19:18:49] __main__ INFO: \u001b[0mEpoch 26 Step 100/351 lr 0.100000 loss 2.1828 (2.1290) acc@1 0.1953 (0.1995) acc@5 0.6406 (0.6519)\n",
      "\u001b[32m[2020-06-28 19:21:08] __main__ INFO: \u001b[0mEpoch 26 Step 200/351 lr 0.100000 loss 2.0990 (2.1286) acc@1 0.1875 (0.1978) acc@5 0.5781 (0.6445)\n",
      "\u001b[32m[2020-06-28 19:23:28] __main__ INFO: \u001b[0mEpoch 26 Step 300/351 lr 0.100000 loss 2.1520 (2.1272) acc@1 0.2188 (0.1981) acc@5 0.6562 (0.6443)\n",
      "\u001b[32m[2020-06-28 19:24:39] __main__ INFO: \u001b[0mEpoch 26 Step 351/351 lr 0.100000 loss 2.2013 (2.1280) acc@1 0.1172 (0.1975) acc@5 0.6016 (0.6454)\n",
      "\u001b[32m[2020-06-28 19:24:39] __main__ INFO: \u001b[0mElapsed 489.85\n",
      "\u001b[32m[2020-06-28 19:24:39] __main__ INFO: \u001b[0mVal 26\n",
      "\u001b[32m[2020-06-28 19:24:56] __main__ INFO: \u001b[0mEpoch 26 loss 2.1999 acc@1 0.1694 acc@5 0.6232\n",
      "\u001b[32m[2020-06-28 19:24:56] __main__ INFO: \u001b[0mElapsed 17.33\n",
      "\u001b[32m[2020-06-28 19:24:56] __main__ INFO: \u001b[0mTrain 27 9126\n",
      "\u001b[32m[2020-06-28 19:27:16] __main__ INFO: \u001b[0mEpoch 27 Step 100/351 lr 0.100000 loss 2.1499 (2.1247) acc@1 0.1484 (0.1955) acc@5 0.6250 (0.6548)\n",
      "\u001b[32m[2020-06-28 19:29:35] __main__ INFO: \u001b[0mEpoch 27 Step 200/351 lr 0.100000 loss 2.1462 (2.1231) acc@1 0.1484 (0.1995) acc@5 0.6484 (0.6527)\n",
      "\u001b[32m[2020-06-28 19:31:55] __main__ INFO: \u001b[0mEpoch 27 Step 300/351 lr 0.100000 loss 2.1341 (2.1224) acc@1 0.2188 (0.2005) acc@5 0.6328 (0.6524)\n",
      "\u001b[32m[2020-06-28 19:33:06] __main__ INFO: \u001b[0mEpoch 27 Step 351/351 lr 0.100000 loss 2.1149 (2.1223) acc@1 0.1797 (0.2004) acc@5 0.6953 (0.6521)\n",
      "\u001b[32m[2020-06-28 19:33:06] __main__ INFO: \u001b[0mElapsed 489.67\n",
      "\u001b[32m[2020-06-28 19:33:06] __main__ INFO: \u001b[0mVal 27\n",
      "\u001b[32m[2020-06-28 19:33:23] __main__ INFO: \u001b[0mEpoch 27 loss 2.1310 acc@1 0.1906 acc@5 0.6478\n",
      "\u001b[32m[2020-06-28 19:33:23] __main__ INFO: \u001b[0mElapsed 17.33\n",
      "\u001b[32m[2020-06-28 19:33:23] __main__ INFO: \u001b[0mTrain 28 9477\n",
      "\u001b[32m[2020-06-28 19:35:43] __main__ INFO: \u001b[0mEpoch 28 Step 100/351 lr 0.100000 loss 2.0830 (2.1188) acc@1 0.2188 (0.1971) acc@5 0.7266 (0.6456)\n",
      "\u001b[32m[2020-06-28 19:38:03] __main__ INFO: \u001b[0mEpoch 28 Step 200/351 lr 0.100000 loss 2.1333 (2.1185) acc@1 0.1641 (0.2002) acc@5 0.6484 (0.6482)\n",
      "\u001b[32m[2020-06-28 19:40:22] __main__ INFO: \u001b[0mEpoch 28 Step 300/351 lr 0.100000 loss 2.1919 (2.1162) acc@1 0.1641 (0.1994) acc@5 0.6016 (0.6484)\n",
      "\u001b[32m[2020-06-28 19:41:33] __main__ INFO: \u001b[0mEpoch 28 Step 351/351 lr 0.100000 loss 2.1817 (2.1161) acc@1 0.1797 (0.1997) acc@5 0.6641 (0.6493)\n",
      "\u001b[32m[2020-06-28 19:41:33] __main__ INFO: \u001b[0mElapsed 489.78\n",
      "\u001b[32m[2020-06-28 19:41:33] __main__ INFO: \u001b[0mVal 28\n",
      "\u001b[32m[2020-06-28 19:41:51] __main__ INFO: \u001b[0mEpoch 28 loss 2.1841 acc@1 0.1702 acc@5 0.6286\n",
      "\u001b[32m[2020-06-28 19:41:51] __main__ INFO: \u001b[0mElapsed 17.33\n",
      "\u001b[32m[2020-06-28 19:41:51] __main__ INFO: \u001b[0mTrain 29 9828\n",
      "\u001b[32m[2020-06-28 19:44:10] __main__ INFO: \u001b[0mEpoch 29 Step 100/351 lr 0.100000 loss 2.0992 (2.1201) acc@1 0.1641 (0.2041) acc@5 0.6250 (0.6536)\n",
      "\u001b[32m[2020-06-28 19:46:29] __main__ INFO: \u001b[0mEpoch 29 Step 200/351 lr 0.100000 loss 2.0405 (2.1166) acc@1 0.2422 (0.2024) acc@5 0.6875 (0.6505)\n",
      "\u001b[32m[2020-06-28 19:48:49] __main__ INFO: \u001b[0mEpoch 29 Step 300/351 lr 0.100000 loss 2.1086 (2.1120) acc@1 0.1797 (0.2031) acc@5 0.6875 (0.6518)\n",
      "\u001b[32m[2020-06-28 19:50:00] __main__ INFO: \u001b[0mEpoch 29 Step 351/351 lr 0.100000 loss 2.0547 (2.1116) acc@1 0.2344 (0.2030) acc@5 0.7734 (0.6510)\n",
      "\u001b[32m[2020-06-28 19:50:00] __main__ INFO: \u001b[0mElapsed 489.41\n",
      "\u001b[32m[2020-06-28 19:50:00] __main__ INFO: \u001b[0mVal 29\n",
      "\u001b[32m[2020-06-28 19:50:17] __main__ INFO: \u001b[0mEpoch 29 loss 2.1860 acc@1 0.1952 acc@5 0.6400\n",
      "\u001b[32m[2020-06-28 19:50:17] __main__ INFO: \u001b[0mElapsed 17.33\n",
      "\u001b[32m[2020-06-28 19:50:17] __main__ INFO: \u001b[0mTrain 30 10179\n",
      "\u001b[32m[2020-06-28 19:52:37] __main__ INFO: \u001b[0mEpoch 30 Step 100/351 lr 0.100000 loss 2.1089 (2.0983) acc@1 0.1641 (0.2102) acc@5 0.6250 (0.6593)\n",
      "\u001b[32m[2020-06-28 19:54:56] __main__ INFO: \u001b[0mEpoch 30 Step 200/351 lr 0.100000 loss 2.1033 (2.1043) acc@1 0.2422 (0.2065) acc@5 0.7344 (0.6567)\n",
      "\u001b[32m[2020-06-28 19:57:15] __main__ INFO: \u001b[0mEpoch 30 Step 300/351 lr 0.100000 loss 2.0858 (2.1036) acc@1 0.2344 (0.2068) acc@5 0.6250 (0.6544)\n",
      "\u001b[32m[2020-06-28 19:58:26] __main__ INFO: \u001b[0mEpoch 30 Step 351/351 lr 0.100000 loss 2.2085 (2.1030) acc@1 0.1562 (0.2076) acc@5 0.6641 (0.6535)\n",
      "\u001b[32m[2020-06-28 19:58:26] __main__ INFO: \u001b[0mElapsed 489.08\n",
      "\u001b[32m[2020-06-28 19:58:26] __main__ INFO: \u001b[0mVal 30\n",
      "\u001b[32m[2020-06-28 19:58:44] __main__ INFO: \u001b[0mEpoch 30 loss 2.2681 acc@1 0.1730 acc@5 0.6220\n",
      "\u001b[32m[2020-06-28 19:58:44] __main__ INFO: \u001b[0mElapsed 17.30\n",
      "\u001b[32m[2020-06-28 19:58:44] __main__ INFO: \u001b[0mTrain 31 10530\n",
      "\u001b[32m[2020-06-28 20:01:03] __main__ INFO: \u001b[0mEpoch 31 Step 100/351 lr 0.100000 loss 2.1530 (2.0933) acc@1 0.2422 (0.2102) acc@5 0.5938 (0.6642)\n",
      "\u001b[32m[2020-06-28 20:03:22] __main__ INFO: \u001b[0mEpoch 31 Step 200/351 lr 0.100000 loss 2.0731 (2.0957) acc@1 0.2656 (0.2116) acc@5 0.6641 (0.6579)\n",
      "\u001b[32m[2020-06-28 20:05:42] __main__ INFO: \u001b[0mEpoch 31 Step 300/351 lr 0.100000 loss 2.0941 (2.0945) acc@1 0.1953 (0.2117) acc@5 0.6016 (0.6567)\n",
      "\u001b[32m[2020-06-28 20:06:53] __main__ INFO: \u001b[0mEpoch 31 Step 351/351 lr 0.100000 loss 2.1099 (2.0930) acc@1 0.1953 (0.2117) acc@5 0.6016 (0.6561)\n",
      "\u001b[32m[2020-06-28 20:06:53] __main__ INFO: \u001b[0mElapsed 488.89\n",
      "\u001b[32m[2020-06-28 20:06:53] __main__ INFO: \u001b[0mVal 31\n",
      "\u001b[32m[2020-06-28 20:07:10] __main__ INFO: \u001b[0mEpoch 31 loss 2.1957 acc@1 0.1818 acc@5 0.6474\n",
      "\u001b[32m[2020-06-28 20:07:10] __main__ INFO: \u001b[0mElapsed 17.32\n",
      "\u001b[32m[2020-06-28 20:07:10] __main__ INFO: \u001b[0mTrain 32 10881\n",
      "\u001b[32m[2020-06-28 20:09:29] __main__ INFO: \u001b[0mEpoch 32 Step 100/351 lr 0.100000 loss 1.9986 (2.0773) acc@1 0.2578 (0.2185) acc@5 0.6875 (0.6629)\n",
      "\u001b[32m[2020-06-28 20:11:48] __main__ INFO: \u001b[0mEpoch 32 Step 200/351 lr 0.100000 loss 2.1047 (2.0815) acc@1 0.2188 (0.2148) acc@5 0.7422 (0.6650)\n",
      "\u001b[32m[2020-06-28 20:14:07] __main__ INFO: \u001b[0mEpoch 32 Step 300/351 lr 0.100000 loss 1.9766 (2.0867) acc@1 0.2812 (0.2124) acc@5 0.6797 (0.6614)\n",
      "\u001b[32m[2020-06-28 20:15:18] __main__ INFO: \u001b[0mEpoch 32 Step 351/351 lr 0.100000 loss 2.1839 (2.0864) acc@1 0.1953 (0.2130) acc@5 0.6250 (0.6612)\n",
      "\u001b[32m[2020-06-28 20:15:18] __main__ INFO: \u001b[0mElapsed 488.60\n",
      "\u001b[32m[2020-06-28 20:15:18] __main__ INFO: \u001b[0mVal 32\n",
      "\u001b[32m[2020-06-28 20:15:36] __main__ INFO: \u001b[0mEpoch 32 loss 2.1316 acc@1 0.2008 acc@5 0.6426\n",
      "\u001b[32m[2020-06-28 20:15:36] __main__ INFO: \u001b[0mElapsed 17.31\n",
      "\u001b[32m[2020-06-28 20:15:36] __main__ INFO: \u001b[0mTrain 33 11232\n",
      "\u001b[32m[2020-06-28 20:17:55] __main__ INFO: \u001b[0mEpoch 33 Step 100/351 lr 0.100000 loss 2.1041 (2.0818) acc@1 0.2266 (0.2200) acc@5 0.6562 (0.6617)\n",
      "\u001b[32m[2020-06-28 20:20:14] __main__ INFO: \u001b[0mEpoch 33 Step 200/351 lr 0.100000 loss 2.0117 (2.0801) acc@1 0.2500 (0.2171) acc@5 0.7344 (0.6572)\n",
      "\u001b[32m[2020-06-28 20:22:33] __main__ INFO: \u001b[0mEpoch 33 Step 300/351 lr 0.100000 loss 2.0371 (2.0831) acc@1 0.2109 (0.2156) acc@5 0.7109 (0.6580)\n",
      "\u001b[32m[2020-06-28 20:23:44] __main__ INFO: \u001b[0mEpoch 33 Step 351/351 lr 0.100000 loss 2.0568 (2.0815) acc@1 0.2031 (0.2165) acc@5 0.6562 (0.6575)\n",
      "\u001b[32m[2020-06-28 20:23:44] __main__ INFO: \u001b[0mElapsed 488.55\n",
      "\u001b[32m[2020-06-28 20:23:44] __main__ INFO: \u001b[0mVal 33\n",
      "\u001b[32m[2020-06-28 20:24:02] __main__ INFO: \u001b[0mEpoch 33 loss 2.0968 acc@1 0.2050 acc@5 0.6556\n",
      "\u001b[32m[2020-06-28 20:24:02] __main__ INFO: \u001b[0mElapsed 17.35\n",
      "\u001b[32m[2020-06-28 20:24:02] __main__ INFO: \u001b[0mTrain 34 11583\n",
      "\u001b[32m[2020-06-28 20:26:21] __main__ INFO: \u001b[0mEpoch 34 Step 100/351 lr 0.100000 loss 1.9469 (2.0734) acc@1 0.2969 (0.2145) acc@5 0.7188 (0.6650)\n",
      "\u001b[32m[2020-06-28 20:28:40] __main__ INFO: \u001b[0mEpoch 34 Step 200/351 lr 0.100000 loss 2.0735 (2.0771) acc@1 0.1797 (0.2150) acc@5 0.7031 (0.6645)\n",
      "\u001b[32m[2020-06-28 20:30:59] __main__ INFO: \u001b[0mEpoch 34 Step 300/351 lr 0.100000 loss 2.0772 (2.0753) acc@1 0.2266 (0.2155) acc@5 0.7031 (0.6634)\n",
      "\u001b[32m[2020-06-28 20:32:10] __main__ INFO: \u001b[0mEpoch 34 Step 351/351 lr 0.100000 loss 2.1404 (2.0770) acc@1 0.1250 (0.2156) acc@5 0.6172 (0.6629)\n",
      "\u001b[32m[2020-06-28 20:32:10] __main__ INFO: \u001b[0mElapsed 488.31\n",
      "\u001b[32m[2020-06-28 20:32:10] __main__ INFO: \u001b[0mVal 34\n",
      "\u001b[32m[2020-06-28 20:32:27] __main__ INFO: \u001b[0mEpoch 34 loss 2.1255 acc@1 0.1898 acc@5 0.6488\n",
      "\u001b[32m[2020-06-28 20:32:27] __main__ INFO: \u001b[0mElapsed 17.30\n",
      "\u001b[32m[2020-06-28 20:32:27] __main__ INFO: \u001b[0mTrain 35 11934\n",
      "\u001b[32m[2020-06-28 20:34:47] __main__ INFO: \u001b[0mEpoch 35 Step 100/351 lr 0.100000 loss 1.9574 (2.0685) acc@1 0.2578 (0.2224) acc@5 0.6797 (0.6673)\n",
      "\u001b[32m[2020-06-28 20:37:06] __main__ INFO: \u001b[0mEpoch 35 Step 200/351 lr 0.100000 loss 2.1223 (2.0692) acc@1 0.1797 (0.2205) acc@5 0.6953 (0.6645)\n",
      "\u001b[32m[2020-06-28 20:39:25] __main__ INFO: \u001b[0mEpoch 35 Step 300/351 lr 0.100000 loss 2.0428 (2.0720) acc@1 0.2422 (0.2193) acc@5 0.6797 (0.6645)\n",
      "\u001b[32m[2020-06-28 20:40:36] __main__ INFO: \u001b[0mEpoch 35 Step 351/351 lr 0.100000 loss 2.1008 (2.0725) acc@1 0.2031 (0.2191) acc@5 0.6797 (0.6639)\n",
      "\u001b[32m[2020-06-28 20:40:36] __main__ INFO: \u001b[0mElapsed 488.23\n",
      "\u001b[32m[2020-06-28 20:40:36] __main__ INFO: \u001b[0mVal 35\n",
      "\u001b[32m[2020-06-28 20:40:53] __main__ INFO: \u001b[0mEpoch 35 loss 2.1206 acc@1 0.2138 acc@5 0.6580\n",
      "\u001b[32m[2020-06-28 20:40:53] __main__ INFO: \u001b[0mElapsed 17.31\n",
      "\u001b[32m[2020-06-28 20:40:53] __main__ INFO: \u001b[0mTrain 36 12285\n",
      "\u001b[32m[2020-06-28 20:43:12] __main__ INFO: \u001b[0mEpoch 36 Step 100/351 lr 0.100000 loss 2.0534 (2.0598) acc@1 0.2031 (0.2218) acc@5 0.6641 (0.6618)\n",
      "\u001b[32m[2020-06-28 20:45:31] __main__ INFO: \u001b[0mEpoch 36 Step 200/351 lr 0.100000 loss 2.1112 (2.0646) acc@1 0.2344 (0.2223) acc@5 0.6797 (0.6653)\n",
      "\u001b[32m[2020-06-28 20:47:50] __main__ INFO: \u001b[0mEpoch 36 Step 300/351 lr 0.100000 loss 2.0650 (2.0660) acc@1 0.2266 (0.2213) acc@5 0.6641 (0.6645)\n",
      "\u001b[32m[2020-06-28 20:49:01] __main__ INFO: \u001b[0mEpoch 36 Step 351/351 lr 0.100000 loss 2.0290 (2.0671) acc@1 0.2500 (0.2217) acc@5 0.6328 (0.6635)\n",
      "\u001b[32m[2020-06-28 20:49:01] __main__ INFO: \u001b[0mElapsed 488.03\n",
      "\u001b[32m[2020-06-28 20:49:01] __main__ INFO: \u001b[0mVal 36\n",
      "\u001b[32m[2020-06-28 20:49:18] __main__ INFO: \u001b[0mEpoch 36 loss 2.2079 acc@1 0.1820 acc@5 0.6144\n",
      "\u001b[32m[2020-06-28 20:49:18] __main__ INFO: \u001b[0mElapsed 17.31\n",
      "\u001b[32m[2020-06-28 20:49:18] __main__ INFO: \u001b[0mTrain 37 12636\n",
      "\u001b[32m[2020-06-28 20:51:37] __main__ INFO: \u001b[0mEpoch 37 Step 100/351 lr 0.100000 loss 2.0792 (2.0601) acc@1 0.2031 (0.2223) acc@5 0.6406 (0.6653)\n",
      "\u001b[32m[2020-06-28 20:53:56] __main__ INFO: \u001b[0mEpoch 37 Step 200/351 lr 0.100000 loss 2.0758 (2.0620) acc@1 0.1953 (0.2235) acc@5 0.6797 (0.6632)\n",
      "\u001b[32m[2020-06-28 20:56:15] __main__ INFO: \u001b[0mEpoch 37 Step 300/351 lr 0.100000 loss 2.0347 (2.0608) acc@1 0.1641 (0.2234) acc@5 0.7578 (0.6663)\n",
      "\u001b[32m[2020-06-28 20:57:26] __main__ INFO: \u001b[0mEpoch 37 Step 351/351 lr 0.100000 loss 1.9769 (2.0609) acc@1 0.2344 (0.2222) acc@5 0.6250 (0.6654)\n",
      "\u001b[32m[2020-06-28 20:57:26] __main__ INFO: \u001b[0mElapsed 488.01\n",
      "\u001b[32m[2020-06-28 20:57:26] __main__ INFO: \u001b[0mVal 37\n",
      "\u001b[32m[2020-06-28 20:57:44] __main__ INFO: \u001b[0mEpoch 37 loss 2.1034 acc@1 0.2024 acc@5 0.6496\n",
      "\u001b[32m[2020-06-28 20:57:44] __main__ INFO: \u001b[0mElapsed 17.30\n",
      "\u001b[32m[2020-06-28 20:57:44] __main__ INFO: \u001b[0mTrain 38 12987\n",
      "\u001b[32m[2020-06-28 21:00:03] __main__ INFO: \u001b[0mEpoch 38 Step 100/351 lr 0.100000 loss 2.0424 (2.0528) acc@1 0.2031 (0.2291) acc@5 0.6406 (0.6685)\n",
      "\u001b[32m[2020-06-28 21:02:22] __main__ INFO: \u001b[0mEpoch 38 Step 200/351 lr 0.100000 loss 2.0670 (2.0533) acc@1 0.2578 (0.2266) acc@5 0.6562 (0.6702)\n",
      "\u001b[32m[2020-06-28 21:04:41] __main__ INFO: \u001b[0mEpoch 38 Step 300/351 lr 0.100000 loss 2.1206 (2.0588) acc@1 0.2266 (0.2243) acc@5 0.6953 (0.6678)\n",
      "\u001b[32m[2020-06-28 21:05:51] __main__ INFO: \u001b[0mEpoch 38 Step 351/351 lr 0.100000 loss 2.0760 (2.0561) acc@1 0.2500 (0.2250) acc@5 0.6797 (0.6689)\n",
      "\u001b[32m[2020-06-28 21:05:51] __main__ INFO: \u001b[0mElapsed 487.87\n",
      "\u001b[32m[2020-06-28 21:05:51] __main__ INFO: \u001b[0mVal 38\n",
      "\u001b[32m[2020-06-28 21:06:09] __main__ INFO: \u001b[0mEpoch 38 loss 2.2618 acc@1 0.1686 acc@5 0.6070\n",
      "\u001b[32m[2020-06-28 21:06:09] __main__ INFO: \u001b[0mElapsed 17.29\n",
      "\u001b[32m[2020-06-28 21:06:09] __main__ INFO: \u001b[0mTrain 39 13338\n",
      "\u001b[32m[2020-06-28 21:08:28] __main__ INFO: \u001b[0mEpoch 39 Step 100/351 lr 0.100000 loss 2.1542 (2.0641) acc@1 0.1641 (0.2248) acc@5 0.5781 (0.6650)\n",
      "\u001b[32m[2020-06-28 21:10:47] __main__ INFO: \u001b[0mEpoch 39 Step 200/351 lr 0.100000 loss 2.1045 (2.0560) acc@1 0.1953 (0.2254) acc@5 0.6016 (0.6661)\n",
      "\u001b[32m[2020-06-28 21:13:06] __main__ INFO: \u001b[0mEpoch 39 Step 300/351 lr 0.100000 loss 2.0519 (2.0551) acc@1 0.2812 (0.2248) acc@5 0.6328 (0.6670)\n",
      "\u001b[32m[2020-06-28 21:14:16] __main__ INFO: \u001b[0mEpoch 39 Step 351/351 lr 0.100000 loss 2.0640 (2.0539) acc@1 0.2422 (0.2258) acc@5 0.6250 (0.6684)\n",
      "\u001b[32m[2020-06-28 21:14:16] __main__ INFO: \u001b[0mElapsed 487.71\n",
      "\u001b[32m[2020-06-28 21:14:16] __main__ INFO: \u001b[0mVal 39\n",
      "\u001b[32m[2020-06-28 21:14:34] __main__ INFO: \u001b[0mEpoch 39 loss 2.0918 acc@1 0.2226 acc@5 0.6596\n",
      "\u001b[32m[2020-06-28 21:14:34] __main__ INFO: \u001b[0mElapsed 17.31\n",
      "\u001b[32m[2020-06-28 21:14:34] __main__ INFO: \u001b[0mTrain 40 13689\n",
      "\u001b[32m[2020-06-28 21:16:53] __main__ INFO: \u001b[0mEpoch 40 Step 100/351 lr 0.100000 loss 2.1636 (2.0432) acc@1 0.1719 (0.2245) acc@5 0.6406 (0.6700)\n",
      "\u001b[32m[2020-06-28 21:19:12] __main__ INFO: \u001b[0mEpoch 40 Step 200/351 lr 0.100000 loss 2.1537 (2.0512) acc@1 0.2188 (0.2248) acc@5 0.6172 (0.6681)\n",
      "\u001b[32m[2020-06-28 21:21:31] __main__ INFO: \u001b[0mEpoch 40 Step 300/351 lr 0.100000 loss 2.1204 (2.0515) acc@1 0.1953 (0.2264) acc@5 0.6953 (0.6668)\n",
      "\u001b[32m[2020-06-28 21:22:42] __main__ INFO: \u001b[0mEpoch 40 Step 351/351 lr 0.100000 loss 2.1296 (2.0504) acc@1 0.2266 (0.2276) acc@5 0.5781 (0.6678)\n",
      "\u001b[32m[2020-06-28 21:22:42] __main__ INFO: \u001b[0mElapsed 487.88\n",
      "\u001b[32m[2020-06-28 21:22:42] __main__ INFO: \u001b[0mVal 40\n",
      "\u001b[32m[2020-06-28 21:22:59] __main__ INFO: \u001b[0mEpoch 40 loss 2.4114 acc@1 0.1640 acc@5 0.6104\n",
      "\u001b[32m[2020-06-28 21:22:59] __main__ INFO: \u001b[0mElapsed 17.30\n",
      "\u001b[32m[2020-06-28 21:22:59] __main__ INFO: \u001b[0mTrain 41 14040\n",
      "\u001b[32m[2020-06-28 21:25:18] __main__ INFO: \u001b[0mEpoch 41 Step 100/351 lr 0.100000 loss 2.0132 (2.0394) acc@1 0.2500 (0.2288) acc@5 0.6484 (0.6702)\n",
      "\u001b[32m[2020-06-28 21:27:37] __main__ INFO: \u001b[0mEpoch 41 Step 200/351 lr 0.100000 loss 2.1195 (2.0428) acc@1 0.2188 (0.2301) acc@5 0.6797 (0.6717)\n",
      "\u001b[32m[2020-06-28 21:29:56] __main__ INFO: \u001b[0mEpoch 41 Step 300/351 lr 0.100000 loss 2.0345 (2.0435) acc@1 0.2266 (0.2290) acc@5 0.6797 (0.6707)\n",
      "\u001b[32m[2020-06-28 21:31:07] __main__ INFO: \u001b[0mEpoch 41 Step 351/351 lr 0.100000 loss 2.0515 (2.0456) acc@1 0.2422 (0.2282) acc@5 0.6719 (0.6699)\n",
      "\u001b[32m[2020-06-28 21:31:07] __main__ INFO: \u001b[0mElapsed 487.70\n",
      "\u001b[32m[2020-06-28 21:31:07] __main__ INFO: \u001b[0mVal 41\n",
      "\u001b[32m[2020-06-28 21:31:24] __main__ INFO: \u001b[0mEpoch 41 loss 2.1203 acc@1 0.2032 acc@5 0.6448\n",
      "\u001b[32m[2020-06-28 21:31:24] __main__ INFO: \u001b[0mElapsed 17.32\n",
      "\u001b[32m[2020-06-28 21:31:24] __main__ INFO: \u001b[0mTrain 42 14391\n",
      "\u001b[32m[2020-06-28 21:33:43] __main__ INFO: \u001b[0mEpoch 42 Step 100/351 lr 0.100000 loss 2.0001 (2.0315) acc@1 0.2422 (0.2359) acc@5 0.7266 (0.6749)\n",
      "\u001b[32m[2020-06-28 21:36:02] __main__ INFO: \u001b[0mEpoch 42 Step 200/351 lr 0.100000 loss 2.0990 (2.0340) acc@1 0.2109 (0.2362) acc@5 0.6953 (0.6754)\n",
      "\u001b[32m[2020-06-28 21:38:21] __main__ INFO: \u001b[0mEpoch 42 Step 300/351 lr 0.100000 loss 2.0800 (2.0363) acc@1 0.2031 (0.2339) acc@5 0.5938 (0.6718)\n",
      "\u001b[32m[2020-06-28 21:39:32] __main__ INFO: \u001b[0mEpoch 42 Step 351/351 lr 0.100000 loss 2.0360 (2.0389) acc@1 0.2266 (0.2330) acc@5 0.6328 (0.6703)\n",
      "\u001b[32m[2020-06-28 21:39:32] __main__ INFO: \u001b[0mElapsed 487.62\n",
      "\u001b[32m[2020-06-28 21:39:32] __main__ INFO: \u001b[0mVal 42\n",
      "\u001b[32m[2020-06-28 21:39:49] __main__ INFO: \u001b[0mEpoch 42 loss 2.1620 acc@1 0.2056 acc@5 0.6418\n",
      "\u001b[32m[2020-06-28 21:39:49] __main__ INFO: \u001b[0mElapsed 17.29\n",
      "\u001b[32m[2020-06-28 21:39:49] __main__ INFO: \u001b[0mTrain 43 14742\n",
      "\u001b[32m[2020-06-28 21:42:08] __main__ INFO: \u001b[0mEpoch 43 Step 100/351 lr 0.100000 loss 2.0015 (2.0347) acc@1 0.2500 (0.2322) acc@5 0.6641 (0.6750)\n",
      "\u001b[32m[2020-06-28 21:44:27] __main__ INFO: \u001b[0mEpoch 43 Step 200/351 lr 0.100000 loss 2.0006 (2.0348) acc@1 0.2344 (0.2315) acc@5 0.6562 (0.6704)\n",
      "\u001b[32m[2020-06-28 21:46:46] __main__ INFO: \u001b[0mEpoch 43 Step 300/351 lr 0.100000 loss 2.0347 (2.0342) acc@1 0.2422 (0.2341) acc@5 0.7031 (0.6695)\n",
      "\u001b[32m[2020-06-28 21:47:56] __main__ INFO: \u001b[0mEpoch 43 Step 351/351 lr 0.100000 loss 2.0248 (2.0361) acc@1 0.2188 (0.2340) acc@5 0.6875 (0.6691)\n",
      "\u001b[32m[2020-06-28 21:47:56] __main__ INFO: \u001b[0mElapsed 487.57\n",
      "\u001b[32m[2020-06-28 21:47:56] __main__ INFO: \u001b[0mVal 43\n",
      "\u001b[32m[2020-06-28 21:48:14] __main__ INFO: \u001b[0mEpoch 43 loss 2.1554 acc@1 0.2098 acc@5 0.6404\n",
      "\u001b[32m[2020-06-28 21:48:14] __main__ INFO: \u001b[0mElapsed 17.29\n",
      "\u001b[32m[2020-06-28 21:48:14] __main__ INFO: \u001b[0mTrain 44 15093\n",
      "\u001b[32m[2020-06-28 21:50:33] __main__ INFO: \u001b[0mEpoch 44 Step 100/351 lr 0.100000 loss 2.0416 (2.0300) acc@1 0.2578 (0.2409) acc@5 0.7656 (0.6709)\n",
      "\u001b[32m[2020-06-28 21:52:51] __main__ INFO: \u001b[0mEpoch 44 Step 200/351 lr 0.100000 loss 2.0288 (2.0317) acc@1 0.2109 (0.2384) acc@5 0.7188 (0.6726)\n",
      "\u001b[32m[2020-06-28 21:55:10] __main__ INFO: \u001b[0mEpoch 44 Step 300/351 lr 0.100000 loss 2.1583 (2.0334) acc@1 0.2109 (0.2364) acc@5 0.6094 (0.6707)\n",
      "\u001b[32m[2020-06-28 21:56:21] __main__ INFO: \u001b[0mEpoch 44 Step 351/351 lr 0.100000 loss 1.9497 (2.0338) acc@1 0.2344 (0.2358) acc@5 0.6875 (0.6703)\n",
      "\u001b[32m[2020-06-28 21:56:21] __main__ INFO: \u001b[0mElapsed 487.56\n",
      "\u001b[32m[2020-06-28 21:56:21] __main__ INFO: \u001b[0mVal 44\n",
      "\u001b[32m[2020-06-28 21:56:39] __main__ INFO: \u001b[0mEpoch 44 loss 2.1243 acc@1 0.2164 acc@5 0.6506\n",
      "\u001b[32m[2020-06-28 21:56:39] __main__ INFO: \u001b[0mElapsed 17.30\n",
      "\u001b[32m[2020-06-28 21:56:39] __main__ INFO: \u001b[0mTrain 45 15444\n",
      "\u001b[32m[2020-06-28 21:58:58] __main__ INFO: \u001b[0mEpoch 45 Step 100/351 lr 0.100000 loss 2.1285 (2.0138) acc@1 0.1875 (0.2433) acc@5 0.6406 (0.6795)\n",
      "\u001b[32m[2020-06-28 22:01:16] __main__ INFO: \u001b[0mEpoch 45 Step 200/351 lr 0.100000 loss 2.0742 (2.0235) acc@1 0.2188 (0.2407) acc@5 0.6953 (0.6746)\n",
      "\u001b[32m[2020-06-28 22:03:35] __main__ INFO: \u001b[0mEpoch 45 Step 300/351 lr 0.100000 loss 1.9487 (2.0282) acc@1 0.2812 (0.2375) acc@5 0.7344 (0.6731)\n",
      "\u001b[32m[2020-06-28 22:04:46] __main__ INFO: \u001b[0mEpoch 45 Step 351/351 lr 0.100000 loss 2.0269 (2.0283) acc@1 0.2266 (0.2365) acc@5 0.6875 (0.6723)\n",
      "\u001b[32m[2020-06-28 22:04:46] __main__ INFO: \u001b[0mElapsed 487.45\n",
      "\u001b[32m[2020-06-28 22:04:46] __main__ INFO: \u001b[0mVal 45\n",
      "\u001b[32m[2020-06-28 22:05:03] __main__ INFO: \u001b[0mEpoch 45 loss 2.1073 acc@1 0.2106 acc@5 0.6530\n",
      "\u001b[32m[2020-06-28 22:05:03] __main__ INFO: \u001b[0mElapsed 17.29\n",
      "\u001b[32m[2020-06-28 22:05:03] __main__ INFO: \u001b[0mTrain 46 15795\n",
      "\u001b[32m[2020-06-28 22:07:22] __main__ INFO: \u001b[0mEpoch 46 Step 100/351 lr 0.100000 loss 2.0262 (2.0204) acc@1 0.2422 (0.2370) acc@5 0.6406 (0.6750)\n",
      "\u001b[32m[2020-06-28 22:09:41] __main__ INFO: \u001b[0mEpoch 46 Step 200/351 lr 0.100000 loss 1.9321 (2.0296) acc@1 0.2656 (0.2350) acc@5 0.6562 (0.6714)\n",
      "\u001b[32m[2020-06-28 22:12:00] __main__ INFO: \u001b[0mEpoch 46 Step 300/351 lr 0.100000 loss 2.0358 (2.0287) acc@1 0.2188 (0.2367) acc@5 0.6797 (0.6701)\n",
      "\u001b[32m[2020-06-28 22:13:11] __main__ INFO: \u001b[0mEpoch 46 Step 351/351 lr 0.100000 loss 2.0254 (2.0274) acc@1 0.2109 (0.2374) acc@5 0.6875 (0.6708)\n",
      "\u001b[32m[2020-06-28 22:13:11] __main__ INFO: \u001b[0mElapsed 487.42\n",
      "\u001b[32m[2020-06-28 22:13:11] __main__ INFO: \u001b[0mVal 46\n",
      "\u001b[32m[2020-06-28 22:13:28] __main__ INFO: \u001b[0mEpoch 46 loss 2.0976 acc@1 0.1980 acc@5 0.6488\n",
      "\u001b[32m[2020-06-28 22:13:28] __main__ INFO: \u001b[0mElapsed 17.29\n",
      "\u001b[32m[2020-06-28 22:13:28] __main__ INFO: \u001b[0mTrain 47 16146\n",
      "\u001b[32m[2020-06-28 22:15:47] __main__ INFO: \u001b[0mEpoch 47 Step 100/351 lr 0.100000 loss 2.0061 (2.0185) acc@1 0.2344 (0.2422) acc@5 0.7734 (0.6793)\n",
      "\u001b[32m[2020-06-28 22:18:06] __main__ INFO: \u001b[0mEpoch 47 Step 200/351 lr 0.100000 loss 2.0294 (2.0231) acc@1 0.2500 (0.2402) acc@5 0.6953 (0.6778)\n",
      "\u001b[32m[2020-06-28 22:20:25] __main__ INFO: \u001b[0mEpoch 47 Step 300/351 lr 0.100000 loss 2.0625 (2.0261) acc@1 0.1953 (0.2386) acc@5 0.6719 (0.6745)\n",
      "\u001b[32m[2020-06-28 22:21:36] __main__ INFO: \u001b[0mEpoch 47 Step 351/351 lr 0.100000 loss 1.9782 (2.0253) acc@1 0.2188 (0.2385) acc@5 0.7891 (0.6741)\n",
      "\u001b[32m[2020-06-28 22:21:36] __main__ INFO: \u001b[0mElapsed 487.72\n",
      "\u001b[32m[2020-06-28 22:21:36] __main__ INFO: \u001b[0mVal 47\n",
      "\u001b[32m[2020-06-28 22:21:53] __main__ INFO: \u001b[0mEpoch 47 loss 2.3104 acc@1 0.1788 acc@5 0.6140\n",
      "\u001b[32m[2020-06-28 22:21:53] __main__ INFO: \u001b[0mElapsed 17.33\n",
      "\u001b[32m[2020-06-28 22:21:53] __main__ INFO: \u001b[0mTrain 48 16497\n",
      "\u001b[32m[2020-06-28 22:24:12] __main__ INFO: \u001b[0mEpoch 48 Step 100/351 lr 0.100000 loss 2.0489 (2.0180) acc@1 0.2422 (0.2440) acc@5 0.6484 (0.6792)\n",
      "\u001b[32m[2020-06-28 22:26:31] __main__ INFO: \u001b[0mEpoch 48 Step 200/351 lr 0.100000 loss 2.0405 (2.0184) acc@1 0.2422 (0.2427) acc@5 0.7266 (0.6794)\n",
      "\u001b[32m[2020-06-28 22:28:50] __main__ INFO: \u001b[0mEpoch 48 Step 300/351 lr 0.100000 loss 1.9062 (2.0179) acc@1 0.3359 (0.2415) acc@5 0.7266 (0.6781)\n",
      "\u001b[32m[2020-06-28 22:30:01] __main__ INFO: \u001b[0mEpoch 48 Step 351/351 lr 0.100000 loss 1.9508 (2.0187) acc@1 0.3047 (0.2407) acc@5 0.6484 (0.6765)\n",
      "\u001b[32m[2020-06-28 22:30:01] __main__ INFO: \u001b[0mElapsed 487.57\n",
      "\u001b[32m[2020-06-28 22:30:01] __main__ INFO: \u001b[0mVal 48\n",
      "\u001b[32m[2020-06-28 22:30:18] __main__ INFO: \u001b[0mEpoch 48 loss 2.1280 acc@1 0.2104 acc@5 0.6604\n",
      "\u001b[32m[2020-06-28 22:30:18] __main__ INFO: \u001b[0mElapsed 17.31\n",
      "\u001b[32m[2020-06-28 22:30:18] __main__ INFO: \u001b[0mTrain 49 16848\n",
      "\u001b[32m[2020-06-28 22:32:37] __main__ INFO: \u001b[0mEpoch 49 Step 100/351 lr 0.100000 loss 1.9785 (2.0106) acc@1 0.2891 (0.2443) acc@5 0.6797 (0.6730)\n",
      "\u001b[32m[2020-06-28 22:34:56] __main__ INFO: \u001b[0mEpoch 49 Step 200/351 lr 0.100000 loss 2.1231 (2.0101) acc@1 0.1641 (0.2421) acc@5 0.6484 (0.6759)\n",
      "\u001b[32m[2020-06-28 22:37:15] __main__ INFO: \u001b[0mEpoch 49 Step 300/351 lr 0.100000 loss 2.1290 (2.0160) acc@1 0.2344 (0.2417) acc@5 0.6328 (0.6757)\n",
      "\u001b[32m[2020-06-28 22:38:25] __main__ INFO: \u001b[0mEpoch 49 Step 351/351 lr 0.100000 loss 1.9694 (2.0183) acc@1 0.2109 (0.2404) acc@5 0.6016 (0.6741)\n",
      "\u001b[32m[2020-06-28 22:38:25] __main__ INFO: \u001b[0mElapsed 487.42\n",
      "\u001b[32m[2020-06-28 22:38:25] __main__ INFO: \u001b[0mVal 49\n",
      "\u001b[32m[2020-06-28 22:38:43] __main__ INFO: \u001b[0mEpoch 49 loss 2.1700 acc@1 0.2088 acc@5 0.6378\n",
      "\u001b[32m[2020-06-28 22:38:43] __main__ INFO: \u001b[0mElapsed 17.30\n",
      "\u001b[32m[2020-06-28 22:38:43] __main__ INFO: \u001b[0mTrain 50 17199\n",
      "\u001b[32m[2020-06-28 22:41:02] __main__ INFO: \u001b[0mEpoch 50 Step 100/351 lr 0.100000 loss 2.0026 (2.0163) acc@1 0.2812 (0.2444) acc@5 0.7031 (0.6716)\n",
      "\u001b[32m[2020-06-28 22:43:21] __main__ INFO: \u001b[0mEpoch 50 Step 200/351 lr 0.100000 loss 2.0331 (2.0201) acc@1 0.2344 (0.2424) acc@5 0.6953 (0.6732)\n",
      "\u001b[32m[2020-06-28 22:45:39] __main__ INFO: \u001b[0mEpoch 50 Step 300/351 lr 0.100000 loss 2.0509 (2.0191) acc@1 0.2422 (0.2413) acc@5 0.6562 (0.6723)\n",
      "\u001b[32m[2020-06-28 22:46:50] __main__ INFO: \u001b[0mEpoch 50 Step 351/351 lr 0.100000 loss 2.1058 (2.0184) acc@1 0.2500 (0.2421) acc@5 0.6250 (0.6735)\n",
      "\u001b[32m[2020-06-28 22:46:50] __main__ INFO: \u001b[0mElapsed 487.59\n",
      "\u001b[32m[2020-06-28 22:46:50] __main__ INFO: \u001b[0mVal 50\n",
      "\u001b[32m[2020-06-28 22:47:08] __main__ INFO: \u001b[0mEpoch 50 loss 2.1747 acc@1 0.2128 acc@5 0.6534\n",
      "\u001b[32m[2020-06-28 22:47:08] __main__ INFO: \u001b[0mElapsed 17.30\n",
      "\u001b[32m[2020-06-28 22:47:08] __main__ INFO: \u001b[0mTrain 51 17550\n",
      "\u001b[32m[2020-06-28 22:49:27] __main__ INFO: \u001b[0mEpoch 51 Step 100/351 lr 0.100000 loss 1.9797 (2.0104) acc@1 0.2578 (0.2428) acc@5 0.6484 (0.6744)\n",
      "\u001b[32m[2020-06-28 22:51:45] __main__ INFO: \u001b[0mEpoch 51 Step 200/351 lr 0.100000 loss 2.1091 (2.0116) acc@1 0.2188 (0.2421) acc@5 0.6641 (0.6741)\n",
      "\u001b[32m[2020-06-28 22:54:04] __main__ INFO: \u001b[0mEpoch 51 Step 300/351 lr 0.100000 loss 1.9328 (2.0146) acc@1 0.2891 (0.2420) acc@5 0.6875 (0.6746)\n",
      "\u001b[32m[2020-06-28 22:55:15] __main__ INFO: \u001b[0mEpoch 51 Step 351/351 lr 0.100000 loss 2.0589 (2.0160) acc@1 0.1797 (0.2421) acc@5 0.6484 (0.6754)\n",
      "\u001b[32m[2020-06-28 22:55:15] __main__ INFO: \u001b[0mElapsed 487.53\n",
      "\u001b[32m[2020-06-28 22:55:15] __main__ INFO: \u001b[0mVal 51\n",
      "\u001b[32m[2020-06-28 22:55:32] __main__ INFO: \u001b[0mEpoch 51 loss 2.1026 acc@1 0.2056 acc@5 0.6548\n",
      "\u001b[32m[2020-06-28 22:55:32] __main__ INFO: \u001b[0mElapsed 17.32\n",
      "\u001b[32m[2020-06-28 22:55:32] __main__ INFO: \u001b[0mTrain 52 17901\n",
      "\u001b[32m[2020-06-28 22:57:51] __main__ INFO: \u001b[0mEpoch 52 Step 100/351 lr 0.100000 loss 2.0439 (1.9993) acc@1 0.1953 (0.2485) acc@5 0.7188 (0.6841)\n",
      "\u001b[32m[2020-06-28 23:00:10] __main__ INFO: \u001b[0mEpoch 52 Step 200/351 lr 0.100000 loss 2.0392 (2.0087) acc@1 0.2031 (0.2442) acc@5 0.7422 (0.6770)\n",
      "\u001b[32m[2020-06-28 23:02:29] __main__ INFO: \u001b[0mEpoch 52 Step 300/351 lr 0.100000 loss 2.0160 (2.0113) acc@1 0.2344 (0.2439) acc@5 0.6641 (0.6773)\n",
      "\u001b[32m[2020-06-28 23:03:40] __main__ INFO: \u001b[0mEpoch 52 Step 351/351 lr 0.100000 loss 1.9549 (2.0153) acc@1 0.2578 (0.2417) acc@5 0.6797 (0.6755)\n",
      "\u001b[32m[2020-06-28 23:03:40] __main__ INFO: \u001b[0mElapsed 487.52\n",
      "\u001b[32m[2020-06-28 23:03:40] __main__ INFO: \u001b[0mVal 52\n",
      "\u001b[32m[2020-06-28 23:03:57] __main__ INFO: \u001b[0mEpoch 52 loss 2.1021 acc@1 0.2114 acc@5 0.6562\n",
      "\u001b[32m[2020-06-28 23:03:57] __main__ INFO: \u001b[0mElapsed 17.29\n",
      "\u001b[32m[2020-06-28 23:03:57] __main__ INFO: \u001b[0mTrain 53 18252\n",
      "\u001b[32m[2020-06-28 23:06:16] __main__ INFO: \u001b[0mEpoch 53 Step 100/351 lr 0.100000 loss 2.0972 (2.0024) acc@1 0.2188 (0.2527) acc@5 0.5938 (0.6798)\n",
      "\u001b[32m[2020-06-28 23:08:35] __main__ INFO: \u001b[0mEpoch 53 Step 200/351 lr 0.100000 loss 2.0146 (2.0052) acc@1 0.2031 (0.2473) acc@5 0.6797 (0.6795)\n",
      "\u001b[32m[2020-06-28 23:10:54] __main__ INFO: \u001b[0mEpoch 53 Step 300/351 lr 0.100000 loss 1.9824 (2.0121) acc@1 0.2891 (0.2454) acc@5 0.7031 (0.6779)\n",
      "\u001b[32m[2020-06-28 23:12:04] __main__ INFO: \u001b[0mEpoch 53 Step 351/351 lr 0.100000 loss 1.9367 (2.0135) acc@1 0.2578 (0.2445) acc@5 0.6562 (0.6776)\n",
      "\u001b[32m[2020-06-28 23:12:04] __main__ INFO: \u001b[0mElapsed 487.18\n",
      "\u001b[32m[2020-06-28 23:12:04] __main__ INFO: \u001b[0mVal 53\n",
      "\u001b[32m[2020-06-28 23:12:22] __main__ INFO: \u001b[0mEpoch 53 loss 2.2376 acc@1 0.1978 acc@5 0.6428\n",
      "\u001b[32m[2020-06-28 23:12:22] __main__ INFO: \u001b[0mElapsed 17.30\n",
      "\u001b[32m[2020-06-28 23:12:22] __main__ INFO: \u001b[0mTrain 54 18603\n",
      "\u001b[32m[2020-06-28 23:14:41] __main__ INFO: \u001b[0mEpoch 54 Step 100/351 lr 0.100000 loss 1.9453 (2.0004) acc@1 0.2734 (0.2463) acc@5 0.6719 (0.6742)\n",
      "\u001b[32m[2020-06-28 23:16:59] __main__ INFO: \u001b[0mEpoch 54 Step 200/351 lr 0.100000 loss 1.9697 (2.0066) acc@1 0.2266 (0.2462) acc@5 0.7422 (0.6777)\n",
      "\u001b[32m[2020-06-28 23:19:18] __main__ INFO: \u001b[0mEpoch 54 Step 300/351 lr 0.100000 loss 1.9229 (2.0077) acc@1 0.2891 (0.2478) acc@5 0.6797 (0.6772)\n",
      "\u001b[32m[2020-06-28 23:20:29] __main__ INFO: \u001b[0mEpoch 54 Step 351/351 lr 0.100000 loss 2.1130 (2.0067) acc@1 0.1797 (0.2478) acc@5 0.6094 (0.6770)\n",
      "\u001b[32m[2020-06-28 23:20:29] __main__ INFO: \u001b[0mElapsed 487.15\n",
      "\u001b[32m[2020-06-28 23:20:29] __main__ INFO: \u001b[0mVal 54\n",
      "\u001b[32m[2020-06-28 23:20:46] __main__ INFO: \u001b[0mEpoch 54 loss 2.1166 acc@1 0.2158 acc@5 0.6488\n",
      "\u001b[32m[2020-06-28 23:20:46] __main__ INFO: \u001b[0mElapsed 17.31\n",
      "\u001b[32m[2020-06-28 23:20:46] __main__ INFO: \u001b[0mTrain 55 18954\n",
      "\u001b[32m[2020-06-28 23:23:05] __main__ INFO: \u001b[0mEpoch 55 Step 100/351 lr 0.100000 loss 2.2064 (1.9996) acc@1 0.1797 (0.2501) acc@5 0.6641 (0.6810)\n",
      "\u001b[32m[2020-06-28 23:25:24] __main__ INFO: \u001b[0mEpoch 55 Step 200/351 lr 0.100000 loss 2.0541 (2.0023) acc@1 0.1875 (0.2500) acc@5 0.6484 (0.6810)\n",
      "\u001b[32m[2020-06-28 23:27:43] __main__ INFO: \u001b[0mEpoch 55 Step 300/351 lr 0.100000 loss 1.9732 (2.0047) acc@1 0.2344 (0.2474) acc@5 0.6875 (0.6811)\n",
      "\u001b[32m[2020-06-28 23:28:53] __main__ INFO: \u001b[0mEpoch 55 Step 351/351 lr 0.100000 loss 2.0062 (2.0046) acc@1 0.1953 (0.2475) acc@5 0.6172 (0.6816)\n",
      "\u001b[32m[2020-06-28 23:28:53] __main__ INFO: \u001b[0mElapsed 487.26\n",
      "\u001b[32m[2020-06-28 23:28:53] __main__ INFO: \u001b[0mVal 55\n",
      "\u001b[32m[2020-06-28 23:29:11] __main__ INFO: \u001b[0mEpoch 55 loss 2.1164 acc@1 0.2240 acc@5 0.6578\n",
      "\u001b[32m[2020-06-28 23:29:11] __main__ INFO: \u001b[0mElapsed 17.33\n",
      "\u001b[32m[2020-06-28 23:29:11] __main__ INFO: \u001b[0mTrain 56 19305\n",
      "\u001b[32m[2020-06-28 23:31:30] __main__ INFO: \u001b[0mEpoch 56 Step 100/351 lr 0.100000 loss 2.1182 (1.9954) acc@1 0.2109 (0.2482) acc@5 0.6875 (0.6787)\n",
      "\u001b[32m[2020-06-28 23:33:48] __main__ INFO: \u001b[0mEpoch 56 Step 200/351 lr 0.100000 loss 2.0327 (2.0013) acc@1 0.2578 (0.2457) acc@5 0.6328 (0.6811)\n",
      "\u001b[32m[2020-06-28 23:36:07] __main__ INFO: \u001b[0mEpoch 56 Step 300/351 lr 0.100000 loss 1.9079 (2.0044) acc@1 0.2578 (0.2458) acc@5 0.6641 (0.6792)\n",
      "\u001b[32m[2020-06-28 23:37:18] __main__ INFO: \u001b[0mEpoch 56 Step 351/351 lr 0.100000 loss 2.1005 (2.0046) acc@1 0.2031 (0.2457) acc@5 0.6562 (0.6786)\n",
      "\u001b[32m[2020-06-28 23:37:18] __main__ INFO: \u001b[0mElapsed 487.29\n",
      "\u001b[32m[2020-06-28 23:37:18] __main__ INFO: \u001b[0mVal 56\n",
      "\u001b[32m[2020-06-28 23:37:35] __main__ INFO: \u001b[0mEpoch 56 loss 2.1168 acc@1 0.2214 acc@5 0.6646\n",
      "\u001b[32m[2020-06-28 23:37:35] __main__ INFO: \u001b[0mElapsed 17.32\n",
      "\u001b[32m[2020-06-28 23:37:35] __main__ INFO: \u001b[0mTrain 57 19656\n",
      "\u001b[32m[2020-06-28 23:39:54] __main__ INFO: \u001b[0mEpoch 57 Step 100/351 lr 0.100000 loss 1.9872 (2.0067) acc@1 0.2734 (0.2499) acc@5 0.6875 (0.6795)\n",
      "\u001b[32m[2020-06-28 23:42:13] __main__ INFO: \u001b[0mEpoch 57 Step 200/351 lr 0.100000 loss 2.0707 (2.0021) acc@1 0.1797 (0.2503) acc@5 0.7031 (0.6788)\n",
      "\u001b[32m[2020-06-28 23:44:32] __main__ INFO: \u001b[0mEpoch 57 Step 300/351 lr 0.100000 loss 2.0732 (2.0002) acc@1 0.2344 (0.2497) acc@5 0.6953 (0.6808)\n",
      "\u001b[32m[2020-06-28 23:45:43] __main__ INFO: \u001b[0mEpoch 57 Step 351/351 lr 0.100000 loss 1.9804 (2.0030) acc@1 0.2578 (0.2493) acc@5 0.7266 (0.6806)\n",
      "\u001b[32m[2020-06-28 23:45:43] __main__ INFO: \u001b[0mElapsed 487.23\n",
      "\u001b[32m[2020-06-28 23:45:43] __main__ INFO: \u001b[0mVal 57\n",
      "\u001b[32m[2020-06-28 23:46:00] __main__ INFO: \u001b[0mEpoch 57 loss 2.1533 acc@1 0.2166 acc@5 0.6404\n",
      "\u001b[32m[2020-06-28 23:46:00] __main__ INFO: \u001b[0mElapsed 17.29\n",
      "\u001b[32m[2020-06-28 23:46:00] __main__ INFO: \u001b[0mTrain 58 20007\n",
      "\u001b[32m[2020-06-28 23:48:19] __main__ INFO: \u001b[0mEpoch 58 Step 100/351 lr 0.100000 loss 2.0010 (1.9986) acc@1 0.2422 (0.2496) acc@5 0.6484 (0.6742)\n",
      "\u001b[32m[2020-06-28 23:50:37] __main__ INFO: \u001b[0mEpoch 58 Step 200/351 lr 0.100000 loss 2.0159 (2.0026) acc@1 0.2031 (0.2481) acc@5 0.6172 (0.6744)\n",
      "\u001b[32m[2020-06-28 23:52:56] __main__ INFO: \u001b[0mEpoch 58 Step 300/351 lr 0.100000 loss 2.0680 (2.0005) acc@1 0.2266 (0.2469) acc@5 0.6953 (0.6749)\n",
      "\u001b[32m[2020-06-28 23:54:07] __main__ INFO: \u001b[0mEpoch 58 Step 351/351 lr 0.100000 loss 2.0874 (2.0010) acc@1 0.2266 (0.2471) acc@5 0.6797 (0.6753)\n",
      "\u001b[32m[2020-06-28 23:54:07] __main__ INFO: \u001b[0mElapsed 487.09\n",
      "\u001b[32m[2020-06-28 23:54:07] __main__ INFO: \u001b[0mVal 58\n",
      "\u001b[32m[2020-06-28 23:54:24] __main__ INFO: \u001b[0mEpoch 58 loss 2.1482 acc@1 0.1972 acc@5 0.6570\n",
      "\u001b[32m[2020-06-28 23:54:24] __main__ INFO: \u001b[0mElapsed 17.31\n",
      "\u001b[32m[2020-06-28 23:54:24] __main__ INFO: \u001b[0mTrain 59 20358\n",
      "\u001b[32m[2020-06-28 23:56:43] __main__ INFO: \u001b[0mEpoch 59 Step 100/351 lr 0.100000 loss 1.9176 (2.0002) acc@1 0.2891 (0.2471) acc@5 0.6641 (0.6805)\n",
      "\u001b[32m[2020-06-28 23:59:02] __main__ INFO: \u001b[0mEpoch 59 Step 200/351 lr 0.100000 loss 2.0254 (2.0014) acc@1 0.2266 (0.2493) acc@5 0.6797 (0.6791)\n",
      "\u001b[32m[2020-06-29 00:01:21] __main__ INFO: \u001b[0mEpoch 59 Step 300/351 lr 0.100000 loss 1.9160 (2.0050) acc@1 0.3281 (0.2465) acc@5 0.7500 (0.6783)\n",
      "\u001b[32m[2020-06-29 00:02:31] __main__ INFO: \u001b[0mEpoch 59 Step 351/351 lr 0.100000 loss 1.9210 (2.0008) acc@1 0.2656 (0.2486) acc@5 0.7344 (0.6798)\n",
      "\u001b[32m[2020-06-29 00:02:31] __main__ INFO: \u001b[0mElapsed 487.12\n",
      "\u001b[32m[2020-06-29 00:02:31] __main__ INFO: \u001b[0mVal 59\n",
      "\u001b[32m[2020-06-29 00:02:49] __main__ INFO: \u001b[0mEpoch 59 loss 2.0219 acc@1 0.2420 acc@5 0.6622\n",
      "\u001b[32m[2020-06-29 00:02:49] __main__ INFO: \u001b[0mElapsed 17.26\n",
      "\u001b[32m[2020-06-29 00:02:49] __main__ INFO: \u001b[0mTrain 60 20709\n",
      "\u001b[32m[2020-06-29 00:05:08] __main__ INFO: \u001b[0mEpoch 60 Step 100/351 lr 0.100000 loss 2.1764 (1.9893) acc@1 0.2188 (0.2492) acc@5 0.6719 (0.6792)\n",
      "\u001b[32m[2020-06-29 00:07:26] __main__ INFO: \u001b[0mEpoch 60 Step 200/351 lr 0.100000 loss 2.0786 (1.9907) acc@1 0.1562 (0.2515) acc@5 0.6328 (0.6812)\n",
      "\u001b[32m[2020-06-29 00:09:45] __main__ INFO: \u001b[0mEpoch 60 Step 300/351 lr 0.100000 loss 2.0526 (1.9948) acc@1 0.2500 (0.2490) acc@5 0.6953 (0.6799)\n",
      "\u001b[32m[2020-06-29 00:10:56] __main__ INFO: \u001b[0mEpoch 60 Step 351/351 lr 0.100000 loss 1.9324 (1.9949) acc@1 0.2734 (0.2484) acc@5 0.6797 (0.6789)\n",
      "\u001b[32m[2020-06-29 00:10:56] __main__ INFO: \u001b[0mElapsed 487.18\n",
      "\u001b[32m[2020-06-29 00:10:56] __main__ INFO: \u001b[0mVal 60\n",
      "\u001b[32m[2020-06-29 00:11:13] __main__ INFO: \u001b[0mEpoch 60 loss 2.0088 acc@1 0.2366 acc@5 0.6658\n",
      "\u001b[32m[2020-06-29 00:11:13] __main__ INFO: \u001b[0mElapsed 17.28\n",
      "\u001b[32m[2020-06-29 00:11:13] __main__ INFO: \u001b[0mTrain 61 21060\n",
      "\u001b[32m[2020-06-29 00:13:32] __main__ INFO: \u001b[0mEpoch 61 Step 100/351 lr 0.100000 loss 1.9850 (1.9898) acc@1 0.2578 (0.2461) acc@5 0.7031 (0.6792)\n",
      "\u001b[32m[2020-06-29 00:15:51] __main__ INFO: \u001b[0mEpoch 61 Step 200/351 lr 0.100000 loss 1.9913 (1.9912) acc@1 0.2734 (0.2501) acc@5 0.6094 (0.6809)\n",
      "\u001b[32m[2020-06-29 00:18:09] __main__ INFO: \u001b[0mEpoch 61 Step 300/351 lr 0.100000 loss 2.0257 (1.9918) acc@1 0.2031 (0.2499) acc@5 0.6562 (0.6788)\n",
      "\u001b[32m[2020-06-29 00:19:20] __main__ INFO: \u001b[0mEpoch 61 Step 351/351 lr 0.100000 loss 1.9899 (1.9910) acc@1 0.2344 (0.2503) acc@5 0.7266 (0.6790)\n",
      "\u001b[32m[2020-06-29 00:19:20] __main__ INFO: \u001b[0mElapsed 486.88\n",
      "\u001b[32m[2020-06-29 00:19:20] __main__ INFO: \u001b[0mVal 61\n",
      "\u001b[32m[2020-06-29 00:19:37] __main__ INFO: \u001b[0mEpoch 61 loss 2.1112 acc@1 0.2060 acc@5 0.6488\n",
      "\u001b[32m[2020-06-29 00:19:37] __main__ INFO: \u001b[0mElapsed 17.29\n",
      "\u001b[32m[2020-06-29 00:19:37] __main__ INFO: \u001b[0mTrain 62 21411\n",
      "\u001b[32m[2020-06-29 00:21:56] __main__ INFO: \u001b[0mEpoch 62 Step 100/351 lr 0.100000 loss 1.9661 (1.9823) acc@1 0.2109 (0.2524) acc@5 0.6484 (0.6770)\n",
      "\u001b[32m[2020-06-29 00:24:15] __main__ INFO: \u001b[0mEpoch 62 Step 200/351 lr 0.100000 loss 2.0507 (1.9843) acc@1 0.2031 (0.2553) acc@5 0.6953 (0.6809)\n",
      "\u001b[32m[2020-06-29 00:26:33] __main__ INFO: \u001b[0mEpoch 62 Step 300/351 lr 0.100000 loss 1.9285 (1.9850) acc@1 0.2891 (0.2550) acc@5 0.6953 (0.6807)\n",
      "\u001b[32m[2020-06-29 00:27:44] __main__ INFO: \u001b[0mEpoch 62 Step 351/351 lr 0.100000 loss 2.0203 (1.9879) acc@1 0.2578 (0.2542) acc@5 0.6719 (0.6818)\n",
      "\u001b[32m[2020-06-29 00:27:44] __main__ INFO: \u001b[0mElapsed 486.87\n",
      "\u001b[32m[2020-06-29 00:27:44] __main__ INFO: \u001b[0mVal 62\n",
      "\u001b[32m[2020-06-29 00:28:01] __main__ INFO: \u001b[0mEpoch 62 loss 2.0894 acc@1 0.2314 acc@5 0.6614\n",
      "\u001b[32m[2020-06-29 00:28:01] __main__ INFO: \u001b[0mElapsed 17.27\n",
      "\u001b[32m[2020-06-29 00:28:01] __main__ INFO: \u001b[0mTrain 63 21762\n",
      "\u001b[32m[2020-06-29 00:30:20] __main__ INFO: \u001b[0mEpoch 63 Step 100/351 lr 0.100000 loss 1.9269 (1.9736) acc@1 0.2422 (0.2629) acc@5 0.7266 (0.6873)\n",
      "\u001b[32m[2020-06-29 00:32:39] __main__ INFO: \u001b[0mEpoch 63 Step 200/351 lr 0.100000 loss 1.9498 (1.9766) acc@1 0.2734 (0.2600) acc@5 0.7500 (0.6861)\n",
      "\u001b[32m[2020-06-29 00:34:57] __main__ INFO: \u001b[0mEpoch 63 Step 300/351 lr 0.100000 loss 1.9720 (1.9797) acc@1 0.2031 (0.2590) acc@5 0.6719 (0.6843)\n",
      "\u001b[32m[2020-06-29 00:36:08] __main__ INFO: \u001b[0mEpoch 63 Step 351/351 lr 0.100000 loss 1.9781 (1.9814) acc@1 0.1953 (0.2574) acc@5 0.6875 (0.6840)\n",
      "\u001b[32m[2020-06-29 00:36:08] __main__ INFO: \u001b[0mElapsed 486.73\n",
      "\u001b[32m[2020-06-29 00:36:08] __main__ INFO: \u001b[0mVal 63\n",
      "\u001b[32m[2020-06-29 00:36:25] __main__ INFO: \u001b[0mEpoch 63 loss 2.2442 acc@1 0.1840 acc@5 0.6250\n",
      "\u001b[32m[2020-06-29 00:36:25] __main__ INFO: \u001b[0mElapsed 17.30\n",
      "\u001b[32m[2020-06-29 00:36:25] __main__ INFO: \u001b[0mTrain 64 22113\n",
      "\u001b[32m[2020-06-29 00:38:44] __main__ INFO: \u001b[0mEpoch 64 Step 100/351 lr 0.100000 loss 1.9971 (1.9726) acc@1 0.2344 (0.2592) acc@5 0.6406 (0.6852)\n",
      "\u001b[32m[2020-06-29 00:41:03] __main__ INFO: \u001b[0mEpoch 64 Step 200/351 lr 0.100000 loss 2.0069 (1.9849) acc@1 0.2656 (0.2532) acc@5 0.6953 (0.6834)\n",
      "\u001b[32m[2020-06-29 00:43:22] __main__ INFO: \u001b[0mEpoch 64 Step 300/351 lr 0.100000 loss 1.9834 (1.9801) acc@1 0.2344 (0.2554) acc@5 0.6875 (0.6846)\n",
      "\u001b[32m[2020-06-29 00:44:32] __main__ INFO: \u001b[0mEpoch 64 Step 351/351 lr 0.100000 loss 2.0776 (1.9820) acc@1 0.2188 (0.2552) acc@5 0.5391 (0.6841)\n",
      "\u001b[32m[2020-06-29 00:44:32] __main__ INFO: \u001b[0mElapsed 486.95\n",
      "\u001b[32m[2020-06-29 00:44:32] __main__ INFO: \u001b[0mVal 64\n",
      "\u001b[32m[2020-06-29 00:44:50] __main__ INFO: \u001b[0mEpoch 64 loss 2.1154 acc@1 0.2114 acc@5 0.6486\n",
      "\u001b[32m[2020-06-29 00:44:50] __main__ INFO: \u001b[0mElapsed 17.30\n",
      "\u001b[32m[2020-06-29 00:44:50] __main__ INFO: \u001b[0mTrain 65 22464\n",
      "\u001b[32m[2020-06-29 00:47:09] __main__ INFO: \u001b[0mEpoch 65 Step 100/351 lr 0.100000 loss 1.8555 (1.9732) acc@1 0.2969 (0.2606) acc@5 0.7656 (0.6866)\n",
      "\u001b[32m[2020-06-29 00:49:27] __main__ INFO: \u001b[0mEpoch 65 Step 200/351 lr 0.100000 loss 2.0377 (1.9767) acc@1 0.2188 (0.2600) acc@5 0.7031 (0.6855)\n",
      "\u001b[32m[2020-06-29 00:51:46] __main__ INFO: \u001b[0mEpoch 65 Step 300/351 lr 0.100000 loss 2.0008 (1.9832) acc@1 0.2422 (0.2567) acc@5 0.6641 (0.6821)\n",
      "\u001b[32m[2020-06-29 00:52:56] __main__ INFO: \u001b[0mEpoch 65 Step 351/351 lr 0.100000 loss 2.0515 (1.9825) acc@1 0.2188 (0.2576) acc@5 0.7109 (0.6826)\n",
      "\u001b[32m[2020-06-29 00:52:56] __main__ INFO: \u001b[0mElapsed 486.73\n",
      "\u001b[32m[2020-06-29 00:52:56] __main__ INFO: \u001b[0mVal 65\n",
      "\u001b[32m[2020-06-29 00:53:14] __main__ INFO: \u001b[0mEpoch 65 loss 2.1056 acc@1 0.2050 acc@5 0.6590\n",
      "\u001b[32m[2020-06-29 00:53:14] __main__ INFO: \u001b[0mElapsed 17.30\n",
      "\u001b[32m[2020-06-29 00:53:14] __main__ INFO: \u001b[0mTrain 66 22815\n",
      "\u001b[32m[2020-06-29 00:55:32] __main__ INFO: \u001b[0mEpoch 66 Step 100/351 lr 0.100000 loss 1.8904 (1.9851) acc@1 0.3359 (0.2524) acc@5 0.7109 (0.6808)\n",
      "\u001b[32m[2020-06-29 00:57:51] __main__ INFO: \u001b[0mEpoch 66 Step 200/351 lr 0.100000 loss 2.0581 (1.9822) acc@1 0.2266 (0.2538) acc@5 0.6484 (0.6809)\n",
      "\u001b[32m[2020-06-29 01:00:10] __main__ INFO: \u001b[0mEpoch 66 Step 300/351 lr 0.100000 loss 1.9774 (1.9794) acc@1 0.2500 (0.2548) acc@5 0.7422 (0.6832)\n",
      "\u001b[32m[2020-06-29 01:01:20] __main__ INFO: \u001b[0mEpoch 66 Step 351/351 lr 0.100000 loss 1.9770 (1.9764) acc@1 0.2578 (0.2562) acc@5 0.6797 (0.6840)\n",
      "\u001b[32m[2020-06-29 01:01:20] __main__ INFO: \u001b[0mElapsed 486.64\n",
      "\u001b[32m[2020-06-29 01:01:20] __main__ INFO: \u001b[0mVal 66\n",
      "\u001b[32m[2020-06-29 01:01:38] __main__ INFO: \u001b[0mEpoch 66 loss 2.0811 acc@1 0.2262 acc@5 0.6698\n",
      "\u001b[32m[2020-06-29 01:01:38] __main__ INFO: \u001b[0mElapsed 17.28\n",
      "\u001b[32m[2020-06-29 01:01:38] __main__ INFO: \u001b[0mTrain 67 23166\n",
      "\u001b[32m[2020-06-29 01:03:56] __main__ INFO: \u001b[0mEpoch 67 Step 100/351 lr 0.100000 loss 1.9170 (1.9738) acc@1 0.2891 (0.2628) acc@5 0.6172 (0.6869)\n",
      "\u001b[32m[2020-06-29 01:06:15] __main__ INFO: \u001b[0mEpoch 67 Step 200/351 lr 0.100000 loss 1.9694 (1.9741) acc@1 0.2266 (0.2626) acc@5 0.6953 (0.6875)\n",
      "\u001b[32m[2020-06-29 01:08:34] __main__ INFO: \u001b[0mEpoch 67 Step 300/351 lr 0.100000 loss 1.9062 (1.9770) acc@1 0.2812 (0.2608) acc@5 0.7031 (0.6860)\n",
      "\u001b[32m[2020-06-29 01:09:44] __main__ INFO: \u001b[0mEpoch 67 Step 351/351 lr 0.100000 loss 1.9221 (1.9772) acc@1 0.2656 (0.2596) acc@5 0.6797 (0.6850)\n",
      "\u001b[32m[2020-06-29 01:09:44] __main__ INFO: \u001b[0mElapsed 486.69\n",
      "\u001b[32m[2020-06-29 01:09:44] __main__ INFO: \u001b[0mVal 67\n",
      "\u001b[32m[2020-06-29 01:10:02] __main__ INFO: \u001b[0mEpoch 67 loss 2.1438 acc@1 0.2142 acc@5 0.6580\n",
      "\u001b[32m[2020-06-29 01:10:02] __main__ INFO: \u001b[0mElapsed 17.30\n",
      "\u001b[32m[2020-06-29 01:10:02] __main__ INFO: \u001b[0mTrain 68 23517\n",
      "\u001b[32m[2020-06-29 01:12:20] __main__ INFO: \u001b[0mEpoch 68 Step 100/351 lr 0.100000 loss 1.9288 (1.9641) acc@1 0.2422 (0.2618) acc@5 0.6719 (0.6813)\n",
      "\u001b[32m[2020-06-29 01:14:39] __main__ INFO: \u001b[0mEpoch 68 Step 200/351 lr 0.100000 loss 1.8432 (1.9673) acc@1 0.3359 (0.2599) acc@5 0.7266 (0.6815)\n",
      "\u001b[32m[2020-06-29 01:16:58] __main__ INFO: \u001b[0mEpoch 68 Step 300/351 lr 0.100000 loss 2.0284 (1.9729) acc@1 0.2188 (0.2573) acc@5 0.6406 (0.6808)\n",
      "\u001b[32m[2020-06-29 01:18:08] __main__ INFO: \u001b[0mEpoch 68 Step 351/351 lr 0.100000 loss 2.1188 (1.9729) acc@1 0.1953 (0.2581) acc@5 0.6406 (0.6803)\n",
      "\u001b[32m[2020-06-29 01:18:08] __main__ INFO: \u001b[0mElapsed 486.75\n",
      "\u001b[32m[2020-06-29 01:18:08] __main__ INFO: \u001b[0mVal 68\n",
      "\u001b[32m[2020-06-29 01:18:26] __main__ INFO: \u001b[0mEpoch 68 loss 2.1300 acc@1 0.2194 acc@5 0.6500\n",
      "\u001b[32m[2020-06-29 01:18:26] __main__ INFO: \u001b[0mElapsed 17.25\n",
      "\u001b[32m[2020-06-29 01:18:26] __main__ INFO: \u001b[0mTrain 69 23868\n",
      "\u001b[32m[2020-06-29 01:20:44] __main__ INFO: \u001b[0mEpoch 69 Step 100/351 lr 0.100000 loss 1.9994 (1.9637) acc@1 0.2500 (0.2648) acc@5 0.7031 (0.6905)\n",
      "\u001b[32m[2020-06-29 01:23:03] __main__ INFO: \u001b[0mEpoch 69 Step 200/351 lr 0.100000 loss 2.0191 (1.9596) acc@1 0.2266 (0.2679) acc@5 0.6562 (0.6913)\n",
      "\u001b[32m[2020-06-29 01:25:22] __main__ INFO: \u001b[0mEpoch 69 Step 300/351 lr 0.100000 loss 2.1780 (1.9674) acc@1 0.1875 (0.2636) acc@5 0.6484 (0.6873)\n",
      "\u001b[32m[2020-06-29 01:26:32] __main__ INFO: \u001b[0mEpoch 69 Step 351/351 lr 0.100000 loss 1.9633 (1.9686) acc@1 0.2812 (0.2628) acc@5 0.6484 (0.6871)\n",
      "\u001b[32m[2020-06-29 01:26:32] __main__ INFO: \u001b[0mElapsed 486.55\n",
      "\u001b[32m[2020-06-29 01:26:32] __main__ INFO: \u001b[0mVal 69\n",
      "\u001b[32m[2020-06-29 01:26:50] __main__ INFO: \u001b[0mEpoch 69 loss 2.0671 acc@1 0.2316 acc@5 0.6550\n",
      "\u001b[32m[2020-06-29 01:26:50] __main__ INFO: \u001b[0mElapsed 17.28\n",
      "\u001b[32m[2020-06-29 01:26:50] __main__ INFO: \u001b[0mTrain 70 24219\n",
      "\u001b[32m[2020-06-29 01:29:08] __main__ INFO: \u001b[0mEpoch 70 Step 100/351 lr 0.100000 loss 2.0302 (1.9728) acc@1 0.2578 (0.2594) acc@5 0.6406 (0.6848)\n",
      "\u001b[32m[2020-06-29 01:31:27] __main__ INFO: \u001b[0mEpoch 70 Step 200/351 lr 0.100000 loss 2.0007 (1.9698) acc@1 0.2500 (0.2596) acc@5 0.6172 (0.6837)\n",
      "\u001b[32m[2020-06-29 01:33:45] __main__ INFO: \u001b[0mEpoch 70 Step 300/351 lr 0.100000 loss 1.9464 (1.9679) acc@1 0.2734 (0.2592) acc@5 0.6719 (0.6849)\n",
      "\u001b[32m[2020-06-29 01:34:56] __main__ INFO: \u001b[0mEpoch 70 Step 351/351 lr 0.100000 loss 1.8497 (1.9691) acc@1 0.2969 (0.2589) acc@5 0.7266 (0.6845)\n",
      "\u001b[32m[2020-06-29 01:34:56] __main__ INFO: \u001b[0mElapsed 486.48\n",
      "\u001b[32m[2020-06-29 01:34:56] __main__ INFO: \u001b[0mVal 70\n",
      "\u001b[32m[2020-06-29 01:35:13] __main__ INFO: \u001b[0mEpoch 70 loss 2.1491 acc@1 0.2246 acc@5 0.6520\n",
      "\u001b[32m[2020-06-29 01:35:13] __main__ INFO: \u001b[0mElapsed 17.28\n",
      "\u001b[32m[2020-06-29 01:35:13] __main__ INFO: \u001b[0mTrain 71 24570\n",
      "\u001b[32m[2020-06-29 01:37:32] __main__ INFO: \u001b[0mEpoch 71 Step 100/351 lr 0.100000 loss 2.0539 (1.9605) acc@1 0.2344 (0.2660) acc@5 0.6875 (0.6877)\n",
      "\u001b[32m[2020-06-29 01:39:51] __main__ INFO: \u001b[0mEpoch 71 Step 200/351 lr 0.100000 loss 1.9195 (1.9634) acc@1 0.2656 (0.2625) acc@5 0.5938 (0.6878)\n",
      "\u001b[32m[2020-06-29 01:42:09] __main__ INFO: \u001b[0mEpoch 71 Step 300/351 lr 0.100000 loss 1.9875 (1.9656) acc@1 0.2578 (0.2631) acc@5 0.6484 (0.6860)\n",
      "\u001b[32m[2020-06-29 01:43:20] __main__ INFO: \u001b[0mEpoch 71 Step 351/351 lr 0.100000 loss 1.8742 (1.9642) acc@1 0.2891 (0.2637) acc@5 0.6250 (0.6856)\n",
      "\u001b[32m[2020-06-29 01:43:20] __main__ INFO: \u001b[0mElapsed 486.50\n",
      "\u001b[32m[2020-06-29 01:43:20] __main__ INFO: \u001b[0mVal 71\n",
      "\u001b[32m[2020-06-29 01:43:37] __main__ INFO: \u001b[0mEpoch 71 loss 2.0331 acc@1 0.2552 acc@5 0.6790\n",
      "\u001b[32m[2020-06-29 01:43:37] __main__ INFO: \u001b[0mElapsed 17.29\n",
      "\u001b[32m[2020-06-29 01:43:37] __main__ INFO: \u001b[0mTrain 72 24921\n",
      "\u001b[32m[2020-06-29 01:45:56] __main__ INFO: \u001b[0mEpoch 72 Step 100/351 lr 0.100000 loss 2.0957 (1.9612) acc@1 0.1641 (0.2670) acc@5 0.6094 (0.6866)\n",
      "\u001b[32m[2020-06-29 01:48:14] __main__ INFO: \u001b[0mEpoch 72 Step 200/351 lr 0.100000 loss 1.9419 (1.9649) acc@1 0.2891 (0.2644) acc@5 0.6562 (0.6863)\n",
      "\u001b[32m[2020-06-29 01:50:33] __main__ INFO: \u001b[0mEpoch 72 Step 300/351 lr 0.100000 loss 2.0537 (1.9674) acc@1 0.1953 (0.2622) acc@5 0.6016 (0.6875)\n",
      "\u001b[32m[2020-06-29 01:51:44] __main__ INFO: \u001b[0mEpoch 72 Step 351/351 lr 0.100000 loss 2.0052 (1.9653) acc@1 0.2109 (0.2634) acc@5 0.6641 (0.6869)\n",
      "\u001b[32m[2020-06-29 01:51:44] __main__ INFO: \u001b[0mElapsed 486.54\n",
      "\u001b[32m[2020-06-29 01:51:44] __main__ INFO: \u001b[0mVal 72\n",
      "\u001b[32m[2020-06-29 01:52:01] __main__ INFO: \u001b[0mEpoch 72 loss 2.1258 acc@1 0.2186 acc@5 0.6610\n",
      "\u001b[32m[2020-06-29 01:52:01] __main__ INFO: \u001b[0mElapsed 17.28\n",
      "\u001b[32m[2020-06-29 01:52:01] __main__ INFO: \u001b[0mTrain 73 25272\n",
      "\u001b[32m[2020-06-29 01:54:19] __main__ INFO: \u001b[0mEpoch 73 Step 100/351 lr 0.100000 loss 1.9996 (1.9495) acc@1 0.2344 (0.2633) acc@5 0.6094 (0.6895)\n",
      "\u001b[32m[2020-06-29 01:56:38] __main__ INFO: \u001b[0mEpoch 73 Step 200/351 lr 0.100000 loss 1.9659 (1.9597) acc@1 0.2812 (0.2634) acc@5 0.6797 (0.6874)\n",
      "\u001b[32m[2020-06-29 01:58:57] __main__ INFO: \u001b[0mEpoch 73 Step 300/351 lr 0.100000 loss 1.9871 (1.9649) acc@1 0.2109 (0.2638) acc@5 0.6875 (0.6865)\n",
      "\u001b[32m[2020-06-29 02:00:07] __main__ INFO: \u001b[0mEpoch 73 Step 351/351 lr 0.100000 loss 1.9084 (1.9653) acc@1 0.2344 (0.2633) acc@5 0.6406 (0.6863)\n",
      "\u001b[32m[2020-06-29 02:00:07] __main__ INFO: \u001b[0mElapsed 486.48\n",
      "\u001b[32m[2020-06-29 02:00:07] __main__ INFO: \u001b[0mVal 73\n",
      "\u001b[32m[2020-06-29 02:00:25] __main__ INFO: \u001b[0mEpoch 73 loss 2.0989 acc@1 0.2252 acc@5 0.6660\n",
      "\u001b[32m[2020-06-29 02:00:25] __main__ INFO: \u001b[0mElapsed 17.33\n",
      "\u001b[32m[2020-06-29 02:00:25] __main__ INFO: \u001b[0mTrain 74 25623\n",
      "\u001b[32m[2020-06-29 02:02:43] __main__ INFO: \u001b[0mEpoch 74 Step 100/351 lr 0.100000 loss 1.9408 (1.9466) acc@1 0.2969 (0.2719) acc@5 0.6953 (0.6959)\n",
      "\u001b[32m[2020-06-29 02:05:02] __main__ INFO: \u001b[0mEpoch 74 Step 200/351 lr 0.100000 loss 2.0121 (1.9556) acc@1 0.2266 (0.2700) acc@5 0.6484 (0.6915)\n",
      "\u001b[32m[2020-06-29 02:07:20] __main__ INFO: \u001b[0mEpoch 74 Step 300/351 lr 0.100000 loss 1.8924 (1.9591) acc@1 0.3281 (0.2680) acc@5 0.6719 (0.6918)\n",
      "\u001b[32m[2020-06-29 02:08:31] __main__ INFO: \u001b[0mEpoch 74 Step 351/351 lr 0.100000 loss 1.9818 (1.9584) acc@1 0.2422 (0.2687) acc@5 0.6875 (0.6914)\n",
      "\u001b[32m[2020-06-29 02:08:31] __main__ INFO: \u001b[0mElapsed 486.46\n",
      "\u001b[32m[2020-06-29 02:08:31] __main__ INFO: \u001b[0mVal 74\n",
      "\u001b[32m[2020-06-29 02:08:48] __main__ INFO: \u001b[0mEpoch 74 loss 1.9964 acc@1 0.2442 acc@5 0.6752\n",
      "\u001b[32m[2020-06-29 02:08:48] __main__ INFO: \u001b[0mElapsed 17.28\n",
      "\u001b[32m[2020-06-29 02:08:48] __main__ INFO: \u001b[0mTrain 75 25974\n",
      "\u001b[32m[2020-06-29 02:11:07] __main__ INFO: \u001b[0mEpoch 75 Step 100/351 lr 0.100000 loss 2.0225 (1.9494) acc@1 0.2578 (0.2723) acc@5 0.6328 (0.6887)\n",
      "\u001b[32m[2020-06-29 02:13:26] __main__ INFO: \u001b[0mEpoch 75 Step 200/351 lr 0.100000 loss 1.8840 (1.9556) acc@1 0.3281 (0.2682) acc@5 0.6797 (0.6895)\n",
      "\u001b[32m[2020-06-29 02:15:44] __main__ INFO: \u001b[0mEpoch 75 Step 300/351 lr 0.100000 loss 2.0661 (1.9566) acc@1 0.1953 (0.2680) acc@5 0.5938 (0.6874)\n",
      "\u001b[32m[2020-06-29 02:16:55] __main__ INFO: \u001b[0mEpoch 75 Step 351/351 lr 0.100000 loss 2.0297 (1.9563) acc@1 0.2422 (0.2671) acc@5 0.6562 (0.6882)\n",
      "\u001b[32m[2020-06-29 02:16:55] __main__ INFO: \u001b[0mElapsed 486.36\n",
      "\u001b[32m[2020-06-29 02:16:55] __main__ INFO: \u001b[0mVal 75\n",
      "\u001b[32m[2020-06-29 02:17:12] __main__ INFO: \u001b[0mEpoch 75 loss 2.0323 acc@1 0.2362 acc@5 0.6636\n",
      "\u001b[32m[2020-06-29 02:17:12] __main__ INFO: \u001b[0mElapsed 17.27\n",
      "\u001b[32m[2020-06-29 02:17:12] __main__ INFO: \u001b[0mTrain 76 26325\n",
      "\u001b[32m[2020-06-29 02:19:31] __main__ INFO: \u001b[0mEpoch 76 Step 100/351 lr 0.100000 loss 1.9089 (1.9528) acc@1 0.2500 (0.2685) acc@5 0.7188 (0.6930)\n",
      "\u001b[32m[2020-06-29 02:21:49] __main__ INFO: \u001b[0mEpoch 76 Step 200/351 lr 0.100000 loss 1.9284 (1.9569) acc@1 0.3125 (0.2675) acc@5 0.6562 (0.6881)\n",
      "\u001b[32m[2020-06-29 02:24:08] __main__ INFO: \u001b[0mEpoch 76 Step 300/351 lr 0.100000 loss 2.0648 (1.9566) acc@1 0.2109 (0.2658) acc@5 0.6406 (0.6898)\n",
      "\u001b[32m[2020-06-29 02:25:18] __main__ INFO: \u001b[0mEpoch 76 Step 351/351 lr 0.100000 loss 2.0321 (1.9567) acc@1 0.2109 (0.2646) acc@5 0.5859 (0.6890)\n",
      "\u001b[32m[2020-06-29 02:25:18] __main__ INFO: \u001b[0mElapsed 486.38\n",
      "\u001b[32m[2020-06-29 02:25:18] __main__ INFO: \u001b[0mVal 76\n",
      "\u001b[32m[2020-06-29 02:25:36] __main__ INFO: \u001b[0mEpoch 76 loss 2.0521 acc@1 0.2310 acc@5 0.6570\n",
      "\u001b[32m[2020-06-29 02:25:36] __main__ INFO: \u001b[0mElapsed 17.29\n",
      "\u001b[32m[2020-06-29 02:25:36] __main__ INFO: \u001b[0mTrain 77 26676\n",
      "\u001b[32m[2020-06-29 02:27:54] __main__ INFO: \u001b[0mEpoch 77 Step 100/351 lr 0.100000 loss 1.8716 (1.9576) acc@1 0.3125 (0.2678) acc@5 0.6797 (0.6869)\n",
      "\u001b[32m[2020-06-29 02:30:13] __main__ INFO: \u001b[0mEpoch 77 Step 200/351 lr 0.100000 loss 1.9990 (1.9569) acc@1 0.2578 (0.2673) acc@5 0.7188 (0.6894)\n",
      "\u001b[32m[2020-06-29 02:32:31] __main__ INFO: \u001b[0mEpoch 77 Step 300/351 lr 0.100000 loss 1.9535 (1.9585) acc@1 0.2812 (0.2651) acc@5 0.7031 (0.6862)\n",
      "\u001b[32m[2020-06-29 02:33:42] __main__ INFO: \u001b[0mEpoch 77 Step 351/351 lr 0.100000 loss 1.9745 (1.9569) acc@1 0.2656 (0.2659) acc@5 0.6406 (0.6873)\n",
      "\u001b[32m[2020-06-29 02:33:42] __main__ INFO: \u001b[0mElapsed 486.10\n",
      "\u001b[32m[2020-06-29 02:33:42] __main__ INFO: \u001b[0mVal 77\n",
      "\u001b[32m[2020-06-29 02:33:59] __main__ INFO: \u001b[0mEpoch 77 loss 2.1627 acc@1 0.2152 acc@5 0.6528\n",
      "\u001b[32m[2020-06-29 02:33:59] __main__ INFO: \u001b[0mElapsed 17.26\n",
      "\u001b[32m[2020-06-29 02:33:59] __main__ INFO: \u001b[0mTrain 78 27027\n",
      "\u001b[32m[2020-06-29 02:36:18] __main__ INFO: \u001b[0mEpoch 78 Step 100/351 lr 0.100000 loss 2.0048 (1.9449) acc@1 0.2812 (0.2703) acc@5 0.6562 (0.6890)\n",
      "\u001b[32m[2020-06-29 02:38:36] __main__ INFO: \u001b[0mEpoch 78 Step 200/351 lr 0.100000 loss 2.0067 (1.9513) acc@1 0.2344 (0.2710) acc@5 0.7109 (0.6919)\n",
      "\u001b[32m[2020-06-29 02:40:55] __main__ INFO: \u001b[0mEpoch 78 Step 300/351 lr 0.100000 loss 1.9087 (1.9555) acc@1 0.2656 (0.2687) acc@5 0.6562 (0.6892)\n",
      "\u001b[32m[2020-06-29 02:42:05] __main__ INFO: \u001b[0mEpoch 78 Step 351/351 lr 0.100000 loss 2.0458 (1.9556) acc@1 0.2109 (0.2681) acc@5 0.6328 (0.6887)\n",
      "\u001b[32m[2020-06-29 02:42:05] __main__ INFO: \u001b[0mElapsed 486.28\n",
      "\u001b[32m[2020-06-29 02:42:05] __main__ INFO: \u001b[0mVal 78\n",
      "\u001b[32m[2020-06-29 02:42:23] __main__ INFO: \u001b[0mEpoch 78 loss 2.2197 acc@1 0.2042 acc@5 0.6508\n",
      "\u001b[32m[2020-06-29 02:42:23] __main__ INFO: \u001b[0mElapsed 17.27\n",
      "\u001b[32m[2020-06-29 02:42:23] __main__ INFO: \u001b[0mTrain 79 27378\n",
      "\u001b[32m[2020-06-29 02:44:41] __main__ INFO: \u001b[0mEpoch 79 Step 100/351 lr 0.100000 loss 2.0331 (1.9506) acc@1 0.1797 (0.2734) acc@5 0.6562 (0.6885)\n",
      "\u001b[32m[2020-06-29 02:47:00] __main__ INFO: \u001b[0mEpoch 79 Step 200/351 lr 0.100000 loss 1.9143 (1.9574) acc@1 0.2500 (0.2656) acc@5 0.6562 (0.6871)\n",
      "\u001b[32m[2020-06-29 02:49:18] __main__ INFO: \u001b[0mEpoch 79 Step 300/351 lr 0.100000 loss 1.9257 (1.9546) acc@1 0.3047 (0.2675) acc@5 0.6172 (0.6872)\n",
      "\u001b[32m[2020-06-29 02:50:29] __main__ INFO: \u001b[0mEpoch 79 Step 351/351 lr 0.100000 loss 1.9168 (1.9536) acc@1 0.2891 (0.2675) acc@5 0.7656 (0.6870)\n",
      "\u001b[32m[2020-06-29 02:50:29] __main__ INFO: \u001b[0mElapsed 486.21\n",
      "\u001b[32m[2020-06-29 02:50:29] __main__ INFO: \u001b[0mVal 79\n",
      "\u001b[32m[2020-06-29 02:50:46] __main__ INFO: \u001b[0mEpoch 79 loss 2.0204 acc@1 0.2456 acc@5 0.6740\n",
      "\u001b[32m[2020-06-29 02:50:46] __main__ INFO: \u001b[0mElapsed 17.25\n",
      "\u001b[32m[2020-06-29 02:50:46] __main__ INFO: \u001b[0mTrain 80 27729\n",
      "\u001b[32m[2020-06-29 02:53:05] __main__ INFO: \u001b[0mEpoch 80 Step 100/351 lr 0.100000 loss 1.9208 (1.9483) acc@1 0.2969 (0.2737) acc@5 0.7422 (0.6887)\n",
      "\u001b[32m[2020-06-29 02:55:23] __main__ INFO: \u001b[0mEpoch 80 Step 200/351 lr 0.100000 loss 1.9033 (1.9516) acc@1 0.3125 (0.2712) acc@5 0.6641 (0.6893)\n",
      "\u001b[32m[2020-06-29 02:57:42] __main__ INFO: \u001b[0mEpoch 80 Step 300/351 lr 0.100000 loss 2.0462 (1.9546) acc@1 0.2344 (0.2709) acc@5 0.6094 (0.6895)\n",
      "\u001b[32m[2020-06-29 02:58:52] __main__ INFO: \u001b[0mEpoch 80 Step 351/351 lr 0.100000 loss 2.0796 (1.9513) acc@1 0.2031 (0.2720) acc@5 0.6406 (0.6912)\n",
      "\u001b[32m[2020-06-29 02:58:52] __main__ INFO: \u001b[0mElapsed 486.14\n",
      "\u001b[32m[2020-06-29 02:58:52] __main__ INFO: \u001b[0mVal 80\n",
      "\u001b[32m[2020-06-29 02:59:10] __main__ INFO: \u001b[0mEpoch 80 loss 2.0767 acc@1 0.2324 acc@5 0.6570\n",
      "\u001b[32m[2020-06-29 02:59:10] __main__ INFO: \u001b[0mElapsed 17.28\n",
      "\u001b[32m[2020-06-29 02:59:10] __main__ INFO: \u001b[0mTrain 81 28080\n",
      "\u001b[32m[2020-06-29 03:01:28] __main__ INFO: \u001b[0mEpoch 81 Step 100/351 lr 0.100000 loss 1.8159 (1.9449) acc@1 0.3047 (0.2705) acc@5 0.7656 (0.6924)\n",
      "\u001b[32m[2020-06-29 03:03:47] __main__ INFO: \u001b[0mEpoch 81 Step 200/351 lr 0.100000 loss 1.9448 (1.9454) acc@1 0.2188 (0.2686) acc@5 0.6719 (0.6884)\n",
      "\u001b[32m[2020-06-29 03:06:05] __main__ INFO: \u001b[0mEpoch 81 Step 300/351 lr 0.100000 loss 1.9883 (1.9480) acc@1 0.2422 (0.2686) acc@5 0.7109 (0.6884)\n",
      "\u001b[32m[2020-06-29 03:07:16] __main__ INFO: \u001b[0mEpoch 81 Step 351/351 lr 0.100000 loss 2.0479 (1.9512) acc@1 0.2266 (0.2677) acc@5 0.6562 (0.6885)\n",
      "\u001b[32m[2020-06-29 03:07:16] __main__ INFO: \u001b[0mElapsed 485.97\n",
      "\u001b[32m[2020-06-29 03:07:16] __main__ INFO: \u001b[0mVal 81\n",
      "\u001b[32m[2020-06-29 03:07:33] __main__ INFO: \u001b[0mEpoch 81 loss 2.1640 acc@1 0.2098 acc@5 0.6408\n",
      "\u001b[32m[2020-06-29 03:07:33] __main__ INFO: \u001b[0mElapsed 17.25\n",
      "\u001b[32m[2020-06-29 03:07:33] __main__ INFO: \u001b[0mTrain 82 28431\n",
      "\u001b[32m[2020-06-29 03:09:51] __main__ INFO: \u001b[0mEpoch 82 Step 100/351 lr 0.100000 loss 1.8613 (1.9333) acc@1 0.3281 (0.2787) acc@5 0.7500 (0.7023)\n",
      "\u001b[32m[2020-06-29 03:12:10] __main__ INFO: \u001b[0mEpoch 82 Step 200/351 lr 0.100000 loss 1.9852 (1.9397) acc@1 0.2578 (0.2728) acc@5 0.7109 (0.6973)\n",
      "\u001b[32m[2020-06-29 03:14:28] __main__ INFO: \u001b[0mEpoch 82 Step 300/351 lr 0.100000 loss 1.9371 (1.9460) acc@1 0.2891 (0.2694) acc@5 0.6641 (0.6938)\n",
      "\u001b[32m[2020-06-29 03:15:39] __main__ INFO: \u001b[0mEpoch 82 Step 351/351 lr 0.100000 loss 1.9235 (1.9481) acc@1 0.2734 (0.2684) acc@5 0.7500 (0.6927)\n",
      "\u001b[32m[2020-06-29 03:15:39] __main__ INFO: \u001b[0mElapsed 486.01\n",
      "\u001b[32m[2020-06-29 03:15:39] __main__ INFO: \u001b[0mVal 82\n",
      "\u001b[32m[2020-06-29 03:15:56] __main__ INFO: \u001b[0mEpoch 82 loss 2.0299 acc@1 0.2444 acc@5 0.6732\n",
      "\u001b[32m[2020-06-29 03:15:56] __main__ INFO: \u001b[0mElapsed 17.25\n",
      "\u001b[32m[2020-06-29 03:15:56] __main__ INFO: \u001b[0mTrain 83 28782\n",
      "\u001b[32m[2020-06-29 03:18:14] __main__ INFO: \u001b[0mEpoch 83 Step 100/351 lr 0.100000 loss 1.9736 (1.9496) acc@1 0.2656 (0.2688) acc@5 0.6641 (0.6922)\n",
      "\u001b[32m[2020-06-29 03:20:33] __main__ INFO: \u001b[0mEpoch 83 Step 200/351 lr 0.100000 loss 1.9742 (1.9472) acc@1 0.2500 (0.2729) acc@5 0.6797 (0.6916)\n",
      "\u001b[32m[2020-06-29 03:22:51] __main__ INFO: \u001b[0mEpoch 83 Step 300/351 lr 0.100000 loss 1.9924 (1.9462) acc@1 0.2500 (0.2726) acc@5 0.6016 (0.6929)\n",
      "\u001b[32m[2020-06-29 03:24:02] __main__ INFO: \u001b[0mEpoch 83 Step 351/351 lr 0.100000 loss 1.8935 (1.9488) acc@1 0.2812 (0.2710) acc@5 0.6719 (0.6930)\n",
      "\u001b[32m[2020-06-29 03:24:02] __main__ INFO: \u001b[0mElapsed 486.06\n",
      "\u001b[32m[2020-06-29 03:24:02] __main__ INFO: \u001b[0mVal 83\n",
      "\u001b[32m[2020-06-29 03:24:19] __main__ INFO: \u001b[0mEpoch 83 loss 2.0310 acc@1 0.2510 acc@5 0.6836\n",
      "\u001b[32m[2020-06-29 03:24:19] __main__ INFO: \u001b[0mElapsed 17.27\n",
      "\u001b[32m[2020-06-29 03:24:19] __main__ INFO: \u001b[0mTrain 84 29133\n",
      "\u001b[32m[2020-06-29 03:26:38] __main__ INFO: \u001b[0mEpoch 84 Step 100/351 lr 0.100000 loss 1.8617 (1.9312) acc@1 0.2969 (0.2733) acc@5 0.6562 (0.6905)\n"
     ]
    }
   ],
   "source": [
    "# Train the model per the settings specified for ResNext 29_4x64d in the original paper\n",
    "os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "!python train.py --config configs/cifar/resnext.yaml \\\n",
    "    model.resnext.cardinality 4 \\\n",
    "    train.batch_size 128 \\\n",
    "    dataset.name CIFAR10_RA_3_20 \\\n",
    "    train.base_lr 0.1 \\\n",
    "    train.output_dir /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_ra_3_20/exp00 \\\n",
    "    scheduler.epochs 400\n",
    "\n",
    "# Number of epochs should be 300!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-01 00:19:54] __main__ INFO: \u001b[0mdevice: cuda\n",
      "cudnn:\n",
      "  benchmark: True\n",
      "  deterministic: False\n",
      "dataset:\n",
      "  name: CIFAR10\n",
      "  dataset_dir: ~/.torch/datasets/CIFAR10\n",
      "  image_size: 32\n",
      "  n_channels: 3\n",
      "  n_classes: 10\n",
      "model:\n",
      "  type: cifar\n",
      "  name: resnext\n",
      "  init_mode: kaiming_fan_out\n",
      "  vgg:\n",
      "    n_channels: [64, 128, 256, 512, 512]\n",
      "    n_layers: [2, 2, 3, 3, 3]\n",
      "    use_bn: True\n",
      "  resnet:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "  resnet_preact:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "  wrn:\n",
      "    depth: 28\n",
      "    initial_channels: 16\n",
      "    widening_factor: 10\n",
      "    drop_rate: 0.0\n",
      "  densenet:\n",
      "    depth: 100\n",
      "    n_blocks: [6, 12, 24, 16]\n",
      "    block_type: bottleneck\n",
      "    growth_rate: 12\n",
      "    drop_rate: 0.0\n",
      "    compression_rate: 0.5\n",
      "  pyramidnet:\n",
      "    depth: 272\n",
      "    n_blocks: [3, 24, 36, 3]\n",
      "    initial_channels: 16\n",
      "    block_type: bottleneck\n",
      "    alpha: 200\n",
      "  resnext:\n",
      "    depth: 29\n",
      "    n_blocks: [3, 4, 6, 3]\n",
      "    initial_channels: 64\n",
      "    cardinality: 4\n",
      "    base_channels: 64\n",
      "  shake_shake:\n",
      "    depth: 26\n",
      "    initial_channels: 96\n",
      "    shake_forward: True\n",
      "    shake_backward: True\n",
      "    shake_image: True\n",
      "  se_resnet_preact:\n",
      "    depth: 110\n",
      "    initial_channels: 16\n",
      "    se_reduction: 16\n",
      "    block_type: basic\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "train:\n",
      "  checkpoint: /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_ra_3_20/exp00/checkpoint_00400.pth\n",
      "  resume: False\n",
      "  precision: O0\n",
      "  batch_size: 128\n",
      "  subdivision: 1\n",
      "  optimizer: sgd\n",
      "  base_lr: 0.001\n",
      "  momentum: 0.9\n",
      "  nesterov: True\n",
      "  weight_decay: 0.0005\n",
      "  no_weight_decay_on_bn: False\n",
      "  gradient_clip: 0\n",
      "  start_epoch: 0\n",
      "  seed: 0\n",
      "  val_first: True\n",
      "  val_period: 1\n",
      "  val_ratio: 0.1\n",
      "  use_test_as_val: False\n",
      "  output_dir: /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_ra_3_20/exp00_resume400_50\n",
      "  log_period: 100\n",
      "  checkpoint_period: 100\n",
      "  use_tensorboard: True\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: True\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "  distributed: False\n",
      "  dist:\n",
      "    backend: nccl\n",
      "    init_method: env://\n",
      "    world_size: -1\n",
      "    node_rank: -1\n",
      "    local_rank: 0\n",
      "    use_sync_bn: False\n",
      "tensorboard:\n",
      "  train_images: False\n",
      "  val_images: False\n",
      "  model_params: False\n",
      "optim:\n",
      "  adam:\n",
      "    betas: (0.9, 0.999)\n",
      "  lars:\n",
      "    eps: 1e-09\n",
      "    threshold: 0.01\n",
      "  adabound:\n",
      "    betas: (0.9, 0.999)\n",
      "    final_lr: 0.1\n",
      "    gamma: 0.001\n",
      "scheduler:\n",
      "  epochs: 50\n",
      "  warmup:\n",
      "    type: none\n",
      "    epochs: 0\n",
      "    start_factor: 0.001\n",
      "    exponent: 4\n",
      "  type: multistep\n",
      "  milestones: [150, 225]\n",
      "  lr_decay: 0.1\n",
      "  lr_min_factor: 0.001\n",
      "  T0: 10\n",
      "  T_mul: 1.0\n",
      "validation:\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: False\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "augmentation:\n",
      "  use_random_crop: True\n",
      "  use_random_horizontal_flip: True\n",
      "  use_cutout: False\n",
      "  use_random_erasing: False\n",
      "  use_dual_cutout: False\n",
      "  use_mixup: False\n",
      "  use_ricap: False\n",
      "  use_cutmix: False\n",
      "  use_label_smoothing: False\n",
      "  random_crop:\n",
      "    padding: 4\n",
      "    fill: 0\n",
      "    padding_mode: constant\n",
      "  random_horizontal_flip:\n",
      "    prob: 0.5\n",
      "  cutout:\n",
      "    prob: 1.0\n",
      "    mask_size: 16\n",
      "    cut_inside: False\n",
      "    mask_color: 0\n",
      "    dual_cutout_alpha: 0.1\n",
      "  random_erasing:\n",
      "    prob: 0.5\n",
      "    area_ratio_range: [0.02, 0.4]\n",
      "    min_aspect_ratio: 0.3\n",
      "    max_attempt: 20\n",
      "  mixup:\n",
      "    alpha: 1.0\n",
      "  ricap:\n",
      "    beta: 0.3\n",
      "  cutmix:\n",
      "    alpha: 1.0\n",
      "  label_smoothing:\n",
      "    epsilon: 0.1\n",
      "tta:\n",
      "  use_resize: False\n",
      "  use_center_crop: False\n",
      "  resize: 256\n",
      "test:\n",
      "  checkpoint: ''\n",
      "  output_dir: ''\n",
      "  batch_size: 128\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    pin_memory: False\n",
      "\u001b[32m[2020-07-01 00:19:54] __main__ INFO: \u001b[0menv_info:\n",
      "  pytorch_version: 1.4.0\n",
      "  cuda_version: 10.1\n",
      "  cudnn_version: 7603\n",
      "  num_gpus: 1\n",
      "  gpu_name: Tesla K80\n",
      "  gpu_capability: 3.7\n",
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /home/ec2-user/.torch/datasets/CIFAR10/cifar-10-python.tar.gz\n",
      "170500096it [00:02, 72946899.02it/s]                                            \n",
      "Extracting /home/ec2-user/.torch/datasets/CIFAR10/cifar-10-python.tar.gz to /home/ec2-user/.torch/datasets/CIFAR10\n",
      "\u001b[32m[2020-07-01 00:20:02] __main__ INFO: \u001b[0mMACs  : 2.75G\n",
      "\u001b[32m[2020-07-01 00:20:02] __main__ INFO: \u001b[0m#params: 17.56M\n",
      "Selected optimization level O0:  Pure FP32 training.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n",
      "\u001b[32m[2020-07-01 00:20:02] __main__ INFO: \u001b[0mVal 0\n",
      "\u001b[32m[2020-07-01 00:20:28] __main__ INFO: \u001b[0mEpoch 0 loss 1.4021 acc@1 0.6340 acc@5 0.9480\n",
      "\u001b[32m[2020-07-01 00:20:28] __main__ INFO: \u001b[0mElapsed 25.35\n",
      "\u001b[32m[2020-07-01 00:20:28] __main__ INFO: \u001b[0mTrain 1 0\n",
      "\u001b[32m[2020-07-01 00:22:54] __main__ INFO: \u001b[0mEpoch 1 Step 100/351 lr 0.001000 loss 0.3317 (0.5652) acc@1 0.8828 (0.8110) acc@5 0.9922 (0.9861)\n",
      "\u001b[32m[2020-07-01 00:25:12] __main__ INFO: \u001b[0mEpoch 1 Step 200/351 lr 0.001000 loss 0.4806 (0.5140) acc@1 0.8281 (0.8270) acc@5 0.9922 (0.9891)\n",
      "\u001b[32m[2020-07-01 00:27:30] __main__ INFO: \u001b[0mEpoch 1 Step 300/351 lr 0.001000 loss 0.3178 (0.4810) acc@1 0.8828 (0.8377) acc@5 1.0000 (0.9907)\n",
      "\u001b[32m[2020-07-01 00:28:41] __main__ INFO: \u001b[0mEpoch 1 Step 351/351 lr 0.001000 loss 0.3990 (0.4698) acc@1 0.8828 (0.8415) acc@5 1.0000 (0.9911)\n",
      "\u001b[32m[2020-07-01 00:28:41] __main__ INFO: \u001b[0mElapsed 493.08\n",
      "\u001b[32m[2020-07-01 00:28:41] __main__ INFO: \u001b[0mVal 1\n",
      "\u001b[32m[2020-07-01 00:28:58] __main__ INFO: \u001b[0mEpoch 1 loss 0.4336 acc@1 0.8530 acc@5 0.9954\n",
      "\u001b[32m[2020-07-01 00:28:58] __main__ INFO: \u001b[0mElapsed 17.35\n",
      "\u001b[32m[2020-07-01 00:28:58] __main__ INFO: \u001b[0mTrain 2 351\n",
      "\u001b[32m[2020-07-01 00:31:16] __main__ INFO: \u001b[0mEpoch 2 Step 100/351 lr 0.001000 loss 0.2316 (0.3345) acc@1 0.8984 (0.8892) acc@5 0.9922 (0.9961)\n",
      "\u001b[32m[2020-07-01 00:33:35] __main__ INFO: \u001b[0mEpoch 2 Step 200/351 lr 0.001000 loss 0.4868 (0.3321) acc@1 0.8281 (0.8880) acc@5 1.0000 (0.9961)\n",
      "\u001b[32m[2020-07-01 00:35:53] __main__ INFO: \u001b[0mEpoch 2 Step 300/351 lr 0.001000 loss 0.2135 (0.3305) acc@1 0.9297 (0.8880) acc@5 1.0000 (0.9964)\n",
      "\u001b[32m[2020-07-01 00:37:03] __main__ INFO: \u001b[0mEpoch 2 Step 351/351 lr 0.001000 loss 0.5767 (0.3301) acc@1 0.8125 (0.8885) acc@5 0.9844 (0.9965)\n",
      "\u001b[32m[2020-07-01 00:37:03] __main__ INFO: \u001b[0mElapsed 485.36\n",
      "\u001b[32m[2020-07-01 00:37:03] __main__ INFO: \u001b[0mVal 2\n",
      "\u001b[32m[2020-07-01 00:37:21] __main__ INFO: \u001b[0mEpoch 2 loss 0.3844 acc@1 0.8694 acc@5 0.9956\n",
      "\u001b[32m[2020-07-01 00:37:21] __main__ INFO: \u001b[0mElapsed 17.32\n",
      "\u001b[32m[2020-07-01 00:37:21] __main__ INFO: \u001b[0mTrain 3 702\n",
      "\u001b[32m[2020-07-01 00:39:39] __main__ INFO: \u001b[0mEpoch 3 Step 100/351 lr 0.001000 loss 0.2059 (0.2781) acc@1 0.9375 (0.9094) acc@5 1.0000 (0.9971)\n",
      "\u001b[32m[2020-07-01 00:41:57] __main__ INFO: \u001b[0mEpoch 3 Step 200/351 lr 0.001000 loss 0.3360 (0.2748) acc@1 0.8828 (0.9105) acc@5 0.9922 (0.9974)\n",
      "\u001b[32m[2020-07-01 00:44:16] __main__ INFO: \u001b[0mEpoch 3 Step 300/351 lr 0.001000 loss 0.2640 (0.2711) acc@1 0.9297 (0.9110) acc@5 0.9844 (0.9973)\n",
      "\u001b[32m[2020-07-01 00:45:26] __main__ INFO: \u001b[0mEpoch 3 Step 351/351 lr 0.001000 loss 0.3088 (0.2715) acc@1 0.8906 (0.9108) acc@5 1.0000 (0.9974)\n",
      "\u001b[32m[2020-07-01 00:45:26] __main__ INFO: \u001b[0mElapsed 485.26\n",
      "\u001b[32m[2020-07-01 00:45:26] __main__ INFO: \u001b[0mVal 3\n",
      "\u001b[32m[2020-07-01 00:45:43] __main__ INFO: \u001b[0mEpoch 3 loss 0.3726 acc@1 0.8726 acc@5 0.9960\n",
      "\u001b[32m[2020-07-01 00:45:43] __main__ INFO: \u001b[0mElapsed 17.34\n",
      "\u001b[32m[2020-07-01 00:45:43] __main__ INFO: \u001b[0mTrain 4 1053\n",
      "\u001b[32m[2020-07-01 00:48:02] __main__ INFO: \u001b[0mEpoch 4 Step 100/351 lr 0.001000 loss 0.2346 (0.2406) acc@1 0.9375 (0.9227) acc@5 1.0000 (0.9979)\n",
      "\u001b[32m[2020-07-01 00:50:20] __main__ INFO: \u001b[0mEpoch 4 Step 200/351 lr 0.001000 loss 0.2648 (0.2341) acc@1 0.9141 (0.9255) acc@5 1.0000 (0.9981)\n",
      "\u001b[32m[2020-07-01 00:52:38] __main__ INFO: \u001b[0mEpoch 4 Step 300/351 lr 0.001000 loss 0.2191 (0.2316) acc@1 0.9375 (0.9256) acc@5 0.9922 (0.9982)\n",
      "\u001b[32m[2020-07-01 00:53:49] __main__ INFO: \u001b[0mEpoch 4 Step 351/351 lr 0.001000 loss 0.2859 (0.2307) acc@1 0.8906 (0.9259) acc@5 1.0000 (0.9982)\n",
      "\u001b[32m[2020-07-01 00:53:49] __main__ INFO: \u001b[0mElapsed 485.31\n",
      "\u001b[32m[2020-07-01 00:53:49] __main__ INFO: \u001b[0mVal 4\n",
      "\u001b[32m[2020-07-01 00:54:06] __main__ INFO: \u001b[0mEpoch 4 loss 0.3502 acc@1 0.8832 acc@5 0.9964\n",
      "\u001b[32m[2020-07-01 00:54:06] __main__ INFO: \u001b[0mElapsed 17.33\n",
      "\u001b[32m[2020-07-01 00:54:06] __main__ INFO: \u001b[0mTrain 5 1404\n",
      "\u001b[32m[2020-07-01 00:56:24] __main__ INFO: \u001b[0mEpoch 5 Step 100/351 lr 0.001000 loss 0.1374 (0.1956) acc@1 0.9609 (0.9405) acc@5 1.0000 (0.9984)\n",
      "\u001b[32m[2020-07-01 00:58:43] __main__ INFO: \u001b[0mEpoch 5 Step 200/351 lr 0.001000 loss 0.2685 (0.2004) acc@1 0.8828 (0.9377) acc@5 0.9922 (0.9986)\n",
      "\u001b[32m[2020-07-01 01:01:01] __main__ INFO: \u001b[0mEpoch 5 Step 300/351 lr 0.001000 loss 0.2117 (0.2019) acc@1 0.9219 (0.9366) acc@5 1.0000 (0.9985)\n",
      "\u001b[32m[2020-07-01 01:02:11] __main__ INFO: \u001b[0mEpoch 5 Step 351/351 lr 0.001000 loss 0.1317 (0.2030) acc@1 0.9766 (0.9362) acc@5 0.9922 (0.9984)\n",
      "\u001b[32m[2020-07-01 01:02:11] __main__ INFO: \u001b[0mElapsed 485.47\n",
      "\u001b[32m[2020-07-01 01:02:11] __main__ INFO: \u001b[0mVal 5\n",
      "\u001b[32m[2020-07-01 01:02:29] __main__ INFO: \u001b[0mEpoch 5 loss 0.3460 acc@1 0.8856 acc@5 0.9960\n",
      "\u001b[32m[2020-07-01 01:02:29] __main__ INFO: \u001b[0mElapsed 17.35\n",
      "\u001b[32m[2020-07-01 01:02:29] __main__ INFO: \u001b[0mTrain 6 1755\n",
      "\u001b[32m[2020-07-01 01:04:47] __main__ INFO: \u001b[0mEpoch 6 Step 100/351 lr 0.001000 loss 0.1374 (0.1686) acc@1 0.9453 (0.9502) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-01 01:07:05] __main__ INFO: \u001b[0mEpoch 6 Step 200/351 lr 0.001000 loss 0.2370 (0.1740) acc@1 0.9219 (0.9480) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-07-01 01:09:24] __main__ INFO: \u001b[0mEpoch 6 Step 300/351 lr 0.001000 loss 0.2030 (0.1766) acc@1 0.9219 (0.9474) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-07-01 01:10:34] __main__ INFO: \u001b[0mEpoch 6 Step 351/351 lr 0.001000 loss 0.1841 (0.1766) acc@1 0.9531 (0.9470) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-07-01 01:10:34] __main__ INFO: \u001b[0mElapsed 485.47\n",
      "\u001b[32m[2020-07-01 01:10:34] __main__ INFO: \u001b[0mVal 6\n",
      "\u001b[32m[2020-07-01 01:10:52] __main__ INFO: \u001b[0mEpoch 6 loss 0.3384 acc@1 0.8878 acc@5 0.9966\n",
      "\u001b[32m[2020-07-01 01:10:52] __main__ INFO: \u001b[0mElapsed 17.33\n",
      "\u001b[32m[2020-07-01 01:10:52] __main__ INFO: \u001b[0mTrain 7 2106\n",
      "\u001b[32m[2020-07-01 01:13:10] __main__ INFO: \u001b[0mEpoch 7 Step 100/351 lr 0.001000 loss 0.1768 (0.1556) acc@1 0.9453 (0.9559) acc@5 0.9922 (0.9995)\n",
      "\u001b[32m[2020-07-01 01:15:28] __main__ INFO: \u001b[0mEpoch 7 Step 200/351 lr 0.001000 loss 0.1388 (0.1533) acc@1 0.9609 (0.9563) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-01 01:17:47] __main__ INFO: \u001b[0mEpoch 7 Step 300/351 lr 0.001000 loss 0.1065 (0.1551) acc@1 0.9766 (0.9547) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-07-01 01:18:57] __main__ INFO: \u001b[0mEpoch 7 Step 351/351 lr 0.001000 loss 0.1155 (0.1545) acc@1 0.9609 (0.9547) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-07-01 01:18:57] __main__ INFO: \u001b[0mElapsed 485.42\n",
      "\u001b[32m[2020-07-01 01:18:57] __main__ INFO: \u001b[0mVal 7\n",
      "\u001b[32m[2020-07-01 01:19:14] __main__ INFO: \u001b[0mEpoch 7 loss 0.3401 acc@1 0.8860 acc@5 0.9966\n",
      "\u001b[32m[2020-07-01 01:19:14] __main__ INFO: \u001b[0mElapsed 17.35\n",
      "\u001b[32m[2020-07-01 01:19:14] __main__ INFO: \u001b[0mTrain 8 2457\n",
      "\u001b[32m[2020-07-01 01:21:33] __main__ INFO: \u001b[0mEpoch 8 Step 100/351 lr 0.001000 loss 0.1874 (0.1326) acc@1 0.9219 (0.9627) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-01 01:23:51] __main__ INFO: \u001b[0mEpoch 8 Step 200/351 lr 0.001000 loss 0.1048 (0.1356) acc@1 0.9844 (0.9626) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-07-01 01:26:09] __main__ INFO: \u001b[0mEpoch 8 Step 300/351 lr 0.001000 loss 0.1385 (0.1348) acc@1 0.9688 (0.9616) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-01 01:27:20] __main__ INFO: \u001b[0mEpoch 8 Step 351/351 lr 0.001000 loss 0.0981 (0.1353) acc@1 0.9766 (0.9615) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-01 01:27:20] __main__ INFO: \u001b[0mElapsed 485.38\n",
      "\u001b[32m[2020-07-01 01:27:20] __main__ INFO: \u001b[0mVal 8\n",
      "\u001b[32m[2020-07-01 01:27:37] __main__ INFO: \u001b[0mEpoch 8 loss 0.3359 acc@1 0.8892 acc@5 0.9964\n",
      "\u001b[32m[2020-07-01 01:27:37] __main__ INFO: \u001b[0mElapsed 17.31\n",
      "\u001b[32m[2020-07-01 01:27:37] __main__ INFO: \u001b[0mTrain 9 2808\n",
      "\u001b[32m[2020-07-01 01:29:55] __main__ INFO: \u001b[0mEpoch 9 Step 100/351 lr 0.001000 loss 0.1187 (0.1151) acc@1 0.9688 (0.9707) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-01 01:32:14] __main__ INFO: \u001b[0mEpoch 9 Step 200/351 lr 0.001000 loss 0.1438 (0.1173) acc@1 0.9688 (0.9695) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-01 01:34:32] __main__ INFO: \u001b[0mEpoch 9 Step 300/351 lr 0.001000 loss 0.1006 (0.1175) acc@1 0.9844 (0.9686) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-01 01:35:42] __main__ INFO: \u001b[0mEpoch 9 Step 351/351 lr 0.001000 loss 0.0933 (0.1179) acc@1 0.9609 (0.9683) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-01 01:35:42] __main__ INFO: \u001b[0mElapsed 485.24\n",
      "\u001b[32m[2020-07-01 01:35:42] __main__ INFO: \u001b[0mVal 9\n",
      "\u001b[32m[2020-07-01 01:36:00] __main__ INFO: \u001b[0mEpoch 9 loss 0.3386 acc@1 0.8868 acc@5 0.9966\n",
      "\u001b[32m[2020-07-01 01:36:00] __main__ INFO: \u001b[0mElapsed 17.34\n",
      "\u001b[32m[2020-07-01 01:36:00] __main__ INFO: \u001b[0mTrain 10 3159\n",
      "\u001b[32m[2020-07-01 01:38:18] __main__ INFO: \u001b[0mEpoch 10 Step 100/351 lr 0.001000 loss 0.1075 (0.0966) acc@1 0.9688 (0.9767) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-01 01:40:36] __main__ INFO: \u001b[0mEpoch 10 Step 200/351 lr 0.001000 loss 0.0832 (0.0982) acc@1 0.9844 (0.9763) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-01 01:42:55] __main__ INFO: \u001b[0mEpoch 10 Step 300/351 lr 0.001000 loss 0.1053 (0.1003) acc@1 0.9688 (0.9749) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-01 01:44:05] __main__ INFO: \u001b[0mEpoch 10 Step 351/351 lr 0.001000 loss 0.1130 (0.1025) acc@1 0.9688 (0.9739) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-01 01:44:05] __main__ INFO: \u001b[0mElapsed 485.43\n",
      "\u001b[32m[2020-07-01 01:44:05] __main__ INFO: \u001b[0mVal 10\n",
      "\u001b[32m[2020-07-01 01:44:22] __main__ INFO: \u001b[0mEpoch 10 loss 0.3381 acc@1 0.8918 acc@5 0.9958\n",
      "\u001b[32m[2020-07-01 01:44:22] __main__ INFO: \u001b[0mElapsed 17.36\n",
      "\u001b[32m[2020-07-01 01:44:22] __main__ INFO: \u001b[0mTrain 11 3510\n",
      "\u001b[32m[2020-07-01 01:46:41] __main__ INFO: \u001b[0mEpoch 11 Step 100/351 lr 0.001000 loss 0.0623 (0.0835) acc@1 0.9922 (0.9818) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-01 01:48:59] __main__ INFO: \u001b[0mEpoch 11 Step 200/351 lr 0.001000 loss 0.1252 (0.0864) acc@1 0.9375 (0.9802) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-01 01:51:17] __main__ INFO: \u001b[0mEpoch 11 Step 300/351 lr 0.001000 loss 0.0958 (0.0875) acc@1 0.9766 (0.9795) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-01 01:52:28] __main__ INFO: \u001b[0mEpoch 11 Step 351/351 lr 0.001000 loss 0.0623 (0.0888) acc@1 0.9922 (0.9789) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-01 01:52:28] __main__ INFO: \u001b[0mElapsed 485.29\n",
      "\u001b[32m[2020-07-01 01:52:28] __main__ INFO: \u001b[0mVal 11\n",
      "\u001b[32m[2020-07-01 01:52:45] __main__ INFO: \u001b[0mEpoch 11 loss 0.3283 acc@1 0.8936 acc@5 0.9968\n",
      "\u001b[32m[2020-07-01 01:52:45] __main__ INFO: \u001b[0mElapsed 17.32\n",
      "\u001b[32m[2020-07-01 01:52:45] __main__ INFO: \u001b[0mTrain 12 3861\n",
      "\u001b[32m[2020-07-01 01:55:03] __main__ INFO: \u001b[0mEpoch 12 Step 100/351 lr 0.001000 loss 0.0680 (0.0771) acc@1 0.9844 (0.9845) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-01 01:57:22] __main__ INFO: \u001b[0mEpoch 12 Step 200/351 lr 0.001000 loss 0.0537 (0.0785) acc@1 0.9922 (0.9838) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-01 01:59:40] __main__ INFO: \u001b[0mEpoch 12 Step 300/351 lr 0.001000 loss 0.1191 (0.0803) acc@1 0.9609 (0.9823) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-01 02:00:50] __main__ INFO: \u001b[0mEpoch 12 Step 351/351 lr 0.001000 loss 0.0353 (0.0811) acc@1 1.0000 (0.9816) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-01 02:00:50] __main__ INFO: \u001b[0mElapsed 485.38\n",
      "\u001b[32m[2020-07-01 02:00:50] __main__ INFO: \u001b[0mVal 12\n",
      "\u001b[32m[2020-07-01 02:01:08] __main__ INFO: \u001b[0mEpoch 12 loss 0.3495 acc@1 0.8922 acc@5 0.9974\n",
      "\u001b[32m[2020-07-01 02:01:08] __main__ INFO: \u001b[0mElapsed 17.36\n",
      "\u001b[32m[2020-07-01 02:01:08] __main__ INFO: \u001b[0mTrain 13 4212\n",
      "\u001b[32m[2020-07-01 02:03:26] __main__ INFO: \u001b[0mEpoch 13 Step 100/351 lr 0.001000 loss 0.0910 (0.0716) acc@1 0.9766 (0.9845) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-01 02:05:44] __main__ INFO: \u001b[0mEpoch 13 Step 200/351 lr 0.001000 loss 0.0817 (0.0703) acc@1 0.9766 (0.9850) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 02:08:03] __main__ INFO: \u001b[0mEpoch 13 Step 300/351 lr 0.001000 loss 0.0903 (0.0711) acc@1 0.9766 (0.9847) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-01 02:09:13] __main__ INFO: \u001b[0mEpoch 13 Step 351/351 lr 0.001000 loss 0.0429 (0.0713) acc@1 1.0000 (0.9846) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-01 02:09:13] __main__ INFO: \u001b[0mElapsed 485.27\n",
      "\u001b[32m[2020-07-01 02:09:13] __main__ INFO: \u001b[0mVal 13\n",
      "\u001b[32m[2020-07-01 02:09:30] __main__ INFO: \u001b[0mEpoch 13 loss 0.3419 acc@1 0.8918 acc@5 0.9966\n",
      "\u001b[32m[2020-07-01 02:09:30] __main__ INFO: \u001b[0mElapsed 17.36\n",
      "\u001b[32m[2020-07-01 02:09:30] __main__ INFO: \u001b[0mTrain 14 4563\n",
      "\u001b[32m[2020-07-01 02:11:49] __main__ INFO: \u001b[0mEpoch 14 Step 100/351 lr 0.001000 loss 0.0793 (0.0605) acc@1 0.9688 (0.9888) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 02:14:07] __main__ INFO: \u001b[0mEpoch 14 Step 200/351 lr 0.001000 loss 0.0741 (0.0613) acc@1 0.9844 (0.9881) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 02:16:25] __main__ INFO: \u001b[0mEpoch 14 Step 300/351 lr 0.001000 loss 0.0746 (0.0625) acc@1 0.9844 (0.9878) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-01 02:17:36] __main__ INFO: \u001b[0mEpoch 14 Step 351/351 lr 0.001000 loss 0.0591 (0.0628) acc@1 0.9844 (0.9876) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-01 02:17:36] __main__ INFO: \u001b[0mElapsed 485.20\n",
      "\u001b[32m[2020-07-01 02:17:36] __main__ INFO: \u001b[0mVal 14\n",
      "\u001b[32m[2020-07-01 02:17:53] __main__ INFO: \u001b[0mEpoch 14 loss 0.3417 acc@1 0.8940 acc@5 0.9958\n",
      "\u001b[32m[2020-07-01 02:17:53] __main__ INFO: \u001b[0mElapsed 17.32\n",
      "\u001b[32m[2020-07-01 02:17:53] __main__ INFO: \u001b[0mTrain 15 4914\n",
      "\u001b[32m[2020-07-01 02:20:11] __main__ INFO: \u001b[0mEpoch 15 Step 100/351 lr 0.001000 loss 0.0562 (0.0540) acc@1 0.9922 (0.9906) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-01 02:22:30] __main__ INFO: \u001b[0mEpoch 15 Step 200/351 lr 0.001000 loss 0.0507 (0.0562) acc@1 0.9922 (0.9893) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-01 02:24:48] __main__ INFO: \u001b[0mEpoch 15 Step 300/351 lr 0.001000 loss 0.0749 (0.0564) acc@1 0.9766 (0.9895) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-01 02:25:58] __main__ INFO: \u001b[0mEpoch 15 Step 351/351 lr 0.001000 loss 0.0476 (0.0563) acc@1 1.0000 (0.9892) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 02:25:58] __main__ INFO: \u001b[0mElapsed 485.40\n",
      "\u001b[32m[2020-07-01 02:25:58] __main__ INFO: \u001b[0mVal 15\n",
      "\u001b[32m[2020-07-01 02:26:16] __main__ INFO: \u001b[0mEpoch 15 loss 0.3355 acc@1 0.8994 acc@5 0.9964\n",
      "\u001b[32m[2020-07-01 02:26:16] __main__ INFO: \u001b[0mElapsed 17.32\n",
      "\u001b[32m[2020-07-01 02:26:16] __main__ INFO: \u001b[0mTrain 16 5265\n",
      "\u001b[32m[2020-07-01 02:28:34] __main__ INFO: \u001b[0mEpoch 16 Step 100/351 lr 0.001000 loss 0.0472 (0.0474) acc@1 1.0000 (0.9908) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 02:30:52] __main__ INFO: \u001b[0mEpoch 16 Step 200/351 lr 0.001000 loss 0.0486 (0.0492) acc@1 0.9922 (0.9909) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 02:33:11] __main__ INFO: \u001b[0mEpoch 16 Step 300/351 lr 0.001000 loss 0.0388 (0.0495) acc@1 1.0000 (0.9910) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 02:34:21] __main__ INFO: \u001b[0mEpoch 16 Step 351/351 lr 0.001000 loss 0.0835 (0.0498) acc@1 0.9844 (0.9909) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 02:34:21] __main__ INFO: \u001b[0mElapsed 485.43\n",
      "\u001b[32m[2020-07-01 02:34:21] __main__ INFO: \u001b[0mVal 16\n",
      "\u001b[32m[2020-07-01 02:34:38] __main__ INFO: \u001b[0mEpoch 16 loss 0.3353 acc@1 0.8956 acc@5 0.9960\n",
      "\u001b[32m[2020-07-01 02:34:38] __main__ INFO: \u001b[0mElapsed 17.34\n",
      "\u001b[32m[2020-07-01 02:34:38] __main__ INFO: \u001b[0mTrain 17 5616\n",
      "\u001b[32m[2020-07-01 02:36:57] __main__ INFO: \u001b[0mEpoch 17 Step 100/351 lr 0.001000 loss 0.0271 (0.0466) acc@1 1.0000 (0.9923) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 02:39:15] __main__ INFO: \u001b[0mEpoch 17 Step 200/351 lr 0.001000 loss 0.0231 (0.0460) acc@1 1.0000 (0.9920) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 02:41:33] __main__ INFO: \u001b[0mEpoch 17 Step 300/351 lr 0.001000 loss 0.0443 (0.0457) acc@1 1.0000 (0.9922) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 02:42:44] __main__ INFO: \u001b[0mEpoch 17 Step 351/351 lr 0.001000 loss 0.0650 (0.0457) acc@1 0.9922 (0.9921) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 02:42:44] __main__ INFO: \u001b[0mElapsed 485.45\n",
      "\u001b[32m[2020-07-01 02:42:44] __main__ INFO: \u001b[0mVal 17\n",
      "\u001b[32m[2020-07-01 02:43:01] __main__ INFO: \u001b[0mEpoch 17 loss 0.3354 acc@1 0.8942 acc@5 0.9964\n",
      "\u001b[32m[2020-07-01 02:43:01] __main__ INFO: \u001b[0mElapsed 17.34\n",
      "\u001b[32m[2020-07-01 02:43:01] __main__ INFO: \u001b[0mTrain 18 5967\n",
      "\u001b[32m[2020-07-01 02:45:20] __main__ INFO: \u001b[0mEpoch 18 Step 100/351 lr 0.001000 loss 0.0479 (0.0388) acc@1 0.9922 (0.9950) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 02:47:38] __main__ INFO: \u001b[0mEpoch 18 Step 200/351 lr 0.001000 loss 0.0465 (0.0397) acc@1 0.9922 (0.9946) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 02:49:56] __main__ INFO: \u001b[0mEpoch 18 Step 300/351 lr 0.001000 loss 0.0179 (0.0403) acc@1 1.0000 (0.9941) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 02:51:07] __main__ INFO: \u001b[0mEpoch 18 Step 351/351 lr 0.001000 loss 0.0264 (0.0408) acc@1 0.9922 (0.9940) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 02:51:07] __main__ INFO: \u001b[0mElapsed 485.24\n",
      "\u001b[32m[2020-07-01 02:51:07] __main__ INFO: \u001b[0mVal 18\n",
      "\u001b[32m[2020-07-01 02:51:24] __main__ INFO: \u001b[0mEpoch 18 loss 0.3366 acc@1 0.8958 acc@5 0.9960\n",
      "\u001b[32m[2020-07-01 02:51:24] __main__ INFO: \u001b[0mElapsed 17.35\n",
      "\u001b[32m[2020-07-01 02:51:24] __main__ INFO: \u001b[0mTrain 19 6318\n",
      "\u001b[32m[2020-07-01 02:53:42] __main__ INFO: \u001b[0mEpoch 19 Step 100/351 lr 0.001000 loss 0.0248 (0.0356) acc@1 1.0000 (0.9952) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 02:56:01] __main__ INFO: \u001b[0mEpoch 19 Step 200/351 lr 0.001000 loss 0.0231 (0.0362) acc@1 1.0000 (0.9954) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 02:58:19] __main__ INFO: \u001b[0mEpoch 19 Step 300/351 lr 0.001000 loss 0.0407 (0.0363) acc@1 0.9922 (0.9951) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 02:59:29] __main__ INFO: \u001b[0mEpoch 19 Step 351/351 lr 0.001000 loss 0.0506 (0.0366) acc@1 0.9844 (0.9948) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 02:59:29] __main__ INFO: \u001b[0mElapsed 485.40\n",
      "\u001b[32m[2020-07-01 02:59:29] __main__ INFO: \u001b[0mVal 19\n",
      "\u001b[32m[2020-07-01 02:59:47] __main__ INFO: \u001b[0mEpoch 19 loss 0.3530 acc@1 0.8980 acc@5 0.9966\n",
      "\u001b[32m[2020-07-01 02:59:47] __main__ INFO: \u001b[0mElapsed 17.36\n",
      "\u001b[32m[2020-07-01 02:59:47] __main__ INFO: \u001b[0mTrain 20 6669\n",
      "\u001b[32m[2020-07-01 03:02:05] __main__ INFO: \u001b[0mEpoch 20 Step 100/351 lr 0.001000 loss 0.0344 (0.0334) acc@1 1.0000 (0.9962) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 03:04:23] __main__ INFO: \u001b[0mEpoch 20 Step 200/351 lr 0.001000 loss 0.0425 (0.0329) acc@1 0.9922 (0.9965) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 03:06:42] __main__ INFO: \u001b[0mEpoch 20 Step 300/351 lr 0.001000 loss 0.0352 (0.0340) acc@1 1.0000 (0.9958) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 03:07:52] __main__ INFO: \u001b[0mEpoch 20 Step 351/351 lr 0.001000 loss 0.0421 (0.0344) acc@1 0.9922 (0.9958) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 03:07:52] __main__ INFO: \u001b[0mElapsed 485.47\n",
      "\u001b[32m[2020-07-01 03:07:52] __main__ INFO: \u001b[0mVal 20\n",
      "\u001b[32m[2020-07-01 03:08:09] __main__ INFO: \u001b[0mEpoch 20 loss 0.3366 acc@1 0.8988 acc@5 0.9958\n",
      "\u001b[32m[2020-07-01 03:08:09] __main__ INFO: \u001b[0mElapsed 17.35\n",
      "\u001b[32m[2020-07-01 03:08:09] __main__ INFO: \u001b[0mTrain 21 7020\n",
      "\u001b[32m[2020-07-01 03:10:28] __main__ INFO: \u001b[0mEpoch 21 Step 100/351 lr 0.001000 loss 0.0225 (0.0298) acc@1 1.0000 (0.9970) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 03:12:46] __main__ INFO: \u001b[0mEpoch 21 Step 200/351 lr 0.001000 loss 0.0272 (0.0291) acc@1 1.0000 (0.9972) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 03:15:04] __main__ INFO: \u001b[0mEpoch 21 Step 300/351 lr 0.001000 loss 0.0421 (0.0299) acc@1 0.9922 (0.9968) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 03:16:15] __main__ INFO: \u001b[0mEpoch 21 Step 351/351 lr 0.001000 loss 0.0290 (0.0298) acc@1 0.9922 (0.9966) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 03:16:15] __main__ INFO: \u001b[0mElapsed 485.36\n",
      "\u001b[32m[2020-07-01 03:16:15] __main__ INFO: \u001b[0mVal 21\n",
      "\u001b[32m[2020-07-01 03:16:32] __main__ INFO: \u001b[0mEpoch 21 loss 0.3417 acc@1 0.8982 acc@5 0.9950\n",
      "\u001b[32m[2020-07-01 03:16:32] __main__ INFO: \u001b[0mElapsed 17.37\n",
      "\u001b[32m[2020-07-01 03:16:32] __main__ INFO: \u001b[0mTrain 22 7371\n",
      "\u001b[32m[2020-07-01 03:18:51] __main__ INFO: \u001b[0mEpoch 22 Step 100/351 lr 0.001000 loss 0.0442 (0.0267) acc@1 0.9844 (0.9974) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 03:21:09] __main__ INFO: \u001b[0mEpoch 22 Step 200/351 lr 0.001000 loss 0.0191 (0.0273) acc@1 1.0000 (0.9972) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 03:23:27] __main__ INFO: \u001b[0mEpoch 22 Step 300/351 lr 0.001000 loss 0.0180 (0.0278) acc@1 1.0000 (0.9969) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 03:24:38] __main__ INFO: \u001b[0mEpoch 22 Step 351/351 lr 0.001000 loss 0.0252 (0.0279) acc@1 1.0000 (0.9970) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 03:24:38] __main__ INFO: \u001b[0mElapsed 485.40\n",
      "\u001b[32m[2020-07-01 03:24:38] __main__ INFO: \u001b[0mVal 22\n",
      "\u001b[32m[2020-07-01 03:24:55] __main__ INFO: \u001b[0mEpoch 22 loss 0.3417 acc@1 0.8980 acc@5 0.9958\n",
      "\u001b[32m[2020-07-01 03:24:55] __main__ INFO: \u001b[0mElapsed 17.35\n",
      "\u001b[32m[2020-07-01 03:24:55] __main__ INFO: \u001b[0mTrain 23 7722\n",
      "\u001b[32m[2020-07-01 03:27:13] __main__ INFO: \u001b[0mEpoch 23 Step 100/351 lr 0.001000 loss 0.0366 (0.0263) acc@1 0.9922 (0.9971) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 03:29:32] __main__ INFO: \u001b[0mEpoch 23 Step 200/351 lr 0.001000 loss 0.0416 (0.0260) acc@1 0.9922 (0.9970) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 03:31:50] __main__ INFO: \u001b[0mEpoch 23 Step 300/351 lr 0.001000 loss 0.0218 (0.0258) acc@1 1.0000 (0.9972) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 03:33:00] __main__ INFO: \u001b[0mEpoch 23 Step 351/351 lr 0.001000 loss 0.0291 (0.0261) acc@1 1.0000 (0.9972) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 03:33:00] __main__ INFO: \u001b[0mElapsed 485.54\n",
      "\u001b[32m[2020-07-01 03:33:00] __main__ INFO: \u001b[0mVal 23\n",
      "\u001b[32m[2020-07-01 03:33:18] __main__ INFO: \u001b[0mEpoch 23 loss 0.3361 acc@1 0.9030 acc@5 0.9962\n",
      "\u001b[32m[2020-07-01 03:33:18] __main__ INFO: \u001b[0mElapsed 17.37\n",
      "\u001b[32m[2020-07-01 03:33:18] __main__ INFO: \u001b[0mTrain 24 8073\n",
      "\u001b[32m[2020-07-01 03:35:36] __main__ INFO: \u001b[0mEpoch 24 Step 100/351 lr 0.001000 loss 0.0345 (0.0229) acc@1 0.9922 (0.9978) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 03:37:55] __main__ INFO: \u001b[0mEpoch 24 Step 200/351 lr 0.001000 loss 0.0236 (0.0234) acc@1 1.0000 (0.9980) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 03:40:13] __main__ INFO: \u001b[0mEpoch 24 Step 300/351 lr 0.001000 loss 0.0205 (0.0242) acc@1 1.0000 (0.9979) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 03:41:23] __main__ INFO: \u001b[0mEpoch 24 Step 351/351 lr 0.001000 loss 0.0223 (0.0244) acc@1 1.0000 (0.9979) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 03:41:23] __main__ INFO: \u001b[0mElapsed 485.45\n",
      "\u001b[32m[2020-07-01 03:41:23] __main__ INFO: \u001b[0mVal 24\n",
      "\u001b[32m[2020-07-01 03:41:41] __main__ INFO: \u001b[0mEpoch 24 loss 0.3359 acc@1 0.8972 acc@5 0.9954\n",
      "\u001b[32m[2020-07-01 03:41:41] __main__ INFO: \u001b[0mElapsed 17.34\n",
      "\u001b[32m[2020-07-01 03:41:41] __main__ INFO: \u001b[0mTrain 25 8424\n",
      "\u001b[32m[2020-07-01 03:43:59] __main__ INFO: \u001b[0mEpoch 25 Step 100/351 lr 0.001000 loss 0.0121 (0.0225) acc@1 1.0000 (0.9977) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 03:46:17] __main__ INFO: \u001b[0mEpoch 25 Step 200/351 lr 0.001000 loss 0.0314 (0.0225) acc@1 0.9922 (0.9979) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 03:48:35] __main__ INFO: \u001b[0mEpoch 25 Step 300/351 lr 0.001000 loss 0.0111 (0.0227) acc@1 1.0000 (0.9978) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 03:49:46] __main__ INFO: \u001b[0mEpoch 25 Step 351/351 lr 0.001000 loss 0.0236 (0.0225) acc@1 0.9922 (0.9979) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 03:49:46] __main__ INFO: \u001b[0mElapsed 485.34\n",
      "\u001b[32m[2020-07-01 03:49:46] __main__ INFO: \u001b[0mVal 25\n",
      "\u001b[32m[2020-07-01 03:50:03] __main__ INFO: \u001b[0mEpoch 25 loss 0.3513 acc@1 0.8988 acc@5 0.9954\n",
      "\u001b[32m[2020-07-01 03:50:03] __main__ INFO: \u001b[0mElapsed 17.33\n",
      "\u001b[32m[2020-07-01 03:50:03] __main__ INFO: \u001b[0mTrain 26 8775\n",
      "\u001b[32m[2020-07-01 03:52:22] __main__ INFO: \u001b[0mEpoch 26 Step 100/351 lr 0.001000 loss 0.0286 (0.0202) acc@1 1.0000 (0.9981) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 03:54:40] __main__ INFO: \u001b[0mEpoch 26 Step 200/351 lr 0.001000 loss 0.0259 (0.0199) acc@1 0.9922 (0.9983) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 03:56:58] __main__ INFO: \u001b[0mEpoch 26 Step 300/351 lr 0.001000 loss 0.0262 (0.0207) acc@1 0.9922 (0.9979) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 03:58:09] __main__ INFO: \u001b[0mEpoch 26 Step 351/351 lr 0.001000 loss 0.0382 (0.0209) acc@1 0.9844 (0.9978) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 03:58:09] __main__ INFO: \u001b[0mElapsed 485.31\n",
      "\u001b[32m[2020-07-01 03:58:09] __main__ INFO: \u001b[0mVal 26\n",
      "\u001b[32m[2020-07-01 03:58:26] __main__ INFO: \u001b[0mEpoch 26 loss 0.3464 acc@1 0.8990 acc@5 0.9952\n",
      "\u001b[32m[2020-07-01 03:58:26] __main__ INFO: \u001b[0mElapsed 17.35\n",
      "\u001b[32m[2020-07-01 03:58:26] __main__ INFO: \u001b[0mTrain 27 9126\n",
      "\u001b[32m[2020-07-01 04:00:44] __main__ INFO: \u001b[0mEpoch 27 Step 100/351 lr 0.001000 loss 0.0105 (0.0191) acc@1 1.0000 (0.9980) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 04:03:03] __main__ INFO: \u001b[0mEpoch 27 Step 200/351 lr 0.001000 loss 0.0180 (0.0189) acc@1 1.0000 (0.9982) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 04:05:21] __main__ INFO: \u001b[0mEpoch 27 Step 300/351 lr 0.001000 loss 0.0161 (0.0195) acc@1 1.0000 (0.9981) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 04:06:31] __main__ INFO: \u001b[0mEpoch 27 Step 351/351 lr 0.001000 loss 0.0150 (0.0198) acc@1 1.0000 (0.9980) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 04:06:31] __main__ INFO: \u001b[0mElapsed 485.24\n",
      "\u001b[32m[2020-07-01 04:06:31] __main__ INFO: \u001b[0mVal 27\n",
      "\u001b[32m[2020-07-01 04:06:49] __main__ INFO: \u001b[0mEpoch 27 loss 0.3436 acc@1 0.8974 acc@5 0.9964\n",
      "\u001b[32m[2020-07-01 04:06:49] __main__ INFO: \u001b[0mElapsed 17.34\n",
      "\u001b[32m[2020-07-01 04:06:49] __main__ INFO: \u001b[0mTrain 28 9477\n",
      "\u001b[32m[2020-07-01 04:09:07] __main__ INFO: \u001b[0mEpoch 28 Step 100/351 lr 0.001000 loss 0.0160 (0.0177) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 04:11:25] __main__ INFO: \u001b[0mEpoch 28 Step 200/351 lr 0.001000 loss 0.0136 (0.0180) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 04:13:43] __main__ INFO: \u001b[0mEpoch 28 Step 300/351 lr 0.001000 loss 0.0266 (0.0180) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 04:14:54] __main__ INFO: \u001b[0mEpoch 28 Step 351/351 lr 0.001000 loss 0.0087 (0.0179) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 04:14:54] __main__ INFO: \u001b[0mElapsed 485.27\n",
      "\u001b[32m[2020-07-01 04:14:54] __main__ INFO: \u001b[0mVal 28\n",
      "\u001b[32m[2020-07-01 04:15:11] __main__ INFO: \u001b[0mEpoch 28 loss 0.3425 acc@1 0.8984 acc@5 0.9960\n",
      "\u001b[32m[2020-07-01 04:15:11] __main__ INFO: \u001b[0mElapsed 17.30\n",
      "\u001b[32m[2020-07-01 04:15:11] __main__ INFO: \u001b[0mTrain 29 9828\n",
      "\u001b[32m[2020-07-01 04:17:29] __main__ INFO: \u001b[0mEpoch 29 Step 100/351 lr 0.001000 loss 0.0195 (0.0178) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 04:19:48] __main__ INFO: \u001b[0mEpoch 29 Step 200/351 lr 0.001000 loss 0.0275 (0.0178) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 04:22:06] __main__ INFO: \u001b[0mEpoch 29 Step 300/351 lr 0.001000 loss 0.0087 (0.0178) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 04:23:16] __main__ INFO: \u001b[0mEpoch 29 Step 351/351 lr 0.001000 loss 0.0119 (0.0179) acc@1 1.0000 (0.9983) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 04:23:17] __main__ INFO: \u001b[0mElapsed 485.35\n",
      "\u001b[32m[2020-07-01 04:23:17] __main__ INFO: \u001b[0mVal 29\n",
      "\u001b[32m[2020-07-01 04:23:34] __main__ INFO: \u001b[0mEpoch 29 loss 0.3420 acc@1 0.9012 acc@5 0.9960\n",
      "\u001b[32m[2020-07-01 04:23:34] __main__ INFO: \u001b[0mElapsed 17.36\n",
      "\u001b[32m[2020-07-01 04:23:34] __main__ INFO: \u001b[0mTrain 30 10179\n",
      "\u001b[32m[2020-07-01 04:25:52] __main__ INFO: \u001b[0mEpoch 30 Step 100/351 lr 0.001000 loss 0.0171 (0.0175) acc@1 1.0000 (0.9980) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 04:28:10] __main__ INFO: \u001b[0mEpoch 30 Step 200/351 lr 0.001000 loss 0.0161 (0.0175) acc@1 1.0000 (0.9977) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 04:30:29] __main__ INFO: \u001b[0mEpoch 30 Step 300/351 lr 0.001000 loss 0.0206 (0.0172) acc@1 1.0000 (0.9981) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 04:31:39] __main__ INFO: \u001b[0mEpoch 30 Step 351/351 lr 0.001000 loss 0.0147 (0.0168) acc@1 1.0000 (0.9983) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 04:31:39] __main__ INFO: \u001b[0mElapsed 485.32\n",
      "\u001b[32m[2020-07-01 04:31:39] __main__ INFO: \u001b[0mVal 30\n",
      "\u001b[32m[2020-07-01 04:31:57] __main__ INFO: \u001b[0mEpoch 30 loss 0.3306 acc@1 0.9026 acc@5 0.9954\n",
      "\u001b[32m[2020-07-01 04:31:57] __main__ INFO: \u001b[0mElapsed 17.32\n",
      "\u001b[32m[2020-07-01 04:31:57] __main__ INFO: \u001b[0mTrain 31 10530\n",
      "\u001b[32m[2020-07-01 04:34:15] __main__ INFO: \u001b[0mEpoch 31 Step 100/351 lr 0.001000 loss 0.0124 (0.0146) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 04:36:33] __main__ INFO: \u001b[0mEpoch 31 Step 200/351 lr 0.001000 loss 0.0117 (0.0147) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 04:38:51] __main__ INFO: \u001b[0mEpoch 31 Step 300/351 lr 0.001000 loss 0.0096 (0.0148) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 04:40:02] __main__ INFO: \u001b[0mEpoch 31 Step 351/351 lr 0.001000 loss 0.0189 (0.0152) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 04:40:02] __main__ INFO: \u001b[0mElapsed 485.20\n",
      "\u001b[32m[2020-07-01 04:40:02] __main__ INFO: \u001b[0mVal 31\n",
      "\u001b[32m[2020-07-01 04:40:19] __main__ INFO: \u001b[0mEpoch 31 loss 0.3536 acc@1 0.8992 acc@5 0.9950\n",
      "\u001b[32m[2020-07-01 04:40:19] __main__ INFO: \u001b[0mElapsed 17.34\n",
      "\u001b[32m[2020-07-01 04:40:19] __main__ INFO: \u001b[0mTrain 32 10881\n",
      "\u001b[32m[2020-07-01 04:42:37] __main__ INFO: \u001b[0mEpoch 32 Step 100/351 lr 0.001000 loss 0.0125 (0.0150) acc@1 1.0000 (0.9983) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 04:44:56] __main__ INFO: \u001b[0mEpoch 32 Step 200/351 lr 0.001000 loss 0.0175 (0.0148) acc@1 0.9922 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 04:47:14] __main__ INFO: \u001b[0mEpoch 32 Step 300/351 lr 0.001000 loss 0.0126 (0.0149) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 04:48:24] __main__ INFO: \u001b[0mEpoch 32 Step 351/351 lr 0.001000 loss 0.0067 (0.0151) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 04:48:24] __main__ INFO: \u001b[0mElapsed 485.29\n",
      "\u001b[32m[2020-07-01 04:48:24] __main__ INFO: \u001b[0mVal 32\n",
      "\u001b[32m[2020-07-01 04:48:42] __main__ INFO: \u001b[0mEpoch 32 loss 0.3534 acc@1 0.8988 acc@5 0.9958\n",
      "\u001b[32m[2020-07-01 04:48:42] __main__ INFO: \u001b[0mElapsed 17.32\n",
      "\u001b[32m[2020-07-01 04:48:42] __main__ INFO: \u001b[0mTrain 33 11232\n",
      "\u001b[32m[2020-07-01 04:51:00] __main__ INFO: \u001b[0mEpoch 33 Step 100/351 lr 0.001000 loss 0.0169 (0.0148) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 04:53:18] __main__ INFO: \u001b[0mEpoch 33 Step 200/351 lr 0.001000 loss 0.0085 (0.0147) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 04:55:36] __main__ INFO: \u001b[0mEpoch 33 Step 300/351 lr 0.001000 loss 0.0086 (0.0144) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 04:56:47] __main__ INFO: \u001b[0mEpoch 33 Step 351/351 lr 0.001000 loss 0.0128 (0.0148) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 04:56:47] __main__ INFO: \u001b[0mElapsed 485.37\n",
      "\u001b[32m[2020-07-01 04:56:47] __main__ INFO: \u001b[0mVal 33\n",
      "\u001b[32m[2020-07-01 04:57:04] __main__ INFO: \u001b[0mEpoch 33 loss 0.3389 acc@1 0.9004 acc@5 0.9956\n",
      "\u001b[32m[2020-07-01 04:57:04] __main__ INFO: \u001b[0mElapsed 17.32\n",
      "\u001b[32m[2020-07-01 04:57:04] __main__ INFO: \u001b[0mTrain 34 11583\n",
      "\u001b[32m[2020-07-01 04:59:23] __main__ INFO: \u001b[0mEpoch 34 Step 100/351 lr 0.001000 loss 0.0178 (0.0133) acc@1 0.9922 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 05:01:41] __main__ INFO: \u001b[0mEpoch 34 Step 200/351 lr 0.001000 loss 0.0261 (0.0132) acc@1 0.9922 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 05:03:59] __main__ INFO: \u001b[0mEpoch 34 Step 300/351 lr 0.001000 loss 0.0127 (0.0135) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 05:05:10] __main__ INFO: \u001b[0mEpoch 34 Step 351/351 lr 0.001000 loss 0.0452 (0.0137) acc@1 0.9766 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 05:05:10] __main__ INFO: \u001b[0mElapsed 485.21\n",
      "\u001b[32m[2020-07-01 05:05:10] __main__ INFO: \u001b[0mVal 34\n",
      "\u001b[32m[2020-07-01 05:05:27] __main__ INFO: \u001b[0mEpoch 34 loss 0.3387 acc@1 0.9008 acc@5 0.9962\n",
      "\u001b[32m[2020-07-01 05:05:27] __main__ INFO: \u001b[0mElapsed 17.35\n",
      "\u001b[32m[2020-07-01 05:05:27] __main__ INFO: \u001b[0mTrain 35 11934\n",
      "\u001b[32m[2020-07-01 05:07:45] __main__ INFO: \u001b[0mEpoch 35 Step 100/351 lr 0.001000 loss 0.0114 (0.0129) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 05:10:03] __main__ INFO: \u001b[0mEpoch 35 Step 200/351 lr 0.001000 loss 0.0052 (0.0128) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 05:12:22] __main__ INFO: \u001b[0mEpoch 35 Step 300/351 lr 0.001000 loss 0.0130 (0.0132) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 05:13:32] __main__ INFO: \u001b[0mEpoch 35 Step 351/351 lr 0.001000 loss 0.0149 (0.0134) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 05:13:32] __main__ INFO: \u001b[0mElapsed 485.37\n",
      "\u001b[32m[2020-07-01 05:13:32] __main__ INFO: \u001b[0mVal 35\n",
      "\u001b[32m[2020-07-01 05:13:50] __main__ INFO: \u001b[0mEpoch 35 loss 0.3450 acc@1 0.9014 acc@5 0.9958\n",
      "\u001b[32m[2020-07-01 05:13:50] __main__ INFO: \u001b[0mElapsed 17.35\n",
      "\u001b[32m[2020-07-01 05:13:50] __main__ INFO: \u001b[0mTrain 36 12285\n",
      "\u001b[32m[2020-07-01 05:16:08] __main__ INFO: \u001b[0mEpoch 36 Step 100/351 lr 0.001000 loss 0.0313 (0.0116) acc@1 0.9922 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 05:18:26] __main__ INFO: \u001b[0mEpoch 36 Step 200/351 lr 0.001000 loss 0.0103 (0.0120) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 05:20:45] __main__ INFO: \u001b[0mEpoch 36 Step 300/351 lr 0.001000 loss 0.0096 (0.0125) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 05:21:55] __main__ INFO: \u001b[0mEpoch 36 Step 351/351 lr 0.001000 loss 0.0140 (0.0128) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 05:21:55] __main__ INFO: \u001b[0mElapsed 485.40\n",
      "\u001b[32m[2020-07-01 05:21:55] __main__ INFO: \u001b[0mVal 36\n",
      "\u001b[32m[2020-07-01 05:22:12] __main__ INFO: \u001b[0mEpoch 36 loss 0.3451 acc@1 0.9018 acc@5 0.9956\n",
      "\u001b[32m[2020-07-01 05:22:12] __main__ INFO: \u001b[0mElapsed 17.31\n",
      "\u001b[32m[2020-07-01 05:22:12] __main__ INFO: \u001b[0mTrain 37 12636\n",
      "\u001b[32m[2020-07-01 05:24:31] __main__ INFO: \u001b[0mEpoch 37 Step 100/351 lr 0.001000 loss 0.0056 (0.0117) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 05:26:49] __main__ INFO: \u001b[0mEpoch 37 Step 200/351 lr 0.001000 loss 0.0110 (0.0117) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 05:29:07] __main__ INFO: \u001b[0mEpoch 37 Step 300/351 lr 0.001000 loss 0.0236 (0.0123) acc@1 0.9922 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 05:30:18] __main__ INFO: \u001b[0mEpoch 37 Step 351/351 lr 0.001000 loss 0.0214 (0.0124) acc@1 0.9922 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 05:30:18] __main__ INFO: \u001b[0mElapsed 485.27\n",
      "\u001b[32m[2020-07-01 05:30:18] __main__ INFO: \u001b[0mVal 37\n",
      "\u001b[32m[2020-07-01 05:30:35] __main__ INFO: \u001b[0mEpoch 37 loss 0.3461 acc@1 0.8994 acc@5 0.9964\n",
      "\u001b[32m[2020-07-01 05:30:35] __main__ INFO: \u001b[0mElapsed 17.34\n",
      "\u001b[32m[2020-07-01 05:30:35] __main__ INFO: \u001b[0mTrain 38 12987\n",
      "\u001b[32m[2020-07-01 05:32:53] __main__ INFO: \u001b[0mEpoch 38 Step 100/351 lr 0.001000 loss 0.0082 (0.0104) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 05:35:12] __main__ INFO: \u001b[0mEpoch 38 Step 200/351 lr 0.001000 loss 0.0117 (0.0113) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 05:37:30] __main__ INFO: \u001b[0mEpoch 38 Step 300/351 lr 0.001000 loss 0.0101 (0.0113) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 05:38:40] __main__ INFO: \u001b[0mEpoch 38 Step 351/351 lr 0.001000 loss 0.0164 (0.0113) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 05:38:40] __main__ INFO: \u001b[0mElapsed 485.51\n",
      "\u001b[32m[2020-07-01 05:38:40] __main__ INFO: \u001b[0mVal 38\n",
      "\u001b[32m[2020-07-01 05:38:58] __main__ INFO: \u001b[0mEpoch 38 loss 0.3413 acc@1 0.9052 acc@5 0.9960\n",
      "\u001b[32m[2020-07-01 05:38:58] __main__ INFO: \u001b[0mElapsed 17.35\n",
      "\u001b[32m[2020-07-01 05:38:58] __main__ INFO: \u001b[0mTrain 39 13338\n",
      "\u001b[32m[2020-07-01 05:41:16] __main__ INFO: \u001b[0mEpoch 39 Step 100/351 lr 0.001000 loss 0.0105 (0.0108) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 05:43:35] __main__ INFO: \u001b[0mEpoch 39 Step 200/351 lr 0.001000 loss 0.0114 (0.0112) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 05:45:53] __main__ INFO: \u001b[0mEpoch 39 Step 300/351 lr 0.001000 loss 0.0098 (0.0117) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 05:47:03] __main__ INFO: \u001b[0mEpoch 39 Step 351/351 lr 0.001000 loss 0.0248 (0.0117) acc@1 0.9922 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 05:47:03] __main__ INFO: \u001b[0mElapsed 485.45\n",
      "\u001b[32m[2020-07-01 05:47:03] __main__ INFO: \u001b[0mVal 39\n",
      "\u001b[32m[2020-07-01 05:47:21] __main__ INFO: \u001b[0mEpoch 39 loss 0.3435 acc@1 0.9024 acc@5 0.9954\n",
      "\u001b[32m[2020-07-01 05:47:21] __main__ INFO: \u001b[0mElapsed 17.37\n",
      "\u001b[32m[2020-07-01 05:47:21] __main__ INFO: \u001b[0mTrain 40 13689\n",
      "\u001b[32m[2020-07-01 05:49:39] __main__ INFO: \u001b[0mEpoch 40 Step 100/351 lr 0.001000 loss 0.0273 (0.0106) acc@1 0.9922 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 05:51:57] __main__ INFO: \u001b[0mEpoch 40 Step 200/351 lr 0.001000 loss 0.0104 (0.0104) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 05:54:16] __main__ INFO: \u001b[0mEpoch 40 Step 300/351 lr 0.001000 loss 0.0062 (0.0106) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 05:55:26] __main__ INFO: \u001b[0mEpoch 40 Step 351/351 lr 0.001000 loss 0.0241 (0.0106) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 05:55:26] __main__ INFO: \u001b[0mElapsed 485.50\n",
      "\u001b[32m[2020-07-01 05:55:26] __main__ INFO: \u001b[0mVal 40\n",
      "\u001b[32m[2020-07-01 05:55:44] __main__ INFO: \u001b[0mEpoch 40 loss 0.3485 acc@1 0.8998 acc@5 0.9958\n",
      "\u001b[32m[2020-07-01 05:55:44] __main__ INFO: \u001b[0mElapsed 17.36\n",
      "\u001b[32m[2020-07-01 05:55:44] __main__ INFO: \u001b[0mTrain 41 14040\n",
      "\u001b[32m[2020-07-01 05:58:02] __main__ INFO: \u001b[0mEpoch 41 Step 100/351 lr 0.001000 loss 0.0118 (0.0099) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 06:00:20] __main__ INFO: \u001b[0mEpoch 41 Step 200/351 lr 0.001000 loss 0.0077 (0.0106) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 06:02:39] __main__ INFO: \u001b[0mEpoch 41 Step 300/351 lr 0.001000 loss 0.0079 (0.0106) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 06:03:49] __main__ INFO: \u001b[0mEpoch 41 Step 351/351 lr 0.001000 loss 0.0077 (0.0109) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 06:03:49] __main__ INFO: \u001b[0mElapsed 485.50\n",
      "\u001b[32m[2020-07-01 06:03:49] __main__ INFO: \u001b[0mVal 41\n",
      "\u001b[32m[2020-07-01 06:04:06] __main__ INFO: \u001b[0mEpoch 41 loss 0.3444 acc@1 0.9022 acc@5 0.9952\n",
      "\u001b[32m[2020-07-01 06:04:06] __main__ INFO: \u001b[0mElapsed 17.37\n",
      "\u001b[32m[2020-07-01 06:04:06] __main__ INFO: \u001b[0mTrain 42 14391\n",
      "\u001b[32m[2020-07-01 06:06:25] __main__ INFO: \u001b[0mEpoch 42 Step 100/351 lr 0.001000 loss 0.0097 (0.0106) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 06:08:43] __main__ INFO: \u001b[0mEpoch 42 Step 200/351 lr 0.001000 loss 0.0075 (0.0101) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 06:11:01] __main__ INFO: \u001b[0mEpoch 42 Step 300/351 lr 0.001000 loss 0.0182 (0.0100) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 06:12:12] __main__ INFO: \u001b[0mEpoch 42 Step 351/351 lr 0.001000 loss 0.0107 (0.0099) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 06:12:12] __main__ INFO: \u001b[0mElapsed 485.48\n",
      "\u001b[32m[2020-07-01 06:12:12] __main__ INFO: \u001b[0mVal 42\n",
      "\u001b[32m[2020-07-01 06:12:29] __main__ INFO: \u001b[0mEpoch 42 loss 0.3426 acc@1 0.9034 acc@5 0.9962\n",
      "\u001b[32m[2020-07-01 06:12:29] __main__ INFO: \u001b[0mElapsed 17.35\n",
      "\u001b[32m[2020-07-01 06:12:29] __main__ INFO: \u001b[0mTrain 43 14742\n",
      "\u001b[32m[2020-07-01 06:14:48] __main__ INFO: \u001b[0mEpoch 43 Step 100/351 lr 0.001000 loss 0.0117 (0.0085) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 06:17:06] __main__ INFO: \u001b[0mEpoch 43 Step 200/351 lr 0.001000 loss 0.0071 (0.0090) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 06:19:24] __main__ INFO: \u001b[0mEpoch 43 Step 300/351 lr 0.001000 loss 0.0084 (0.0093) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 06:20:35] __main__ INFO: \u001b[0mEpoch 43 Step 351/351 lr 0.001000 loss 0.0083 (0.0095) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 06:20:35] __main__ INFO: \u001b[0mElapsed 485.42\n",
      "\u001b[32m[2020-07-01 06:20:35] __main__ INFO: \u001b[0mVal 43\n",
      "\u001b[32m[2020-07-01 06:20:52] __main__ INFO: \u001b[0mEpoch 43 loss 0.3369 acc@1 0.9026 acc@5 0.9962\n",
      "\u001b[32m[2020-07-01 06:20:52] __main__ INFO: \u001b[0mElapsed 17.35\n",
      "\u001b[32m[2020-07-01 06:20:52] __main__ INFO: \u001b[0mTrain 44 15093\n",
      "\u001b[32m[2020-07-01 06:23:10] __main__ INFO: \u001b[0mEpoch 44 Step 100/351 lr 0.001000 loss 0.0111 (0.0088) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 06:25:29] __main__ INFO: \u001b[0mEpoch 44 Step 200/351 lr 0.001000 loss 0.0062 (0.0095) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 06:27:47] __main__ INFO: \u001b[0mEpoch 44 Step 300/351 lr 0.001000 loss 0.0097 (0.0093) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 06:28:57] __main__ INFO: \u001b[0mEpoch 44 Step 351/351 lr 0.001000 loss 0.0087 (0.0092) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 06:28:57] __main__ INFO: \u001b[0mElapsed 485.46\n",
      "\u001b[32m[2020-07-01 06:28:57] __main__ INFO: \u001b[0mVal 44\n",
      "\u001b[32m[2020-07-01 06:29:15] __main__ INFO: \u001b[0mEpoch 44 loss 0.3330 acc@1 0.9030 acc@5 0.9964\n",
      "\u001b[32m[2020-07-01 06:29:15] __main__ INFO: \u001b[0mElapsed 17.33\n",
      "\u001b[32m[2020-07-01 06:29:15] __main__ INFO: \u001b[0mTrain 45 15444\n",
      "\u001b[32m[2020-07-01 06:31:33] __main__ INFO: \u001b[0mEpoch 45 Step 100/351 lr 0.001000 loss 0.0073 (0.0089) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 06:33:51] __main__ INFO: \u001b[0mEpoch 45 Step 200/351 lr 0.001000 loss 0.0090 (0.0089) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 06:36:10] __main__ INFO: \u001b[0mEpoch 45 Step 300/351 lr 0.001000 loss 0.0072 (0.0088) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 06:37:20] __main__ INFO: \u001b[0mEpoch 45 Step 351/351 lr 0.001000 loss 0.0071 (0.0088) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 06:37:20] __main__ INFO: \u001b[0mElapsed 485.33\n",
      "\u001b[32m[2020-07-01 06:37:20] __main__ INFO: \u001b[0mVal 45\n",
      "\u001b[32m[2020-07-01 06:37:37] __main__ INFO: \u001b[0mEpoch 45 loss 0.3449 acc@1 0.9016 acc@5 0.9956\n",
      "\u001b[32m[2020-07-01 06:37:37] __main__ INFO: \u001b[0mElapsed 17.35\n",
      "\u001b[32m[2020-07-01 06:37:37] __main__ INFO: \u001b[0mTrain 46 15795\n",
      "\u001b[32m[2020-07-01 06:39:56] __main__ INFO: \u001b[0mEpoch 46 Step 100/351 lr 0.001000 loss 0.0032 (0.0089) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 06:42:14] __main__ INFO: \u001b[0mEpoch 46 Step 200/351 lr 0.001000 loss 0.0107 (0.0084) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 06:44:32] __main__ INFO: \u001b[0mEpoch 46 Step 300/351 lr 0.001000 loss 0.0101 (0.0083) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 06:45:43] __main__ INFO: \u001b[0mEpoch 46 Step 351/351 lr 0.001000 loss 0.0103 (0.0083) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 06:45:43] __main__ INFO: \u001b[0mElapsed 485.33\n",
      "\u001b[32m[2020-07-01 06:45:43] __main__ INFO: \u001b[0mVal 46\n",
      "\u001b[32m[2020-07-01 06:46:00] __main__ INFO: \u001b[0mEpoch 46 loss 0.3462 acc@1 0.9008 acc@5 0.9954\n",
      "\u001b[32m[2020-07-01 06:46:00] __main__ INFO: \u001b[0mElapsed 17.34\n",
      "\u001b[32m[2020-07-01 06:46:00] __main__ INFO: \u001b[0mTrain 47 16146\n",
      "\u001b[32m[2020-07-01 06:48:18] __main__ INFO: \u001b[0mEpoch 47 Step 100/351 lr 0.001000 loss 0.0046 (0.0085) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 06:50:37] __main__ INFO: \u001b[0mEpoch 47 Step 200/351 lr 0.001000 loss 0.0052 (0.0085) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 06:52:55] __main__ INFO: \u001b[0mEpoch 47 Step 300/351 lr 0.001000 loss 0.0053 (0.0085) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 06:54:05] __main__ INFO: \u001b[0mEpoch 47 Step 351/351 lr 0.001000 loss 0.0085 (0.0087) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 06:54:05] __main__ INFO: \u001b[0mElapsed 485.23\n",
      "\u001b[32m[2020-07-01 06:54:05] __main__ INFO: \u001b[0mVal 47\n",
      "\u001b[32m[2020-07-01 06:54:23] __main__ INFO: \u001b[0mEpoch 47 loss 0.3531 acc@1 0.9034 acc@5 0.9950\n",
      "\u001b[32m[2020-07-01 06:54:23] __main__ INFO: \u001b[0mElapsed 17.34\n",
      "\u001b[32m[2020-07-01 06:54:23] __main__ INFO: \u001b[0mTrain 48 16497\n",
      "\u001b[32m[2020-07-01 06:56:41] __main__ INFO: \u001b[0mEpoch 48 Step 100/351 lr 0.001000 loss 0.0088 (0.0079) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 06:58:59] __main__ INFO: \u001b[0mEpoch 48 Step 200/351 lr 0.001000 loss 0.0051 (0.0083) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 07:01:18] __main__ INFO: \u001b[0mEpoch 48 Step 300/351 lr 0.001000 loss 0.0038 (0.0084) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 07:02:28] __main__ INFO: \u001b[0mEpoch 48 Step 351/351 lr 0.001000 loss 0.0099 (0.0083) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 07:02:28] __main__ INFO: \u001b[0mElapsed 485.47\n",
      "\u001b[32m[2020-07-01 07:02:28] __main__ INFO: \u001b[0mVal 48\n",
      "\u001b[32m[2020-07-01 07:02:46] __main__ INFO: \u001b[0mEpoch 48 loss 0.3484 acc@1 0.8996 acc@5 0.9956\n",
      "\u001b[32m[2020-07-01 07:02:46] __main__ INFO: \u001b[0mElapsed 17.38\n",
      "\u001b[32m[2020-07-01 07:02:46] __main__ INFO: \u001b[0mTrain 49 16848\n",
      "\u001b[32m[2020-07-01 07:05:04] __main__ INFO: \u001b[0mEpoch 49 Step 100/351 lr 0.001000 loss 0.0072 (0.0080) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 07:07:22] __main__ INFO: \u001b[0mEpoch 49 Step 200/351 lr 0.001000 loss 0.0086 (0.0078) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 07:09:40] __main__ INFO: \u001b[0mEpoch 49 Step 300/351 lr 0.001000 loss 0.0066 (0.0078) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 07:10:51] __main__ INFO: \u001b[0mEpoch 49 Step 351/351 lr 0.001000 loss 0.0090 (0.0079) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 07:10:51] __main__ INFO: \u001b[0mElapsed 485.36\n",
      "\u001b[32m[2020-07-01 07:10:51] __main__ INFO: \u001b[0mVal 49\n",
      "\u001b[32m[2020-07-01 07:11:08] __main__ INFO: \u001b[0mEpoch 49 loss 0.3505 acc@1 0.8984 acc@5 0.9958\n",
      "\u001b[32m[2020-07-01 07:11:08] __main__ INFO: \u001b[0mElapsed 17.35\n",
      "\u001b[32m[2020-07-01 07:11:08] __main__ INFO: \u001b[0mTrain 50 17199\n",
      "\u001b[32m[2020-07-01 07:13:27] __main__ INFO: \u001b[0mEpoch 50 Step 100/351 lr 0.001000 loss 0.0067 (0.0074) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 07:15:45] __main__ INFO: \u001b[0mEpoch 50 Step 200/351 lr 0.001000 loss 0.0037 (0.0076) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 07:18:03] __main__ INFO: \u001b[0mEpoch 50 Step 300/351 lr 0.001000 loss 0.0088 (0.0079) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 07:19:14] __main__ INFO: \u001b[0mEpoch 50 Step 351/351 lr 0.001000 loss 0.0066 (0.0081) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-01 07:19:14] __main__ INFO: \u001b[0mElapsed 485.44\n",
      "\u001b[32m[2020-07-01 07:19:14] __main__ INFO: \u001b[0mVal 50\n",
      "\u001b[32m[2020-07-01 07:19:31] __main__ INFO: \u001b[0mEpoch 50 loss 0.3537 acc@1 0.9024 acc@5 0.9958\n",
      "\u001b[32m[2020-07-01 07:19:31] __main__ INFO: \u001b[0mElapsed 17.36\n",
      "\u001b[32m[2020-07-01 07:19:31] fvcore.common.checkpoint INFO: \u001b[0mSaving checkpoint to /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_ra_3_20/exp00_resume400_50/checkpoint_00050.pth\n"
     ]
    }
   ],
   "source": [
    "# Resume training with the un-augmented data\n",
    "os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "#!python train.py --config configs/cifar/resnet.yaml \\\n",
    "!python train.py --config /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_ra_3_20/exp00/config.yaml \\\n",
    "    model.resnext.cardinality 4 \\\n",
    "    test.batch_size 128 \\\n",
    "    train.checkpoint /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_ra_3_20/exp00/checkpoint_00400.pth \\\n",
    "    dataset.name CIFAR10 \\\n",
    "    train.base_lr .001 \\\n",
    "    train.output_dir /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_ra_3_20/exp00_resume400_50 \\\n",
    "    scheduler.epochs 50\n",
    "\n",
    "#### Set LEARNING RATE based on ending LR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-02 17:28:06] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_ra_3_20/exp00/checkpoint_00400.pth\n",
      "Files already downloaded and verified\n",
      "100%|███████████████████████████████████████████| 79/79 [00:35<00:00,  2.24it/s]\n",
      "\u001b[32m[2020-07-02 17:28:43] __main__ INFO: \u001b[0mElapsed 35.30\n",
      "\u001b[32m[2020-07-02 17:28:43] __main__ INFO: \u001b[0mLoss 1.3829 Accuracy 0.6392\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10 test dataset - without training on unaugmented data\n",
    "# write the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/resnext.yaml \\\n",
    "   model.resnext.cardinality 4 \\\n",
    "   test.batch_size 128 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_ra_3_20/exp00/checkpoint_00400.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_ra_3_20/exp00/test_results_0400_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-02 17:31:51] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_ra_3_20/exp00_resume400_50/checkpoint_00050.pth\n",
      "Files already downloaded and verified\n",
      "100%|███████████████████████████████████████████| 79/79 [00:35<00:00,  2.23it/s]\n",
      "\u001b[32m[2020-07-02 17:32:28] __main__ INFO: \u001b[0mElapsed 35.37\n",
      "\u001b[32m[2020-07-02 17:32:28] __main__ INFO: \u001b[0mLoss 0.3423 Accuracy 0.9018\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10 test dataset - using model refined on 50 epochs\n",
    "# write the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/resnext.yaml \\\n",
    "   model.resnext.cardinality 4 \\\n",
    "   test.batch_size 128 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_ra_3_20/exp00_resume400_50/checkpoint_00050.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_ra_3_20/exp00_resume400_50/test_results_0050_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-02 17:33:37] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_ra_3_20/exp00/checkpoint_00400.pth\n",
      "CIFAR 10.1\n",
      "100%|███████████████████████████████████████████| 16/16 [00:07<00:00,  2.17it/s]\n",
      "\u001b[32m[2020-07-02 17:33:45] __main__ INFO: \u001b[0mElapsed 7.37\n",
      "\u001b[32m[2020-07-02 17:33:45] __main__ INFO: \u001b[0mLoss 1.9102 Accuracy 0.4935\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10.1 test dataset - without training on unaugmented data\n",
    "# write the results to the test output directory specified.\n",
    "os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "!python evaluate.py --config configs/cifar/resnext.yaml \\\n",
    "    model.resnext.cardinality 4 \\\n",
    "    test.batch_size 128 \\\n",
    "    dataset.name CIFAR101 \\\n",
    "    test.checkpoint /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_ra_3_20/exp00/checkpoint_00400.pth \\\n",
    "    test.output_dir /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_ra_3_20/exp00/test_results_0400_CIFAR101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-02 17:34:34] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_ra_3_20/exp00_resume400_50/checkpoint_00050.pth\n",
      "CIFAR 10.1\n",
      "100%|███████████████████████████████████████████| 16/16 [00:07<00:00,  2.19it/s]\n",
      "\u001b[32m[2020-07-02 17:34:42] __main__ INFO: \u001b[0mElapsed 7.32\n",
      "\u001b[32m[2020-07-02 17:34:42] __main__ INFO: \u001b[0mLoss 0.6259 Accuracy 0.8185\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10.1 test dataset - using model refined on 50 epochs\n",
    "# write the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/resnext.yaml \\\n",
    "   model.resnext.cardinality 4 \\\n",
    "   test.batch_size 128 \\\n",
    "   dataset.name CIFAR101 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_ra_3_20/exp00_resume400_50/checkpoint_00050.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_ra_3_20/exp00_resume400_50/test_results_0050_cifar101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Testset</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Original_Accuracy_300epochs</th>\n",
       "      <th>Original_CI_300epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resnext_29_4x64d_ra_3_20</td>\n",
       "      <td>400</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>1.3829</td>\n",
       "      <td>0.7241</td>\n",
       "      <td>96.4</td>\n",
       "      <td>(96.0, 96.7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>resnext_29_4x64d_ra_3_20</td>\n",
       "      <td>400</td>\n",
       "      <td>cifar10.1</td>\n",
       "      <td>1.9102</td>\n",
       "      <td>0.4935</td>\n",
       "      <td>89.6</td>\n",
       "      <td>(88.2, 90.9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>resnext_29_4x64d_ra_3_20_refined400</td>\n",
       "      <td>50</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>0.3423</td>\n",
       "      <td>0.9018</td>\n",
       "      <td>96.4</td>\n",
       "      <td>(96.0, 96.7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>resnext_29_4x64d_ra_3_20_refined400</td>\n",
       "      <td>50</td>\n",
       "      <td>cifar10.1</td>\n",
       "      <td>0.6259</td>\n",
       "      <td>0.8185</td>\n",
       "      <td>89.6</td>\n",
       "      <td>(88.2, 90.9)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model Epoch    Testset    Loss Accuracy  \\\n",
       "0             resnext_29_4x64d_ra_3_20   400    cifar10  1.3829   0.7241   \n",
       "1             resnext_29_4x64d_ra_3_20   400  cifar10.1  1.9102   0.4935   \n",
       "2  resnext_29_4x64d_ra_3_20_refined400    50    cifar10  0.3423   0.9018   \n",
       "3  resnext_29_4x64d_ra_3_20_refined400    50  cifar10.1  0.6259   0.8185   \n",
       "\n",
       "   Original_Accuracy_300epochs Original_CI_300epochs  \n",
       "0                         96.4          (96.0, 96.7)  \n",
       "1                         89.6          (88.2, 90.9)  \n",
       "2                         96.4          (96.0, 96.7)  \n",
       "3                         89.6          (88.2, 90.9)  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "a = pd.Series(['resnext_29_4x64d_ra_3_20', 400, 'cifar10', 1.3829, 0.7241]) #Loss 1.3829 Accuracy 0.6392\n",
    "b = pd.Series(['resnext_29_4x64d_ra_3_20', 400, 'cifar10.1', 1.9102, 0.4935]) #Loss 1.9102 Accuracy 0.4935\n",
    "\n",
    "c = pd.Series(['resnext_29_4x64d_ra_3_20_refined400', 50, 'cifar10', 0.3423, 0.9018]) #Loss 0.3423 Accuracy 0.9018\n",
    "d = pd.Series(['resnext_29_4x64d_ra_3_20_refined400', 50, 'cifar10.1', 0.6259, 0.8185]) #Loss 0.6259 Accuracy 0.8185\n",
    "\n",
    "df_results = pd.concat([a,b,c,d], axis=1).T\n",
    "df_results.columns = ['Model', 'Epoch', 'Testset', 'Loss', 'Accuracy']\n",
    "\n",
    "df_results['Original_Accuracy_300epochs'] = df_results.apply((lambda row: 96.4 if row[2] == 'cifar10' else 89.6), axis=1)\n",
    "df_results['Original_CI_300epochs'] = df_results.apply((lambda row: (96.0, 96.7) if row[2] == 'cifar10' else (88.2, 90.9)), axis=1)\n",
    "\n",
    "df_results.to_csv('/home/ec2-user/SageMaker/experiments/resnext_29_4x64d_ra_3_20/results.csv')\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Testset</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Original_Accuracy</th>\n",
       "      <th>Original_CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resnext_29_4x64d</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6746</td>\n",
       "      <td>0.8019</td>\n",
       "      <td>96.4</td>\n",
       "      <td>(96.0, 96.7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>resnext_29_4x64d</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>200</td>\n",
       "      <td>0.2311</td>\n",
       "      <td>0.9321</td>\n",
       "      <td>96.4</td>\n",
       "      <td>(96.0, 96.7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>resnext_29_4x64d</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>300</td>\n",
       "      <td>0.1517</td>\n",
       "      <td>0.9535</td>\n",
       "      <td>96.4</td>\n",
       "      <td>(96.0, 96.7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>resnext_29_4x64d</td>\n",
       "      <td>cifar10.1</td>\n",
       "      <td>300</td>\n",
       "      <td>0.3742</td>\n",
       "      <td>0.8905</td>\n",
       "      <td>89.6</td>\n",
       "      <td>(88.2, 90.9)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model    Testset  Epoch    Loss  Accuracy  Original_Accuracy  \\\n",
       "0  resnext_29_4x64d    cifar10    100  0.6746    0.8019               96.4   \n",
       "1  resnext_29_4x64d    cifar10    200  0.2311    0.9321               96.4   \n",
       "2  resnext_29_4x64d    cifar10    300  0.1517    0.9535               96.4   \n",
       "3  resnext_29_4x64d  cifar10.1    300  0.3742    0.8905               89.6   \n",
       "\n",
       "    Original_CI  \n",
       "0  (96.0, 96.7)  \n",
       "1  (96.0, 96.7)  \n",
       "2  (96.0, 96.7)  \n",
       "3  (88.2, 90.9)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write the results to a CSV file so that we can analyze later.\n",
    "import pandas as pd\n",
    "\n",
    "results = {'Model': ['resnext_29_4x64d', 'resnext_29_4x64d', 'resnext_29_4x64d', 'resnext_29_4x64d'],\n",
    "           'Testset': ['cifar10', 'cifar10', 'cifar10', 'cifar10.1'],\n",
    "           'Epoch': [100, 200, 300, 300],\n",
    "           'Loss': [0.6746, 0.2311, 0.1517, 0.3742],\n",
    "           'Accuracy': [0.8019, 0.9321, 0.9535, 0.8905],\n",
    "           'Original_Accuracy': [96.4, 96.4, 96.4, 89.6],\n",
    "           'Original_CI': [(96.0, 96.7), (96.0, 96.7), (96.0, 96.7), (88.2, 90.9)]\n",
    "           }\n",
    "\n",
    "df = pd.DataFrame(results, columns = ['Model', 'Testset', 'Epoch', 'Loss', 'Accuracy', \n",
    "                                      'Original_Accuracy', 'Original_CI'])\n",
    "\n",
    "\n",
    "df.to_csv('/home/ec2-user/SageMaker/experiments/resnext_29_4x64d/exp00/results.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['preds', 'probs', 'labels', 'loss', 'acc']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.2041907 , -1.8999833 , -0.24285015, ..., -1.5008752 ,\n",
       "        -1.8426697 , -2.8560946 ],\n",
       "       [ 0.5460079 ,  2.220384  , -1.9393705 , ..., -2.6070693 ,\n",
       "        11.327686  , -1.2085156 ],\n",
       "       [-1.3446747 ,  2.1730833 , -1.1615647 , ..., -2.2299995 ,\n",
       "        10.984515  , -0.75660706],\n",
       "       ...,\n",
       "       [-2.4790986 , -1.3337001 ,  0.61669415, ..., -0.83421385,\n",
       "        -1.8529658 , -1.7280097 ],\n",
       "       [-0.90489024,  9.350766  ,  1.0618937 , ..., -2.3210623 ,\n",
       "        -0.9061641 , -1.8115013 ],\n",
       "       [-1.4560711 , -1.0518838 , -1.4613396 , ..., 12.668192  ,\n",
       "        -2.1191459 , -0.8881919 ]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Peak inside the output file for predictions\n",
    "import numpy as np\n",
    "output = '/home/ec2-user/SageMaker/experiments/resnext_29_4x64d/exp00/test_results_0300/predictions.npz'\n",
    "npzfile = np.load(output)\n",
    "print(npzfile.files)\n",
    "npzfile['preds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the model checkpoints, configs, and results to S3 \n",
    "bucket='sagemaker-may29'\n",
    "prefix = 'sagemaker/results/original-models/'\n",
    "path = '/home/ec2-user/SageMaker/experiments/'\n",
    "\n",
    "s3_resource = boto3.resource(\"s3\", region_name=\"us-east-2\")\n",
    "\n",
    "def uploadDirectory(local_path,bucket_name,s3_prefix):\n",
    "\n",
    "    my_bucket = s3_resource.Bucket(bucket_name)\n",
    "    \n",
    "    for path, subdirs, files in os.walk(local_path):\n",
    "        path = path.replace(\"\\\\\",\"/\")\n",
    "        directory_name = path.replace(local_path,\"\")\n",
    "        for file in files:\n",
    "            #print(\"Local File:\", os.path.join(path, file))\n",
    "            #print(\"      Dest:\", s3_prefix+directory_name+'/'+file)\n",
    "            my_bucket.upload_file(os.path.join(path, file), s3_prefix+directory_name+'/'+file)\n",
    "    \n",
    "uploadDirectory(path,bucket,prefix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
