{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet\n",
    "\n",
    " - Training Dataset:  RandAugment, N=2, M=20\n",
    "   Validation with Unaugmented Data\n",
    " - Sagemaker Notebook must be of type, conda_pytorch_p36\n",
    " \n",
    "#### Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy \n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 1)) (1.18.1)\n",
      "Requirement already satisfied: torch>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 2)) (1.4.0)\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 3)) (0.5.0)\n",
      "Requirement already satisfied: fvcore in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (0.1.1.post20200711)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 5)) (4.44.1)\n",
      "Requirement already satisfied: yacs in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 6)) (0.1.7)\n",
      "Requirement already satisfied: apex from git+https://github.com/NVIDIA/apex.git#egg=apex in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 7)) (0.1)\n",
      "Requirement already satisfied: termcolor in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 8)) (1.1.0)\n",
      "Requirement already satisfied: thop<0.0.31.post2004070130 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 9)) (0.0.31.post2001170342)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 3)) (1.14.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 3)) (7.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from fvcore->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (5.3.1)\n",
      "Requirement already satisfied: tabulate in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from fvcore->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (0.8.7)\n",
      "Requirement already satisfied: portalocker in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from fvcore->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (1.7.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: tensorboard in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (2.2.2)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.30.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.18.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.18.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (46.1.3.post20200330)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.7.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.14.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (2.23.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.0.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.9.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.34.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.4.1)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (3.12.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (3.2.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard) (3.4.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (1.25.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.4.5.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (1.5.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard) (2.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Sagemaker Notebook must be of type, conda_pytorch_p36\n",
    "!pip install -r '/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt'\n",
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-14 00:12:47] __main__ INFO: \u001b[0mdevice: cuda\n",
      "cudnn:\n",
      "  benchmark: True\n",
      "  deterministic: False\n",
      "dataset:\n",
      "  name: CIFAR10_RA_2_20\n",
      "  dataset_dir: ''\n",
      "  image_size: 32\n",
      "  n_channels: 3\n",
      "  n_classes: 10\n",
      "model:\n",
      "  type: cifar\n",
      "  name: resnet\n",
      "  init_mode: kaiming_fan_out\n",
      "  vgg:\n",
      "    n_channels: [64, 128, 256, 512, 512]\n",
      "    n_layers: [2, 2, 3, 3, 3]\n",
      "    use_bn: True\n",
      "  resnet:\n",
      "    depth: 32\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "  resnet_preact:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "  wrn:\n",
      "    depth: 28\n",
      "    initial_channels: 16\n",
      "    widening_factor: 10\n",
      "    drop_rate: 0.0\n",
      "  densenet:\n",
      "    depth: 100\n",
      "    n_blocks: [6, 12, 24, 16]\n",
      "    block_type: bottleneck\n",
      "    growth_rate: 12\n",
      "    drop_rate: 0.0\n",
      "    compression_rate: 0.5\n",
      "  pyramidnet:\n",
      "    depth: 272\n",
      "    n_blocks: [3, 24, 36, 3]\n",
      "    initial_channels: 16\n",
      "    block_type: bottleneck\n",
      "    alpha: 200\n",
      "  resnext:\n",
      "    depth: 29\n",
      "    n_blocks: [3, 4, 6, 3]\n",
      "    initial_channels: 64\n",
      "    cardinality: 8\n",
      "    base_channels: 4\n",
      "  shake_shake:\n",
      "    depth: 26\n",
      "    initial_channels: 96\n",
      "    shake_forward: True\n",
      "    shake_backward: True\n",
      "    shake_image: True\n",
      "  se_resnet_preact:\n",
      "    depth: 110\n",
      "    initial_channels: 16\n",
      "    se_reduction: 16\n",
      "    block_type: basic\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "train:\n",
      "  checkpoint: ''\n",
      "  resume: False\n",
      "  precision: O0\n",
      "  batch_size: 128\n",
      "  subdivision: 1\n",
      "  optimizer: sgd\n",
      "  base_lr: 0.1\n",
      "  momentum: 0.9\n",
      "  nesterov: True\n",
      "  weight_decay: 0.0001\n",
      "  no_weight_decay_on_bn: False\n",
      "  gradient_clip: 0\n",
      "  start_epoch: 0\n",
      "  seed: 0\n",
      "  val_first: True\n",
      "  val_period: 1\n",
      "  val_ratio: 0.1\n",
      "  use_test_as_val: False\n",
      "  output_dir: /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_20_c10val/exp00\n",
      "  log_period: 100\n",
      "  checkpoint_period: 100\n",
      "  use_tensorboard: True\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: True\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "  distributed: False\n",
      "  dist:\n",
      "    backend: nccl\n",
      "    init_method: env://\n",
      "    world_size: -1\n",
      "    node_rank: -1\n",
      "    local_rank: 0\n",
      "    use_sync_bn: False\n",
      "tensorboard:\n",
      "  train_images: False\n",
      "  val_images: False\n",
      "  model_params: False\n",
      "optim:\n",
      "  adam:\n",
      "    betas: (0.9, 0.999)\n",
      "  lars:\n",
      "    eps: 1e-09\n",
      "    threshold: 0.01\n",
      "  adabound:\n",
      "    betas: (0.9, 0.999)\n",
      "    final_lr: 0.1\n",
      "    gamma: 0.001\n",
      "scheduler:\n",
      "  epochs: 400\n",
      "  warmup:\n",
      "    type: none\n",
      "    epochs: 0\n",
      "    start_factor: 0.001\n",
      "    exponent: 4\n",
      "  type: multistep\n",
      "  milestones: [80, 120]\n",
      "  lr_decay: 0.1\n",
      "  lr_min_factor: 0.001\n",
      "  T0: 10\n",
      "  T_mul: 1.0\n",
      "validation:\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: False\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "augmentation:\n",
      "  use_random_crop: True\n",
      "  use_random_horizontal_flip: True\n",
      "  use_cutout: False\n",
      "  use_random_erasing: False\n",
      "  use_dual_cutout: False\n",
      "  use_mixup: False\n",
      "  use_ricap: False\n",
      "  use_cutmix: False\n",
      "  use_label_smoothing: False\n",
      "  random_crop:\n",
      "    padding: 4\n",
      "    fill: 0\n",
      "    padding_mode: constant\n",
      "  random_horizontal_flip:\n",
      "    prob: 0.5\n",
      "  cutout:\n",
      "    prob: 1.0\n",
      "    mask_size: 16\n",
      "    cut_inside: False\n",
      "    mask_color: 0\n",
      "    dual_cutout_alpha: 0.1\n",
      "  random_erasing:\n",
      "    prob: 0.5\n",
      "    area_ratio_range: [0.02, 0.4]\n",
      "    min_aspect_ratio: 0.3\n",
      "    max_attempt: 20\n",
      "  mixup:\n",
      "    alpha: 1.0\n",
      "  ricap:\n",
      "    beta: 0.3\n",
      "  cutmix:\n",
      "    alpha: 1.0\n",
      "  label_smoothing:\n",
      "    epsilon: 0.1\n",
      "tta:\n",
      "  use_resize: False\n",
      "  use_center_crop: False\n",
      "  resize: 256\n",
      "test:\n",
      "  checkpoint: ''\n",
      "  output_dir: ''\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    pin_memory: False\n",
      "\u001b[32m[2020-07-14 00:12:47] __main__ INFO: \u001b[0menv_info:\n",
      "  pytorch_version: 1.4.0\n",
      "  cuda_version: 10.1\n",
      "  cudnn_version: 7603\n",
      "  num_gpus: 1\n",
      "  gpu_name: Tesla K80\n",
      "  gpu_capability: 3.7\n",
      "Files already downloaded and verified\n",
      "\u001b[32m[2020-07-14 00:12:53] __main__ INFO: \u001b[0mMACs  : 69.76M\n",
      "\u001b[32m[2020-07-14 00:12:53] __main__ INFO: \u001b[0m#params: 466.91K\n",
      "Selected optimization level O0:  Pure FP32 training.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n",
      "\u001b[32m[2020-07-14 00:12:53] __main__ INFO: \u001b[0mVal 0\n",
      "\u001b[32m[2020-07-14 00:12:54] __main__ INFO: \u001b[0mEpoch 0 loss 2711.0736 acc@1 0.1050 acc@5 0.5004\n",
      "\u001b[32m[2020-07-14 00:12:54] __main__ INFO: \u001b[0mElapsed 1.41\n",
      "\u001b[32m[2020-07-14 00:12:54] __main__ INFO: \u001b[0mTrain 1 0\n",
      "\u001b[32m[2020-07-14 00:13:04] __main__ INFO: \u001b[0mEpoch 1 Step 100/351 lr 0.100000 loss 2.3108 (2.9195) acc@1 0.1328 (0.1001) acc@5 0.5156 (0.5088)\n",
      "\u001b[32m[2020-07-14 00:13:13] __main__ INFO: \u001b[0mEpoch 1 Step 200/351 lr 0.100000 loss 2.2975 (2.6139) acc@1 0.1016 (0.1020) acc@5 0.5000 (0.5044)\n",
      "\u001b[32m[2020-07-14 00:13:22] __main__ INFO: \u001b[0mEpoch 1 Step 300/351 lr 0.100000 loss 2.2973 (2.5107) acc@1 0.0781 (0.1012) acc@5 0.4688 (0.5059)\n",
      "\u001b[32m[2020-07-14 00:13:27] __main__ INFO: \u001b[0mEpoch 1 Step 351/351 lr 0.100000 loss 2.3228 (2.4809) acc@1 0.0625 (0.1029) acc@5 0.4453 (0.5059)\n",
      "\u001b[32m[2020-07-14 00:13:27] __main__ INFO: \u001b[0mElapsed 32.12\n",
      "\u001b[32m[2020-07-14 00:13:27] __main__ INFO: \u001b[0mVal 1\n",
      "\u001b[32m[2020-07-14 00:13:28] __main__ INFO: \u001b[0mEpoch 1 loss 2.3044 acc@1 0.1034 acc@5 0.5132\n",
      "\u001b[32m[2020-07-14 00:13:28] __main__ INFO: \u001b[0mElapsed 1.03\n",
      "\u001b[32m[2020-07-14 00:13:28] __main__ INFO: \u001b[0mTrain 2 351\n",
      "\u001b[32m[2020-07-14 00:13:37] __main__ INFO: \u001b[0mEpoch 2 Step 100/351 lr 0.100000 loss 2.2926 (2.3042) acc@1 0.1094 (0.1043) acc@5 0.4766 (0.5127)\n",
      "\u001b[32m[2020-07-14 00:13:46] __main__ INFO: \u001b[0mEpoch 2 Step 200/351 lr 0.100000 loss 2.3006 (2.3033) acc@1 0.0938 (0.1024) acc@5 0.5312 (0.5106)\n",
      "\u001b[32m[2020-07-14 00:13:55] __main__ INFO: \u001b[0mEpoch 2 Step 300/351 lr 0.100000 loss 2.2886 (2.3018) acc@1 0.1094 (0.1022) acc@5 0.5156 (0.5112)\n",
      "\u001b[32m[2020-07-14 00:14:00] __main__ INFO: \u001b[0mEpoch 2 Step 351/351 lr 0.100000 loss 2.3207 (2.3011) acc@1 0.1172 (0.1037) acc@5 0.4219 (0.5127)\n",
      "\u001b[32m[2020-07-14 00:14:00] __main__ INFO: \u001b[0mElapsed 31.93\n",
      "\u001b[32m[2020-07-14 00:14:00] __main__ INFO: \u001b[0mVal 2\n",
      "\u001b[32m[2020-07-14 00:14:01] __main__ INFO: \u001b[0mEpoch 2 loss 2.3032 acc@1 0.1064 acc@5 0.5164\n",
      "\u001b[32m[2020-07-14 00:14:01] __main__ INFO: \u001b[0mElapsed 1.15\n",
      "\u001b[32m[2020-07-14 00:14:01] __main__ INFO: \u001b[0mTrain 3 702\n",
      "\u001b[32m[2020-07-14 00:14:10] __main__ INFO: \u001b[0mEpoch 3 Step 100/351 lr 0.100000 loss 2.2855 (2.3004) acc@1 0.1328 (0.1043) acc@5 0.5234 (0.5159)\n",
      "\u001b[32m[2020-07-14 00:14:19] __main__ INFO: \u001b[0mEpoch 3 Step 200/351 lr 0.100000 loss 2.2566 (2.2979) acc@1 0.1406 (0.1073) acc@5 0.6094 (0.5207)\n",
      "\u001b[32m[2020-07-14 00:14:28] __main__ INFO: \u001b[0mEpoch 3 Step 300/351 lr 0.100000 loss 2.2918 (2.2971) acc@1 0.1172 (0.1064) acc@5 0.5078 (0.5248)\n",
      "\u001b[32m[2020-07-14 00:14:33] __main__ INFO: \u001b[0mEpoch 3 Step 351/351 lr 0.100000 loss 2.3223 (2.2964) acc@1 0.0859 (0.1082) acc@5 0.5078 (0.5253)\n",
      "\u001b[32m[2020-07-14 00:14:33] __main__ INFO: \u001b[0mElapsed 32.10\n",
      "\u001b[32m[2020-07-14 00:14:33] __main__ INFO: \u001b[0mVal 3\n",
      "\u001b[32m[2020-07-14 00:14:34] __main__ INFO: \u001b[0mEpoch 3 loss 2.2972 acc@1 0.1010 acc@5 0.5778\n",
      "\u001b[32m[2020-07-14 00:14:34] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-07-14 00:14:34] __main__ INFO: \u001b[0mTrain 4 1053\n",
      "\u001b[32m[2020-07-14 00:14:43] __main__ INFO: \u001b[0mEpoch 4 Step 100/351 lr 0.100000 loss 2.2833 (2.2947) acc@1 0.1250 (0.1064) acc@5 0.5938 (0.5273)\n",
      "\u001b[32m[2020-07-14 00:14:52] __main__ INFO: \u001b[0mEpoch 4 Step 200/351 lr 0.100000 loss 2.2903 (2.2926) acc@1 0.1406 (0.1073) acc@5 0.5234 (0.5309)\n",
      "\u001b[32m[2020-07-14 00:15:01] __main__ INFO: \u001b[0mEpoch 4 Step 300/351 lr 0.100000 loss 2.2883 (2.2913) acc@1 0.1328 (0.1117) acc@5 0.4922 (0.5354)\n",
      "\u001b[32m[2020-07-14 00:15:06] __main__ INFO: \u001b[0mEpoch 4 Step 351/351 lr 0.100000 loss 2.3127 (2.2897) acc@1 0.1250 (0.1130) acc@5 0.5703 (0.5395)\n",
      "\u001b[32m[2020-07-14 00:15:06] __main__ INFO: \u001b[0mElapsed 32.20\n",
      "\u001b[32m[2020-07-14 00:15:06] __main__ INFO: \u001b[0mVal 4\n",
      "\u001b[32m[2020-07-14 00:15:07] __main__ INFO: \u001b[0mEpoch 4 loss 2.2752 acc@1 0.1214 acc@5 0.5660\n",
      "\u001b[32m[2020-07-14 00:15:07] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-07-14 00:15:07] __main__ INFO: \u001b[0mTrain 5 1404\n",
      "\u001b[32m[2020-07-14 00:15:16] __main__ INFO: \u001b[0mEpoch 5 Step 100/351 lr 0.100000 loss 2.2596 (2.2852) acc@1 0.1719 (0.1187) acc@5 0.5938 (0.5584)\n",
      "\u001b[32m[2020-07-14 00:15:25] __main__ INFO: \u001b[0mEpoch 5 Step 200/351 lr 0.100000 loss 2.2875 (2.2808) acc@1 0.1328 (0.1226) acc@5 0.5391 (0.5629)\n",
      "\u001b[32m[2020-07-14 00:15:35] __main__ INFO: \u001b[0mEpoch 5 Step 300/351 lr 0.100000 loss 2.2423 (2.2766) acc@1 0.1250 (0.1240) acc@5 0.6250 (0.5696)\n",
      "\u001b[32m[2020-07-14 00:15:39] __main__ INFO: \u001b[0mEpoch 5 Step 351/351 lr 0.100000 loss 2.2683 (2.2738) acc@1 0.1641 (0.1258) acc@5 0.6016 (0.5717)\n",
      "\u001b[32m[2020-07-14 00:15:39] __main__ INFO: \u001b[0mElapsed 32.14\n",
      "\u001b[32m[2020-07-14 00:15:39] __main__ INFO: \u001b[0mVal 5\n",
      "\u001b[32m[2020-07-14 00:15:40] __main__ INFO: \u001b[0mEpoch 5 loss 2.1449 acc@1 0.1968 acc@5 0.7542\n",
      "\u001b[32m[2020-07-14 00:15:40] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-07-14 00:15:40] __main__ INFO: \u001b[0mTrain 6 1755\n",
      "\u001b[32m[2020-07-14 00:15:50] __main__ INFO: \u001b[0mEpoch 6 Step 100/351 lr 0.100000 loss 2.2283 (2.2555) acc@1 0.1484 (0.1368) acc@5 0.6016 (0.5884)\n",
      "\u001b[32m[2020-07-14 00:15:59] __main__ INFO: \u001b[0mEpoch 6 Step 200/351 lr 0.100000 loss 2.2428 (2.2497) acc@1 0.1562 (0.1418) acc@5 0.5938 (0.5978)\n",
      "\u001b[32m[2020-07-14 00:16:08] __main__ INFO: \u001b[0mEpoch 6 Step 300/351 lr 0.100000 loss 2.2149 (2.2456) acc@1 0.1484 (0.1447) acc@5 0.6953 (0.6010)\n",
      "\u001b[32m[2020-07-14 00:16:12] __main__ INFO: \u001b[0mEpoch 6 Step 351/351 lr 0.100000 loss 2.2294 (2.2450) acc@1 0.1719 (0.1429) acc@5 0.5938 (0.6024)\n",
      "\u001b[32m[2020-07-14 00:16:12] __main__ INFO: \u001b[0mElapsed 32.18\n",
      "\u001b[32m[2020-07-14 00:16:12] __main__ INFO: \u001b[0mVal 6\n",
      "\u001b[32m[2020-07-14 00:16:14] __main__ INFO: \u001b[0mEpoch 6 loss 2.0523 acc@1 0.2048 acc@5 0.7728\n",
      "\u001b[32m[2020-07-14 00:16:14] __main__ INFO: \u001b[0mElapsed 1.03\n",
      "\u001b[32m[2020-07-14 00:16:14] __main__ INFO: \u001b[0mTrain 7 2106\n",
      "\u001b[32m[2020-07-14 00:16:23] __main__ INFO: \u001b[0mEpoch 7 Step 100/351 lr 0.100000 loss 2.2513 (2.2336) acc@1 0.1328 (0.1513) acc@5 0.5312 (0.6108)\n",
      "\u001b[32m[2020-07-14 00:16:32] __main__ INFO: \u001b[0mEpoch 7 Step 200/351 lr 0.100000 loss 2.1762 (2.2280) acc@1 0.2031 (0.1525) acc@5 0.7031 (0.6147)\n",
      "\u001b[32m[2020-07-14 00:16:41] __main__ INFO: \u001b[0mEpoch 7 Step 300/351 lr 0.100000 loss 2.2293 (2.2248) acc@1 0.1250 (0.1529) acc@5 0.5625 (0.6177)\n",
      "\u001b[32m[2020-07-14 00:16:46] __main__ INFO: \u001b[0mEpoch 7 Step 351/351 lr 0.100000 loss 2.2082 (2.2228) acc@1 0.1484 (0.1535) acc@5 0.5781 (0.6202)\n",
      "\u001b[32m[2020-07-14 00:16:46] __main__ INFO: \u001b[0mElapsed 32.20\n",
      "\u001b[32m[2020-07-14 00:16:46] __main__ INFO: \u001b[0mVal 7\n",
      "\u001b[32m[2020-07-14 00:16:47] __main__ INFO: \u001b[0mEpoch 7 loss 2.0323 acc@1 0.2566 acc@5 0.7862\n",
      "\u001b[32m[2020-07-14 00:16:47] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-07-14 00:16:47] __main__ INFO: \u001b[0mTrain 8 2457\n",
      "\u001b[32m[2020-07-14 00:16:56] __main__ INFO: \u001b[0mEpoch 8 Step 100/351 lr 0.100000 loss 2.2275 (2.2064) acc@1 0.1562 (0.1641) acc@5 0.5859 (0.6316)\n",
      "\u001b[32m[2020-07-14 00:17:05] __main__ INFO: \u001b[0mEpoch 8 Step 200/351 lr 0.100000 loss 2.2175 (2.2051) acc@1 0.1562 (0.1610) acc@5 0.6172 (0.6306)\n",
      "\u001b[32m[2020-07-14 00:17:14] __main__ INFO: \u001b[0mEpoch 8 Step 300/351 lr 0.100000 loss 2.2141 (2.2039) acc@1 0.1562 (0.1621) acc@5 0.6328 (0.6303)\n",
      "\u001b[32m[2020-07-14 00:17:19] __main__ INFO: \u001b[0mEpoch 8 Step 351/351 lr 0.100000 loss 2.1728 (2.2020) acc@1 0.1562 (0.1639) acc@5 0.6797 (0.6306)\n",
      "\u001b[32m[2020-07-14 00:17:19] __main__ INFO: \u001b[0mElapsed 32.22\n",
      "\u001b[32m[2020-07-14 00:17:19] __main__ INFO: \u001b[0mVal 8\n",
      "\u001b[32m[2020-07-14 00:17:20] __main__ INFO: \u001b[0mEpoch 8 loss 1.9027 acc@1 0.2806 acc@5 0.8170\n",
      "\u001b[32m[2020-07-14 00:17:20] __main__ INFO: \u001b[0mElapsed 1.03\n",
      "\u001b[32m[2020-07-14 00:17:20] __main__ INFO: \u001b[0mTrain 9 2808\n",
      "\u001b[32m[2020-07-14 00:17:29] __main__ INFO: \u001b[0mEpoch 9 Step 100/351 lr 0.100000 loss 2.1416 (2.1927) acc@1 0.1328 (0.1659) acc@5 0.6406 (0.6330)\n",
      "\u001b[32m[2020-07-14 00:17:38] __main__ INFO: \u001b[0mEpoch 9 Step 200/351 lr 0.100000 loss 2.1815 (2.1850) acc@1 0.1875 (0.1700) acc@5 0.6797 (0.6401)\n",
      "\u001b[32m[2020-07-14 00:17:48] __main__ INFO: \u001b[0mEpoch 9 Step 300/351 lr 0.100000 loss 2.2194 (2.1844) acc@1 0.1797 (0.1716) acc@5 0.6172 (0.6425)\n",
      "\u001b[32m[2020-07-14 00:17:52] __main__ INFO: \u001b[0mEpoch 9 Step 351/351 lr 0.100000 loss 2.1723 (2.1812) acc@1 0.2031 (0.1733) acc@5 0.6641 (0.6440)\n",
      "\u001b[32m[2020-07-14 00:17:52] __main__ INFO: \u001b[0mElapsed 32.26\n",
      "\u001b[32m[2020-07-14 00:17:52] __main__ INFO: \u001b[0mVal 9\n",
      "\u001b[32m[2020-07-14 00:17:53] __main__ INFO: \u001b[0mEpoch 9 loss 1.8857 acc@1 0.3044 acc@5 0.8156\n",
      "\u001b[32m[2020-07-14 00:17:53] __main__ INFO: \u001b[0mElapsed 1.03\n",
      "\u001b[32m[2020-07-14 00:17:53] __main__ INFO: \u001b[0mTrain 10 3159\n",
      "\u001b[32m[2020-07-14 00:18:03] __main__ INFO: \u001b[0mEpoch 10 Step 100/351 lr 0.100000 loss 2.1647 (2.1606) acc@1 0.1953 (0.1791) acc@5 0.6797 (0.6578)\n",
      "\u001b[32m[2020-07-14 00:18:12] __main__ INFO: \u001b[0mEpoch 10 Step 200/351 lr 0.100000 loss 2.1791 (2.1605) acc@1 0.1719 (0.1819) acc@5 0.6484 (0.6543)\n",
      "\u001b[32m[2020-07-14 00:18:21] __main__ INFO: \u001b[0mEpoch 10 Step 300/351 lr 0.100000 loss 2.1235 (2.1573) acc@1 0.1953 (0.1829) acc@5 0.6328 (0.6543)\n",
      "\u001b[32m[2020-07-14 00:18:26] __main__ INFO: \u001b[0mEpoch 10 Step 351/351 lr 0.100000 loss 2.1943 (2.1574) acc@1 0.1797 (0.1831) acc@5 0.6406 (0.6540)\n",
      "\u001b[32m[2020-07-14 00:18:26] __main__ INFO: \u001b[0mElapsed 32.23\n",
      "\u001b[32m[2020-07-14 00:18:26] __main__ INFO: \u001b[0mVal 10\n",
      "\u001b[32m[2020-07-14 00:18:27] __main__ INFO: \u001b[0mEpoch 10 loss 1.7661 acc@1 0.3408 acc@5 0.8716\n",
      "\u001b[32m[2020-07-14 00:18:27] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-07-14 00:18:27] __main__ INFO: \u001b[0mTrain 11 3510\n",
      "\u001b[32m[2020-07-14 00:18:36] __main__ INFO: \u001b[0mEpoch 11 Step 100/351 lr 0.100000 loss 2.1582 (2.1359) acc@1 0.1641 (0.1950) acc@5 0.6719 (0.6634)\n",
      "\u001b[32m[2020-07-14 00:18:45] __main__ INFO: \u001b[0mEpoch 11 Step 200/351 lr 0.100000 loss 2.1466 (2.1386) acc@1 0.1641 (0.1945) acc@5 0.6328 (0.6611)\n",
      "\u001b[32m[2020-07-14 00:18:54] __main__ INFO: \u001b[0mEpoch 11 Step 300/351 lr 0.100000 loss 2.0847 (2.1357) acc@1 0.2109 (0.1937) acc@5 0.6797 (0.6649)\n",
      "\u001b[32m[2020-07-14 00:18:59] __main__ INFO: \u001b[0mEpoch 11 Step 351/351 lr 0.100000 loss 2.2186 (2.1348) acc@1 0.1875 (0.1955) acc@5 0.5625 (0.6651)\n",
      "\u001b[32m[2020-07-14 00:18:59] __main__ INFO: \u001b[0mElapsed 32.23\n",
      "\u001b[32m[2020-07-14 00:18:59] __main__ INFO: \u001b[0mVal 11\n",
      "\u001b[32m[2020-07-14 00:19:00] __main__ INFO: \u001b[0mEpoch 11 loss 1.8332 acc@1 0.3252 acc@5 0.8506\n",
      "\u001b[32m[2020-07-14 00:19:00] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-07-14 00:19:00] __main__ INFO: \u001b[0mTrain 12 3861\n",
      "\u001b[32m[2020-07-14 00:19:09] __main__ INFO: \u001b[0mEpoch 12 Step 100/351 lr 0.100000 loss 2.1413 (2.1124) acc@1 0.1953 (0.2038) acc@5 0.6797 (0.6791)\n",
      "\u001b[32m[2020-07-14 00:19:18] __main__ INFO: \u001b[0mEpoch 12 Step 200/351 lr 0.100000 loss 2.1913 (2.1107) acc@1 0.1484 (0.2050) acc@5 0.6562 (0.6796)\n",
      "\u001b[32m[2020-07-14 00:19:27] __main__ INFO: \u001b[0mEpoch 12 Step 300/351 lr 0.100000 loss 2.1133 (2.1100) acc@1 0.1875 (0.2053) acc@5 0.7109 (0.6779)\n",
      "\u001b[32m[2020-07-14 00:19:32] __main__ INFO: \u001b[0mEpoch 12 Step 351/351 lr 0.100000 loss 2.0966 (2.1094) acc@1 0.1719 (0.2057) acc@5 0.6406 (0.6778)\n",
      "\u001b[32m[2020-07-14 00:19:32] __main__ INFO: \u001b[0mElapsed 32.24\n",
      "\u001b[32m[2020-07-14 00:19:32] __main__ INFO: \u001b[0mVal 12\n",
      "\u001b[32m[2020-07-14 00:19:33] __main__ INFO: \u001b[0mEpoch 12 loss 1.6725 acc@1 0.3878 acc@5 0.8790\n",
      "\u001b[32m[2020-07-14 00:19:33] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-07-14 00:19:33] __main__ INFO: \u001b[0mTrain 13 4212\n",
      "\u001b[32m[2020-07-14 00:19:42] __main__ INFO: \u001b[0mEpoch 13 Step 100/351 lr 0.100000 loss 2.0598 (2.0928) acc@1 0.2188 (0.2091) acc@5 0.6797 (0.6823)\n",
      "\u001b[32m[2020-07-14 00:19:52] __main__ INFO: \u001b[0mEpoch 13 Step 200/351 lr 0.100000 loss 2.1051 (2.0935) acc@1 0.2109 (0.2113) acc@5 0.7031 (0.6788)\n",
      "\u001b[32m[2020-07-14 00:20:01] __main__ INFO: \u001b[0mEpoch 13 Step 300/351 lr 0.100000 loss 2.0987 (2.0912) acc@1 0.2109 (0.2125) acc@5 0.6875 (0.6812)\n",
      "\u001b[32m[2020-07-14 00:20:05] __main__ INFO: \u001b[0mEpoch 13 Step 351/351 lr 0.100000 loss 2.0701 (2.0888) acc@1 0.2578 (0.2133) acc@5 0.7188 (0.6820)\n",
      "\u001b[32m[2020-07-14 00:20:05] __main__ INFO: \u001b[0mElapsed 32.29\n",
      "\u001b[32m[2020-07-14 00:20:05] __main__ INFO: \u001b[0mVal 13\n",
      "\u001b[32m[2020-07-14 00:20:07] __main__ INFO: \u001b[0mEpoch 13 loss 1.6623 acc@1 0.3790 acc@5 0.8976\n",
      "\u001b[32m[2020-07-14 00:20:07] __main__ INFO: \u001b[0mElapsed 1.11\n",
      "\u001b[32m[2020-07-14 00:20:07] __main__ INFO: \u001b[0mTrain 14 4563\n",
      "\u001b[32m[2020-07-14 00:20:16] __main__ INFO: \u001b[0mEpoch 14 Step 100/351 lr 0.100000 loss 2.1144 (2.0695) acc@1 0.1328 (0.2238) acc@5 0.6797 (0.6923)\n",
      "\u001b[32m[2020-07-14 00:20:25] __main__ INFO: \u001b[0mEpoch 14 Step 200/351 lr 0.100000 loss 2.0815 (2.0663) acc@1 0.2031 (0.2242) acc@5 0.6875 (0.6886)\n",
      "\u001b[32m[2020-07-14 00:20:34] __main__ INFO: \u001b[0mEpoch 14 Step 300/351 lr 0.100000 loss 1.9984 (2.0631) acc@1 0.2422 (0.2260) acc@5 0.6953 (0.6904)\n",
      "\u001b[32m[2020-07-14 00:20:39] __main__ INFO: \u001b[0mEpoch 14 Step 351/351 lr 0.100000 loss 2.0211 (2.0626) acc@1 0.2578 (0.2267) acc@5 0.7188 (0.6904)\n",
      "\u001b[32m[2020-07-14 00:20:39] __main__ INFO: \u001b[0mElapsed 32.27\n",
      "\u001b[32m[2020-07-14 00:20:39] __main__ INFO: \u001b[0mVal 14\n",
      "\u001b[32m[2020-07-14 00:20:40] __main__ INFO: \u001b[0mEpoch 14 loss 1.5855 acc@1 0.4292 acc@5 0.9024\n",
      "\u001b[32m[2020-07-14 00:20:40] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-07-14 00:20:40] __main__ INFO: \u001b[0mTrain 15 4914\n",
      "\u001b[32m[2020-07-14 00:20:49] __main__ INFO: \u001b[0mEpoch 15 Step 100/351 lr 0.100000 loss 2.1756 (2.0383) acc@1 0.2188 (0.2377) acc@5 0.6484 (0.7029)\n",
      "\u001b[32m[2020-07-14 00:20:58] __main__ INFO: \u001b[0mEpoch 15 Step 200/351 lr 0.100000 loss 2.0100 (2.0404) acc@1 0.2812 (0.2361) acc@5 0.7188 (0.6984)\n",
      "\u001b[32m[2020-07-14 00:21:08] __main__ INFO: \u001b[0mEpoch 15 Step 300/351 lr 0.100000 loss 2.0321 (2.0355) acc@1 0.1875 (0.2364) acc@5 0.7266 (0.7005)\n",
      "\u001b[32m[2020-07-14 00:21:12] __main__ INFO: \u001b[0mEpoch 15 Step 351/351 lr 0.100000 loss 2.0104 (2.0337) acc@1 0.2500 (0.2370) acc@5 0.6953 (0.7009)\n",
      "\u001b[32m[2020-07-14 00:21:12] __main__ INFO: \u001b[0mElapsed 32.28\n",
      "\u001b[32m[2020-07-14 00:21:12] __main__ INFO: \u001b[0mVal 15\n",
      "\u001b[32m[2020-07-14 00:21:13] __main__ INFO: \u001b[0mEpoch 15 loss 1.6987 acc@1 0.3882 acc@5 0.8610\n",
      "\u001b[32m[2020-07-14 00:21:13] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-07-14 00:21:13] __main__ INFO: \u001b[0mTrain 16 5265\n",
      "\u001b[32m[2020-07-14 00:21:23] __main__ INFO: \u001b[0mEpoch 16 Step 100/351 lr 0.100000 loss 1.9688 (2.0088) acc@1 0.2500 (0.2473) acc@5 0.6641 (0.7079)\n",
      "\u001b[32m[2020-07-14 00:21:32] __main__ INFO: \u001b[0mEpoch 16 Step 200/351 lr 0.100000 loss 1.9893 (2.0102) acc@1 0.2188 (0.2496) acc@5 0.7031 (0.7071)\n",
      "\u001b[32m[2020-07-14 00:21:41] __main__ INFO: \u001b[0mEpoch 16 Step 300/351 lr 0.100000 loss 2.0863 (2.0092) acc@1 0.2891 (0.2489) acc@5 0.7031 (0.7079)\n",
      "\u001b[32m[2020-07-14 00:21:46] __main__ INFO: \u001b[0mEpoch 16 Step 351/351 lr 0.100000 loss 1.9888 (2.0050) acc@1 0.2422 (0.2501) acc@5 0.7656 (0.7090)\n",
      "\u001b[32m[2020-07-14 00:21:46] __main__ INFO: \u001b[0mElapsed 32.28\n",
      "\u001b[32m[2020-07-14 00:21:46] __main__ INFO: \u001b[0mVal 16\n",
      "\u001b[32m[2020-07-14 00:21:47] __main__ INFO: \u001b[0mEpoch 16 loss 1.4832 acc@1 0.4664 acc@5 0.9050\n",
      "\u001b[32m[2020-07-14 00:21:47] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-07-14 00:21:47] __main__ INFO: \u001b[0mTrain 17 5616\n",
      "\u001b[32m[2020-07-14 00:21:56] __main__ INFO: \u001b[0mEpoch 17 Step 100/351 lr 0.100000 loss 1.9018 (1.9888) acc@1 0.2734 (0.2609) acc@5 0.7578 (0.7173)\n",
      "\u001b[32m[2020-07-14 00:22:05] __main__ INFO: \u001b[0mEpoch 17 Step 200/351 lr 0.100000 loss 1.9997 (1.9806) acc@1 0.2109 (0.2614) acc@5 0.6562 (0.7180)\n",
      "\u001b[32m[2020-07-14 00:22:14] __main__ INFO: \u001b[0mEpoch 17 Step 300/351 lr 0.100000 loss 1.9632 (1.9752) acc@1 0.2422 (0.2629) acc@5 0.7109 (0.7174)\n",
      "\u001b[32m[2020-07-14 00:22:19] __main__ INFO: \u001b[0mEpoch 17 Step 351/351 lr 0.100000 loss 1.8623 (1.9733) acc@1 0.3281 (0.2640) acc@5 0.7500 (0.7178)\n",
      "\u001b[32m[2020-07-14 00:22:19] __main__ INFO: \u001b[0mElapsed 32.29\n",
      "\u001b[32m[2020-07-14 00:22:19] __main__ INFO: \u001b[0mVal 17\n",
      "\u001b[32m[2020-07-14 00:22:20] __main__ INFO: \u001b[0mEpoch 17 loss 1.3549 acc@1 0.5018 acc@5 0.9336\n",
      "\u001b[32m[2020-07-14 00:22:20] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-07-14 00:22:20] __main__ INFO: \u001b[0mTrain 18 5967\n",
      "\u001b[32m[2020-07-14 00:22:29] __main__ INFO: \u001b[0mEpoch 18 Step 100/351 lr 0.100000 loss 1.8852 (1.9507) acc@1 0.2891 (0.2707) acc@5 0.7500 (0.7223)\n",
      "\u001b[32m[2020-07-14 00:22:38] __main__ INFO: \u001b[0mEpoch 18 Step 200/351 lr 0.100000 loss 1.9563 (1.9511) acc@1 0.2578 (0.2723) acc@5 0.7188 (0.7226)\n",
      "\u001b[32m[2020-07-14 00:22:48] __main__ INFO: \u001b[0mEpoch 18 Step 300/351 lr 0.100000 loss 1.9466 (1.9447) acc@1 0.2656 (0.2777) acc@5 0.6875 (0.7248)\n",
      "\u001b[32m[2020-07-14 00:22:52] __main__ INFO: \u001b[0mEpoch 18 Step 351/351 lr 0.100000 loss 1.9131 (1.9421) acc@1 0.2891 (0.2777) acc@5 0.7188 (0.7251)\n",
      "\u001b[32m[2020-07-14 00:22:52] __main__ INFO: \u001b[0mElapsed 32.27\n",
      "\u001b[32m[2020-07-14 00:22:52] __main__ INFO: \u001b[0mVal 18\n",
      "\u001b[32m[2020-07-14 00:22:53] __main__ INFO: \u001b[0mEpoch 18 loss 1.3727 acc@1 0.4960 acc@5 0.9290\n",
      "\u001b[32m[2020-07-14 00:22:53] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-14 00:22:53] __main__ INFO: \u001b[0mTrain 19 6318\n",
      "\u001b[32m[2020-07-14 00:23:03] __main__ INFO: \u001b[0mEpoch 19 Step 100/351 lr 0.100000 loss 1.8969 (1.9121) acc@1 0.2422 (0.2859) acc@5 0.7656 (0.7351)\n",
      "\u001b[32m[2020-07-14 00:23:12] __main__ INFO: \u001b[0mEpoch 19 Step 200/351 lr 0.100000 loss 2.0130 (1.9124) acc@1 0.2500 (0.2860) acc@5 0.7266 (0.7345)\n",
      "\u001b[32m[2020-07-14 00:23:21] __main__ INFO: \u001b[0mEpoch 19 Step 300/351 lr 0.100000 loss 1.8564 (1.9087) acc@1 0.3125 (0.2885) acc@5 0.7578 (0.7342)\n",
      "\u001b[32m[2020-07-14 00:23:26] __main__ INFO: \u001b[0mEpoch 19 Step 351/351 lr 0.100000 loss 1.8197 (1.9058) acc@1 0.3516 (0.2900) acc@5 0.7500 (0.7351)\n",
      "\u001b[32m[2020-07-14 00:23:26] __main__ INFO: \u001b[0mElapsed 32.29\n",
      "\u001b[32m[2020-07-14 00:23:26] __main__ INFO: \u001b[0mVal 19\n",
      "\u001b[32m[2020-07-14 00:23:27] __main__ INFO: \u001b[0mEpoch 19 loss 1.2187 acc@1 0.5518 acc@5 0.9424\n",
      "\u001b[32m[2020-07-14 00:23:27] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-07-14 00:23:27] __main__ INFO: \u001b[0mTrain 20 6669\n",
      "\u001b[32m[2020-07-14 00:23:36] __main__ INFO: \u001b[0mEpoch 20 Step 100/351 lr 0.100000 loss 1.9267 (1.8879) acc@1 0.2734 (0.2982) acc@5 0.7344 (0.7350)\n",
      "\u001b[32m[2020-07-14 00:23:45] __main__ INFO: \u001b[0mEpoch 20 Step 200/351 lr 0.100000 loss 1.7825 (1.8893) acc@1 0.3359 (0.3014) acc@5 0.8047 (0.7351)\n",
      "\u001b[32m[2020-07-14 00:23:54] __main__ INFO: \u001b[0mEpoch 20 Step 300/351 lr 0.100000 loss 1.9681 (1.8815) acc@1 0.2656 (0.3032) acc@5 0.6719 (0.7364)\n",
      "\u001b[32m[2020-07-14 00:23:59] __main__ INFO: \u001b[0mEpoch 20 Step 351/351 lr 0.100000 loss 1.8862 (1.8817) acc@1 0.3125 (0.3034) acc@5 0.7031 (0.7360)\n",
      "\u001b[32m[2020-07-14 00:23:59] __main__ INFO: \u001b[0mElapsed 32.26\n",
      "\u001b[32m[2020-07-14 00:23:59] __main__ INFO: \u001b[0mVal 20\n",
      "\u001b[32m[2020-07-14 00:24:00] __main__ INFO: \u001b[0mEpoch 20 loss 1.1773 acc@1 0.5954 acc@5 0.9440\n",
      "\u001b[32m[2020-07-14 00:24:00] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-07-14 00:24:00] __main__ INFO: \u001b[0mTrain 21 7020\n",
      "\u001b[32m[2020-07-14 00:24:09] __main__ INFO: \u001b[0mEpoch 21 Step 100/351 lr 0.100000 loss 1.8929 (1.8532) acc@1 0.2891 (0.3123) acc@5 0.7656 (0.7373)\n",
      "\u001b[32m[2020-07-14 00:24:18] __main__ INFO: \u001b[0mEpoch 21 Step 200/351 lr 0.100000 loss 2.0087 (1.8512) acc@1 0.2266 (0.3138) acc@5 0.6562 (0.7401)\n",
      "\u001b[32m[2020-07-14 00:24:28] __main__ INFO: \u001b[0mEpoch 21 Step 300/351 lr 0.100000 loss 1.8643 (1.8508) acc@1 0.3359 (0.3141) acc@5 0.7422 (0.7391)\n",
      "\u001b[32m[2020-07-14 00:24:32] __main__ INFO: \u001b[0mEpoch 21 Step 351/351 lr 0.100000 loss 1.8079 (1.8509) acc@1 0.3672 (0.3134) acc@5 0.7500 (0.7396)\n",
      "\u001b[32m[2020-07-14 00:24:32] __main__ INFO: \u001b[0mElapsed 32.36\n",
      "\u001b[32m[2020-07-14 00:24:32] __main__ INFO: \u001b[0mVal 21\n",
      "\u001b[32m[2020-07-14 00:24:33] __main__ INFO: \u001b[0mEpoch 21 loss 1.1808 acc@1 0.5892 acc@5 0.9474\n",
      "\u001b[32m[2020-07-14 00:24:33] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-07-14 00:24:33] __main__ INFO: \u001b[0mTrain 22 7371\n",
      "\u001b[32m[2020-07-14 00:24:43] __main__ INFO: \u001b[0mEpoch 22 Step 100/351 lr 0.100000 loss 1.7705 (1.8365) acc@1 0.3672 (0.3182) acc@5 0.7109 (0.7498)\n",
      "\u001b[32m[2020-07-14 00:24:52] __main__ INFO: \u001b[0mEpoch 22 Step 200/351 lr 0.100000 loss 1.8206 (1.8290) acc@1 0.2812 (0.3211) acc@5 0.7344 (0.7481)\n",
      "\u001b[32m[2020-07-14 00:25:01] __main__ INFO: \u001b[0mEpoch 22 Step 300/351 lr 0.100000 loss 1.9393 (1.8288) acc@1 0.2734 (0.3209) acc@5 0.7578 (0.7473)\n",
      "\u001b[32m[2020-07-14 00:25:06] __main__ INFO: \u001b[0mEpoch 22 Step 351/351 lr 0.100000 loss 1.8491 (1.8281) acc@1 0.3125 (0.3211) acc@5 0.7422 (0.7475)\n",
      "\u001b[32m[2020-07-14 00:25:06] __main__ INFO: \u001b[0mElapsed 32.28\n",
      "\u001b[32m[2020-07-14 00:25:06] __main__ INFO: \u001b[0mVal 22\n",
      "\u001b[32m[2020-07-14 00:25:07] __main__ INFO: \u001b[0mEpoch 22 loss 1.1752 acc@1 0.5822 acc@5 0.9476\n",
      "\u001b[32m[2020-07-14 00:25:07] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-07-14 00:25:07] __main__ INFO: \u001b[0mTrain 23 7722\n",
      "\u001b[32m[2020-07-14 00:25:16] __main__ INFO: \u001b[0mEpoch 23 Step 100/351 lr 0.100000 loss 1.7794 (1.7922) acc@1 0.3203 (0.3367) acc@5 0.7812 (0.7475)\n",
      "\u001b[32m[2020-07-14 00:25:25] __main__ INFO: \u001b[0mEpoch 23 Step 200/351 lr 0.100000 loss 1.7557 (1.7984) acc@1 0.3906 (0.3334) acc@5 0.7891 (0.7467)\n",
      "\u001b[32m[2020-07-14 00:25:34] __main__ INFO: \u001b[0mEpoch 23 Step 300/351 lr 0.100000 loss 1.9157 (1.8010) acc@1 0.3047 (0.3314) acc@5 0.6562 (0.7481)\n",
      "\u001b[32m[2020-07-14 00:25:39] __main__ INFO: \u001b[0mEpoch 23 Step 351/351 lr 0.100000 loss 1.7518 (1.8047) acc@1 0.3281 (0.3306) acc@5 0.8125 (0.7482)\n",
      "\u001b[32m[2020-07-14 00:25:39] __main__ INFO: \u001b[0mElapsed 32.28\n",
      "\u001b[32m[2020-07-14 00:25:39] __main__ INFO: \u001b[0mVal 23\n",
      "\u001b[32m[2020-07-14 00:25:40] __main__ INFO: \u001b[0mEpoch 23 loss 1.1489 acc@1 0.6016 acc@5 0.9450\n",
      "\u001b[32m[2020-07-14 00:25:40] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-07-14 00:25:40] __main__ INFO: \u001b[0mTrain 24 8073\n",
      "\u001b[32m[2020-07-14 00:25:49] __main__ INFO: \u001b[0mEpoch 24 Step 100/351 lr 0.100000 loss 1.8819 (1.7870) acc@1 0.2969 (0.3389) acc@5 0.7109 (0.7564)\n",
      "\u001b[32m[2020-07-14 00:25:58] __main__ INFO: \u001b[0mEpoch 24 Step 200/351 lr 0.100000 loss 1.8269 (1.7827) acc@1 0.3203 (0.3412) acc@5 0.7031 (0.7565)\n",
      "\u001b[32m[2020-07-14 00:26:08] __main__ INFO: \u001b[0mEpoch 24 Step 300/351 lr 0.100000 loss 1.7080 (1.7832) acc@1 0.3594 (0.3409) acc@5 0.7891 (0.7557)\n",
      "\u001b[32m[2020-07-14 00:26:12] __main__ INFO: \u001b[0mEpoch 24 Step 351/351 lr 0.100000 loss 1.8227 (1.7837) acc@1 0.3594 (0.3404) acc@5 0.6797 (0.7556)\n",
      "\u001b[32m[2020-07-14 00:26:12] __main__ INFO: \u001b[0mElapsed 32.29\n",
      "\u001b[32m[2020-07-14 00:26:12] __main__ INFO: \u001b[0mVal 24\n",
      "\u001b[32m[2020-07-14 00:26:13] __main__ INFO: \u001b[0mEpoch 24 loss 1.1442 acc@1 0.5970 acc@5 0.9480\n",
      "\u001b[32m[2020-07-14 00:26:13] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-07-14 00:26:13] __main__ INFO: \u001b[0mTrain 25 8424\n",
      "\u001b[32m[2020-07-14 00:26:23] __main__ INFO: \u001b[0mEpoch 25 Step 100/351 lr 0.100000 loss 1.6936 (1.7491) acc@1 0.3594 (0.3544) acc@5 0.7812 (0.7591)\n",
      "\u001b[32m[2020-07-14 00:26:32] __main__ INFO: \u001b[0mEpoch 25 Step 200/351 lr 0.100000 loss 1.7719 (1.7616) acc@1 0.3203 (0.3484) acc@5 0.7656 (0.7571)\n",
      "\u001b[32m[2020-07-14 00:26:41] __main__ INFO: \u001b[0mEpoch 25 Step 300/351 lr 0.100000 loss 1.7707 (1.7634) acc@1 0.3516 (0.3464) acc@5 0.6484 (0.7586)\n",
      "\u001b[32m[2020-07-14 00:26:46] __main__ INFO: \u001b[0mEpoch 25 Step 351/351 lr 0.100000 loss 1.8218 (1.7664) acc@1 0.3281 (0.3444) acc@5 0.7734 (0.7570)\n",
      "\u001b[32m[2020-07-14 00:26:46] __main__ INFO: \u001b[0mElapsed 32.17\n",
      "\u001b[32m[2020-07-14 00:26:46] __main__ INFO: \u001b[0mVal 25\n",
      "\u001b[32m[2020-07-14 00:26:47] __main__ INFO: \u001b[0mEpoch 25 loss 0.9768 acc@1 0.6544 acc@5 0.9668\n",
      "\u001b[32m[2020-07-14 00:26:47] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-07-14 00:26:47] __main__ INFO: \u001b[0mTrain 26 8775\n",
      "\u001b[32m[2020-07-14 00:26:56] __main__ INFO: \u001b[0mEpoch 26 Step 100/351 lr 0.100000 loss 1.7574 (1.7556) acc@1 0.3203 (0.3519) acc@5 0.7422 (0.7555)\n",
      "\u001b[32m[2020-07-14 00:27:05] __main__ INFO: \u001b[0mEpoch 26 Step 200/351 lr 0.100000 loss 1.7347 (1.7572) acc@1 0.3828 (0.3516) acc@5 0.7656 (0.7543)\n",
      "\u001b[32m[2020-07-14 00:27:14] __main__ INFO: \u001b[0mEpoch 26 Step 300/351 lr 0.100000 loss 1.8835 (1.7537) acc@1 0.3281 (0.3519) acc@5 0.7500 (0.7564)\n",
      "\u001b[32m[2020-07-14 00:27:19] __main__ INFO: \u001b[0mEpoch 26 Step 351/351 lr 0.100000 loss 1.6941 (1.7526) acc@1 0.3594 (0.3512) acc@5 0.7656 (0.7577)\n",
      "\u001b[32m[2020-07-14 00:27:19] __main__ INFO: \u001b[0mElapsed 32.26\n",
      "\u001b[32m[2020-07-14 00:27:19] __main__ INFO: \u001b[0mVal 26\n",
      "\u001b[32m[2020-07-14 00:27:20] __main__ INFO: \u001b[0mEpoch 26 loss 1.0112 acc@1 0.6492 acc@5 0.9630\n",
      "\u001b[32m[2020-07-14 00:27:20] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-07-14 00:27:20] __main__ INFO: \u001b[0mTrain 27 9126\n",
      "\u001b[32m[2020-07-14 00:27:29] __main__ INFO: \u001b[0mEpoch 27 Step 100/351 lr 0.100000 loss 1.7032 (1.7329) acc@1 0.3203 (0.3570) acc@5 0.7734 (0.7629)\n",
      "\u001b[32m[2020-07-14 00:27:38] __main__ INFO: \u001b[0mEpoch 27 Step 200/351 lr 0.100000 loss 1.7433 (1.7308) acc@1 0.3594 (0.3585) acc@5 0.7656 (0.7633)\n",
      "\u001b[32m[2020-07-14 00:27:47] __main__ INFO: \u001b[0mEpoch 27 Step 300/351 lr 0.100000 loss 1.7471 (1.7316) acc@1 0.3828 (0.3577) acc@5 0.8047 (0.7642)\n",
      "\u001b[32m[2020-07-14 00:27:52] __main__ INFO: \u001b[0mEpoch 27 Step 351/351 lr 0.100000 loss 1.6585 (1.7299) acc@1 0.3438 (0.3592) acc@5 0.7422 (0.7633)\n",
      "\u001b[32m[2020-07-14 00:27:52] __main__ INFO: \u001b[0mElapsed 32.22\n",
      "\u001b[32m[2020-07-14 00:27:52] __main__ INFO: \u001b[0mVal 27\n",
      "\u001b[32m[2020-07-14 00:27:53] __main__ INFO: \u001b[0mEpoch 27 loss 0.9297 acc@1 0.6720 acc@5 0.9708\n",
      "\u001b[32m[2020-07-14 00:27:53] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-07-14 00:27:53] __main__ INFO: \u001b[0mTrain 28 9477\n",
      "\u001b[32m[2020-07-14 00:28:03] __main__ INFO: \u001b[0mEpoch 28 Step 100/351 lr 0.100000 loss 1.7653 (1.7182) acc@1 0.2812 (0.3645) acc@5 0.7578 (0.7661)\n",
      "\u001b[32m[2020-07-14 00:28:12] __main__ INFO: \u001b[0mEpoch 28 Step 200/351 lr 0.100000 loss 1.7283 (1.7170) acc@1 0.3438 (0.3644) acc@5 0.7266 (0.7666)\n",
      "\u001b[32m[2020-07-14 00:28:21] __main__ INFO: \u001b[0mEpoch 28 Step 300/351 lr 0.100000 loss 1.7806 (1.7162) acc@1 0.2969 (0.3648) acc@5 0.7578 (0.7656)\n",
      "\u001b[32m[2020-07-14 00:28:26] __main__ INFO: \u001b[0mEpoch 28 Step 351/351 lr 0.100000 loss 1.6436 (1.7160) acc@1 0.3906 (0.3649) acc@5 0.7656 (0.7644)\n",
      "\u001b[32m[2020-07-14 00:28:26] __main__ INFO: \u001b[0mElapsed 32.31\n",
      "\u001b[32m[2020-07-14 00:28:26] __main__ INFO: \u001b[0mVal 28\n",
      "\u001b[32m[2020-07-14 00:28:27] __main__ INFO: \u001b[0mEpoch 28 loss 0.9815 acc@1 0.6716 acc@5 0.9580\n",
      "\u001b[32m[2020-07-14 00:28:27] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-07-14 00:28:27] __main__ INFO: \u001b[0mTrain 29 9828\n",
      "\u001b[32m[2020-07-14 00:28:36] __main__ INFO: \u001b[0mEpoch 29 Step 100/351 lr 0.100000 loss 1.6506 (1.7063) acc@1 0.3750 (0.3677) acc@5 0.7656 (0.7687)\n",
      "\u001b[32m[2020-07-14 00:28:45] __main__ INFO: \u001b[0mEpoch 29 Step 200/351 lr 0.100000 loss 1.7142 (1.7030) acc@1 0.3984 (0.3667) acc@5 0.8125 (0.7670)\n",
      "\u001b[32m[2020-07-14 00:28:54] __main__ INFO: \u001b[0mEpoch 29 Step 300/351 lr 0.100000 loss 1.7627 (1.7044) acc@1 0.3281 (0.3675) acc@5 0.7891 (0.7659)\n",
      "\u001b[32m[2020-07-14 00:28:59] __main__ INFO: \u001b[0mEpoch 29 Step 351/351 lr 0.100000 loss 1.7627 (1.7044) acc@1 0.3906 (0.3676) acc@5 0.7812 (0.7656)\n",
      "\u001b[32m[2020-07-14 00:28:59] __main__ INFO: \u001b[0mElapsed 32.28\n",
      "\u001b[32m[2020-07-14 00:28:59] __main__ INFO: \u001b[0mVal 29\n",
      "\u001b[32m[2020-07-14 00:29:00] __main__ INFO: \u001b[0mEpoch 29 loss 1.0930 acc@1 0.6430 acc@5 0.9484\n",
      "\u001b[32m[2020-07-14 00:29:00] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-07-14 00:29:00] __main__ INFO: \u001b[0mTrain 30 10179\n",
      "\u001b[32m[2020-07-14 00:29:09] __main__ INFO: \u001b[0mEpoch 30 Step 100/351 lr 0.100000 loss 1.6343 (1.6905) acc@1 0.3828 (0.3748) acc@5 0.8047 (0.7712)\n",
      "\u001b[32m[2020-07-14 00:29:18] __main__ INFO: \u001b[0mEpoch 30 Step 200/351 lr 0.100000 loss 1.6573 (1.6918) acc@1 0.3672 (0.3734) acc@5 0.7422 (0.7680)\n",
      "\u001b[32m[2020-07-14 00:29:28] __main__ INFO: \u001b[0mEpoch 30 Step 300/351 lr 0.100000 loss 1.6304 (1.6880) acc@1 0.3672 (0.3748) acc@5 0.8125 (0.7709)\n",
      "\u001b[32m[2020-07-14 00:29:32] __main__ INFO: \u001b[0mEpoch 30 Step 351/351 lr 0.100000 loss 1.6767 (1.6875) acc@1 0.4219 (0.3749) acc@5 0.6719 (0.7698)\n",
      "\u001b[32m[2020-07-14 00:29:32] __main__ INFO: \u001b[0mElapsed 32.42\n",
      "\u001b[32m[2020-07-14 00:29:32] __main__ INFO: \u001b[0mVal 30\n",
      "\u001b[32m[2020-07-14 00:29:33] __main__ INFO: \u001b[0mEpoch 30 loss 0.9451 acc@1 0.6804 acc@5 0.9668\n",
      "\u001b[32m[2020-07-14 00:29:33] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-07-14 00:29:33] __main__ INFO: \u001b[0mTrain 31 10530\n",
      "\u001b[32m[2020-07-14 00:29:43] __main__ INFO: \u001b[0mEpoch 31 Step 100/351 lr 0.100000 loss 1.5820 (1.6839) acc@1 0.4609 (0.3767) acc@5 0.7656 (0.7637)\n",
      "\u001b[32m[2020-07-14 00:29:52] __main__ INFO: \u001b[0mEpoch 31 Step 200/351 lr 0.100000 loss 1.5006 (1.6783) acc@1 0.4688 (0.3775) acc@5 0.7500 (0.7683)\n",
      "\u001b[32m[2020-07-14 00:30:01] __main__ INFO: \u001b[0mEpoch 31 Step 300/351 lr 0.100000 loss 1.6980 (1.6761) acc@1 0.3672 (0.3803) acc@5 0.7188 (0.7711)\n",
      "\u001b[32m[2020-07-14 00:30:06] __main__ INFO: \u001b[0mEpoch 31 Step 351/351 lr 0.100000 loss 1.7059 (1.6756) acc@1 0.3516 (0.3799) acc@5 0.7344 (0.7712)\n",
      "\u001b[32m[2020-07-14 00:30:06] __main__ INFO: \u001b[0mElapsed 32.36\n",
      "\u001b[32m[2020-07-14 00:30:06] __main__ INFO: \u001b[0mVal 31\n",
      "\u001b[32m[2020-07-14 00:30:07] __main__ INFO: \u001b[0mEpoch 31 loss 0.9025 acc@1 0.6956 acc@5 0.9700\n",
      "\u001b[32m[2020-07-14 00:30:07] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-07-14 00:30:07] __main__ INFO: \u001b[0mTrain 32 10881\n",
      "\u001b[32m[2020-07-14 00:30:16] __main__ INFO: \u001b[0mEpoch 32 Step 100/351 lr 0.100000 loss 1.6555 (1.6503) acc@1 0.3359 (0.3850) acc@5 0.7188 (0.7730)\n",
      "\u001b[32m[2020-07-14 00:30:25] __main__ INFO: \u001b[0mEpoch 32 Step 200/351 lr 0.100000 loss 1.6568 (1.6599) acc@1 0.3906 (0.3819) acc@5 0.7500 (0.7698)\n",
      "\u001b[32m[2020-07-14 00:30:34] __main__ INFO: \u001b[0mEpoch 32 Step 300/351 lr 0.100000 loss 1.8399 (1.6615) acc@1 0.2969 (0.3805) acc@5 0.7500 (0.7691)\n",
      "\u001b[32m[2020-07-14 00:30:39] __main__ INFO: \u001b[0mEpoch 32 Step 351/351 lr 0.100000 loss 1.5634 (1.6641) acc@1 0.4453 (0.3806) acc@5 0.8125 (0.7682)\n",
      "\u001b[32m[2020-07-14 00:30:39] __main__ INFO: \u001b[0mElapsed 32.34\n",
      "\u001b[32m[2020-07-14 00:30:39] __main__ INFO: \u001b[0mVal 32\n",
      "\u001b[32m[2020-07-14 00:30:40] __main__ INFO: \u001b[0mEpoch 32 loss 0.9612 acc@1 0.6708 acc@5 0.9654\n",
      "\u001b[32m[2020-07-14 00:30:40] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-07-14 00:30:40] __main__ INFO: \u001b[0mTrain 33 11232\n",
      "\u001b[32m[2020-07-14 00:30:50] __main__ INFO: \u001b[0mEpoch 33 Step 100/351 lr 0.100000 loss 1.5943 (1.6455) acc@1 0.4062 (0.3921) acc@5 0.7656 (0.7727)\n",
      "\u001b[32m[2020-07-14 00:30:59] __main__ INFO: \u001b[0mEpoch 33 Step 200/351 lr 0.100000 loss 1.6446 (1.6489) acc@1 0.3828 (0.3884) acc@5 0.7812 (0.7739)\n",
      "\u001b[32m[2020-07-14 00:31:08] __main__ INFO: \u001b[0mEpoch 33 Step 300/351 lr 0.100000 loss 1.5141 (1.6540) acc@1 0.4531 (0.3868) acc@5 0.8125 (0.7738)\n",
      "\u001b[32m[2020-07-14 00:31:12] __main__ INFO: \u001b[0mEpoch 33 Step 351/351 lr 0.100000 loss 1.5630 (1.6521) acc@1 0.3984 (0.3885) acc@5 0.7969 (0.7737)\n",
      "\u001b[32m[2020-07-14 00:31:13] __main__ INFO: \u001b[0mElapsed 32.29\n",
      "\u001b[32m[2020-07-14 00:31:13] __main__ INFO: \u001b[0mVal 33\n",
      "\u001b[32m[2020-07-14 00:31:14] __main__ INFO: \u001b[0mEpoch 33 loss 0.9969 acc@1 0.6540 acc@5 0.9754\n",
      "\u001b[32m[2020-07-14 00:31:14] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-07-14 00:31:14] __main__ INFO: \u001b[0mTrain 34 11583\n",
      "\u001b[32m[2020-07-14 00:31:23] __main__ INFO: \u001b[0mEpoch 34 Step 100/351 lr 0.100000 loss 1.7415 (1.6294) acc@1 0.3672 (0.3956) acc@5 0.7500 (0.7759)\n",
      "\u001b[32m[2020-07-14 00:31:32] __main__ INFO: \u001b[0mEpoch 34 Step 200/351 lr 0.100000 loss 1.5530 (1.6316) acc@1 0.4141 (0.3945) acc@5 0.7812 (0.7714)\n",
      "\u001b[32m[2020-07-14 00:31:41] __main__ INFO: \u001b[0mEpoch 34 Step 300/351 lr 0.100000 loss 1.6091 (1.6356) acc@1 0.4219 (0.3922) acc@5 0.7422 (0.7730)\n",
      "\u001b[32m[2020-07-14 00:31:46] __main__ INFO: \u001b[0mEpoch 34 Step 351/351 lr 0.100000 loss 1.6542 (1.6388) acc@1 0.3438 (0.3909) acc@5 0.7500 (0.7732)\n",
      "\u001b[32m[2020-07-14 00:31:46] __main__ INFO: \u001b[0mElapsed 32.28\n",
      "\u001b[32m[2020-07-14 00:31:46] __main__ INFO: \u001b[0mVal 34\n",
      "\u001b[32m[2020-07-14 00:31:47] __main__ INFO: \u001b[0mEpoch 34 loss 0.9019 acc@1 0.6816 acc@5 0.9712\n",
      "\u001b[32m[2020-07-14 00:31:47] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-07-14 00:31:47] __main__ INFO: \u001b[0mTrain 35 11934\n",
      "\u001b[32m[2020-07-14 00:31:56] __main__ INFO: \u001b[0mEpoch 35 Step 100/351 lr 0.100000 loss 1.5129 (1.6363) acc@1 0.4141 (0.3956) acc@5 0.7812 (0.7726)\n",
      "\u001b[32m[2020-07-14 00:32:05] __main__ INFO: \u001b[0mEpoch 35 Step 200/351 lr 0.100000 loss 1.6112 (1.6291) acc@1 0.3984 (0.3976) acc@5 0.7578 (0.7757)\n",
      "\u001b[32m[2020-07-14 00:32:15] __main__ INFO: \u001b[0mEpoch 35 Step 300/351 lr 0.100000 loss 1.6451 (1.6300) acc@1 0.3672 (0.3967) acc@5 0.7656 (0.7764)\n",
      "\u001b[32m[2020-07-14 00:32:19] __main__ INFO: \u001b[0mEpoch 35 Step 351/351 lr 0.100000 loss 1.6811 (1.6341) acc@1 0.4062 (0.3952) acc@5 0.7656 (0.7764)\n",
      "\u001b[32m[2020-07-14 00:32:19] __main__ INFO: \u001b[0mElapsed 32.34\n",
      "\u001b[32m[2020-07-14 00:32:19] __main__ INFO: \u001b[0mVal 35\n",
      "\u001b[32m[2020-07-14 00:32:20] __main__ INFO: \u001b[0mEpoch 35 loss 0.8953 acc@1 0.6914 acc@5 0.9788\n",
      "\u001b[32m[2020-07-14 00:32:20] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-14 00:32:20] __main__ INFO: \u001b[0mTrain 36 12285\n",
      "\u001b[32m[2020-07-14 00:32:30] __main__ INFO: \u001b[0mEpoch 36 Step 100/351 lr 0.100000 loss 1.5270 (1.6418) acc@1 0.4688 (0.3898) acc@5 0.7969 (0.7709)\n",
      "\u001b[32m[2020-07-14 00:32:39] __main__ INFO: \u001b[0mEpoch 36 Step 200/351 lr 0.100000 loss 1.6429 (1.6278) acc@1 0.3828 (0.3963) acc@5 0.8125 (0.7752)\n",
      "\u001b[32m[2020-07-14 00:32:48] __main__ INFO: \u001b[0mEpoch 36 Step 300/351 lr 0.100000 loss 1.5595 (1.6257) acc@1 0.4062 (0.3963) acc@5 0.8203 (0.7741)\n",
      "\u001b[32m[2020-07-14 00:32:53] __main__ INFO: \u001b[0mEpoch 36 Step 351/351 lr 0.100000 loss 1.5806 (1.6251) acc@1 0.3984 (0.3958) acc@5 0.7500 (0.7753)\n",
      "\u001b[32m[2020-07-14 00:32:53] __main__ INFO: \u001b[0mElapsed 32.41\n",
      "\u001b[32m[2020-07-14 00:32:53] __main__ INFO: \u001b[0mVal 36\n",
      "\u001b[32m[2020-07-14 00:32:54] __main__ INFO: \u001b[0mEpoch 36 loss 0.8276 acc@1 0.7112 acc@5 0.9776\n",
      "\u001b[32m[2020-07-14 00:32:54] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-07-14 00:32:54] __main__ INFO: \u001b[0mTrain 37 12636\n",
      "\u001b[32m[2020-07-14 00:33:03] __main__ INFO: \u001b[0mEpoch 37 Step 100/351 lr 0.100000 loss 1.7385 (1.5846) acc@1 0.3359 (0.4102) acc@5 0.7109 (0.7891)\n",
      "\u001b[32m[2020-07-14 00:33:12] __main__ INFO: \u001b[0mEpoch 37 Step 200/351 lr 0.100000 loss 1.5173 (1.6091) acc@1 0.4375 (0.3995) acc@5 0.7969 (0.7832)\n",
      "\u001b[32m[2020-07-14 00:33:21] __main__ INFO: \u001b[0mEpoch 37 Step 300/351 lr 0.100000 loss 1.6419 (1.6078) acc@1 0.3750 (0.4010) acc@5 0.7656 (0.7827)\n",
      "\u001b[32m[2020-07-14 00:33:26] __main__ INFO: \u001b[0mEpoch 37 Step 351/351 lr 0.100000 loss 1.6355 (1.6101) acc@1 0.3672 (0.4002) acc@5 0.7891 (0.7812)\n",
      "\u001b[32m[2020-07-14 00:33:26] __main__ INFO: \u001b[0mElapsed 32.34\n",
      "\u001b[32m[2020-07-14 00:33:26] __main__ INFO: \u001b[0mVal 37\n",
      "\u001b[32m[2020-07-14 00:33:27] __main__ INFO: \u001b[0mEpoch 37 loss 0.8009 acc@1 0.7226 acc@5 0.9772\n",
      "\u001b[32m[2020-07-14 00:33:27] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-07-14 00:33:27] __main__ INFO: \u001b[0mTrain 38 12987\n",
      "\u001b[32m[2020-07-14 00:33:36] __main__ INFO: \u001b[0mEpoch 38 Step 100/351 lr 0.100000 loss 1.7008 (1.5866) acc@1 0.3750 (0.4127) acc@5 0.8047 (0.7807)\n",
      "\u001b[32m[2020-07-14 00:33:46] __main__ INFO: \u001b[0mEpoch 38 Step 200/351 lr 0.100000 loss 1.5695 (1.5980) acc@1 0.4062 (0.4078) acc@5 0.8047 (0.7783)\n",
      "\u001b[32m[2020-07-14 00:33:55] __main__ INFO: \u001b[0mEpoch 38 Step 300/351 lr 0.100000 loss 1.5654 (1.5994) acc@1 0.4375 (0.4074) acc@5 0.7500 (0.7780)\n",
      "\u001b[32m[2020-07-14 00:34:00] __main__ INFO: \u001b[0mEpoch 38 Step 351/351 lr 0.100000 loss 1.6445 (1.6019) acc@1 0.3359 (0.4070) acc@5 0.7656 (0.7778)\n",
      "\u001b[32m[2020-07-14 00:34:00] __main__ INFO: \u001b[0mElapsed 32.35\n",
      "\u001b[32m[2020-07-14 00:34:00] __main__ INFO: \u001b[0mVal 38\n",
      "\u001b[32m[2020-07-14 00:34:01] __main__ INFO: \u001b[0mEpoch 38 loss 0.9477 acc@1 0.6802 acc@5 0.9688\n",
      "\u001b[32m[2020-07-14 00:34:01] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-07-14 00:34:01] __main__ INFO: \u001b[0mTrain 39 13338\n",
      "\u001b[32m[2020-07-14 00:34:10] __main__ INFO: \u001b[0mEpoch 39 Step 100/351 lr 0.100000 loss 1.5903 (1.5880) acc@1 0.3672 (0.4088) acc@5 0.7500 (0.7837)\n",
      "\u001b[32m[2020-07-14 00:34:19] __main__ INFO: \u001b[0mEpoch 39 Step 200/351 lr 0.100000 loss 1.5565 (1.5912) acc@1 0.3828 (0.4091) acc@5 0.8047 (0.7819)\n",
      "\u001b[32m[2020-07-14 00:34:28] __main__ INFO: \u001b[0mEpoch 39 Step 300/351 lr 0.100000 loss 1.7070 (1.5975) acc@1 0.3906 (0.4064) acc@5 0.8125 (0.7807)\n",
      "\u001b[32m[2020-07-14 00:34:33] __main__ INFO: \u001b[0mEpoch 39 Step 351/351 lr 0.100000 loss 1.7563 (1.5973) acc@1 0.3906 (0.4066) acc@5 0.8125 (0.7808)\n",
      "\u001b[32m[2020-07-14 00:34:33] __main__ INFO: \u001b[0mElapsed 32.35\n",
      "\u001b[32m[2020-07-14 00:34:33] __main__ INFO: \u001b[0mVal 39\n",
      "\u001b[32m[2020-07-14 00:34:34] __main__ INFO: \u001b[0mEpoch 39 loss 0.9147 acc@1 0.7004 acc@5 0.9698\n",
      "\u001b[32m[2020-07-14 00:34:34] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-07-14 00:34:34] __main__ INFO: \u001b[0mTrain 40 13689\n",
      "\u001b[32m[2020-07-14 00:34:43] __main__ INFO: \u001b[0mEpoch 40 Step 100/351 lr 0.100000 loss 1.5864 (1.5779) acc@1 0.4141 (0.4162) acc@5 0.7969 (0.7830)\n",
      "\u001b[32m[2020-07-14 00:34:52] __main__ INFO: \u001b[0mEpoch 40 Step 200/351 lr 0.100000 loss 1.5647 (1.5776) acc@1 0.4219 (0.4156) acc@5 0.7812 (0.7841)\n",
      "\u001b[32m[2020-07-14 00:35:02] __main__ INFO: \u001b[0mEpoch 40 Step 300/351 lr 0.100000 loss 1.4856 (1.5834) acc@1 0.4375 (0.4135) acc@5 0.8047 (0.7819)\n",
      "\u001b[32m[2020-07-14 00:35:06] __main__ INFO: \u001b[0mEpoch 40 Step 351/351 lr 0.100000 loss 1.5845 (1.5858) acc@1 0.4375 (0.4122) acc@5 0.7969 (0.7812)\n",
      "\u001b[32m[2020-07-14 00:35:06] __main__ INFO: \u001b[0mElapsed 32.31\n",
      "\u001b[32m[2020-07-14 00:35:06] __main__ INFO: \u001b[0mVal 40\n",
      "\u001b[32m[2020-07-14 00:35:07] __main__ INFO: \u001b[0mEpoch 40 loss 0.7514 acc@1 0.7434 acc@5 0.9806\n",
      "\u001b[32m[2020-07-14 00:35:07] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-07-14 00:35:07] __main__ INFO: \u001b[0mTrain 41 14040\n",
      "\u001b[32m[2020-07-14 00:35:17] __main__ INFO: \u001b[0mEpoch 41 Step 100/351 lr 0.100000 loss 1.7318 (1.5734) acc@1 0.3203 (0.4182) acc@5 0.7812 (0.7862)\n",
      "\u001b[32m[2020-07-14 00:35:26] __main__ INFO: \u001b[0mEpoch 41 Step 200/351 lr 0.100000 loss 1.4127 (1.5770) acc@1 0.4219 (0.4149) acc@5 0.7812 (0.7822)\n",
      "\u001b[32m[2020-07-14 00:35:35] __main__ INFO: \u001b[0mEpoch 41 Step 300/351 lr 0.100000 loss 1.6678 (1.5843) acc@1 0.3672 (0.4124) acc@5 0.7812 (0.7810)\n",
      "\u001b[32m[2020-07-14 00:35:40] __main__ INFO: \u001b[0mEpoch 41 Step 351/351 lr 0.100000 loss 1.7121 (1.5838) acc@1 0.4062 (0.4121) acc@5 0.7734 (0.7813)\n",
      "\u001b[32m[2020-07-14 00:35:40] __main__ INFO: \u001b[0mElapsed 32.26\n",
      "\u001b[32m[2020-07-14 00:35:40] __main__ INFO: \u001b[0mVal 41\n",
      "\u001b[32m[2020-07-14 00:35:41] __main__ INFO: \u001b[0mEpoch 41 loss 0.7239 acc@1 0.7504 acc@5 0.9824\n",
      "\u001b[32m[2020-07-14 00:35:41] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-07-14 00:35:41] __main__ INFO: \u001b[0mTrain 42 14391\n",
      "\u001b[32m[2020-07-14 00:35:50] __main__ INFO: \u001b[0mEpoch 42 Step 100/351 lr 0.100000 loss 1.5808 (1.5664) acc@1 0.4062 (0.4147) acc@5 0.8047 (0.7882)\n",
      "\u001b[32m[2020-07-14 00:35:59] __main__ INFO: \u001b[0mEpoch 42 Step 200/351 lr 0.100000 loss 1.5458 (1.5719) acc@1 0.4297 (0.4130) acc@5 0.8047 (0.7858)\n",
      "\u001b[32m[2020-07-14 00:36:08] __main__ INFO: \u001b[0mEpoch 42 Step 300/351 lr 0.100000 loss 1.6650 (1.5719) acc@1 0.3672 (0.4151) acc@5 0.8047 (0.7846)\n",
      "\u001b[32m[2020-07-14 00:36:13] __main__ INFO: \u001b[0mEpoch 42 Step 351/351 lr 0.100000 loss 1.6295 (1.5746) acc@1 0.3750 (0.4142) acc@5 0.8047 (0.7844)\n",
      "\u001b[32m[2020-07-14 00:36:13] __main__ INFO: \u001b[0mElapsed 32.22\n",
      "\u001b[32m[2020-07-14 00:36:13] __main__ INFO: \u001b[0mVal 42\n",
      "\u001b[32m[2020-07-14 00:36:14] __main__ INFO: \u001b[0mEpoch 42 loss 0.7755 acc@1 0.7376 acc@5 0.9810\n",
      "\u001b[32m[2020-07-14 00:36:14] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-07-14 00:36:14] __main__ INFO: \u001b[0mTrain 43 14742\n",
      "\u001b[32m[2020-07-14 00:36:23] __main__ INFO: \u001b[0mEpoch 43 Step 100/351 lr 0.100000 loss 1.5013 (1.5553) acc@1 0.4531 (0.4261) acc@5 0.7578 (0.7880)\n",
      "\u001b[32m[2020-07-14 00:36:32] __main__ INFO: \u001b[0mEpoch 43 Step 200/351 lr 0.100000 loss 1.7895 (1.5619) acc@1 0.3359 (0.4221) acc@5 0.7656 (0.7844)\n",
      "\u001b[32m[2020-07-14 00:36:42] __main__ INFO: \u001b[0mEpoch 43 Step 300/351 lr 0.100000 loss 1.5704 (1.5713) acc@1 0.3672 (0.4181) acc@5 0.8125 (0.7822)\n",
      "\u001b[32m[2020-07-14 00:36:46] __main__ INFO: \u001b[0mEpoch 43 Step 351/351 lr 0.100000 loss 1.4755 (1.5685) acc@1 0.4375 (0.4192) acc@5 0.7969 (0.7827)\n",
      "\u001b[32m[2020-07-14 00:36:46] __main__ INFO: \u001b[0mElapsed 32.39\n",
      "\u001b[32m[2020-07-14 00:36:46] __main__ INFO: \u001b[0mVal 43\n",
      "\u001b[32m[2020-07-14 00:36:47] __main__ INFO: \u001b[0mEpoch 43 loss 0.8021 acc@1 0.7288 acc@5 0.9784\n",
      "\u001b[32m[2020-07-14 00:36:47] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-07-14 00:36:47] __main__ INFO: \u001b[0mTrain 44 15093\n",
      "\u001b[32m[2020-07-14 00:36:57] __main__ INFO: \u001b[0mEpoch 44 Step 100/351 lr 0.100000 loss 1.5325 (1.5448) acc@1 0.5000 (0.4273) acc@5 0.8047 (0.7923)\n",
      "\u001b[32m[2020-07-14 00:37:06] __main__ INFO: \u001b[0mEpoch 44 Step 200/351 lr 0.100000 loss 1.4176 (1.5529) acc@1 0.4609 (0.4252) acc@5 0.8438 (0.7884)\n",
      "\u001b[32m[2020-07-14 00:37:15] __main__ INFO: \u001b[0mEpoch 44 Step 300/351 lr 0.100000 loss 1.3961 (1.5583) acc@1 0.4766 (0.4227) acc@5 0.7969 (0.7857)\n",
      "\u001b[32m[2020-07-14 00:37:20] __main__ INFO: \u001b[0mEpoch 44 Step 351/351 lr 0.100000 loss 1.6359 (1.5602) acc@1 0.3828 (0.4230) acc@5 0.8047 (0.7853)\n",
      "\u001b[32m[2020-07-14 00:37:20] __main__ INFO: \u001b[0mElapsed 32.33\n",
      "\u001b[32m[2020-07-14 00:37:20] __main__ INFO: \u001b[0mVal 44\n",
      "\u001b[32m[2020-07-14 00:37:21] __main__ INFO: \u001b[0mEpoch 44 loss 0.9052 acc@1 0.7006 acc@5 0.9732\n",
      "\u001b[32m[2020-07-14 00:37:21] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-07-14 00:37:21] __main__ INFO: \u001b[0mTrain 45 15444\n",
      "\u001b[32m[2020-07-14 00:37:30] __main__ INFO: \u001b[0mEpoch 45 Step 100/351 lr 0.100000 loss 1.5325 (1.5454) acc@1 0.3984 (0.4285) acc@5 0.8281 (0.7916)\n",
      "\u001b[32m[2020-07-14 00:37:39] __main__ INFO: \u001b[0mEpoch 45 Step 200/351 lr 0.100000 loss 1.6460 (1.5448) acc@1 0.3594 (0.4271) acc@5 0.7969 (0.7912)\n",
      "\u001b[32m[2020-07-14 00:37:48] __main__ INFO: \u001b[0mEpoch 45 Step 300/351 lr 0.100000 loss 1.4387 (1.5465) acc@1 0.4844 (0.4264) acc@5 0.7812 (0.7887)\n",
      "\u001b[32m[2020-07-14 00:37:53] __main__ INFO: \u001b[0mEpoch 45 Step 351/351 lr 0.100000 loss 1.4677 (1.5524) acc@1 0.4531 (0.4237) acc@5 0.8516 (0.7868)\n",
      "\u001b[32m[2020-07-14 00:37:53] __main__ INFO: \u001b[0mElapsed 32.35\n",
      "\u001b[32m[2020-07-14 00:37:53] __main__ INFO: \u001b[0mVal 45\n",
      "\u001b[32m[2020-07-14 00:37:54] __main__ INFO: \u001b[0mEpoch 45 loss 0.7872 acc@1 0.7332 acc@5 0.9760\n",
      "\u001b[32m[2020-07-14 00:37:54] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-07-14 00:37:54] __main__ INFO: \u001b[0mTrain 46 15795\n",
      "\u001b[32m[2020-07-14 00:38:03] __main__ INFO: \u001b[0mEpoch 46 Step 100/351 lr 0.100000 loss 1.4023 (1.5327) acc@1 0.4453 (0.4358) acc@5 0.7734 (0.7830)\n",
      "\u001b[32m[2020-07-14 00:38:13] __main__ INFO: \u001b[0mEpoch 46 Step 200/351 lr 0.100000 loss 1.4630 (1.5395) acc@1 0.4531 (0.4304) acc@5 0.7500 (0.7848)\n",
      "\u001b[32m[2020-07-14 00:38:22] __main__ INFO: \u001b[0mEpoch 46 Step 300/351 lr 0.100000 loss 1.5425 (1.5456) acc@1 0.4297 (0.4275) acc@5 0.8203 (0.7853)\n",
      "\u001b[32m[2020-07-14 00:38:26] __main__ INFO: \u001b[0mEpoch 46 Step 351/351 lr 0.100000 loss 1.5482 (1.5475) acc@1 0.4219 (0.4267) acc@5 0.7734 (0.7852)\n",
      "\u001b[32m[2020-07-14 00:38:26] __main__ INFO: \u001b[0mElapsed 32.30\n",
      "\u001b[32m[2020-07-14 00:38:26] __main__ INFO: \u001b[0mVal 46\n",
      "\u001b[32m[2020-07-14 00:38:28] __main__ INFO: \u001b[0mEpoch 46 loss 0.7647 acc@1 0.7398 acc@5 0.9792\n",
      "\u001b[32m[2020-07-14 00:38:28] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-07-14 00:38:28] __main__ INFO: \u001b[0mTrain 47 16146\n",
      "\u001b[32m[2020-07-14 00:38:37] __main__ INFO: \u001b[0mEpoch 47 Step 100/351 lr 0.100000 loss 1.5450 (1.5332) acc@1 0.4062 (0.4285) acc@5 0.7891 (0.7913)\n",
      "\u001b[32m[2020-07-14 00:38:46] __main__ INFO: \u001b[0mEpoch 47 Step 200/351 lr 0.100000 loss 1.6862 (1.5347) acc@1 0.4062 (0.4302) acc@5 0.7578 (0.7875)\n",
      "\u001b[32m[2020-07-14 00:38:55] __main__ INFO: \u001b[0mEpoch 47 Step 300/351 lr 0.100000 loss 1.3830 (1.5363) acc@1 0.4844 (0.4298) acc@5 0.8125 (0.7876)\n",
      "\u001b[32m[2020-07-14 00:39:00] __main__ INFO: \u001b[0mEpoch 47 Step 351/351 lr 0.100000 loss 1.7193 (1.5381) acc@1 0.3438 (0.4283) acc@5 0.7656 (0.7872)\n",
      "\u001b[32m[2020-07-14 00:39:00] __main__ INFO: \u001b[0mElapsed 32.31\n",
      "\u001b[32m[2020-07-14 00:39:00] __main__ INFO: \u001b[0mVal 47\n",
      "\u001b[32m[2020-07-14 00:39:01] __main__ INFO: \u001b[0mEpoch 47 loss 0.8371 acc@1 0.7216 acc@5 0.9772\n",
      "\u001b[32m[2020-07-14 00:39:01] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-07-14 00:39:01] __main__ INFO: \u001b[0mTrain 48 16497\n",
      "\u001b[32m[2020-07-14 00:39:10] __main__ INFO: \u001b[0mEpoch 48 Step 100/351 lr 0.100000 loss 1.5876 (1.5308) acc@1 0.4375 (0.4283) acc@5 0.7812 (0.7853)\n",
      "\u001b[32m[2020-07-14 00:39:19] __main__ INFO: \u001b[0mEpoch 48 Step 200/351 lr 0.100000 loss 1.5238 (1.5302) acc@1 0.4609 (0.4293) acc@5 0.7812 (0.7900)\n",
      "\u001b[32m[2020-07-14 00:39:29] __main__ INFO: \u001b[0mEpoch 48 Step 300/351 lr 0.100000 loss 1.6554 (1.5380) acc@1 0.3828 (0.4266) acc@5 0.7734 (0.7886)\n",
      "\u001b[32m[2020-07-14 00:39:33] __main__ INFO: \u001b[0mEpoch 48 Step 351/351 lr 0.100000 loss 1.5130 (1.5364) acc@1 0.4688 (0.4276) acc@5 0.7656 (0.7873)\n",
      "\u001b[32m[2020-07-14 00:39:33] __main__ INFO: \u001b[0mElapsed 32.36\n",
      "\u001b[32m[2020-07-14 00:39:33] __main__ INFO: \u001b[0mVal 48\n",
      "\u001b[32m[2020-07-14 00:39:34] __main__ INFO: \u001b[0mEpoch 48 loss 0.6999 acc@1 0.7646 acc@5 0.9848\n",
      "\u001b[32m[2020-07-14 00:39:34] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-07-14 00:39:34] __main__ INFO: \u001b[0mTrain 49 16848\n",
      "\u001b[32m[2020-07-14 00:39:44] __main__ INFO: \u001b[0mEpoch 49 Step 100/351 lr 0.100000 loss 1.5192 (1.5202) acc@1 0.4609 (0.4327) acc@5 0.8281 (0.7909)\n",
      "\u001b[32m[2020-07-14 00:39:53] __main__ INFO: \u001b[0mEpoch 49 Step 200/351 lr 0.100000 loss 1.6663 (1.5191) acc@1 0.3828 (0.4344) acc@5 0.8359 (0.7918)\n",
      "\u001b[32m[2020-07-14 00:40:02] __main__ INFO: \u001b[0mEpoch 49 Step 300/351 lr 0.100000 loss 1.6246 (1.5263) acc@1 0.3984 (0.4309) acc@5 0.7578 (0.7870)\n",
      "\u001b[32m[2020-07-14 00:40:07] __main__ INFO: \u001b[0mEpoch 49 Step 351/351 lr 0.100000 loss 1.5720 (1.5295) acc@1 0.3984 (0.4300) acc@5 0.8047 (0.7869)\n",
      "\u001b[32m[2020-07-14 00:40:07] __main__ INFO: \u001b[0mElapsed 32.35\n",
      "\u001b[32m[2020-07-14 00:40:07] __main__ INFO: \u001b[0mVal 49\n",
      "\u001b[32m[2020-07-14 00:40:08] __main__ INFO: \u001b[0mEpoch 49 loss 0.7937 acc@1 0.7294 acc@5 0.9792\n",
      "\u001b[32m[2020-07-14 00:40:08] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-07-14 00:40:08] __main__ INFO: \u001b[0mTrain 50 17199\n",
      "\u001b[32m[2020-07-14 00:40:17] __main__ INFO: \u001b[0mEpoch 50 Step 100/351 lr 0.100000 loss 1.5592 (1.5039) acc@1 0.4453 (0.4398) acc@5 0.7891 (0.7920)\n",
      "\u001b[32m[2020-07-14 00:40:26] __main__ INFO: \u001b[0mEpoch 50 Step 200/351 lr 0.100000 loss 1.5132 (1.5167) acc@1 0.3906 (0.4361) acc@5 0.8203 (0.7895)\n",
      "\u001b[32m[2020-07-14 00:40:35] __main__ INFO: \u001b[0mEpoch 50 Step 300/351 lr 0.100000 loss 1.5620 (1.5203) acc@1 0.4297 (0.4358) acc@5 0.7969 (0.7891)\n",
      "\u001b[32m[2020-07-14 00:40:40] __main__ INFO: \u001b[0mEpoch 50 Step 351/351 lr 0.100000 loss 1.5947 (1.5228) acc@1 0.4141 (0.4357) acc@5 0.7188 (0.7886)\n",
      "\u001b[32m[2020-07-14 00:40:40] __main__ INFO: \u001b[0mElapsed 32.30\n",
      "\u001b[32m[2020-07-14 00:40:40] __main__ INFO: \u001b[0mVal 50\n",
      "\u001b[32m[2020-07-14 00:40:41] __main__ INFO: \u001b[0mEpoch 50 loss 0.7506 acc@1 0.7460 acc@5 0.9824\n",
      "\u001b[32m[2020-07-14 00:40:41] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-07-14 00:40:41] __main__ INFO: \u001b[0mTrain 51 17550\n",
      "\u001b[32m[2020-07-14 00:40:50] __main__ INFO: \u001b[0mEpoch 51 Step 100/351 lr 0.100000 loss 1.4918 (1.4982) acc@1 0.4375 (0.4396) acc@5 0.8281 (0.7895)\n",
      "\u001b[32m[2020-07-14 00:41:00] __main__ INFO: \u001b[0mEpoch 51 Step 200/351 lr 0.100000 loss 1.6034 (1.5088) acc@1 0.3828 (0.4374) acc@5 0.7969 (0.7886)\n",
      "\u001b[32m[2020-07-14 00:41:09] __main__ INFO: \u001b[0mEpoch 51 Step 300/351 lr 0.100000 loss 1.4946 (1.5182) acc@1 0.4531 (0.4345) acc@5 0.8203 (0.7870)\n",
      "\u001b[32m[2020-07-14 00:41:13] __main__ INFO: \u001b[0mEpoch 51 Step 351/351 lr 0.100000 loss 1.6618 (1.5192) acc@1 0.3594 (0.4333) acc@5 0.7656 (0.7877)\n",
      "\u001b[32m[2020-07-14 00:41:13] __main__ INFO: \u001b[0mElapsed 32.36\n",
      "\u001b[32m[2020-07-14 00:41:13] __main__ INFO: \u001b[0mVal 51\n",
      "\u001b[32m[2020-07-14 00:41:15] __main__ INFO: \u001b[0mEpoch 51 loss 0.7131 acc@1 0.7494 acc@5 0.9838\n",
      "\u001b[32m[2020-07-14 00:41:15] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-07-14 00:41:15] __main__ INFO: \u001b[0mTrain 52 17901\n",
      "\u001b[32m[2020-07-14 00:41:24] __main__ INFO: \u001b[0mEpoch 52 Step 100/351 lr 0.100000 loss 1.2719 (1.5000) acc@1 0.5859 (0.4473) acc@5 0.7969 (0.7892)\n",
      "\u001b[32m[2020-07-14 00:41:33] __main__ INFO: \u001b[0mEpoch 52 Step 200/351 lr 0.100000 loss 1.4023 (1.5008) acc@1 0.4688 (0.4432) acc@5 0.7812 (0.7894)\n",
      "\u001b[32m[2020-07-14 00:41:42] __main__ INFO: \u001b[0mEpoch 52 Step 300/351 lr 0.100000 loss 1.5435 (1.5047) acc@1 0.3906 (0.4419) acc@5 0.7344 (0.7882)\n",
      "\u001b[32m[2020-07-14 00:41:47] __main__ INFO: \u001b[0mEpoch 52 Step 351/351 lr 0.100000 loss 1.5985 (1.5083) acc@1 0.4141 (0.4409) acc@5 0.8125 (0.7884)\n",
      "\u001b[32m[2020-07-14 00:41:47] __main__ INFO: \u001b[0mElapsed 32.32\n",
      "\u001b[32m[2020-07-14 00:41:47] __main__ INFO: \u001b[0mVal 52\n",
      "\u001b[32m[2020-07-14 00:41:48] __main__ INFO: \u001b[0mEpoch 52 loss 0.7855 acc@1 0.7432 acc@5 0.9754\n",
      "\u001b[32m[2020-07-14 00:41:48] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-07-14 00:41:48] __main__ INFO: \u001b[0mTrain 53 18252\n",
      "\u001b[32m[2020-07-14 00:41:57] __main__ INFO: \u001b[0mEpoch 53 Step 100/351 lr 0.100000 loss 1.5170 (1.4973) acc@1 0.4219 (0.4452) acc@5 0.7656 (0.7866)\n",
      "\u001b[32m[2020-07-14 00:42:06] __main__ INFO: \u001b[0mEpoch 53 Step 200/351 lr 0.100000 loss 1.4158 (1.5098) acc@1 0.5000 (0.4386) acc@5 0.7891 (0.7899)\n",
      "\u001b[32m[2020-07-14 00:42:15] __main__ INFO: \u001b[0mEpoch 53 Step 300/351 lr 0.100000 loss 1.4707 (1.5088) acc@1 0.4531 (0.4377) acc@5 0.7344 (0.7875)\n",
      "\u001b[32m[2020-07-14 00:42:20] __main__ INFO: \u001b[0mEpoch 53 Step 351/351 lr 0.100000 loss 1.6891 (1.5139) acc@1 0.3750 (0.4362) acc@5 0.7969 (0.7868)\n",
      "\u001b[32m[2020-07-14 00:42:20] __main__ INFO: \u001b[0mElapsed 32.29\n",
      "\u001b[32m[2020-07-14 00:42:20] __main__ INFO: \u001b[0mVal 53\n",
      "\u001b[32m[2020-07-14 00:42:21] __main__ INFO: \u001b[0mEpoch 53 loss 0.8216 acc@1 0.7202 acc@5 0.9820\n",
      "\u001b[32m[2020-07-14 00:42:21] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-07-14 00:42:21] __main__ INFO: \u001b[0mTrain 54 18603\n",
      "\u001b[32m[2020-07-14 00:42:31] __main__ INFO: \u001b[0mEpoch 54 Step 100/351 lr 0.100000 loss 1.5139 (1.4839) acc@1 0.4219 (0.4491) acc@5 0.7969 (0.7947)\n",
      "\u001b[32m[2020-07-14 00:42:40] __main__ INFO: \u001b[0mEpoch 54 Step 200/351 lr 0.100000 loss 1.5594 (1.4916) acc@1 0.4141 (0.4454) acc@5 0.7344 (0.7946)\n",
      "\u001b[32m[2020-07-14 00:42:49] __main__ INFO: \u001b[0mEpoch 54 Step 300/351 lr 0.100000 loss 1.3438 (1.5047) acc@1 0.4922 (0.4401) acc@5 0.8438 (0.7921)\n",
      "\u001b[32m[2020-07-14 00:42:54] __main__ INFO: \u001b[0mEpoch 54 Step 351/351 lr 0.100000 loss 1.4467 (1.5024) acc@1 0.4609 (0.4415) acc@5 0.7734 (0.7911)\n",
      "\u001b[32m[2020-07-14 00:42:54] __main__ INFO: \u001b[0mElapsed 32.38\n",
      "\u001b[32m[2020-07-14 00:42:54] __main__ INFO: \u001b[0mVal 54\n",
      "\u001b[32m[2020-07-14 00:42:55] __main__ INFO: \u001b[0mEpoch 54 loss 0.7078 acc@1 0.7592 acc@5 0.9834\n",
      "\u001b[32m[2020-07-14 00:42:55] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-07-14 00:42:55] __main__ INFO: \u001b[0mTrain 55 18954\n",
      "\u001b[32m[2020-07-14 00:43:04] __main__ INFO: \u001b[0mEpoch 55 Step 100/351 lr 0.100000 loss 1.4971 (1.5008) acc@1 0.4531 (0.4382) acc@5 0.8047 (0.7875)\n",
      "\u001b[32m[2020-07-14 00:43:13] __main__ INFO: \u001b[0mEpoch 55 Step 200/351 lr 0.100000 loss 1.4682 (1.4935) acc@1 0.4375 (0.4422) acc@5 0.8359 (0.7923)\n",
      "\u001b[32m[2020-07-14 00:43:22] __main__ INFO: \u001b[0mEpoch 55 Step 300/351 lr 0.100000 loss 1.5476 (1.4982) acc@1 0.4453 (0.4412) acc@5 0.8125 (0.7903)\n",
      "\u001b[32m[2020-07-14 00:43:27] __main__ INFO: \u001b[0mEpoch 55 Step 351/351 lr 0.100000 loss 1.4429 (1.5011) acc@1 0.4844 (0.4407) acc@5 0.7891 (0.7903)\n",
      "\u001b[32m[2020-07-14 00:43:27] __main__ INFO: \u001b[0mElapsed 32.27\n",
      "\u001b[32m[2020-07-14 00:43:27] __main__ INFO: \u001b[0mVal 55\n",
      "\u001b[32m[2020-07-14 00:43:28] __main__ INFO: \u001b[0mEpoch 55 loss 0.6647 acc@1 0.7826 acc@5 0.9856\n",
      "\u001b[32m[2020-07-14 00:43:28] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-07-14 00:43:28] __main__ INFO: \u001b[0mTrain 56 19305\n",
      "\u001b[32m[2020-07-14 00:43:37] __main__ INFO: \u001b[0mEpoch 56 Step 100/351 lr 0.100000 loss 1.4991 (1.4739) acc@1 0.4766 (0.4546) acc@5 0.7344 (0.8001)\n",
      "\u001b[32m[2020-07-14 00:43:46] __main__ INFO: \u001b[0mEpoch 56 Step 200/351 lr 0.100000 loss 1.4338 (1.4884) acc@1 0.4766 (0.4456) acc@5 0.7969 (0.7955)\n",
      "\u001b[32m[2020-07-14 00:43:56] __main__ INFO: \u001b[0mEpoch 56 Step 300/351 lr 0.100000 loss 1.3943 (1.4915) acc@1 0.4766 (0.4457) acc@5 0.8281 (0.7941)\n",
      "\u001b[32m[2020-07-14 00:44:00] __main__ INFO: \u001b[0mEpoch 56 Step 351/351 lr 0.100000 loss 1.4452 (1.4948) acc@1 0.4453 (0.4448) acc@5 0.8203 (0.7922)\n",
      "\u001b[32m[2020-07-14 00:44:00] __main__ INFO: \u001b[0mElapsed 32.35\n",
      "\u001b[32m[2020-07-14 00:44:00] __main__ INFO: \u001b[0mVal 56\n",
      "\u001b[32m[2020-07-14 00:44:01] __main__ INFO: \u001b[0mEpoch 56 loss 0.7999 acc@1 0.7276 acc@5 0.9802\n",
      "\u001b[32m[2020-07-14 00:44:01] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-14 00:44:01] __main__ INFO: \u001b[0mTrain 57 19656\n",
      "\u001b[32m[2020-07-14 00:44:11] __main__ INFO: \u001b[0mEpoch 57 Step 100/351 lr 0.100000 loss 1.4165 (1.4677) acc@1 0.4688 (0.4572) acc@5 0.7734 (0.7920)\n",
      "\u001b[32m[2020-07-14 00:44:20] __main__ INFO: \u001b[0mEpoch 57 Step 200/351 lr 0.100000 loss 1.7080 (1.4803) acc@1 0.3594 (0.4513) acc@5 0.8125 (0.7927)\n",
      "\u001b[32m[2020-07-14 00:44:29] __main__ INFO: \u001b[0mEpoch 57 Step 300/351 lr 0.100000 loss 1.4591 (1.4892) acc@1 0.4453 (0.4474) acc@5 0.8672 (0.7907)\n",
      "\u001b[32m[2020-07-14 00:44:34] __main__ INFO: \u001b[0mEpoch 57 Step 351/351 lr 0.100000 loss 1.5344 (1.4920) acc@1 0.4375 (0.4456) acc@5 0.7734 (0.7907)\n",
      "\u001b[32m[2020-07-14 00:44:34] __main__ INFO: \u001b[0mElapsed 32.40\n",
      "\u001b[32m[2020-07-14 00:44:34] __main__ INFO: \u001b[0mVal 57\n",
      "\u001b[32m[2020-07-14 00:44:35] __main__ INFO: \u001b[0mEpoch 57 loss 0.8048 acc@1 0.7322 acc@5 0.9736\n",
      "\u001b[32m[2020-07-14 00:44:35] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-07-14 00:44:35] __main__ INFO: \u001b[0mTrain 58 20007\n",
      "\u001b[32m[2020-07-14 00:44:44] __main__ INFO: \u001b[0mEpoch 58 Step 100/351 lr 0.100000 loss 1.5503 (1.4704) acc@1 0.4375 (0.4522) acc@5 0.8281 (0.7887)\n",
      "\u001b[32m[2020-07-14 00:44:53] __main__ INFO: \u001b[0mEpoch 58 Step 200/351 lr 0.100000 loss 1.5270 (1.4789) acc@1 0.4141 (0.4511) acc@5 0.7500 (0.7932)\n",
      "\u001b[32m[2020-07-14 00:45:02] __main__ INFO: \u001b[0mEpoch 58 Step 300/351 lr 0.100000 loss 1.4135 (1.4848) acc@1 0.4844 (0.4494) acc@5 0.7578 (0.7922)\n",
      "\u001b[32m[2020-07-14 00:45:07] __main__ INFO: \u001b[0mEpoch 58 Step 351/351 lr 0.100000 loss 1.4232 (1.4890) acc@1 0.4688 (0.4472) acc@5 0.8906 (0.7920)\n",
      "\u001b[32m[2020-07-14 00:45:07] __main__ INFO: \u001b[0mElapsed 32.25\n",
      "\u001b[32m[2020-07-14 00:45:07] __main__ INFO: \u001b[0mVal 58\n",
      "\u001b[32m[2020-07-14 00:45:08] __main__ INFO: \u001b[0mEpoch 58 loss 0.7041 acc@1 0.7620 acc@5 0.9858\n",
      "\u001b[32m[2020-07-14 00:45:08] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-07-14 00:45:08] __main__ INFO: \u001b[0mTrain 59 20358\n",
      "\u001b[32m[2020-07-14 00:45:17] __main__ INFO: \u001b[0mEpoch 59 Step 100/351 lr 0.100000 loss 1.3949 (1.4702) acc@1 0.4922 (0.4570) acc@5 0.8359 (0.7896)\n",
      "\u001b[32m[2020-07-14 00:45:27] __main__ INFO: \u001b[0mEpoch 59 Step 200/351 lr 0.100000 loss 1.5595 (1.4810) acc@1 0.4141 (0.4514) acc@5 0.7578 (0.7933)\n",
      "\u001b[32m[2020-07-14 00:45:36] __main__ INFO: \u001b[0mEpoch 59 Step 300/351 lr 0.100000 loss 1.3828 (1.4810) acc@1 0.5234 (0.4502) acc@5 0.7891 (0.7928)\n",
      "\u001b[32m[2020-07-14 00:45:40] __main__ INFO: \u001b[0mEpoch 59 Step 351/351 lr 0.100000 loss 1.3113 (1.4811) acc@1 0.5078 (0.4498) acc@5 0.8281 (0.7921)\n",
      "\u001b[32m[2020-07-14 00:45:40] __main__ INFO: \u001b[0mElapsed 32.31\n",
      "\u001b[32m[2020-07-14 00:45:40] __main__ INFO: \u001b[0mVal 59\n",
      "\u001b[32m[2020-07-14 00:45:42] __main__ INFO: \u001b[0mEpoch 59 loss 0.8081 acc@1 0.7304 acc@5 0.9730\n",
      "\u001b[32m[2020-07-14 00:45:42] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-07-14 00:45:42] __main__ INFO: \u001b[0mTrain 60 20709\n",
      "\u001b[32m[2020-07-14 00:45:51] __main__ INFO: \u001b[0mEpoch 60 Step 100/351 lr 0.100000 loss 1.6335 (1.4555) acc@1 0.3750 (0.4584) acc@5 0.7266 (0.7945)\n",
      "\u001b[32m[2020-07-14 00:46:00] __main__ INFO: \u001b[0mEpoch 60 Step 200/351 lr 0.100000 loss 1.4854 (1.4667) acc@1 0.4609 (0.4521) acc@5 0.7656 (0.7941)\n",
      "\u001b[32m[2020-07-14 00:46:09] __main__ INFO: \u001b[0mEpoch 60 Step 300/351 lr 0.100000 loss 1.5534 (1.4767) acc@1 0.4531 (0.4500) acc@5 0.7734 (0.7939)\n",
      "\u001b[32m[2020-07-14 00:46:14] __main__ INFO: \u001b[0mEpoch 60 Step 351/351 lr 0.100000 loss 1.6554 (1.4803) acc@1 0.3984 (0.4479) acc@5 0.7656 (0.7939)\n",
      "\u001b[32m[2020-07-14 00:46:14] __main__ INFO: \u001b[0mElapsed 32.29\n",
      "\u001b[32m[2020-07-14 00:46:14] __main__ INFO: \u001b[0mVal 60\n",
      "\u001b[32m[2020-07-14 00:46:15] __main__ INFO: \u001b[0mEpoch 60 loss 0.7496 acc@1 0.7492 acc@5 0.9802\n",
      "\u001b[32m[2020-07-14 00:46:15] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-07-14 00:46:15] __main__ INFO: \u001b[0mTrain 61 21060\n",
      "\u001b[32m[2020-07-14 00:46:24] __main__ INFO: \u001b[0mEpoch 61 Step 100/351 lr 0.100000 loss 1.4473 (1.4756) acc@1 0.4062 (0.4510) acc@5 0.7734 (0.7966)\n",
      "\u001b[32m[2020-07-14 00:46:33] __main__ INFO: \u001b[0mEpoch 61 Step 200/351 lr 0.100000 loss 1.4661 (1.4801) acc@1 0.4453 (0.4495) acc@5 0.7734 (0.7948)\n",
      "\u001b[32m[2020-07-14 00:46:43] __main__ INFO: \u001b[0mEpoch 61 Step 300/351 lr 0.100000 loss 1.3813 (1.4792) acc@1 0.4766 (0.4489) acc@5 0.7891 (0.7945)\n",
      "\u001b[32m[2020-07-14 00:46:47] __main__ INFO: \u001b[0mEpoch 61 Step 351/351 lr 0.100000 loss 1.3320 (1.4808) acc@1 0.5469 (0.4485) acc@5 0.8750 (0.7939)\n",
      "\u001b[32m[2020-07-14 00:46:47] __main__ INFO: \u001b[0mElapsed 32.34\n",
      "\u001b[32m[2020-07-14 00:46:47] __main__ INFO: \u001b[0mVal 61\n",
      "\u001b[32m[2020-07-14 00:46:48] __main__ INFO: \u001b[0mEpoch 61 loss 0.6757 acc@1 0.7674 acc@5 0.9812\n",
      "\u001b[32m[2020-07-14 00:46:48] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-07-14 00:46:48] __main__ INFO: \u001b[0mTrain 62 21411\n",
      "\u001b[32m[2020-07-14 00:46:58] __main__ INFO: \u001b[0mEpoch 62 Step 100/351 lr 0.100000 loss 1.3914 (1.4352) acc@1 0.4688 (0.4668) acc@5 0.7891 (0.7993)\n",
      "\u001b[32m[2020-07-14 00:47:07] __main__ INFO: \u001b[0mEpoch 62 Step 200/351 lr 0.100000 loss 1.5785 (1.4544) acc@1 0.4062 (0.4605) acc@5 0.7656 (0.7959)\n",
      "\u001b[32m[2020-07-14 00:47:16] __main__ INFO: \u001b[0mEpoch 62 Step 300/351 lr 0.100000 loss 1.6099 (1.4660) acc@1 0.4062 (0.4561) acc@5 0.7344 (0.7933)\n",
      "\u001b[32m[2020-07-14 00:47:21] __main__ INFO: \u001b[0mEpoch 62 Step 351/351 lr 0.100000 loss 1.6720 (1.4703) acc@1 0.4062 (0.4543) acc@5 0.7578 (0.7921)\n",
      "\u001b[32m[2020-07-14 00:47:21] __main__ INFO: \u001b[0mElapsed 32.38\n",
      "\u001b[32m[2020-07-14 00:47:21] __main__ INFO: \u001b[0mVal 62\n",
      "\u001b[32m[2020-07-14 00:47:22] __main__ INFO: \u001b[0mEpoch 62 loss 0.8022 acc@1 0.7398 acc@5 0.9820\n",
      "\u001b[32m[2020-07-14 00:47:22] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-07-14 00:47:22] __main__ INFO: \u001b[0mTrain 63 21762\n",
      "\u001b[32m[2020-07-14 00:47:31] __main__ INFO: \u001b[0mEpoch 63 Step 100/351 lr 0.100000 loss 1.7084 (1.4414) acc@1 0.3359 (0.4637) acc@5 0.7188 (0.7984)\n",
      "\u001b[32m[2020-07-14 00:47:40] __main__ INFO: \u001b[0mEpoch 63 Step 200/351 lr 0.100000 loss 1.4242 (1.4541) acc@1 0.4609 (0.4577) acc@5 0.7734 (0.7979)\n",
      "\u001b[32m[2020-07-14 00:47:49] __main__ INFO: \u001b[0mEpoch 63 Step 300/351 lr 0.100000 loss 1.3792 (1.4625) acc@1 0.5234 (0.4544) acc@5 0.8281 (0.7964)\n",
      "\u001b[32m[2020-07-14 00:47:54] __main__ INFO: \u001b[0mEpoch 63 Step 351/351 lr 0.100000 loss 1.4186 (1.4655) acc@1 0.4375 (0.4529) acc@5 0.7891 (0.7963)\n",
      "\u001b[32m[2020-07-14 00:47:54] __main__ INFO: \u001b[0mElapsed 32.33\n",
      "\u001b[32m[2020-07-14 00:47:54] __main__ INFO: \u001b[0mVal 63\n",
      "\u001b[32m[2020-07-14 00:47:55] __main__ INFO: \u001b[0mEpoch 63 loss 0.6982 acc@1 0.7676 acc@5 0.9820\n",
      "\u001b[32m[2020-07-14 00:47:55] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-07-14 00:47:55] __main__ INFO: \u001b[0mTrain 64 22113\n",
      "\u001b[32m[2020-07-14 00:48:04] __main__ INFO: \u001b[0mEpoch 64 Step 100/351 lr 0.100000 loss 1.5103 (1.4450) acc@1 0.4453 (0.4584) acc@5 0.7969 (0.7990)\n",
      "\u001b[32m[2020-07-14 00:48:14] __main__ INFO: \u001b[0mEpoch 64 Step 200/351 lr 0.100000 loss 1.5692 (1.4491) acc@1 0.4297 (0.4589) acc@5 0.8281 (0.8007)\n",
      "\u001b[32m[2020-07-14 00:48:23] __main__ INFO: \u001b[0mEpoch 64 Step 300/351 lr 0.100000 loss 1.4948 (1.4633) acc@1 0.3984 (0.4550) acc@5 0.7500 (0.7979)\n",
      "\u001b[32m[2020-07-14 00:48:27] __main__ INFO: \u001b[0mEpoch 64 Step 351/351 lr 0.100000 loss 1.4503 (1.4665) acc@1 0.4688 (0.4544) acc@5 0.8125 (0.7974)\n",
      "\u001b[32m[2020-07-14 00:48:27] __main__ INFO: \u001b[0mElapsed 32.34\n",
      "\u001b[32m[2020-07-14 00:48:27] __main__ INFO: \u001b[0mVal 64\n",
      "\u001b[32m[2020-07-14 00:48:28] __main__ INFO: \u001b[0mEpoch 64 loss 0.7987 acc@1 0.7364 acc@5 0.9826\n",
      "\u001b[32m[2020-07-14 00:48:28] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-07-14 00:48:28] __main__ INFO: \u001b[0mTrain 65 22464\n",
      "\u001b[32m[2020-07-14 00:48:38] __main__ INFO: \u001b[0mEpoch 65 Step 100/351 lr 0.100000 loss 1.5230 (1.4268) acc@1 0.4453 (0.4713) acc@5 0.7734 (0.8012)\n",
      "\u001b[32m[2020-07-14 00:48:47] __main__ INFO: \u001b[0mEpoch 65 Step 200/351 lr 0.100000 loss 1.5314 (1.4425) acc@1 0.4219 (0.4638) acc@5 0.7422 (0.7965)\n",
      "\u001b[32m[2020-07-14 00:48:56] __main__ INFO: \u001b[0mEpoch 65 Step 300/351 lr 0.100000 loss 1.3374 (1.4527) acc@1 0.4844 (0.4601) acc@5 0.7812 (0.7938)\n",
      "\u001b[32m[2020-07-14 00:49:01] __main__ INFO: \u001b[0mEpoch 65 Step 351/351 lr 0.100000 loss 1.5201 (1.4560) acc@1 0.4453 (0.4588) acc@5 0.8047 (0.7939)\n",
      "\u001b[32m[2020-07-14 00:49:01] __main__ INFO: \u001b[0mElapsed 32.43\n",
      "\u001b[32m[2020-07-14 00:49:01] __main__ INFO: \u001b[0mVal 65\n",
      "\u001b[32m[2020-07-14 00:49:02] __main__ INFO: \u001b[0mEpoch 65 loss 0.6810 acc@1 0.7776 acc@5 0.9826\n",
      "\u001b[32m[2020-07-14 00:49:02] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-07-14 00:49:02] __main__ INFO: \u001b[0mTrain 66 22815\n",
      "\u001b[32m[2020-07-14 00:49:11] __main__ INFO: \u001b[0mEpoch 66 Step 100/351 lr 0.100000 loss 1.5364 (1.4343) acc@1 0.3984 (0.4619) acc@5 0.8047 (0.8027)\n",
      "\u001b[32m[2020-07-14 00:49:20] __main__ INFO: \u001b[0mEpoch 66 Step 200/351 lr 0.100000 loss 1.4348 (1.4494) acc@1 0.4609 (0.4575) acc@5 0.7266 (0.7957)\n",
      "\u001b[32m[2020-07-14 00:49:30] __main__ INFO: \u001b[0mEpoch 66 Step 300/351 lr 0.100000 loss 1.4635 (1.4565) acc@1 0.4844 (0.4560) acc@5 0.8281 (0.7948)\n",
      "\u001b[32m[2020-07-14 00:49:34] __main__ INFO: \u001b[0mEpoch 66 Step 351/351 lr 0.100000 loss 1.5605 (1.4578) acc@1 0.4609 (0.4563) acc@5 0.7891 (0.7944)\n",
      "\u001b[32m[2020-07-14 00:49:34] __main__ INFO: \u001b[0mElapsed 32.34\n",
      "\u001b[32m[2020-07-14 00:49:34] __main__ INFO: \u001b[0mVal 66\n",
      "\u001b[32m[2020-07-14 00:49:35] __main__ INFO: \u001b[0mEpoch 66 loss 0.8848 acc@1 0.7320 acc@5 0.9732\n",
      "\u001b[32m[2020-07-14 00:49:35] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-07-14 00:49:35] __main__ INFO: \u001b[0mTrain 67 23166\n",
      "\u001b[32m[2020-07-14 00:49:45] __main__ INFO: \u001b[0mEpoch 67 Step 100/351 lr 0.100000 loss 1.4220 (1.4569) acc@1 0.4766 (0.4559) acc@5 0.7734 (0.7941)\n",
      "\u001b[32m[2020-07-14 00:49:54] __main__ INFO: \u001b[0mEpoch 67 Step 200/351 lr 0.100000 loss 1.6688 (1.4489) acc@1 0.4453 (0.4586) acc@5 0.7812 (0.7965)\n",
      "\u001b[32m[2020-07-14 00:50:03] __main__ INFO: \u001b[0mEpoch 67 Step 300/351 lr 0.100000 loss 1.4501 (1.4491) acc@1 0.4922 (0.4582) acc@5 0.8281 (0.7972)\n",
      "\u001b[32m[2020-07-14 00:50:08] __main__ INFO: \u001b[0mEpoch 67 Step 351/351 lr 0.100000 loss 1.3702 (1.4544) acc@1 0.5000 (0.4563) acc@5 0.7891 (0.7963)\n",
      "\u001b[32m[2020-07-14 00:50:08] __main__ INFO: \u001b[0mElapsed 32.36\n",
      "\u001b[32m[2020-07-14 00:50:08] __main__ INFO: \u001b[0mVal 67\n",
      "\u001b[32m[2020-07-14 00:50:09] __main__ INFO: \u001b[0mEpoch 67 loss 0.8161 acc@1 0.7204 acc@5 0.9766\n",
      "\u001b[32m[2020-07-14 00:50:09] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-07-14 00:50:09] __main__ INFO: \u001b[0mTrain 68 23517\n",
      "\u001b[32m[2020-07-14 00:50:18] __main__ INFO: \u001b[0mEpoch 68 Step 100/351 lr 0.100000 loss 1.4827 (1.4244) acc@1 0.4297 (0.4623) acc@5 0.7500 (0.7998)\n",
      "\u001b[32m[2020-07-14 00:50:27] __main__ INFO: \u001b[0mEpoch 68 Step 200/351 lr 0.100000 loss 1.5395 (1.4460) acc@1 0.4375 (0.4596) acc@5 0.7734 (0.7966)\n",
      "\u001b[32m[2020-07-14 00:50:36] __main__ INFO: \u001b[0mEpoch 68 Step 300/351 lr 0.100000 loss 1.2360 (1.4487) acc@1 0.5703 (0.4604) acc@5 0.8984 (0.7970)\n",
      "\u001b[32m[2020-07-14 00:50:41] __main__ INFO: \u001b[0mEpoch 68 Step 351/351 lr 0.100000 loss 1.3296 (1.4477) acc@1 0.5234 (0.4606) acc@5 0.7969 (0.7962)\n",
      "\u001b[32m[2020-07-14 00:50:41] __main__ INFO: \u001b[0mElapsed 32.32\n",
      "\u001b[32m[2020-07-14 00:50:41] __main__ INFO: \u001b[0mVal 68\n",
      "\u001b[32m[2020-07-14 00:50:42] __main__ INFO: \u001b[0mEpoch 68 loss 0.7596 acc@1 0.7572 acc@5 0.9800\n",
      "\u001b[32m[2020-07-14 00:50:42] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-07-14 00:50:42] __main__ INFO: \u001b[0mTrain 69 23868\n",
      "\u001b[32m[2020-07-14 00:50:51] __main__ INFO: \u001b[0mEpoch 69 Step 100/351 lr 0.100000 loss 1.5621 (1.4541) acc@1 0.4609 (0.4544) acc@5 0.8203 (0.7970)\n",
      "\u001b[32m[2020-07-14 00:51:01] __main__ INFO: \u001b[0mEpoch 69 Step 200/351 lr 0.100000 loss 1.4196 (1.4528) acc@1 0.4766 (0.4570) acc@5 0.8281 (0.7994)\n",
      "\u001b[32m[2020-07-14 00:51:10] __main__ INFO: \u001b[0mEpoch 69 Step 300/351 lr 0.100000 loss 1.2674 (1.4524) acc@1 0.5625 (0.4585) acc@5 0.8438 (0.7972)\n",
      "\u001b[32m[2020-07-14 00:51:14] __main__ INFO: \u001b[0mEpoch 69 Step 351/351 lr 0.100000 loss 1.3495 (1.4523) acc@1 0.4844 (0.4581) acc@5 0.7969 (0.7964)\n",
      "\u001b[32m[2020-07-14 00:51:14] __main__ INFO: \u001b[0mElapsed 32.28\n",
      "\u001b[32m[2020-07-14 00:51:14] __main__ INFO: \u001b[0mVal 69\n",
      "\u001b[32m[2020-07-14 00:51:15] __main__ INFO: \u001b[0mEpoch 69 loss 0.7223 acc@1 0.7592 acc@5 0.9814\n",
      "\u001b[32m[2020-07-14 00:51:15] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-07-14 00:51:15] __main__ INFO: \u001b[0mTrain 70 24219\n",
      "\u001b[32m[2020-07-14 00:51:25] __main__ INFO: \u001b[0mEpoch 70 Step 100/351 lr 0.100000 loss 1.3911 (1.4232) acc@1 0.5156 (0.4707) acc@5 0.8047 (0.8010)\n",
      "\u001b[32m[2020-07-14 00:51:34] __main__ INFO: \u001b[0mEpoch 70 Step 200/351 lr 0.100000 loss 1.5539 (1.4340) acc@1 0.4219 (0.4673) acc@5 0.7031 (0.7975)\n",
      "\u001b[32m[2020-07-14 00:51:43] __main__ INFO: \u001b[0mEpoch 70 Step 300/351 lr 0.100000 loss 1.4288 (1.4450) acc@1 0.4766 (0.4628) acc@5 0.7969 (0.7966)\n",
      "\u001b[32m[2020-07-14 00:51:48] __main__ INFO: \u001b[0mEpoch 70 Step 351/351 lr 0.100000 loss 1.3969 (1.4475) acc@1 0.4297 (0.4618) acc@5 0.7500 (0.7961)\n",
      "\u001b[32m[2020-07-14 00:51:48] __main__ INFO: \u001b[0mElapsed 32.32\n",
      "\u001b[32m[2020-07-14 00:51:48] __main__ INFO: \u001b[0mVal 70\n",
      "\u001b[32m[2020-07-14 00:51:49] __main__ INFO: \u001b[0mEpoch 70 loss 0.7980 acc@1 0.7498 acc@5 0.9764\n",
      "\u001b[32m[2020-07-14 00:51:49] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-07-14 00:51:49] __main__ INFO: \u001b[0mTrain 71 24570\n",
      "\u001b[32m[2020-07-14 00:51:58] __main__ INFO: \u001b[0mEpoch 71 Step 100/351 lr 0.100000 loss 1.5291 (1.4117) acc@1 0.4297 (0.4720) acc@5 0.7656 (0.8020)\n",
      "\u001b[32m[2020-07-14 00:52:07] __main__ INFO: \u001b[0mEpoch 71 Step 200/351 lr 0.100000 loss 1.5405 (1.4282) acc@1 0.4219 (0.4649) acc@5 0.8047 (0.7982)\n",
      "\u001b[32m[2020-07-14 00:52:17] __main__ INFO: \u001b[0mEpoch 71 Step 300/351 lr 0.100000 loss 1.4405 (1.4375) acc@1 0.4531 (0.4617) acc@5 0.7891 (0.7971)\n",
      "\u001b[32m[2020-07-14 00:52:21] __main__ INFO: \u001b[0mEpoch 71 Step 351/351 lr 0.100000 loss 1.2825 (1.4374) acc@1 0.5234 (0.4613) acc@5 0.9141 (0.7977)\n",
      "\u001b[32m[2020-07-14 00:52:21] __main__ INFO: \u001b[0mElapsed 32.37\n",
      "\u001b[32m[2020-07-14 00:52:21] __main__ INFO: \u001b[0mVal 71\n",
      "\u001b[32m[2020-07-14 00:52:22] __main__ INFO: \u001b[0mEpoch 71 loss 0.6345 acc@1 0.7882 acc@5 0.9844\n",
      "\u001b[32m[2020-07-14 00:52:22] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-07-14 00:52:22] __main__ INFO: \u001b[0mTrain 72 24921\n",
      "\u001b[32m[2020-07-14 00:52:32] __main__ INFO: \u001b[0mEpoch 72 Step 100/351 lr 0.100000 loss 1.3797 (1.4359) acc@1 0.4453 (0.4660) acc@5 0.8516 (0.8013)\n",
      "\u001b[32m[2020-07-14 00:52:41] __main__ INFO: \u001b[0mEpoch 72 Step 200/351 lr 0.100000 loss 1.7210 (1.4365) acc@1 0.3438 (0.4640) acc@5 0.6641 (0.7959)\n",
      "\u001b[32m[2020-07-14 00:52:50] __main__ INFO: \u001b[0mEpoch 72 Step 300/351 lr 0.100000 loss 1.4082 (1.4384) acc@1 0.4609 (0.4657) acc@5 0.7500 (0.7959)\n",
      "\u001b[32m[2020-07-14 00:52:55] __main__ INFO: \u001b[0mEpoch 72 Step 351/351 lr 0.100000 loss 1.3429 (1.4399) acc@1 0.5469 (0.4648) acc@5 0.8047 (0.7957)\n",
      "\u001b[32m[2020-07-14 00:52:55] __main__ INFO: \u001b[0mElapsed 32.31\n",
      "\u001b[32m[2020-07-14 00:52:55] __main__ INFO: \u001b[0mVal 72\n",
      "\u001b[32m[2020-07-14 00:52:56] __main__ INFO: \u001b[0mEpoch 72 loss 0.7181 acc@1 0.7638 acc@5 0.9862\n",
      "\u001b[32m[2020-07-14 00:52:56] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-07-14 00:52:56] __main__ INFO: \u001b[0mTrain 73 25272\n",
      "\u001b[32m[2020-07-14 00:53:05] __main__ INFO: \u001b[0mEpoch 73 Step 100/351 lr 0.100000 loss 1.3558 (1.4281) acc@1 0.5000 (0.4684) acc@5 0.8281 (0.7991)\n",
      "\u001b[32m[2020-07-14 00:53:14] __main__ INFO: \u001b[0mEpoch 73 Step 200/351 lr 0.100000 loss 1.4060 (1.4272) acc@1 0.5078 (0.4692) acc@5 0.8281 (0.8007)\n",
      "\u001b[32m[2020-07-14 00:53:23] __main__ INFO: \u001b[0mEpoch 73 Step 300/351 lr 0.100000 loss 1.4101 (1.4305) acc@1 0.4453 (0.4672) acc@5 0.8203 (0.7983)\n",
      "\u001b[32m[2020-07-14 00:53:28] __main__ INFO: \u001b[0mEpoch 73 Step 351/351 lr 0.100000 loss 1.3395 (1.4376) acc@1 0.5234 (0.4643) acc@5 0.8516 (0.7974)\n",
      "\u001b[32m[2020-07-14 00:53:28] __main__ INFO: \u001b[0mElapsed 32.32\n",
      "\u001b[32m[2020-07-14 00:53:28] __main__ INFO: \u001b[0mVal 73\n",
      "\u001b[32m[2020-07-14 00:53:29] __main__ INFO: \u001b[0mEpoch 73 loss 0.6743 acc@1 0.7742 acc@5 0.9866\n",
      "\u001b[32m[2020-07-14 00:53:29] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-07-14 00:53:29] __main__ INFO: \u001b[0mTrain 74 25623\n",
      "\u001b[32m[2020-07-14 00:53:38] __main__ INFO: \u001b[0mEpoch 74 Step 100/351 lr 0.100000 loss 1.5660 (1.4172) acc@1 0.3750 (0.4696) acc@5 0.7969 (0.8012)\n",
      "\u001b[32m[2020-07-14 00:53:48] __main__ INFO: \u001b[0mEpoch 74 Step 200/351 lr 0.100000 loss 1.3768 (1.4229) acc@1 0.5000 (0.4684) acc@5 0.8203 (0.8025)\n",
      "\u001b[32m[2020-07-14 00:53:57] __main__ INFO: \u001b[0mEpoch 74 Step 300/351 lr 0.100000 loss 1.5058 (1.4268) acc@1 0.4141 (0.4683) acc@5 0.7500 (0.8006)\n",
      "\u001b[32m[2020-07-14 00:54:01] __main__ INFO: \u001b[0mEpoch 74 Step 351/351 lr 0.100000 loss 1.3819 (1.4315) acc@1 0.5312 (0.4661) acc@5 0.8438 (0.8004)\n",
      "\u001b[32m[2020-07-14 00:54:01] __main__ INFO: \u001b[0mElapsed 32.32\n",
      "\u001b[32m[2020-07-14 00:54:01] __main__ INFO: \u001b[0mVal 74\n",
      "\u001b[32m[2020-07-14 00:54:02] __main__ INFO: \u001b[0mEpoch 74 loss 0.7241 acc@1 0.7670 acc@5 0.9826\n",
      "\u001b[32m[2020-07-14 00:54:02] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-07-14 00:54:02] __main__ INFO: \u001b[0mTrain 75 25974\n",
      "\u001b[32m[2020-07-14 00:54:12] __main__ INFO: \u001b[0mEpoch 75 Step 100/351 lr 0.100000 loss 1.4847 (1.4126) acc@1 0.4531 (0.4691) acc@5 0.7891 (0.7946)\n",
      "\u001b[32m[2020-07-14 00:54:21] __main__ INFO: \u001b[0mEpoch 75 Step 200/351 lr 0.100000 loss 1.4422 (1.4195) acc@1 0.4219 (0.4673) acc@5 0.7812 (0.7983)\n",
      "\u001b[32m[2020-07-14 00:54:30] __main__ INFO: \u001b[0mEpoch 75 Step 300/351 lr 0.100000 loss 1.4968 (1.4286) acc@1 0.4766 (0.4654) acc@5 0.8125 (0.7975)\n",
      "\u001b[32m[2020-07-14 00:54:35] __main__ INFO: \u001b[0mEpoch 75 Step 351/351 lr 0.100000 loss 1.2640 (1.4340) acc@1 0.5234 (0.4633) acc@5 0.8438 (0.7961)\n",
      "\u001b[32m[2020-07-14 00:54:35] __main__ INFO: \u001b[0mElapsed 32.33\n",
      "\u001b[32m[2020-07-14 00:54:35] __main__ INFO: \u001b[0mVal 75\n",
      "\u001b[32m[2020-07-14 00:54:36] __main__ INFO: \u001b[0mEpoch 75 loss 0.7330 acc@1 0.7580 acc@5 0.9818\n",
      "\u001b[32m[2020-07-14 00:54:36] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-07-14 00:54:36] __main__ INFO: \u001b[0mTrain 76 26325\n",
      "\u001b[32m[2020-07-14 00:54:45] __main__ INFO: \u001b[0mEpoch 76 Step 100/351 lr 0.100000 loss 1.3944 (1.4261) acc@1 0.4922 (0.4698) acc@5 0.8594 (0.7957)\n",
      "\u001b[32m[2020-07-14 00:54:54] __main__ INFO: \u001b[0mEpoch 76 Step 200/351 lr 0.100000 loss 1.4630 (1.4189) acc@1 0.4375 (0.4709) acc@5 0.7500 (0.7982)\n",
      "\u001b[32m[2020-07-14 00:55:03] __main__ INFO: \u001b[0mEpoch 76 Step 300/351 lr 0.100000 loss 1.4819 (1.4242) acc@1 0.4219 (0.4687) acc@5 0.7812 (0.7985)\n",
      "\u001b[32m[2020-07-14 00:55:08] __main__ INFO: \u001b[0mEpoch 76 Step 351/351 lr 0.100000 loss 1.4762 (1.4251) acc@1 0.4531 (0.4690) acc@5 0.7812 (0.7985)\n",
      "\u001b[32m[2020-07-14 00:55:08] __main__ INFO: \u001b[0mElapsed 32.34\n",
      "\u001b[32m[2020-07-14 00:55:08] __main__ INFO: \u001b[0mVal 76\n",
      "\u001b[32m[2020-07-14 00:55:09] __main__ INFO: \u001b[0mEpoch 76 loss 0.7250 acc@1 0.7632 acc@5 0.9820\n",
      "\u001b[32m[2020-07-14 00:55:09] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-07-14 00:55:09] __main__ INFO: \u001b[0mTrain 77 26676\n",
      "\u001b[32m[2020-07-14 00:55:18] __main__ INFO: \u001b[0mEpoch 77 Step 100/351 lr 0.100000 loss 1.3174 (1.4059) acc@1 0.5078 (0.4734) acc@5 0.8047 (0.8010)\n",
      "\u001b[32m[2020-07-14 00:55:28] __main__ INFO: \u001b[0mEpoch 77 Step 200/351 lr 0.100000 loss 1.5275 (1.4214) acc@1 0.4453 (0.4711) acc@5 0.7734 (0.7970)\n",
      "\u001b[32m[2020-07-14 00:55:37] __main__ INFO: \u001b[0mEpoch 77 Step 300/351 lr 0.100000 loss 1.5950 (1.4215) acc@1 0.3984 (0.4716) acc@5 0.7969 (0.7981)\n",
      "\u001b[32m[2020-07-14 00:55:41] __main__ INFO: \u001b[0mEpoch 77 Step 351/351 lr 0.100000 loss 1.4556 (1.4211) acc@1 0.4453 (0.4715) acc@5 0.8359 (0.7983)\n",
      "\u001b[32m[2020-07-14 00:55:41] __main__ INFO: \u001b[0mElapsed 32.26\n",
      "\u001b[32m[2020-07-14 00:55:41] __main__ INFO: \u001b[0mVal 77\n",
      "\u001b[32m[2020-07-14 00:55:42] __main__ INFO: \u001b[0mEpoch 77 loss 0.7078 acc@1 0.7826 acc@5 0.9802\n",
      "\u001b[32m[2020-07-14 00:55:42] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-07-14 00:55:42] __main__ INFO: \u001b[0mTrain 78 27027\n",
      "\u001b[32m[2020-07-14 00:55:52] __main__ INFO: \u001b[0mEpoch 78 Step 100/351 lr 0.100000 loss 1.6538 (1.4134) acc@1 0.3516 (0.4739) acc@5 0.6953 (0.7959)\n",
      "\u001b[32m[2020-07-14 00:56:01] __main__ INFO: \u001b[0mEpoch 78 Step 200/351 lr 0.100000 loss 1.6776 (1.4261) acc@1 0.3750 (0.4684) acc@5 0.7656 (0.7963)\n",
      "\u001b[32m[2020-07-14 00:56:10] __main__ INFO: \u001b[0mEpoch 78 Step 300/351 lr 0.100000 loss 1.5848 (1.4238) acc@1 0.3750 (0.4702) acc@5 0.7422 (0.7968)\n",
      "\u001b[32m[2020-07-14 00:56:15] __main__ INFO: \u001b[0mEpoch 78 Step 351/351 lr 0.100000 loss 1.2941 (1.4282) acc@1 0.5234 (0.4685) acc@5 0.8594 (0.7968)\n",
      "\u001b[32m[2020-07-14 00:56:15] __main__ INFO: \u001b[0mElapsed 32.27\n",
      "\u001b[32m[2020-07-14 00:56:15] __main__ INFO: \u001b[0mVal 78\n",
      "\u001b[32m[2020-07-14 00:56:16] __main__ INFO: \u001b[0mEpoch 78 loss 0.9755 acc@1 0.7198 acc@5 0.9808\n",
      "\u001b[32m[2020-07-14 00:56:16] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-07-14 00:56:16] __main__ INFO: \u001b[0mTrain 79 27378\n",
      "\u001b[32m[2020-07-14 00:56:25] __main__ INFO: \u001b[0mEpoch 79 Step 100/351 lr 0.100000 loss 1.3449 (1.3927) acc@1 0.5078 (0.4827) acc@5 0.8516 (0.8051)\n",
      "\u001b[32m[2020-07-14 00:56:34] __main__ INFO: \u001b[0mEpoch 79 Step 200/351 lr 0.100000 loss 1.2640 (1.4157) acc@1 0.5000 (0.4732) acc@5 0.8047 (0.8008)\n"
     ]
    }
   ],
   "source": [
    "# Train the model per the settings specified in the original paper\n",
    "os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "!python train.py --config configs/cifar/resnet.yaml \\\n",
    "    model.resnet.depth 32 \\\n",
    "    train.batch_size 128 \\\n",
    "    dataset.name CIFAR10_RA_2_20 \\\n",
    "    train.base_lr 0.1 \\\n",
    "    train.output_dir /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_20_c10val/exp00 \\\n",
    "    scheduler.epochs 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refine the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 436, in <module>\n",
      "    main()\n",
      "  File \"train.py\", line 336, in main\n",
      "    f'Output directory `{output_dir.as_posix()}` already exists')\n",
      "RuntimeError: Output directory `/home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_20/exp00_resume400_50` already exists\n"
     ]
    }
   ],
   "source": [
    "# Resume training with the un-augmented data\n",
    "os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "#!python train.py --config configs/cifar/resnet.yaml \\\n",
    "!python train.py --config /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_20_c10val/exp00/config.yaml \\\n",
    "    train.checkpoint /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_20_c10val/exp00/checkpoint_00400.pth \\\n",
    "    dataset.name CIFAR10 \\\n",
    "    train.base_lr .001 \\\n",
    "    train.output_dir /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_20_c10val/exp00_resume400_50 \\\n",
    "    scheduler.epochs 50\n",
    "\n",
    "#### Set LEARNING RATE based on ending LR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-06-21 21:43:10] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_20/exp00/checkpoint_00400.pth\n",
      "Files already downloaded and verified\n",
      "100%|| 79/79 [00:02<00:00, 26.40it/s]\n",
      "\u001b[32m[2020-06-21 21:43:14] __main__ INFO: \u001b[0mElapsed 3.00\n",
      "\u001b[32m[2020-06-21 21:43:14] __main__ INFO: \u001b[0mLoss 1.7503 Accuracy 0.7241\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10 test dataset - without training on unaugmented data\n",
    "# Right the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/resnet.yaml \\\n",
    "   model.resnet.depth 32 \\\n",
    "   test.batch_size 128 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_20_c10val/exp00/checkpoint_00400.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_20_c10val/exp00/test_results_0400_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10 test dataset - without training on unaugmented data\n",
    "# Right the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/resnet.yaml \\\n",
    "   model.resnet.depth 32 \\\n",
    "   test.batch_size 128 \\\n",
    "   dataset.name CIFAR101 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_20/exp00/checkpoint_00400.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_20/exp00/test_results_0400_cifar101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-06-21 21:44:42] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_20/exp00_resume400_50/checkpoint_00050.pth\n",
      "Files already downloaded and verified\n",
      "100%|| 79/79 [00:03<00:00, 25.85it/s]\n",
      "\u001b[32m[2020-06-21 21:44:46] __main__ INFO: \u001b[0mElapsed 3.06\n",
      "\u001b[32m[2020-06-21 21:44:46] __main__ INFO: \u001b[0mLoss 0.4279 Accuracy 0.8670\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10 test dataset \n",
    "# Right the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/resnet.yaml \\\n",
    "   model.resnet.depth 32 \\\n",
    "   test.batch_size 128 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_20_c10val/exp00_resume400_50/checkpoint_00050.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_20_c10val/exp00_resume400_50/test_results_0050_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-06-21 21:47:35] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_20/exp00_resume400_50/checkpoint_00050.pth\n",
      "CIFAR 10.1\n",
      "100%|| 16/16 [00:00<00:00, 17.36it/s]\n",
      "\u001b[32m[2020-06-21 21:47:37] __main__ INFO: \u001b[0mElapsed 0.92\n",
      "\u001b[32m[2020-06-21 21:47:37] __main__ INFO: \u001b[0mLoss 0.7639 Accuracy 0.7685\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10.1 test dataset \n",
    "# Right the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/resnet.yaml \\\n",
    "   model.resnet.depth 32 \\\n",
    "   test.batch_size 128 \\\n",
    "   dataset.name CIFAR101 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_20_c10val/exp00_resume400_50/checkpoint_00050.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_20_c10val/exp00_resume400_50/test_results_0050_cifar101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Record the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Testset</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Original_Accuracy</th>\n",
       "      <th>Original_CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resnet_basic_32_ra_2_20</td>\n",
       "      <td>400</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>1.7503</td>\n",
       "      <td>0.7241</td>\n",
       "      <td>92.5</td>\n",
       "      <td>(92.0, 93.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>resnet_basic_32_ra_2_20</td>\n",
       "      <td>300</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>1.6118</td>\n",
       "      <td>0.7259</td>\n",
       "      <td>92.5</td>\n",
       "      <td>(92.0, 93.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>resnet_basic_32_ra_2_20</td>\n",
       "      <td>400</td>\n",
       "      <td>cifar10.1</td>\n",
       "      <td>3.1568</td>\n",
       "      <td>0.5375</td>\n",
       "      <td>84.9</td>\n",
       "      <td>(83.2, 86.4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>resnet_basic_32_ra_2_20</td>\n",
       "      <td>300</td>\n",
       "      <td>cifar10.1</td>\n",
       "      <td>3.047</td>\n",
       "      <td>0.5265</td>\n",
       "      <td>84.9</td>\n",
       "      <td>(83.2, 86.4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>resnet_basic_32_ra_2_20_refined400</td>\n",
       "      <td>50</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>0.4279</td>\n",
       "      <td>0.867</td>\n",
       "      <td>92.5</td>\n",
       "      <td>(92.0, 93.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>resnet_basic_32_ra_2_20_refined300</td>\n",
       "      <td>150</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>0.4342</td>\n",
       "      <td>0.874</td>\n",
       "      <td>92.5</td>\n",
       "      <td>(92.0, 93.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>resnet_basic_32_ra_2_20_refined400</td>\n",
       "      <td>50</td>\n",
       "      <td>cifar10.1</td>\n",
       "      <td>0.8061</td>\n",
       "      <td>0.7645</td>\n",
       "      <td>84.9</td>\n",
       "      <td>(83.2, 86.4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>resnet_basic_32_ra_2_20_refined300</td>\n",
       "      <td>150</td>\n",
       "      <td>cifar10.1</td>\n",
       "      <td>0.7919</td>\n",
       "      <td>0.7635</td>\n",
       "      <td>84.9</td>\n",
       "      <td>(83.2, 86.4)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Model Epoch    Testset    Loss Accuracy  \\\n",
       "0             resnet_basic_32_ra_2_20   400    cifar10  1.7503   0.7241   \n",
       "1             resnet_basic_32_ra_2_20   300    cifar10  1.6118   0.7259   \n",
       "2             resnet_basic_32_ra_2_20   400  cifar10.1  3.1568   0.5375   \n",
       "3             resnet_basic_32_ra_2_20   300  cifar10.1   3.047   0.5265   \n",
       "4  resnet_basic_32_ra_2_20_refined400    50    cifar10  0.4279    0.867   \n",
       "5  resnet_basic_32_ra_2_20_refined300   150    cifar10  0.4342    0.874   \n",
       "6  resnet_basic_32_ra_2_20_refined400    50  cifar10.1  0.8061   0.7645   \n",
       "7  resnet_basic_32_ra_2_20_refined300   150  cifar10.1  0.7919   0.7635   \n",
       "\n",
       "   Original_Accuracy   Original_CI  \n",
       "0               92.5  (92.0, 93.0)  \n",
       "1               92.5  (92.0, 93.0)  \n",
       "2               84.9  (83.2, 86.4)  \n",
       "3               84.9  (83.2, 86.4)  \n",
       "4               92.5  (92.0, 93.0)  \n",
       "5               92.5  (92.0, 93.0)  \n",
       "6               84.9  (83.2, 86.4)  \n",
       "7               84.9  (83.2, 86.4)  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "model = 'resnet_basic_32_ra_2_20_c10val'\n",
    "model_refined = model + '_refined400'\n",
    "\n",
    "a = pd.Series([model, 400, 'cifar10',])\n",
    "c = pd.Series([model, 400, 'cifar10.1', ])\n",
    "\n",
    "e = pd.Series([model_refined, 50, 'cifar10.1',])\n",
    "f = pd.Series([model_refined, 50, 'cifar10', ])\n",
    "               \n",
    "df_results = pd.concat([a,c,e,f], axis=1).T\n",
    "df_results.columns = ['Model', 'Epoch', 'Testset', 'Loss', 'Accuracy']\n",
    "\n",
    "df_results['Original_Accuracy'] = df_results.apply((lambda row: 92.5 if row[2] == 'cifar10' else 84.9), axis=1)\n",
    "df_results['Original_CI'] = df_results.apply((lambda row: (92.0, 93.0) if row[2] == 'cifar10' else (83.2, 86.4)), axis=1)\n",
    "\n",
    "df_results.to_csv('/home/ec2-user/SageMaker/experiments/' + model + '/results.csv')\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the model checkpoints, configs, and results to S3 \n",
    "bucket='sagemaker-may29'\n",
    "prefix = 'sagemaker/results/original-models/resnet_basic_32_ra_2_20_c10val'\n",
    "path = '/home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_20_c10val'\n",
    "\n",
    "s3_resource = boto3.resource(\"s3\", region_name=\"us-east-2\")\n",
    "\n",
    "def uploadDirectory(local_path,bucket_name,s3_prefix):\n",
    "\n",
    "    my_bucket = s3_resource.Bucket(bucket_name)\n",
    "    \n",
    "    for path, subdirs, files in os.walk(local_path):\n",
    "        path = path.replace(\"\\\\\",\"/\")\n",
    "        directory_name = path.replace(local_path,\"\")\n",
    "        for file in files:\n",
    "            #print(\"Local File:\", os.path.join(path, file))\n",
    "            #print(\"      Dest:\", s3_prefix+directory_name+'/'+file)\n",
    "            my_bucket.upload_file(os.path.join(path, file), s3_prefix+directory_name+'/'+file)\n",
    "    \n",
    "uploadDirectory(path,bucket,prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
