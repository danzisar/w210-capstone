{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wide Residual Net\n",
    "\n",
    " - Training Dataset:  RandAugment, N=2, M=20\n",
    "   Validation with Unaugmented Data\n",
    " - Sagemaker Notebook must be of type, conda_pytorch_p36\n",
    " \n",
    "#### Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy \n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 1)) (1.18.1)\n",
      "Requirement already satisfied: torch>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 2)) (1.4.0)\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 3)) (0.5.0)\n",
      "Requirement already satisfied: fvcore in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (0.1.1.post20200711)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 5)) (4.44.1)\n",
      "Requirement already satisfied: yacs in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 6)) (0.1.7)\n",
      "Requirement already satisfied: apex from git+https://github.com/NVIDIA/apex.git#egg=apex in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 7)) (0.1)\n",
      "Requirement already satisfied: termcolor in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 8)) (1.1.0)\n",
      "Requirement already satisfied: thop<0.0.31.post2004070130 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 9)) (0.0.31.post2001170342)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 3)) (1.14.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 3)) (7.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from fvcore->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (5.3.1)\n",
      "Requirement already satisfied: tabulate in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from fvcore->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (0.8.7)\n",
      "Requirement already satisfied: portalocker in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from fvcore->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (1.7.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: tensorboard in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.18.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.14.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.18.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (46.1.3.post20200330)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (2.23.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.7.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (3.2.2)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (3.12.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.4.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.30.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.34.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.9.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.1.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard) (3.4.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.4.5.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (1.25.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (1.5.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard) (2.2.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r '/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt'\n",
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-15 02:19:27] __main__ INFO: \u001b[0mdevice: cuda\n",
      "cudnn:\n",
      "  benchmark: True\n",
      "  deterministic: False\n",
      "dataset:\n",
      "  name: CIFAR10_RA_2_20\n",
      "  dataset_dir: ''\n",
      "  image_size: 32\n",
      "  n_channels: 3\n",
      "  n_classes: 10\n",
      "model:\n",
      "  type: cifar\n",
      "  name: wrn\n",
      "  init_mode: kaiming_fan_in\n",
      "  vgg:\n",
      "    n_channels: [64, 128, 256, 512, 512]\n",
      "    n_layers: [2, 2, 3, 3, 3]\n",
      "    use_bn: True\n",
      "  resnet:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "  resnet_preact:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "  wrn:\n",
      "    depth: 28\n",
      "    initial_channels: 16\n",
      "    widening_factor: 10\n",
      "    drop_rate: 0.0\n",
      "  densenet:\n",
      "    depth: 100\n",
      "    n_blocks: [6, 12, 24, 16]\n",
      "    block_type: bottleneck\n",
      "    growth_rate: 12\n",
      "    drop_rate: 0.0\n",
      "    compression_rate: 0.5\n",
      "  pyramidnet:\n",
      "    depth: 272\n",
      "    n_blocks: [3, 24, 36, 3]\n",
      "    initial_channels: 16\n",
      "    block_type: bottleneck\n",
      "    alpha: 200\n",
      "  resnext:\n",
      "    depth: 29\n",
      "    n_blocks: [3, 4, 6, 3]\n",
      "    initial_channels: 64\n",
      "    cardinality: 8\n",
      "    base_channels: 4\n",
      "  shake_shake:\n",
      "    depth: 26\n",
      "    initial_channels: 96\n",
      "    shake_forward: True\n",
      "    shake_backward: True\n",
      "    shake_image: True\n",
      "  se_resnet_preact:\n",
      "    depth: 110\n",
      "    initial_channels: 16\n",
      "    se_reduction: 16\n",
      "    block_type: basic\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "train:\n",
      "  checkpoint: ''\n",
      "  resume: False\n",
      "  precision: O0\n",
      "  batch_size: 128\n",
      "  subdivision: 1\n",
      "  optimizer: sgd\n",
      "  base_lr: 0.1\n",
      "  momentum: 0.9\n",
      "  nesterov: True\n",
      "  weight_decay: 0.0005\n",
      "  no_weight_decay_on_bn: False\n",
      "  gradient_clip: 0\n",
      "  start_epoch: 0\n",
      "  seed: 0\n",
      "  val_first: True\n",
      "  val_period: 1\n",
      "  val_ratio: 0.1\n",
      "  use_test_as_val: False\n",
      "  output_dir: /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_20_c10val/exp00\n",
      "  log_period: 100\n",
      "  checkpoint_period: 100\n",
      "  use_tensorboard: True\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: True\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "  distributed: False\n",
      "  dist:\n",
      "    backend: nccl\n",
      "    init_method: env://\n",
      "    world_size: -1\n",
      "    node_rank: -1\n",
      "    local_rank: 0\n",
      "    use_sync_bn: False\n",
      "tensorboard:\n",
      "  train_images: False\n",
      "  val_images: False\n",
      "  model_params: False\n",
      "optim:\n",
      "  adam:\n",
      "    betas: (0.9, 0.999)\n",
      "  lars:\n",
      "    eps: 1e-09\n",
      "    threshold: 0.01\n",
      "  adabound:\n",
      "    betas: (0.9, 0.999)\n",
      "    final_lr: 0.1\n",
      "    gamma: 0.001\n",
      "scheduler:\n",
      "  epochs: 400\n",
      "  warmup:\n",
      "    type: none\n",
      "    epochs: 0\n",
      "    start_factor: 0.001\n",
      "    exponent: 4\n",
      "  type: multistep\n",
      "  milestones: [60, 120, 160]\n",
      "  lr_decay: 0.2\n",
      "  lr_min_factor: 0.001\n",
      "  T0: 10\n",
      "  T_mul: 1.0\n",
      "validation:\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: False\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "augmentation:\n",
      "  use_random_crop: True\n",
      "  use_random_horizontal_flip: True\n",
      "  use_cutout: False\n",
      "  use_random_erasing: False\n",
      "  use_dual_cutout: False\n",
      "  use_mixup: False\n",
      "  use_ricap: False\n",
      "  use_cutmix: False\n",
      "  use_label_smoothing: False\n",
      "  random_crop:\n",
      "    padding: 4\n",
      "    fill: 0\n",
      "    padding_mode: constant\n",
      "  random_horizontal_flip:\n",
      "    prob: 0.5\n",
      "  cutout:\n",
      "    prob: 1.0\n",
      "    mask_size: 16\n",
      "    cut_inside: False\n",
      "    mask_color: 0\n",
      "    dual_cutout_alpha: 0.1\n",
      "  random_erasing:\n",
      "    prob: 0.5\n",
      "    area_ratio_range: [0.02, 0.4]\n",
      "    min_aspect_ratio: 0.3\n",
      "    max_attempt: 20\n",
      "  mixup:\n",
      "    alpha: 1.0\n",
      "  ricap:\n",
      "    beta: 0.3\n",
      "  cutmix:\n",
      "    alpha: 1.0\n",
      "  label_smoothing:\n",
      "    epsilon: 0.1\n",
      "tta:\n",
      "  use_resize: False\n",
      "  use_center_crop: False\n",
      "  resize: 256\n",
      "test:\n",
      "  checkpoint: ''\n",
      "  output_dir: ''\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    pin_memory: False\n",
      "\u001b[32m[2020-07-15 02:19:27] __main__ INFO: \u001b[0menv_info:\n",
      "  pytorch_version: 1.4.0\n",
      "  cuda_version: 10.1\n",
      "  cudnn_version: 7603\n",
      "  num_gpus: 1\n",
      "  gpu_name: Tesla K80\n",
      "  gpu_capability: 3.7\n",
      "Files already downloaded and verified\n",
      "\u001b[32m[2020-07-15 02:19:34] __main__ INFO: \u001b[0mMACs  : 5.25G\n",
      "\u001b[32m[2020-07-15 02:19:34] __main__ INFO: \u001b[0m#params: 36.48M\n",
      "Selected optimization level O0:  Pure FP32 training.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n",
      "\u001b[32m[2020-07-15 02:19:34] __main__ INFO: \u001b[0mVal 0\n",
      "\u001b[32m[2020-07-15 02:19:54] __main__ INFO: \u001b[0mEpoch 0 loss 188.4703 acc@1 0.0968 acc@5 0.5544\n",
      "\u001b[32m[2020-07-15 02:19:54] __main__ INFO: \u001b[0mElapsed 20.12\n",
      "\u001b[32m[2020-07-15 02:19:54] __main__ INFO: \u001b[0mTrain 1 0\n",
      "\u001b[32m[2020-07-15 02:21:53] __main__ INFO: \u001b[0mEpoch 1 Step 100/351 lr 0.100000 loss 2.2988 (2.5352) acc@1 0.1172 (0.1000) acc@5 0.6172 (0.5078)\n",
      "\u001b[32m[2020-07-15 02:23:47] __main__ INFO: \u001b[0mEpoch 1 Step 200/351 lr 0.100000 loss 2.2870 (2.4219) acc@1 0.1016 (0.1033) acc@5 0.5156 (0.5186)\n",
      "\u001b[32m[2020-07-15 02:25:41] __main__ INFO: \u001b[0mEpoch 1 Step 300/351 lr 0.100000 loss 2.3020 (2.3767) acc@1 0.1094 (0.1098) acc@5 0.5938 (0.5319)\n",
      "\u001b[32m[2020-07-15 02:26:39] __main__ INFO: \u001b[0mEpoch 1 Step 351/351 lr 0.100000 loss 2.2510 (2.3608) acc@1 0.1094 (0.1118) acc@5 0.5547 (0.5379)\n",
      "\u001b[32m[2020-07-15 02:26:39] __main__ INFO: \u001b[0mElapsed 404.55\n",
      "\u001b[32m[2020-07-15 02:26:39] __main__ INFO: \u001b[0mVal 1\n",
      "\u001b[32m[2020-07-15 02:26:52] __main__ INFO: \u001b[0mEpoch 1 loss 2.1092 acc@1 0.1992 acc@5 0.7440\n",
      "\u001b[32m[2020-07-15 02:26:52] __main__ INFO: \u001b[0mElapsed 13.45\n",
      "\u001b[32m[2020-07-15 02:26:52] __main__ INFO: \u001b[0mTrain 2 351\n",
      "\u001b[32m[2020-07-15 02:28:46] __main__ INFO: \u001b[0mEpoch 2 Step 100/351 lr 0.100000 loss 2.2031 (2.2589) acc@1 0.1953 (0.1368) acc@5 0.6719 (0.5930)\n",
      "\u001b[32m[2020-07-15 02:30:40] __main__ INFO: \u001b[0mEpoch 2 Step 200/351 lr 0.100000 loss 2.2239 (2.2473) acc@1 0.1406 (0.1404) acc@5 0.5938 (0.6002)\n",
      "\u001b[32m[2020-07-15 02:32:34] __main__ INFO: \u001b[0mEpoch 2 Step 300/351 lr 0.100000 loss 2.2020 (2.2362) acc@1 0.1719 (0.1457) acc@5 0.6406 (0.6058)\n",
      "\u001b[32m[2020-07-15 02:33:32] __main__ INFO: \u001b[0mEpoch 2 Step 351/351 lr 0.100000 loss 2.2158 (2.2340) acc@1 0.1016 (0.1470) acc@5 0.6406 (0.6072)\n",
      "\u001b[32m[2020-07-15 02:33:32] __main__ INFO: \u001b[0mElapsed 400.25\n",
      "\u001b[32m[2020-07-15 02:33:32] __main__ INFO: \u001b[0mVal 2\n",
      "\u001b[32m[2020-07-15 02:33:46] __main__ INFO: \u001b[0mEpoch 2 loss 1.9403 acc@1 0.2744 acc@5 0.7998\n",
      "\u001b[32m[2020-07-15 02:33:46] __main__ INFO: \u001b[0mElapsed 13.46\n",
      "\u001b[32m[2020-07-15 02:33:46] __main__ INFO: \u001b[0mTrain 3 702\n",
      "\u001b[32m[2020-07-15 02:35:40] __main__ INFO: \u001b[0mEpoch 3 Step 100/351 lr 0.100000 loss 2.2317 (2.2017) acc@1 0.1406 (0.1627) acc@5 0.5625 (0.6337)\n",
      "\u001b[32m[2020-07-15 02:37:34] __main__ INFO: \u001b[0mEpoch 3 Step 200/351 lr 0.100000 loss 2.1919 (2.2023) acc@1 0.1406 (0.1655) acc@5 0.6562 (0.6284)\n",
      "\u001b[32m[2020-07-15 02:39:28] __main__ INFO: \u001b[0mEpoch 3 Step 300/351 lr 0.100000 loss 2.1978 (2.1925) acc@1 0.1328 (0.1691) acc@5 0.6562 (0.6351)\n",
      "\u001b[32m[2020-07-15 02:40:27] __main__ INFO: \u001b[0mEpoch 3 Step 351/351 lr 0.100000 loss 2.2600 (2.1913) acc@1 0.1328 (0.1696) acc@5 0.6016 (0.6359)\n",
      "\u001b[32m[2020-07-15 02:40:27] __main__ INFO: \u001b[0mElapsed 400.74\n",
      "\u001b[32m[2020-07-15 02:40:27] __main__ INFO: \u001b[0mVal 3\n",
      "\u001b[32m[2020-07-15 02:40:40] __main__ INFO: \u001b[0mEpoch 3 loss 1.8207 acc@1 0.3166 acc@5 0.8520\n",
      "\u001b[32m[2020-07-15 02:40:40] __main__ INFO: \u001b[0mElapsed 13.47\n",
      "\u001b[32m[2020-07-15 02:40:40] __main__ INFO: \u001b[0mTrain 4 1053\n",
      "\u001b[32m[2020-07-15 02:42:34] __main__ INFO: \u001b[0mEpoch 4 Step 100/351 lr 0.100000 loss 2.1448 (2.1669) acc@1 0.1797 (0.1800) acc@5 0.7266 (0.6470)\n",
      "\u001b[32m[2020-07-15 02:44:28] __main__ INFO: \u001b[0mEpoch 4 Step 200/351 lr 0.100000 loss 2.1555 (2.1626) acc@1 0.1250 (0.1818) acc@5 0.6797 (0.6500)\n",
      "\u001b[32m[2020-07-15 02:46:23] __main__ INFO: \u001b[0mEpoch 4 Step 300/351 lr 0.100000 loss 2.1694 (2.1569) acc@1 0.2031 (0.1840) acc@5 0.6641 (0.6539)\n",
      "\u001b[32m[2020-07-15 02:47:21] __main__ INFO: \u001b[0mEpoch 4 Step 351/351 lr 0.100000 loss 2.1318 (2.1536) acc@1 0.1875 (0.1868) acc@5 0.6719 (0.6557)\n",
      "\u001b[32m[2020-07-15 02:47:21] __main__ INFO: \u001b[0mElapsed 400.76\n",
      "\u001b[32m[2020-07-15 02:47:21] __main__ INFO: \u001b[0mVal 4\n",
      "\u001b[32m[2020-07-15 02:47:34] __main__ INFO: \u001b[0mEpoch 4 loss 1.7830 acc@1 0.3250 acc@5 0.8468\n",
      "\u001b[32m[2020-07-15 02:47:34] __main__ INFO: \u001b[0mElapsed 13.50\n",
      "\u001b[32m[2020-07-15 02:47:34] __main__ INFO: \u001b[0mTrain 5 1404\n",
      "\u001b[32m[2020-07-15 02:49:29] __main__ INFO: \u001b[0mEpoch 5 Step 100/351 lr 0.100000 loss 2.1645 (2.1372) acc@1 0.1406 (0.1889) acc@5 0.6406 (0.6666)\n",
      "\u001b[32m[2020-07-15 02:51:23] __main__ INFO: \u001b[0mEpoch 5 Step 200/351 lr 0.100000 loss 2.1358 (2.1302) acc@1 0.1641 (0.1911) acc@5 0.6875 (0.6702)\n",
      "\u001b[32m[2020-07-15 02:53:17] __main__ INFO: \u001b[0mEpoch 5 Step 300/351 lr 0.100000 loss 2.0628 (2.1229) acc@1 0.2031 (0.1944) acc@5 0.7344 (0.6715)\n",
      "\u001b[32m[2020-07-15 02:54:15] __main__ INFO: \u001b[0mEpoch 5 Step 351/351 lr 0.100000 loss 1.9907 (2.1194) acc@1 0.2188 (0.1984) acc@5 0.7422 (0.6719)\n",
      "\u001b[32m[2020-07-15 02:54:15] __main__ INFO: \u001b[0mElapsed 400.95\n",
      "\u001b[32m[2020-07-15 02:54:15] __main__ INFO: \u001b[0mVal 5\n",
      "\u001b[32m[2020-07-15 02:54:29] __main__ INFO: \u001b[0mEpoch 5 loss 1.6178 acc@1 0.4158 acc@5 0.8940\n",
      "\u001b[32m[2020-07-15 02:54:29] __main__ INFO: \u001b[0mElapsed 13.52\n",
      "\u001b[32m[2020-07-15 02:54:29] __main__ INFO: \u001b[0mTrain 6 1755\n",
      "\u001b[32m[2020-07-15 02:56:23] __main__ INFO: \u001b[0mEpoch 6 Step 100/351 lr 0.100000 loss 2.0464 (2.1114) acc@1 0.2031 (0.2100) acc@5 0.7031 (0.6690)\n",
      "\u001b[32m[2020-07-15 02:58:17] __main__ INFO: \u001b[0mEpoch 6 Step 200/351 lr 0.100000 loss 2.0215 (2.0957) acc@1 0.2031 (0.2164) acc@5 0.7188 (0.6788)\n",
      "\u001b[32m[2020-07-15 03:00:12] __main__ INFO: \u001b[0mEpoch 6 Step 300/351 lr 0.100000 loss 1.9603 (2.0821) acc@1 0.2500 (0.2224) acc@5 0.7500 (0.6837)\n",
      "\u001b[32m[2020-07-15 03:01:10] __main__ INFO: \u001b[0mEpoch 6 Step 351/351 lr 0.100000 loss 2.1038 (2.0768) acc@1 0.2109 (0.2242) acc@5 0.6562 (0.6857)\n",
      "\u001b[32m[2020-07-15 03:01:10] __main__ INFO: \u001b[0mElapsed 401.18\n",
      "\u001b[32m[2020-07-15 03:01:10] __main__ INFO: \u001b[0mVal 6\n",
      "\u001b[32m[2020-07-15 03:01:23] __main__ INFO: \u001b[0mEpoch 6 loss 1.5568 acc@1 0.4360 acc@5 0.9004\n",
      "\u001b[32m[2020-07-15 03:01:23] __main__ INFO: \u001b[0mElapsed 13.54\n",
      "\u001b[32m[2020-07-15 03:01:23] __main__ INFO: \u001b[0mTrain 7 2106\n",
      "\u001b[32m[2020-07-15 03:03:18] __main__ INFO: \u001b[0mEpoch 7 Step 100/351 lr 0.100000 loss 2.0074 (2.0185) acc@1 0.2969 (0.2428) acc@5 0.7109 (0.7041)\n",
      "\u001b[32m[2020-07-15 03:05:12] __main__ INFO: \u001b[0mEpoch 7 Step 200/351 lr 0.100000 loss 1.9841 (2.0062) acc@1 0.2578 (0.2487) acc@5 0.6797 (0.7045)\n",
      "\u001b[32m[2020-07-15 03:07:07] __main__ INFO: \u001b[0mEpoch 7 Step 300/351 lr 0.100000 loss 1.8934 (2.0005) acc@1 0.2656 (0.2530) acc@5 0.7812 (0.7063)\n",
      "\u001b[32m[2020-07-15 03:08:05] __main__ INFO: \u001b[0mEpoch 7 Step 351/351 lr 0.100000 loss 2.0037 (1.9943) acc@1 0.2500 (0.2553) acc@5 0.7031 (0.7076)\n",
      "\u001b[32m[2020-07-15 03:08:05] __main__ INFO: \u001b[0mElapsed 401.81\n",
      "\u001b[32m[2020-07-15 03:08:05] __main__ INFO: \u001b[0mVal 7\n",
      "\u001b[32m[2020-07-15 03:08:19] __main__ INFO: \u001b[0mEpoch 7 loss 1.3174 acc@1 0.5364 acc@5 0.9344\n",
      "\u001b[32m[2020-07-15 03:08:19] __main__ INFO: \u001b[0mElapsed 13.59\n",
      "\u001b[32m[2020-07-15 03:08:19] __main__ INFO: \u001b[0mTrain 8 2457\n",
      "\u001b[32m[2020-07-15 03:10:13] __main__ INFO: \u001b[0mEpoch 8 Step 100/351 lr 0.100000 loss 1.9756 (1.9295) acc@1 0.2812 (0.2821) acc@5 0.7188 (0.7234)\n",
      "\u001b[32m[2020-07-15 03:12:08] __main__ INFO: \u001b[0mEpoch 8 Step 200/351 lr 0.100000 loss 2.0205 (1.9341) acc@1 0.2188 (0.2804) acc@5 0.6953 (0.7187)\n",
      "\u001b[32m[2020-07-15 03:14:03] __main__ INFO: \u001b[0mEpoch 8 Step 300/351 lr 0.100000 loss 1.7458 (1.9262) acc@1 0.2969 (0.2827) acc@5 0.7891 (0.7211)\n",
      "\u001b[32m[2020-07-15 03:15:01] __main__ INFO: \u001b[0mEpoch 8 Step 351/351 lr 0.100000 loss 1.9896 (1.9226) acc@1 0.2422 (0.2851) acc@5 0.6875 (0.7231)\n",
      "\u001b[32m[2020-07-15 03:15:01] __main__ INFO: \u001b[0mElapsed 402.11\n",
      "\u001b[32m[2020-07-15 03:15:01] __main__ INFO: \u001b[0mVal 8\n",
      "\u001b[32m[2020-07-15 03:15:15] __main__ INFO: \u001b[0mEpoch 8 loss 1.2031 acc@1 0.5870 acc@5 0.9490\n",
      "\u001b[32m[2020-07-15 03:15:15] __main__ INFO: \u001b[0mElapsed 13.58\n",
      "\u001b[32m[2020-07-15 03:15:15] __main__ INFO: \u001b[0mTrain 9 2808\n",
      "\u001b[32m[2020-07-15 03:17:09] __main__ INFO: \u001b[0mEpoch 9 Step 100/351 lr 0.100000 loss 1.8542 (1.8886) acc@1 0.3516 (0.2994) acc@5 0.7578 (0.7230)\n",
      "\u001b[32m[2020-07-15 03:19:04] __main__ INFO: \u001b[0mEpoch 9 Step 200/351 lr 0.100000 loss 1.8008 (1.8747) acc@1 0.2891 (0.3026) acc@5 0.7344 (0.7292)\n",
      "\u001b[32m[2020-07-15 03:20:58] __main__ INFO: \u001b[0mEpoch 9 Step 300/351 lr 0.100000 loss 1.6682 (1.8712) acc@1 0.3984 (0.3040) acc@5 0.7969 (0.7318)\n",
      "\u001b[32m[2020-07-15 03:21:56] __main__ INFO: \u001b[0mEpoch 9 Step 351/351 lr 0.100000 loss 1.9241 (1.8694) acc@1 0.2578 (0.3042) acc@5 0.7734 (0.7323)\n",
      "\u001b[32m[2020-07-15 03:21:56] __main__ INFO: \u001b[0mElapsed 401.23\n",
      "\u001b[32m[2020-07-15 03:21:56] __main__ INFO: \u001b[0mVal 9\n",
      "\u001b[32m[2020-07-15 03:22:09] __main__ INFO: \u001b[0mEpoch 9 loss 1.2126 acc@1 0.5856 acc@5 0.9450\n",
      "\u001b[32m[2020-07-15 03:22:09] __main__ INFO: \u001b[0mElapsed 13.42\n",
      "\u001b[32m[2020-07-15 03:22:09] __main__ INFO: \u001b[0mTrain 10 3159\n",
      "\u001b[32m[2020-07-15 03:24:03] __main__ INFO: \u001b[0mEpoch 10 Step 100/351 lr 0.100000 loss 1.7352 (1.8277) acc@1 0.3281 (0.3232) acc@5 0.7734 (0.7463)\n",
      "\u001b[32m[2020-07-15 03:25:56] __main__ INFO: \u001b[0mEpoch 10 Step 200/351 lr 0.100000 loss 1.8485 (1.8265) acc@1 0.2891 (0.3229) acc@5 0.7500 (0.7444)\n",
      "\u001b[32m[2020-07-15 03:27:49] __main__ INFO: \u001b[0mEpoch 10 Step 300/351 lr 0.100000 loss 1.9368 (1.8270) acc@1 0.2578 (0.3242) acc@5 0.7422 (0.7437)\n",
      "\u001b[32m[2020-07-15 03:28:47] __main__ INFO: \u001b[0mEpoch 10 Step 351/351 lr 0.100000 loss 1.6691 (1.8243) acc@1 0.3516 (0.3246) acc@5 0.7812 (0.7452)\n",
      "\u001b[32m[2020-07-15 03:28:47] __main__ INFO: \u001b[0mElapsed 398.01\n",
      "\u001b[32m[2020-07-15 03:28:47] __main__ INFO: \u001b[0mVal 10\n",
      "\u001b[32m[2020-07-15 03:29:01] __main__ INFO: \u001b[0mEpoch 10 loss 1.2642 acc@1 0.5648 acc@5 0.9370\n",
      "\u001b[32m[2020-07-15 03:29:01] __main__ INFO: \u001b[0mElapsed 13.42\n",
      "\u001b[32m[2020-07-15 03:29:01] __main__ INFO: \u001b[0mTrain 11 3510\n",
      "\u001b[32m[2020-07-15 03:30:54] __main__ INFO: \u001b[0mEpoch 11 Step 100/351 lr 0.100000 loss 1.7914 (1.7922) acc@1 0.3281 (0.3320) acc@5 0.7266 (0.7482)\n",
      "\u001b[32m[2020-07-15 03:32:47] __main__ INFO: \u001b[0mEpoch 11 Step 200/351 lr 0.100000 loss 1.8027 (1.7952) acc@1 0.3281 (0.3339) acc@5 0.7344 (0.7486)\n",
      "\u001b[32m[2020-07-15 03:34:41] __main__ INFO: \u001b[0mEpoch 11 Step 300/351 lr 0.100000 loss 1.7101 (1.7866) acc@1 0.3438 (0.3372) acc@5 0.7656 (0.7512)\n",
      "\u001b[32m[2020-07-15 03:35:38] __main__ INFO: \u001b[0mEpoch 11 Step 351/351 lr 0.100000 loss 1.7021 (1.7844) acc@1 0.3438 (0.3373) acc@5 0.8203 (0.7517)\n",
      "\u001b[32m[2020-07-15 03:35:38] __main__ INFO: \u001b[0mElapsed 397.80\n",
      "\u001b[32m[2020-07-15 03:35:38] __main__ INFO: \u001b[0mVal 11\n",
      "\u001b[32m[2020-07-15 03:35:52] __main__ INFO: \u001b[0mEpoch 11 loss 1.0737 acc@1 0.6246 acc@5 0.9608\n",
      "\u001b[32m[2020-07-15 03:35:52] __main__ INFO: \u001b[0mElapsed 13.44\n",
      "\u001b[32m[2020-07-15 03:35:52] __main__ INFO: \u001b[0mTrain 12 3861\n",
      "\u001b[32m[2020-07-15 03:37:45] __main__ INFO: \u001b[0mEpoch 12 Step 100/351 lr 0.100000 loss 1.8234 (1.7510) acc@1 0.2812 (0.3540) acc@5 0.7812 (0.7587)\n",
      "\u001b[32m[2020-07-15 03:39:38] __main__ INFO: \u001b[0mEpoch 12 Step 200/351 lr 0.100000 loss 1.6835 (1.7488) acc@1 0.4297 (0.3534) acc@5 0.7812 (0.7627)\n",
      "\u001b[32m[2020-07-15 03:41:32] __main__ INFO: \u001b[0mEpoch 12 Step 300/351 lr 0.100000 loss 1.8019 (1.7507) acc@1 0.3047 (0.3509) acc@5 0.6875 (0.7604)\n",
      "\u001b[32m[2020-07-15 03:42:30] __main__ INFO: \u001b[0mEpoch 12 Step 351/351 lr 0.100000 loss 1.8041 (1.7511) acc@1 0.3359 (0.3505) acc@5 0.7266 (0.7597)\n",
      "\u001b[32m[2020-07-15 03:42:30] __main__ INFO: \u001b[0mElapsed 397.75\n",
      "\u001b[32m[2020-07-15 03:42:30] __main__ INFO: \u001b[0mVal 12\n",
      "\u001b[32m[2020-07-15 03:42:43] __main__ INFO: \u001b[0mEpoch 12 loss 1.4566 acc@1 0.5306 acc@5 0.9282\n",
      "\u001b[32m[2020-07-15 03:42:43] __main__ INFO: \u001b[0mElapsed 13.43\n",
      "\u001b[32m[2020-07-15 03:42:43] __main__ INFO: \u001b[0mTrain 13 4212\n",
      "\u001b[32m[2020-07-15 03:44:37] __main__ INFO: \u001b[0mEpoch 13 Step 100/351 lr 0.100000 loss 1.8283 (1.7234) acc@1 0.3516 (0.3670) acc@5 0.7188 (0.7700)\n",
      "\u001b[32m[2020-07-15 03:46:30] __main__ INFO: \u001b[0mEpoch 13 Step 200/351 lr 0.100000 loss 1.7077 (1.7235) acc@1 0.4141 (0.3644) acc@5 0.7422 (0.7681)\n",
      "\u001b[32m[2020-07-15 03:48:23] __main__ INFO: \u001b[0mEpoch 13 Step 300/351 lr 0.100000 loss 1.8204 (1.7248) acc@1 0.3047 (0.3609) acc@5 0.7266 (0.7635)\n",
      "\u001b[32m[2020-07-15 03:49:21] __main__ INFO: \u001b[0mEpoch 13 Step 351/351 lr 0.100000 loss 1.6339 (1.7243) acc@1 0.3906 (0.3613) acc@5 0.7812 (0.7642)\n",
      "\u001b[32m[2020-07-15 03:49:21] __main__ INFO: \u001b[0mElapsed 398.03\n",
      "\u001b[32m[2020-07-15 03:49:21] __main__ INFO: \u001b[0mVal 13\n",
      "\u001b[32m[2020-07-15 03:49:35] __main__ INFO: \u001b[0mEpoch 13 loss 1.0056 acc@1 0.6496 acc@5 0.9638\n",
      "\u001b[32m[2020-07-15 03:49:35] __main__ INFO: \u001b[0mElapsed 13.41\n",
      "\u001b[32m[2020-07-15 03:49:35] __main__ INFO: \u001b[0mTrain 14 4563\n",
      "\u001b[32m[2020-07-15 03:51:28] __main__ INFO: \u001b[0mEpoch 14 Step 100/351 lr 0.100000 loss 1.7958 (1.7155) acc@1 0.3281 (0.3676) acc@5 0.7344 (0.7608)\n",
      "\u001b[32m[2020-07-15 03:53:21] __main__ INFO: \u001b[0mEpoch 14 Step 200/351 lr 0.100000 loss 1.6568 (1.7093) acc@1 0.3438 (0.3670) acc@5 0.7578 (0.7620)\n",
      "\u001b[32m[2020-07-15 03:55:14] __main__ INFO: \u001b[0mEpoch 14 Step 300/351 lr 0.100000 loss 1.6562 (1.7108) acc@1 0.3594 (0.3668) acc@5 0.8203 (0.7624)\n",
      "\u001b[32m[2020-07-15 03:56:12] __main__ INFO: \u001b[0mEpoch 14 Step 351/351 lr 0.100000 loss 1.7603 (1.7076) acc@1 0.3516 (0.3683) acc@5 0.7500 (0.7627)\n",
      "\u001b[32m[2020-07-15 03:56:12] __main__ INFO: \u001b[0mElapsed 397.32\n",
      "\u001b[32m[2020-07-15 03:56:12] __main__ INFO: \u001b[0mVal 14\n",
      "\u001b[32m[2020-07-15 03:56:25] __main__ INFO: \u001b[0mEpoch 14 loss 0.9597 acc@1 0.6792 acc@5 0.9678\n",
      "\u001b[32m[2020-07-15 03:56:25] __main__ INFO: \u001b[0mElapsed 13.40\n",
      "\u001b[32m[2020-07-15 03:56:25] __main__ INFO: \u001b[0mTrain 15 4914\n",
      "\u001b[32m[2020-07-15 03:58:18] __main__ INFO: \u001b[0mEpoch 15 Step 100/351 lr 0.100000 loss 1.7565 (1.6690) acc@1 0.3438 (0.3855) acc@5 0.7266 (0.7702)\n",
      "\u001b[32m[2020-07-15 04:00:12] __main__ INFO: \u001b[0mEpoch 15 Step 200/351 lr 0.100000 loss 1.6549 (1.6869) acc@1 0.3828 (0.3782) acc@5 0.8281 (0.7662)\n",
      "\u001b[32m[2020-07-15 04:02:05] __main__ INFO: \u001b[0mEpoch 15 Step 300/351 lr 0.100000 loss 1.6969 (1.6900) acc@1 0.3281 (0.3761) acc@5 0.7812 (0.7657)\n",
      "\u001b[32m[2020-07-15 04:03:03] __main__ INFO: \u001b[0mEpoch 15 Step 351/351 lr 0.100000 loss 1.7228 (1.6891) acc@1 0.3906 (0.3759) acc@5 0.7578 (0.7659)\n",
      "\u001b[32m[2020-07-15 04:03:03] __main__ INFO: \u001b[0mElapsed 397.70\n",
      "\u001b[32m[2020-07-15 04:03:03] __main__ INFO: \u001b[0mVal 15\n",
      "\u001b[32m[2020-07-15 04:03:16] __main__ INFO: \u001b[0mEpoch 15 loss 0.9362 acc@1 0.6800 acc@5 0.9706\n",
      "\u001b[32m[2020-07-15 04:03:16] __main__ INFO: \u001b[0mElapsed 13.51\n",
      "\u001b[32m[2020-07-15 04:03:16] __main__ INFO: \u001b[0mTrain 16 5265\n",
      "\u001b[32m[2020-07-15 04:05:10] __main__ INFO: \u001b[0mEpoch 16 Step 100/351 lr 0.100000 loss 1.7494 (1.6618) acc@1 0.3281 (0.3848) acc@5 0.7109 (0.7720)\n",
      "\u001b[32m[2020-07-15 04:07:04] __main__ INFO: \u001b[0mEpoch 16 Step 200/351 lr 0.100000 loss 1.5854 (1.6694) acc@1 0.4219 (0.3855) acc@5 0.7734 (0.7714)\n",
      "\u001b[32m[2020-07-15 04:08:58] __main__ INFO: \u001b[0mEpoch 16 Step 300/351 lr 0.100000 loss 1.8175 (1.6721) acc@1 0.3438 (0.3831) acc@5 0.7344 (0.7693)\n",
      "\u001b[32m[2020-07-15 04:09:56] __main__ INFO: \u001b[0mEpoch 16 Step 351/351 lr 0.100000 loss 1.7066 (1.6715) acc@1 0.3438 (0.3830) acc@5 0.7812 (0.7692)\n",
      "\u001b[32m[2020-07-15 04:09:56] __main__ INFO: \u001b[0mElapsed 399.93\n",
      "\u001b[32m[2020-07-15 04:09:56] __main__ INFO: \u001b[0mVal 16\n",
      "\u001b[32m[2020-07-15 04:10:10] __main__ INFO: \u001b[0mEpoch 16 loss 0.8833 acc@1 0.7008 acc@5 0.9700\n",
      "\u001b[32m[2020-07-15 04:10:10] __main__ INFO: \u001b[0mElapsed 13.44\n",
      "\u001b[32m[2020-07-15 04:10:10] __main__ INFO: \u001b[0mTrain 17 5616\n",
      "\u001b[32m[2020-07-15 04:12:04] __main__ INFO: \u001b[0mEpoch 17 Step 100/351 lr 0.100000 loss 1.6407 (1.6496) acc@1 0.4219 (0.3892) acc@5 0.7969 (0.7752)\n",
      "\u001b[32m[2020-07-15 04:13:59] __main__ INFO: \u001b[0mEpoch 17 Step 200/351 lr 0.100000 loss 1.6419 (1.6580) acc@1 0.3984 (0.3854) acc@5 0.8438 (0.7724)\n",
      "\u001b[32m[2020-07-15 04:15:53] __main__ INFO: \u001b[0mEpoch 17 Step 300/351 lr 0.100000 loss 1.7211 (1.6592) acc@1 0.3281 (0.3852) acc@5 0.7188 (0.7713)\n",
      "\u001b[32m[2020-07-15 04:16:51] __main__ INFO: \u001b[0mEpoch 17 Step 351/351 lr 0.100000 loss 1.8602 (1.6585) acc@1 0.3516 (0.3866) acc@5 0.7031 (0.7711)\n",
      "\u001b[32m[2020-07-15 04:16:51] __main__ INFO: \u001b[0mElapsed 401.52\n",
      "\u001b[32m[2020-07-15 04:16:51] __main__ INFO: \u001b[0mVal 17\n",
      "\u001b[32m[2020-07-15 04:17:05] __main__ INFO: \u001b[0mEpoch 17 loss 1.0211 acc@1 0.6618 acc@5 0.9738\n",
      "\u001b[32m[2020-07-15 04:17:05] __main__ INFO: \u001b[0mElapsed 13.52\n",
      "\u001b[32m[2020-07-15 04:17:05] __main__ INFO: \u001b[0mTrain 18 5967\n",
      "\u001b[32m[2020-07-15 04:18:59] __main__ INFO: \u001b[0mEpoch 18 Step 100/351 lr 0.100000 loss 1.6533 (1.6374) acc@1 0.3828 (0.3964) acc@5 0.7500 (0.7702)\n",
      "\u001b[32m[2020-07-15 04:20:54] __main__ INFO: \u001b[0mEpoch 18 Step 200/351 lr 0.100000 loss 1.5812 (1.6439) acc@1 0.3594 (0.3901) acc@5 0.8125 (0.7717)\n",
      "\u001b[32m[2020-07-15 04:22:48] __main__ INFO: \u001b[0mEpoch 18 Step 300/351 lr 0.100000 loss 1.6582 (1.6465) acc@1 0.3672 (0.3906) acc@5 0.7656 (0.7726)\n",
      "\u001b[32m[2020-07-15 04:23:46] __main__ INFO: \u001b[0mEpoch 18 Step 351/351 lr 0.100000 loss 1.6774 (1.6459) acc@1 0.3516 (0.3911) acc@5 0.8047 (0.7737)\n",
      "\u001b[32m[2020-07-15 04:23:46] __main__ INFO: \u001b[0mElapsed 401.27\n",
      "\u001b[32m[2020-07-15 04:23:46] __main__ INFO: \u001b[0mVal 18\n",
      "\u001b[32m[2020-07-15 04:24:00] __main__ INFO: \u001b[0mEpoch 18 loss 1.1740 acc@1 0.6082 acc@5 0.9658\n",
      "\u001b[32m[2020-07-15 04:24:00] __main__ INFO: \u001b[0mElapsed 13.49\n",
      "\u001b[32m[2020-07-15 04:24:00] __main__ INFO: \u001b[0mTrain 19 6318\n",
      "\u001b[32m[2020-07-15 04:25:54] __main__ INFO: \u001b[0mEpoch 19 Step 100/351 lr 0.100000 loss 1.6582 (1.6318) acc@1 0.3750 (0.3947) acc@5 0.7656 (0.7830)\n",
      "\u001b[32m[2020-07-15 04:27:48] __main__ INFO: \u001b[0mEpoch 19 Step 200/351 lr 0.100000 loss 1.5482 (1.6291) acc@1 0.4141 (0.3962) acc@5 0.7656 (0.7791)\n",
      "\u001b[32m[2020-07-15 04:29:43] __main__ INFO: \u001b[0mEpoch 19 Step 300/351 lr 0.100000 loss 1.6128 (1.6290) acc@1 0.3516 (0.3961) acc@5 0.7500 (0.7781)\n",
      "\u001b[32m[2020-07-15 04:30:41] __main__ INFO: \u001b[0mEpoch 19 Step 351/351 lr 0.100000 loss 1.6697 (1.6327) acc@1 0.3906 (0.3951) acc@5 0.7656 (0.7773)\n",
      "\u001b[32m[2020-07-15 04:30:41] __main__ INFO: \u001b[0mElapsed 401.27\n",
      "\u001b[32m[2020-07-15 04:30:41] __main__ INFO: \u001b[0mVal 19\n",
      "\u001b[32m[2020-07-15 04:30:54] __main__ INFO: \u001b[0mEpoch 19 loss 0.7575 acc@1 0.7458 acc@5 0.9804\n",
      "\u001b[32m[2020-07-15 04:30:54] __main__ INFO: \u001b[0mElapsed 13.48\n",
      "\u001b[32m[2020-07-15 04:30:54] __main__ INFO: \u001b[0mTrain 20 6669\n",
      "\u001b[32m[2020-07-15 04:32:49] __main__ INFO: \u001b[0mEpoch 20 Step 100/351 lr 0.100000 loss 1.6547 (1.6157) acc@1 0.4062 (0.4053) acc@5 0.7109 (0.7752)\n",
      "\u001b[32m[2020-07-15 04:34:43] __main__ INFO: \u001b[0mEpoch 20 Step 200/351 lr 0.100000 loss 1.6988 (1.6201) acc@1 0.3359 (0.4029) acc@5 0.7578 (0.7778)\n",
      "\u001b[32m[2020-07-15 04:36:37] __main__ INFO: \u001b[0mEpoch 20 Step 300/351 lr 0.100000 loss 1.5138 (1.6190) acc@1 0.4688 (0.4024) acc@5 0.7656 (0.7755)\n",
      "\u001b[32m[2020-07-15 04:37:35] __main__ INFO: \u001b[0mEpoch 20 Step 351/351 lr 0.100000 loss 1.6920 (1.6215) acc@1 0.3750 (0.4007) acc@5 0.7891 (0.7749)\n",
      "\u001b[32m[2020-07-15 04:37:35] __main__ INFO: \u001b[0mElapsed 400.42\n",
      "\u001b[32m[2020-07-15 04:37:35] __main__ INFO: \u001b[0mVal 20\n",
      "\u001b[32m[2020-07-15 04:37:48] __main__ INFO: \u001b[0mEpoch 20 loss 0.7554 acc@1 0.7288 acc@5 0.9826\n",
      "\u001b[32m[2020-07-15 04:37:48] __main__ INFO: \u001b[0mElapsed 13.49\n",
      "\u001b[32m[2020-07-15 04:37:48] __main__ INFO: \u001b[0mTrain 21 7020\n",
      "\u001b[32m[2020-07-15 04:39:43] __main__ INFO: \u001b[0mEpoch 21 Step 100/351 lr 0.100000 loss 1.5347 (1.6030) acc@1 0.4688 (0.4054) acc@5 0.7422 (0.7755)\n",
      "\u001b[32m[2020-07-15 04:41:37] __main__ INFO: \u001b[0mEpoch 21 Step 200/351 lr 0.100000 loss 1.5138 (1.6008) acc@1 0.4609 (0.4055) acc@5 0.7969 (0.7792)\n",
      "\u001b[32m[2020-07-15 04:43:31] __main__ INFO: \u001b[0mEpoch 21 Step 300/351 lr 0.100000 loss 1.7017 (1.6085) acc@1 0.3672 (0.4033) acc@5 0.7344 (0.7792)\n",
      "\u001b[32m[2020-07-15 04:44:29] __main__ INFO: \u001b[0mEpoch 21 Step 351/351 lr 0.100000 loss 1.5543 (1.6084) acc@1 0.4297 (0.4040) acc@5 0.8203 (0.7787)\n",
      "\u001b[32m[2020-07-15 04:44:29] __main__ INFO: \u001b[0mElapsed 400.27\n",
      "\u001b[32m[2020-07-15 04:44:29] __main__ INFO: \u001b[0mVal 21\n",
      "\u001b[32m[2020-07-15 04:44:42] __main__ INFO: \u001b[0mEpoch 21 loss 0.7758 acc@1 0.7342 acc@5 0.9792\n",
      "\u001b[32m[2020-07-15 04:44:42] __main__ INFO: \u001b[0mElapsed 13.49\n",
      "\u001b[32m[2020-07-15 04:44:42] __main__ INFO: \u001b[0mTrain 22 7371\n",
      "\u001b[32m[2020-07-15 04:46:36] __main__ INFO: \u001b[0mEpoch 22 Step 100/351 lr 0.100000 loss 1.7447 (1.5747) acc@1 0.3594 (0.4199) acc@5 0.7422 (0.7824)\n",
      "\u001b[32m[2020-07-15 04:48:30] __main__ INFO: \u001b[0mEpoch 22 Step 200/351 lr 0.100000 loss 1.5334 (1.5858) acc@1 0.4609 (0.4161) acc@5 0.8594 (0.7788)\n",
      "\u001b[32m[2020-07-15 04:50:24] __main__ INFO: \u001b[0mEpoch 22 Step 300/351 lr 0.100000 loss 1.4974 (1.5920) acc@1 0.4453 (0.4120) acc@5 0.8359 (0.7785)\n",
      "\u001b[32m[2020-07-15 04:51:22] __main__ INFO: \u001b[0mEpoch 22 Step 351/351 lr 0.100000 loss 1.5948 (1.5948) acc@1 0.3906 (0.4106) acc@5 0.7500 (0.7782)\n",
      "\u001b[32m[2020-07-15 04:51:22] __main__ INFO: \u001b[0mElapsed 399.65\n",
      "\u001b[32m[2020-07-15 04:51:22] __main__ INFO: \u001b[0mVal 22\n",
      "\u001b[32m[2020-07-15 04:51:35] __main__ INFO: \u001b[0mEpoch 22 loss 0.9774 acc@1 0.6866 acc@5 0.9640\n",
      "\u001b[32m[2020-07-15 04:51:35] __main__ INFO: \u001b[0mElapsed 13.45\n",
      "\u001b[32m[2020-07-15 04:51:35] __main__ INFO: \u001b[0mTrain 23 7722\n",
      "\u001b[32m[2020-07-15 04:53:29] __main__ INFO: \u001b[0mEpoch 23 Step 100/351 lr 0.100000 loss 1.5205 (1.5704) acc@1 0.4609 (0.4198) acc@5 0.7891 (0.7858)\n",
      "\u001b[32m[2020-07-15 04:55:23] __main__ INFO: \u001b[0mEpoch 23 Step 200/351 lr 0.100000 loss 1.5197 (1.5850) acc@1 0.3984 (0.4132) acc@5 0.7891 (0.7824)\n",
      "\u001b[32m[2020-07-15 04:57:16] __main__ INFO: \u001b[0mEpoch 23 Step 300/351 lr 0.100000 loss 1.7586 (1.5877) acc@1 0.3750 (0.4108) acc@5 0.7578 (0.7803)\n",
      "\u001b[32m[2020-07-15 04:58:14] __main__ INFO: \u001b[0mEpoch 23 Step 351/351 lr 0.100000 loss 1.6540 (1.5870) acc@1 0.3906 (0.4112) acc@5 0.8359 (0.7810)\n",
      "\u001b[32m[2020-07-15 04:58:14] __main__ INFO: \u001b[0mElapsed 399.14\n",
      "\u001b[32m[2020-07-15 04:58:14] __main__ INFO: \u001b[0mVal 23\n",
      "\u001b[32m[2020-07-15 04:58:28] __main__ INFO: \u001b[0mEpoch 23 loss 0.6852 acc@1 0.7620 acc@5 0.9836\n",
      "\u001b[32m[2020-07-15 04:58:28] __main__ INFO: \u001b[0mElapsed 13.44\n",
      "\u001b[32m[2020-07-15 04:58:28] __main__ INFO: \u001b[0mTrain 24 8073\n",
      "\u001b[32m[2020-07-15 05:00:21] __main__ INFO: \u001b[0mEpoch 24 Step 100/351 lr 0.100000 loss 1.7628 (1.5775) acc@1 0.3828 (0.4149) acc@5 0.7500 (0.7801)\n",
      "\u001b[32m[2020-07-15 05:02:15] __main__ INFO: \u001b[0mEpoch 24 Step 200/351 lr 0.100000 loss 1.5716 (1.5813) acc@1 0.4375 (0.4143) acc@5 0.7578 (0.7798)\n",
      "\u001b[32m[2020-07-15 05:04:09] __main__ INFO: \u001b[0mEpoch 24 Step 300/351 lr 0.100000 loss 1.5729 (1.5876) acc@1 0.4766 (0.4109) acc@5 0.8438 (0.7787)\n",
      "\u001b[32m[2020-07-15 05:05:07] __main__ INFO: \u001b[0mEpoch 24 Step 351/351 lr 0.100000 loss 1.6023 (1.5828) acc@1 0.4219 (0.4126) acc@5 0.7500 (0.7796)\n",
      "\u001b[32m[2020-07-15 05:05:07] __main__ INFO: \u001b[0mElapsed 398.99\n",
      "\u001b[32m[2020-07-15 05:05:07] __main__ INFO: \u001b[0mVal 24\n",
      "\u001b[32m[2020-07-15 05:05:20] __main__ INFO: \u001b[0mEpoch 24 loss 0.8258 acc@1 0.7104 acc@5 0.9758\n",
      "\u001b[32m[2020-07-15 05:05:20] __main__ INFO: \u001b[0mElapsed 13.47\n",
      "\u001b[32m[2020-07-15 05:05:20] __main__ INFO: \u001b[0mTrain 25 8424\n",
      "\u001b[32m[2020-07-15 05:07:14] __main__ INFO: \u001b[0mEpoch 25 Step 100/351 lr 0.100000 loss 1.5366 (1.5661) acc@1 0.4219 (0.4244) acc@5 0.7266 (0.7838)\n",
      "\u001b[32m[2020-07-15 05:09:08] __main__ INFO: \u001b[0mEpoch 25 Step 200/351 lr 0.100000 loss 1.5761 (1.5622) acc@1 0.3750 (0.4229) acc@5 0.7500 (0.7814)\n",
      "\u001b[32m[2020-07-15 05:11:02] __main__ INFO: \u001b[0mEpoch 25 Step 300/351 lr 0.100000 loss 1.4527 (1.5785) acc@1 0.4375 (0.4183) acc@5 0.7578 (0.7790)\n",
      "\u001b[32m[2020-07-15 05:12:00] __main__ INFO: \u001b[0mEpoch 25 Step 351/351 lr 0.100000 loss 1.6499 (1.5800) acc@1 0.4062 (0.4179) acc@5 0.7188 (0.7783)\n",
      "\u001b[32m[2020-07-15 05:12:00] __main__ INFO: \u001b[0mElapsed 399.36\n",
      "\u001b[32m[2020-07-15 05:12:00] __main__ INFO: \u001b[0mVal 25\n",
      "\u001b[32m[2020-07-15 05:12:13] __main__ INFO: \u001b[0mEpoch 25 loss 0.9477 acc@1 0.7046 acc@5 0.9618\n",
      "\u001b[32m[2020-07-15 05:12:13] __main__ INFO: \u001b[0mElapsed 13.46\n",
      "\u001b[32m[2020-07-15 05:12:13] __main__ INFO: \u001b[0mTrain 26 8775\n",
      "\u001b[32m[2020-07-15 05:14:07] __main__ INFO: \u001b[0mEpoch 26 Step 100/351 lr 0.100000 loss 1.5864 (1.5721) acc@1 0.3438 (0.4189) acc@5 0.8359 (0.7836)\n",
      "\u001b[32m[2020-07-15 05:16:01] __main__ INFO: \u001b[0mEpoch 26 Step 200/351 lr 0.100000 loss 1.4458 (1.5602) acc@1 0.4766 (0.4243) acc@5 0.8281 (0.7829)\n",
      "\u001b[32m[2020-07-15 05:17:54] __main__ INFO: \u001b[0mEpoch 26 Step 300/351 lr 0.100000 loss 1.5899 (1.5686) acc@1 0.3984 (0.4196) acc@5 0.7734 (0.7812)\n",
      "\u001b[32m[2020-07-15 05:18:52] __main__ INFO: \u001b[0mEpoch 26 Step 351/351 lr 0.100000 loss 1.6808 (1.5674) acc@1 0.3984 (0.4197) acc@5 0.7656 (0.7816)\n",
      "\u001b[32m[2020-07-15 05:18:52] __main__ INFO: \u001b[0mElapsed 399.36\n",
      "\u001b[32m[2020-07-15 05:18:52] __main__ INFO: \u001b[0mVal 26\n",
      "\u001b[32m[2020-07-15 05:19:06] __main__ INFO: \u001b[0mEpoch 26 loss 0.9071 acc@1 0.7054 acc@5 0.9748\n",
      "\u001b[32m[2020-07-15 05:19:06] __main__ INFO: \u001b[0mElapsed 13.43\n",
      "\u001b[32m[2020-07-15 05:19:06] __main__ INFO: \u001b[0mTrain 27 9126\n",
      "\u001b[32m[2020-07-15 05:21:00] __main__ INFO: \u001b[0mEpoch 27 Step 100/351 lr 0.100000 loss 1.5563 (1.5465) acc@1 0.3906 (0.4284) acc@5 0.8203 (0.7866)\n",
      "\u001b[32m[2020-07-15 05:22:53] __main__ INFO: \u001b[0mEpoch 27 Step 200/351 lr 0.100000 loss 1.7072 (1.5593) acc@1 0.3906 (0.4249) acc@5 0.7500 (0.7841)\n",
      "\u001b[32m[2020-07-15 05:24:46] __main__ INFO: \u001b[0mEpoch 27 Step 300/351 lr 0.100000 loss 1.5648 (1.5635) acc@1 0.3984 (0.4236) acc@5 0.7969 (0.7835)\n",
      "\u001b[32m[2020-07-15 05:25:44] __main__ INFO: \u001b[0mEpoch 27 Step 351/351 lr 0.100000 loss 1.6466 (1.5647) acc@1 0.3750 (0.4227) acc@5 0.7500 (0.7831)\n",
      "\u001b[32m[2020-07-15 05:25:44] __main__ INFO: \u001b[0mElapsed 398.15\n",
      "\u001b[32m[2020-07-15 05:25:44] __main__ INFO: \u001b[0mVal 27\n",
      "\u001b[32m[2020-07-15 05:25:57] __main__ INFO: \u001b[0mEpoch 27 loss 1.0809 acc@1 0.6520 acc@5 0.9682\n",
      "\u001b[32m[2020-07-15 05:25:57] __main__ INFO: \u001b[0mElapsed 13.44\n",
      "\u001b[32m[2020-07-15 05:25:57] __main__ INFO: \u001b[0mTrain 28 9477\n",
      "\u001b[32m[2020-07-15 05:27:51] __main__ INFO: \u001b[0mEpoch 28 Step 100/351 lr 0.100000 loss 1.4630 (1.5534) acc@1 0.4375 (0.4217) acc@5 0.8125 (0.7836)\n",
      "\u001b[32m[2020-07-15 05:29:45] __main__ INFO: \u001b[0mEpoch 28 Step 200/351 lr 0.100000 loss 1.6596 (1.5528) acc@1 0.3594 (0.4240) acc@5 0.7891 (0.7821)\n",
      "\u001b[32m[2020-07-15 05:31:38] __main__ INFO: \u001b[0mEpoch 28 Step 300/351 lr 0.100000 loss 1.2776 (1.5570) acc@1 0.5312 (0.4228) acc@5 0.8984 (0.7804)\n",
      "\u001b[32m[2020-07-15 05:32:36] __main__ INFO: \u001b[0mEpoch 28 Step 351/351 lr 0.100000 loss 1.4054 (1.5578) acc@1 0.5156 (0.4225) acc@5 0.8359 (0.7795)\n",
      "\u001b[32m[2020-07-15 05:32:36] __main__ INFO: \u001b[0mElapsed 398.95\n",
      "\u001b[32m[2020-07-15 05:32:36] __main__ INFO: \u001b[0mVal 28\n",
      "\u001b[32m[2020-07-15 05:32:50] __main__ INFO: \u001b[0mEpoch 28 loss 0.7629 acc@1 0.7492 acc@5 0.9796\n",
      "\u001b[32m[2020-07-15 05:32:50] __main__ INFO: \u001b[0mElapsed 13.45\n",
      "\u001b[32m[2020-07-15 05:32:50] __main__ INFO: \u001b[0mTrain 29 9828\n",
      "\u001b[32m[2020-07-15 05:34:44] __main__ INFO: \u001b[0mEpoch 29 Step 100/351 lr 0.100000 loss 1.4570 (1.5387) acc@1 0.4844 (0.4311) acc@5 0.8281 (0.7858)\n",
      "\u001b[32m[2020-07-15 05:36:37] __main__ INFO: \u001b[0mEpoch 29 Step 200/351 lr 0.100000 loss 1.3952 (1.5385) acc@1 0.4922 (0.4296) acc@5 0.8438 (0.7841)\n",
      "\u001b[32m[2020-07-15 05:38:31] __main__ INFO: \u001b[0mEpoch 29 Step 300/351 lr 0.100000 loss 1.5697 (1.5510) acc@1 0.4375 (0.4247) acc@5 0.7188 (0.7812)\n",
      "\u001b[32m[2020-07-15 05:39:29] __main__ INFO: \u001b[0mEpoch 29 Step 351/351 lr 0.100000 loss 1.5294 (1.5524) acc@1 0.4297 (0.4232) acc@5 0.7969 (0.7816)\n",
      "\u001b[32m[2020-07-15 05:39:29] __main__ INFO: \u001b[0mElapsed 398.96\n",
      "\u001b[32m[2020-07-15 05:39:29] __main__ INFO: \u001b[0mVal 29\n",
      "\u001b[32m[2020-07-15 05:39:42] __main__ INFO: \u001b[0mEpoch 29 loss 0.8789 acc@1 0.7068 acc@5 0.9726\n",
      "\u001b[32m[2020-07-15 05:39:42] __main__ INFO: \u001b[0mElapsed 13.46\n",
      "\u001b[32m[2020-07-15 05:39:42] __main__ INFO: \u001b[0mTrain 30 10179\n",
      "\u001b[32m[2020-07-15 05:41:36] __main__ INFO: \u001b[0mEpoch 30 Step 100/351 lr 0.100000 loss 1.6236 (1.5298) acc@1 0.3984 (0.4340) acc@5 0.7500 (0.7847)\n",
      "\u001b[32m[2020-07-15 05:43:30] __main__ INFO: \u001b[0mEpoch 30 Step 200/351 lr 0.100000 loss 1.5738 (1.5364) acc@1 0.4297 (0.4299) acc@5 0.7891 (0.7837)\n",
      "\u001b[32m[2020-07-15 05:45:23] __main__ INFO: \u001b[0mEpoch 30 Step 300/351 lr 0.100000 loss 1.4988 (1.5423) acc@1 0.4609 (0.4297) acc@5 0.7578 (0.7824)\n",
      "\u001b[32m[2020-07-15 05:46:21] __main__ INFO: \u001b[0mEpoch 30 Step 351/351 lr 0.100000 loss 1.6935 (1.5421) acc@1 0.3906 (0.4308) acc@5 0.7422 (0.7835)\n",
      "\u001b[32m[2020-07-15 05:46:22] __main__ INFO: \u001b[0mElapsed 399.26\n",
      "\u001b[32m[2020-07-15 05:46:22] __main__ INFO: \u001b[0mVal 30\n",
      "\u001b[32m[2020-07-15 05:46:35] __main__ INFO: \u001b[0mEpoch 30 loss 0.9402 acc@1 0.6740 acc@5 0.9692\n",
      "\u001b[32m[2020-07-15 05:46:35] __main__ INFO: \u001b[0mElapsed 13.44\n",
      "\u001b[32m[2020-07-15 05:46:35] __main__ INFO: \u001b[0mTrain 31 10530\n",
      "\u001b[32m[2020-07-15 05:48:29] __main__ INFO: \u001b[0mEpoch 31 Step 100/351 lr 0.100000 loss 1.6255 (1.5209) acc@1 0.3750 (0.4373) acc@5 0.7031 (0.7891)\n",
      "\u001b[32m[2020-07-15 05:50:22] __main__ INFO: \u001b[0mEpoch 31 Step 200/351 lr 0.100000 loss 1.4451 (1.5350) acc@1 0.4531 (0.4304) acc@5 0.7422 (0.7842)\n",
      "\u001b[32m[2020-07-15 05:52:16] __main__ INFO: \u001b[0mEpoch 31 Step 300/351 lr 0.100000 loss 1.4871 (1.5363) acc@1 0.4141 (0.4304) acc@5 0.7891 (0.7833)\n",
      "\u001b[32m[2020-07-15 05:53:14] __main__ INFO: \u001b[0mEpoch 31 Step 351/351 lr 0.100000 loss 1.7291 (1.5379) acc@1 0.3750 (0.4297) acc@5 0.7266 (0.7837)\n",
      "\u001b[32m[2020-07-15 05:53:14] __main__ INFO: \u001b[0mElapsed 398.90\n",
      "\u001b[32m[2020-07-15 05:53:14] __main__ INFO: \u001b[0mVal 31\n",
      "\u001b[32m[2020-07-15 05:53:27] __main__ INFO: \u001b[0mEpoch 31 loss 0.6749 acc@1 0.7716 acc@5 0.9854\n",
      "\u001b[32m[2020-07-15 05:53:27] __main__ INFO: \u001b[0mElapsed 13.40\n",
      "\u001b[32m[2020-07-15 05:53:27] __main__ INFO: \u001b[0mTrain 32 10881\n",
      "\u001b[32m[2020-07-15 05:55:21] __main__ INFO: \u001b[0mEpoch 32 Step 100/351 lr 0.100000 loss 1.4190 (1.5248) acc@1 0.4609 (0.4291) acc@5 0.8438 (0.7866)\n",
      "\u001b[32m[2020-07-15 05:57:14] __main__ INFO: \u001b[0mEpoch 32 Step 200/351 lr 0.100000 loss 1.4807 (1.5286) acc@1 0.4688 (0.4305) acc@5 0.8047 (0.7867)\n",
      "\u001b[32m[2020-07-15 05:59:07] __main__ INFO: \u001b[0mEpoch 32 Step 300/351 lr 0.100000 loss 1.5305 (1.5366) acc@1 0.3984 (0.4289) acc@5 0.7734 (0.7851)\n",
      "\u001b[32m[2020-07-15 06:00:04] __main__ INFO: \u001b[0mEpoch 32 Step 351/351 lr 0.100000 loss 1.6772 (1.5390) acc@1 0.3984 (0.4288) acc@5 0.7422 (0.7849)\n",
      "\u001b[32m[2020-07-15 06:00:04] __main__ INFO: \u001b[0mElapsed 397.12\n",
      "\u001b[32m[2020-07-15 06:00:04] __main__ INFO: \u001b[0mVal 32\n",
      "\u001b[32m[2020-07-15 06:00:18] __main__ INFO: \u001b[0mEpoch 32 loss 0.6913 acc@1 0.7718 acc@5 0.9828\n",
      "\u001b[32m[2020-07-15 06:00:18] __main__ INFO: \u001b[0mElapsed 13.38\n",
      "\u001b[32m[2020-07-15 06:00:18] __main__ INFO: \u001b[0mTrain 33 11232\n",
      "\u001b[32m[2020-07-15 06:02:11] __main__ INFO: \u001b[0mEpoch 33 Step 100/351 lr 0.100000 loss 1.4659 (1.5230) acc@1 0.4297 (0.4395) acc@5 0.7969 (0.7938)\n",
      "\u001b[32m[2020-07-15 06:04:04] __main__ INFO: \u001b[0mEpoch 33 Step 200/351 lr 0.100000 loss 1.5370 (1.5262) acc@1 0.4219 (0.4363) acc@5 0.7578 (0.7895)\n",
      "\u001b[32m[2020-07-15 06:05:57] __main__ INFO: \u001b[0mEpoch 33 Step 300/351 lr 0.100000 loss 1.5873 (1.5279) acc@1 0.3750 (0.4356) acc@5 0.7734 (0.7888)\n",
      "\u001b[32m[2020-07-15 06:06:54] __main__ INFO: \u001b[0mEpoch 33 Step 351/351 lr 0.100000 loss 1.4037 (1.5336) acc@1 0.4844 (0.4342) acc@5 0.7578 (0.7864)\n",
      "\u001b[32m[2020-07-15 06:06:54] __main__ INFO: \u001b[0mElapsed 396.57\n",
      "\u001b[32m[2020-07-15 06:06:54] __main__ INFO: \u001b[0mVal 33\n",
      "\u001b[32m[2020-07-15 06:07:08] __main__ INFO: \u001b[0mEpoch 33 loss 1.0588 acc@1 0.6760 acc@5 0.9702\n",
      "\u001b[32m[2020-07-15 06:07:08] __main__ INFO: \u001b[0mElapsed 13.38\n",
      "\u001b[32m[2020-07-15 06:07:08] __main__ INFO: \u001b[0mTrain 34 11583\n",
      "\u001b[32m[2020-07-15 06:09:01] __main__ INFO: \u001b[0mEpoch 34 Step 100/351 lr 0.100000 loss 1.3210 (1.4991) acc@1 0.5156 (0.4453) acc@5 0.7969 (0.7880)\n",
      "\u001b[32m[2020-07-15 06:10:54] __main__ INFO: \u001b[0mEpoch 34 Step 200/351 lr 0.100000 loss 1.5339 (1.5131) acc@1 0.4453 (0.4394) acc@5 0.7812 (0.7877)\n",
      "\u001b[32m[2020-07-15 06:12:47] __main__ INFO: \u001b[0mEpoch 34 Step 300/351 lr 0.100000 loss 1.4335 (1.5203) acc@1 0.4297 (0.4374) acc@5 0.7812 (0.7867)\n",
      "\u001b[32m[2020-07-15 06:13:45] __main__ INFO: \u001b[0mEpoch 34 Step 351/351 lr 0.100000 loss 1.6934 (1.5239) acc@1 0.3672 (0.4355) acc@5 0.7500 (0.7848)\n",
      "\u001b[32m[2020-07-15 06:13:45] __main__ INFO: \u001b[0mElapsed 397.30\n",
      "\u001b[32m[2020-07-15 06:13:45] __main__ INFO: \u001b[0mVal 34\n",
      "\u001b[32m[2020-07-15 06:13:58] __main__ INFO: \u001b[0mEpoch 34 loss 0.7797 acc@1 0.7432 acc@5 0.9762\n",
      "\u001b[32m[2020-07-15 06:13:58] __main__ INFO: \u001b[0mElapsed 13.38\n",
      "\u001b[32m[2020-07-15 06:13:58] __main__ INFO: \u001b[0mTrain 35 11934\n",
      "\u001b[32m[2020-07-15 06:15:52] __main__ INFO: \u001b[0mEpoch 35 Step 100/351 lr 0.100000 loss 1.5775 (1.5129) acc@1 0.4062 (0.4417) acc@5 0.7812 (0.7855)\n",
      "\u001b[32m[2020-07-15 06:17:44] __main__ INFO: \u001b[0mEpoch 35 Step 200/351 lr 0.100000 loss 1.5467 (1.5149) acc@1 0.4453 (0.4384) acc@5 0.8125 (0.7889)\n",
      "\u001b[32m[2020-07-15 06:19:38] __main__ INFO: \u001b[0mEpoch 35 Step 300/351 lr 0.100000 loss 1.3895 (1.5217) acc@1 0.4766 (0.4378) acc@5 0.8203 (0.7881)\n",
      "\u001b[32m[2020-07-15 06:20:36] __main__ INFO: \u001b[0mEpoch 35 Step 351/351 lr 0.100000 loss 1.6285 (1.5245) acc@1 0.4219 (0.4373) acc@5 0.7422 (0.7875)\n",
      "\u001b[32m[2020-07-15 06:20:36] __main__ INFO: \u001b[0mElapsed 397.18\n",
      "\u001b[32m[2020-07-15 06:20:36] __main__ INFO: \u001b[0mVal 35\n",
      "\u001b[32m[2020-07-15 06:20:49] __main__ INFO: \u001b[0mEpoch 35 loss 0.8477 acc@1 0.7154 acc@5 0.9826\n",
      "\u001b[32m[2020-07-15 06:20:49] __main__ INFO: \u001b[0mElapsed 13.45\n",
      "\u001b[32m[2020-07-15 06:20:49] __main__ INFO: \u001b[0mTrain 36 12285\n",
      "\u001b[32m[2020-07-15 06:22:43] __main__ INFO: \u001b[0mEpoch 36 Step 100/351 lr 0.100000 loss 1.4105 (1.4983) acc@1 0.4766 (0.4448) acc@5 0.8281 (0.7899)\n",
      "\u001b[32m[2020-07-15 06:24:37] __main__ INFO: \u001b[0mEpoch 36 Step 200/351 lr 0.100000 loss 1.6399 (1.5125) acc@1 0.4141 (0.4411) acc@5 0.7891 (0.7883)\n",
      "\u001b[32m[2020-07-15 06:26:30] __main__ INFO: \u001b[0mEpoch 36 Step 300/351 lr 0.100000 loss 1.4878 (1.5173) acc@1 0.4453 (0.4394) acc@5 0.8203 (0.7863)\n",
      "\u001b[32m[2020-07-15 06:27:28] __main__ INFO: \u001b[0mEpoch 36 Step 351/351 lr 0.100000 loss 1.3412 (1.5195) acc@1 0.5312 (0.4380) acc@5 0.8281 (0.7863)\n",
      "\u001b[32m[2020-07-15 06:27:28] __main__ INFO: \u001b[0mElapsed 399.43\n",
      "\u001b[32m[2020-07-15 06:27:28] __main__ INFO: \u001b[0mVal 36\n",
      "\u001b[32m[2020-07-15 06:27:42] __main__ INFO: \u001b[0mEpoch 36 loss 0.7128 acc@1 0.7560 acc@5 0.9818\n",
      "\u001b[32m[2020-07-15 06:27:42] __main__ INFO: \u001b[0mElapsed 13.42\n",
      "\u001b[32m[2020-07-15 06:27:42] __main__ INFO: \u001b[0mTrain 37 12636\n",
      "\u001b[32m[2020-07-15 06:29:36] __main__ INFO: \u001b[0mEpoch 37 Step 100/351 lr 0.100000 loss 1.2744 (1.5015) acc@1 0.5078 (0.4471) acc@5 0.8281 (0.7809)\n",
      "\u001b[32m[2020-07-15 06:31:29] __main__ INFO: \u001b[0mEpoch 37 Step 200/351 lr 0.100000 loss 1.6280 (1.5070) acc@1 0.3672 (0.4441) acc@5 0.7578 (0.7823)\n",
      "\u001b[32m[2020-07-15 06:33:23] __main__ INFO: \u001b[0mEpoch 37 Step 300/351 lr 0.100000 loss 1.5827 (1.5140) acc@1 0.4297 (0.4401) acc@5 0.7266 (0.7833)\n",
      "\u001b[32m[2020-07-15 06:34:21] __main__ INFO: \u001b[0mEpoch 37 Step 351/351 lr 0.100000 loss 1.4665 (1.5176) acc@1 0.4766 (0.4391) acc@5 0.8047 (0.7838)\n",
      "\u001b[32m[2020-07-15 06:34:21] __main__ INFO: \u001b[0mElapsed 399.45\n",
      "\u001b[32m[2020-07-15 06:34:21] __main__ INFO: \u001b[0mVal 37\n",
      "\u001b[32m[2020-07-15 06:34:35] __main__ INFO: \u001b[0mEpoch 37 loss 0.7562 acc@1 0.7404 acc@5 0.9796\n",
      "\u001b[32m[2020-07-15 06:34:35] __main__ INFO: \u001b[0mElapsed 13.46\n",
      "\u001b[32m[2020-07-15 06:34:35] __main__ INFO: \u001b[0mTrain 38 12987\n",
      "\u001b[32m[2020-07-15 06:36:29] __main__ INFO: \u001b[0mEpoch 38 Step 100/351 lr 0.100000 loss 1.5413 (1.4964) acc@1 0.4219 (0.4426) acc@5 0.8047 (0.7882)\n",
      "\u001b[32m[2020-07-15 06:38:22] __main__ INFO: \u001b[0mEpoch 38 Step 200/351 lr 0.100000 loss 1.4964 (1.5069) acc@1 0.4297 (0.4418) acc@5 0.8203 (0.7915)\n",
      "\u001b[32m[2020-07-15 06:40:16] __main__ INFO: \u001b[0mEpoch 38 Step 300/351 lr 0.100000 loss 1.5858 (1.5107) acc@1 0.3672 (0.4409) acc@5 0.7969 (0.7923)\n",
      "\u001b[32m[2020-07-15 06:41:14] __main__ INFO: \u001b[0mEpoch 38 Step 351/351 lr 0.100000 loss 1.6705 (1.5115) acc@1 0.4062 (0.4406) acc@5 0.7266 (0.7908)\n",
      "\u001b[32m[2020-07-15 06:41:14] __main__ INFO: \u001b[0mElapsed 399.36\n",
      "\u001b[32m[2020-07-15 06:41:14] __main__ INFO: \u001b[0mVal 38\n",
      "\u001b[32m[2020-07-15 06:41:28] __main__ INFO: \u001b[0mEpoch 38 loss 0.6299 acc@1 0.7886 acc@5 0.9852\n",
      "\u001b[32m[2020-07-15 06:41:28] __main__ INFO: \u001b[0mElapsed 13.45\n",
      "\u001b[32m[2020-07-15 06:41:28] __main__ INFO: \u001b[0mTrain 39 13338\n",
      "\u001b[32m[2020-07-15 06:43:21] __main__ INFO: \u001b[0mEpoch 39 Step 100/351 lr 0.100000 loss 1.4451 (1.4916) acc@1 0.5078 (0.4488) acc@5 0.8359 (0.7884)\n",
      "\u001b[32m[2020-07-15 06:45:15] __main__ INFO: \u001b[0mEpoch 39 Step 200/351 lr 0.100000 loss 1.4894 (1.4999) acc@1 0.4531 (0.4432) acc@5 0.7969 (0.7877)\n",
      "\u001b[32m[2020-07-15 06:47:09] __main__ INFO: \u001b[0mEpoch 39 Step 300/351 lr 0.100000 loss 1.4854 (1.5072) acc@1 0.4219 (0.4409) acc@5 0.7656 (0.7876)\n",
      "\u001b[32m[2020-07-15 06:48:07] __main__ INFO: \u001b[0mEpoch 39 Step 351/351 lr 0.100000 loss 1.6267 (1.5105) acc@1 0.4375 (0.4404) acc@5 0.7812 (0.7873)\n",
      "\u001b[32m[2020-07-15 06:48:07] __main__ INFO: \u001b[0mElapsed 399.29\n",
      "\u001b[32m[2020-07-15 06:48:07] __main__ INFO: \u001b[0mVal 39\n",
      "\u001b[32m[2020-07-15 06:48:20] __main__ INFO: \u001b[0mEpoch 39 loss 0.7355 acc@1 0.7494 acc@5 0.9802\n",
      "\u001b[32m[2020-07-15 06:48:20] __main__ INFO: \u001b[0mElapsed 13.48\n",
      "\u001b[32m[2020-07-15 06:48:20] __main__ INFO: \u001b[0mTrain 40 13689\n",
      "\u001b[32m[2020-07-15 06:50:14] __main__ INFO: \u001b[0mEpoch 40 Step 100/351 lr 0.100000 loss 1.6824 (1.4942) acc@1 0.3672 (0.4466) acc@5 0.7891 (0.7932)\n",
      "\u001b[32m[2020-07-15 06:52:08] __main__ INFO: \u001b[0mEpoch 40 Step 200/351 lr 0.100000 loss 1.6555 (1.5033) acc@1 0.4219 (0.4449) acc@5 0.7812 (0.7941)\n",
      "\u001b[32m[2020-07-15 06:54:02] __main__ INFO: \u001b[0mEpoch 40 Step 300/351 lr 0.100000 loss 1.4636 (1.5049) acc@1 0.4766 (0.4435) acc@5 0.8438 (0.7931)\n",
      "\u001b[32m[2020-07-15 06:55:00] __main__ INFO: \u001b[0mEpoch 40 Step 351/351 lr 0.100000 loss 1.5173 (1.5058) acc@1 0.3984 (0.4434) acc@5 0.7656 (0.7917)\n",
      "\u001b[32m[2020-07-15 06:55:00] __main__ INFO: \u001b[0mElapsed 399.51\n",
      "\u001b[32m[2020-07-15 06:55:00] __main__ INFO: \u001b[0mVal 40\n",
      "\u001b[32m[2020-07-15 06:55:13] __main__ INFO: \u001b[0mEpoch 40 loss 0.6468 acc@1 0.7790 acc@5 0.9850\n",
      "\u001b[32m[2020-07-15 06:55:13] __main__ INFO: \u001b[0mElapsed 13.43\n",
      "\u001b[32m[2020-07-15 06:55:13] __main__ INFO: \u001b[0mTrain 41 14040\n",
      "\u001b[32m[2020-07-15 06:57:07] __main__ INFO: \u001b[0mEpoch 41 Step 100/351 lr 0.100000 loss 1.5096 (1.4780) acc@1 0.4141 (0.4501) acc@5 0.7344 (0.7905)\n",
      "\u001b[32m[2020-07-15 06:59:01] __main__ INFO: \u001b[0mEpoch 41 Step 200/351 lr 0.100000 loss 1.4133 (1.4927) acc@1 0.4922 (0.4451) acc@5 0.8281 (0.7889)\n",
      "\u001b[32m[2020-07-15 07:00:55] __main__ INFO: \u001b[0mEpoch 41 Step 300/351 lr 0.100000 loss 1.5459 (1.4991) acc@1 0.4766 (0.4452) acc@5 0.7969 (0.7891)\n",
      "\u001b[32m[2020-07-15 07:01:53] __main__ INFO: \u001b[0mEpoch 41 Step 351/351 lr 0.100000 loss 1.6199 (1.5019) acc@1 0.4141 (0.4449) acc@5 0.7578 (0.7889)\n",
      "\u001b[32m[2020-07-15 07:01:53] __main__ INFO: \u001b[0mElapsed 399.47\n",
      "\u001b[32m[2020-07-15 07:01:53] __main__ INFO: \u001b[0mVal 41\n",
      "\u001b[32m[2020-07-15 07:02:06] __main__ INFO: \u001b[0mEpoch 41 loss 0.7193 acc@1 0.7582 acc@5 0.9786\n",
      "\u001b[32m[2020-07-15 07:02:06] __main__ INFO: \u001b[0mElapsed 13.45\n",
      "\u001b[32m[2020-07-15 07:02:06] __main__ INFO: \u001b[0mTrain 42 14391\n",
      "\u001b[32m[2020-07-15 07:04:00] __main__ INFO: \u001b[0mEpoch 42 Step 100/351 lr 0.100000 loss 1.4623 (1.4857) acc@1 0.4922 (0.4513) acc@5 0.7734 (0.7888)\n",
      "\u001b[32m[2020-07-15 07:05:54] __main__ INFO: \u001b[0mEpoch 42 Step 200/351 lr 0.100000 loss 1.4261 (1.4907) acc@1 0.4688 (0.4483) acc@5 0.7969 (0.7872)\n",
      "\u001b[32m[2020-07-15 07:07:47] __main__ INFO: \u001b[0mEpoch 42 Step 300/351 lr 0.100000 loss 1.5363 (1.4939) acc@1 0.4453 (0.4453) acc@5 0.7656 (0.7891)\n",
      "\u001b[32m[2020-07-15 07:08:45] __main__ INFO: \u001b[0mEpoch 42 Step 351/351 lr 0.100000 loss 1.4848 (1.4981) acc@1 0.4297 (0.4438) acc@5 0.8359 (0.7889)\n",
      "\u001b[32m[2020-07-15 07:08:45] __main__ INFO: \u001b[0mElapsed 399.20\n",
      "\u001b[32m[2020-07-15 07:08:45] __main__ INFO: \u001b[0mVal 42\n",
      "\u001b[32m[2020-07-15 07:08:59] __main__ INFO: \u001b[0mEpoch 42 loss 0.7291 acc@1 0.7616 acc@5 0.9834\n",
      "\u001b[32m[2020-07-15 07:08:59] __main__ INFO: \u001b[0mElapsed 13.45\n",
      "\u001b[32m[2020-07-15 07:08:59] __main__ INFO: \u001b[0mTrain 43 14742\n",
      "\u001b[32m[2020-07-15 07:10:53] __main__ INFO: \u001b[0mEpoch 43 Step 100/351 lr 0.100000 loss 1.6022 (1.4797) acc@1 0.3984 (0.4488) acc@5 0.8125 (0.7906)\n",
      "\u001b[32m[2020-07-15 07:12:46] __main__ INFO: \u001b[0mEpoch 43 Step 200/351 lr 0.100000 loss 1.4184 (1.4950) acc@1 0.4766 (0.4451) acc@5 0.7734 (0.7926)\n",
      "\u001b[32m[2020-07-15 07:14:40] __main__ INFO: \u001b[0mEpoch 43 Step 300/351 lr 0.100000 loss 1.5580 (1.4961) acc@1 0.4141 (0.4448) acc@5 0.8281 (0.7918)\n",
      "\u001b[32m[2020-07-15 07:15:38] __main__ INFO: \u001b[0mEpoch 43 Step 351/351 lr 0.100000 loss 1.2820 (1.5001) acc@1 0.5625 (0.4447) acc@5 0.8125 (0.7909)\n",
      "\u001b[32m[2020-07-15 07:15:38] __main__ INFO: \u001b[0mElapsed 399.18\n",
      "\u001b[32m[2020-07-15 07:15:38] __main__ INFO: \u001b[0mVal 43\n",
      "\u001b[32m[2020-07-15 07:15:51] __main__ INFO: \u001b[0mEpoch 43 loss 0.6486 acc@1 0.7832 acc@5 0.9836\n",
      "\u001b[32m[2020-07-15 07:15:51] __main__ INFO: \u001b[0mElapsed 13.41\n",
      "\u001b[32m[2020-07-15 07:15:51] __main__ INFO: \u001b[0mTrain 44 15093\n",
      "\u001b[32m[2020-07-15 07:17:45] __main__ INFO: \u001b[0mEpoch 44 Step 100/351 lr 0.100000 loss 1.4978 (1.4498) acc@1 0.4688 (0.4631) acc@5 0.8047 (0.7959)\n",
      "\u001b[32m[2020-07-15 07:19:39] __main__ INFO: \u001b[0mEpoch 44 Step 200/351 lr 0.100000 loss 1.3422 (1.4750) acc@1 0.5000 (0.4575) acc@5 0.8281 (0.7911)\n",
      "\u001b[32m[2020-07-15 07:21:33] __main__ INFO: \u001b[0mEpoch 44 Step 300/351 lr 0.100000 loss 1.4716 (1.4873) acc@1 0.4219 (0.4511) acc@5 0.7891 (0.7902)\n",
      "\u001b[32m[2020-07-15 07:22:31] __main__ INFO: \u001b[0mEpoch 44 Step 351/351 lr 0.100000 loss 1.5034 (1.4901) acc@1 0.4766 (0.4491) acc@5 0.7578 (0.7897)\n",
      "\u001b[32m[2020-07-15 07:22:31] __main__ INFO: \u001b[0mElapsed 399.30\n",
      "\u001b[32m[2020-07-15 07:22:31] __main__ INFO: \u001b[0mVal 44\n",
      "\u001b[32m[2020-07-15 07:22:44] __main__ INFO: \u001b[0mEpoch 44 loss 0.6249 acc@1 0.7870 acc@5 0.9880\n",
      "\u001b[32m[2020-07-15 07:22:44] __main__ INFO: \u001b[0mElapsed 13.45\n",
      "\u001b[32m[2020-07-15 07:22:44] __main__ INFO: \u001b[0mTrain 45 15444\n",
      "\u001b[32m[2020-07-15 07:24:38] __main__ INFO: \u001b[0mEpoch 45 Step 100/351 lr 0.100000 loss 1.5558 (1.4750) acc@1 0.4297 (0.4548) acc@5 0.8125 (0.7914)\n",
      "\u001b[32m[2020-07-15 07:26:32] __main__ INFO: \u001b[0mEpoch 45 Step 200/351 lr 0.100000 loss 1.4763 (1.4834) acc@1 0.4609 (0.4533) acc@5 0.7500 (0.7923)\n",
      "\u001b[32m[2020-07-15 07:28:26] __main__ INFO: \u001b[0mEpoch 45 Step 300/351 lr 0.100000 loss 1.6677 (1.4861) acc@1 0.3594 (0.4507) acc@5 0.7656 (0.7899)\n",
      "\u001b[32m[2020-07-15 07:29:23] __main__ INFO: \u001b[0mEpoch 45 Step 351/351 lr 0.100000 loss 1.4367 (1.4938) acc@1 0.4688 (0.4474) acc@5 0.8203 (0.7893)\n",
      "\u001b[32m[2020-07-15 07:29:24] __main__ INFO: \u001b[0mElapsed 399.29\n",
      "\u001b[32m[2020-07-15 07:29:24] __main__ INFO: \u001b[0mVal 45\n",
      "\u001b[32m[2020-07-15 07:29:37] __main__ INFO: \u001b[0mEpoch 45 loss 0.7474 acc@1 0.7540 acc@5 0.9748\n",
      "\u001b[32m[2020-07-15 07:29:37] __main__ INFO: \u001b[0mElapsed 13.43\n",
      "\u001b[32m[2020-07-15 07:29:37] __main__ INFO: \u001b[0mTrain 46 15795\n",
      "\u001b[32m[2020-07-15 07:31:31] __main__ INFO: \u001b[0mEpoch 46 Step 100/351 lr 0.100000 loss 1.5797 (1.4717) acc@1 0.4062 (0.4541) acc@5 0.7422 (0.7933)\n",
      "\u001b[32m[2020-07-15 07:33:24] __main__ INFO: \u001b[0mEpoch 46 Step 200/351 lr 0.100000 loss 1.6251 (1.4767) acc@1 0.4688 (0.4549) acc@5 0.8203 (0.7936)\n",
      "\u001b[32m[2020-07-15 07:35:18] __main__ INFO: \u001b[0mEpoch 46 Step 300/351 lr 0.100000 loss 1.5154 (1.4802) acc@1 0.4688 (0.4531) acc@5 0.7344 (0.7937)\n",
      "\u001b[32m[2020-07-15 07:36:16] __main__ INFO: \u001b[0mEpoch 46 Step 351/351 lr 0.100000 loss 1.5791 (1.4841) acc@1 0.4062 (0.4518) acc@5 0.7656 (0.7923)\n",
      "\u001b[32m[2020-07-15 07:36:16] __main__ INFO: \u001b[0mElapsed 399.17\n",
      "\u001b[32m[2020-07-15 07:36:16] __main__ INFO: \u001b[0mVal 46\n",
      "\u001b[32m[2020-07-15 07:36:30] __main__ INFO: \u001b[0mEpoch 46 loss 0.6313 acc@1 0.7840 acc@5 0.9866\n",
      "\u001b[32m[2020-07-15 07:36:30] __main__ INFO: \u001b[0mElapsed 13.43\n",
      "\u001b[32m[2020-07-15 07:36:30] __main__ INFO: \u001b[0mTrain 47 16146\n",
      "\u001b[32m[2020-07-15 07:38:23] __main__ INFO: \u001b[0mEpoch 47 Step 100/351 lr 0.100000 loss 1.5129 (1.4663) acc@1 0.4531 (0.4630) acc@5 0.7578 (0.7946)\n",
      "\u001b[32m[2020-07-15 07:40:17] __main__ INFO: \u001b[0mEpoch 47 Step 200/351 lr 0.100000 loss 1.5691 (1.4789) acc@1 0.4062 (0.4549) acc@5 0.7500 (0.7930)\n",
      "\u001b[32m[2020-07-15 07:42:11] __main__ INFO: \u001b[0mEpoch 47 Step 300/351 lr 0.100000 loss 1.5289 (1.4863) acc@1 0.4531 (0.4506) acc@5 0.7578 (0.7926)\n",
      "\u001b[32m[2020-07-15 07:43:09] __main__ INFO: \u001b[0mEpoch 47 Step 351/351 lr 0.100000 loss 1.5439 (1.4872) acc@1 0.4219 (0.4502) acc@5 0.7891 (0.7925)\n",
      "\u001b[32m[2020-07-15 07:43:09] __main__ INFO: \u001b[0mElapsed 399.20\n",
      "\u001b[32m[2020-07-15 07:43:09] __main__ INFO: \u001b[0mVal 47\n",
      "\u001b[32m[2020-07-15 07:43:22] __main__ INFO: \u001b[0mEpoch 47 loss 0.6500 acc@1 0.7818 acc@5 0.9874\n",
      "\u001b[32m[2020-07-15 07:43:22] __main__ INFO: \u001b[0mElapsed 13.45\n",
      "\u001b[32m[2020-07-15 07:43:22] __main__ INFO: \u001b[0mTrain 48 16497\n",
      "\u001b[32m[2020-07-15 07:45:16] __main__ INFO: \u001b[0mEpoch 48 Step 100/351 lr 0.100000 loss 1.3608 (1.4591) acc@1 0.5156 (0.4551) acc@5 0.8359 (0.7942)\n",
      "\u001b[32m[2020-07-15 07:47:10] __main__ INFO: \u001b[0mEpoch 48 Step 200/351 lr 0.100000 loss 1.4448 (1.4727) acc@1 0.4922 (0.4527) acc@5 0.7734 (0.7914)\n",
      "\u001b[32m[2020-07-15 07:49:03] __main__ INFO: \u001b[0mEpoch 48 Step 300/351 lr 0.100000 loss 1.5483 (1.4808) acc@1 0.4453 (0.4508) acc@5 0.7422 (0.7916)\n",
      "\u001b[32m[2020-07-15 07:50:01] __main__ INFO: \u001b[0mEpoch 48 Step 351/351 lr 0.100000 loss 1.6546 (1.4836) acc@1 0.3672 (0.4500) acc@5 0.7031 (0.7909)\n",
      "\u001b[32m[2020-07-15 07:50:01] __main__ INFO: \u001b[0mElapsed 399.19\n",
      "\u001b[32m[2020-07-15 07:50:01] __main__ INFO: \u001b[0mVal 48\n",
      "\u001b[32m[2020-07-15 07:50:15] __main__ INFO: \u001b[0mEpoch 48 loss 0.6035 acc@1 0.7930 acc@5 0.9832\n",
      "\u001b[32m[2020-07-15 07:50:15] __main__ INFO: \u001b[0mElapsed 13.44\n",
      "\u001b[32m[2020-07-15 07:50:15] __main__ INFO: \u001b[0mTrain 49 16848\n",
      "\u001b[32m[2020-07-15 07:52:09] __main__ INFO: \u001b[0mEpoch 49 Step 100/351 lr 0.100000 loss 1.3855 (1.4557) acc@1 0.5234 (0.4591) acc@5 0.8438 (0.7912)\n",
      "\u001b[32m[2020-07-15 07:54:02] __main__ INFO: \u001b[0mEpoch 49 Step 200/351 lr 0.100000 loss 1.4435 (1.4683) acc@1 0.4922 (0.4555) acc@5 0.7734 (0.7927)\n",
      "\u001b[32m[2020-07-15 07:55:56] __main__ INFO: \u001b[0mEpoch 49 Step 300/351 lr 0.100000 loss 1.4606 (1.4770) acc@1 0.4297 (0.4520) acc@5 0.7891 (0.7923)\n",
      "\u001b[32m[2020-07-15 07:56:54] __main__ INFO: \u001b[0mEpoch 49 Step 351/351 lr 0.100000 loss 1.4287 (1.4808) acc@1 0.5000 (0.4515) acc@5 0.7812 (0.7916)\n",
      "\u001b[32m[2020-07-15 07:56:54] __main__ INFO: \u001b[0mElapsed 399.03\n",
      "\u001b[32m[2020-07-15 07:56:54] __main__ INFO: \u001b[0mVal 49\n",
      "\u001b[32m[2020-07-15 07:57:07] __main__ INFO: \u001b[0mEpoch 49 loss 0.9667 acc@1 0.7034 acc@5 0.9718\n",
      "\u001b[32m[2020-07-15 07:57:07] __main__ INFO: \u001b[0mElapsed 13.43\n",
      "\u001b[32m[2020-07-15 07:57:07] __main__ INFO: \u001b[0mTrain 50 17199\n",
      "\u001b[32m[2020-07-15 07:59:01] __main__ INFO: \u001b[0mEpoch 50 Step 100/351 lr 0.100000 loss 1.4034 (1.4656) acc@1 0.5000 (0.4590) acc@5 0.7812 (0.7930)\n",
      "\u001b[32m[2020-07-15 08:00:55] __main__ INFO: \u001b[0mEpoch 50 Step 200/351 lr 0.100000 loss 1.2355 (1.4772) acc@1 0.5547 (0.4544) acc@5 0.8750 (0.7920)\n",
      "\u001b[32m[2020-07-15 08:02:48] __main__ INFO: \u001b[0mEpoch 50 Step 300/351 lr 0.100000 loss 1.4759 (1.4806) acc@1 0.5000 (0.4533) acc@5 0.7734 (0.7916)\n",
      "\u001b[32m[2020-07-15 08:03:46] __main__ INFO: \u001b[0mEpoch 50 Step 351/351 lr 0.100000 loss 1.3712 (1.4852) acc@1 0.4844 (0.4512) acc@5 0.7734 (0.7900)\n",
      "\u001b[32m[2020-07-15 08:03:47] __main__ INFO: \u001b[0mElapsed 399.20\n",
      "\u001b[32m[2020-07-15 08:03:47] __main__ INFO: \u001b[0mVal 50\n",
      "\u001b[32m[2020-07-15 08:04:00] __main__ INFO: \u001b[0mEpoch 50 loss 0.8338 acc@1 0.7442 acc@5 0.9836\n",
      "\u001b[32m[2020-07-15 08:04:00] __main__ INFO: \u001b[0mElapsed 13.44\n",
      "\u001b[32m[2020-07-15 08:04:00] __main__ INFO: \u001b[0mTrain 51 17550\n",
      "\u001b[32m[2020-07-15 08:05:54] __main__ INFO: \u001b[0mEpoch 51 Step 100/351 lr 0.100000 loss 1.5750 (1.4337) acc@1 0.4062 (0.4672) acc@5 0.7734 (0.8029)\n",
      "\u001b[32m[2020-07-15 08:07:47] __main__ INFO: \u001b[0mEpoch 51 Step 200/351 lr 0.100000 loss 1.4334 (1.4569) acc@1 0.4609 (0.4595) acc@5 0.8047 (0.7966)\n",
      "\u001b[32m[2020-07-15 08:09:41] __main__ INFO: \u001b[0mEpoch 51 Step 300/351 lr 0.100000 loss 1.4352 (1.4731) acc@1 0.4688 (0.4517) acc@5 0.8359 (0.7917)\n",
      "\u001b[32m[2020-07-15 08:10:39] __main__ INFO: \u001b[0mEpoch 51 Step 351/351 lr 0.100000 loss 1.3040 (1.4776) acc@1 0.5312 (0.4496) acc@5 0.8594 (0.7910)\n",
      "\u001b[32m[2020-07-15 08:10:39] __main__ INFO: \u001b[0mElapsed 399.18\n",
      "\u001b[32m[2020-07-15 08:10:39] __main__ INFO: \u001b[0mVal 51\n",
      "\u001b[32m[2020-07-15 08:10:53] __main__ INFO: \u001b[0mEpoch 51 loss 0.7475 acc@1 0.7418 acc@5 0.9854\n",
      "\u001b[32m[2020-07-15 08:10:53] __main__ INFO: \u001b[0mElapsed 13.46\n",
      "\u001b[32m[2020-07-15 08:10:53] __main__ INFO: \u001b[0mTrain 52 17901\n",
      "\u001b[32m[2020-07-15 08:12:46] __main__ INFO: \u001b[0mEpoch 52 Step 100/351 lr 0.100000 loss 1.2809 (1.4615) acc@1 0.5312 (0.4612) acc@5 0.8125 (0.7970)\n",
      "\u001b[32m[2020-07-15 08:14:40] __main__ INFO: \u001b[0mEpoch 52 Step 200/351 lr 0.100000 loss 1.5154 (1.4649) acc@1 0.4609 (0.4579) acc@5 0.7891 (0.7963)\n",
      "\u001b[32m[2020-07-15 08:16:34] __main__ INFO: \u001b[0mEpoch 52 Step 300/351 lr 0.100000 loss 1.4817 (1.4737) acc@1 0.4766 (0.4565) acc@5 0.7578 (0.7930)\n",
      "\u001b[32m[2020-07-15 08:17:32] __main__ INFO: \u001b[0mEpoch 52 Step 351/351 lr 0.100000 loss 1.4765 (1.4775) acc@1 0.4453 (0.4555) acc@5 0.8047 (0.7916)\n",
      "\u001b[32m[2020-07-15 08:17:32] __main__ INFO: \u001b[0mElapsed 399.29\n",
      "\u001b[32m[2020-07-15 08:17:32] __main__ INFO: \u001b[0mVal 52\n",
      "\u001b[32m[2020-07-15 08:17:45] __main__ INFO: \u001b[0mEpoch 52 loss 0.6492 acc@1 0.7780 acc@5 0.9848\n",
      "\u001b[32m[2020-07-15 08:17:45] __main__ INFO: \u001b[0mElapsed 13.43\n",
      "\u001b[32m[2020-07-15 08:17:45] __main__ INFO: \u001b[0mTrain 53 18252\n",
      "\u001b[32m[2020-07-15 08:19:39] __main__ INFO: \u001b[0mEpoch 53 Step 100/351 lr 0.100000 loss 1.4489 (1.4324) acc@1 0.4453 (0.4726) acc@5 0.8672 (0.8003)\n",
      "\u001b[32m[2020-07-15 08:21:33] __main__ INFO: \u001b[0mEpoch 53 Step 200/351 lr 0.100000 loss 1.4148 (1.4577) acc@1 0.4844 (0.4617) acc@5 0.7656 (0.7920)\n",
      "\u001b[32m[2020-07-15 08:23:26] __main__ INFO: \u001b[0mEpoch 53 Step 300/351 lr 0.100000 loss 1.7037 (1.4684) acc@1 0.3203 (0.4579) acc@5 0.7969 (0.7918)\n",
      "\u001b[32m[2020-07-15 08:24:24] __main__ INFO: \u001b[0mEpoch 53 Step 351/351 lr 0.100000 loss 1.4245 (1.4738) acc@1 0.5156 (0.4557) acc@5 0.8281 (0.7914)\n",
      "\u001b[32m[2020-07-15 08:24:24] __main__ INFO: \u001b[0mElapsed 399.12\n",
      "\u001b[32m[2020-07-15 08:24:24] __main__ INFO: \u001b[0mVal 53\n",
      "\u001b[32m[2020-07-15 08:24:38] __main__ INFO: \u001b[0mEpoch 53 loss 0.6625 acc@1 0.7762 acc@5 0.9800\n",
      "\u001b[32m[2020-07-15 08:24:38] __main__ INFO: \u001b[0mElapsed 13.44\n",
      "\u001b[32m[2020-07-15 08:24:38] __main__ INFO: \u001b[0mTrain 54 18603\n",
      "\u001b[32m[2020-07-15 08:26:32] __main__ INFO: \u001b[0mEpoch 54 Step 100/351 lr 0.100000 loss 1.5460 (1.4378) acc@1 0.4141 (0.4655) acc@5 0.7500 (0.7936)\n",
      "\u001b[32m[2020-07-15 08:28:25] __main__ INFO: \u001b[0mEpoch 54 Step 200/351 lr 0.100000 loss 1.4569 (1.4579) acc@1 0.4844 (0.4596) acc@5 0.8125 (0.7952)\n",
      "\u001b[32m[2020-07-15 08:30:19] __main__ INFO: \u001b[0mEpoch 54 Step 300/351 lr 0.100000 loss 1.3463 (1.4668) acc@1 0.4766 (0.4553) acc@5 0.8281 (0.7939)\n",
      "\u001b[32m[2020-07-15 08:31:17] __main__ INFO: \u001b[0mEpoch 54 Step 351/351 lr 0.100000 loss 1.3639 (1.4730) acc@1 0.5312 (0.4534) acc@5 0.7656 (0.7920)\n",
      "\u001b[32m[2020-07-15 08:31:17] __main__ INFO: \u001b[0mElapsed 399.16\n",
      "\u001b[32m[2020-07-15 08:31:17] __main__ INFO: \u001b[0mVal 54\n",
      "\u001b[32m[2020-07-15 08:31:31] __main__ INFO: \u001b[0mEpoch 54 loss 0.5666 acc@1 0.8016 acc@5 0.9904\n",
      "\u001b[32m[2020-07-15 08:31:31] __main__ INFO: \u001b[0mElapsed 13.48\n",
      "\u001b[32m[2020-07-15 08:31:31] __main__ INFO: \u001b[0mTrain 55 18954\n",
      "\u001b[32m[2020-07-15 08:33:24] __main__ INFO: \u001b[0mEpoch 55 Step 100/351 lr 0.100000 loss 1.3801 (1.4657) acc@1 0.4531 (0.4627) acc@5 0.7891 (0.7978)\n",
      "\u001b[32m[2020-07-15 08:35:18] __main__ INFO: \u001b[0mEpoch 55 Step 200/351 lr 0.100000 loss 1.5065 (1.4653) acc@1 0.4219 (0.4596) acc@5 0.7812 (0.7958)\n",
      "\u001b[32m[2020-07-15 08:37:12] __main__ INFO: \u001b[0mEpoch 55 Step 300/351 lr 0.100000 loss 1.4622 (1.4682) acc@1 0.4688 (0.4584) acc@5 0.8047 (0.7941)\n",
      "\u001b[32m[2020-07-15 08:38:09] __main__ INFO: \u001b[0mEpoch 55 Step 351/351 lr 0.100000 loss 1.4788 (1.4709) acc@1 0.4297 (0.4582) acc@5 0.8281 (0.7936)\n",
      "\u001b[32m[2020-07-15 08:38:09] __main__ INFO: \u001b[0mElapsed 398.96\n",
      "\u001b[32m[2020-07-15 08:38:09] __main__ INFO: \u001b[0mVal 55\n",
      "\u001b[32m[2020-07-15 08:38:23] __main__ INFO: \u001b[0mEpoch 55 loss 0.8239 acc@1 0.7170 acc@5 0.9818\n",
      "\u001b[32m[2020-07-15 08:38:23] __main__ INFO: \u001b[0mElapsed 13.43\n",
      "\u001b[32m[2020-07-15 08:38:23] __main__ INFO: \u001b[0mTrain 56 19305\n",
      "\u001b[32m[2020-07-15 08:40:17] __main__ INFO: \u001b[0mEpoch 56 Step 100/351 lr 0.100000 loss 1.5572 (1.4499) acc@1 0.4531 (0.4652) acc@5 0.7656 (0.7961)\n",
      "\u001b[32m[2020-07-15 08:42:10] __main__ INFO: \u001b[0mEpoch 56 Step 200/351 lr 0.100000 loss 1.5402 (1.4561) acc@1 0.4297 (0.4635) acc@5 0.8281 (0.7962)\n",
      "\u001b[32m[2020-07-15 08:44:04] __main__ INFO: \u001b[0mEpoch 56 Step 300/351 lr 0.100000 loss 1.5087 (1.4688) acc@1 0.4141 (0.4570) acc@5 0.8203 (0.7949)\n",
      "\u001b[32m[2020-07-15 08:45:02] __main__ INFO: \u001b[0mEpoch 56 Step 351/351 lr 0.100000 loss 1.2806 (1.4709) acc@1 0.5625 (0.4564) acc@5 0.7969 (0.7934)\n",
      "\u001b[32m[2020-07-15 08:45:02] __main__ INFO: \u001b[0mElapsed 399.06\n",
      "\u001b[32m[2020-07-15 08:45:02] __main__ INFO: \u001b[0mVal 56\n",
      "\u001b[32m[2020-07-15 08:45:15] __main__ INFO: \u001b[0mEpoch 56 loss 0.7406 acc@1 0.7442 acc@5 0.9826\n",
      "\u001b[32m[2020-07-15 08:45:15] __main__ INFO: \u001b[0mElapsed 13.44\n",
      "\u001b[32m[2020-07-15 08:45:15] __main__ INFO: \u001b[0mTrain 57 19656\n",
      "\u001b[32m[2020-07-15 08:47:09] __main__ INFO: \u001b[0mEpoch 57 Step 100/351 lr 0.100000 loss 1.4544 (1.4496) acc@1 0.5078 (0.4617) acc@5 0.7812 (0.7920)\n",
      "\u001b[32m[2020-07-15 08:49:03] __main__ INFO: \u001b[0mEpoch 57 Step 200/351 lr 0.100000 loss 1.4824 (1.4709) acc@1 0.4844 (0.4534) acc@5 0.8203 (0.7908)\n",
      "\u001b[32m[2020-07-15 08:50:56] __main__ INFO: \u001b[0mEpoch 57 Step 300/351 lr 0.100000 loss 1.4490 (1.4723) acc@1 0.4453 (0.4532) acc@5 0.8203 (0.7913)\n",
      "\u001b[32m[2020-07-15 08:51:54] __main__ INFO: \u001b[0mEpoch 57 Step 351/351 lr 0.100000 loss 1.3865 (1.4758) acc@1 0.4609 (0.4509) acc@5 0.8516 (0.7907)\n",
      "\u001b[32m[2020-07-15 08:51:54] __main__ INFO: \u001b[0mElapsed 398.89\n",
      "\u001b[32m[2020-07-15 08:51:54] __main__ INFO: \u001b[0mVal 57\n",
      "\u001b[32m[2020-07-15 08:52:08] __main__ INFO: \u001b[0mEpoch 57 loss 0.6454 acc@1 0.7844 acc@5 0.9840\n",
      "\u001b[32m[2020-07-15 08:52:08] __main__ INFO: \u001b[0mElapsed 13.44\n",
      "\u001b[32m[2020-07-15 08:52:08] __main__ INFO: \u001b[0mTrain 58 20007\n",
      "\u001b[32m[2020-07-15 08:54:02] __main__ INFO: \u001b[0mEpoch 58 Step 100/351 lr 0.100000 loss 1.2732 (1.4220) acc@1 0.5312 (0.4740) acc@5 0.8359 (0.7964)\n",
      "\u001b[32m[2020-07-15 08:55:55] __main__ INFO: \u001b[0mEpoch 58 Step 200/351 lr 0.100000 loss 1.4646 (1.4435) acc@1 0.4219 (0.4634) acc@5 0.7812 (0.7962)\n",
      "\u001b[32m[2020-07-15 08:57:49] __main__ INFO: \u001b[0mEpoch 58 Step 300/351 lr 0.100000 loss 1.3259 (1.4599) acc@1 0.5000 (0.4596) acc@5 0.8672 (0.7940)\n",
      "\u001b[32m[2020-07-15 08:58:47] __main__ INFO: \u001b[0mEpoch 58 Step 351/351 lr 0.100000 loss 1.4104 (1.4678) acc@1 0.4688 (0.4555) acc@5 0.7812 (0.7926)\n",
      "\u001b[32m[2020-07-15 08:58:47] __main__ INFO: \u001b[0mElapsed 399.07\n",
      "\u001b[32m[2020-07-15 08:58:47] __main__ INFO: \u001b[0mVal 58\n",
      "\u001b[32m[2020-07-15 08:59:00] __main__ INFO: \u001b[0mEpoch 58 loss 0.9058 acc@1 0.7068 acc@5 0.9766\n",
      "\u001b[32m[2020-07-15 08:59:00] __main__ INFO: \u001b[0mElapsed 13.40\n",
      "\u001b[32m[2020-07-15 08:59:00] __main__ INFO: \u001b[0mTrain 59 20358\n",
      "\u001b[32m[2020-07-15 09:00:54] __main__ INFO: \u001b[0mEpoch 59 Step 100/351 lr 0.100000 loss 1.4476 (1.4438) acc@1 0.4531 (0.4656) acc@5 0.7891 (0.7971)\n",
      "\u001b[32m[2020-07-15 09:02:48] __main__ INFO: \u001b[0mEpoch 59 Step 200/351 lr 0.100000 loss 1.5483 (1.4556) acc@1 0.3984 (0.4618) acc@5 0.7812 (0.7955)\n",
      "\u001b[32m[2020-07-15 09:04:41] __main__ INFO: \u001b[0mEpoch 59 Step 300/351 lr 0.100000 loss 1.6049 (1.4593) acc@1 0.4062 (0.4603) acc@5 0.7891 (0.7950)\n",
      "\u001b[32m[2020-07-15 09:05:39] __main__ INFO: \u001b[0mEpoch 59 Step 351/351 lr 0.100000 loss 1.4576 (1.4660) acc@1 0.4297 (0.4579) acc@5 0.7422 (0.7935)\n",
      "\u001b[32m[2020-07-15 09:05:39] __main__ INFO: \u001b[0mElapsed 399.09\n",
      "\u001b[32m[2020-07-15 09:05:39] __main__ INFO: \u001b[0mVal 59\n",
      "\u001b[32m[2020-07-15 09:05:53] __main__ INFO: \u001b[0mEpoch 59 loss 0.5664 acc@1 0.8102 acc@5 0.9862\n",
      "\u001b[32m[2020-07-15 09:05:53] __main__ INFO: \u001b[0mElapsed 13.43\n",
      "\u001b[32m[2020-07-15 09:05:53] __main__ INFO: \u001b[0mTrain 60 20709\n",
      "\u001b[32m[2020-07-15 09:07:47] __main__ INFO: \u001b[0mEpoch 60 Step 100/351 lr 0.100000 loss 1.4449 (1.4512) acc@1 0.4297 (0.4616) acc@5 0.7969 (0.7997)\n",
      "\u001b[32m[2020-07-15 09:09:40] __main__ INFO: \u001b[0mEpoch 60 Step 200/351 lr 0.100000 loss 1.4399 (1.4530) acc@1 0.4219 (0.4605) acc@5 0.7891 (0.7970)\n",
      "\u001b[32m[2020-07-15 09:11:34] __main__ INFO: \u001b[0mEpoch 60 Step 300/351 lr 0.100000 loss 1.6139 (1.4615) acc@1 0.4062 (0.4575) acc@5 0.7891 (0.7963)\n",
      "\u001b[32m[2020-07-15 09:12:32] __main__ INFO: \u001b[0mEpoch 60 Step 351/351 lr 0.100000 loss 1.5242 (1.4647) acc@1 0.3906 (0.4557) acc@5 0.7891 (0.7946)\n",
      "\u001b[32m[2020-07-15 09:12:32] __main__ INFO: \u001b[0mElapsed 399.02\n",
      "\u001b[32m[2020-07-15 09:12:32] __main__ INFO: \u001b[0mVal 60\n",
      "\u001b[32m[2020-07-15 09:12:45] __main__ INFO: \u001b[0mEpoch 60 loss 0.7036 acc@1 0.7678 acc@5 0.9826\n",
      "\u001b[32m[2020-07-15 09:12:45] __main__ INFO: \u001b[0mElapsed 13.43\n",
      "\u001b[32m[2020-07-15 09:12:45] __main__ INFO: \u001b[0mTrain 61 21060\n",
      "\u001b[32m[2020-07-15 09:14:39] __main__ INFO: \u001b[0mEpoch 61 Step 100/351 lr 0.020000 loss 1.1669 (1.3160) acc@1 0.5547 (0.5131) acc@5 0.8594 (0.8053)\n",
      "\u001b[32m[2020-07-15 09:16:33] __main__ INFO: \u001b[0mEpoch 61 Step 200/351 lr 0.020000 loss 1.2373 (1.2961) acc@1 0.5078 (0.5188) acc@5 0.7969 (0.8051)\n",
      "\u001b[32m[2020-07-15 09:18:26] __main__ INFO: \u001b[0mEpoch 61 Step 300/351 lr 0.020000 loss 1.1843 (1.2795) acc@1 0.5781 (0.5228) acc@5 0.8047 (0.8074)\n",
      "\u001b[32m[2020-07-15 09:19:24] __main__ INFO: \u001b[0mEpoch 61 Step 351/351 lr 0.020000 loss 1.3550 (1.2731) acc@1 0.5391 (0.5252) acc@5 0.8281 (0.8082)\n",
      "\u001b[32m[2020-07-15 09:19:24] __main__ INFO: \u001b[0mElapsed 398.92\n",
      "\u001b[32m[2020-07-15 09:19:24] __main__ INFO: \u001b[0mVal 61\n",
      "\u001b[32m[2020-07-15 09:19:38] __main__ INFO: \u001b[0mEpoch 61 loss 0.3726 acc@1 0.8762 acc@5 0.9944\n",
      "\u001b[32m[2020-07-15 09:19:38] __main__ INFO: \u001b[0mElapsed 13.44\n",
      "\u001b[32m[2020-07-15 09:19:38] __main__ INFO: \u001b[0mTrain 62 21411\n",
      "\u001b[32m[2020-07-15 09:21:31] __main__ INFO: \u001b[0mEpoch 62 Step 100/351 lr 0.020000 loss 1.1044 (1.1957) acc@1 0.5859 (0.5548) acc@5 0.7891 (0.8139)\n",
      "\u001b[32m[2020-07-15 09:23:25] __main__ INFO: \u001b[0mEpoch 62 Step 200/351 lr 0.020000 loss 1.1708 (1.1983) acc@1 0.5625 (0.5527) acc@5 0.8281 (0.8120)\n",
      "\u001b[32m[2020-07-15 09:25:19] __main__ INFO: \u001b[0mEpoch 62 Step 300/351 lr 0.020000 loss 1.3501 (1.1998) acc@1 0.5000 (0.5510) acc@5 0.7656 (0.8137)\n",
      "\u001b[32m[2020-07-15 09:26:17] __main__ INFO: \u001b[0mEpoch 62 Step 351/351 lr 0.020000 loss 1.2859 (1.2010) acc@1 0.5156 (0.5501) acc@5 0.7734 (0.8127)\n",
      "\u001b[32m[2020-07-15 09:26:17] __main__ INFO: \u001b[0mElapsed 399.01\n",
      "\u001b[32m[2020-07-15 09:26:17] __main__ INFO: \u001b[0mVal 62\n",
      "\u001b[32m[2020-07-15 09:26:30] __main__ INFO: \u001b[0mEpoch 62 loss 0.3467 acc@1 0.8838 acc@5 0.9958\n",
      "\u001b[32m[2020-07-15 09:26:30] __main__ INFO: \u001b[0mElapsed 13.43\n",
      "\u001b[32m[2020-07-15 09:26:30] __main__ INFO: \u001b[0mTrain 63 21762\n",
      "\u001b[32m[2020-07-15 09:28:24] __main__ INFO: \u001b[0mEpoch 63 Step 100/351 lr 0.020000 loss 1.2992 (1.1582) acc@1 0.4922 (0.5670) acc@5 0.7656 (0.8157)\n",
      "\u001b[32m[2020-07-15 09:30:17] __main__ INFO: \u001b[0mEpoch 63 Step 200/351 lr 0.020000 loss 1.0131 (1.1571) acc@1 0.6328 (0.5670) acc@5 0.7969 (0.8163)\n",
      "\u001b[32m[2020-07-15 09:32:11] __main__ INFO: \u001b[0mEpoch 63 Step 300/351 lr 0.020000 loss 1.2397 (1.1675) acc@1 0.5938 (0.5634) acc@5 0.8125 (0.8149)\n",
      "\u001b[32m[2020-07-15 09:33:09] __main__ INFO: \u001b[0mEpoch 63 Step 351/351 lr 0.020000 loss 1.1773 (1.1705) acc@1 0.5234 (0.5617) acc@5 0.7969 (0.8139)\n",
      "\u001b[32m[2020-07-15 09:33:09] __main__ INFO: \u001b[0mElapsed 399.10\n",
      "\u001b[32m[2020-07-15 09:33:09] __main__ INFO: \u001b[0mVal 63\n",
      "\u001b[32m[2020-07-15 09:33:23] __main__ INFO: \u001b[0mEpoch 63 loss 0.4128 acc@1 0.8694 acc@5 0.9950\n",
      "\u001b[32m[2020-07-15 09:33:23] __main__ INFO: \u001b[0mElapsed 13.46\n",
      "\u001b[32m[2020-07-15 09:33:23] __main__ INFO: \u001b[0mTrain 64 22113\n",
      "\u001b[32m[2020-07-15 09:35:16] __main__ INFO: \u001b[0mEpoch 64 Step 100/351 lr 0.020000 loss 1.1832 (1.1383) acc@1 0.5156 (0.5688) acc@5 0.8203 (0.8170)\n",
      "\u001b[32m[2020-07-15 09:37:10] __main__ INFO: \u001b[0mEpoch 64 Step 200/351 lr 0.020000 loss 1.3121 (1.1464) acc@1 0.5078 (0.5684) acc@5 0.8047 (0.8165)\n",
      "\u001b[32m[2020-07-15 09:39:03] __main__ INFO: \u001b[0mEpoch 64 Step 300/351 lr 0.020000 loss 1.0011 (1.1557) acc@1 0.6172 (0.5652) acc@5 0.8672 (0.8152)\n",
      "\u001b[32m[2020-07-15 09:40:01] __main__ INFO: \u001b[0mEpoch 64 Step 351/351 lr 0.020000 loss 1.3244 (1.1572) acc@1 0.4844 (0.5643) acc@5 0.7969 (0.8158)\n",
      "\u001b[32m[2020-07-15 09:40:01] __main__ INFO: \u001b[0mElapsed 398.90\n",
      "\u001b[32m[2020-07-15 09:40:01] __main__ INFO: \u001b[0mVal 64\n",
      "\u001b[32m[2020-07-15 09:40:15] __main__ INFO: \u001b[0mEpoch 64 loss 0.4233 acc@1 0.8664 acc@5 0.9942\n",
      "\u001b[32m[2020-07-15 09:40:15] __main__ INFO: \u001b[0mElapsed 13.43\n",
      "\u001b[32m[2020-07-15 09:40:15] __main__ INFO: \u001b[0mTrain 65 22464\n",
      "\u001b[32m[2020-07-15 09:42:09] __main__ INFO: \u001b[0mEpoch 65 Step 100/351 lr 0.020000 loss 1.1639 (1.1356) acc@1 0.5469 (0.5721) acc@5 0.7656 (0.8130)\n",
      "\u001b[32m[2020-07-15 09:44:02] __main__ INFO: \u001b[0mEpoch 65 Step 200/351 lr 0.020000 loss 1.0972 (1.1413) acc@1 0.5938 (0.5706) acc@5 0.8516 (0.8131)\n",
      "\u001b[32m[2020-07-15 09:45:56] __main__ INFO: \u001b[0mEpoch 65 Step 300/351 lr 0.020000 loss 0.9773 (1.1373) acc@1 0.6250 (0.5721) acc@5 0.7969 (0.8149)\n",
      "\u001b[32m[2020-07-15 09:46:54] __main__ INFO: \u001b[0mEpoch 65 Step 351/351 lr 0.020000 loss 1.1778 (1.1364) acc@1 0.5469 (0.5727) acc@5 0.8203 (0.8155)\n",
      "\u001b[32m[2020-07-15 09:46:54] __main__ INFO: \u001b[0mElapsed 398.84\n",
      "\u001b[32m[2020-07-15 09:46:54] __main__ INFO: \u001b[0mVal 65\n",
      "\u001b[32m[2020-07-15 09:47:07] __main__ INFO: \u001b[0mEpoch 65 loss 0.3859 acc@1 0.8816 acc@5 0.9946\n",
      "\u001b[32m[2020-07-15 09:47:07] __main__ INFO: \u001b[0mElapsed 13.44\n",
      "\u001b[32m[2020-07-15 09:47:07] __main__ INFO: \u001b[0mTrain 66 22815\n",
      "\u001b[32m[2020-07-15 09:49:01] __main__ INFO: \u001b[0mEpoch 66 Step 100/351 lr 0.020000 loss 1.0767 (1.1036) acc@1 0.5625 (0.5802) acc@5 0.8047 (0.8220)\n",
      "\u001b[32m[2020-07-15 09:50:55] __main__ INFO: \u001b[0mEpoch 66 Step 200/351 lr 0.020000 loss 1.2569 (1.1160) acc@1 0.5234 (0.5769) acc@5 0.8047 (0.8197)\n",
      "\u001b[32m[2020-07-15 09:52:48] __main__ INFO: \u001b[0mEpoch 66 Step 300/351 lr 0.020000 loss 1.1184 (1.1201) acc@1 0.5625 (0.5746) acc@5 0.8438 (0.8198)\n",
      "\u001b[32m[2020-07-15 09:53:46] __main__ INFO: \u001b[0mEpoch 66 Step 351/351 lr 0.020000 loss 1.0456 (1.1269) acc@1 0.6172 (0.5722) acc@5 0.8203 (0.8190)\n",
      "\u001b[32m[2020-07-15 09:53:46] __main__ INFO: \u001b[0mElapsed 398.88\n",
      "\u001b[32m[2020-07-15 09:53:46] __main__ INFO: \u001b[0mVal 66\n",
      "\u001b[32m[2020-07-15 09:53:59] __main__ INFO: \u001b[0mEpoch 66 loss 0.4193 acc@1 0.8676 acc@5 0.9952\n",
      "\u001b[32m[2020-07-15 09:53:59] __main__ INFO: \u001b[0mElapsed 13.42\n",
      "\u001b[32m[2020-07-15 09:53:59] __main__ INFO: \u001b[0mTrain 67 23166\n",
      "\u001b[32m[2020-07-15 09:55:53] __main__ INFO: \u001b[0mEpoch 67 Step 100/351 lr 0.020000 loss 1.3349 (1.1043) acc@1 0.4844 (0.5833) acc@5 0.7188 (0.8137)\n",
      "\u001b[32m[2020-07-15 09:57:47] __main__ INFO: \u001b[0mEpoch 67 Step 200/351 lr 0.020000 loss 1.0825 (1.1098) acc@1 0.5781 (0.5830) acc@5 0.7969 (0.8141)\n",
      "\u001b[32m[2020-07-15 09:59:40] __main__ INFO: \u001b[0mEpoch 67 Step 300/351 lr 0.020000 loss 1.0870 (1.1113) acc@1 0.5781 (0.5812) acc@5 0.8359 (0.8174)\n",
      "\u001b[32m[2020-07-15 10:00:38] __main__ INFO: \u001b[0mEpoch 67 Step 351/351 lr 0.020000 loss 1.1136 (1.1173) acc@1 0.5625 (0.5787) acc@5 0.8359 (0.8175)\n",
      "\u001b[32m[2020-07-15 10:00:38] __main__ INFO: \u001b[0mElapsed 398.89\n",
      "\u001b[32m[2020-07-15 10:00:38] __main__ INFO: \u001b[0mVal 67\n",
      "\u001b[32m[2020-07-15 10:00:52] __main__ INFO: \u001b[0mEpoch 67 loss 0.3981 acc@1 0.8766 acc@5 0.9944\n",
      "\u001b[32m[2020-07-15 10:00:52] __main__ INFO: \u001b[0mElapsed 13.44\n",
      "\u001b[32m[2020-07-15 10:00:52] __main__ INFO: \u001b[0mTrain 68 23517\n",
      "\u001b[32m[2020-07-15 10:02:46] __main__ INFO: \u001b[0mEpoch 68 Step 100/351 lr 0.020000 loss 1.2484 (1.1162) acc@1 0.5078 (0.5780) acc@5 0.7969 (0.8209)\n",
      "\u001b[32m[2020-07-15 10:04:39] __main__ INFO: \u001b[0mEpoch 68 Step 200/351 lr 0.020000 loss 0.9051 (1.1088) acc@1 0.6953 (0.5818) acc@5 0.8750 (0.8187)\n",
      "\u001b[32m[2020-07-15 10:06:33] __main__ INFO: \u001b[0mEpoch 68 Step 300/351 lr 0.020000 loss 1.0858 (1.1127) acc@1 0.6328 (0.5801) acc@5 0.8750 (0.8183)\n",
      "\u001b[32m[2020-07-15 10:07:31] __main__ INFO: \u001b[0mEpoch 68 Step 351/351 lr 0.020000 loss 1.2118 (1.1107) acc@1 0.5312 (0.5803) acc@5 0.7812 (0.8185)\n",
      "\u001b[32m[2020-07-15 10:07:31] __main__ INFO: \u001b[0mElapsed 398.83\n",
      "\u001b[32m[2020-07-15 10:07:31] __main__ INFO: \u001b[0mVal 68\n",
      "\u001b[32m[2020-07-15 10:07:44] __main__ INFO: \u001b[0mEpoch 68 loss 0.4120 acc@1 0.8750 acc@5 0.9934\n",
      "\u001b[32m[2020-07-15 10:07:44] __main__ INFO: \u001b[0mElapsed 13.44\n",
      "\u001b[32m[2020-07-15 10:07:44] __main__ INFO: \u001b[0mTrain 69 23868\n",
      "\u001b[32m[2020-07-15 10:09:38] __main__ INFO: \u001b[0mEpoch 69 Step 100/351 lr 0.020000 loss 1.0958 (1.0737) acc@1 0.5547 (0.5931) acc@5 0.8203 (0.8281)\n",
      "\u001b[32m[2020-07-15 10:11:31] __main__ INFO: \u001b[0mEpoch 69 Step 200/351 lr 0.020000 loss 1.1029 (1.0950) acc@1 0.6094 (0.5849) acc@5 0.8438 (0.8200)\n",
      "\u001b[32m[2020-07-15 10:13:25] __main__ INFO: \u001b[0mEpoch 69 Step 300/351 lr 0.020000 loss 1.1737 (1.1041) acc@1 0.5391 (0.5811) acc@5 0.8281 (0.8172)\n",
      "\u001b[32m[2020-07-15 10:14:23] __main__ INFO: \u001b[0mEpoch 69 Step 351/351 lr 0.020000 loss 1.4281 (1.1061) acc@1 0.4922 (0.5812) acc@5 0.8125 (0.8176)\n",
      "\u001b[32m[2020-07-15 10:14:23] __main__ INFO: \u001b[0mElapsed 398.80\n",
      "\u001b[32m[2020-07-15 10:14:23] __main__ INFO: \u001b[0mVal 69\n",
      "\u001b[32m[2020-07-15 10:14:36] __main__ INFO: \u001b[0mEpoch 69 loss 0.3815 acc@1 0.8812 acc@5 0.9942\n",
      "\u001b[32m[2020-07-15 10:14:36] __main__ INFO: \u001b[0mElapsed 13.42\n",
      "\u001b[32m[2020-07-15 10:14:36] __main__ INFO: \u001b[0mTrain 70 24219\n",
      "\u001b[32m[2020-07-15 10:16:30] __main__ INFO: \u001b[0mEpoch 70 Step 100/351 lr 0.020000 loss 0.9158 (1.0699) acc@1 0.6641 (0.5955) acc@5 0.8047 (0.8229)\n",
      "\u001b[32m[2020-07-15 10:18:24] __main__ INFO: \u001b[0mEpoch 70 Step 200/351 lr 0.020000 loss 1.1983 (1.0842) acc@1 0.5547 (0.5892) acc@5 0.7422 (0.8195)\n",
      "\u001b[32m[2020-07-15 10:20:17] __main__ INFO: \u001b[0mEpoch 70 Step 300/351 lr 0.020000 loss 1.3655 (1.0946) acc@1 0.4531 (0.5859) acc@5 0.7891 (0.8193)\n",
      "\u001b[32m[2020-07-15 10:21:15] __main__ INFO: \u001b[0mEpoch 70 Step 351/351 lr 0.020000 loss 0.7705 (1.0974) acc@1 0.7188 (0.5857) acc@5 0.8828 (0.8197)\n",
      "\u001b[32m[2020-07-15 10:21:15] __main__ INFO: \u001b[0mElapsed 398.82\n",
      "\u001b[32m[2020-07-15 10:21:15] __main__ INFO: \u001b[0mVal 70\n",
      "\u001b[32m[2020-07-15 10:21:29] __main__ INFO: \u001b[0mEpoch 70 loss 0.3951 acc@1 0.8766 acc@5 0.9958\n",
      "\u001b[32m[2020-07-15 10:21:29] __main__ INFO: \u001b[0mElapsed 13.44\n",
      "\u001b[32m[2020-07-15 10:21:29] __main__ INFO: \u001b[0mTrain 71 24570\n",
      "\u001b[32m[2020-07-15 10:23:22] __main__ INFO: \u001b[0mEpoch 71 Step 100/351 lr 0.020000 loss 1.1281 (1.0769) acc@1 0.5859 (0.5941) acc@5 0.8828 (0.8196)\n",
      "\u001b[32m[2020-07-15 10:25:16] __main__ INFO: \u001b[0mEpoch 71 Step 200/351 lr 0.020000 loss 1.1440 (1.0789) acc@1 0.5547 (0.5935) acc@5 0.7734 (0.8191)\n",
      "\u001b[32m[2020-07-15 10:27:10] __main__ INFO: \u001b[0mEpoch 71 Step 300/351 lr 0.020000 loss 1.1346 (1.0906) acc@1 0.6250 (0.5886) acc@5 0.8516 (0.8172)\n",
      "\u001b[32m[2020-07-15 10:28:07] __main__ INFO: \u001b[0mEpoch 71 Step 351/351 lr 0.020000 loss 1.2727 (1.0915) acc@1 0.5469 (0.5887) acc@5 0.7969 (0.8182)\n",
      "\u001b[32m[2020-07-15 10:28:07] __main__ INFO: \u001b[0mElapsed 398.88\n",
      "\u001b[32m[2020-07-15 10:28:07] __main__ INFO: \u001b[0mVal 71\n",
      "\u001b[32m[2020-07-15 10:28:21] __main__ INFO: \u001b[0mEpoch 71 loss 0.4252 acc@1 0.8750 acc@5 0.9930\n",
      "\u001b[32m[2020-07-15 10:28:21] __main__ INFO: \u001b[0mElapsed 13.42\n",
      "\u001b[32m[2020-07-15 10:28:21] __main__ INFO: \u001b[0mTrain 72 24921\n",
      "\u001b[32m[2020-07-15 10:30:15] __main__ INFO: \u001b[0mEpoch 72 Step 100/351 lr 0.020000 loss 1.1262 (1.0694) acc@1 0.6094 (0.5962) acc@5 0.7969 (0.8195)\n",
      "\u001b[32m[2020-07-15 10:32:08] __main__ INFO: \u001b[0mEpoch 72 Step 200/351 lr 0.020000 loss 1.2502 (1.0793) acc@1 0.5391 (0.5903) acc@5 0.8047 (0.8173)\n",
      "\u001b[32m[2020-07-15 10:34:02] __main__ INFO: \u001b[0mEpoch 72 Step 300/351 lr 0.020000 loss 1.2127 (1.0837) acc@1 0.5391 (0.5893) acc@5 0.8203 (0.8166)\n",
      "\u001b[32m[2020-07-15 10:35:00] __main__ INFO: \u001b[0mEpoch 72 Step 351/351 lr 0.020000 loss 1.2442 (1.0832) acc@1 0.5391 (0.5896) acc@5 0.8203 (0.8173)\n",
      "\u001b[32m[2020-07-15 10:35:00] __main__ INFO: \u001b[0mElapsed 398.91\n",
      "\u001b[32m[2020-07-15 10:35:00] __main__ INFO: \u001b[0mVal 72\n",
      "\u001b[32m[2020-07-15 10:35:13] __main__ INFO: \u001b[0mEpoch 72 loss 0.4352 acc@1 0.8666 acc@5 0.9948\n",
      "\u001b[32m[2020-07-15 10:35:13] __main__ INFO: \u001b[0mElapsed 13.46\n",
      "\u001b[32m[2020-07-15 10:35:13] __main__ INFO: \u001b[0mTrain 73 25272\n",
      "\u001b[32m[2020-07-15 10:37:07] __main__ INFO: \u001b[0mEpoch 73 Step 100/351 lr 0.020000 loss 1.1682 (1.0689) acc@1 0.5234 (0.5941) acc@5 0.7578 (0.8215)\n",
      "\u001b[32m[2020-07-15 10:39:01] __main__ INFO: \u001b[0mEpoch 73 Step 200/351 lr 0.020000 loss 1.0266 (1.0766) acc@1 0.6484 (0.5901) acc@5 0.8906 (0.8195)\n",
      "\u001b[32m[2020-07-15 10:40:54] __main__ INFO: \u001b[0mEpoch 73 Step 300/351 lr 0.020000 loss 1.0416 (1.0893) acc@1 0.5469 (0.5860) acc@5 0.7578 (0.8197)\n",
      "\u001b[32m[2020-07-15 10:41:52] __main__ INFO: \u001b[0mEpoch 73 Step 351/351 lr 0.020000 loss 1.2688 (1.0876) acc@1 0.5625 (0.5866) acc@5 0.8203 (0.8192)\n",
      "\u001b[32m[2020-07-15 10:41:52] __main__ INFO: \u001b[0mElapsed 399.16\n",
      "\u001b[32m[2020-07-15 10:41:52] __main__ INFO: \u001b[0mVal 73\n",
      "\u001b[32m[2020-07-15 10:42:06] __main__ INFO: \u001b[0mEpoch 73 loss 0.3785 acc@1 0.8832 acc@5 0.9948\n",
      "\u001b[32m[2020-07-15 10:42:06] __main__ INFO: \u001b[0mElapsed 13.44\n",
      "\u001b[32m[2020-07-15 10:42:06] __main__ INFO: \u001b[0mTrain 74 25623\n",
      "\u001b[32m[2020-07-15 10:44:00] __main__ INFO: \u001b[0mEpoch 74 Step 100/351 lr 0.020000 loss 1.1337 (1.0555) acc@1 0.5625 (0.6008) acc@5 0.7578 (0.8230)\n",
      "\u001b[32m[2020-07-15 10:45:53] __main__ INFO: \u001b[0mEpoch 74 Step 200/351 lr 0.020000 loss 1.1691 (1.0635) acc@1 0.5312 (0.5970) acc@5 0.8281 (0.8219)\n",
      "\u001b[32m[2020-07-15 10:47:47] __main__ INFO: \u001b[0mEpoch 74 Step 300/351 lr 0.020000 loss 1.0468 (1.0746) acc@1 0.5859 (0.5929) acc@5 0.8203 (0.8210)\n",
      "\u001b[32m[2020-07-15 10:48:45] __main__ INFO: \u001b[0mEpoch 74 Step 351/351 lr 0.020000 loss 1.1494 (1.0780) acc@1 0.5625 (0.5913) acc@5 0.8516 (0.8213)\n",
      "\u001b[32m[2020-07-15 10:48:45] __main__ INFO: \u001b[0mElapsed 398.94\n",
      "\u001b[32m[2020-07-15 10:48:45] __main__ INFO: \u001b[0mVal 74\n",
      "\u001b[32m[2020-07-15 10:48:58] __main__ INFO: \u001b[0mEpoch 74 loss 0.4092 acc@1 0.8770 acc@5 0.9950\n",
      "\u001b[32m[2020-07-15 10:48:58] __main__ INFO: \u001b[0mElapsed 13.46\n",
      "\u001b[32m[2020-07-15 10:48:58] __main__ INFO: \u001b[0mTrain 75 25974\n",
      "\u001b[32m[2020-07-15 10:50:52] __main__ INFO: \u001b[0mEpoch 75 Step 100/351 lr 0.020000 loss 1.1506 (1.0558) acc@1 0.5938 (0.6023) acc@5 0.8672 (0.8241)\n",
      "\u001b[32m[2020-07-15 10:52:45] __main__ INFO: \u001b[0mEpoch 75 Step 200/351 lr 0.020000 loss 1.0096 (1.0627) acc@1 0.6484 (0.5975) acc@5 0.8125 (0.8218)\n",
      "\u001b[32m[2020-07-15 10:54:39] __main__ INFO: \u001b[0mEpoch 75 Step 300/351 lr 0.020000 loss 1.0504 (1.0686) acc@1 0.6094 (0.5934) acc@5 0.8047 (0.8215)\n",
      "\u001b[32m[2020-07-15 10:55:37] __main__ INFO: \u001b[0mEpoch 75 Step 351/351 lr 0.020000 loss 1.0095 (1.0714) acc@1 0.5938 (0.5923) acc@5 0.8203 (0.8215)\n",
      "\u001b[32m[2020-07-15 10:55:37] __main__ INFO: \u001b[0mElapsed 398.67\n",
      "\u001b[32m[2020-07-15 10:55:37] __main__ INFO: \u001b[0mVal 75\n",
      "\u001b[32m[2020-07-15 10:55:50] __main__ INFO: \u001b[0mEpoch 75 loss 0.4325 acc@1 0.8808 acc@5 0.9942\n",
      "\u001b[32m[2020-07-15 10:55:50] __main__ INFO: \u001b[0mElapsed 13.44\n",
      "\u001b[32m[2020-07-15 10:55:50] __main__ INFO: \u001b[0mTrain 76 26325\n",
      "\u001b[32m[2020-07-15 10:57:44] __main__ INFO: \u001b[0mEpoch 76 Step 100/351 lr 0.020000 loss 1.1932 (1.0493) acc@1 0.5391 (0.6029) acc@5 0.7500 (0.8234)\n",
      "\u001b[32m[2020-07-15 10:59:38] __main__ INFO: \u001b[0mEpoch 76 Step 200/351 lr 0.020000 loss 1.1427 (1.0591) acc@1 0.5703 (0.5996) acc@5 0.8125 (0.8221)\n",
      "\u001b[32m[2020-07-15 11:01:31] __main__ INFO: \u001b[0mEpoch 76 Step 300/351 lr 0.020000 loss 1.1315 (1.0677) acc@1 0.5391 (0.5960) acc@5 0.7812 (0.8206)\n",
      "\u001b[32m[2020-07-15 11:02:29] __main__ INFO: \u001b[0mEpoch 76 Step 351/351 lr 0.020000 loss 0.9403 (1.0688) acc@1 0.6641 (0.5955) acc@5 0.8281 (0.8208)\n",
      "\u001b[32m[2020-07-15 11:02:29] __main__ INFO: \u001b[0mElapsed 398.78\n",
      "\u001b[32m[2020-07-15 11:02:29] __main__ INFO: \u001b[0mVal 76\n",
      "\u001b[32m[2020-07-15 11:02:43] __main__ INFO: \u001b[0mEpoch 76 loss 0.4470 acc@1 0.8698 acc@5 0.9940\n",
      "\u001b[32m[2020-07-15 11:02:43] __main__ INFO: \u001b[0mElapsed 13.45\n",
      "\u001b[32m[2020-07-15 11:02:43] __main__ INFO: \u001b[0mTrain 77 26676\n",
      "\u001b[32m[2020-07-15 11:04:36] __main__ INFO: \u001b[0mEpoch 77 Step 100/351 lr 0.020000 loss 1.0207 (1.0248) acc@1 0.5781 (0.6107) acc@5 0.7734 (0.8234)\n",
      "\u001b[32m[2020-07-15 11:06:30] __main__ INFO: \u001b[0mEpoch 77 Step 200/351 lr 0.020000 loss 1.1204 (1.0386) acc@1 0.5547 (0.6059) acc@5 0.7891 (0.8232)\n",
      "\u001b[32m[2020-07-15 11:08:24] __main__ INFO: \u001b[0mEpoch 77 Step 300/351 lr 0.020000 loss 1.0915 (1.0557) acc@1 0.5781 (0.6001) acc@5 0.7578 (0.8206)\n",
      "\u001b[32m[2020-07-15 11:09:21] __main__ INFO: \u001b[0mEpoch 77 Step 351/351 lr 0.020000 loss 1.1174 (1.0643) acc@1 0.5938 (0.5971) acc@5 0.8203 (0.8193)\n",
      "\u001b[32m[2020-07-15 11:09:21] __main__ INFO: \u001b[0mElapsed 398.79\n",
      "\u001b[32m[2020-07-15 11:09:21] __main__ INFO: \u001b[0mVal 77\n",
      "\u001b[32m[2020-07-15 11:09:35] __main__ INFO: \u001b[0mEpoch 77 loss 0.3945 acc@1 0.8792 acc@5 0.9944\n",
      "\u001b[32m[2020-07-15 11:09:35] __main__ INFO: \u001b[0mElapsed 13.44\n",
      "\u001b[32m[2020-07-15 11:09:35] __main__ INFO: \u001b[0mTrain 78 27027\n",
      "\u001b[32m[2020-07-15 11:11:29] __main__ INFO: \u001b[0mEpoch 78 Step 100/351 lr 0.020000 loss 0.9528 (1.0484) acc@1 0.6562 (0.6015) acc@5 0.8516 (0.8177)\n",
      "\u001b[32m[2020-07-15 11:13:22] __main__ INFO: \u001b[0mEpoch 78 Step 200/351 lr 0.020000 loss 1.1289 (1.0461) acc@1 0.5938 (0.6030) acc@5 0.8203 (0.8186)\n",
      "\u001b[32m[2020-07-15 11:15:16] __main__ INFO: \u001b[0mEpoch 78 Step 300/351 lr 0.020000 loss 0.9193 (1.0562) acc@1 0.6562 (0.5996) acc@5 0.8984 (0.8182)\n",
      "\u001b[32m[2020-07-15 11:16:13] __main__ INFO: \u001b[0mEpoch 78 Step 351/351 lr 0.020000 loss 1.0682 (1.0566) acc@1 0.5703 (0.5998) acc@5 0.8047 (0.8185)\n",
      "\u001b[32m[2020-07-15 11:16:13] __main__ INFO: \u001b[0mElapsed 398.61\n",
      "\u001b[32m[2020-07-15 11:16:13] __main__ INFO: \u001b[0mVal 78\n",
      "\u001b[32m[2020-07-15 11:16:27] __main__ INFO: \u001b[0mEpoch 78 loss 0.4886 acc@1 0.8564 acc@5 0.9924\n",
      "\u001b[32m[2020-07-15 11:16:27] __main__ INFO: \u001b[0mElapsed 13.45\n",
      "\u001b[32m[2020-07-15 11:16:27] __main__ INFO: \u001b[0mTrain 79 27378\n",
      "\u001b[32m[2020-07-15 11:18:21] __main__ INFO: \u001b[0mEpoch 79 Step 100/351 lr 0.020000 loss 1.1979 (1.0316) acc@1 0.5469 (0.6092) acc@5 0.7344 (0.8217)\n",
      "\u001b[32m[2020-07-15 11:20:14] __main__ INFO: \u001b[0mEpoch 79 Step 200/351 lr 0.020000 loss 1.0366 (1.0389) acc@1 0.6094 (0.6053) acc@5 0.8281 (0.8200)\n",
      "\u001b[32m[2020-07-15 11:22:08] __main__ INFO: \u001b[0mEpoch 79 Step 300/351 lr 0.020000 loss 1.1205 (1.0487) acc@1 0.5859 (0.6008) acc@5 0.8281 (0.8213)\n",
      "\u001b[32m[2020-07-15 11:23:06] __main__ INFO: \u001b[0mEpoch 79 Step 351/351 lr 0.020000 loss 0.9713 (1.0520) acc@1 0.6406 (0.5994) acc@5 0.8516 (0.8214)\n",
      "\u001b[32m[2020-07-15 11:23:06] __main__ INFO: \u001b[0mElapsed 398.77\n",
      "\u001b[32m[2020-07-15 11:23:06] __main__ INFO: \u001b[0mVal 79\n",
      "\u001b[32m[2020-07-15 11:23:19] __main__ INFO: \u001b[0mEpoch 79 loss 0.5216 acc@1 0.8586 acc@5 0.9924\n",
      "\u001b[32m[2020-07-15 11:23:19] __main__ INFO: \u001b[0mElapsed 13.47\n",
      "\u001b[32m[2020-07-15 11:23:19] __main__ INFO: \u001b[0mTrain 80 27729\n",
      "\u001b[32m[2020-07-15 11:25:13] __main__ INFO: \u001b[0mEpoch 80 Step 100/351 lr 0.020000 loss 1.1463 (1.0155) acc@1 0.5469 (0.6168) acc@5 0.7500 (0.8222)\n",
      "\u001b[32m[2020-07-15 11:27:06] __main__ INFO: \u001b[0mEpoch 80 Step 200/351 lr 0.020000 loss 1.1333 (1.0327) acc@1 0.5703 (0.6091) acc@5 0.7734 (0.8212)\n",
      "\u001b[32m[2020-07-15 11:29:00] __main__ INFO: \u001b[0mEpoch 80 Step 300/351 lr 0.020000 loss 1.1866 (1.0455) acc@1 0.5547 (0.6037) acc@5 0.8359 (0.8198)\n",
      "\u001b[32m[2020-07-15 11:29:58] __main__ INFO: \u001b[0mEpoch 80 Step 351/351 lr 0.020000 loss 0.9150 (1.0494) acc@1 0.6328 (0.6027) acc@5 0.8203 (0.8189)\n",
      "\u001b[32m[2020-07-15 11:29:58] __main__ INFO: \u001b[0mElapsed 398.46\n",
      "\u001b[32m[2020-07-15 11:29:58] __main__ INFO: \u001b[0mVal 80\n",
      "\u001b[32m[2020-07-15 11:30:11] __main__ INFO: \u001b[0mEpoch 80 loss 0.4364 acc@1 0.8724 acc@5 0.9956\n",
      "\u001b[32m[2020-07-15 11:30:11] __main__ INFO: \u001b[0mElapsed 13.41\n",
      "\u001b[32m[2020-07-15 11:30:11] __main__ INFO: \u001b[0mTrain 81 28080\n",
      "\u001b[32m[2020-07-15 11:32:05] __main__ INFO: \u001b[0mEpoch 81 Step 100/351 lr 0.020000 loss 1.1228 (1.0179) acc@1 0.6172 (0.6140) acc@5 0.8672 (0.8225)\n",
      "\u001b[32m[2020-07-15 11:33:58] __main__ INFO: \u001b[0mEpoch 81 Step 200/351 lr 0.020000 loss 1.1098 (1.0378) acc@1 0.5938 (0.6076) acc@5 0.7969 (0.8211)\n",
      "\u001b[32m[2020-07-15 11:35:52] __main__ INFO: \u001b[0mEpoch 81 Step 300/351 lr 0.020000 loss 1.2715 (1.0519) acc@1 0.5312 (0.6028) acc@5 0.7578 (0.8215)\n",
      "\u001b[32m[2020-07-15 11:36:50] __main__ INFO: \u001b[0mEpoch 81 Step 351/351 lr 0.020000 loss 1.0866 (1.0538) acc@1 0.5781 (0.6019) acc@5 0.8125 (0.8219)\n",
      "\u001b[32m[2020-07-15 11:36:50] __main__ INFO: \u001b[0mElapsed 398.73\n",
      "\u001b[32m[2020-07-15 11:36:50] __main__ INFO: \u001b[0mVal 81\n",
      "\u001b[32m[2020-07-15 11:37:03] __main__ INFO: \u001b[0mEpoch 81 loss 0.4236 acc@1 0.8782 acc@5 0.9952\n",
      "\u001b[32m[2020-07-15 11:37:03] __main__ INFO: \u001b[0mElapsed 13.43\n",
      "\u001b[32m[2020-07-15 11:37:03] __main__ INFO: \u001b[0mTrain 82 28431\n",
      "\u001b[32m[2020-07-15 11:38:57] __main__ INFO: \u001b[0mEpoch 82 Step 100/351 lr 0.020000 loss 0.9389 (1.0139) acc@1 0.6406 (0.6147) acc@5 0.8750 (0.8204)\n",
      "\u001b[32m[2020-07-15 11:40:50] __main__ INFO: \u001b[0mEpoch 82 Step 200/351 lr 0.020000 loss 0.9463 (1.0228) acc@1 0.6328 (0.6121) acc@5 0.8047 (0.8196)\n",
      "\u001b[32m[2020-07-15 11:42:44] __main__ INFO: \u001b[0mEpoch 82 Step 300/351 lr 0.020000 loss 1.1130 (1.0346) acc@1 0.5781 (0.6081) acc@5 0.8281 (0.8211)\n",
      "\u001b[32m[2020-07-15 11:43:42] __main__ INFO: \u001b[0mEpoch 82 Step 351/351 lr 0.020000 loss 0.9480 (1.0402) acc@1 0.6484 (0.6064) acc@5 0.8281 (0.8200)\n",
      "\u001b[32m[2020-07-15 11:43:42] __main__ INFO: \u001b[0mElapsed 398.80\n",
      "\u001b[32m[2020-07-15 11:43:42] __main__ INFO: \u001b[0mVal 82\n",
      "\u001b[32m[2020-07-15 11:43:55] __main__ INFO: \u001b[0mEpoch 82 loss 0.4959 acc@1 0.8666 acc@5 0.9928\n",
      "\u001b[32m[2020-07-15 11:43:55] __main__ INFO: \u001b[0mElapsed 13.43\n",
      "\u001b[32m[2020-07-15 11:43:55] __main__ INFO: \u001b[0mTrain 83 28782\n",
      "\u001b[32m[2020-07-15 11:45:49] __main__ INFO: \u001b[0mEpoch 83 Step 100/351 lr 0.020000 loss 1.0154 (1.0095) acc@1 0.6328 (0.6187) acc@5 0.8203 (0.8255)\n",
      "\u001b[32m[2020-07-15 11:47:43] __main__ INFO: \u001b[0mEpoch 83 Step 200/351 lr 0.020000 loss 0.8548 (1.0259) acc@1 0.6797 (0.6104) acc@5 0.8438 (0.8238)\n",
      "\u001b[32m[2020-07-15 11:49:36] __main__ INFO: \u001b[0mEpoch 83 Step 300/351 lr 0.020000 loss 1.0783 (1.0286) acc@1 0.6250 (0.6095) acc@5 0.8359 (0.8252)\n",
      "\u001b[32m[2020-07-15 11:50:34] __main__ INFO: \u001b[0mEpoch 83 Step 351/351 lr 0.020000 loss 1.2088 (1.0366) acc@1 0.5547 (0.6062) acc@5 0.8203 (0.8240)\n",
      "\u001b[32m[2020-07-15 11:50:34] __main__ INFO: \u001b[0mElapsed 398.75\n",
      "\u001b[32m[2020-07-15 11:50:34] __main__ INFO: \u001b[0mVal 83\n",
      "\u001b[32m[2020-07-15 11:50:48] __main__ INFO: \u001b[0mEpoch 83 loss 0.4716 acc@1 0.8660 acc@5 0.9926\n",
      "\u001b[32m[2020-07-15 11:50:48] __main__ INFO: \u001b[0mElapsed 13.43\n",
      "\u001b[32m[2020-07-15 11:50:48] __main__ INFO: \u001b[0mTrain 84 29133\n",
      "\u001b[32m[2020-07-15 11:52:41] __main__ INFO: \u001b[0mEpoch 84 Step 100/351 lr 0.020000 loss 1.2733 (1.0115) acc@1 0.5078 (0.6145) acc@5 0.7266 (0.8197)\n",
      "\u001b[32m[2020-07-15 11:54:35] __main__ INFO: \u001b[0mEpoch 84 Step 200/351 lr 0.020000 loss 1.0643 (1.0205) acc@1 0.5469 (0.6111) acc@5 0.7812 (0.8214)\n",
      "\u001b[32m[2020-07-15 11:56:28] __main__ INFO: \u001b[0mEpoch 84 Step 300/351 lr 0.020000 loss 1.0070 (1.0285) acc@1 0.6016 (0.6082) acc@5 0.8203 (0.8212)\n",
      "\u001b[32m[2020-07-15 11:57:26] __main__ INFO: \u001b[0mEpoch 84 Step 351/351 lr 0.020000 loss 1.0399 (1.0315) acc@1 0.5703 (0.6069) acc@5 0.7891 (0.8201)\n",
      "\u001b[32m[2020-07-15 11:57:26] __main__ INFO: \u001b[0mElapsed 398.70\n",
      "\u001b[32m[2020-07-15 11:57:26] __main__ INFO: \u001b[0mVal 84\n",
      "\u001b[32m[2020-07-15 11:57:40] __main__ INFO: \u001b[0mEpoch 84 loss 0.4410 acc@1 0.8734 acc@5 0.9936\n",
      "\u001b[32m[2020-07-15 11:57:40] __main__ INFO: \u001b[0mElapsed 13.44\n",
      "\u001b[32m[2020-07-15 11:57:40] __main__ INFO: \u001b[0mTrain 85 29484\n",
      "\u001b[32m[2020-07-15 11:59:33] __main__ INFO: \u001b[0mEpoch 85 Step 100/351 lr 0.020000 loss 0.8983 (1.0009) acc@1 0.6406 (0.6184) acc@5 0.8750 (0.8241)\n",
      "\u001b[32m[2020-07-15 12:01:27] __main__ INFO: \u001b[0mEpoch 85 Step 200/351 lr 0.020000 loss 0.9606 (1.0148) acc@1 0.6328 (0.6154) acc@5 0.8594 (0.8202)\n",
      "\u001b[32m[2020-07-15 12:03:20] __main__ INFO: \u001b[0mEpoch 85 Step 300/351 lr 0.020000 loss 1.0549 (1.0320) acc@1 0.6172 (0.6081) acc@5 0.8047 (0.8190)\n",
      "\u001b[32m[2020-07-15 12:04:18] __main__ INFO: \u001b[0mEpoch 85 Step 351/351 lr 0.020000 loss 1.0429 (1.0338) acc@1 0.5859 (0.6071) acc@5 0.8125 (0.8194)\n",
      "\u001b[32m[2020-07-15 12:04:18] __main__ INFO: \u001b[0mElapsed 398.59\n",
      "\u001b[32m[2020-07-15 12:04:18] __main__ INFO: \u001b[0mVal 85\n",
      "\u001b[32m[2020-07-15 12:04:32] __main__ INFO: \u001b[0mEpoch 85 loss 0.4568 acc@1 0.8732 acc@5 0.9950\n",
      "\u001b[32m[2020-07-15 12:04:32] __main__ INFO: \u001b[0mElapsed 13.42\n",
      "\u001b[32m[2020-07-15 12:04:32] __main__ INFO: \u001b[0mTrain 86 29835\n",
      "\u001b[32m[2020-07-15 12:06:26] __main__ INFO: \u001b[0mEpoch 86 Step 100/351 lr 0.020000 loss 1.0015 (0.9926) acc@1 0.6406 (0.6230) acc@5 0.8281 (0.8191)\n",
      "\u001b[32m[2020-07-15 12:08:19] __main__ INFO: \u001b[0mEpoch 86 Step 200/351 lr 0.020000 loss 1.0995 (1.0068) acc@1 0.5781 (0.6185) acc@5 0.7812 (0.8217)\n",
      "\u001b[32m[2020-07-15 12:10:13] __main__ INFO: \u001b[0mEpoch 86 Step 300/351 lr 0.020000 loss 0.8711 (1.0182) acc@1 0.6641 (0.6134) acc@5 0.8438 (0.8222)\n",
      "\u001b[32m[2020-07-15 12:11:11] __main__ INFO: \u001b[0mEpoch 86 Step 351/351 lr 0.020000 loss 0.9298 (1.0200) acc@1 0.6797 (0.6126) acc@5 0.8672 (0.8218)\n",
      "\u001b[32m[2020-07-15 12:11:11] __main__ INFO: \u001b[0mElapsed 398.90\n",
      "\u001b[32m[2020-07-15 12:11:11] __main__ INFO: \u001b[0mVal 86\n",
      "\u001b[32m[2020-07-15 12:11:24] __main__ INFO: \u001b[0mEpoch 86 loss 0.5213 acc@1 0.8588 acc@5 0.9926\n",
      "\u001b[32m[2020-07-15 12:11:24] __main__ INFO: \u001b[0mElapsed 13.42\n",
      "\u001b[32m[2020-07-15 12:11:24] __main__ INFO: \u001b[0mTrain 87 30186\n",
      "\u001b[32m[2020-07-15 12:13:18] __main__ INFO: \u001b[0mEpoch 87 Step 100/351 lr 0.020000 loss 1.1691 (1.0030) acc@1 0.5781 (0.6178) acc@5 0.7891 (0.8239)\n",
      "\u001b[32m[2020-07-15 12:15:11] __main__ INFO: \u001b[0mEpoch 87 Step 200/351 lr 0.020000 loss 0.9206 (1.0000) acc@1 0.6719 (0.6195) acc@5 0.8203 (0.8229)\n",
      "\u001b[32m[2020-07-15 12:17:05] __main__ INFO: \u001b[0mEpoch 87 Step 300/351 lr 0.020000 loss 1.1477 (1.0136) acc@1 0.5547 (0.6142) acc@5 0.7812 (0.8209)\n",
      "\u001b[32m[2020-07-15 12:18:03] __main__ INFO: \u001b[0mEpoch 87 Step 351/351 lr 0.020000 loss 1.1065 (1.0182) acc@1 0.5547 (0.6122) acc@5 0.8438 (0.8200)\n",
      "\u001b[32m[2020-07-15 12:18:03] __main__ INFO: \u001b[0mElapsed 398.97\n",
      "\u001b[32m[2020-07-15 12:18:03] __main__ INFO: \u001b[0mVal 87\n",
      "\u001b[32m[2020-07-15 12:18:17] __main__ INFO: \u001b[0mEpoch 87 loss 0.4771 acc@1 0.8724 acc@5 0.9952\n",
      "\u001b[32m[2020-07-15 12:18:17] __main__ INFO: \u001b[0mElapsed 13.44\n",
      "\u001b[32m[2020-07-15 12:18:17] __main__ INFO: \u001b[0mTrain 88 30537\n",
      "\u001b[32m[2020-07-15 12:20:10] __main__ INFO: \u001b[0mEpoch 88 Step 100/351 lr 0.020000 loss 0.9759 (1.0040) acc@1 0.6172 (0.6182) acc@5 0.8047 (0.8200)\n",
      "\u001b[32m[2020-07-15 12:22:04] __main__ INFO: \u001b[0mEpoch 88 Step 200/351 lr 0.020000 loss 1.0663 (1.0092) acc@1 0.5781 (0.6144) acc@5 0.8203 (0.8191)\n",
      "\u001b[32m[2020-07-15 12:23:58] __main__ INFO: \u001b[0mEpoch 88 Step 300/351 lr 0.020000 loss 1.0802 (1.0186) acc@1 0.5859 (0.6126) acc@5 0.8594 (0.8209)\n",
      "\u001b[32m[2020-07-15 12:24:56] __main__ INFO: \u001b[0mEpoch 88 Step 351/351 lr 0.020000 loss 1.0524 (1.0167) acc@1 0.5938 (0.6135) acc@5 0.8125 (0.8223)\n",
      "\u001b[32m[2020-07-15 12:24:56] __main__ INFO: \u001b[0mElapsed 399.07\n",
      "\u001b[32m[2020-07-15 12:24:56] __main__ INFO: \u001b[0mVal 88\n",
      "\u001b[32m[2020-07-15 12:25:09] __main__ INFO: \u001b[0mEpoch 88 loss 0.5705 acc@1 0.8486 acc@5 0.9916\n",
      "\u001b[32m[2020-07-15 12:25:09] __main__ INFO: \u001b[0mElapsed 13.43\n",
      "\u001b[32m[2020-07-15 12:25:09] __main__ INFO: \u001b[0mTrain 89 30888\n",
      "\u001b[32m[2020-07-15 12:27:03] __main__ INFO: \u001b[0mEpoch 89 Step 100/351 lr 0.020000 loss 1.0232 (0.9865) acc@1 0.6641 (0.6252) acc@5 0.8203 (0.8220)\n",
      "\u001b[32m[2020-07-15 12:28:56] __main__ INFO: \u001b[0mEpoch 89 Step 200/351 lr 0.020000 loss 1.0696 (0.9919) acc@1 0.5859 (0.6228) acc@5 0.7578 (0.8203)\n",
      "\u001b[32m[2020-07-15 12:30:50] __main__ INFO: \u001b[0mEpoch 89 Step 300/351 lr 0.020000 loss 0.8825 (1.0048) acc@1 0.6797 (0.6175) acc@5 0.8516 (0.8210)\n",
      "\u001b[32m[2020-07-15 12:31:48] __main__ INFO: \u001b[0mEpoch 89 Step 351/351 lr 0.020000 loss 1.0535 (1.0114) acc@1 0.6094 (0.6153) acc@5 0.8516 (0.8204)\n",
      "\u001b[32m[2020-07-15 12:31:48] __main__ INFO: \u001b[0mElapsed 399.06\n",
      "\u001b[32m[2020-07-15 12:31:48] __main__ INFO: \u001b[0mVal 89\n",
      "\u001b[32m[2020-07-15 12:32:02] __main__ INFO: \u001b[0mEpoch 89 loss 0.4407 acc@1 0.8772 acc@5 0.9944\n",
      "\u001b[32m[2020-07-15 12:32:02] __main__ INFO: \u001b[0mElapsed 13.45\n",
      "\u001b[32m[2020-07-15 12:32:02] __main__ INFO: \u001b[0mTrain 90 31239\n",
      "\u001b[32m[2020-07-15 12:33:55] __main__ INFO: \u001b[0mEpoch 90 Step 100/351 lr 0.020000 loss 0.9283 (1.0071) acc@1 0.6484 (0.6177) acc@5 0.8438 (0.8246)\n",
      "\u001b[32m[2020-07-15 12:35:49] __main__ INFO: \u001b[0mEpoch 90 Step 200/351 lr 0.020000 loss 0.9428 (1.0016) acc@1 0.6562 (0.6180) acc@5 0.8359 (0.8243)\n",
      "\u001b[32m[2020-07-15 12:37:43] __main__ INFO: \u001b[0mEpoch 90 Step 300/351 lr 0.020000 loss 1.0671 (1.0011) acc@1 0.6016 (0.6190) acc@5 0.7969 (0.8244)\n",
      "\u001b[32m[2020-07-15 12:38:41] __main__ INFO: \u001b[0mEpoch 90 Step 351/351 lr 0.020000 loss 0.9903 (1.0048) acc@1 0.5781 (0.6171) acc@5 0.7969 (0.8246)\n",
      "\u001b[32m[2020-07-15 12:38:41] __main__ INFO: \u001b[0mElapsed 399.21\n",
      "\u001b[32m[2020-07-15 12:38:41] __main__ INFO: \u001b[0mVal 90\n",
      "\u001b[32m[2020-07-15 12:38:54] __main__ INFO: \u001b[0mEpoch 90 loss 0.5812 acc@1 0.8462 acc@5 0.9924\n",
      "\u001b[32m[2020-07-15 12:38:54] __main__ INFO: \u001b[0mElapsed 13.43\n",
      "\u001b[32m[2020-07-15 12:38:54] __main__ INFO: \u001b[0mTrain 91 31590\n",
      "\u001b[32m[2020-07-15 12:40:48] __main__ INFO: \u001b[0mEpoch 91 Step 100/351 lr 0.020000 loss 1.0030 (0.9757) acc@1 0.6250 (0.6273) acc@5 0.8125 (0.8235)\n",
      "\u001b[32m[2020-07-15 12:42:42] __main__ INFO: \u001b[0mEpoch 91 Step 200/351 lr 0.020000 loss 0.8382 (0.9885) acc@1 0.7344 (0.6214) acc@5 0.8750 (0.8217)\n",
      "\u001b[32m[2020-07-15 12:44:35] __main__ INFO: \u001b[0mEpoch 91 Step 300/351 lr 0.020000 loss 0.9097 (1.0028) acc@1 0.6797 (0.6179) acc@5 0.8672 (0.8204)\n",
      "\u001b[32m[2020-07-15 12:45:33] __main__ INFO: \u001b[0mEpoch 91 Step 351/351 lr 0.020000 loss 0.9726 (1.0058) acc@1 0.6250 (0.6170) acc@5 0.8359 (0.8214)\n",
      "\u001b[32m[2020-07-15 12:45:33] __main__ INFO: \u001b[0mElapsed 399.02\n",
      "\u001b[32m[2020-07-15 12:45:33] __main__ INFO: \u001b[0mVal 91\n",
      "\u001b[32m[2020-07-15 12:45:47] __main__ INFO: \u001b[0mEpoch 91 loss 0.5244 acc@1 0.8504 acc@5 0.9922\n",
      "\u001b[32m[2020-07-15 12:45:47] __main__ INFO: \u001b[0mElapsed 13.45\n",
      "\u001b[32m[2020-07-15 12:45:47] __main__ INFO: \u001b[0mTrain 92 31941\n",
      "\u001b[32m[2020-07-15 12:47:40] __main__ INFO: \u001b[0mEpoch 92 Step 100/351 lr 0.020000 loss 1.0236 (0.9869) acc@1 0.6016 (0.6255) acc@5 0.8359 (0.8252)\n",
      "\u001b[32m[2020-07-15 12:49:34] __main__ INFO: \u001b[0mEpoch 92 Step 200/351 lr 0.020000 loss 1.0175 (0.9985) acc@1 0.6172 (0.6202) acc@5 0.8047 (0.8228)\n",
      "\u001b[32m[2020-07-15 12:51:28] __main__ INFO: \u001b[0mEpoch 92 Step 300/351 lr 0.020000 loss 0.9855 (1.0060) acc@1 0.5859 (0.6171) acc@5 0.8047 (0.8220)\n",
      "\u001b[32m[2020-07-15 12:52:26] __main__ INFO: \u001b[0mEpoch 92 Step 351/351 lr 0.020000 loss 0.9475 (1.0070) acc@1 0.6484 (0.6166) acc@5 0.7969 (0.8223)\n",
      "\u001b[32m[2020-07-15 12:52:26] __main__ INFO: \u001b[0mElapsed 399.27\n",
      "\u001b[32m[2020-07-15 12:52:26] __main__ INFO: \u001b[0mVal 92\n",
      "\u001b[32m[2020-07-15 12:52:39] __main__ INFO: \u001b[0mEpoch 92 loss 0.4889 acc@1 0.8666 acc@5 0.9938\n",
      "\u001b[32m[2020-07-15 12:52:39] __main__ INFO: \u001b[0mElapsed 13.43\n",
      "\u001b[32m[2020-07-15 12:52:39] __main__ INFO: \u001b[0mTrain 93 32292\n",
      "\u001b[32m[2020-07-15 12:54:33] __main__ INFO: \u001b[0mEpoch 93 Step 100/351 lr 0.020000 loss 0.8360 (0.9789) acc@1 0.6797 (0.6292) acc@5 0.8516 (0.8262)\n",
      "\u001b[32m[2020-07-15 12:56:27] __main__ INFO: \u001b[0mEpoch 93 Step 200/351 lr 0.020000 loss 1.0165 (0.9940) acc@1 0.6250 (0.6228) acc@5 0.7969 (0.8206)\n",
      "\u001b[32m[2020-07-15 12:58:20] __main__ INFO: \u001b[0mEpoch 93 Step 300/351 lr 0.020000 loss 0.9280 (1.0012) acc@1 0.6562 (0.6195) acc@5 0.8672 (0.8204)\n",
      "\u001b[32m[2020-07-15 12:59:18] __main__ INFO: \u001b[0mEpoch 93 Step 351/351 lr 0.020000 loss 1.0241 (1.0037) acc@1 0.6094 (0.6178) acc@5 0.8203 (0.8208)\n",
      "\u001b[32m[2020-07-15 12:59:18] __main__ INFO: \u001b[0mElapsed 398.98\n",
      "\u001b[32m[2020-07-15 12:59:18] __main__ INFO: \u001b[0mVal 93\n",
      "\u001b[32m[2020-07-15 12:59:32] __main__ INFO: \u001b[0mEpoch 93 loss 0.4416 acc@1 0.8720 acc@5 0.9950\n",
      "\u001b[32m[2020-07-15 12:59:32] __main__ INFO: \u001b[0mElapsed 13.43\n",
      "\u001b[32m[2020-07-15 12:59:32] __main__ INFO: \u001b[0mTrain 94 32643\n",
      "\u001b[32m[2020-07-15 13:01:26] __main__ INFO: \u001b[0mEpoch 94 Step 100/351 lr 0.020000 loss 0.9239 (0.9719) acc@1 0.6641 (0.6322) acc@5 0.8594 (0.8215)\n",
      "\u001b[32m[2020-07-15 13:03:19] __main__ INFO: \u001b[0mEpoch 94 Step 200/351 lr 0.020000 loss 1.0184 (0.9936) acc@1 0.5703 (0.6230) acc@5 0.8125 (0.8205)\n",
      "\u001b[32m[2020-07-15 13:05:13] __main__ INFO: \u001b[0mEpoch 94 Step 300/351 lr 0.020000 loss 1.0342 (0.9978) acc@1 0.6250 (0.6219) acc@5 0.8516 (0.8214)\n",
      "\u001b[32m[2020-07-15 13:06:11] __main__ INFO: \u001b[0mEpoch 94 Step 351/351 lr 0.020000 loss 1.0576 (1.0017) acc@1 0.6094 (0.6203) acc@5 0.7734 (0.8207)\n",
      "\u001b[32m[2020-07-15 13:06:11] __main__ INFO: \u001b[0mElapsed 399.14\n",
      "\u001b[32m[2020-07-15 13:06:11] __main__ INFO: \u001b[0mVal 94\n",
      "\u001b[32m[2020-07-15 13:06:24] __main__ INFO: \u001b[0mEpoch 94 loss 0.4632 acc@1 0.8678 acc@5 0.9920\n",
      "\u001b[32m[2020-07-15 13:06:24] __main__ INFO: \u001b[0mElapsed 13.44\n",
      "\u001b[32m[2020-07-15 13:06:24] __main__ INFO: \u001b[0mTrain 95 32994\n",
      "\u001b[32m[2020-07-15 13:08:18] __main__ INFO: \u001b[0mEpoch 95 Step 100/351 lr 0.020000 loss 0.9574 (0.9745) acc@1 0.6172 (0.6263) acc@5 0.8750 (0.8273)\n",
      "\u001b[32m[2020-07-15 13:10:12] __main__ INFO: \u001b[0mEpoch 95 Step 200/351 lr 0.020000 loss 0.9215 (0.9846) acc@1 0.6641 (0.6237) acc@5 0.7734 (0.8250)\n",
      "\u001b[32m[2020-07-15 13:12:06] __main__ INFO: \u001b[0mEpoch 95 Step 300/351 lr 0.020000 loss 1.0076 (0.9951) acc@1 0.6250 (0.6194) acc@5 0.8203 (0.8236)\n",
      "\u001b[32m[2020-07-15 13:13:04] __main__ INFO: \u001b[0mEpoch 95 Step 351/351 lr 0.020000 loss 1.1438 (0.9966) acc@1 0.5547 (0.6201) acc@5 0.7969 (0.8231)\n",
      "\u001b[32m[2020-07-15 13:13:04] __main__ INFO: \u001b[0mElapsed 399.39\n",
      "\u001b[32m[2020-07-15 13:13:04] __main__ INFO: \u001b[0mVal 95\n",
      "\u001b[32m[2020-07-15 13:13:17] __main__ INFO: \u001b[0mEpoch 95 loss 0.4789 acc@1 0.8694 acc@5 0.9930\n",
      "\u001b[32m[2020-07-15 13:13:17] __main__ INFO: \u001b[0mElapsed 13.44\n",
      "\u001b[32m[2020-07-15 13:13:17] __main__ INFO: \u001b[0mTrain 96 33345\n",
      "\u001b[32m[2020-07-15 13:15:11] __main__ INFO: \u001b[0mEpoch 96 Step 100/351 lr 0.020000 loss 1.0542 (0.9727) acc@1 0.5859 (0.6295) acc@5 0.8047 (0.8265)\n",
      "\u001b[32m[2020-07-15 13:17:05] __main__ INFO: \u001b[0mEpoch 96 Step 200/351 lr 0.020000 loss 0.9802 (0.9759) acc@1 0.5938 (0.6291) acc@5 0.8438 (0.8244)\n",
      "\u001b[32m[2020-07-15 13:18:59] __main__ INFO: \u001b[0mEpoch 96 Step 300/351 lr 0.020000 loss 0.9635 (0.9848) acc@1 0.6484 (0.6254) acc@5 0.8047 (0.8244)\n",
      "\u001b[32m[2020-07-15 13:19:57] __main__ INFO: \u001b[0mEpoch 96 Step 351/351 lr 0.020000 loss 0.9495 (0.9895) acc@1 0.6328 (0.6238) acc@5 0.8438 (0.8242)\n",
      "\u001b[32m[2020-07-15 13:19:57] __main__ INFO: \u001b[0mElapsed 399.54\n",
      "\u001b[32m[2020-07-15 13:19:57] __main__ INFO: \u001b[0mVal 96\n",
      "\u001b[32m[2020-07-15 13:20:10] __main__ INFO: \u001b[0mEpoch 96 loss 0.5457 acc@1 0.8556 acc@5 0.9928\n",
      "\u001b[32m[2020-07-15 13:20:10] __main__ INFO: \u001b[0mElapsed 13.44\n",
      "\u001b[32m[2020-07-15 13:20:10] __main__ INFO: \u001b[0mTrain 97 33696\n",
      "\u001b[32m[2020-07-15 13:22:04] __main__ INFO: \u001b[0mEpoch 97 Step 100/351 lr 0.020000 loss 0.8202 (0.9721) acc@1 0.7422 (0.6346) acc@5 0.8672 (0.8280)\n",
      "\u001b[32m[2020-07-15 13:23:58] __main__ INFO: \u001b[0mEpoch 97 Step 200/351 lr 0.020000 loss 1.0136 (0.9856) acc@1 0.6172 (0.6282) acc@5 0.8672 (0.8258)\n",
      "\u001b[32m[2020-07-15 13:25:52] __main__ INFO: \u001b[0mEpoch 97 Step 300/351 lr 0.020000 loss 1.0626 (0.9958) acc@1 0.5938 (0.6229) acc@5 0.8203 (0.8236)\n",
      "\u001b[32m[2020-07-15 13:26:50] __main__ INFO: \u001b[0mEpoch 97 Step 351/351 lr 0.020000 loss 0.9108 (0.9995) acc@1 0.6953 (0.6215) acc@5 0.8359 (0.8240)\n",
      "\u001b[32m[2020-07-15 13:26:50] __main__ INFO: \u001b[0mElapsed 399.56\n",
      "\u001b[32m[2020-07-15 13:26:50] __main__ INFO: \u001b[0mVal 97\n",
      "\u001b[32m[2020-07-15 13:27:03] __main__ INFO: \u001b[0mEpoch 97 loss 0.4560 acc@1 0.8750 acc@5 0.9952\n",
      "\u001b[32m[2020-07-15 13:27:03] __main__ INFO: \u001b[0mElapsed 13.44\n",
      "\u001b[32m[2020-07-15 13:27:03] __main__ INFO: \u001b[0mTrain 98 34047\n",
      "\u001b[32m[2020-07-15 13:28:57] __main__ INFO: \u001b[0mEpoch 98 Step 100/351 lr 0.020000 loss 0.9961 (0.9753) acc@1 0.6250 (0.6320) acc@5 0.8047 (0.8271)\n",
      "\u001b[32m[2020-07-15 13:30:51] __main__ INFO: \u001b[0mEpoch 98 Step 200/351 lr 0.020000 loss 0.8550 (0.9819) acc@1 0.6562 (0.6273) acc@5 0.8672 (0.8231)\n",
      "\u001b[32m[2020-07-15 13:32:45] __main__ INFO: \u001b[0mEpoch 98 Step 300/351 lr 0.020000 loss 0.9208 (0.9845) acc@1 0.6328 (0.6248) acc@5 0.8672 (0.8238)\n",
      "\u001b[32m[2020-07-15 13:33:43] __main__ INFO: \u001b[0mEpoch 98 Step 351/351 lr 0.020000 loss 1.0691 (0.9898) acc@1 0.6172 (0.6223) acc@5 0.8359 (0.8234)\n",
      "\u001b[32m[2020-07-15 13:33:43] __main__ INFO: \u001b[0mElapsed 399.51\n",
      "\u001b[32m[2020-07-15 13:33:43] __main__ INFO: \u001b[0mVal 98\n",
      "\u001b[32m[2020-07-15 13:33:56] __main__ INFO: \u001b[0mEpoch 98 loss 0.4964 acc@1 0.8642 acc@5 0.9912\n",
      "\u001b[32m[2020-07-15 13:33:56] __main__ INFO: \u001b[0mElapsed 13.45\n",
      "\u001b[32m[2020-07-15 13:33:56] __main__ INFO: \u001b[0mTrain 99 34398\n",
      "\u001b[32m[2020-07-15 13:35:50] __main__ INFO: \u001b[0mEpoch 99 Step 100/351 lr 0.020000 loss 0.9060 (0.9624) acc@1 0.6484 (0.6342) acc@5 0.8438 (0.8247)\n",
      "\u001b[32m[2020-07-15 13:37:44] __main__ INFO: \u001b[0mEpoch 99 Step 200/351 lr 0.020000 loss 0.9191 (0.9642) acc@1 0.6328 (0.6325) acc@5 0.8125 (0.8259)\n",
      "\u001b[32m[2020-07-15 13:39:38] __main__ INFO: \u001b[0mEpoch 99 Step 300/351 lr 0.020000 loss 1.1625 (0.9801) acc@1 0.5391 (0.6258) acc@5 0.8125 (0.8249)\n",
      "\u001b[32m[2020-07-15 13:40:36] __main__ INFO: \u001b[0mEpoch 99 Step 351/351 lr 0.020000 loss 1.0300 (0.9874) acc@1 0.6016 (0.6227) acc@5 0.7812 (0.8239)\n",
      "\u001b[32m[2020-07-15 13:40:36] __main__ INFO: \u001b[0mElapsed 399.50\n",
      "\u001b[32m[2020-07-15 13:40:36] __main__ INFO: \u001b[0mVal 99\n",
      "\u001b[32m[2020-07-15 13:40:49] __main__ INFO: \u001b[0mEpoch 99 loss 0.4738 acc@1 0.8688 acc@5 0.9926\n",
      "\u001b[32m[2020-07-15 13:40:49] __main__ INFO: \u001b[0mElapsed 13.43\n",
      "\u001b[32m[2020-07-15 13:40:49] __main__ INFO: \u001b[0mTrain 100 34749\n",
      "\u001b[32m[2020-07-15 13:42:43] __main__ INFO: \u001b[0mEpoch 100 Step 100/351 lr 0.020000 loss 0.8903 (0.9556) acc@1 0.6797 (0.6396) acc@5 0.8594 (0.8239)\n",
      "\u001b[32m[2020-07-15 13:44:37] __main__ INFO: \u001b[0mEpoch 100 Step 200/351 lr 0.020000 loss 1.1130 (0.9684) acc@1 0.5781 (0.6342) acc@5 0.8281 (0.8240)\n",
      "\u001b[32m[2020-07-15 13:46:31] __main__ INFO: \u001b[0mEpoch 100 Step 300/351 lr 0.020000 loss 1.1324 (0.9808) acc@1 0.5625 (0.6277) acc@5 0.8047 (0.8240)\n",
      "\u001b[32m[2020-07-15 13:47:29] __main__ INFO: \u001b[0mEpoch 100 Step 351/351 lr 0.020000 loss 1.1846 (0.9924) acc@1 0.5312 (0.6235) acc@5 0.7188 (0.8231)\n",
      "\u001b[32m[2020-07-15 13:47:29] __main__ INFO: \u001b[0mElapsed 399.54\n",
      "\u001b[32m[2020-07-15 13:47:29] __main__ INFO: \u001b[0mVal 100\n",
      "\u001b[32m[2020-07-15 13:47:42] __main__ INFO: \u001b[0mEpoch 100 loss 0.4572 acc@1 0.8734 acc@5 0.9944\n",
      "\u001b[32m[2020-07-15 13:47:42] __main__ INFO: \u001b[0mElapsed 13.46\n",
      "\u001b[32m[2020-07-15 13:47:42] fvcore.common.checkpoint INFO: \u001b[0mSaving checkpoint to /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_20_c10val/exp00/checkpoint_00100.pth\n",
      "\u001b[32m[2020-07-15 13:47:42] __main__ INFO: \u001b[0mTrain 101 35100\n",
      "\u001b[32m[2020-07-15 13:49:36] __main__ INFO: \u001b[0mEpoch 101 Step 100/351 lr 0.020000 loss 1.1459 (0.9736) acc@1 0.5547 (0.6295) acc@5 0.7812 (0.8217)\n",
      "\u001b[32m[2020-07-15 13:51:30] __main__ INFO: \u001b[0mEpoch 101 Step 200/351 lr 0.020000 loss 0.9540 (0.9771) acc@1 0.6250 (0.6257) acc@5 0.8672 (0.8237)\n"
     ]
    }
   ],
   "source": [
    "# Train the model per the settings specified in the original paper\n",
    "os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "!python train.py --config configs/cifar/wrn.yaml \\\n",
    "    model.wrn.depth 28 \\\n",
    "    model.wrn.widening_factor 10 \\\n",
    "    train.batch_size 128 \\\n",
    "    train.base_lr 0.1 \\\n",
    "    dataset.name CIFAR10_RA_2_20 \\\n",
    "    train.output_dir /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_20_c10val/exp00 \\\n",
    "    scheduler.epochs 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refine the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-17 01:35:07] __main__ INFO: \u001b[0mdevice: cuda\n",
      "cudnn:\n",
      "  benchmark: True\n",
      "  deterministic: False\n",
      "dataset:\n",
      "  name: CIFAR10\n",
      "  dataset_dir: ~/.torch/datasets/CIFAR10\n",
      "  image_size: 32\n",
      "  n_channels: 3\n",
      "  n_classes: 10\n",
      "model:\n",
      "  type: cifar\n",
      "  name: wrn\n",
      "  init_mode: kaiming_fan_in\n",
      "  vgg:\n",
      "    n_channels: [64, 128, 256, 512, 512]\n",
      "    n_layers: [2, 2, 3, 3, 3]\n",
      "    use_bn: True\n",
      "  resnet:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "  resnet_preact:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "  wrn:\n",
      "    depth: 28\n",
      "    initial_channels: 16\n",
      "    widening_factor: 10\n",
      "    drop_rate: 0.0\n",
      "  densenet:\n",
      "    depth: 100\n",
      "    n_blocks: [6, 12, 24, 16]\n",
      "    block_type: bottleneck\n",
      "    growth_rate: 12\n",
      "    drop_rate: 0.0\n",
      "    compression_rate: 0.5\n",
      "  pyramidnet:\n",
      "    depth: 272\n",
      "    n_blocks: [3, 24, 36, 3]\n",
      "    initial_channels: 16\n",
      "    block_type: bottleneck\n",
      "    alpha: 200\n",
      "  resnext:\n",
      "    depth: 29\n",
      "    n_blocks: [3, 4, 6, 3]\n",
      "    initial_channels: 64\n",
      "    cardinality: 8\n",
      "    base_channels: 4\n",
      "  shake_shake:\n",
      "    depth: 26\n",
      "    initial_channels: 96\n",
      "    shake_forward: True\n",
      "    shake_backward: True\n",
      "    shake_image: True\n",
      "  se_resnet_preact:\n",
      "    depth: 110\n",
      "    initial_channels: 16\n",
      "    se_reduction: 16\n",
      "    block_type: basic\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "train:\n",
      "  checkpoint: /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_20_c10val/exp00/checkpoint_00400.pth\n",
      "  resume: False\n",
      "  precision: O0\n",
      "  batch_size: 128\n",
      "  subdivision: 1\n",
      "  optimizer: sgd\n",
      "  base_lr: 0.0008\n",
      "  momentum: 0.9\n",
      "  nesterov: True\n",
      "  weight_decay: 0.0005\n",
      "  no_weight_decay_on_bn: False\n",
      "  gradient_clip: 0\n",
      "  start_epoch: 0\n",
      "  seed: 0\n",
      "  val_first: True\n",
      "  val_period: 1\n",
      "  val_ratio: 0.1\n",
      "  use_test_as_val: False\n",
      "  output_dir: /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_20_c10val/exp00_resume400_50\n",
      "  log_period: 100\n",
      "  checkpoint_period: 100\n",
      "  use_tensorboard: True\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: True\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "  distributed: False\n",
      "  dist:\n",
      "    backend: nccl\n",
      "    init_method: env://\n",
      "    world_size: -1\n",
      "    node_rank: -1\n",
      "    local_rank: 0\n",
      "    use_sync_bn: False\n",
      "tensorboard:\n",
      "  train_images: False\n",
      "  val_images: False\n",
      "  model_params: False\n",
      "optim:\n",
      "  adam:\n",
      "    betas: (0.9, 0.999)\n",
      "  lars:\n",
      "    eps: 1e-09\n",
      "    threshold: 0.01\n",
      "  adabound:\n",
      "    betas: (0.9, 0.999)\n",
      "    final_lr: 0.1\n",
      "    gamma: 0.001\n",
      "scheduler:\n",
      "  epochs: 50\n",
      "  warmup:\n",
      "    type: none\n",
      "    epochs: 0\n",
      "    start_factor: 0.001\n",
      "    exponent: 4\n",
      "  type: multistep\n",
      "  milestones: [60, 120, 160]\n",
      "  lr_decay: 0.2\n",
      "  lr_min_factor: 0.001\n",
      "  T0: 10\n",
      "  T_mul: 1.0\n",
      "validation:\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: False\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "augmentation:\n",
      "  use_random_crop: True\n",
      "  use_random_horizontal_flip: True\n",
      "  use_cutout: False\n",
      "  use_random_erasing: False\n",
      "  use_dual_cutout: False\n",
      "  use_mixup: False\n",
      "  use_ricap: False\n",
      "  use_cutmix: False\n",
      "  use_label_smoothing: False\n",
      "  random_crop:\n",
      "    padding: 4\n",
      "    fill: 0\n",
      "    padding_mode: constant\n",
      "  random_horizontal_flip:\n",
      "    prob: 0.5\n",
      "  cutout:\n",
      "    prob: 1.0\n",
      "    mask_size: 16\n",
      "    cut_inside: False\n",
      "    mask_color: 0\n",
      "    dual_cutout_alpha: 0.1\n",
      "  random_erasing:\n",
      "    prob: 0.5\n",
      "    area_ratio_range: [0.02, 0.4]\n",
      "    min_aspect_ratio: 0.3\n",
      "    max_attempt: 20\n",
      "  mixup:\n",
      "    alpha: 1.0\n",
      "  ricap:\n",
      "    beta: 0.3\n",
      "  cutmix:\n",
      "    alpha: 1.0\n",
      "  label_smoothing:\n",
      "    epsilon: 0.1\n",
      "tta:\n",
      "  use_resize: False\n",
      "  use_center_crop: False\n",
      "  resize: 256\n",
      "test:\n",
      "  checkpoint: ''\n",
      "  output_dir: ''\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    pin_memory: False\n",
      "\u001b[32m[2020-07-17 01:35:07] __main__ INFO: \u001b[0menv_info:\n",
      "  pytorch_version: 1.4.0\n",
      "  cuda_version: 10.1\n",
      "  cudnn_version: 7603\n",
      "  num_gpus: 1\n",
      "  gpu_name: Tesla K80\n",
      "  gpu_capability: 3.7\n",
      "Files already downloaded and verified\n",
      "\u001b[32m[2020-07-17 01:35:11] __main__ INFO: \u001b[0mMACs  : 5.25G\n",
      "\u001b[32m[2020-07-17 01:35:11] __main__ INFO: \u001b[0m#params: 36.48M\n",
      "Selected optimization level O0:  Pure FP32 training.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n",
      "\u001b[32m[2020-07-17 01:35:11] __main__ INFO: \u001b[0mVal 0\n",
      "\u001b[32m[2020-07-17 01:35:31] __main__ INFO: \u001b[0mEpoch 0 loss 0.6064 acc@1 0.8516 acc@5 0.9898\n",
      "\u001b[32m[2020-07-17 01:35:31] __main__ INFO: \u001b[0mElapsed 19.99\n",
      "\u001b[32m[2020-07-17 01:35:31] __main__ INFO: \u001b[0mTrain 1 0\n",
      "\u001b[32m[2020-07-17 01:37:30] __main__ INFO: \u001b[0mEpoch 1 Step 100/351 lr 0.000800 loss 0.1540 (0.2967) acc@1 0.9453 (0.9105) acc@5 1.0000 (0.9955)\n",
      "\u001b[32m[2020-07-17 01:39:24] __main__ INFO: \u001b[0mEpoch 1 Step 200/351 lr 0.000800 loss 0.3661 (0.2777) acc@1 0.8750 (0.9150) acc@5 1.0000 (0.9962)\n",
      "\u001b[32m[2020-07-17 03:20:53] __main__ INFO: \u001b[0mEpoch 16 Step 100/351 lr 0.000800 loss 0.0180 (0.0145) acc@1 0.9922 (0.9978) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 03:22:47] __main__ INFO: \u001b[0mEpoch 16 Step 200/351 lr 0.000800 loss 0.0096 (0.0154) acc@1 1.0000 (0.9974) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 03:24:41] __main__ INFO: \u001b[0mEpoch 16 Step 300/351 lr 0.000800 loss 0.0155 (0.0153) acc@1 0.9922 (0.9975) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 03:25:39] __main__ INFO: \u001b[0mEpoch 16 Step 351/351 lr 0.000800 loss 0.0105 (0.0156) acc@1 1.0000 (0.9974) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 03:25:39] __main__ INFO: \u001b[0mElapsed 400.01\n",
      "\u001b[32m[2020-07-17 03:25:39] __main__ INFO: \u001b[0mVal 16\n",
      "\u001b[32m[2020-07-17 03:25:52] __main__ INFO: \u001b[0mEpoch 16 loss 0.2781 acc@1 0.9272 acc@5 0.9960\n",
      "\u001b[32m[2020-07-17 03:25:52] __main__ INFO: \u001b[0mElapsed 13.46\n",
      "\u001b[32m[2020-07-17 03:25:52] __main__ INFO: \u001b[0mTrain 17 5616\n",
      "\u001b[32m[2020-07-17 03:27:46] __main__ INFO: \u001b[0mEpoch 17 Step 100/351 lr 0.000800 loss 0.0123 (0.0137) acc@1 1.0000 (0.9973) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 03:29:40] __main__ INFO: \u001b[0mEpoch 17 Step 200/351 lr 0.000800 loss 0.0217 (0.0156) acc@1 0.9922 (0.9968) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 03:31:34] __main__ INFO: \u001b[0mEpoch 17 Step 300/351 lr 0.000800 loss 0.0109 (0.0153) acc@1 1.0000 (0.9970) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 03:32:32] __main__ INFO: \u001b[0mEpoch 17 Step 351/351 lr 0.000800 loss 0.0060 (0.0154) acc@1 1.0000 (0.9971) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 03:32:32] __main__ INFO: \u001b[0mElapsed 399.98\n",
      "\u001b[32m[2020-07-17 03:32:32] __main__ INFO: \u001b[0mVal 17\n",
      "\u001b[32m[2020-07-17 03:32:46] __main__ INFO: \u001b[0mEpoch 17 loss 0.2584 acc@1 0.9310 acc@5 0.9978\n",
      "\u001b[32m[2020-07-17 03:32:46] __main__ INFO: \u001b[0mElapsed 13.48\n",
      "\u001b[32m[2020-07-17 03:32:46] __main__ INFO: \u001b[0mTrain 18 5967\n",
      "\u001b[32m[2020-07-17 03:34:40] __main__ INFO: \u001b[0mEpoch 18 Step 100/351 lr 0.000800 loss 0.0252 (0.0152) acc@1 0.9922 (0.9970) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 03:36:33] __main__ INFO: \u001b[0mEpoch 18 Step 200/351 lr 0.000800 loss 0.0105 (0.0145) acc@1 1.0000 (0.9975) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 03:38:27] __main__ INFO: \u001b[0mEpoch 18 Step 300/351 lr 0.000800 loss 0.0180 (0.0138) acc@1 0.9922 (0.9976) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 03:39:25] __main__ INFO: \u001b[0mEpoch 18 Step 351/351 lr 0.000800 loss 0.0338 (0.0136) acc@1 0.9844 (0.9977) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 03:39:25] __main__ INFO: \u001b[0mElapsed 399.94\n",
      "\u001b[32m[2020-07-17 03:39:25] __main__ INFO: \u001b[0mVal 18\n",
      "\u001b[32m[2020-07-17 03:39:39] __main__ INFO: \u001b[0mEpoch 18 loss 0.2697 acc@1 0.9290 acc@5 0.9966\n",
      "\u001b[32m[2020-07-17 03:39:39] __main__ INFO: \u001b[0mElapsed 13.45\n",
      "\u001b[32m[2020-07-17 03:39:39] __main__ INFO: \u001b[0mTrain 19 6318\n",
      "\u001b[32m[2020-07-17 03:41:33] __main__ INFO: \u001b[0mEpoch 19 Step 100/351 lr 0.000800 loss 0.0143 (0.0120) acc@1 1.0000 (0.9980) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 03:43:27] __main__ INFO: \u001b[0mEpoch 19 Step 200/351 lr 0.000800 loss 0.0082 (0.0129) acc@1 1.0000 (0.9978) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 03:45:21] __main__ INFO: \u001b[0mEpoch 19 Step 300/351 lr 0.000800 loss 0.0178 (0.0129) acc@1 0.9922 (0.9979) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 03:46:19] __main__ INFO: \u001b[0mEpoch 19 Step 351/351 lr 0.000800 loss 0.0076 (0.0129) acc@1 1.0000 (0.9979) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 03:46:19] __main__ INFO: \u001b[0mElapsed 399.84\n",
      "\u001b[32m[2020-07-17 03:46:19] __main__ INFO: \u001b[0mVal 19\n",
      "\u001b[32m[2020-07-17 03:46:32] __main__ INFO: \u001b[0mEpoch 19 loss 0.2650 acc@1 0.9304 acc@5 0.9974\n",
      "\u001b[32m[2020-07-17 03:46:32] __main__ INFO: \u001b[0mElapsed 13.41\n",
      "\u001b[32m[2020-07-17 03:46:32] __main__ INFO: \u001b[0mTrain 20 6669\n",
      "\u001b[32m[2020-07-17 03:48:26] __main__ INFO: \u001b[0mEpoch 20 Step 100/351 lr 0.000800 loss 0.0047 (0.0117) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 03:50:20] __main__ INFO: \u001b[0mEpoch 20 Step 200/351 lr 0.000800 loss 0.0139 (0.0124) acc@1 0.9922 (0.9980) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 03:52:14] __main__ INFO: \u001b[0mEpoch 20 Step 300/351 lr 0.000800 loss 0.0076 (0.0120) acc@1 1.0000 (0.9981) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 03:53:12] __main__ INFO: \u001b[0mEpoch 20 Step 351/351 lr 0.000800 loss 0.0103 (0.0118) acc@1 1.0000 (0.9982) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 03:53:12] __main__ INFO: \u001b[0mElapsed 399.92\n",
      "\u001b[32m[2020-07-17 03:53:12] __main__ INFO: \u001b[0mVal 20\n",
      "\u001b[32m[2020-07-17 03:53:26] __main__ INFO: \u001b[0mEpoch 20 loss 0.2695 acc@1 0.9330 acc@5 0.9964\n",
      "\u001b[32m[2020-07-17 03:53:26] __main__ INFO: \u001b[0mElapsed 13.43\n",
      "\u001b[32m[2020-07-17 03:53:26] __main__ INFO: \u001b[0mTrain 21 7020\n",
      "\u001b[32m[2020-07-17 03:55:20] __main__ INFO: \u001b[0mEpoch 21 Step 100/351 lr 0.000800 loss 0.0055 (0.0096) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 03:57:13] __main__ INFO: \u001b[0mEpoch 21 Step 200/351 lr 0.000800 loss 0.0390 (0.0107) acc@1 0.9922 (0.9982) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 03:59:07] __main__ INFO: \u001b[0mEpoch 21 Step 300/351 lr 0.000800 loss 0.0044 (0.0102) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 04:00:05] __main__ INFO: \u001b[0mEpoch 21 Step 351/351 lr 0.000800 loss 0.0098 (0.0101) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 04:00:05] __main__ INFO: \u001b[0mElapsed 399.84\n",
      "\u001b[32m[2020-07-17 04:00:05] __main__ INFO: \u001b[0mVal 21\n",
      "\u001b[32m[2020-07-17 04:00:19] __main__ INFO: \u001b[0mEpoch 21 loss 0.2642 acc@1 0.9330 acc@5 0.9972\n",
      "\u001b[32m[2020-07-17 04:00:19] __main__ INFO: \u001b[0mElapsed 13.45\n",
      "\u001b[32m[2020-07-17 04:00:19] __main__ INFO: \u001b[0mTrain 22 7371\n",
      "\u001b[32m[2020-07-17 04:02:13] __main__ INFO: \u001b[0mEpoch 22 Step 100/351 lr 0.000800 loss 0.0105 (0.0093) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 04:04:07] __main__ INFO: \u001b[0mEpoch 22 Step 200/351 lr 0.000800 loss 0.0069 (0.0090) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 04:06:01] __main__ INFO: \u001b[0mEpoch 22 Step 300/351 lr 0.000800 loss 0.0141 (0.0095) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 04:06:59] __main__ INFO: \u001b[0mEpoch 22 Step 351/351 lr 0.000800 loss 0.0121 (0.0097) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 04:06:59] __main__ INFO: \u001b[0mElapsed 399.93\n",
      "\u001b[32m[2020-07-17 04:06:59] __main__ INFO: \u001b[0mVal 22\n",
      "\u001b[32m[2020-07-17 04:07:12] __main__ INFO: \u001b[0mEpoch 22 loss 0.2783 acc@1 0.9312 acc@5 0.9970\n",
      "\u001b[32m[2020-07-17 04:07:12] __main__ INFO: \u001b[0mElapsed 13.40\n",
      "\u001b[32m[2020-07-17 04:07:12] __main__ INFO: \u001b[0mTrain 23 7722\n",
      "\u001b[32m[2020-07-17 04:09:06] __main__ INFO: \u001b[0mEpoch 23 Step 100/351 lr 0.000800 loss 0.0338 (0.0108) acc@1 0.9922 (0.9980) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 04:11:00] __main__ INFO: \u001b[0mEpoch 23 Step 200/351 lr 0.000800 loss 0.0084 (0.0102) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 04:12:54] __main__ INFO: \u001b[0mEpoch 23 Step 300/351 lr 0.000800 loss 0.0198 (0.0098) acc@1 0.9922 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 04:13:52] __main__ INFO: \u001b[0mEpoch 23 Step 351/351 lr 0.000800 loss 0.0080 (0.0097) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 04:13:52] __main__ INFO: \u001b[0mElapsed 399.93\n",
      "\u001b[32m[2020-07-17 04:13:52] __main__ INFO: \u001b[0mVal 23\n",
      "\u001b[32m[2020-07-17 04:14:06] __main__ INFO: \u001b[0mEpoch 23 loss 0.2650 acc@1 0.9348 acc@5 0.9968\n",
      "\u001b[32m[2020-07-17 04:14:06] __main__ INFO: \u001b[0mElapsed 13.41\n",
      "\u001b[32m[2020-07-17 04:14:06] __main__ INFO: \u001b[0mTrain 24 8073\n",
      "\u001b[32m[2020-07-17 04:16:00] __main__ INFO: \u001b[0mEpoch 24 Step 100/351 lr 0.000800 loss 0.0108 (0.0093) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 04:29:46] __main__ INFO: \u001b[0mEpoch 26 Step 100/351 lr 0.000800 loss 0.0079 (0.0085) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 04:31:40] __main__ INFO: \u001b[0mEpoch 26 Step 200/351 lr 0.000800 loss 0.0132 (0.0087) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 04:33:33] __main__ INFO: \u001b[0mEpoch 26 Step 300/351 lr 0.000800 loss 0.0050 (0.0086) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 04:34:31] __main__ INFO: \u001b[0mEpoch 26 Step 351/351 lr 0.000800 loss 0.0228 (0.0088) acc@1 0.9922 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 04:34:31] __main__ INFO: \u001b[0mElapsed 399.63\n",
      "\u001b[32m[2020-07-17 04:34:32] __main__ INFO: \u001b[0mVal 26\n",
      "\u001b[32m[2020-07-17 04:34:45] __main__ INFO: \u001b[0mEpoch 26 loss 0.2673 acc@1 0.9348 acc@5 0.9974\n",
      "\u001b[32m[2020-07-17 04:34:45] __main__ INFO: \u001b[0mElapsed 13.43\n",
      "\u001b[32m[2020-07-17 04:34:45] __main__ INFO: \u001b[0mTrain 27 9126\n",
      "\u001b[32m[2020-07-17 04:36:39] __main__ INFO: \u001b[0mEpoch 27 Step 100/351 lr 0.000800 loss 0.0131 (0.0077) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 04:38:33] __main__ INFO: \u001b[0mEpoch 27 Step 200/351 lr 0.000800 loss 0.0034 (0.0076) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 04:40:27] __main__ INFO: \u001b[0mEpoch 27 Step 300/351 lr 0.000800 loss 0.0057 (0.0079) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 04:41:25] __main__ INFO: \u001b[0mEpoch 27 Step 351/351 lr 0.000800 loss 0.0067 (0.0080) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 04:41:25] __main__ INFO: \u001b[0mElapsed 399.70\n",
      "\u001b[32m[2020-07-17 04:41:25] __main__ INFO: \u001b[0mVal 27\n",
      "\u001b[32m[2020-07-17 04:41:38] __main__ INFO: \u001b[0mEpoch 27 loss 0.2972 acc@1 0.9296 acc@5 0.9964\n",
      "\u001b[32m[2020-07-17 04:41:38] __main__ INFO: \u001b[0mElapsed 13.44\n",
      "\u001b[32m[2020-07-17 04:41:38] __main__ INFO: \u001b[0mTrain 28 9477\n",
      "\u001b[32m[2020-07-17 04:43:32] __main__ INFO: \u001b[0mEpoch 28 Step 100/351 lr 0.000800 loss 0.0044 (0.0087) acc@1 1.0000 (0.9981) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 04:45:26] __main__ INFO: \u001b[0mEpoch 28 Step 200/351 lr 0.000800 loss 0.0078 (0.0088) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 04:47:20] __main__ INFO: \u001b[0mEpoch 28 Step 300/351 lr 0.000800 loss 0.0045 (0.0086) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 04:48:18] __main__ INFO: \u001b[0mEpoch 28 Step 351/351 lr 0.000800 loss 0.0034 (0.0087) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 04:48:18] __main__ INFO: \u001b[0mElapsed 399.53\n",
      "\u001b[32m[2020-07-17 04:48:18] __main__ INFO: \u001b[0mVal 28\n",
      "\u001b[32m[2020-07-17 04:48:31] __main__ INFO: \u001b[0mEpoch 28 loss 0.2728 acc@1 0.9342 acc@5 0.9960\n",
      "\u001b[32m[2020-07-17 04:48:31] __main__ INFO: \u001b[0mElapsed 13.43\n",
      "\u001b[32m[2020-07-17 04:48:31] __main__ INFO: \u001b[0mTrain 29 9828\n",
      "\u001b[32m[2020-07-17 04:50:25] __main__ INFO: \u001b[0mEpoch 29 Step 100/351 lr 0.000800 loss 0.0043 (0.0062) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 04:52:19] __main__ INFO: \u001b[0mEpoch 29 Step 200/351 lr 0.000800 loss 0.0040 (0.0066) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 04:54:13] __main__ INFO: \u001b[0mEpoch 29 Step 300/351 lr 0.000800 loss 0.0032 (0.0069) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 04:55:11] __main__ INFO: \u001b[0mEpoch 29 Step 351/351 lr 0.000800 loss 0.0063 (0.0069) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 04:55:11] __main__ INFO: \u001b[0mElapsed 399.63\n",
      "\u001b[32m[2020-07-17 04:55:11] __main__ INFO: \u001b[0mVal 29\n",
      "\u001b[32m[2020-07-17 04:55:24] __main__ INFO: \u001b[0mEpoch 29 loss 0.2640 acc@1 0.9356 acc@5 0.9968\n",
      "\u001b[32m[2020-07-17 04:55:24] __main__ INFO: \u001b[0mElapsed 13.44\n",
      "\u001b[32m[2020-07-17 04:55:24] __main__ INFO: \u001b[0mTrain 30 10179\n",
      "\u001b[32m[2020-07-17 04:57:18] __main__ INFO: \u001b[0mEpoch 30 Step 100/351 lr 0.000800 loss 0.0044 (0.0064) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 04:59:12] __main__ INFO: \u001b[0mEpoch 30 Step 200/351 lr 0.000800 loss 0.0079 (0.0061) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 05:01:06] __main__ INFO: \u001b[0mEpoch 30 Step 300/351 lr 0.000800 loss 0.0034 (0.0066) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 05:02:04] __main__ INFO: \u001b[0mEpoch 30 Step 351/351 lr 0.000800 loss 0.0030 (0.0067) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 05:02:04] __main__ INFO: \u001b[0mElapsed 399.76\n",
      "\u001b[32m[2020-07-17 05:02:04] __main__ INFO: \u001b[0mVal 30\n",
      "\u001b[32m[2020-07-17 05:02:17] __main__ INFO: \u001b[0mEpoch 30 loss 0.2714 acc@1 0.9340 acc@5 0.9964\n",
      "\u001b[32m[2020-07-17 05:02:17] __main__ INFO: \u001b[0mElapsed 13.44\n",
      "\u001b[32m[2020-07-17 05:02:17] __main__ INFO: \u001b[0mTrain 31 10530\n",
      "\u001b[32m[2020-07-17 05:04:11] __main__ INFO: \u001b[0mEpoch 31 Step 100/351 lr 0.000800 loss 0.0042 (0.0077) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 05:06:05] __main__ INFO: \u001b[0mEpoch 31 Step 200/351 lr 0.000800 loss 0.0045 (0.0072) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 05:07:59] __main__ INFO: \u001b[0mEpoch 31 Step 300/351 lr 0.000800 loss 0.0039 (0.0071) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 05:08:57] __main__ INFO: \u001b[0mEpoch 31 Step 351/351 lr 0.000800 loss 0.0033 (0.0072) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 05:08:57] __main__ INFO: \u001b[0mElapsed 399.75\n",
      "\u001b[32m[2020-07-17 05:08:57] __main__ INFO: \u001b[0mVal 31\n",
      "\u001b[32m[2020-07-17 05:09:10] __main__ INFO: \u001b[0mEpoch 31 loss 0.2706 acc@1 0.9350 acc@5 0.9968\n",
      "\u001b[32m[2020-07-17 05:09:10] __main__ INFO: \u001b[0mElapsed 13.43\n",
      "\u001b[32m[2020-07-17 05:09:10] __main__ INFO: \u001b[0mTrain 32 10881\n",
      "\u001b[32m[2020-07-17 05:11:04] __main__ INFO: \u001b[0mEpoch 32 Step 100/351 lr 0.000800 loss 0.0102 (0.0055) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 05:12:58] __main__ INFO: \u001b[0mEpoch 32 Step 200/351 lr 0.000800 loss 0.0027 (0.0057) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 05:14:52] __main__ INFO: \u001b[0mEpoch 32 Step 300/351 lr 0.000800 loss 0.0104 (0.0059) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 05:15:50] __main__ INFO: \u001b[0mEpoch 32 Step 351/351 lr 0.000800 loss 0.0102 (0.0061) acc@1 0.9922 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 05:15:50] __main__ INFO: \u001b[0mElapsed 399.79\n",
      "\u001b[32m[2020-07-17 05:15:50] __main__ INFO: \u001b[0mVal 32\n",
      "\u001b[32m[2020-07-17 05:16:04] __main__ INFO: \u001b[0mEpoch 32 loss 0.2644 acc@1 0.9356 acc@5 0.9962\n",
      "\u001b[32m[2020-07-17 05:16:04] __main__ INFO: \u001b[0mElapsed 13.42\n",
      "\u001b[32m[2020-07-17 05:16:04] __main__ INFO: \u001b[0mTrain 33 11232\n",
      "\u001b[32m[2020-07-17 05:17:58] __main__ INFO: \u001b[0mEpoch 33 Step 100/351 lr 0.000800 loss 0.0028 (0.0061) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 05:19:51] __main__ INFO: \u001b[0mEpoch 33 Step 200/351 lr 0.000800 loss 0.0067 (0.0059) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 05:21:45] __main__ INFO: \u001b[0mEpoch 33 Step 300/351 lr 0.000800 loss 0.0036 (0.0056) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 05:22:43] __main__ INFO: \u001b[0mEpoch 33 Step 351/351 lr 0.000800 loss 0.0023 (0.0056) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 05:22:43] __main__ INFO: \u001b[0mElapsed 399.64\n",
      "\u001b[32m[2020-07-17 05:22:43] __main__ INFO: \u001b[0mVal 33\n",
      "\u001b[32m[2020-07-17 05:22:57] __main__ INFO: \u001b[0mEpoch 33 loss 0.2660 acc@1 0.9334 acc@5 0.9960\n",
      "\u001b[32m[2020-07-17 05:22:57] __main__ INFO: \u001b[0mElapsed 13.41\n",
      "\u001b[32m[2020-07-17 05:22:57] __main__ INFO: \u001b[0mTrain 34 11583\n",
      "\u001b[32m[2020-07-17 05:24:51] __main__ INFO: \u001b[0mEpoch 34 Step 100/351 lr 0.000800 loss 0.0049 (0.0065) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 05:26:45] __main__ INFO: \u001b[0mEpoch 34 Step 200/351 lr 0.000800 loss 0.0065 (0.0060) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 05:28:38] __main__ INFO: \u001b[0mEpoch 34 Step 300/351 lr 0.000800 loss 0.0034 (0.0058) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 05:29:37] __main__ INFO: \u001b[0mEpoch 34 Step 351/351 lr 0.000800 loss 0.0093 (0.0057) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 05:29:37] __main__ INFO: \u001b[0mElapsed 399.80\n",
      "\u001b[32m[2020-07-17 05:29:37] __main__ INFO: \u001b[0mVal 34\n",
      "\u001b[32m[2020-07-17 05:29:50] __main__ INFO: \u001b[0mEpoch 34 loss 0.2653 acc@1 0.9364 acc@5 0.9964\n",
      "\u001b[32m[2020-07-17 05:29:50] __main__ INFO: \u001b[0mElapsed 13.42\n",
      "\u001b[32m[2020-07-17 05:29:50] __main__ INFO: \u001b[0mTrain 35 11934\n",
      "\u001b[32m[2020-07-17 05:31:44] __main__ INFO: \u001b[0mEpoch 35 Step 100/351 lr 0.000800 loss 0.0036 (0.0054) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 05:33:38] __main__ INFO: \u001b[0mEpoch 35 Step 200/351 lr 0.000800 loss 0.0021 (0.0056) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 05:35:32] __main__ INFO: \u001b[0mEpoch 35 Step 300/351 lr 0.000800 loss 0.0031 (0.0056) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 05:36:30] __main__ INFO: \u001b[0mEpoch 35 Step 351/351 lr 0.000800 loss 0.0046 (0.0058) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 05:36:30] __main__ INFO: \u001b[0mElapsed 399.73\n",
      "\u001b[32m[2020-07-17 05:36:30] __main__ INFO: \u001b[0mVal 35\n",
      "\u001b[32m[2020-07-17 05:36:43] __main__ INFO: \u001b[0mEpoch 35 loss 0.2703 acc@1 0.9338 acc@5 0.9970\n",
      "\u001b[32m[2020-07-17 05:36:43] __main__ INFO: \u001b[0mElapsed 13.42\n",
      "\u001b[32m[2020-07-17 05:36:43] __main__ INFO: \u001b[0mTrain 36 12285\n",
      "\u001b[32m[2020-07-17 05:38:37] __main__ INFO: \u001b[0mEpoch 36 Step 100/351 lr 0.000800 loss 0.0031 (0.0056) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 05:40:31] __main__ INFO: \u001b[0mEpoch 36 Step 200/351 lr 0.000800 loss 0.0044 (0.0054) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 05:42:25] __main__ INFO: \u001b[0mEpoch 36 Step 300/351 lr 0.000800 loss 0.0040 (0.0054) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 05:43:23] __main__ INFO: \u001b[0mEpoch 36 Step 351/351 lr 0.000800 loss 0.0081 (0.0054) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 05:43:23] __main__ INFO: \u001b[0mElapsed 399.70\n",
      "\u001b[32m[2020-07-17 05:43:23] __main__ INFO: \u001b[0mVal 36\n",
      "\u001b[32m[2020-07-17 05:43:36] __main__ INFO: \u001b[0mEpoch 36 loss 0.2733 acc@1 0.9322 acc@5 0.9962\n",
      "\u001b[32m[2020-07-17 05:43:36] __main__ INFO: \u001b[0mElapsed 13.45\n",
      "\u001b[32m[2020-07-17 05:43:36] __main__ INFO: \u001b[0mTrain 37 12636\n",
      "\u001b[32m[2020-07-17 05:45:30] __main__ INFO: \u001b[0mEpoch 37 Step 100/351 lr 0.000800 loss 0.0033 (0.0057) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 05:47:24] __main__ INFO: \u001b[0mEpoch 37 Step 200/351 lr 0.000800 loss 0.0030 (0.0052) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 05:49:18] __main__ INFO: \u001b[0mEpoch 37 Step 300/351 lr 0.000800 loss 0.0052 (0.0054) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 05:50:16] __main__ INFO: \u001b[0mEpoch 37 Step 351/351 lr 0.000800 loss 0.0031 (0.0053) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 05:50:16] __main__ INFO: \u001b[0mElapsed 399.56\n",
      "\u001b[32m[2020-07-17 05:50:16] __main__ INFO: \u001b[0mVal 37\n",
      "\u001b[32m[2020-07-17 05:50:29] __main__ INFO: \u001b[0mEpoch 37 loss 0.2721 acc@1 0.9346 acc@5 0.9958\n",
      "\u001b[32m[2020-07-17 05:50:29] __main__ INFO: \u001b[0mElapsed 13.46\n",
      "\u001b[32m[2020-07-17 05:50:29] __main__ INFO: \u001b[0mTrain 38 12987\n",
      "\u001b[32m[2020-07-17 05:52:23] __main__ INFO: \u001b[0mEpoch 38 Step 100/351 lr 0.000800 loss 0.0025 (0.0050) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 05:54:17] __main__ INFO: \u001b[0mEpoch 38 Step 200/351 lr 0.000800 loss 0.0034 (0.0045) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 05:56:11] __main__ INFO: \u001b[0mEpoch 38 Step 300/351 lr 0.000800 loss 0.0035 (0.0046) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 05:57:09] __main__ INFO: \u001b[0mEpoch 38 Step 351/351 lr 0.000800 loss 0.0022 (0.0047) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 05:57:09] __main__ INFO: \u001b[0mElapsed 399.60\n",
      "\u001b[32m[2020-07-17 05:57:09] __main__ INFO: \u001b[0mVal 38\n",
      "\u001b[32m[2020-07-17 05:57:22] __main__ INFO: \u001b[0mEpoch 38 loss 0.2697 acc@1 0.9350 acc@5 0.9968\n",
      "\u001b[32m[2020-07-17 05:57:22] __main__ INFO: \u001b[0mElapsed 13.43\n",
      "\u001b[32m[2020-07-17 05:57:22] __main__ INFO: \u001b[0mTrain 39 13338\n",
      "\u001b[32m[2020-07-17 05:59:16] __main__ INFO: \u001b[0mEpoch 39 Step 100/351 lr 0.000800 loss 0.0027 (0.0050) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 06:01:10] __main__ INFO: \u001b[0mEpoch 39 Step 200/351 lr 0.000800 loss 0.0040 (0.0048) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 06:03:04] __main__ INFO: \u001b[0mEpoch 39 Step 300/351 lr 0.000800 loss 0.0089 (0.0049) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 06:04:02] __main__ INFO: \u001b[0mEpoch 39 Step 351/351 lr 0.000800 loss 0.0049 (0.0049) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 06:04:02] __main__ INFO: \u001b[0mElapsed 399.60\n",
      "\u001b[32m[2020-07-17 06:04:02] __main__ INFO: \u001b[0mVal 39\n",
      "\u001b[32m[2020-07-17 06:04:15] __main__ INFO: \u001b[0mEpoch 39 loss 0.2708 acc@1 0.9348 acc@5 0.9966\n",
      "\u001b[32m[2020-07-17 06:04:15] __main__ INFO: \u001b[0mElapsed 13.44\n",
      "\u001b[32m[2020-07-17 06:04:15] __main__ INFO: \u001b[0mTrain 40 13689\n",
      "\u001b[32m[2020-07-17 06:06:09] __main__ INFO: \u001b[0mEpoch 40 Step 100/351 lr 0.000800 loss 0.0029 (0.0049) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 06:08:03] __main__ INFO: \u001b[0mEpoch 40 Step 200/351 lr 0.000800 loss 0.0148 (0.0049) acc@1 0.9922 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 06:09:57] __main__ INFO: \u001b[0mEpoch 40 Step 300/351 lr 0.000800 loss 0.0032 (0.0047) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 06:10:55] __main__ INFO: \u001b[0mEpoch 40 Step 351/351 lr 0.000800 loss 0.0061 (0.0047) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 06:10:55] __main__ INFO: \u001b[0mElapsed 399.62\n",
      "\u001b[32m[2020-07-17 06:10:55] __main__ INFO: \u001b[0mVal 40\n",
      "\u001b[32m[2020-07-17 06:11:08] __main__ INFO: \u001b[0mEpoch 40 loss 0.2715 acc@1 0.9332 acc@5 0.9964\n",
      "\u001b[32m[2020-07-17 06:11:08] __main__ INFO: \u001b[0mElapsed 13.45\n",
      "\u001b[32m[2020-07-17 06:11:08] __main__ INFO: \u001b[0mTrain 41 14040\n",
      "\u001b[32m[2020-07-17 06:13:02] __main__ INFO: \u001b[0mEpoch 41 Step 100/351 lr 0.000800 loss 0.0031 (0.0043) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 06:14:56] __main__ INFO: \u001b[0mEpoch 41 Step 200/351 lr 0.000800 loss 0.0123 (0.0044) acc@1 0.9922 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 06:16:50] __main__ INFO: \u001b[0mEpoch 41 Step 300/351 lr 0.000800 loss 0.0036 (0.0044) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 06:17:48] __main__ INFO: \u001b[0mEpoch 41 Step 351/351 lr 0.000800 loss 0.0031 (0.0044) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 06:17:48] __main__ INFO: \u001b[0mElapsed 399.65\n",
      "\u001b[32m[2020-07-17 06:17:48] __main__ INFO: \u001b[0mVal 41\n",
      "\u001b[32m[2020-07-17 06:18:02] __main__ INFO: \u001b[0mEpoch 41 loss 0.2646 acc@1 0.9342 acc@5 0.9956\n",
      "\u001b[32m[2020-07-17 06:18:02] __main__ INFO: \u001b[0mElapsed 13.41\n",
      "\u001b[32m[2020-07-17 06:18:02] __main__ INFO: \u001b[0mTrain 42 14391\n",
      "\u001b[32m[2020-07-17 06:19:55] __main__ INFO: \u001b[0mEpoch 42 Step 100/351 lr 0.000800 loss 0.0023 (0.0043) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 06:21:49] __main__ INFO: \u001b[0mEpoch 42 Step 200/351 lr 0.000800 loss 0.0026 (0.0044) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 06:23:43] __main__ INFO: \u001b[0mEpoch 42 Step 300/351 lr 0.000800 loss 0.0230 (0.0045) acc@1 0.9922 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 06:24:41] __main__ INFO: \u001b[0mEpoch 42 Step 351/351 lr 0.000800 loss 0.0025 (0.0047) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 06:24:41] __main__ INFO: \u001b[0mElapsed 399.60\n",
      "\u001b[32m[2020-07-17 06:24:41] __main__ INFO: \u001b[0mVal 42\n",
      "\u001b[32m[2020-07-17 06:24:55] __main__ INFO: \u001b[0mEpoch 42 loss 0.2773 acc@1 0.9324 acc@5 0.9954\n",
      "\u001b[32m[2020-07-17 06:24:55] __main__ INFO: \u001b[0mElapsed 13.43\n",
      "\u001b[32m[2020-07-17 06:24:55] __main__ INFO: \u001b[0mTrain 43 14742\n",
      "\u001b[32m[2020-07-17 06:26:49] __main__ INFO: \u001b[0mEpoch 43 Step 100/351 lr 0.000800 loss 0.0037 (0.0047) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 06:28:42] __main__ INFO: \u001b[0mEpoch 43 Step 200/351 lr 0.000800 loss 0.0016 (0.0047) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 06:30:36] __main__ INFO: \u001b[0mEpoch 43 Step 300/351 lr 0.000800 loss 0.0075 (0.0045) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 06:31:34] __main__ INFO: \u001b[0mEpoch 43 Step 351/351 lr 0.000800 loss 0.0026 (0.0044) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 06:31:34] __main__ INFO: \u001b[0mElapsed 399.76\n",
      "\u001b[32m[2020-07-17 06:31:34] __main__ INFO: \u001b[0mVal 43\n",
      "\u001b[32m[2020-07-17 06:31:48] __main__ INFO: \u001b[0mEpoch 43 loss 0.2698 acc@1 0.9352 acc@5 0.9964\n",
      "\u001b[32m[2020-07-17 06:31:48] __main__ INFO: \u001b[0mElapsed 13.44\n",
      "\u001b[32m[2020-07-17 06:31:48] __main__ INFO: \u001b[0mTrain 44 15093\n",
      "\u001b[32m[2020-07-17 06:33:42] __main__ INFO: \u001b[0mEpoch 44 Step 100/351 lr 0.000800 loss 0.0024 (0.0037) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 06:35:36] __main__ INFO: \u001b[0mEpoch 44 Step 200/351 lr 0.000800 loss 0.0036 (0.0040) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 06:37:29] __main__ INFO: \u001b[0mEpoch 44 Step 300/351 lr 0.000800 loss 0.0198 (0.0045) acc@1 0.9922 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 06:38:27] __main__ INFO: \u001b[0mEpoch 44 Step 351/351 lr 0.000800 loss 0.0025 (0.0046) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 06:38:27] __main__ INFO: \u001b[0mElapsed 399.68\n",
      "\u001b[32m[2020-07-17 06:38:27] __main__ INFO: \u001b[0mVal 44\n",
      "\u001b[32m[2020-07-17 06:38:41] __main__ INFO: \u001b[0mEpoch 44 loss 0.2716 acc@1 0.9342 acc@5 0.9960\n",
      "\u001b[32m[2020-07-17 06:38:41] __main__ INFO: \u001b[0mElapsed 13.42\n",
      "\u001b[32m[2020-07-17 06:38:41] __main__ INFO: \u001b[0mTrain 45 15444\n",
      "\u001b[32m[2020-07-17 06:40:35] __main__ INFO: \u001b[0mEpoch 45 Step 100/351 lr 0.000800 loss 0.0021 (0.0040) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 06:42:29] __main__ INFO: \u001b[0mEpoch 45 Step 200/351 lr 0.000800 loss 0.0090 (0.0041) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 06:44:22] __main__ INFO: \u001b[0mEpoch 45 Step 300/351 lr 0.000800 loss 0.0051 (0.0040) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 06:45:20] __main__ INFO: \u001b[0mEpoch 45 Step 351/351 lr 0.000800 loss 0.0030 (0.0039) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 06:45:20] __main__ INFO: \u001b[0mElapsed 399.58\n",
      "\u001b[32m[2020-07-17 06:45:20] __main__ INFO: \u001b[0mVal 45\n",
      "\u001b[32m[2020-07-17 06:45:34] __main__ INFO: \u001b[0mEpoch 45 loss 0.2681 acc@1 0.9344 acc@5 0.9962\n",
      "\u001b[32m[2020-07-17 06:45:34] __main__ INFO: \u001b[0mElapsed 13.40\n",
      "\u001b[32m[2020-07-17 06:45:34] __main__ INFO: \u001b[0mTrain 46 15795\n",
      "\u001b[32m[2020-07-17 06:47:28] __main__ INFO: \u001b[0mEpoch 46 Step 100/351 lr 0.000800 loss 0.0056 (0.0043) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 06:49:22] __main__ INFO: \u001b[0mEpoch 46 Step 200/351 lr 0.000800 loss 0.0022 (0.0042) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 06:51:15] __main__ INFO: \u001b[0mEpoch 46 Step 300/351 lr 0.000800 loss 0.0020 (0.0040) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 06:52:13] __main__ INFO: \u001b[0mEpoch 46 Step 351/351 lr 0.000800 loss 0.0095 (0.0040) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 06:52:13] __main__ INFO: \u001b[0mElapsed 399.58\n",
      "\u001b[32m[2020-07-17 06:52:13] __main__ INFO: \u001b[0mVal 46\n",
      "\u001b[32m[2020-07-17 06:52:27] __main__ INFO: \u001b[0mEpoch 46 loss 0.2655 acc@1 0.9356 acc@5 0.9964\n",
      "\u001b[32m[2020-07-17 06:52:27] __main__ INFO: \u001b[0mElapsed 13.41\n",
      "\u001b[32m[2020-07-17 06:52:27] __main__ INFO: \u001b[0mTrain 47 16146\n",
      "\u001b[32m[2020-07-17 06:54:21] __main__ INFO: \u001b[0mEpoch 47 Step 100/351 lr 0.000800 loss 0.0019 (0.0035) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 06:56:15] __main__ INFO: \u001b[0mEpoch 47 Step 200/351 lr 0.000800 loss 0.0031 (0.0035) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 06:58:08] __main__ INFO: \u001b[0mEpoch 47 Step 300/351 lr 0.000800 loss 0.0030 (0.0034) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 06:59:06] __main__ INFO: \u001b[0mEpoch 47 Step 351/351 lr 0.000800 loss 0.0027 (0.0034) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 06:59:06] __main__ INFO: \u001b[0mElapsed 399.55\n",
      "\u001b[32m[2020-07-17 06:59:06] __main__ INFO: \u001b[0mVal 47\n",
      "\u001b[32m[2020-07-17 06:59:20] __main__ INFO: \u001b[0mEpoch 47 loss 0.2684 acc@1 0.9362 acc@5 0.9964\n",
      "\u001b[32m[2020-07-17 06:59:20] __main__ INFO: \u001b[0mElapsed 13.39\n",
      "\u001b[32m[2020-07-17 06:59:20] __main__ INFO: \u001b[0mTrain 48 16497\n",
      "\u001b[32m[2020-07-17 07:01:14] __main__ INFO: \u001b[0mEpoch 48 Step 100/351 lr 0.000800 loss 0.0020 (0.0038) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 07:03:07] __main__ INFO: \u001b[0mEpoch 48 Step 200/351 lr 0.000800 loss 0.0024 (0.0039) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 07:05:01] __main__ INFO: \u001b[0mEpoch 48 Step 300/351 lr 0.000800 loss 0.0275 (0.0041) acc@1 0.9922 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 07:05:59] __main__ INFO: \u001b[0mEpoch 48 Step 351/351 lr 0.000800 loss 0.0070 (0.0040) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 07:05:59] __main__ INFO: \u001b[0mElapsed 399.60\n",
      "\u001b[32m[2020-07-17 07:05:59] __main__ INFO: \u001b[0mVal 48\n",
      "\u001b[32m[2020-07-17 07:06:13] __main__ INFO: \u001b[0mEpoch 48 loss 0.2668 acc@1 0.9344 acc@5 0.9958\n",
      "\u001b[32m[2020-07-17 07:06:13] __main__ INFO: \u001b[0mElapsed 13.47\n",
      "\u001b[32m[2020-07-17 07:06:13] __main__ INFO: \u001b[0mTrain 49 16848\n",
      "\u001b[32m[2020-07-17 07:08:07] __main__ INFO: \u001b[0mEpoch 49 Step 100/351 lr 0.000800 loss 0.0019 (0.0039) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 07:10:01] __main__ INFO: \u001b[0mEpoch 49 Step 200/351 lr 0.000800 loss 0.0026 (0.0037) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 07:11:54] __main__ INFO: \u001b[0mEpoch 49 Step 300/351 lr 0.000800 loss 0.0034 (0.0038) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 07:12:52] __main__ INFO: \u001b[0mEpoch 49 Step 351/351 lr 0.000800 loss 0.0043 (0.0038) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 07:12:52] __main__ INFO: \u001b[0mElapsed 399.56\n",
      "\u001b[32m[2020-07-17 07:12:52] __main__ INFO: \u001b[0mVal 49\n",
      "\u001b[32m[2020-07-17 07:13:06] __main__ INFO: \u001b[0mEpoch 49 loss 0.2736 acc@1 0.9352 acc@5 0.9952\n",
      "\u001b[32m[2020-07-17 07:13:06] __main__ INFO: \u001b[0mElapsed 13.44\n",
      "\u001b[32m[2020-07-17 07:13:06] __main__ INFO: \u001b[0mTrain 50 17199\n",
      "\u001b[32m[2020-07-17 07:15:00] __main__ INFO: \u001b[0mEpoch 50 Step 100/351 lr 0.000800 loss 0.0034 (0.0041) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 07:16:54] __main__ INFO: \u001b[0mEpoch 50 Step 200/351 lr 0.000800 loss 0.0034 (0.0040) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 07:18:47] __main__ INFO: \u001b[0mEpoch 50 Step 300/351 lr 0.000800 loss 0.0017 (0.0040) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 07:19:45] __main__ INFO: \u001b[0mEpoch 50 Step 351/351 lr 0.000800 loss 0.0046 (0.0039) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-17 07:19:45] __main__ INFO: \u001b[0mElapsed 399.61\n",
      "\u001b[32m[2020-07-17 07:19:45] __main__ INFO: \u001b[0mVal 50\n",
      "\u001b[32m[2020-07-17 07:19:59] __main__ INFO: \u001b[0mEpoch 50 loss 0.2719 acc@1 0.9342 acc@5 0.9960\n",
      "\u001b[32m[2020-07-17 07:19:59] __main__ INFO: \u001b[0mElapsed 13.41\n",
      "\u001b[32m[2020-07-17 07:19:59] fvcore.common.checkpoint INFO: \u001b[0mSaving checkpoint to /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_20_c10val/exp00_resume400_50/checkpoint_00050.pth\n"
     ]
    }
   ],
   "source": [
    "# Resume training with the un-augmented data\n",
    "os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "!python train.py --config /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_20_c10val/exp00/config.yaml \\\n",
    "    train.checkpoint /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_20_c10val/exp00/checkpoint_00400.pth \\\n",
    "    dataset.name CIFAR10 \\\n",
    "    train.base_lr 0.0008 \\\n",
    "    train.output_dir /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_20_c10val/exp00_resume400_50 \\\n",
    "    scheduler.epochs 50\n",
    "\n",
    "#### Set LEARNING RATE based on ending LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-17 12:19:31] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_20_c10val/exp00/checkpoint_00400.pth\n",
      "Files already downloaded and verified\n",
      "100%|███████████████████████████████████████████| 79/79 [00:26<00:00,  2.93it/s]\n",
      "\u001b[32m[2020-07-17 12:19:59] __main__ INFO: \u001b[0mElapsed 26.97\n",
      "\u001b[32m[2020-07-17 12:19:59] __main__ INFO: \u001b[0mLoss 0.6113 Accuracy 0.8456\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10 test dataset - without training on unaugmented data\n",
    "# Right the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/wrn.yaml \\\n",
    "   test.batch_size 128 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_20_c10val/exp00/checkpoint_00400.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_20_c10val/exp00/test_results_0400_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-17 12:20:21] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_20_c10val/exp00/checkpoint_00400.pth\n",
      "CIFAR 10.1\n",
      "100%|███████████████████████████████████████████| 16/16 [00:05<00:00,  2.81it/s]\n",
      "\u001b[32m[2020-07-17 12:20:27] __main__ INFO: \u001b[0mElapsed 5.70\n",
      "\u001b[32m[2020-07-17 12:20:27] __main__ INFO: \u001b[0mLoss 1.1302 Accuracy 0.7365\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10 test dataset - without training on unaugmented data\n",
    "# Write the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/wrn.yaml \\\n",
    "   test.batch_size 128 \\\n",
    "   dataset.name CIFAR101 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_20_c10val/exp00/checkpoint_00400.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_20_c10val/exp00/test_results_0400_cifar101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-17 12:20:48] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_20_c10val/exp00_resume400_50/checkpoint_00050.pth\n",
      "Files already downloaded and verified\n",
      "100%|███████████████████████████████████████████| 79/79 [00:27<00:00,  2.92it/s]\n",
      "\u001b[32m[2020-07-17 12:21:16] __main__ INFO: \u001b[0mElapsed 27.05\n",
      "\u001b[32m[2020-07-17 12:21:16] __main__ INFO: \u001b[0mLoss 0.2748 Accuracy 0.9333\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10 test dataset \n",
    "# Write the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/wrn.yaml \\\n",
    "   test.batch_size 128 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_20_c10val/exp00_resume400_50/checkpoint_00050.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_20_c10val/exp00_resume400_50/test_results_0050_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-17 12:21:38] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_20_c10val/exp00_resume400_50/checkpoint_00050.pth\n",
      "CIFAR 10.1\n",
      "100%|███████████████████████████████████████████| 16/16 [00:05<00:00,  2.80it/s]\n",
      "\u001b[32m[2020-07-17 12:21:44] __main__ INFO: \u001b[0mElapsed 5.73\n",
      "\u001b[32m[2020-07-17 12:21:44] __main__ INFO: \u001b[0mLoss 0.6334 Accuracy 0.8525\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10.1 test dataset \n",
    "# Write the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/wrn.yaml \\\n",
    "   test.batch_size 128 \\\n",
    "   dataset.name CIFAR101 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_20_c10val/exp00_resume400_50/checkpoint_00050.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_20_c10val/exp00_resume400_50/test_results_0050_cifar101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Record the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Testset</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Original_Accuracy</th>\n",
       "      <th>Original_CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wrn_28_10_ra_2_20_c10val</td>\n",
       "      <td>400</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>0.6113</td>\n",
       "      <td>0.8456</td>\n",
       "      <td>92.5</td>\n",
       "      <td>(92.0, 93.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wrn_28_10_ra_2_20_c10val</td>\n",
       "      <td>400</td>\n",
       "      <td>cifar10.1</td>\n",
       "      <td>1.1302</td>\n",
       "      <td>0.7365</td>\n",
       "      <td>84.9</td>\n",
       "      <td>(83.2, 86.4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wrn_28_10_ra_2_20_c10val_refined400</td>\n",
       "      <td>50</td>\n",
       "      <td>cifar10.1</td>\n",
       "      <td>0.6334</td>\n",
       "      <td>0.8525</td>\n",
       "      <td>84.9</td>\n",
       "      <td>(83.2, 86.4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wrn_28_10_ra_2_20_c10val_refined400</td>\n",
       "      <td>50</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>0.2748</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>92.5</td>\n",
       "      <td>(92.0, 93.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model Epoch    Testset    Loss Accuracy  \\\n",
       "0             wrn_28_10_ra_2_20_c10val   400    cifar10  0.6113   0.8456   \n",
       "1             wrn_28_10_ra_2_20_c10val   400  cifar10.1  1.1302   0.7365   \n",
       "2  wrn_28_10_ra_2_20_c10val_refined400    50  cifar10.1  0.6334   0.8525   \n",
       "3  wrn_28_10_ra_2_20_c10val_refined400    50    cifar10  0.2748   0.9333   \n",
       "\n",
       "   Original_Accuracy   Original_CI  \n",
       "0               92.5  (92.0, 93.0)  \n",
       "1               84.9  (83.2, 86.4)  \n",
       "2               84.9  (83.2, 86.4)  \n",
       "3               92.5  (92.0, 93.0)  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "model = 'wrn_28_10_ra_2_20_c10val'\n",
    "model_refined = model + '_refined400'\n",
    "\n",
    "a = pd.Series([model, 400, 'cifar10', 0.6113, 0.8456])\n",
    "c = pd.Series([model, 400, 'cifar10.1', 1.1302, 0.7365])\n",
    "\n",
    "e = pd.Series([model_refined, 50, 'cifar10.1', 0.6334, 0.8525])\n",
    "f = pd.Series([model_refined, 50, 'cifar10', 0.2748, 0.9333])\n",
    "               \n",
    "df_results = pd.concat([a,c,e,f], axis=1).T\n",
    "df_results.columns = ['Model', 'Epoch', 'Testset', 'Loss', 'Accuracy']\n",
    "\n",
    "df_results['Original_Accuracy'] = df_results.apply((lambda row: 92.5 if row[2] == 'cifar10' else 84.9), axis=1)\n",
    "df_results['Original_CI'] = df_results.apply((lambda row: (92.0, 93.0) if row[2] == 'cifar10' else (83.2, 86.4)), axis=1)\n",
    "\n",
    "df_results.to_csv('/home/ec2-user/SageMaker/experiments/' + model + '/results.csv')\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the model checkpoints, configs, and results to S3 \n",
    "bucket='sagemaker-june29'\n",
    "prefix = 'sagemaker/results/original-models/wrn_28_10_ra_2_20_c10val'\n",
    "path = '/home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_20_c10val'\n",
    "\n",
    "s3_resource = boto3.resource(\"s3\", region_name=\"us-east-2\")\n",
    "\n",
    "def uploadDirectory(local_path,bucket_name,s3_prefix):\n",
    "\n",
    "    my_bucket = s3_resource.Bucket(bucket_name)\n",
    "    \n",
    "    for path, subdirs, files in os.walk(local_path):\n",
    "        path = path.replace(\"\\\\\",\"/\")\n",
    "        directory_name = path.replace(local_path,\"\")\n",
    "        for file in files:\n",
    "            #print(\"Local File:\", os.path.join(path, file))\n",
    "            #print(\"      Dest:\", s3_prefix+directory_name+'/'+file)\n",
    "            my_bucket.upload_file(os.path.join(path, file), s3_prefix+directory_name+'/'+file)\n",
    "    \n",
    "uploadDirectory(path,bucket,prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
