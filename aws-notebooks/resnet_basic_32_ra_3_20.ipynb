{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESNET 32\n",
    "- Training Dataset: RandAugment, N=3, M=20\n",
    "- Sagemaker Notebook must be of type, conda_pytorch_p36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy \n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 1)) (1.18.1)\n",
      "Requirement already satisfied: torch>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 2)) (1.4.0)\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 3)) (0.5.0)\n",
      "Requirement already satisfied: fvcore in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (0.1.1.post20200619)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 5)) (4.44.1)\n",
      "Requirement already satisfied: yacs in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 6)) (0.1.7)\n",
      "Requirement already satisfied: apex from git+https://github.com/NVIDIA/apex.git#egg=apex in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 7)) (0.1)\n",
      "Requirement already satisfied: termcolor in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 8)) (1.1.0)\n",
      "Requirement already satisfied: thop<0.0.31.post2004070130 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 9)) (0.0.31.post2001170342)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 3)) (1.14.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 3)) (7.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from fvcore->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (5.3.1)\n",
      "Requirement already satisfied: tabulate in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from fvcore->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (0.8.7)\n",
      "Requirement already satisfied: portalocker in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from fvcore->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (1.7.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Sagemaker Notebook must be of type, conda_pytorch_p36\n",
    "\n",
    "!pip install -r '/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (2.2.2)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.29.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (46.1.3.post20200330)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.6.0.post3)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (3.12.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (3.2.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.18.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.14.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.34.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.18.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (2.23.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (1.5.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.1.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard) (3.4.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.4.5.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (1.25.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard) (2.2.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Need to add this to requirements.txt\n",
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model per the settings specified in the original RESNET paper\n",
    "# os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "# !python train.py --config configs/cifar/resnet.yaml \\\n",
    "#     model.resnet.depth 32 \\\n",
    "#     train.batch_size 128 \\\n",
    "#     dataset.name CIFAR10 \\\n",
    "#     train.base_lr 0.1 \\\n",
    "#     train.output_dir /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_5/exp00 \\\n",
    "#     scheduler.epochs 1\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data\n",
    "bucket='sagemaker-may29'\n",
    "prefix = 'sagemaker/RandAugmentation/cifar10_ra_3_20.npy'\n",
    "path = '/home/ec2-user/SageMaker/cifar10_ra_3_20.npy'\n",
    "\n",
    "s3_resource = boto3.resource(\"s3\", region_name=\"us-east-2\")\n",
    "\n",
    "s3_resource.Bucket(bucket).download_file(prefix, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-06-22 16:28:33] __main__ INFO: \u001b[0mdevice: cuda\n",
      "cudnn:\n",
      "  benchmark: True\n",
      "  deterministic: False\n",
      "dataset:\n",
      "  name: CIFAR10_RA_3_20\n",
      "  dataset_dir: ''\n",
      "  image_size: 32\n",
      "  n_channels: 3\n",
      "  n_classes: 10\n",
      "model:\n",
      "  type: cifar\n",
      "  name: resnet\n",
      "  init_mode: kaiming_fan_out\n",
      "  vgg:\n",
      "    n_channels: [64, 128, 256, 512, 512]\n",
      "    n_layers: [2, 2, 3, 3, 3]\n",
      "    use_bn: True\n",
      "  resnet:\n",
      "    depth: 32\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "  resnet_preact:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "  wrn:\n",
      "    depth: 28\n",
      "    initial_channels: 16\n",
      "    widening_factor: 10\n",
      "    drop_rate: 0.0\n",
      "  densenet:\n",
      "    depth: 100\n",
      "    n_blocks: [6, 12, 24, 16]\n",
      "    block_type: bottleneck\n",
      "    growth_rate: 12\n",
      "    drop_rate: 0.0\n",
      "    compression_rate: 0.5\n",
      "  pyramidnet:\n",
      "    depth: 272\n",
      "    n_blocks: [3, 24, 36, 3]\n",
      "    initial_channels: 16\n",
      "    block_type: bottleneck\n",
      "    alpha: 200\n",
      "  resnext:\n",
      "    depth: 29\n",
      "    n_blocks: [3, 4, 6, 3]\n",
      "    initial_channels: 64\n",
      "    cardinality: 8\n",
      "    base_channels: 4\n",
      "  shake_shake:\n",
      "    depth: 26\n",
      "    initial_channels: 96\n",
      "    shake_forward: True\n",
      "    shake_backward: True\n",
      "    shake_image: True\n",
      "  se_resnet_preact:\n",
      "    depth: 110\n",
      "    initial_channels: 16\n",
      "    se_reduction: 16\n",
      "    block_type: basic\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "train:\n",
      "  checkpoint: ''\n",
      "  resume: False\n",
      "  precision: O0\n",
      "  batch_size: 128\n",
      "  subdivision: 1\n",
      "  optimizer: sgd\n",
      "  base_lr: 0.1\n",
      "  momentum: 0.9\n",
      "  nesterov: True\n",
      "  weight_decay: 0.0001\n",
      "  no_weight_decay_on_bn: False\n",
      "  gradient_clip: 0\n",
      "  start_epoch: 0\n",
      "  seed: 0\n",
      "  val_first: True\n",
      "  val_period: 1\n",
      "  val_ratio: 0.1\n",
      "  use_test_as_val: False\n",
      "  output_dir: /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00\n",
      "  log_period: 100\n",
      "  checkpoint_period: 100\n",
      "  use_tensorboard: True\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: True\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "  distributed: False\n",
      "  dist:\n",
      "    backend: nccl\n",
      "    init_method: env://\n",
      "    world_size: -1\n",
      "    node_rank: -1\n",
      "    local_rank: 0\n",
      "    use_sync_bn: False\n",
      "tensorboard:\n",
      "  train_images: False\n",
      "  val_images: False\n",
      "  model_params: False\n",
      "optim:\n",
      "  adam:\n",
      "    betas: (0.9, 0.999)\n",
      "  lars:\n",
      "    eps: 1e-09\n",
      "    threshold: 0.01\n",
      "  adabound:\n",
      "    betas: (0.9, 0.999)\n",
      "    final_lr: 0.1\n",
      "    gamma: 0.001\n",
      "scheduler:\n",
      "  epochs: 400\n",
      "  warmup:\n",
      "    type: none\n",
      "    epochs: 0\n",
      "    start_factor: 0.001\n",
      "    exponent: 4\n",
      "  type: multistep\n",
      "  milestones: [80, 120]\n",
      "  lr_decay: 0.1\n",
      "  lr_min_factor: 0.001\n",
      "  T0: 10\n",
      "  T_mul: 1.0\n",
      "validation:\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: False\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "augmentation:\n",
      "  use_random_crop: True\n",
      "  use_random_horizontal_flip: True\n",
      "  use_cutout: False\n",
      "  use_random_erasing: False\n",
      "  use_dual_cutout: False\n",
      "  use_mixup: False\n",
      "  use_ricap: False\n",
      "  use_cutmix: False\n",
      "  use_label_smoothing: False\n",
      "  random_crop:\n",
      "    padding: 4\n",
      "    fill: 0\n",
      "    padding_mode: constant\n",
      "  random_horizontal_flip:\n",
      "    prob: 0.5\n",
      "  cutout:\n",
      "    prob: 1.0\n",
      "    mask_size: 16\n",
      "    cut_inside: False\n",
      "    mask_color: 0\n",
      "    dual_cutout_alpha: 0.1\n",
      "  random_erasing:\n",
      "    prob: 0.5\n",
      "    area_ratio_range: [0.02, 0.4]\n",
      "    min_aspect_ratio: 0.3\n",
      "    max_attempt: 20\n",
      "  mixup:\n",
      "    alpha: 1.0\n",
      "  ricap:\n",
      "    beta: 0.3\n",
      "  cutmix:\n",
      "    alpha: 1.0\n",
      "  label_smoothing:\n",
      "    epsilon: 0.1\n",
      "tta:\n",
      "  use_resize: False\n",
      "  use_center_crop: False\n",
      "  resize: 256\n",
      "test:\n",
      "  checkpoint: ''\n",
      "  output_dir: ''\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    pin_memory: False\n",
      "\u001b[32m[2020-06-22 16:28:33] __main__ INFO: \u001b[0menv_info:\n",
      "  pytorch_version: 1.4.0\n",
      "  cuda_version: 10.1\n",
      "  cudnn_version: 7603\n",
      "  num_gpus: 1\n",
      "  gpu_name: Tesla K80\n",
      "  gpu_capability: 3.7\n",
      "(50000, 32, 32, 3)\n",
      "\u001b[32m[2020-06-22 16:28:39] __main__ INFO: \u001b[0mMACs  : 69.76M\n",
      "\u001b[32m[2020-06-22 16:28:39] __main__ INFO: \u001b[0m#params: 466.91K\n",
      "Selected optimization level O0:  Pure FP32 training.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n",
      "\u001b[32m[2020-06-22 16:28:39] __main__ INFO: \u001b[0mVal 0\n",
      "\u001b[32m[2020-06-22 16:28:40] __main__ INFO: \u001b[0mEpoch 0 loss 4206.7115 acc@1 0.1008 acc@5 0.5044\n",
      "\u001b[32m[2020-06-22 16:28:40] __main__ INFO: \u001b[0mElapsed 1.38\n",
      "\u001b[32m[2020-06-22 16:28:40] __main__ INFO: \u001b[0mTrain 1 0\n",
      "\u001b[32m[2020-06-22 16:28:50] __main__ INFO: \u001b[0mEpoch 1 Step 100/351 lr 0.100000 loss 2.3246 (2.7872) acc@1 0.1016 (0.1002) acc@5 0.5312 (0.5045)\n",
      "\u001b[32m[2020-06-22 16:28:59] __main__ INFO: \u001b[0mEpoch 1 Step 200/351 lr 0.100000 loss 2.3049 (2.5502) acc@1 0.0781 (0.1021) acc@5 0.4844 (0.5009)\n",
      "\u001b[32m[2020-06-22 16:29:08] __main__ INFO: \u001b[0mEpoch 1 Step 300/351 lr 0.100000 loss 2.3167 (2.4698) acc@1 0.1016 (0.1022) acc@5 0.4609 (0.5003)\n",
      "\u001b[32m[2020-06-22 16:29:12] __main__ INFO: \u001b[0mEpoch 1 Step 351/351 lr 0.100000 loss 2.3074 (2.4463) acc@1 0.0938 (0.1024) acc@5 0.5000 (0.5010)\n",
      "\u001b[32m[2020-06-22 16:29:12] __main__ INFO: \u001b[0mElapsed 32.35\n",
      "\u001b[32m[2020-06-22 16:29:12] __main__ INFO: \u001b[0mVal 1\n",
      "\u001b[32m[2020-06-22 16:29:14] __main__ INFO: \u001b[0mEpoch 1 loss 2.3067 acc@1 0.0950 acc@5 0.4992\n",
      "\u001b[32m[2020-06-22 16:29:14] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 16:29:14] __main__ INFO: \u001b[0mTrain 2 351\n",
      "\u001b[32m[2020-06-22 16:29:23] __main__ INFO: \u001b[0mEpoch 2 Step 100/351 lr 0.100000 loss 2.3216 (2.3072) acc@1 0.0781 (0.1011) acc@5 0.5312 (0.5142)\n",
      "\u001b[32m[2020-06-22 16:29:32] __main__ INFO: \u001b[0mEpoch 2 Step 200/351 lr 0.100000 loss 2.2989 (2.3066) acc@1 0.1094 (0.1022) acc@5 0.5312 (0.5091)\n",
      "\u001b[32m[2020-06-22 16:29:41] __main__ INFO: \u001b[0mEpoch 2 Step 300/351 lr 0.100000 loss 2.3179 (2.3061) acc@1 0.0469 (0.1020) acc@5 0.3984 (0.5086)\n",
      "\u001b[32m[2020-06-22 16:29:46] __main__ INFO: \u001b[0mEpoch 2 Step 351/351 lr 0.100000 loss 2.3125 (2.3055) acc@1 0.1016 (0.1035) acc@5 0.4922 (0.5105)\n",
      "\u001b[32m[2020-06-22 16:29:46] __main__ INFO: \u001b[0mElapsed 32.41\n",
      "\u001b[32m[2020-06-22 16:29:46] __main__ INFO: \u001b[0mVal 2\n",
      "\u001b[32m[2020-06-22 16:29:47] __main__ INFO: \u001b[0mEpoch 2 loss 2.3052 acc@1 0.1002 acc@5 0.4978\n",
      "\u001b[32m[2020-06-22 16:29:47] __main__ INFO: \u001b[0mElapsed 1.20\n",
      "\u001b[32m[2020-06-22 16:29:47] __main__ INFO: \u001b[0mTrain 3 702\n",
      "\u001b[32m[2020-06-22 16:29:56] __main__ INFO: \u001b[0mEpoch 3 Step 100/351 lr 0.100000 loss 2.3038 (2.3045) acc@1 0.1016 (0.1061) acc@5 0.5312 (0.5134)\n",
      "\u001b[32m[2020-06-22 16:30:06] __main__ INFO: \u001b[0mEpoch 3 Step 200/351 lr 0.100000 loss 2.2948 (2.3037) acc@1 0.1484 (0.1079) acc@5 0.5938 (0.5128)\n",
      "\u001b[32m[2020-06-22 16:30:15] __main__ INFO: \u001b[0mEpoch 3 Step 300/351 lr 0.100000 loss 2.2966 (2.3035) acc@1 0.0781 (0.1059) acc@5 0.5156 (0.5130)\n",
      "\u001b[32m[2020-06-22 16:30:20] __main__ INFO: \u001b[0mEpoch 3 Step 351/351 lr 0.100000 loss 2.3055 (2.3028) acc@1 0.1250 (0.1061) acc@5 0.5391 (0.5147)\n",
      "\u001b[32m[2020-06-22 16:30:20] __main__ INFO: \u001b[0mElapsed 32.55\n",
      "\u001b[32m[2020-06-22 16:30:20] __main__ INFO: \u001b[0mVal 3\n",
      "\u001b[32m[2020-06-22 16:30:21] __main__ INFO: \u001b[0mEpoch 3 loss 2.4578 acc@1 0.1042 acc@5 0.5132\n",
      "\u001b[32m[2020-06-22 16:30:21] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 16:30:21] __main__ INFO: \u001b[0mTrain 4 1053\n",
      "\u001b[32m[2020-06-22 16:30:30] __main__ INFO: \u001b[0mEpoch 4 Step 100/351 lr 0.100000 loss 2.2917 (2.3014) acc@1 0.1016 (0.1070) acc@5 0.5781 (0.5209)\n",
      "\u001b[32m[2020-06-22 16:30:39] __main__ INFO: \u001b[0mEpoch 4 Step 200/351 lr 0.100000 loss 2.2885 (2.3011) acc@1 0.1172 (0.1087) acc@5 0.5781 (0.5232)\n",
      "\u001b[32m[2020-06-22 16:30:49] __main__ INFO: \u001b[0mEpoch 4 Step 300/351 lr 0.100000 loss 2.3024 (2.3006) acc@1 0.0703 (0.1097) acc@5 0.4922 (0.5217)\n",
      "\u001b[32m[2020-06-22 16:30:53] __main__ INFO: \u001b[0mEpoch 4 Step 351/351 lr 0.100000 loss 2.2850 (2.3004) acc@1 0.1016 (0.1091) acc@5 0.6016 (0.5219)\n",
      "\u001b[32m[2020-06-22 16:30:53] __main__ INFO: \u001b[0mElapsed 32.59\n",
      "\u001b[32m[2020-06-22 16:30:53] __main__ INFO: \u001b[0mVal 4\n",
      "\u001b[32m[2020-06-22 16:30:54] __main__ INFO: \u001b[0mEpoch 4 loss 2.2999 acc@1 0.1112 acc@5 0.5196\n",
      "\u001b[32m[2020-06-22 16:30:54] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 16:30:54] __main__ INFO: \u001b[0mTrain 5 1404\n",
      "\u001b[32m[2020-06-22 16:31:04] __main__ INFO: \u001b[0mEpoch 5 Step 100/351 lr 0.100000 loss 2.2962 (2.2986) acc@1 0.0625 (0.1095) acc@5 0.5703 (0.5230)\n",
      "\u001b[32m[2020-06-22 16:31:13] __main__ INFO: \u001b[0mEpoch 5 Step 200/351 lr 0.100000 loss 2.3145 (2.2981) acc@1 0.0703 (0.1097) acc@5 0.5234 (0.5260)\n",
      "\u001b[32m[2020-06-22 16:31:22] __main__ INFO: \u001b[0mEpoch 5 Step 300/351 lr 0.100000 loss 2.3166 (2.2980) acc@1 0.0938 (0.1095) acc@5 0.5234 (0.5274)\n",
      "\u001b[32m[2020-06-22 16:31:27] __main__ INFO: \u001b[0mEpoch 5 Step 351/351 lr 0.100000 loss 2.2963 (2.2972) acc@1 0.1172 (0.1099) acc@5 0.5547 (0.5300)\n",
      "\u001b[32m[2020-06-22 16:31:27] __main__ INFO: \u001b[0mElapsed 32.70\n",
      "\u001b[32m[2020-06-22 16:31:27] __main__ INFO: \u001b[0mVal 5\n",
      "\u001b[32m[2020-06-22 16:31:28] __main__ INFO: \u001b[0mEpoch 5 loss 2.2933 acc@1 0.1090 acc@5 0.5462\n",
      "\u001b[32m[2020-06-22 16:31:28] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 16:31:28] __main__ INFO: \u001b[0mTrain 6 1755\n",
      "\u001b[32m[2020-06-22 16:31:37] __main__ INFO: \u001b[0mEpoch 6 Step 100/351 lr 0.100000 loss 2.3141 (2.2949) acc@1 0.0938 (0.1105) acc@5 0.4844 (0.5339)\n",
      "\u001b[32m[2020-06-22 16:31:47] __main__ INFO: \u001b[0mEpoch 6 Step 200/351 lr 0.100000 loss 2.2978 (2.2949) acc@1 0.1016 (0.1098) acc@5 0.5781 (0.5320)\n",
      "\u001b[32m[2020-06-22 16:31:56] __main__ INFO: \u001b[0mEpoch 6 Step 300/351 lr 0.100000 loss 2.2937 (2.2945) acc@1 0.0859 (0.1100) acc@5 0.5625 (0.5326)\n",
      "\u001b[32m[2020-06-22 16:32:01] __main__ INFO: \u001b[0mEpoch 6 Step 351/351 lr 0.100000 loss 2.2868 (2.2940) acc@1 0.1172 (0.1110) acc@5 0.5859 (0.5347)\n",
      "\u001b[32m[2020-06-22 16:32:01] __main__ INFO: \u001b[0mElapsed 32.71\n",
      "\u001b[32m[2020-06-22 16:32:01] __main__ INFO: \u001b[0mVal 6\n",
      "\u001b[32m[2020-06-22 16:32:02] __main__ INFO: \u001b[0mEpoch 6 loss 2.2914 acc@1 0.1128 acc@5 0.5514\n",
      "\u001b[32m[2020-06-22 16:32:02] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 16:32:02] __main__ INFO: \u001b[0mTrain 7 2106\n",
      "\u001b[32m[2020-06-22 16:32:11] __main__ INFO: \u001b[0mEpoch 7 Step 100/351 lr 0.100000 loss 2.2955 (2.2909) acc@1 0.1172 (0.1203) acc@5 0.5703 (0.5480)\n",
      "\u001b[32m[2020-06-22 16:32:21] __main__ INFO: \u001b[0mEpoch 7 Step 200/351 lr 0.100000 loss 2.2881 (2.2909) acc@1 0.0938 (0.1160) acc@5 0.5234 (0.5480)\n",
      "\u001b[32m[2020-06-22 16:32:30] __main__ INFO: \u001b[0mEpoch 7 Step 300/351 lr 0.100000 loss 2.2739 (2.2898) acc@1 0.1562 (0.1170) acc@5 0.5391 (0.5468)\n",
      "\u001b[32m[2020-06-22 16:32:35] __main__ INFO: \u001b[0mEpoch 7 Step 351/351 lr 0.100000 loss 2.2714 (2.2897) acc@1 0.1094 (0.1161) acc@5 0.5547 (0.5454)\n",
      "\u001b[32m[2020-06-22 16:32:35] __main__ INFO: \u001b[0mElapsed 32.72\n",
      "\u001b[32m[2020-06-22 16:32:35] __main__ INFO: \u001b[0mVal 7\n",
      "\u001b[32m[2020-06-22 16:32:36] __main__ INFO: \u001b[0mEpoch 7 loss 2.2948 acc@1 0.1212 acc@5 0.5260\n",
      "\u001b[32m[2020-06-22 16:32:36] __main__ INFO: \u001b[0mElapsed 1.03\n",
      "\u001b[32m[2020-06-22 16:32:36] __main__ INFO: \u001b[0mTrain 8 2457\n",
      "\u001b[32m[2020-06-22 16:32:45] __main__ INFO: \u001b[0mEpoch 8 Step 100/351 lr 0.100000 loss 2.2602 (2.2846) acc@1 0.1328 (0.1187) acc@5 0.5859 (0.5559)\n",
      "\u001b[32m[2020-06-22 16:32:54] __main__ INFO: \u001b[0mEpoch 8 Step 200/351 lr 0.100000 loss 2.2683 (2.2844) acc@1 0.1094 (0.1182) acc@5 0.5781 (0.5520)\n",
      "\u001b[32m[2020-06-22 16:33:04] __main__ INFO: \u001b[0mEpoch 8 Step 300/351 lr 0.100000 loss 2.2789 (2.2810) acc@1 0.1250 (0.1210) acc@5 0.5312 (0.5565)\n",
      "\u001b[32m[2020-06-22 16:33:08] __main__ INFO: \u001b[0mEpoch 8 Step 351/351 lr 0.100000 loss 2.2920 (2.2796) acc@1 0.1250 (0.1213) acc@5 0.5391 (0.5569)\n",
      "\u001b[32m[2020-06-22 16:33:08] __main__ INFO: \u001b[0mElapsed 32.71\n",
      "\u001b[32m[2020-06-22 16:33:08] __main__ INFO: \u001b[0mVal 8\n",
      "\u001b[32m[2020-06-22 16:33:09] __main__ INFO: \u001b[0mEpoch 8 loss 2.2955 acc@1 0.1160 acc@5 0.5396\n",
      "\u001b[32m[2020-06-22 16:33:09] __main__ INFO: \u001b[0mElapsed 1.03\n",
      "\u001b[32m[2020-06-22 16:33:09] __main__ INFO: \u001b[0mTrain 9 2808\n",
      "\u001b[32m[2020-06-22 16:33:19] __main__ INFO: \u001b[0mEpoch 9 Step 100/351 lr 0.100000 loss 2.2607 (2.2714) acc@1 0.1719 (0.1295) acc@5 0.5469 (0.5649)\n",
      "\u001b[32m[2020-06-22 16:33:28] __main__ INFO: \u001b[0mEpoch 9 Step 200/351 lr 0.100000 loss 2.2740 (2.2727) acc@1 0.1094 (0.1287) acc@5 0.5625 (0.5651)\n",
      "\u001b[32m[2020-06-22 16:33:37] __main__ INFO: \u001b[0mEpoch 9 Step 300/351 lr 0.100000 loss 2.2421 (2.2704) acc@1 0.1719 (0.1287) acc@5 0.6328 (0.5676)\n",
      "\u001b[32m[2020-06-22 16:33:42] __main__ INFO: \u001b[0mEpoch 9 Step 351/351 lr 0.100000 loss 2.2593 (2.2693) acc@1 0.1016 (0.1291) acc@5 0.5625 (0.5689)\n",
      "\u001b[32m[2020-06-22 16:33:42] __main__ INFO: \u001b[0mElapsed 32.78\n",
      "\u001b[32m[2020-06-22 16:33:42] __main__ INFO: \u001b[0mVal 9\n",
      "\u001b[32m[2020-06-22 16:33:43] __main__ INFO: \u001b[0mEpoch 9 loss 2.2655 acc@1 0.1260 acc@5 0.5704\n",
      "\u001b[32m[2020-06-22 16:33:43] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 16:33:43] __main__ INFO: \u001b[0mTrain 10 3159\n",
      "\u001b[32m[2020-06-22 16:33:53] __main__ INFO: \u001b[0mEpoch 10 Step 100/351 lr 0.100000 loss 2.2264 (2.2604) acc@1 0.1641 (0.1329) acc@5 0.6094 (0.5813)\n",
      "\u001b[32m[2020-06-22 16:34:02] __main__ INFO: \u001b[0mEpoch 10 Step 200/351 lr 0.100000 loss 2.2495 (2.2585) acc@1 0.1094 (0.1324) acc@5 0.5469 (0.5819)\n",
      "\u001b[32m[2020-06-22 16:34:11] __main__ INFO: \u001b[0mEpoch 10 Step 300/351 lr 0.100000 loss 2.3138 (2.2589) acc@1 0.1172 (0.1328) acc@5 0.5234 (0.5786)\n",
      "\u001b[32m[2020-06-22 16:34:16] __main__ INFO: \u001b[0mEpoch 10 Step 351/351 lr 0.100000 loss 2.2720 (2.2577) acc@1 0.1641 (0.1337) acc@5 0.6406 (0.5808)\n",
      "\u001b[32m[2020-06-22 16:34:16] __main__ INFO: \u001b[0mElapsed 32.69\n",
      "\u001b[32m[2020-06-22 16:34:16] __main__ INFO: \u001b[0mVal 10\n",
      "\u001b[32m[2020-06-22 16:34:17] __main__ INFO: \u001b[0mEpoch 10 loss 2.2532 acc@1 0.1316 acc@5 0.5748\n",
      "\u001b[32m[2020-06-22 16:34:17] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 16:34:17] __main__ INFO: \u001b[0mTrain 11 3510\n",
      "\u001b[32m[2020-06-22 16:34:26] __main__ INFO: \u001b[0mEpoch 11 Step 100/351 lr 0.100000 loss 2.2581 (2.2527) acc@1 0.1641 (0.1377) acc@5 0.6172 (0.5860)\n",
      "\u001b[32m[2020-06-22 16:34:36] __main__ INFO: \u001b[0mEpoch 11 Step 200/351 lr 0.100000 loss 2.2758 (2.2495) acc@1 0.0938 (0.1400) acc@5 0.6016 (0.5873)\n",
      "\u001b[32m[2020-06-22 16:34:45] __main__ INFO: \u001b[0mEpoch 11 Step 300/351 lr 0.100000 loss 2.2365 (2.2500) acc@1 0.0625 (0.1377) acc@5 0.5781 (0.5853)\n",
      "\u001b[32m[2020-06-22 16:34:50] __main__ INFO: \u001b[0mEpoch 11 Step 351/351 lr 0.100000 loss 2.2251 (2.2495) acc@1 0.1641 (0.1374) acc@5 0.6406 (0.5858)\n",
      "\u001b[32m[2020-06-22 16:34:50] __main__ INFO: \u001b[0mElapsed 32.74\n",
      "\u001b[32m[2020-06-22 16:34:50] __main__ INFO: \u001b[0mVal 11\n",
      "\u001b[32m[2020-06-22 16:34:51] __main__ INFO: \u001b[0mEpoch 11 loss 2.2503 acc@1 0.1352 acc@5 0.5926\n",
      "\u001b[32m[2020-06-22 16:34:51] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 16:34:51] __main__ INFO: \u001b[0mTrain 12 3861\n",
      "\u001b[32m[2020-06-22 16:35:00] __main__ INFO: \u001b[0mEpoch 12 Step 100/351 lr 0.100000 loss 2.2375 (2.2435) acc@1 0.1562 (0.1384) acc@5 0.6016 (0.5916)\n",
      "\u001b[32m[2020-06-22 16:35:09] __main__ INFO: \u001b[0mEpoch 12 Step 200/351 lr 0.100000 loss 2.2591 (2.2436) acc@1 0.0938 (0.1402) acc@5 0.5703 (0.5940)\n",
      "\u001b[32m[2020-06-22 16:35:19] __main__ INFO: \u001b[0mEpoch 12 Step 300/351 lr 0.100000 loss 2.2360 (2.2407) acc@1 0.1172 (0.1427) acc@5 0.5938 (0.5934)\n",
      "\u001b[32m[2020-06-22 16:35:23] __main__ INFO: \u001b[0mEpoch 12 Step 351/351 lr 0.100000 loss 2.2395 (2.2409) acc@1 0.1250 (0.1425) acc@5 0.5859 (0.5924)\n",
      "\u001b[32m[2020-06-22 16:35:24] __main__ INFO: \u001b[0mElapsed 32.75\n",
      "\u001b[32m[2020-06-22 16:35:24] __main__ INFO: \u001b[0mVal 12\n",
      "\u001b[32m[2020-06-22 16:35:25] __main__ INFO: \u001b[0mEpoch 12 loss 2.2292 acc@1 0.1428 acc@5 0.6012\n",
      "\u001b[32m[2020-06-22 16:35:25] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 16:35:25] __main__ INFO: \u001b[0mTrain 13 4212\n",
      "\u001b[32m[2020-06-22 16:35:34] __main__ INFO: \u001b[0mEpoch 13 Step 100/351 lr 0.100000 loss 2.2361 (2.2323) acc@1 0.1172 (0.1468) acc@5 0.5938 (0.5933)\n",
      "\u001b[32m[2020-06-22 16:35:43] __main__ INFO: \u001b[0mEpoch 13 Step 200/351 lr 0.100000 loss 2.2014 (2.2301) acc@1 0.1719 (0.1472) acc@5 0.6016 (0.5962)\n",
      "\u001b[32m[2020-06-22 16:35:53] __main__ INFO: \u001b[0mEpoch 13 Step 300/351 lr 0.100000 loss 2.2872 (2.2305) acc@1 0.1719 (0.1479) acc@5 0.6016 (0.5977)\n",
      "\u001b[32m[2020-06-22 16:35:57] __main__ INFO: \u001b[0mEpoch 13 Step 351/351 lr 0.100000 loss 2.1742 (2.2304) acc@1 0.1953 (0.1483) acc@5 0.6719 (0.5988)\n",
      "\u001b[32m[2020-06-22 16:35:57] __main__ INFO: \u001b[0mElapsed 32.73\n",
      "\u001b[32m[2020-06-22 16:35:57] __main__ INFO: \u001b[0mVal 13\n",
      "\u001b[32m[2020-06-22 16:35:58] __main__ INFO: \u001b[0mEpoch 13 loss 2.3412 acc@1 0.1398 acc@5 0.5880\n",
      "\u001b[32m[2020-06-22 16:35:58] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 16:35:58] __main__ INFO: \u001b[0mTrain 14 4563\n",
      "\u001b[32m[2020-06-22 16:36:08] __main__ INFO: \u001b[0mEpoch 14 Step 100/351 lr 0.100000 loss 2.1643 (2.2266) acc@1 0.1562 (0.1498) acc@5 0.6250 (0.6001)\n",
      "\u001b[32m[2020-06-22 16:36:17] __main__ INFO: \u001b[0mEpoch 14 Step 200/351 lr 0.100000 loss 2.2060 (2.2231) acc@1 0.1719 (0.1513) acc@5 0.5938 (0.6033)\n",
      "\u001b[32m[2020-06-22 16:36:26] __main__ INFO: \u001b[0mEpoch 14 Step 300/351 lr 0.100000 loss 2.1399 (2.2223) acc@1 0.2344 (0.1536) acc@5 0.6719 (0.6043)\n",
      "\u001b[32m[2020-06-22 16:36:31] __main__ INFO: \u001b[0mEpoch 14 Step 351/351 lr 0.100000 loss 2.2025 (2.2224) acc@1 0.1562 (0.1538) acc@5 0.6172 (0.6036)\n",
      "\u001b[32m[2020-06-22 16:36:31] __main__ INFO: \u001b[0mElapsed 32.74\n",
      "\u001b[32m[2020-06-22 16:36:31] __main__ INFO: \u001b[0mVal 14\n",
      "\u001b[32m[2020-06-22 16:36:32] __main__ INFO: \u001b[0mEpoch 14 loss 2.2802 acc@1 0.1444 acc@5 0.5924\n",
      "\u001b[32m[2020-06-22 16:36:32] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 16:36:32] __main__ INFO: \u001b[0mTrain 15 4914\n",
      "\u001b[32m[2020-06-22 16:36:42] __main__ INFO: \u001b[0mEpoch 15 Step 100/351 lr 0.100000 loss 2.2378 (2.2174) acc@1 0.1328 (0.1548) acc@5 0.6250 (0.6054)\n",
      "\u001b[32m[2020-06-22 16:36:51] __main__ INFO: \u001b[0mEpoch 15 Step 200/351 lr 0.100000 loss 2.1731 (2.2129) acc@1 0.1641 (0.1557) acc@5 0.5781 (0.6107)\n",
      "\u001b[32m[2020-06-22 16:37:00] __main__ INFO: \u001b[0mEpoch 15 Step 300/351 lr 0.100000 loss 2.2144 (2.2117) acc@1 0.1875 (0.1566) acc@5 0.6250 (0.6107)\n",
      "\u001b[32m[2020-06-22 16:37:05] __main__ INFO: \u001b[0mEpoch 15 Step 351/351 lr 0.100000 loss 2.1973 (2.2114) acc@1 0.1562 (0.1567) acc@5 0.6172 (0.6103)\n",
      "\u001b[32m[2020-06-22 16:37:05] __main__ INFO: \u001b[0mElapsed 32.75\n",
      "\u001b[32m[2020-06-22 16:37:05] __main__ INFO: \u001b[0mVal 15\n",
      "\u001b[32m[2020-06-22 16:37:06] __main__ INFO: \u001b[0mEpoch 15 loss 2.2017 acc@1 0.1606 acc@5 0.6268\n",
      "\u001b[32m[2020-06-22 16:37:06] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 16:37:06] __main__ INFO: \u001b[0mTrain 16 5265\n",
      "\u001b[32m[2020-06-22 16:37:15] __main__ INFO: \u001b[0mEpoch 16 Step 100/351 lr 0.100000 loss 2.1846 (2.1979) acc@1 0.1562 (0.1696) acc@5 0.5781 (0.6223)\n",
      "\u001b[32m[2020-06-22 16:37:25] __main__ INFO: \u001b[0mEpoch 16 Step 200/351 lr 0.100000 loss 2.2287 (2.2022) acc@1 0.1562 (0.1654) acc@5 0.6016 (0.6193)\n",
      "\u001b[32m[2020-06-22 16:37:34] __main__ INFO: \u001b[0mEpoch 16 Step 300/351 lr 0.100000 loss 2.1644 (2.2032) acc@1 0.1719 (0.1636) acc@5 0.6719 (0.6180)\n",
      "\u001b[32m[2020-06-22 16:37:39] __main__ INFO: \u001b[0mEpoch 16 Step 351/351 lr 0.100000 loss 2.1944 (2.2043) acc@1 0.1250 (0.1631) acc@5 0.5859 (0.6159)\n",
      "\u001b[32m[2020-06-22 16:37:39] __main__ INFO: \u001b[0mElapsed 32.74\n",
      "\u001b[32m[2020-06-22 16:37:39] __main__ INFO: \u001b[0mVal 16\n",
      "\u001b[32m[2020-06-22 16:37:40] __main__ INFO: \u001b[0mEpoch 16 loss 2.1922 acc@1 0.1628 acc@5 0.6248\n",
      "\u001b[32m[2020-06-22 16:37:40] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 16:37:40] __main__ INFO: \u001b[0mTrain 17 5616\n",
      "\u001b[32m[2020-06-22 16:37:49] __main__ INFO: \u001b[0mEpoch 17 Step 100/351 lr 0.100000 loss 2.2492 (2.1933) acc@1 0.1562 (0.1712) acc@5 0.6250 (0.6172)\n",
      "\u001b[32m[2020-06-22 16:37:58] __main__ INFO: \u001b[0mEpoch 17 Step 200/351 lr 0.100000 loss 2.1781 (2.1947) acc@1 0.1484 (0.1672) acc@5 0.6641 (0.6148)\n",
      "\u001b[32m[2020-06-22 16:38:08] __main__ INFO: \u001b[0mEpoch 17 Step 300/351 lr 0.100000 loss 2.2572 (2.1950) acc@1 0.1484 (0.1652) acc@5 0.6250 (0.6161)\n",
      "\u001b[32m[2020-06-22 16:38:12] __main__ INFO: \u001b[0mEpoch 17 Step 351/351 lr 0.100000 loss 2.2387 (2.1941) acc@1 0.1641 (0.1660) acc@5 0.5703 (0.6182)\n",
      "\u001b[32m[2020-06-22 16:38:12] __main__ INFO: \u001b[0mElapsed 32.72\n",
      "\u001b[32m[2020-06-22 16:38:12] __main__ INFO: \u001b[0mVal 17\n",
      "\u001b[32m[2020-06-22 16:38:14] __main__ INFO: \u001b[0mEpoch 17 loss 2.2466 acc@1 0.1544 acc@5 0.6056\n",
      "\u001b[32m[2020-06-22 16:38:14] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 16:38:14] __main__ INFO: \u001b[0mTrain 18 5967\n",
      "\u001b[32m[2020-06-22 16:38:23] __main__ INFO: \u001b[0mEpoch 18 Step 100/351 lr 0.100000 loss 2.1753 (2.1864) acc@1 0.1406 (0.1671) acc@5 0.6016 (0.6200)\n",
      "\u001b[32m[2020-06-22 16:38:32] __main__ INFO: \u001b[0mEpoch 18 Step 200/351 lr 0.100000 loss 2.2185 (2.1865) acc@1 0.1484 (0.1673) acc@5 0.5938 (0.6230)\n",
      "\u001b[32m[2020-06-22 16:38:42] __main__ INFO: \u001b[0mEpoch 18 Step 300/351 lr 0.100000 loss 2.1712 (2.1852) acc@1 0.1172 (0.1670) acc@5 0.7188 (0.6242)\n",
      "\u001b[32m[2020-06-22 16:38:46] __main__ INFO: \u001b[0mEpoch 18 Step 351/351 lr 0.100000 loss 2.0972 (2.1852) acc@1 0.2344 (0.1675) acc@5 0.6953 (0.6239)\n",
      "\u001b[32m[2020-06-22 16:38:46] __main__ INFO: \u001b[0mElapsed 32.77\n",
      "\u001b[32m[2020-06-22 16:38:46] __main__ INFO: \u001b[0mVal 18\n",
      "\u001b[32m[2020-06-22 16:38:47] __main__ INFO: \u001b[0mEpoch 18 loss 2.1988 acc@1 0.1526 acc@5 0.6144\n",
      "\u001b[32m[2020-06-22 16:38:47] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 16:38:47] __main__ INFO: \u001b[0mTrain 19 6318\n",
      "\u001b[32m[2020-06-22 16:38:57] __main__ INFO: \u001b[0mEpoch 19 Step 100/351 lr 0.100000 loss 2.1033 (2.1758) acc@1 0.2031 (0.1736) acc@5 0.6641 (0.6252)\n",
      "\u001b[32m[2020-06-22 16:39:06] __main__ INFO: \u001b[0mEpoch 19 Step 200/351 lr 0.100000 loss 2.2064 (2.1725) acc@1 0.1875 (0.1727) acc@5 0.6406 (0.6253)\n",
      "\u001b[32m[2020-06-22 16:39:15] __main__ INFO: \u001b[0mEpoch 19 Step 300/351 lr 0.100000 loss 2.1521 (2.1718) acc@1 0.1641 (0.1745) acc@5 0.5938 (0.6262)\n",
      "\u001b[32m[2020-06-22 16:39:20] __main__ INFO: \u001b[0mEpoch 19 Step 351/351 lr 0.100000 loss 2.1635 (2.1725) acc@1 0.1875 (0.1747) acc@5 0.5859 (0.6267)\n",
      "\u001b[32m[2020-06-22 16:39:20] __main__ INFO: \u001b[0mElapsed 32.76\n",
      "\u001b[32m[2020-06-22 16:39:20] __main__ INFO: \u001b[0mVal 19\n",
      "\u001b[32m[2020-06-22 16:39:21] __main__ INFO: \u001b[0mEpoch 19 loss 2.1630 acc@1 0.1734 acc@5 0.6224\n",
      "\u001b[32m[2020-06-22 16:39:21] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 16:39:21] __main__ INFO: \u001b[0mTrain 20 6669\n",
      "\u001b[32m[2020-06-22 16:39:31] __main__ INFO: \u001b[0mEpoch 20 Step 100/351 lr 0.100000 loss 2.1089 (2.1522) acc@1 0.1875 (0.1795) acc@5 0.6172 (0.6397)\n",
      "\u001b[32m[2020-06-22 16:39:40] __main__ INFO: \u001b[0mEpoch 20 Step 200/351 lr 0.100000 loss 2.1723 (2.1596) acc@1 0.1641 (0.1765) acc@5 0.6406 (0.6368)\n",
      "\u001b[32m[2020-06-22 16:39:49] __main__ INFO: \u001b[0mEpoch 20 Step 300/351 lr 0.100000 loss 2.1911 (2.1617) acc@1 0.1875 (0.1782) acc@5 0.5859 (0.6362)\n",
      "\u001b[32m[2020-06-22 16:39:54] __main__ INFO: \u001b[0mEpoch 20 Step 351/351 lr 0.100000 loss 2.0725 (2.1616) acc@1 0.2109 (0.1791) acc@5 0.6719 (0.6374)\n",
      "\u001b[32m[2020-06-22 16:39:54] __main__ INFO: \u001b[0mElapsed 32.72\n",
      "\u001b[32m[2020-06-22 16:39:54] __main__ INFO: \u001b[0mVal 20\n",
      "\u001b[32m[2020-06-22 16:39:55] __main__ INFO: \u001b[0mEpoch 20 loss 2.1978 acc@1 0.1638 acc@5 0.6232\n",
      "\u001b[32m[2020-06-22 16:39:55] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 16:39:55] __main__ INFO: \u001b[0mTrain 21 7020\n",
      "\u001b[32m[2020-06-22 16:40:04] __main__ INFO: \u001b[0mEpoch 21 Step 100/351 lr 0.100000 loss 2.1031 (2.1442) acc@1 0.2188 (0.1895) acc@5 0.6172 (0.6467)\n",
      "\u001b[32m[2020-06-22 16:40:14] __main__ INFO: \u001b[0mEpoch 21 Step 200/351 lr 0.100000 loss 2.0732 (2.1494) acc@1 0.2109 (0.1861) acc@5 0.7188 (0.6420)\n",
      "\u001b[32m[2020-06-22 16:40:23] __main__ INFO: \u001b[0mEpoch 21 Step 300/351 lr 0.100000 loss 2.1844 (2.1483) acc@1 0.1797 (0.1874) acc@5 0.5703 (0.6378)\n",
      "\u001b[32m[2020-06-22 16:40:28] __main__ INFO: \u001b[0mEpoch 21 Step 351/351 lr 0.100000 loss 2.0875 (2.1473) acc@1 0.1797 (0.1865) acc@5 0.6797 (0.6372)\n",
      "\u001b[32m[2020-06-22 16:40:28] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 16:40:28] __main__ INFO: \u001b[0mVal 21\n",
      "\u001b[32m[2020-06-22 16:40:29] __main__ INFO: \u001b[0mEpoch 21 loss 2.1753 acc@1 0.1770 acc@5 0.6220\n",
      "\u001b[32m[2020-06-22 16:40:29] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 16:40:29] __main__ INFO: \u001b[0mTrain 22 7371\n",
      "\u001b[32m[2020-06-22 16:40:38] __main__ INFO: \u001b[0mEpoch 22 Step 100/351 lr 0.100000 loss 2.2416 (2.1492) acc@1 0.1719 (0.1850) acc@5 0.5391 (0.6416)\n",
      "\u001b[32m[2020-06-22 16:40:48] __main__ INFO: \u001b[0mEpoch 22 Step 200/351 lr 0.100000 loss 2.1612 (2.1443) acc@1 0.1953 (0.1890) acc@5 0.5625 (0.6454)\n",
      "\u001b[32m[2020-06-22 16:40:57] __main__ INFO: \u001b[0mEpoch 22 Step 300/351 lr 0.100000 loss 2.1464 (2.1400) acc@1 0.1719 (0.1903) acc@5 0.6406 (0.6446)\n",
      "\u001b[32m[2020-06-22 16:41:02] __main__ INFO: \u001b[0mEpoch 22 Step 351/351 lr 0.100000 loss 2.1397 (2.1377) acc@1 0.1875 (0.1908) acc@5 0.6172 (0.6453)\n",
      "\u001b[32m[2020-06-22 16:41:02] __main__ INFO: \u001b[0mElapsed 32.74\n",
      "\u001b[32m[2020-06-22 16:41:02] __main__ INFO: \u001b[0mVal 22\n",
      "\u001b[32m[2020-06-22 16:41:03] __main__ INFO: \u001b[0mEpoch 22 loss 2.2357 acc@1 0.1624 acc@5 0.6292\n",
      "\u001b[32m[2020-06-22 16:41:03] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 16:41:03] __main__ INFO: \u001b[0mTrain 23 7722\n",
      "\u001b[32m[2020-06-22 16:41:12] __main__ INFO: \u001b[0mEpoch 23 Step 100/351 lr 0.100000 loss 2.0883 (2.1338) acc@1 0.2344 (0.1937) acc@5 0.7344 (0.6441)\n",
      "\u001b[32m[2020-06-22 16:41:21] __main__ INFO: \u001b[0mEpoch 23 Step 200/351 lr 0.100000 loss 2.1155 (2.1292) acc@1 0.1953 (0.1955) acc@5 0.6328 (0.6475)\n",
      "\u001b[32m[2020-06-22 16:41:31] __main__ INFO: \u001b[0mEpoch 23 Step 300/351 lr 0.100000 loss 2.1319 (2.1275) acc@1 0.2109 (0.1959) acc@5 0.6016 (0.6449)\n",
      "\u001b[32m[2020-06-22 16:41:35] __main__ INFO: \u001b[0mEpoch 23 Step 351/351 lr 0.100000 loss 2.1093 (2.1276) acc@1 0.2812 (0.1955) acc@5 0.6641 (0.6450)\n",
      "\u001b[32m[2020-06-22 16:41:35] __main__ INFO: \u001b[0mElapsed 32.77\n",
      "\u001b[32m[2020-06-22 16:41:35] __main__ INFO: \u001b[0mVal 23\n",
      "\u001b[32m[2020-06-22 16:41:36] __main__ INFO: \u001b[0mEpoch 23 loss 2.1357 acc@1 0.1876 acc@5 0.6522\n",
      "\u001b[32m[2020-06-22 16:41:36] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 16:41:36] __main__ INFO: \u001b[0mTrain 24 8073\n",
      "\u001b[32m[2020-06-22 16:41:46] __main__ INFO: \u001b[0mEpoch 24 Step 100/351 lr 0.100000 loss 2.1705 (2.1101) acc@1 0.2109 (0.2027) acc@5 0.6719 (0.6509)\n",
      "\u001b[32m[2020-06-22 16:41:55] __main__ INFO: \u001b[0mEpoch 24 Step 200/351 lr 0.100000 loss 2.0798 (2.1179) acc@1 0.2500 (0.1995) acc@5 0.6875 (0.6462)\n",
      "\u001b[32m[2020-06-22 16:42:04] __main__ INFO: \u001b[0mEpoch 24 Step 300/351 lr 0.100000 loss 2.1886 (2.1197) acc@1 0.2266 (0.1994) acc@5 0.6641 (0.6450)\n",
      "\u001b[32m[2020-06-22 16:42:09] __main__ INFO: \u001b[0mEpoch 24 Step 351/351 lr 0.100000 loss 2.1334 (2.1208) acc@1 0.1953 (0.1984) acc@5 0.6484 (0.6453)\n",
      "\u001b[32m[2020-06-22 16:42:09] __main__ INFO: \u001b[0mElapsed 32.78\n",
      "\u001b[32m[2020-06-22 16:42:09] __main__ INFO: \u001b[0mVal 24\n",
      "\u001b[32m[2020-06-22 16:42:10] __main__ INFO: \u001b[0mEpoch 24 loss 2.1528 acc@1 0.1838 acc@5 0.6376\n",
      "\u001b[32m[2020-06-22 16:42:10] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 16:42:10] __main__ INFO: \u001b[0mTrain 25 8424\n",
      "\u001b[32m[2020-06-22 16:42:20] __main__ INFO: \u001b[0mEpoch 25 Step 100/351 lr 0.100000 loss 2.1077 (2.1124) acc@1 0.1875 (0.2017) acc@5 0.7188 (0.6516)\n",
      "\u001b[32m[2020-06-22 16:42:29] __main__ INFO: \u001b[0mEpoch 25 Step 200/351 lr 0.100000 loss 2.0790 (2.1136) acc@1 0.1562 (0.1993) acc@5 0.6094 (0.6523)\n",
      "\u001b[32m[2020-06-22 16:42:38] __main__ INFO: \u001b[0mEpoch 25 Step 300/351 lr 0.100000 loss 1.9843 (2.1129) acc@1 0.2656 (0.1994) acc@5 0.7188 (0.6504)\n",
      "\u001b[32m[2020-06-22 16:42:43] __main__ INFO: \u001b[0mEpoch 25 Step 351/351 lr 0.100000 loss 2.1130 (2.1126) acc@1 0.2344 (0.2004) acc@5 0.6562 (0.6526)\n",
      "\u001b[32m[2020-06-22 16:42:43] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 16:42:43] __main__ INFO: \u001b[0mVal 25\n",
      "\u001b[32m[2020-06-22 16:42:44] __main__ INFO: \u001b[0mEpoch 25 loss 2.1246 acc@1 0.1930 acc@5 0.6358\n",
      "\u001b[32m[2020-06-22 16:42:44] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 16:42:44] __main__ INFO: \u001b[0mTrain 26 8775\n",
      "\u001b[32m[2020-06-22 16:42:54] __main__ INFO: \u001b[0mEpoch 26 Step 100/351 lr 0.100000 loss 2.2072 (2.0996) acc@1 0.1406 (0.2065) acc@5 0.6094 (0.6580)\n",
      "\u001b[32m[2020-06-22 16:43:03] __main__ INFO: \u001b[0mEpoch 26 Step 200/351 lr 0.100000 loss 2.1216 (2.0971) acc@1 0.1875 (0.2086) acc@5 0.6250 (0.6590)\n",
      "\u001b[32m[2020-06-22 16:43:12] __main__ INFO: \u001b[0mEpoch 26 Step 300/351 lr 0.100000 loss 2.1151 (2.0993) acc@1 0.2109 (0.2092) acc@5 0.6953 (0.6586)\n",
      "\u001b[32m[2020-06-22 16:43:17] __main__ INFO: \u001b[0mEpoch 26 Step 351/351 lr 0.100000 loss 2.0818 (2.1013) acc@1 0.1797 (0.2079) acc@5 0.6562 (0.6571)\n",
      "\u001b[32m[2020-06-22 16:43:17] __main__ INFO: \u001b[0mElapsed 32.75\n",
      "\u001b[32m[2020-06-22 16:43:17] __main__ INFO: \u001b[0mVal 26\n",
      "\u001b[32m[2020-06-22 16:43:18] __main__ INFO: \u001b[0mEpoch 26 loss 2.1137 acc@1 0.1908 acc@5 0.6462\n",
      "\u001b[32m[2020-06-22 16:43:18] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 16:43:18] __main__ INFO: \u001b[0mTrain 27 9126\n",
      "\u001b[32m[2020-06-22 16:43:27] __main__ INFO: \u001b[0mEpoch 27 Step 100/351 lr 0.100000 loss 2.1830 (2.1009) acc@1 0.1797 (0.2101) acc@5 0.5938 (0.6562)\n",
      "\u001b[32m[2020-06-22 16:43:37] __main__ INFO: \u001b[0mEpoch 27 Step 200/351 lr 0.100000 loss 1.9265 (2.0957) acc@1 0.3125 (0.2105) acc@5 0.7266 (0.6608)\n",
      "\u001b[32m[2020-06-22 16:43:46] __main__ INFO: \u001b[0mEpoch 27 Step 300/351 lr 0.100000 loss 1.9638 (2.0963) acc@1 0.2812 (0.2095) acc@5 0.6797 (0.6574)\n",
      "\u001b[32m[2020-06-22 16:43:51] __main__ INFO: \u001b[0mEpoch 27 Step 351/351 lr 0.100000 loss 2.0884 (2.0953) acc@1 0.2812 (0.2099) acc@5 0.7188 (0.6575)\n",
      "\u001b[32m[2020-06-22 16:43:51] __main__ INFO: \u001b[0mElapsed 32.73\n",
      "\u001b[32m[2020-06-22 16:43:51] __main__ INFO: \u001b[0mVal 27\n",
      "\u001b[32m[2020-06-22 16:43:52] __main__ INFO: \u001b[0mEpoch 27 loss 2.1630 acc@1 0.1898 acc@5 0.6370\n",
      "\u001b[32m[2020-06-22 16:43:52] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 16:43:52] __main__ INFO: \u001b[0mTrain 28 9477\n",
      "\u001b[32m[2020-06-22 16:44:01] __main__ INFO: \u001b[0mEpoch 28 Step 100/351 lr 0.100000 loss 2.0542 (2.0873) acc@1 0.1953 (0.2130) acc@5 0.7031 (0.6613)\n",
      "\u001b[32m[2020-06-22 16:44:10] __main__ INFO: \u001b[0mEpoch 28 Step 200/351 lr 0.100000 loss 2.0193 (2.0869) acc@1 0.2734 (0.2132) acc@5 0.6562 (0.6584)\n",
      "\u001b[32m[2020-06-22 16:44:20] __main__ INFO: \u001b[0mEpoch 28 Step 300/351 lr 0.100000 loss 1.9879 (2.0861) acc@1 0.2109 (0.2118) acc@5 0.7266 (0.6591)\n",
      "\u001b[32m[2020-06-22 16:44:24] __main__ INFO: \u001b[0mEpoch 28 Step 351/351 lr 0.100000 loss 2.1462 (2.0872) acc@1 0.2031 (0.2118) acc@5 0.5625 (0.6589)\n",
      "\u001b[32m[2020-06-22 16:44:24] __main__ INFO: \u001b[0mElapsed 32.75\n",
      "\u001b[32m[2020-06-22 16:44:24] __main__ INFO: \u001b[0mVal 28\n",
      "\u001b[32m[2020-06-22 16:44:26] __main__ INFO: \u001b[0mEpoch 28 loss 2.1367 acc@1 0.1780 acc@5 0.6380\n",
      "\u001b[32m[2020-06-22 16:44:26] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 16:44:26] __main__ INFO: \u001b[0mTrain 29 9828\n",
      "\u001b[32m[2020-06-22 16:44:35] __main__ INFO: \u001b[0mEpoch 29 Step 100/351 lr 0.100000 loss 2.1167 (2.0756) acc@1 0.2422 (0.2191) acc@5 0.6719 (0.6679)\n",
      "\u001b[32m[2020-06-22 16:44:44] __main__ INFO: \u001b[0mEpoch 29 Step 200/351 lr 0.100000 loss 2.0023 (2.0791) acc@1 0.2422 (0.2198) acc@5 0.7344 (0.6629)\n",
      "\u001b[32m[2020-06-22 16:44:54] __main__ INFO: \u001b[0mEpoch 29 Step 300/351 lr 0.100000 loss 2.0491 (2.0773) acc@1 0.2109 (0.2185) acc@5 0.6484 (0.6628)\n",
      "\u001b[32m[2020-06-22 16:44:58] __main__ INFO: \u001b[0mEpoch 29 Step 351/351 lr 0.100000 loss 1.8783 (2.0759) acc@1 0.3516 (0.2194) acc@5 0.7969 (0.6619)\n",
      "\u001b[32m[2020-06-22 16:44:58] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 16:44:58] __main__ INFO: \u001b[0mVal 29\n",
      "\u001b[32m[2020-06-22 16:44:59] __main__ INFO: \u001b[0mEpoch 29 loss 2.1910 acc@1 0.1814 acc@5 0.6476\n",
      "\u001b[32m[2020-06-22 16:44:59] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 16:44:59] __main__ INFO: \u001b[0mTrain 30 10179\n",
      "\u001b[32m[2020-06-22 16:45:09] __main__ INFO: \u001b[0mEpoch 30 Step 100/351 lr 0.100000 loss 2.0480 (2.0690) acc@1 0.2422 (0.2184) acc@5 0.6875 (0.6657)\n",
      "\u001b[32m[2020-06-22 16:45:18] __main__ INFO: \u001b[0mEpoch 30 Step 200/351 lr 0.100000 loss 2.0725 (2.0714) acc@1 0.2344 (0.2197) acc@5 0.6406 (0.6634)\n",
      "\u001b[32m[2020-06-22 16:45:27] __main__ INFO: \u001b[0mEpoch 30 Step 300/351 lr 0.100000 loss 2.0000 (2.0726) acc@1 0.1875 (0.2191) acc@5 0.6641 (0.6635)\n",
      "\u001b[32m[2020-06-22 16:45:32] __main__ INFO: \u001b[0mEpoch 30 Step 351/351 lr 0.100000 loss 2.1133 (2.0728) acc@1 0.1953 (0.2196) acc@5 0.7266 (0.6627)\n",
      "\u001b[32m[2020-06-22 16:45:32] __main__ INFO: \u001b[0mElapsed 32.77\n",
      "\u001b[32m[2020-06-22 16:45:32] __main__ INFO: \u001b[0mVal 30\n",
      "\u001b[32m[2020-06-22 16:45:33] __main__ INFO: \u001b[0mEpoch 30 loss 2.0765 acc@1 0.2142 acc@5 0.6694\n",
      "\u001b[32m[2020-06-22 16:45:33] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 16:45:33] __main__ INFO: \u001b[0mTrain 31 10530\n",
      "\u001b[32m[2020-06-22 16:45:43] __main__ INFO: \u001b[0mEpoch 31 Step 100/351 lr 0.100000 loss 2.0900 (2.0628) acc@1 0.2188 (0.2200) acc@5 0.6406 (0.6599)\n",
      "\u001b[32m[2020-06-22 16:45:52] __main__ INFO: \u001b[0mEpoch 31 Step 200/351 lr 0.100000 loss 2.0838 (2.0590) acc@1 0.2031 (0.2220) acc@5 0.6406 (0.6648)\n",
      "\u001b[32m[2020-06-22 16:46:01] __main__ INFO: \u001b[0mEpoch 31 Step 300/351 lr 0.100000 loss 2.0622 (2.0615) acc@1 0.2188 (0.2226) acc@5 0.6875 (0.6660)\n",
      "\u001b[32m[2020-06-22 16:46:06] __main__ INFO: \u001b[0mEpoch 31 Step 351/351 lr 0.100000 loss 2.0929 (2.0641) acc@1 0.2031 (0.2231) acc@5 0.5938 (0.6651)\n",
      "\u001b[32m[2020-06-22 16:46:06] __main__ INFO: \u001b[0mElapsed 32.75\n",
      "\u001b[32m[2020-06-22 16:46:06] __main__ INFO: \u001b[0mVal 31\n",
      "\u001b[32m[2020-06-22 16:46:07] __main__ INFO: \u001b[0mEpoch 31 loss 2.0995 acc@1 0.2072 acc@5 0.6502\n",
      "\u001b[32m[2020-06-22 16:46:07] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 16:46:07] __main__ INFO: \u001b[0mTrain 32 10881\n",
      "\u001b[32m[2020-06-22 16:46:16] __main__ INFO: \u001b[0mEpoch 32 Step 100/351 lr 0.100000 loss 2.0882 (2.0575) acc@1 0.1875 (0.2248) acc@5 0.6562 (0.6732)\n",
      "\u001b[32m[2020-06-22 16:46:26] __main__ INFO: \u001b[0mEpoch 32 Step 200/351 lr 0.100000 loss 2.1215 (2.0582) acc@1 0.1797 (0.2247) acc@5 0.6172 (0.6686)\n",
      "\u001b[32m[2020-06-22 16:46:35] __main__ INFO: \u001b[0mEpoch 32 Step 300/351 lr 0.100000 loss 2.0132 (2.0577) acc@1 0.2344 (0.2261) acc@5 0.6953 (0.6690)\n",
      "\u001b[32m[2020-06-22 16:46:40] __main__ INFO: \u001b[0mEpoch 32 Step 351/351 lr 0.100000 loss 2.0273 (2.0592) acc@1 0.2500 (0.2255) acc@5 0.6406 (0.6682)\n",
      "\u001b[32m[2020-06-22 16:46:40] __main__ INFO: \u001b[0mElapsed 32.71\n",
      "\u001b[32m[2020-06-22 16:46:40] __main__ INFO: \u001b[0mVal 32\n",
      "\u001b[32m[2020-06-22 16:46:41] __main__ INFO: \u001b[0mEpoch 32 loss 2.0864 acc@1 0.2130 acc@5 0.6656\n",
      "\u001b[32m[2020-06-22 16:46:41] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 16:46:41] __main__ INFO: \u001b[0mTrain 33 11232\n",
      "\u001b[32m[2020-06-22 16:46:50] __main__ INFO: \u001b[0mEpoch 33 Step 100/351 lr 0.100000 loss 2.0501 (2.0513) acc@1 0.2578 (0.2274) acc@5 0.6250 (0.6673)\n",
      "\u001b[32m[2020-06-22 16:46:59] __main__ INFO: \u001b[0mEpoch 33 Step 200/351 lr 0.100000 loss 1.9950 (2.0501) acc@1 0.2422 (0.2269) acc@5 0.6953 (0.6671)\n",
      "\u001b[32m[2020-06-22 16:47:09] __main__ INFO: \u001b[0mEpoch 33 Step 300/351 lr 0.100000 loss 2.0735 (2.0495) acc@1 0.2344 (0.2279) acc@5 0.7031 (0.6679)\n",
      "\u001b[32m[2020-06-22 16:47:13] __main__ INFO: \u001b[0mEpoch 33 Step 351/351 lr 0.100000 loss 2.0486 (2.0503) acc@1 0.2188 (0.2283) acc@5 0.6719 (0.6678)\n",
      "\u001b[32m[2020-06-22 16:47:14] __main__ INFO: \u001b[0mElapsed 32.75\n",
      "\u001b[32m[2020-06-22 16:47:14] __main__ INFO: \u001b[0mVal 33\n",
      "\u001b[32m[2020-06-22 16:47:15] __main__ INFO: \u001b[0mEpoch 33 loss 2.0503 acc@1 0.2268 acc@5 0.6618\n",
      "\u001b[32m[2020-06-22 16:47:15] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 16:47:15] __main__ INFO: \u001b[0mTrain 34 11583\n",
      "\u001b[32m[2020-06-22 16:47:24] __main__ INFO: \u001b[0mEpoch 34 Step 100/351 lr 0.100000 loss 1.9994 (2.0474) acc@1 0.2656 (0.2321) acc@5 0.6797 (0.6722)\n",
      "\u001b[32m[2020-06-22 16:47:33] __main__ INFO: \u001b[0mEpoch 34 Step 200/351 lr 0.100000 loss 2.1659 (2.0440) acc@1 0.2578 (0.2320) acc@5 0.6797 (0.6693)\n",
      "\u001b[32m[2020-06-22 16:47:43] __main__ INFO: \u001b[0mEpoch 34 Step 300/351 lr 0.100000 loss 2.0369 (2.0453) acc@1 0.2109 (0.2310) acc@5 0.6797 (0.6706)\n",
      "\u001b[32m[2020-06-22 16:47:47] __main__ INFO: \u001b[0mEpoch 34 Step 351/351 lr 0.100000 loss 1.9892 (2.0447) acc@1 0.2500 (0.2305) acc@5 0.7500 (0.6706)\n",
      "\u001b[32m[2020-06-22 16:47:47] __main__ INFO: \u001b[0mElapsed 32.72\n",
      "\u001b[32m[2020-06-22 16:47:47] __main__ INFO: \u001b[0mVal 34\n",
      "\u001b[32m[2020-06-22 16:47:48] __main__ INFO: \u001b[0mEpoch 34 loss 2.1386 acc@1 0.2100 acc@5 0.6504\n",
      "\u001b[32m[2020-06-22 16:47:48] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 16:47:48] __main__ INFO: \u001b[0mTrain 35 11934\n",
      "\u001b[32m[2020-06-22 16:47:58] __main__ INFO: \u001b[0mEpoch 35 Step 100/351 lr 0.100000 loss 2.0192 (2.0339) acc@1 0.2656 (0.2374) acc@5 0.7734 (0.6719)\n",
      "\u001b[32m[2020-06-22 16:48:07] __main__ INFO: \u001b[0mEpoch 35 Step 200/351 lr 0.100000 loss 2.0261 (2.0370) acc@1 0.2734 (0.2379) acc@5 0.6562 (0.6703)\n",
      "\u001b[32m[2020-06-22 16:48:16] __main__ INFO: \u001b[0mEpoch 35 Step 300/351 lr 0.100000 loss 2.1000 (2.0362) acc@1 0.1484 (0.2355) acc@5 0.6797 (0.6724)\n",
      "\u001b[32m[2020-06-22 16:48:21] __main__ INFO: \u001b[0mEpoch 35 Step 351/351 lr 0.100000 loss 2.0678 (2.0386) acc@1 0.2266 (0.2347) acc@5 0.7109 (0.6711)\n",
      "\u001b[32m[2020-06-22 16:48:21] __main__ INFO: \u001b[0mElapsed 32.74\n",
      "\u001b[32m[2020-06-22 16:48:21] __main__ INFO: \u001b[0mVal 35\n",
      "\u001b[32m[2020-06-22 16:48:22] __main__ INFO: \u001b[0mEpoch 35 loss 2.1123 acc@1 0.2148 acc@5 0.6564\n",
      "\u001b[32m[2020-06-22 16:48:22] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 16:48:22] __main__ INFO: \u001b[0mTrain 36 12285\n",
      "\u001b[32m[2020-06-22 16:48:32] __main__ INFO: \u001b[0mEpoch 36 Step 100/351 lr 0.100000 loss 1.9441 (2.0320) acc@1 0.3203 (0.2402) acc@5 0.7188 (0.6727)\n",
      "\u001b[32m[2020-06-22 16:48:41] __main__ INFO: \u001b[0mEpoch 36 Step 200/351 lr 0.100000 loss 2.0461 (2.0287) acc@1 0.2188 (0.2383) acc@5 0.6484 (0.6736)\n",
      "\u001b[32m[2020-06-22 16:48:50] __main__ INFO: \u001b[0mEpoch 36 Step 300/351 lr 0.100000 loss 2.0952 (2.0304) acc@1 0.1797 (0.2364) acc@5 0.6016 (0.6733)\n",
      "\u001b[32m[2020-06-22 16:48:55] __main__ INFO: \u001b[0mEpoch 36 Step 351/351 lr 0.100000 loss 2.0694 (2.0308) acc@1 0.2344 (0.2358) acc@5 0.6328 (0.6738)\n",
      "\u001b[32m[2020-06-22 16:48:55] __main__ INFO: \u001b[0mElapsed 32.78\n",
      "\u001b[32m[2020-06-22 16:48:55] __main__ INFO: \u001b[0mVal 36\n",
      "\u001b[32m[2020-06-22 16:48:56] __main__ INFO: \u001b[0mEpoch 36 loss 2.0539 acc@1 0.2292 acc@5 0.6652\n",
      "\u001b[32m[2020-06-22 16:48:56] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 16:48:56] __main__ INFO: \u001b[0mTrain 37 12636\n",
      "\u001b[32m[2020-06-22 16:49:05] __main__ INFO: \u001b[0mEpoch 37 Step 100/351 lr 0.100000 loss 2.0104 (2.0265) acc@1 0.2578 (0.2403) acc@5 0.6094 (0.6705)\n",
      "\u001b[32m[2020-06-22 16:49:15] __main__ INFO: \u001b[0mEpoch 37 Step 200/351 lr 0.100000 loss 2.1545 (2.0322) acc@1 0.2266 (0.2359) acc@5 0.6094 (0.6722)\n",
      "\u001b[32m[2020-06-22 16:49:24] __main__ INFO: \u001b[0mEpoch 37 Step 300/351 lr 0.100000 loss 1.9257 (2.0311) acc@1 0.3281 (0.2367) acc@5 0.7266 (0.6717)\n",
      "\u001b[32m[2020-06-22 16:49:29] __main__ INFO: \u001b[0mEpoch 37 Step 351/351 lr 0.100000 loss 2.0242 (2.0294) acc@1 0.2344 (0.2378) acc@5 0.6562 (0.6738)\n",
      "\u001b[32m[2020-06-22 16:49:29] __main__ INFO: \u001b[0mElapsed 32.75\n",
      "\u001b[32m[2020-06-22 16:49:29] __main__ INFO: \u001b[0mVal 37\n",
      "\u001b[32m[2020-06-22 16:49:30] __main__ INFO: \u001b[0mEpoch 37 loss 2.0448 acc@1 0.2298 acc@5 0.6758\n",
      "\u001b[32m[2020-06-22 16:49:30] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 16:49:30] __main__ INFO: \u001b[0mTrain 38 12987\n",
      "\u001b[32m[2020-06-22 16:49:39] __main__ INFO: \u001b[0mEpoch 38 Step 100/351 lr 0.100000 loss 2.0036 (2.0130) acc@1 0.3125 (0.2481) acc@5 0.7109 (0.6782)\n",
      "\u001b[32m[2020-06-22 16:49:48] __main__ INFO: \u001b[0mEpoch 38 Step 200/351 lr 0.100000 loss 2.0693 (2.0162) acc@1 0.2188 (0.2450) acc@5 0.6328 (0.6751)\n",
      "\u001b[32m[2020-06-22 16:49:58] __main__ INFO: \u001b[0mEpoch 38 Step 300/351 lr 0.100000 loss 1.9905 (2.0198) acc@1 0.2656 (0.2414) acc@5 0.7109 (0.6734)\n",
      "\u001b[32m[2020-06-22 16:50:02] __main__ INFO: \u001b[0mEpoch 38 Step 351/351 lr 0.100000 loss 2.0419 (2.0201) acc@1 0.2344 (0.2412) acc@5 0.6094 (0.6730)\n",
      "\u001b[32m[2020-06-22 16:50:03] __main__ INFO: \u001b[0mElapsed 32.74\n",
      "\u001b[32m[2020-06-22 16:50:03] __main__ INFO: \u001b[0mVal 38\n",
      "\u001b[32m[2020-06-22 16:50:04] __main__ INFO: \u001b[0mEpoch 38 loss 2.0582 acc@1 0.2240 acc@5 0.6666\n",
      "\u001b[32m[2020-06-22 16:50:04] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 16:50:04] __main__ INFO: \u001b[0mTrain 39 13338\n",
      "\u001b[32m[2020-06-22 16:50:13] __main__ INFO: \u001b[0mEpoch 39 Step 100/351 lr 0.100000 loss 2.0509 (2.0094) acc@1 0.2266 (0.2431) acc@5 0.6953 (0.6798)\n",
      "\u001b[32m[2020-06-22 16:50:22] __main__ INFO: \u001b[0mEpoch 39 Step 200/351 lr 0.100000 loss 2.0203 (2.0140) acc@1 0.1875 (0.2423) acc@5 0.6953 (0.6773)\n",
      "\u001b[32m[2020-06-22 16:50:32] __main__ INFO: \u001b[0mEpoch 39 Step 300/351 lr 0.100000 loss 2.0164 (2.0141) acc@1 0.2422 (0.2428) acc@5 0.6641 (0.6768)\n",
      "\u001b[32m[2020-06-22 16:50:36] __main__ INFO: \u001b[0mEpoch 39 Step 351/351 lr 0.100000 loss 2.0198 (2.0145) acc@1 0.2422 (0.2425) acc@5 0.7266 (0.6771)\n",
      "\u001b[32m[2020-06-22 16:50:36] __main__ INFO: \u001b[0mElapsed 32.73\n",
      "\u001b[32m[2020-06-22 16:50:36] __main__ INFO: \u001b[0mVal 39\n",
      "\u001b[32m[2020-06-22 16:50:37] __main__ INFO: \u001b[0mEpoch 39 loss 2.0519 acc@1 0.2220 acc@5 0.6662\n",
      "\u001b[32m[2020-06-22 16:50:37] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 16:50:37] __main__ INFO: \u001b[0mTrain 40 13689\n",
      "\u001b[32m[2020-06-22 16:50:47] __main__ INFO: \u001b[0mEpoch 40 Step 100/351 lr 0.100000 loss 1.9931 (2.0011) acc@1 0.2578 (0.2486) acc@5 0.7734 (0.6802)\n",
      "\u001b[32m[2020-06-22 16:50:56] __main__ INFO: \u001b[0mEpoch 40 Step 200/351 lr 0.100000 loss 1.9130 (2.0089) acc@1 0.2734 (0.2441) acc@5 0.7188 (0.6781)\n",
      "\u001b[32m[2020-06-22 16:51:05] __main__ INFO: \u001b[0mEpoch 40 Step 300/351 lr 0.100000 loss 1.9463 (2.0085) acc@1 0.2734 (0.2463) acc@5 0.6953 (0.6767)\n",
      "\u001b[32m[2020-06-22 16:51:10] __main__ INFO: \u001b[0mEpoch 40 Step 351/351 lr 0.100000 loss 2.0064 (2.0098) acc@1 0.2266 (0.2458) acc@5 0.6250 (0.6767)\n",
      "\u001b[32m[2020-06-22 16:51:10] __main__ INFO: \u001b[0mElapsed 32.77\n",
      "\u001b[32m[2020-06-22 16:51:10] __main__ INFO: \u001b[0mVal 40\n",
      "\u001b[32m[2020-06-22 16:51:11] __main__ INFO: \u001b[0mEpoch 40 loss 2.0417 acc@1 0.2268 acc@5 0.6776\n",
      "\u001b[32m[2020-06-22 16:51:11] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 16:51:11] __main__ INFO: \u001b[0mTrain 41 14040\n",
      "\u001b[32m[2020-06-22 16:51:21] __main__ INFO: \u001b[0mEpoch 41 Step 100/351 lr 0.100000 loss 2.0780 (1.9994) acc@1 0.2422 (0.2461) acc@5 0.6875 (0.6752)\n",
      "\u001b[32m[2020-06-22 16:51:30] __main__ INFO: \u001b[0mEpoch 41 Step 200/351 lr 0.100000 loss 1.9839 (2.0030) acc@1 0.1953 (0.2457) acc@5 0.7266 (0.6743)\n",
      "\u001b[32m[2020-06-22 16:51:39] __main__ INFO: \u001b[0mEpoch 41 Step 300/351 lr 0.100000 loss 2.0460 (2.0044) acc@1 0.2422 (0.2458) acc@5 0.7344 (0.6768)\n",
      "\u001b[32m[2020-06-22 16:51:44] __main__ INFO: \u001b[0mEpoch 41 Step 351/351 lr 0.100000 loss 1.9680 (2.0049) acc@1 0.3125 (0.2461) acc@5 0.7266 (0.6775)\n",
      "\u001b[32m[2020-06-22 16:51:44] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 16:51:44] __main__ INFO: \u001b[0mVal 41\n",
      "\u001b[32m[2020-06-22 16:51:45] __main__ INFO: \u001b[0mEpoch 41 loss 2.1179 acc@1 0.2176 acc@5 0.6478\n",
      "\u001b[32m[2020-06-22 16:51:45] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 16:51:45] __main__ INFO: \u001b[0mTrain 42 14391\n",
      "\u001b[32m[2020-06-22 16:51:54] __main__ INFO: \u001b[0mEpoch 42 Step 100/351 lr 0.100000 loss 1.9644 (1.9904) acc@1 0.2188 (0.2555) acc@5 0.6719 (0.6791)\n",
      "\u001b[32m[2020-06-22 16:52:04] __main__ INFO: \u001b[0mEpoch 42 Step 200/351 lr 0.100000 loss 2.0278 (1.9946) acc@1 0.2266 (0.2539) acc@5 0.6875 (0.6789)\n",
      "\u001b[32m[2020-06-22 16:52:13] __main__ INFO: \u001b[0mEpoch 42 Step 300/351 lr 0.100000 loss 2.0628 (1.9999) acc@1 0.2266 (0.2525) acc@5 0.6406 (0.6821)\n",
      "\u001b[32m[2020-06-22 16:52:18] __main__ INFO: \u001b[0mEpoch 42 Step 351/351 lr 0.100000 loss 2.0424 (1.9985) acc@1 0.2344 (0.2521) acc@5 0.6641 (0.6827)\n",
      "\u001b[32m[2020-06-22 16:52:18] __main__ INFO: \u001b[0mElapsed 32.75\n",
      "\u001b[32m[2020-06-22 16:52:18] __main__ INFO: \u001b[0mVal 42\n",
      "\u001b[32m[2020-06-22 16:52:19] __main__ INFO: \u001b[0mEpoch 42 loss 2.0559 acc@1 0.2252 acc@5 0.6716\n",
      "\u001b[32m[2020-06-22 16:52:19] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 16:52:19] __main__ INFO: \u001b[0mTrain 43 14742\n",
      "\u001b[32m[2020-06-22 16:52:28] __main__ INFO: \u001b[0mEpoch 43 Step 100/351 lr 0.100000 loss 1.9592 (1.9896) acc@1 0.2578 (0.2536) acc@5 0.6719 (0.6863)\n",
      "\u001b[32m[2020-06-22 16:52:38] __main__ INFO: \u001b[0mEpoch 43 Step 200/351 lr 0.100000 loss 2.0764 (1.9870) acc@1 0.2109 (0.2517) acc@5 0.6797 (0.6894)\n",
      "\u001b[32m[2020-06-22 16:52:47] __main__ INFO: \u001b[0mEpoch 43 Step 300/351 lr 0.100000 loss 2.0722 (1.9923) acc@1 0.2422 (0.2512) acc@5 0.7031 (0.6855)\n",
      "\u001b[32m[2020-06-22 16:52:52] __main__ INFO: \u001b[0mEpoch 43 Step 351/351 lr 0.100000 loss 2.0109 (1.9911) acc@1 0.2578 (0.2519) acc@5 0.6328 (0.6854)\n",
      "\u001b[32m[2020-06-22 16:52:52] __main__ INFO: \u001b[0mElapsed 32.73\n",
      "\u001b[32m[2020-06-22 16:52:52] __main__ INFO: \u001b[0mVal 43\n",
      "\u001b[32m[2020-06-22 16:52:53] __main__ INFO: \u001b[0mEpoch 43 loss 2.1533 acc@1 0.2322 acc@5 0.6644\n",
      "\u001b[32m[2020-06-22 16:52:53] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 16:52:53] __main__ INFO: \u001b[0mTrain 44 15093\n",
      "\u001b[32m[2020-06-22 16:53:02] __main__ INFO: \u001b[0mEpoch 44 Step 100/351 lr 0.100000 loss 1.9035 (1.9735) acc@1 0.2578 (0.2639) acc@5 0.6719 (0.6923)\n",
      "\u001b[32m[2020-06-22 16:53:11] __main__ INFO: \u001b[0mEpoch 44 Step 200/351 lr 0.100000 loss 1.9999 (1.9742) acc@1 0.2969 (0.2602) acc@5 0.6875 (0.6855)\n",
      "\u001b[32m[2020-06-22 16:53:21] __main__ INFO: \u001b[0mEpoch 44 Step 300/351 lr 0.100000 loss 1.9119 (1.9834) acc@1 0.2578 (0.2553) acc@5 0.6641 (0.6821)\n",
      "\u001b[32m[2020-06-22 16:53:25] __main__ INFO: \u001b[0mEpoch 44 Step 351/351 lr 0.100000 loss 1.9599 (1.9855) acc@1 0.2656 (0.2547) acc@5 0.6797 (0.6816)\n",
      "\u001b[32m[2020-06-22 16:53:25] __main__ INFO: \u001b[0mElapsed 32.75\n",
      "\u001b[32m[2020-06-22 16:53:25] __main__ INFO: \u001b[0mVal 44\n",
      "\u001b[32m[2020-06-22 16:53:26] __main__ INFO: \u001b[0mEpoch 44 loss 2.0512 acc@1 0.2386 acc@5 0.6702\n",
      "\u001b[32m[2020-06-22 16:53:26] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 16:53:26] __main__ INFO: \u001b[0mTrain 45 15444\n",
      "\u001b[32m[2020-06-22 16:53:36] __main__ INFO: \u001b[0mEpoch 45 Step 100/351 lr 0.100000 loss 1.9742 (1.9749) acc@1 0.2656 (0.2522) acc@5 0.6797 (0.6818)\n",
      "\u001b[32m[2020-06-22 16:53:45] __main__ INFO: \u001b[0mEpoch 45 Step 200/351 lr 0.100000 loss 2.0043 (1.9717) acc@1 0.2734 (0.2552) acc@5 0.6719 (0.6851)\n",
      "\u001b[32m[2020-06-22 16:53:54] __main__ INFO: \u001b[0mEpoch 45 Step 300/351 lr 0.100000 loss 1.9638 (1.9772) acc@1 0.2422 (0.2573) acc@5 0.6328 (0.6856)\n",
      "\u001b[32m[2020-06-22 16:53:59] __main__ INFO: \u001b[0mEpoch 45 Step 351/351 lr 0.100000 loss 1.9114 (1.9789) acc@1 0.3125 (0.2567) acc@5 0.7031 (0.6847)\n",
      "\u001b[32m[2020-06-22 16:53:59] __main__ INFO: \u001b[0mElapsed 32.73\n",
      "\u001b[32m[2020-06-22 16:53:59] __main__ INFO: \u001b[0mVal 45\n",
      "\u001b[32m[2020-06-22 16:54:00] __main__ INFO: \u001b[0mEpoch 45 loss 2.0503 acc@1 0.2262 acc@5 0.6654\n",
      "\u001b[32m[2020-06-22 16:54:00] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 16:54:00] __main__ INFO: \u001b[0mTrain 46 15795\n",
      "\u001b[32m[2020-06-22 16:54:10] __main__ INFO: \u001b[0mEpoch 46 Step 100/351 lr 0.100000 loss 2.0526 (1.9705) acc@1 0.2188 (0.2598) acc@5 0.6484 (0.6877)\n",
      "\u001b[32m[2020-06-22 16:54:19] __main__ INFO: \u001b[0mEpoch 46 Step 200/351 lr 0.100000 loss 2.0131 (1.9697) acc@1 0.2344 (0.2612) acc@5 0.7109 (0.6843)\n",
      "\u001b[32m[2020-06-22 16:54:28] __main__ INFO: \u001b[0mEpoch 46 Step 300/351 lr 0.100000 loss 2.0187 (1.9690) acc@1 0.2812 (0.2618) acc@5 0.6250 (0.6857)\n",
      "\u001b[32m[2020-06-22 16:54:33] __main__ INFO: \u001b[0mEpoch 46 Step 351/351 lr 0.100000 loss 1.9345 (1.9710) acc@1 0.2422 (0.2614) acc@5 0.6406 (0.6859)\n",
      "\u001b[32m[2020-06-22 16:54:33] __main__ INFO: \u001b[0mElapsed 32.74\n",
      "\u001b[32m[2020-06-22 16:54:33] __main__ INFO: \u001b[0mVal 46\n",
      "\u001b[32m[2020-06-22 16:54:34] __main__ INFO: \u001b[0mEpoch 46 loss 2.0911 acc@1 0.2196 acc@5 0.6532\n",
      "\u001b[32m[2020-06-22 16:54:34] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 16:54:34] __main__ INFO: \u001b[0mTrain 47 16146\n",
      "\u001b[32m[2020-06-22 16:54:43] __main__ INFO: \u001b[0mEpoch 47 Step 100/351 lr 0.100000 loss 2.0603 (1.9625) acc@1 0.2266 (0.2710) acc@5 0.6719 (0.6859)\n",
      "\u001b[32m[2020-06-22 16:54:53] __main__ INFO: \u001b[0mEpoch 47 Step 200/351 lr 0.100000 loss 2.0643 (1.9639) acc@1 0.2266 (0.2688) acc@5 0.7109 (0.6880)\n",
      "\u001b[32m[2020-06-22 16:55:02] __main__ INFO: \u001b[0mEpoch 47 Step 300/351 lr 0.100000 loss 1.9205 (1.9661) acc@1 0.2969 (0.2649) acc@5 0.7500 (0.6873)\n",
      "\u001b[32m[2020-06-22 16:55:07] __main__ INFO: \u001b[0mEpoch 47 Step 351/351 lr 0.100000 loss 1.9968 (1.9679) acc@1 0.1953 (0.2644) acc@5 0.7109 (0.6876)\n",
      "\u001b[32m[2020-06-22 16:55:07] __main__ INFO: \u001b[0mElapsed 32.76\n",
      "\u001b[32m[2020-06-22 16:55:07] __main__ INFO: \u001b[0mVal 47\n",
      "\u001b[32m[2020-06-22 16:55:08] __main__ INFO: \u001b[0mEpoch 47 loss 2.0414 acc@1 0.2318 acc@5 0.6602\n",
      "\u001b[32m[2020-06-22 16:55:08] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 16:55:08] __main__ INFO: \u001b[0mTrain 48 16497\n",
      "\u001b[32m[2020-06-22 16:55:17] __main__ INFO: \u001b[0mEpoch 48 Step 100/351 lr 0.100000 loss 2.0093 (1.9495) acc@1 0.2422 (0.2695) acc@5 0.6719 (0.6952)\n",
      "\u001b[32m[2020-06-22 16:55:27] __main__ INFO: \u001b[0mEpoch 48 Step 200/351 lr 0.100000 loss 1.9319 (1.9562) acc@1 0.2812 (0.2660) acc@5 0.6484 (0.6907)\n",
      "\u001b[32m[2020-06-22 16:55:36] __main__ INFO: \u001b[0mEpoch 48 Step 300/351 lr 0.100000 loss 1.9217 (1.9559) acc@1 0.2891 (0.2654) acc@5 0.6875 (0.6909)\n",
      "\u001b[32m[2020-06-22 16:55:41] __main__ INFO: \u001b[0mEpoch 48 Step 351/351 lr 0.100000 loss 2.0556 (1.9567) acc@1 0.1953 (0.2655) acc@5 0.6953 (0.6918)\n",
      "\u001b[32m[2020-06-22 16:55:41] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 16:55:41] __main__ INFO: \u001b[0mVal 48\n",
      "\u001b[32m[2020-06-22 16:55:42] __main__ INFO: \u001b[0mEpoch 48 loss 2.0435 acc@1 0.2356 acc@5 0.6782\n",
      "\u001b[32m[2020-06-22 16:55:42] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 16:55:42] __main__ INFO: \u001b[0mTrain 49 16848\n",
      "\u001b[32m[2020-06-22 16:55:51] __main__ INFO: \u001b[0mEpoch 49 Step 100/351 lr 0.100000 loss 2.0616 (1.9354) acc@1 0.2109 (0.2725) acc@5 0.6641 (0.6960)\n",
      "\u001b[32m[2020-06-22 16:56:00] __main__ INFO: \u001b[0mEpoch 49 Step 200/351 lr 0.100000 loss 2.0832 (1.9506) acc@1 0.3047 (0.2699) acc@5 0.6250 (0.6913)\n",
      "\u001b[32m[2020-06-22 16:56:10] __main__ INFO: \u001b[0mEpoch 49 Step 300/351 lr 0.100000 loss 1.9911 (1.9519) acc@1 0.2656 (0.2683) acc@5 0.6719 (0.6910)\n",
      "\u001b[32m[2020-06-22 16:56:14] __main__ INFO: \u001b[0mEpoch 49 Step 351/351 lr 0.100000 loss 1.8917 (1.9517) acc@1 0.2891 (0.2680) acc@5 0.6719 (0.6904)\n",
      "\u001b[32m[2020-06-22 16:56:14] __main__ INFO: \u001b[0mElapsed 32.74\n",
      "\u001b[32m[2020-06-22 16:56:14] __main__ INFO: \u001b[0mVal 49\n",
      "\u001b[32m[2020-06-22 16:56:15] __main__ INFO: \u001b[0mEpoch 49 loss 1.9927 acc@1 0.2504 acc@5 0.6786\n",
      "\u001b[32m[2020-06-22 16:56:15] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 16:56:15] __main__ INFO: \u001b[0mTrain 50 17199\n",
      "\u001b[32m[2020-06-22 16:56:25] __main__ INFO: \u001b[0mEpoch 50 Step 100/351 lr 0.100000 loss 2.0178 (1.9459) acc@1 0.2109 (0.2662) acc@5 0.6641 (0.6916)\n",
      "\u001b[32m[2020-06-22 16:56:34] __main__ INFO: \u001b[0mEpoch 50 Step 200/351 lr 0.100000 loss 2.0792 (1.9464) acc@1 0.1953 (0.2689) acc@5 0.6719 (0.6913)\n",
      "\u001b[32m[2020-06-22 16:56:43] __main__ INFO: \u001b[0mEpoch 50 Step 300/351 lr 0.100000 loss 1.9177 (1.9470) acc@1 0.3047 (0.2704) acc@5 0.7266 (0.6914)\n",
      "\u001b[32m[2020-06-22 16:56:48] __main__ INFO: \u001b[0mEpoch 50 Step 351/351 lr 0.100000 loss 1.9393 (1.9468) acc@1 0.2734 (0.2697) acc@5 0.6953 (0.6920)\n",
      "\u001b[32m[2020-06-22 16:56:48] __main__ INFO: \u001b[0mElapsed 32.77\n",
      "\u001b[32m[2020-06-22 16:56:48] __main__ INFO: \u001b[0mVal 50\n",
      "\u001b[32m[2020-06-22 16:56:49] __main__ INFO: \u001b[0mEpoch 50 loss 2.0338 acc@1 0.2398 acc@5 0.6780\n",
      "\u001b[32m[2020-06-22 16:56:49] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 16:56:49] __main__ INFO: \u001b[0mTrain 51 17550\n",
      "\u001b[32m[2020-06-22 16:56:59] __main__ INFO: \u001b[0mEpoch 51 Step 100/351 lr 0.100000 loss 1.9480 (1.9303) acc@1 0.2500 (0.2756) acc@5 0.6484 (0.6909)\n",
      "\u001b[32m[2020-06-22 16:57:08] __main__ INFO: \u001b[0mEpoch 51 Step 200/351 lr 0.100000 loss 1.9756 (1.9329) acc@1 0.2656 (0.2745) acc@5 0.7109 (0.6909)\n",
      "\u001b[32m[2020-06-22 16:57:17] __main__ INFO: \u001b[0mEpoch 51 Step 300/351 lr 0.100000 loss 1.8513 (1.9373) acc@1 0.2969 (0.2730) acc@5 0.7188 (0.6907)\n",
      "\u001b[32m[2020-06-22 16:57:22] __main__ INFO: \u001b[0mEpoch 51 Step 351/351 lr 0.100000 loss 1.9166 (1.9400) acc@1 0.2812 (0.2717) acc@5 0.7500 (0.6899)\n",
      "\u001b[32m[2020-06-22 16:57:22] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 16:57:22] __main__ INFO: \u001b[0mVal 51\n",
      "\u001b[32m[2020-06-22 16:57:23] __main__ INFO: \u001b[0mEpoch 51 loss 1.9919 acc@1 0.2458 acc@5 0.6734\n",
      "\u001b[32m[2020-06-22 16:57:23] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 16:57:23] __main__ INFO: \u001b[0mTrain 52 17901\n",
      "\u001b[32m[2020-06-22 16:57:33] __main__ INFO: \u001b[0mEpoch 52 Step 100/351 lr 0.100000 loss 1.9827 (1.9273) acc@1 0.2344 (0.2778) acc@5 0.6484 (0.6966)\n",
      "\u001b[32m[2020-06-22 16:57:42] __main__ INFO: \u001b[0mEpoch 52 Step 200/351 lr 0.100000 loss 1.9427 (1.9282) acc@1 0.2891 (0.2773) acc@5 0.6406 (0.6973)\n",
      "\u001b[32m[2020-06-22 16:57:51] __main__ INFO: \u001b[0mEpoch 52 Step 300/351 lr 0.100000 loss 1.7636 (1.9286) acc@1 0.3203 (0.2770) acc@5 0.7734 (0.6947)\n",
      "\u001b[32m[2020-06-22 16:57:56] __main__ INFO: \u001b[0mEpoch 52 Step 351/351 lr 0.100000 loss 2.1233 (1.9327) acc@1 0.2109 (0.2745) acc@5 0.7031 (0.6949)\n",
      "\u001b[32m[2020-06-22 16:57:56] __main__ INFO: \u001b[0mElapsed 32.74\n",
      "\u001b[32m[2020-06-22 16:57:56] __main__ INFO: \u001b[0mVal 52\n",
      "\u001b[32m[2020-06-22 16:57:57] __main__ INFO: \u001b[0mEpoch 52 loss 2.0567 acc@1 0.2468 acc@5 0.6714\n",
      "\u001b[32m[2020-06-22 16:57:57] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 16:57:57] __main__ INFO: \u001b[0mTrain 53 18252\n",
      "\u001b[32m[2020-06-22 16:58:06] __main__ INFO: \u001b[0mEpoch 53 Step 100/351 lr 0.100000 loss 1.9936 (1.9019) acc@1 0.1875 (0.2844) acc@5 0.6484 (0.7038)\n",
      "\u001b[32m[2020-06-22 16:58:16] __main__ INFO: \u001b[0mEpoch 53 Step 200/351 lr 0.100000 loss 1.9930 (1.9186) acc@1 0.2656 (0.2781) acc@5 0.6953 (0.6993)\n",
      "\u001b[32m[2020-06-22 16:58:25] __main__ INFO: \u001b[0mEpoch 53 Step 300/351 lr 0.100000 loss 2.1096 (1.9255) acc@1 0.2344 (0.2755) acc@5 0.5938 (0.6974)\n",
      "\u001b[32m[2020-06-22 16:58:30] __main__ INFO: \u001b[0mEpoch 53 Step 351/351 lr 0.100000 loss 1.9429 (1.9293) acc@1 0.3047 (0.2739) acc@5 0.6406 (0.6961)\n",
      "\u001b[32m[2020-06-22 16:58:30] __main__ INFO: \u001b[0mElapsed 32.77\n",
      "\u001b[32m[2020-06-22 16:58:30] __main__ INFO: \u001b[0mVal 53\n",
      "\u001b[32m[2020-06-22 16:58:31] __main__ INFO: \u001b[0mEpoch 53 loss 2.0246 acc@1 0.2568 acc@5 0.6758\n",
      "\u001b[32m[2020-06-22 16:58:31] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 16:58:31] __main__ INFO: \u001b[0mTrain 54 18603\n",
      "\u001b[32m[2020-06-22 16:58:40] __main__ INFO: \u001b[0mEpoch 54 Step 100/351 lr 0.100000 loss 1.8904 (1.9234) acc@1 0.3203 (0.2782) acc@5 0.7266 (0.6929)\n",
      "\u001b[32m[2020-06-22 16:58:49] __main__ INFO: \u001b[0mEpoch 54 Step 200/351 lr 0.100000 loss 2.0135 (1.9200) acc@1 0.2344 (0.2799) acc@5 0.6641 (0.6949)\n",
      "\u001b[32m[2020-06-22 16:58:59] __main__ INFO: \u001b[0mEpoch 54 Step 300/351 lr 0.100000 loss 1.8478 (1.9238) acc@1 0.3438 (0.2796) acc@5 0.7656 (0.6938)\n",
      "\u001b[32m[2020-06-22 16:59:04] __main__ INFO: \u001b[0mEpoch 54 Step 351/351 lr 0.100000 loss 1.9523 (1.9225) acc@1 0.2422 (0.2802) acc@5 0.6875 (0.6941)\n",
      "\u001b[32m[2020-06-22 16:59:04] __main__ INFO: \u001b[0mElapsed 32.77\n",
      "\u001b[32m[2020-06-22 16:59:04] __main__ INFO: \u001b[0mVal 54\n",
      "\u001b[32m[2020-06-22 16:59:05] __main__ INFO: \u001b[0mEpoch 54 loss 1.9964 acc@1 0.2526 acc@5 0.6710\n",
      "\u001b[32m[2020-06-22 16:59:05] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 16:59:05] __main__ INFO: \u001b[0mTrain 55 18954\n",
      "\u001b[32m[2020-06-22 16:59:14] __main__ INFO: \u001b[0mEpoch 55 Step 100/351 lr 0.100000 loss 1.9393 (1.9171) acc@1 0.2734 (0.2816) acc@5 0.6953 (0.7020)\n",
      "\u001b[32m[2020-06-22 16:59:23] __main__ INFO: \u001b[0mEpoch 55 Step 200/351 lr 0.100000 loss 1.9671 (1.9192) acc@1 0.2578 (0.2815) acc@5 0.6953 (0.6979)\n",
      "\u001b[32m[2020-06-22 16:59:33] __main__ INFO: \u001b[0mEpoch 55 Step 300/351 lr 0.100000 loss 1.9515 (1.9213) acc@1 0.2500 (0.2823) acc@5 0.7266 (0.6982)\n",
      "\u001b[32m[2020-06-22 16:59:37] __main__ INFO: \u001b[0mEpoch 55 Step 351/351 lr 0.100000 loss 1.8934 (1.9208) acc@1 0.2500 (0.2815) acc@5 0.6562 (0.6982)\n",
      "\u001b[32m[2020-06-22 16:59:37] __main__ INFO: \u001b[0mElapsed 32.72\n",
      "\u001b[32m[2020-06-22 16:59:37] __main__ INFO: \u001b[0mVal 55\n",
      "\u001b[32m[2020-06-22 16:59:38] __main__ INFO: \u001b[0mEpoch 55 loss 2.0049 acc@1 0.2570 acc@5 0.6718\n",
      "\u001b[32m[2020-06-22 16:59:38] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 16:59:38] __main__ INFO: \u001b[0mTrain 56 19305\n",
      "\u001b[32m[2020-06-22 16:59:48] __main__ INFO: \u001b[0mEpoch 56 Step 100/351 lr 0.100000 loss 1.8023 (1.9013) acc@1 0.3516 (0.2900) acc@5 0.6875 (0.6977)\n",
      "\u001b[32m[2020-06-22 16:59:57] __main__ INFO: \u001b[0mEpoch 56 Step 200/351 lr 0.100000 loss 1.9539 (1.9054) acc@1 0.2891 (0.2905) acc@5 0.7031 (0.6989)\n",
      "\u001b[32m[2020-06-22 17:00:06] __main__ INFO: \u001b[0mEpoch 56 Step 300/351 lr 0.100000 loss 1.8718 (1.9098) acc@1 0.2734 (0.2878) acc@5 0.6719 (0.6977)\n",
      "\u001b[32m[2020-06-22 17:00:11] __main__ INFO: \u001b[0mEpoch 56 Step 351/351 lr 0.100000 loss 1.8100 (1.9105) acc@1 0.2969 (0.2879) acc@5 0.7031 (0.6981)\n",
      "\u001b[32m[2020-06-22 17:00:11] __main__ INFO: \u001b[0mElapsed 32.75\n",
      "\u001b[32m[2020-06-22 17:00:11] __main__ INFO: \u001b[0mVal 56\n",
      "\u001b[32m[2020-06-22 17:00:12] __main__ INFO: \u001b[0mEpoch 56 loss 2.0021 acc@1 0.2462 acc@5 0.6868\n",
      "\u001b[32m[2020-06-22 17:00:12] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 17:00:12] __main__ INFO: \u001b[0mTrain 57 19656\n",
      "\u001b[32m[2020-06-22 17:00:22] __main__ INFO: \u001b[0mEpoch 57 Step 100/351 lr 0.100000 loss 1.8378 (1.9059) acc@1 0.3125 (0.2873) acc@5 0.7422 (0.6937)\n",
      "\u001b[32m[2020-06-22 17:00:31] __main__ INFO: \u001b[0mEpoch 57 Step 200/351 lr 0.100000 loss 1.9325 (1.9076) acc@1 0.2891 (0.2863) acc@5 0.7422 (0.6974)\n",
      "\u001b[32m[2020-06-22 17:00:40] __main__ INFO: \u001b[0mEpoch 57 Step 300/351 lr 0.100000 loss 2.0115 (1.9093) acc@1 0.2656 (0.2819) acc@5 0.6406 (0.6964)\n",
      "\u001b[32m[2020-06-22 17:00:45] __main__ INFO: \u001b[0mEpoch 57 Step 351/351 lr 0.100000 loss 1.9921 (1.9101) acc@1 0.2734 (0.2816) acc@5 0.6484 (0.6969)\n",
      "\u001b[32m[2020-06-22 17:00:45] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 17:00:45] __main__ INFO: \u001b[0mVal 57\n",
      "\u001b[32m[2020-06-22 17:00:46] __main__ INFO: \u001b[0mEpoch 57 loss 2.0808 acc@1 0.2456 acc@5 0.6660\n",
      "\u001b[32m[2020-06-22 17:00:46] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 17:00:46] __main__ INFO: \u001b[0mTrain 58 20007\n",
      "\u001b[32m[2020-06-22 17:00:55] __main__ INFO: \u001b[0mEpoch 58 Step 100/351 lr 0.100000 loss 1.8564 (1.9054) acc@1 0.3438 (0.2866) acc@5 0.7656 (0.7009)\n",
      "\u001b[32m[2020-06-22 17:01:05] __main__ INFO: \u001b[0mEpoch 58 Step 200/351 lr 0.100000 loss 1.8117 (1.9062) acc@1 0.3047 (0.2859) acc@5 0.7500 (0.7009)\n",
      "\u001b[32m[2020-06-22 17:01:14] __main__ INFO: \u001b[0mEpoch 58 Step 300/351 lr 0.100000 loss 1.9132 (1.9050) acc@1 0.2812 (0.2852) acc@5 0.7031 (0.6998)\n",
      "\u001b[32m[2020-06-22 17:01:19] __main__ INFO: \u001b[0mEpoch 58 Step 351/351 lr 0.100000 loss 1.7061 (1.9043) acc@1 0.3516 (0.2851) acc@5 0.7500 (0.6990)\n",
      "\u001b[32m[2020-06-22 17:01:19] __main__ INFO: \u001b[0mElapsed 32.74\n",
      "\u001b[32m[2020-06-22 17:01:19] __main__ INFO: \u001b[0mVal 58\n",
      "\u001b[32m[2020-06-22 17:01:20] __main__ INFO: \u001b[0mEpoch 58 loss 1.9640 acc@1 0.2538 acc@5 0.6836\n",
      "\u001b[32m[2020-06-22 17:01:20] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 17:01:20] __main__ INFO: \u001b[0mTrain 59 20358\n",
      "\u001b[32m[2020-06-22 17:01:29] __main__ INFO: \u001b[0mEpoch 59 Step 100/351 lr 0.100000 loss 1.9437 (1.8928) acc@1 0.2656 (0.2863) acc@5 0.6562 (0.6950)\n",
      "\u001b[32m[2020-06-22 17:01:39] __main__ INFO: \u001b[0mEpoch 59 Step 200/351 lr 0.100000 loss 1.7851 (1.8932) acc@1 0.3125 (0.2861) acc@5 0.7266 (0.6987)\n",
      "\u001b[32m[2020-06-22 17:01:48] __main__ INFO: \u001b[0mEpoch 59 Step 300/351 lr 0.100000 loss 1.8251 (1.8952) acc@1 0.3203 (0.2882) acc@5 0.7656 (0.7000)\n",
      "\u001b[32m[2020-06-22 17:01:53] __main__ INFO: \u001b[0mEpoch 59 Step 351/351 lr 0.100000 loss 1.8616 (1.8984) acc@1 0.2812 (0.2868) acc@5 0.7109 (0.6993)\n",
      "\u001b[32m[2020-06-22 17:01:53] __main__ INFO: \u001b[0mElapsed 32.77\n",
      "\u001b[32m[2020-06-22 17:01:53] __main__ INFO: \u001b[0mVal 59\n",
      "\u001b[32m[2020-06-22 17:01:54] __main__ INFO: \u001b[0mEpoch 59 loss 2.0073 acc@1 0.2508 acc@5 0.6800\n",
      "\u001b[32m[2020-06-22 17:01:54] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 17:01:54] __main__ INFO: \u001b[0mTrain 60 20709\n",
      "\u001b[32m[2020-06-22 17:02:03] __main__ INFO: \u001b[0mEpoch 60 Step 100/351 lr 0.100000 loss 1.8867 (1.8844) acc@1 0.2891 (0.2895) acc@5 0.7578 (0.7093)\n",
      "\u001b[32m[2020-06-22 17:02:12] __main__ INFO: \u001b[0mEpoch 60 Step 200/351 lr 0.100000 loss 1.8750 (1.8927) acc@1 0.2734 (0.2888) acc@5 0.6797 (0.7061)\n",
      "\u001b[32m[2020-06-22 17:02:22] __main__ INFO: \u001b[0mEpoch 60 Step 300/351 lr 0.100000 loss 1.8412 (1.8948) acc@1 0.3828 (0.2891) acc@5 0.7500 (0.7045)\n",
      "\u001b[32m[2020-06-22 17:02:26] __main__ INFO: \u001b[0mEpoch 60 Step 351/351 lr 0.100000 loss 2.1341 (1.8959) acc@1 0.2266 (0.2879) acc@5 0.6172 (0.7029)\n",
      "\u001b[32m[2020-06-22 17:02:26] __main__ INFO: \u001b[0mElapsed 32.76\n",
      "\u001b[32m[2020-06-22 17:02:26] __main__ INFO: \u001b[0mVal 60\n",
      "\u001b[32m[2020-06-22 17:02:27] __main__ INFO: \u001b[0mEpoch 60 loss 2.0123 acc@1 0.2428 acc@5 0.6724\n",
      "\u001b[32m[2020-06-22 17:02:27] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 17:02:27] __main__ INFO: \u001b[0mTrain 61 21060\n",
      "\u001b[32m[2020-06-22 17:02:37] __main__ INFO: \u001b[0mEpoch 61 Step 100/351 lr 0.100000 loss 1.8183 (1.8729) acc@1 0.3359 (0.3016) acc@5 0.7266 (0.7104)\n",
      "\u001b[32m[2020-06-22 17:02:46] __main__ INFO: \u001b[0mEpoch 61 Step 200/351 lr 0.100000 loss 1.9264 (1.8829) acc@1 0.2812 (0.2950) acc@5 0.6172 (0.7068)\n",
      "\u001b[32m[2020-06-22 17:02:55] __main__ INFO: \u001b[0mEpoch 61 Step 300/351 lr 0.100000 loss 1.8739 (1.8852) acc@1 0.2969 (0.2940) acc@5 0.6875 (0.7027)\n",
      "\u001b[32m[2020-06-22 17:03:00] __main__ INFO: \u001b[0mEpoch 61 Step 351/351 lr 0.100000 loss 1.9491 (1.8876) acc@1 0.2812 (0.2929) acc@5 0.6641 (0.7029)\n",
      "\u001b[32m[2020-06-22 17:03:00] __main__ INFO: \u001b[0mElapsed 32.73\n",
      "\u001b[32m[2020-06-22 17:03:00] __main__ INFO: \u001b[0mVal 61\n",
      "\u001b[32m[2020-06-22 17:03:01] __main__ INFO: \u001b[0mEpoch 61 loss 2.1114 acc@1 0.2570 acc@5 0.6798\n",
      "\u001b[32m[2020-06-22 17:03:01] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 17:03:01] __main__ INFO: \u001b[0mTrain 62 21411\n",
      "\u001b[32m[2020-06-22 17:03:11] __main__ INFO: \u001b[0mEpoch 62 Step 100/351 lr 0.100000 loss 1.8750 (1.8697) acc@1 0.2656 (0.2973) acc@5 0.6641 (0.7084)\n",
      "\u001b[32m[2020-06-22 17:03:20] __main__ INFO: \u001b[0mEpoch 62 Step 200/351 lr 0.100000 loss 1.7415 (1.8719) acc@1 0.3203 (0.2954) acc@5 0.6797 (0.7037)\n",
      "\u001b[32m[2020-06-22 17:03:29] __main__ INFO: \u001b[0mEpoch 62 Step 300/351 lr 0.100000 loss 1.9290 (1.8799) acc@1 0.2656 (0.2921) acc@5 0.7188 (0.7023)\n",
      "\u001b[32m[2020-06-22 17:03:34] __main__ INFO: \u001b[0mEpoch 62 Step 351/351 lr 0.100000 loss 1.7382 (1.8824) acc@1 0.3828 (0.2916) acc@5 0.7734 (0.7025)\n",
      "\u001b[32m[2020-06-22 17:03:34] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 17:03:34] __main__ INFO: \u001b[0mVal 62\n",
      "\u001b[32m[2020-06-22 17:03:35] __main__ INFO: \u001b[0mEpoch 62 loss 1.9822 acc@1 0.2674 acc@5 0.6800\n",
      "\u001b[32m[2020-06-22 17:03:35] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 17:03:35] __main__ INFO: \u001b[0mTrain 63 21762\n",
      "\u001b[32m[2020-06-22 17:03:44] __main__ INFO: \u001b[0mEpoch 63 Step 100/351 lr 0.100000 loss 1.9300 (1.8665) acc@1 0.2734 (0.3034) acc@5 0.7656 (0.7087)\n",
      "\u001b[32m[2020-06-22 17:03:54] __main__ INFO: \u001b[0mEpoch 63 Step 200/351 lr 0.100000 loss 2.0057 (1.8815) acc@1 0.2422 (0.2979) acc@5 0.6641 (0.7024)\n",
      "\u001b[32m[2020-06-22 17:04:03] __main__ INFO: \u001b[0mEpoch 63 Step 300/351 lr 0.100000 loss 1.8710 (1.8810) acc@1 0.2969 (0.2958) acc@5 0.7031 (0.7020)\n",
      "\u001b[32m[2020-06-22 17:04:08] __main__ INFO: \u001b[0mEpoch 63 Step 351/351 lr 0.100000 loss 1.9732 (1.8803) acc@1 0.3047 (0.2956) acc@5 0.6953 (0.7028)\n",
      "\u001b[32m[2020-06-22 17:04:08] __main__ INFO: \u001b[0mElapsed 32.77\n",
      "\u001b[32m[2020-06-22 17:04:08] __main__ INFO: \u001b[0mVal 63\n",
      "\u001b[32m[2020-06-22 17:04:09] __main__ INFO: \u001b[0mEpoch 63 loss 2.0018 acc@1 0.2652 acc@5 0.6846\n",
      "\u001b[32m[2020-06-22 17:04:09] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 17:04:09] __main__ INFO: \u001b[0mTrain 64 22113\n",
      "\u001b[32m[2020-06-22 17:04:18] __main__ INFO: \u001b[0mEpoch 64 Step 100/351 lr 0.100000 loss 1.7794 (1.8639) acc@1 0.3359 (0.3005) acc@5 0.7344 (0.7024)\n",
      "\u001b[32m[2020-06-22 17:04:28] __main__ INFO: \u001b[0mEpoch 64 Step 200/351 lr 0.100000 loss 1.7104 (1.8652) acc@1 0.3672 (0.2996) acc@5 0.7344 (0.7048)\n",
      "\u001b[32m[2020-06-22 17:04:37] __main__ INFO: \u001b[0mEpoch 64 Step 300/351 lr 0.100000 loss 1.8058 (1.8730) acc@1 0.3047 (0.2979) acc@5 0.7344 (0.7019)\n",
      "\u001b[32m[2020-06-22 17:04:42] __main__ INFO: \u001b[0mEpoch 64 Step 351/351 lr 0.100000 loss 1.9909 (1.8752) acc@1 0.2656 (0.2972) acc@5 0.6641 (0.7017)\n",
      "\u001b[32m[2020-06-22 17:04:42] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 17:04:42] __main__ INFO: \u001b[0mVal 64\n",
      "\u001b[32m[2020-06-22 17:04:43] __main__ INFO: \u001b[0mEpoch 64 loss 1.9703 acc@1 0.2672 acc@5 0.6872\n",
      "\u001b[32m[2020-06-22 17:04:43] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 17:04:43] __main__ INFO: \u001b[0mTrain 65 22464\n",
      "\u001b[32m[2020-06-22 17:04:52] __main__ INFO: \u001b[0mEpoch 65 Step 100/351 lr 0.100000 loss 1.6641 (1.8557) acc@1 0.3516 (0.3043) acc@5 0.8047 (0.7104)\n",
      "\u001b[32m[2020-06-22 17:05:01] __main__ INFO: \u001b[0mEpoch 65 Step 200/351 lr 0.100000 loss 1.9035 (1.8653) acc@1 0.2656 (0.3013) acc@5 0.6484 (0.7081)\n",
      "\u001b[32m[2020-06-22 17:05:11] __main__ INFO: \u001b[0mEpoch 65 Step 300/351 lr 0.100000 loss 1.7968 (1.8705) acc@1 0.3281 (0.2986) acc@5 0.7266 (0.7051)\n",
      "\u001b[32m[2020-06-22 17:05:15] __main__ INFO: \u001b[0mEpoch 65 Step 351/351 lr 0.100000 loss 1.8055 (1.8716) acc@1 0.2891 (0.2985) acc@5 0.7344 (0.7039)\n",
      "\u001b[32m[2020-06-22 17:05:15] __main__ INFO: \u001b[0mElapsed 32.72\n",
      "\u001b[32m[2020-06-22 17:05:15] __main__ INFO: \u001b[0mVal 65\n",
      "\u001b[32m[2020-06-22 17:05:17] __main__ INFO: \u001b[0mEpoch 65 loss 2.0723 acc@1 0.2446 acc@5 0.6622\n",
      "\u001b[32m[2020-06-22 17:05:17] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 17:05:17] __main__ INFO: \u001b[0mTrain 66 22815\n",
      "\u001b[32m[2020-06-22 17:05:26] __main__ INFO: \u001b[0mEpoch 66 Step 100/351 lr 0.100000 loss 2.0008 (1.8725) acc@1 0.2500 (0.2987) acc@5 0.6016 (0.7070)\n",
      "\u001b[32m[2020-06-22 17:05:35] __main__ INFO: \u001b[0mEpoch 66 Step 200/351 lr 0.100000 loss 1.8809 (1.8665) acc@1 0.2422 (0.2978) acc@5 0.6641 (0.7063)\n",
      "\u001b[32m[2020-06-22 17:05:44] __main__ INFO: \u001b[0mEpoch 66 Step 300/351 lr 0.100000 loss 1.8472 (1.8687) acc@1 0.2734 (0.2963) acc@5 0.6953 (0.7053)\n",
      "\u001b[32m[2020-06-22 17:05:49] __main__ INFO: \u001b[0mEpoch 66 Step 351/351 lr 0.100000 loss 1.8402 (1.8684) acc@1 0.3047 (0.2972) acc@5 0.7656 (0.7055)\n",
      "\u001b[32m[2020-06-22 17:05:49] __main__ INFO: \u001b[0mElapsed 32.70\n",
      "\u001b[32m[2020-06-22 17:05:49] __main__ INFO: \u001b[0mVal 66\n",
      "\u001b[32m[2020-06-22 17:05:50] __main__ INFO: \u001b[0mEpoch 66 loss 1.9823 acc@1 0.2706 acc@5 0.6858\n",
      "\u001b[32m[2020-06-22 17:05:50] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 17:05:50] __main__ INFO: \u001b[0mTrain 67 23166\n",
      "\u001b[32m[2020-06-22 17:06:00] __main__ INFO: \u001b[0mEpoch 67 Step 100/351 lr 0.100000 loss 1.8408 (1.8613) acc@1 0.2812 (0.3042) acc@5 0.7109 (0.7036)\n",
      "\u001b[32m[2020-06-22 17:06:09] __main__ INFO: \u001b[0mEpoch 67 Step 200/351 lr 0.100000 loss 1.9089 (1.8706) acc@1 0.2891 (0.2986) acc@5 0.7109 (0.7034)\n",
      "\u001b[32m[2020-06-22 17:06:18] __main__ INFO: \u001b[0mEpoch 67 Step 300/351 lr 0.100000 loss 1.9330 (1.8705) acc@1 0.3125 (0.2999) acc@5 0.7266 (0.7042)\n",
      "\u001b[32m[2020-06-22 17:06:23] __main__ INFO: \u001b[0mEpoch 67 Step 351/351 lr 0.100000 loss 1.7673 (1.8705) acc@1 0.3359 (0.2994) acc@5 0.7734 (0.7038)\n",
      "\u001b[32m[2020-06-22 17:06:23] __main__ INFO: \u001b[0mElapsed 32.76\n",
      "\u001b[32m[2020-06-22 17:06:23] __main__ INFO: \u001b[0mVal 67\n",
      "\u001b[32m[2020-06-22 17:06:24] __main__ INFO: \u001b[0mEpoch 67 loss 1.9671 acc@1 0.2604 acc@5 0.6898\n",
      "\u001b[32m[2020-06-22 17:06:24] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 17:06:24] __main__ INFO: \u001b[0mTrain 68 23517\n",
      "\u001b[32m[2020-06-22 17:06:34] __main__ INFO: \u001b[0mEpoch 68 Step 100/351 lr 0.100000 loss 1.8744 (1.8404) acc@1 0.2500 (0.3121) acc@5 0.6953 (0.7095)\n",
      "\u001b[32m[2020-06-22 17:06:43] __main__ INFO: \u001b[0mEpoch 68 Step 200/351 lr 0.100000 loss 1.8621 (1.8584) acc@1 0.2812 (0.3054) acc@5 0.6641 (0.7062)\n",
      "\u001b[32m[2020-06-22 17:06:52] __main__ INFO: \u001b[0mEpoch 68 Step 300/351 lr 0.100000 loss 1.9081 (1.8610) acc@1 0.2734 (0.3038) acc@5 0.7031 (0.7048)\n",
      "\u001b[32m[2020-06-22 17:06:57] __main__ INFO: \u001b[0mEpoch 68 Step 351/351 lr 0.100000 loss 1.8454 (1.8619) acc@1 0.2891 (0.3035) acc@5 0.7422 (0.7071)\n",
      "\u001b[32m[2020-06-22 17:06:57] __main__ INFO: \u001b[0mElapsed 32.77\n",
      "\u001b[32m[2020-06-22 17:06:57] __main__ INFO: \u001b[0mVal 68\n",
      "\u001b[32m[2020-06-22 17:06:58] __main__ INFO: \u001b[0mEpoch 68 loss 1.9922 acc@1 0.2556 acc@5 0.6820\n",
      "\u001b[32m[2020-06-22 17:06:58] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 17:06:58] __main__ INFO: \u001b[0mTrain 69 23868\n",
      "\u001b[32m[2020-06-22 17:07:07] __main__ INFO: \u001b[0mEpoch 69 Step 100/351 lr 0.100000 loss 1.7932 (1.8571) acc@1 0.3125 (0.3017) acc@5 0.6328 (0.7048)\n",
      "\u001b[32m[2020-06-22 17:07:17] __main__ INFO: \u001b[0mEpoch 69 Step 200/351 lr 0.100000 loss 1.8314 (1.8570) acc@1 0.3125 (0.3038) acc@5 0.7344 (0.7107)\n",
      "\u001b[32m[2020-06-22 17:07:26] __main__ INFO: \u001b[0mEpoch 69 Step 300/351 lr 0.100000 loss 1.8598 (1.8581) acc@1 0.3047 (0.3026) acc@5 0.7266 (0.7090)\n",
      "\u001b[32m[2020-06-22 17:07:31] __main__ INFO: \u001b[0mEpoch 69 Step 351/351 lr 0.100000 loss 1.9702 (1.8579) acc@1 0.3281 (0.3029) acc@5 0.7031 (0.7088)\n",
      "\u001b[32m[2020-06-22 17:07:31] __main__ INFO: \u001b[0mElapsed 32.73\n",
      "\u001b[32m[2020-06-22 17:07:31] __main__ INFO: \u001b[0mVal 69\n",
      "\u001b[32m[2020-06-22 17:07:32] __main__ INFO: \u001b[0mEpoch 69 loss 1.9623 acc@1 0.2654 acc@5 0.6874\n",
      "\u001b[32m[2020-06-22 17:07:32] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 17:07:32] __main__ INFO: \u001b[0mTrain 70 24219\n",
      "\u001b[32m[2020-06-22 17:07:41] __main__ INFO: \u001b[0mEpoch 70 Step 100/351 lr 0.100000 loss 1.9102 (1.8476) acc@1 0.3047 (0.3041) acc@5 0.6719 (0.7055)\n",
      "\u001b[32m[2020-06-22 17:07:50] __main__ INFO: \u001b[0mEpoch 70 Step 200/351 lr 0.100000 loss 1.8821 (1.8513) acc@1 0.2578 (0.3056) acc@5 0.6328 (0.7085)\n",
      "\u001b[32m[2020-06-22 17:08:00] __main__ INFO: \u001b[0mEpoch 70 Step 300/351 lr 0.100000 loss 1.9022 (1.8545) acc@1 0.2734 (0.3041) acc@5 0.6562 (0.7060)\n",
      "\u001b[32m[2020-06-22 17:08:04] __main__ INFO: \u001b[0mEpoch 70 Step 351/351 lr 0.100000 loss 1.9706 (1.8542) acc@1 0.2344 (0.3043) acc@5 0.6719 (0.7063)\n",
      "\u001b[32m[2020-06-22 17:08:04] __main__ INFO: \u001b[0mElapsed 32.78\n",
      "\u001b[32m[2020-06-22 17:08:04] __main__ INFO: \u001b[0mVal 70\n",
      "\u001b[32m[2020-06-22 17:08:06] __main__ INFO: \u001b[0mEpoch 70 loss 1.9522 acc@1 0.2732 acc@5 0.6990\n",
      "\u001b[32m[2020-06-22 17:08:06] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 17:08:06] __main__ INFO: \u001b[0mTrain 71 24570\n",
      "\u001b[32m[2020-06-22 17:08:15] __main__ INFO: \u001b[0mEpoch 71 Step 100/351 lr 0.100000 loss 1.8534 (1.8477) acc@1 0.2891 (0.3055) acc@5 0.7422 (0.7067)\n",
      "\u001b[32m[2020-06-22 17:08:24] __main__ INFO: \u001b[0mEpoch 71 Step 200/351 lr 0.100000 loss 1.9483 (1.8468) acc@1 0.2500 (0.3055) acc@5 0.6797 (0.7101)\n",
      "\u001b[32m[2020-06-22 17:08:34] __main__ INFO: \u001b[0mEpoch 71 Step 300/351 lr 0.100000 loss 1.8447 (1.8504) acc@1 0.3594 (0.3042) acc@5 0.6875 (0.7080)\n",
      "\u001b[32m[2020-06-22 17:08:38] __main__ INFO: \u001b[0mEpoch 71 Step 351/351 lr 0.100000 loss 1.7346 (1.8492) acc@1 0.3203 (0.3046) acc@5 0.7500 (0.7087)\n",
      "\u001b[32m[2020-06-22 17:08:38] __main__ INFO: \u001b[0mElapsed 32.72\n",
      "\u001b[32m[2020-06-22 17:08:38] __main__ INFO: \u001b[0mVal 71\n",
      "\u001b[32m[2020-06-22 17:08:39] __main__ INFO: \u001b[0mEpoch 71 loss 2.0235 acc@1 0.2522 acc@5 0.6768\n",
      "\u001b[32m[2020-06-22 17:08:39] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 17:08:39] __main__ INFO: \u001b[0mTrain 72 24921\n",
      "\u001b[32m[2020-06-22 17:08:49] __main__ INFO: \u001b[0mEpoch 72 Step 100/351 lr 0.100000 loss 1.8882 (1.8279) acc@1 0.2109 (0.3123) acc@5 0.6875 (0.7188)\n",
      "\u001b[32m[2020-06-22 17:08:58] __main__ INFO: \u001b[0mEpoch 72 Step 200/351 lr 0.100000 loss 1.7539 (1.8397) acc@1 0.3828 (0.3080) acc@5 0.7031 (0.7132)\n",
      "\u001b[32m[2020-06-22 17:09:07] __main__ INFO: \u001b[0mEpoch 72 Step 300/351 lr 0.100000 loss 1.9021 (1.8448) acc@1 0.2812 (0.3079) acc@5 0.7266 (0.7122)\n",
      "\u001b[32m[2020-06-22 17:09:12] __main__ INFO: \u001b[0mEpoch 72 Step 351/351 lr 0.100000 loss 2.0121 (1.8465) acc@1 0.2812 (0.3078) acc@5 0.6562 (0.7133)\n",
      "\u001b[32m[2020-06-22 17:09:12] __main__ INFO: \u001b[0mElapsed 32.76\n",
      "\u001b[32m[2020-06-22 17:09:12] __main__ INFO: \u001b[0mVal 72\n",
      "\u001b[32m[2020-06-22 17:09:13] __main__ INFO: \u001b[0mEpoch 72 loss 1.9366 acc@1 0.2774 acc@5 0.6914\n",
      "\u001b[32m[2020-06-22 17:09:13] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 17:09:13] __main__ INFO: \u001b[0mTrain 73 25272\n",
      "\u001b[32m[2020-06-22 17:09:23] __main__ INFO: \u001b[0mEpoch 73 Step 100/351 lr 0.100000 loss 1.7841 (1.8241) acc@1 0.3281 (0.3182) acc@5 0.6641 (0.7148)\n",
      "\u001b[32m[2020-06-22 17:09:32] __main__ INFO: \u001b[0mEpoch 73 Step 200/351 lr 0.100000 loss 1.8860 (1.8399) acc@1 0.2734 (0.3109) acc@5 0.6875 (0.7122)\n",
      "\u001b[32m[2020-06-22 17:09:41] __main__ INFO: \u001b[0mEpoch 73 Step 300/351 lr 0.100000 loss 1.7282 (1.8449) acc@1 0.3047 (0.3098) acc@5 0.7578 (0.7110)\n",
      "\u001b[32m[2020-06-22 17:09:46] __main__ INFO: \u001b[0mEpoch 73 Step 351/351 lr 0.100000 loss 1.8239 (1.8431) acc@1 0.3281 (0.3102) acc@5 0.6797 (0.7114)\n",
      "\u001b[32m[2020-06-22 17:09:46] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 17:09:46] __main__ INFO: \u001b[0mVal 73\n",
      "\u001b[32m[2020-06-22 17:09:47] __main__ INFO: \u001b[0mEpoch 73 loss 1.9694 acc@1 0.2742 acc@5 0.6844\n",
      "\u001b[32m[2020-06-22 17:09:47] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 17:09:47] __main__ INFO: \u001b[0mTrain 74 25623\n",
      "\u001b[32m[2020-06-22 17:09:56] __main__ INFO: \u001b[0mEpoch 74 Step 100/351 lr 0.100000 loss 1.8381 (1.8208) acc@1 0.3203 (0.3133) acc@5 0.7031 (0.7105)\n",
      "\u001b[32m[2020-06-22 17:10:06] __main__ INFO: \u001b[0mEpoch 74 Step 200/351 lr 0.100000 loss 1.9840 (1.8231) acc@1 0.2656 (0.3141) acc@5 0.7188 (0.7131)\n",
      "\u001b[32m[2020-06-22 17:10:15] __main__ INFO: \u001b[0mEpoch 74 Step 300/351 lr 0.100000 loss 1.8432 (1.8351) acc@1 0.3203 (0.3118) acc@5 0.7266 (0.7093)\n",
      "\u001b[32m[2020-06-22 17:10:20] __main__ INFO: \u001b[0mEpoch 74 Step 351/351 lr 0.100000 loss 1.7777 (1.8383) acc@1 0.3594 (0.3109) acc@5 0.7188 (0.7080)\n",
      "\u001b[32m[2020-06-22 17:10:20] __main__ INFO: \u001b[0mElapsed 32.76\n",
      "\u001b[32m[2020-06-22 17:10:20] __main__ INFO: \u001b[0mVal 74\n",
      "\u001b[32m[2020-06-22 17:10:21] __main__ INFO: \u001b[0mEpoch 74 loss 1.9440 acc@1 0.2750 acc@5 0.6760\n",
      "\u001b[32m[2020-06-22 17:10:21] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 17:10:21] __main__ INFO: \u001b[0mTrain 75 25974\n",
      "\u001b[32m[2020-06-22 17:10:30] __main__ INFO: \u001b[0mEpoch 75 Step 100/351 lr 0.100000 loss 1.8812 (1.8324) acc@1 0.2969 (0.3128) acc@5 0.7266 (0.7168)\n",
      "\u001b[32m[2020-06-22 17:10:39] __main__ INFO: \u001b[0mEpoch 75 Step 200/351 lr 0.100000 loss 1.8992 (1.8349) acc@1 0.2812 (0.3129) acc@5 0.6875 (0.7123)\n",
      "\u001b[32m[2020-06-22 17:10:49] __main__ INFO: \u001b[0mEpoch 75 Step 300/351 lr 0.100000 loss 1.8328 (1.8382) acc@1 0.3516 (0.3127) acc@5 0.7188 (0.7127)\n",
      "\u001b[32m[2020-06-22 17:10:53] __main__ INFO: \u001b[0mEpoch 75 Step 351/351 lr 0.100000 loss 1.8233 (1.8403) acc@1 0.3203 (0.3121) acc@5 0.7500 (0.7109)\n",
      "\u001b[32m[2020-06-22 17:10:54] __main__ INFO: \u001b[0mElapsed 32.71\n",
      "\u001b[32m[2020-06-22 17:10:54] __main__ INFO: \u001b[0mVal 75\n",
      "\u001b[32m[2020-06-22 17:10:55] __main__ INFO: \u001b[0mEpoch 75 loss 2.0392 acc@1 0.2558 acc@5 0.6894\n",
      "\u001b[32m[2020-06-22 17:10:55] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 17:10:55] __main__ INFO: \u001b[0mTrain 76 26325\n",
      "\u001b[32m[2020-06-22 17:11:04] __main__ INFO: \u001b[0mEpoch 76 Step 100/351 lr 0.100000 loss 2.0445 (1.8320) acc@1 0.2109 (0.3132) acc@5 0.6328 (0.7084)\n",
      "\u001b[32m[2020-06-22 17:11:13] __main__ INFO: \u001b[0mEpoch 76 Step 200/351 lr 0.100000 loss 1.9166 (1.8394) acc@1 0.2812 (0.3089) acc@5 0.7344 (0.7073)\n",
      "\u001b[32m[2020-06-22 17:11:23] __main__ INFO: \u001b[0mEpoch 76 Step 300/351 lr 0.100000 loss 1.7948 (1.8321) acc@1 0.3203 (0.3117) acc@5 0.6797 (0.7109)\n",
      "\u001b[32m[2020-06-22 17:11:27] __main__ INFO: \u001b[0mEpoch 76 Step 351/351 lr 0.100000 loss 1.7147 (1.8325) acc@1 0.3672 (0.3109) acc@5 0.7188 (0.7096)\n",
      "\u001b[32m[2020-06-22 17:11:27] __main__ INFO: \u001b[0mElapsed 32.70\n",
      "\u001b[32m[2020-06-22 17:11:27] __main__ INFO: \u001b[0mVal 76\n",
      "\u001b[32m[2020-06-22 17:11:28] __main__ INFO: \u001b[0mEpoch 76 loss 2.0553 acc@1 0.2630 acc@5 0.6782\n",
      "\u001b[32m[2020-06-22 17:11:28] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 17:11:28] __main__ INFO: \u001b[0mTrain 77 26676\n",
      "\u001b[32m[2020-06-22 17:11:38] __main__ INFO: \u001b[0mEpoch 77 Step 100/351 lr 0.100000 loss 1.7973 (1.8248) acc@1 0.3281 (0.3119) acc@5 0.7578 (0.7112)\n",
      "\u001b[32m[2020-06-22 17:11:47] __main__ INFO: \u001b[0mEpoch 77 Step 200/351 lr 0.100000 loss 1.8701 (1.8229) acc@1 0.2812 (0.3143) acc@5 0.6406 (0.7110)\n",
      "\u001b[32m[2020-06-22 17:11:56] __main__ INFO: \u001b[0mEpoch 77 Step 300/351 lr 0.100000 loss 1.8376 (1.8286) acc@1 0.3125 (0.3130) acc@5 0.7188 (0.7104)\n",
      "\u001b[32m[2020-06-22 17:12:01] __main__ INFO: \u001b[0mEpoch 77 Step 351/351 lr 0.100000 loss 1.7341 (1.8281) acc@1 0.3438 (0.3122) acc@5 0.7969 (0.7110)\n",
      "\u001b[32m[2020-06-22 17:12:01] __main__ INFO: \u001b[0mElapsed 32.75\n",
      "\u001b[32m[2020-06-22 17:12:01] __main__ INFO: \u001b[0mVal 77\n",
      "\u001b[32m[2020-06-22 17:12:02] __main__ INFO: \u001b[0mEpoch 77 loss 1.9497 acc@1 0.2828 acc@5 0.6998\n",
      "\u001b[32m[2020-06-22 17:12:02] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 17:12:02] __main__ INFO: \u001b[0mTrain 78 27027\n",
      "\u001b[32m[2020-06-22 17:12:11] __main__ INFO: \u001b[0mEpoch 78 Step 100/351 lr 0.100000 loss 1.8999 (1.8260) acc@1 0.2578 (0.3134) acc@5 0.7031 (0.7140)\n",
      "\u001b[32m[2020-06-22 17:12:21] __main__ INFO: \u001b[0mEpoch 78 Step 200/351 lr 0.100000 loss 1.8500 (1.8242) acc@1 0.3203 (0.3153) acc@5 0.6875 (0.7164)\n",
      "\u001b[32m[2020-06-22 17:12:30] __main__ INFO: \u001b[0mEpoch 78 Step 300/351 lr 0.100000 loss 1.7204 (1.8291) acc@1 0.3984 (0.3146) acc@5 0.6875 (0.7132)\n",
      "\u001b[32m[2020-06-22 17:12:35] __main__ INFO: \u001b[0mEpoch 78 Step 351/351 lr 0.100000 loss 1.8341 (1.8299) acc@1 0.2734 (0.3140) acc@5 0.7344 (0.7143)\n",
      "\u001b[32m[2020-06-22 17:12:35] __main__ INFO: \u001b[0mElapsed 32.77\n",
      "\u001b[32m[2020-06-22 17:12:35] __main__ INFO: \u001b[0mVal 78\n",
      "\u001b[32m[2020-06-22 17:12:36] __main__ INFO: \u001b[0mEpoch 78 loss 1.9736 acc@1 0.2768 acc@5 0.6924\n",
      "\u001b[32m[2020-06-22 17:12:36] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 17:12:36] __main__ INFO: \u001b[0mTrain 79 27378\n",
      "\u001b[32m[2020-06-22 17:12:45] __main__ INFO: \u001b[0mEpoch 79 Step 100/351 lr 0.100000 loss 1.7191 (1.8175) acc@1 0.3516 (0.3156) acc@5 0.6719 (0.7160)\n",
      "\u001b[32m[2020-06-22 17:12:55] __main__ INFO: \u001b[0mEpoch 79 Step 200/351 lr 0.100000 loss 1.8244 (1.8220) acc@1 0.3281 (0.3140) acc@5 0.7500 (0.7137)\n",
      "\u001b[32m[2020-06-22 17:13:04] __main__ INFO: \u001b[0mEpoch 79 Step 300/351 lr 0.100000 loss 1.8142 (1.8245) acc@1 0.2812 (0.3143) acc@5 0.6406 (0.7129)\n",
      "\u001b[32m[2020-06-22 17:13:09] __main__ INFO: \u001b[0mEpoch 79 Step 351/351 lr 0.100000 loss 1.7642 (1.8240) acc@1 0.2734 (0.3137) acc@5 0.7109 (0.7117)\n",
      "\u001b[32m[2020-06-22 17:13:09] __main__ INFO: \u001b[0mElapsed 32.75\n",
      "\u001b[32m[2020-06-22 17:13:09] __main__ INFO: \u001b[0mVal 79\n",
      "\u001b[32m[2020-06-22 17:13:10] __main__ INFO: \u001b[0mEpoch 79 loss 1.9731 acc@1 0.2736 acc@5 0.6882\n",
      "\u001b[32m[2020-06-22 17:13:10] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 17:13:10] __main__ INFO: \u001b[0mTrain 80 27729\n",
      "\u001b[32m[2020-06-22 17:13:19] __main__ INFO: \u001b[0mEpoch 80 Step 100/351 lr 0.100000 loss 1.8155 (1.8126) acc@1 0.3281 (0.3192) acc@5 0.6875 (0.7149)\n",
      "\u001b[32m[2020-06-22 17:13:28] __main__ INFO: \u001b[0mEpoch 80 Step 200/351 lr 0.100000 loss 1.8919 (1.8157) acc@1 0.3047 (0.3164) acc@5 0.6797 (0.7126)\n",
      "\u001b[32m[2020-06-22 17:13:38] __main__ INFO: \u001b[0mEpoch 80 Step 300/351 lr 0.100000 loss 1.7629 (1.8147) acc@1 0.3125 (0.3183) acc@5 0.6797 (0.7118)\n",
      "\u001b[32m[2020-06-22 17:13:42] __main__ INFO: \u001b[0mEpoch 80 Step 351/351 lr 0.100000 loss 1.9009 (1.8194) acc@1 0.2578 (0.3169) acc@5 0.6797 (0.7108)\n",
      "\u001b[32m[2020-06-22 17:13:43] __main__ INFO: \u001b[0mElapsed 32.77\n",
      "\u001b[32m[2020-06-22 17:13:43] __main__ INFO: \u001b[0mVal 80\n",
      "\u001b[32m[2020-06-22 17:13:44] __main__ INFO: \u001b[0mEpoch 80 loss 1.9592 acc@1 0.2848 acc@5 0.6960\n",
      "\u001b[32m[2020-06-22 17:13:44] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 17:13:44] __main__ INFO: \u001b[0mTrain 81 28080\n",
      "\u001b[32m[2020-06-22 17:13:53] __main__ INFO: \u001b[0mEpoch 81 Step 100/351 lr 0.010000 loss 1.8622 (1.7511) acc@1 0.3047 (0.3412) acc@5 0.6484 (0.7163)\n",
      "\u001b[32m[2020-06-22 17:14:02] __main__ INFO: \u001b[0mEpoch 81 Step 200/351 lr 0.010000 loss 1.7319 (1.7403) acc@1 0.3359 (0.3466) acc@5 0.7734 (0.7209)\n",
      "\u001b[32m[2020-06-22 17:14:12] __main__ INFO: \u001b[0mEpoch 81 Step 300/351 lr 0.010000 loss 1.6777 (1.7334) acc@1 0.3359 (0.3489) acc@5 0.7344 (0.7237)\n",
      "\u001b[32m[2020-06-22 17:14:16] __main__ INFO: \u001b[0mEpoch 81 Step 351/351 lr 0.010000 loss 1.7269 (1.7289) acc@1 0.3594 (0.3506) acc@5 0.7500 (0.7236)\n",
      "\u001b[32m[2020-06-22 17:14:16] __main__ INFO: \u001b[0mElapsed 32.78\n",
      "\u001b[32m[2020-06-22 17:14:16] __main__ INFO: \u001b[0mVal 81\n",
      "\u001b[32m[2020-06-22 17:14:17] __main__ INFO: \u001b[0mEpoch 81 loss 1.8701 acc@1 0.2972 acc@5 0.7066\n",
      "\u001b[32m[2020-06-22 17:14:17] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 17:14:17] __main__ INFO: \u001b[0mTrain 82 28431\n",
      "\u001b[32m[2020-06-22 17:14:27] __main__ INFO: \u001b[0mEpoch 82 Step 100/351 lr 0.010000 loss 1.8483 (1.6979) acc@1 0.3594 (0.3632) acc@5 0.6641 (0.7265)\n",
      "\u001b[32m[2020-06-22 17:14:36] __main__ INFO: \u001b[0mEpoch 82 Step 200/351 lr 0.010000 loss 1.7092 (1.6991) acc@1 0.3672 (0.3611) acc@5 0.7500 (0.7289)\n",
      "\u001b[32m[2020-06-22 17:14:45] __main__ INFO: \u001b[0mEpoch 82 Step 300/351 lr 0.010000 loss 1.8471 (1.6987) acc@1 0.2891 (0.3618) acc@5 0.6953 (0.7293)\n",
      "\u001b[32m[2020-06-22 17:14:50] __main__ INFO: \u001b[0mEpoch 82 Step 351/351 lr 0.010000 loss 1.6619 (1.6997) acc@1 0.3516 (0.3619) acc@5 0.7422 (0.7291)\n",
      "\u001b[32m[2020-06-22 17:14:50] __main__ INFO: \u001b[0mElapsed 32.76\n",
      "\u001b[32m[2020-06-22 17:14:50] __main__ INFO: \u001b[0mVal 82\n",
      "\u001b[32m[2020-06-22 17:14:51] __main__ INFO: \u001b[0mEpoch 82 loss 1.8701 acc@1 0.2996 acc@5 0.6930\n",
      "\u001b[32m[2020-06-22 17:14:51] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 17:14:51] __main__ INFO: \u001b[0mTrain 83 28782\n",
      "\u001b[32m[2020-06-22 17:15:01] __main__ INFO: \u001b[0mEpoch 83 Step 100/351 lr 0.010000 loss 1.6979 (1.6810) acc@1 0.3516 (0.3651) acc@5 0.6797 (0.7326)\n",
      "\u001b[32m[2020-06-22 17:15:10] __main__ INFO: \u001b[0mEpoch 83 Step 200/351 lr 0.010000 loss 1.6476 (1.6856) acc@1 0.3594 (0.3642) acc@5 0.7109 (0.7298)\n",
      "\u001b[32m[2020-06-22 17:15:19] __main__ INFO: \u001b[0mEpoch 83 Step 300/351 lr 0.010000 loss 1.6332 (1.6802) acc@1 0.3984 (0.3651) acc@5 0.7656 (0.7329)\n",
      "\u001b[32m[2020-06-22 17:15:24] __main__ INFO: \u001b[0mEpoch 83 Step 351/351 lr 0.010000 loss 1.7028 (1.6794) acc@1 0.3359 (0.3651) acc@5 0.6875 (0.7323)\n",
      "\u001b[32m[2020-06-22 17:15:24] __main__ INFO: \u001b[0mElapsed 32.73\n",
      "\u001b[32m[2020-06-22 17:15:24] __main__ INFO: \u001b[0mVal 83\n",
      "\u001b[32m[2020-06-22 17:15:25] __main__ INFO: \u001b[0mEpoch 83 loss 1.8862 acc@1 0.2976 acc@5 0.6948\n",
      "\u001b[32m[2020-06-22 17:15:25] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 17:15:25] __main__ INFO: \u001b[0mTrain 84 29133\n",
      "\u001b[32m[2020-06-22 17:15:34] __main__ INFO: \u001b[0mEpoch 84 Step 100/351 lr 0.010000 loss 1.8676 (1.6609) acc@1 0.2734 (0.3756) acc@5 0.7500 (0.7398)\n",
      "\u001b[32m[2020-06-22 17:15:44] __main__ INFO: \u001b[0mEpoch 84 Step 200/351 lr 0.010000 loss 1.6896 (1.6621) acc@1 0.3125 (0.3721) acc@5 0.7109 (0.7368)\n",
      "\u001b[32m[2020-06-22 17:15:53] __main__ INFO: \u001b[0mEpoch 84 Step 300/351 lr 0.010000 loss 1.6820 (1.6675) acc@1 0.3047 (0.3700) acc@5 0.7812 (0.7339)\n",
      "\u001b[32m[2020-06-22 17:15:58] __main__ INFO: \u001b[0mEpoch 84 Step 351/351 lr 0.010000 loss 1.7474 (1.6700) acc@1 0.3516 (0.3684) acc@5 0.7578 (0.7323)\n",
      "\u001b[32m[2020-06-22 17:15:58] __main__ INFO: \u001b[0mElapsed 32.76\n",
      "\u001b[32m[2020-06-22 17:15:58] __main__ INFO: \u001b[0mVal 84\n",
      "\u001b[32m[2020-06-22 17:15:59] __main__ INFO: \u001b[0mEpoch 84 loss 1.8793 acc@1 0.2956 acc@5 0.7056\n",
      "\u001b[32m[2020-06-22 17:15:59] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 17:15:59] __main__ INFO: \u001b[0mTrain 85 29484\n",
      "\u001b[32m[2020-06-22 17:16:08] __main__ INFO: \u001b[0mEpoch 85 Step 100/351 lr 0.010000 loss 1.6651 (1.6633) acc@1 0.3906 (0.3741) acc@5 0.7500 (0.7286)\n",
      "\u001b[32m[2020-06-22 17:16:18] __main__ INFO: \u001b[0mEpoch 85 Step 200/351 lr 0.010000 loss 1.6693 (1.6610) acc@1 0.3750 (0.3736) acc@5 0.7188 (0.7308)\n",
      "\u001b[32m[2020-06-22 17:16:27] __main__ INFO: \u001b[0mEpoch 85 Step 300/351 lr 0.010000 loss 1.5150 (1.6621) acc@1 0.4453 (0.3720) acc@5 0.7578 (0.7326)\n",
      "\u001b[32m[2020-06-22 17:16:32] __main__ INFO: \u001b[0mEpoch 85 Step 351/351 lr 0.010000 loss 1.7092 (1.6608) acc@1 0.3438 (0.3732) acc@5 0.7266 (0.7325)\n",
      "\u001b[32m[2020-06-22 17:16:32] __main__ INFO: \u001b[0mElapsed 32.75\n",
      "\u001b[32m[2020-06-22 17:16:32] __main__ INFO: \u001b[0mVal 85\n",
      "\u001b[32m[2020-06-22 17:16:33] __main__ INFO: \u001b[0mEpoch 85 loss 1.8974 acc@1 0.3016 acc@5 0.7042\n",
      "\u001b[32m[2020-06-22 17:16:33] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 17:16:33] __main__ INFO: \u001b[0mTrain 86 29835\n",
      "\u001b[32m[2020-06-22 17:16:42] __main__ INFO: \u001b[0mEpoch 86 Step 100/351 lr 0.010000 loss 1.5801 (1.6523) acc@1 0.3672 (0.3759) acc@5 0.7656 (0.7359)\n",
      "\u001b[32m[2020-06-22 17:16:51] __main__ INFO: \u001b[0mEpoch 86 Step 200/351 lr 0.010000 loss 1.6636 (1.6507) acc@1 0.3828 (0.3748) acc@5 0.7812 (0.7334)\n",
      "\u001b[32m[2020-06-22 17:17:01] __main__ INFO: \u001b[0mEpoch 86 Step 300/351 lr 0.010000 loss 1.6638 (1.6462) acc@1 0.3594 (0.3758) acc@5 0.7734 (0.7341)\n",
      "\u001b[32m[2020-06-22 17:17:05] __main__ INFO: \u001b[0mEpoch 86 Step 351/351 lr 0.010000 loss 1.7649 (1.6512) acc@1 0.3828 (0.3746) acc@5 0.7031 (0.7339)\n",
      "\u001b[32m[2020-06-22 17:17:05] __main__ INFO: \u001b[0mElapsed 32.77\n",
      "\u001b[32m[2020-06-22 17:17:05] __main__ INFO: \u001b[0mVal 86\n",
      "\u001b[32m[2020-06-22 17:17:06] __main__ INFO: \u001b[0mEpoch 86 loss 1.9055 acc@1 0.2998 acc@5 0.6948\n",
      "\u001b[32m[2020-06-22 17:17:06] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 17:17:06] __main__ INFO: \u001b[0mTrain 87 30186\n",
      "\u001b[32m[2020-06-22 17:17:16] __main__ INFO: \u001b[0mEpoch 87 Step 100/351 lr 0.010000 loss 1.7629 (1.6409) acc@1 0.3438 (0.3801) acc@5 0.6562 (0.7341)\n",
      "\u001b[32m[2020-06-22 17:17:25] __main__ INFO: \u001b[0mEpoch 87 Step 200/351 lr 0.010000 loss 1.7107 (1.6512) acc@1 0.3750 (0.3756) acc@5 0.7266 (0.7318)\n",
      "\u001b[32m[2020-06-22 17:17:34] __main__ INFO: \u001b[0mEpoch 87 Step 300/351 lr 0.010000 loss 1.6600 (1.6447) acc@1 0.3906 (0.3789) acc@5 0.6953 (0.7343)\n",
      "\u001b[32m[2020-06-22 17:17:39] __main__ INFO: \u001b[0mEpoch 87 Step 351/351 lr 0.010000 loss 1.6849 (1.6444) acc@1 0.3672 (0.3790) acc@5 0.7656 (0.7337)\n",
      "\u001b[32m[2020-06-22 17:17:39] __main__ INFO: \u001b[0mElapsed 32.72\n",
      "\u001b[32m[2020-06-22 17:17:39] __main__ INFO: \u001b[0mVal 87\n",
      "\u001b[32m[2020-06-22 17:17:40] __main__ INFO: \u001b[0mEpoch 87 loss 1.9162 acc@1 0.2982 acc@5 0.6996\n",
      "\u001b[32m[2020-06-22 17:17:40] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 17:17:40] __main__ INFO: \u001b[0mTrain 88 30537\n",
      "\u001b[32m[2020-06-22 17:17:50] __main__ INFO: \u001b[0mEpoch 88 Step 100/351 lr 0.010000 loss 1.5499 (1.6386) acc@1 0.3984 (0.3805) acc@5 0.7656 (0.7334)\n",
      "\u001b[32m[2020-06-22 17:17:59] __main__ INFO: \u001b[0mEpoch 88 Step 200/351 lr 0.010000 loss 1.5700 (1.6363) acc@1 0.4375 (0.3827) acc@5 0.6719 (0.7381)\n",
      "\u001b[32m[2020-06-22 17:18:08] __main__ INFO: \u001b[0mEpoch 88 Step 300/351 lr 0.010000 loss 1.5779 (1.6406) acc@1 0.4375 (0.3802) acc@5 0.7656 (0.7357)\n",
      "\u001b[32m[2020-06-22 17:18:13] __main__ INFO: \u001b[0mEpoch 88 Step 351/351 lr 0.010000 loss 1.6305 (1.6391) acc@1 0.4141 (0.3808) acc@5 0.7266 (0.7355)\n",
      "\u001b[32m[2020-06-22 17:18:13] __main__ INFO: \u001b[0mElapsed 32.73\n",
      "\u001b[32m[2020-06-22 17:18:13] __main__ INFO: \u001b[0mVal 88\n",
      "\u001b[32m[2020-06-22 17:18:14] __main__ INFO: \u001b[0mEpoch 88 loss 1.9147 acc@1 0.2998 acc@5 0.6996\n",
      "\u001b[32m[2020-06-22 17:18:14] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 17:18:14] __main__ INFO: \u001b[0mTrain 89 30888\n",
      "\u001b[32m[2020-06-22 17:18:23] __main__ INFO: \u001b[0mEpoch 89 Step 100/351 lr 0.010000 loss 1.6780 (1.6237) acc@1 0.3906 (0.3849) acc@5 0.7500 (0.7364)\n",
      "\u001b[32m[2020-06-22 17:18:33] __main__ INFO: \u001b[0mEpoch 89 Step 200/351 lr 0.010000 loss 1.6787 (1.6290) acc@1 0.3750 (0.3813) acc@5 0.7266 (0.7381)\n",
      "\u001b[32m[2020-06-22 17:18:42] __main__ INFO: \u001b[0mEpoch 89 Step 300/351 lr 0.010000 loss 1.4704 (1.6309) acc@1 0.4375 (0.3814) acc@5 0.7891 (0.7370)\n",
      "\u001b[32m[2020-06-22 17:18:47] __main__ INFO: \u001b[0mEpoch 89 Step 351/351 lr 0.010000 loss 1.7447 (1.6323) acc@1 0.3516 (0.3815) acc@5 0.7422 (0.7364)\n",
      "\u001b[32m[2020-06-22 17:18:47] __main__ INFO: \u001b[0mElapsed 32.82\n",
      "\u001b[32m[2020-06-22 17:18:47] __main__ INFO: \u001b[0mVal 89\n",
      "\u001b[32m[2020-06-22 17:18:48] __main__ INFO: \u001b[0mEpoch 89 loss 1.9232 acc@1 0.2958 acc@5 0.6990\n",
      "\u001b[32m[2020-06-22 17:18:48] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 17:18:48] __main__ INFO: \u001b[0mTrain 90 31239\n",
      "\u001b[32m[2020-06-22 17:18:57] __main__ INFO: \u001b[0mEpoch 90 Step 100/351 lr 0.010000 loss 1.3843 (1.6174) acc@1 0.4844 (0.3877) acc@5 0.7812 (0.7409)\n",
      "\u001b[32m[2020-06-22 17:19:07] __main__ INFO: \u001b[0mEpoch 90 Step 200/351 lr 0.010000 loss 1.5772 (1.6250) acc@1 0.3984 (0.3845) acc@5 0.7656 (0.7373)\n",
      "\u001b[32m[2020-06-22 17:19:16] __main__ INFO: \u001b[0mEpoch 90 Step 300/351 lr 0.010000 loss 1.7236 (1.6270) acc@1 0.3203 (0.3832) acc@5 0.6797 (0.7359)\n",
      "\u001b[32m[2020-06-22 17:19:21] __main__ INFO: \u001b[0mEpoch 90 Step 351/351 lr 0.010000 loss 1.6040 (1.6288) acc@1 0.3672 (0.3831) acc@5 0.7578 (0.7357)\n",
      "\u001b[32m[2020-06-22 17:19:21] __main__ INFO: \u001b[0mElapsed 32.74\n",
      "\u001b[32m[2020-06-22 17:19:21] __main__ INFO: \u001b[0mVal 90\n",
      "\u001b[32m[2020-06-22 17:19:22] __main__ INFO: \u001b[0mEpoch 90 loss 1.9276 acc@1 0.3026 acc@5 0.6924\n",
      "\u001b[32m[2020-06-22 17:19:22] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 17:19:22] __main__ INFO: \u001b[0mTrain 91 31590\n",
      "\u001b[32m[2020-06-22 17:19:31] __main__ INFO: \u001b[0mEpoch 91 Step 100/351 lr 0.010000 loss 1.3868 (1.6088) acc@1 0.4766 (0.3912) acc@5 0.7812 (0.7435)\n",
      "\u001b[32m[2020-06-22 17:19:40] __main__ INFO: \u001b[0mEpoch 91 Step 200/351 lr 0.010000 loss 1.5790 (1.6154) acc@1 0.4219 (0.3884) acc@5 0.7422 (0.7378)\n",
      "\u001b[32m[2020-06-22 17:19:50] __main__ INFO: \u001b[0mEpoch 91 Step 300/351 lr 0.010000 loss 1.6254 (1.6216) acc@1 0.3906 (0.3866) acc@5 0.7500 (0.7359)\n",
      "\u001b[32m[2020-06-22 17:19:54] __main__ INFO: \u001b[0mEpoch 91 Step 351/351 lr 0.010000 loss 1.7227 (1.6241) acc@1 0.3516 (0.3857) acc@5 0.7656 (0.7348)\n",
      "\u001b[32m[2020-06-22 17:19:54] __main__ INFO: \u001b[0mElapsed 32.78\n",
      "\u001b[32m[2020-06-22 17:19:54] __main__ INFO: \u001b[0mVal 91\n",
      "\u001b[32m[2020-06-22 17:19:56] __main__ INFO: \u001b[0mEpoch 91 loss 1.9206 acc@1 0.3000 acc@5 0.7054\n",
      "\u001b[32m[2020-06-22 17:19:56] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 17:19:56] __main__ INFO: \u001b[0mTrain 92 31941\n",
      "\u001b[32m[2020-06-22 17:20:05] __main__ INFO: \u001b[0mEpoch 92 Step 100/351 lr 0.010000 loss 1.4975 (1.6186) acc@1 0.4375 (0.3890) acc@5 0.7734 (0.7411)\n",
      "\u001b[32m[2020-06-22 17:20:14] __main__ INFO: \u001b[0mEpoch 92 Step 200/351 lr 0.010000 loss 1.6016 (1.6165) acc@1 0.3516 (0.3875) acc@5 0.7812 (0.7388)\n",
      "\u001b[32m[2020-06-22 17:20:24] __main__ INFO: \u001b[0mEpoch 92 Step 300/351 lr 0.010000 loss 1.7423 (1.6201) acc@1 0.3359 (0.3856) acc@5 0.6797 (0.7372)\n",
      "\u001b[32m[2020-06-22 17:20:28] __main__ INFO: \u001b[0mEpoch 92 Step 351/351 lr 0.010000 loss 1.5668 (1.6202) acc@1 0.4062 (0.3857) acc@5 0.6875 (0.7386)\n",
      "\u001b[32m[2020-06-22 17:20:28] __main__ INFO: \u001b[0mElapsed 32.76\n",
      "\u001b[32m[2020-06-22 17:20:28] __main__ INFO: \u001b[0mVal 92\n",
      "\u001b[32m[2020-06-22 17:20:29] __main__ INFO: \u001b[0mEpoch 92 loss 1.9316 acc@1 0.2924 acc@5 0.6978\n",
      "\u001b[32m[2020-06-22 17:20:29] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 17:20:29] __main__ INFO: \u001b[0mTrain 93 32292\n",
      "\u001b[32m[2020-06-22 17:20:39] __main__ INFO: \u001b[0mEpoch 93 Step 100/351 lr 0.010000 loss 1.7087 (1.6169) acc@1 0.3438 (0.3802) acc@5 0.6875 (0.7363)\n",
      "\u001b[32m[2020-06-22 17:20:48] __main__ INFO: \u001b[0mEpoch 93 Step 200/351 lr 0.010000 loss 1.6719 (1.6149) acc@1 0.4141 (0.3859) acc@5 0.7656 (0.7375)\n",
      "\u001b[32m[2020-06-22 17:20:57] __main__ INFO: \u001b[0mEpoch 93 Step 300/351 lr 0.010000 loss 1.7226 (1.6162) acc@1 0.3828 (0.3866) acc@5 0.7578 (0.7362)\n",
      "\u001b[32m[2020-06-22 17:21:02] __main__ INFO: \u001b[0mEpoch 93 Step 351/351 lr 0.010000 loss 1.4793 (1.6145) acc@1 0.4219 (0.3877) acc@5 0.7578 (0.7369)\n",
      "\u001b[32m[2020-06-22 17:21:02] __main__ INFO: \u001b[0mElapsed 32.74\n",
      "\u001b[32m[2020-06-22 17:21:02] __main__ INFO: \u001b[0mVal 93\n",
      "\u001b[32m[2020-06-22 17:21:03] __main__ INFO: \u001b[0mEpoch 93 loss 1.9308 acc@1 0.3026 acc@5 0.7074\n",
      "\u001b[32m[2020-06-22 17:21:03] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 17:21:03] __main__ INFO: \u001b[0mTrain 94 32643\n",
      "\u001b[32m[2020-06-22 17:21:13] __main__ INFO: \u001b[0mEpoch 94 Step 100/351 lr 0.010000 loss 1.5558 (1.6026) acc@1 0.3828 (0.3961) acc@5 0.7734 (0.7419)\n",
      "\u001b[32m[2020-06-22 17:21:22] __main__ INFO: \u001b[0mEpoch 94 Step 200/351 lr 0.010000 loss 1.5298 (1.6066) acc@1 0.4141 (0.3938) acc@5 0.7422 (0.7381)\n",
      "\u001b[32m[2020-06-22 17:21:31] __main__ INFO: \u001b[0mEpoch 94 Step 300/351 lr 0.010000 loss 1.6602 (1.6046) acc@1 0.3594 (0.3923) acc@5 0.6797 (0.7372)\n",
      "\u001b[32m[2020-06-22 17:21:36] __main__ INFO: \u001b[0mEpoch 94 Step 351/351 lr 0.010000 loss 1.5876 (1.6053) acc@1 0.4062 (0.3925) acc@5 0.7812 (0.7367)\n",
      "\u001b[32m[2020-06-22 17:21:36] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 17:21:36] __main__ INFO: \u001b[0mVal 94\n",
      "\u001b[32m[2020-06-22 17:21:37] __main__ INFO: \u001b[0mEpoch 94 loss 1.9479 acc@1 0.2924 acc@5 0.6974\n",
      "\u001b[32m[2020-06-22 17:21:37] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 17:21:37] __main__ INFO: \u001b[0mTrain 95 32994\n",
      "\u001b[32m[2020-06-22 17:21:46] __main__ INFO: \u001b[0mEpoch 95 Step 100/351 lr 0.010000 loss 1.6561 (1.5965) acc@1 0.3828 (0.3998) acc@5 0.7500 (0.7416)\n",
      "\u001b[32m[2020-06-22 17:21:56] __main__ INFO: \u001b[0mEpoch 95 Step 200/351 lr 0.010000 loss 1.6068 (1.6028) acc@1 0.3906 (0.3941) acc@5 0.7344 (0.7395)\n",
      "\u001b[32m[2020-06-22 17:22:05] __main__ INFO: \u001b[0mEpoch 95 Step 300/351 lr 0.010000 loss 1.6739 (1.6013) acc@1 0.3828 (0.3953) acc@5 0.7344 (0.7405)\n",
      "\u001b[32m[2020-06-22 17:22:10] __main__ INFO: \u001b[0mEpoch 95 Step 351/351 lr 0.010000 loss 1.6338 (1.6019) acc@1 0.3594 (0.3939) acc@5 0.7188 (0.7406)\n",
      "\u001b[32m[2020-06-22 17:22:10] __main__ INFO: \u001b[0mElapsed 32.74\n",
      "\u001b[32m[2020-06-22 17:22:10] __main__ INFO: \u001b[0mVal 95\n",
      "\u001b[32m[2020-06-22 17:22:11] __main__ INFO: \u001b[0mEpoch 95 loss 1.9494 acc@1 0.2920 acc@5 0.6940\n",
      "\u001b[32m[2020-06-22 17:22:11] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 17:22:11] __main__ INFO: \u001b[0mTrain 96 33345\n",
      "\u001b[32m[2020-06-22 17:22:20] __main__ INFO: \u001b[0mEpoch 96 Step 100/351 lr 0.010000 loss 1.5803 (1.6090) acc@1 0.3359 (0.3909) acc@5 0.7812 (0.7355)\n",
      "\u001b[32m[2020-06-22 17:22:30] __main__ INFO: \u001b[0mEpoch 96 Step 200/351 lr 0.010000 loss 1.6745 (1.6092) acc@1 0.3750 (0.3914) acc@5 0.7266 (0.7377)\n",
      "\u001b[32m[2020-06-22 17:22:39] __main__ INFO: \u001b[0mEpoch 96 Step 300/351 lr 0.010000 loss 1.6910 (1.5996) acc@1 0.3750 (0.3950) acc@5 0.7109 (0.7385)\n",
      "\u001b[32m[2020-06-22 17:22:44] __main__ INFO: \u001b[0mEpoch 96 Step 351/351 lr 0.010000 loss 1.5339 (1.5997) acc@1 0.4062 (0.3949) acc@5 0.7578 (0.7376)\n",
      "\u001b[32m[2020-06-22 17:22:44] __main__ INFO: \u001b[0mElapsed 32.74\n",
      "\u001b[32m[2020-06-22 17:22:44] __main__ INFO: \u001b[0mVal 96\n",
      "\u001b[32m[2020-06-22 17:22:45] __main__ INFO: \u001b[0mEpoch 96 loss 1.9377 acc@1 0.2986 acc@5 0.7038\n",
      "\u001b[32m[2020-06-22 17:22:45] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 17:22:45] __main__ INFO: \u001b[0mTrain 97 33696\n",
      "\u001b[32m[2020-06-22 17:22:54] __main__ INFO: \u001b[0mEpoch 97 Step 100/351 lr 0.010000 loss 1.4987 (1.5847) acc@1 0.4062 (0.4049) acc@5 0.7188 (0.7379)\n",
      "\u001b[32m[2020-06-22 17:23:03] __main__ INFO: \u001b[0mEpoch 97 Step 200/351 lr 0.010000 loss 1.4055 (1.5861) acc@1 0.4609 (0.4037) acc@5 0.8125 (0.7396)\n",
      "\u001b[32m[2020-06-22 17:23:13] __main__ INFO: \u001b[0mEpoch 97 Step 300/351 lr 0.010000 loss 1.5819 (1.5906) acc@1 0.3984 (0.4011) acc@5 0.7500 (0.7378)\n",
      "\u001b[32m[2020-06-22 17:23:17] __main__ INFO: \u001b[0mEpoch 97 Step 351/351 lr 0.010000 loss 1.5997 (1.5941) acc@1 0.4453 (0.3994) acc@5 0.7734 (0.7374)\n",
      "\u001b[32m[2020-06-22 17:23:17] __main__ INFO: \u001b[0mElapsed 32.74\n",
      "\u001b[32m[2020-06-22 17:23:17] __main__ INFO: \u001b[0mVal 97\n",
      "\u001b[32m[2020-06-22 17:23:18] __main__ INFO: \u001b[0mEpoch 97 loss 1.9580 acc@1 0.2974 acc@5 0.7054\n",
      "\u001b[32m[2020-06-22 17:23:18] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 17:23:18] __main__ INFO: \u001b[0mTrain 98 34047\n",
      "\u001b[32m[2020-06-22 17:23:28] __main__ INFO: \u001b[0mEpoch 98 Step 100/351 lr 0.010000 loss 1.6435 (1.5833) acc@1 0.3516 (0.4010) acc@5 0.7422 (0.7376)\n",
      "\u001b[32m[2020-06-22 17:23:37] __main__ INFO: \u001b[0mEpoch 98 Step 200/351 lr 0.010000 loss 1.4986 (1.5867) acc@1 0.4609 (0.3982) acc@5 0.8125 (0.7401)\n",
      "\u001b[32m[2020-06-22 17:23:46] __main__ INFO: \u001b[0mEpoch 98 Step 300/351 lr 0.010000 loss 1.4232 (1.5889) acc@1 0.4688 (0.3982) acc@5 0.8047 (0.7401)\n",
      "\u001b[32m[2020-06-22 17:23:51] __main__ INFO: \u001b[0mEpoch 98 Step 351/351 lr 0.010000 loss 1.6555 (1.5902) acc@1 0.3750 (0.3974) acc@5 0.7266 (0.7398)\n",
      "\u001b[32m[2020-06-22 17:23:51] __main__ INFO: \u001b[0mElapsed 32.75\n",
      "\u001b[32m[2020-06-22 17:23:51] __main__ INFO: \u001b[0mVal 98\n",
      "\u001b[32m[2020-06-22 17:23:52] __main__ INFO: \u001b[0mEpoch 98 loss 1.9575 acc@1 0.3002 acc@5 0.7020\n",
      "\u001b[32m[2020-06-22 17:23:52] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 17:23:52] __main__ INFO: \u001b[0mTrain 99 34398\n",
      "\u001b[32m[2020-06-22 17:24:02] __main__ INFO: \u001b[0mEpoch 99 Step 100/351 lr 0.010000 loss 1.5676 (1.5712) acc@1 0.4219 (0.4091) acc@5 0.7656 (0.7500)\n",
      "\u001b[32m[2020-06-22 17:24:11] __main__ INFO: \u001b[0mEpoch 99 Step 200/351 lr 0.010000 loss 1.5415 (1.5830) acc@1 0.3828 (0.4011) acc@5 0.7500 (0.7453)\n",
      "\u001b[32m[2020-06-22 17:24:20] __main__ INFO: \u001b[0mEpoch 99 Step 300/351 lr 0.010000 loss 1.7665 (1.5916) acc@1 0.3281 (0.3984) acc@5 0.7188 (0.7433)\n",
      "\u001b[32m[2020-06-22 17:24:25] __main__ INFO: \u001b[0mEpoch 99 Step 351/351 lr 0.010000 loss 1.7295 (1.5933) acc@1 0.3203 (0.3974) acc@5 0.7188 (0.7419)\n",
      "\u001b[32m[2020-06-22 17:24:25] __main__ INFO: \u001b[0mElapsed 32.77\n",
      "\u001b[32m[2020-06-22 17:24:25] __main__ INFO: \u001b[0mVal 99\n",
      "\u001b[32m[2020-06-22 17:24:26] __main__ INFO: \u001b[0mEpoch 99 loss 1.9789 acc@1 0.2840 acc@5 0.7062\n",
      "\u001b[32m[2020-06-22 17:24:26] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 17:24:26] __main__ INFO: \u001b[0mTrain 100 34749\n",
      "\u001b[32m[2020-06-22 17:24:36] __main__ INFO: \u001b[0mEpoch 100 Step 100/351 lr 0.010000 loss 1.7935 (1.5742) acc@1 0.3672 (0.4056) acc@5 0.7031 (0.7402)\n",
      "\u001b[32m[2020-06-22 17:24:45] __main__ INFO: \u001b[0mEpoch 100 Step 200/351 lr 0.010000 loss 1.4147 (1.5794) acc@1 0.4844 (0.4028) acc@5 0.7734 (0.7417)\n",
      "\u001b[32m[2020-06-22 17:24:54] __main__ INFO: \u001b[0mEpoch 100 Step 300/351 lr 0.010000 loss 1.5366 (1.5798) acc@1 0.4297 (0.4020) acc@5 0.8203 (0.7396)\n",
      "\u001b[32m[2020-06-22 17:24:59] __main__ INFO: \u001b[0mEpoch 100 Step 351/351 lr 0.010000 loss 1.4574 (1.5807) acc@1 0.4844 (0.4019) acc@5 0.7656 (0.7391)\n",
      "\u001b[32m[2020-06-22 17:24:59] __main__ INFO: \u001b[0mElapsed 32.83\n",
      "\u001b[32m[2020-06-22 17:24:59] __main__ INFO: \u001b[0mVal 100\n",
      "\u001b[32m[2020-06-22 17:25:00] __main__ INFO: \u001b[0mEpoch 100 loss 1.9747 acc@1 0.3102 acc@5 0.7144\n",
      "\u001b[32m[2020-06-22 17:25:00] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 17:25:00] fvcore.common.checkpoint INFO: \u001b[0mSaving checkpoint to /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00/checkpoint_00100.pth\n",
      "\u001b[32m[2020-06-22 17:25:00] __main__ INFO: \u001b[0mTrain 101 35100\n",
      "\u001b[32m[2020-06-22 17:25:09] __main__ INFO: \u001b[0mEpoch 101 Step 100/351 lr 0.010000 loss 1.8334 (1.5760) acc@1 0.2969 (0.4041) acc@5 0.6719 (0.7389)\n",
      "\u001b[32m[2020-06-22 17:25:19] __main__ INFO: \u001b[0mEpoch 101 Step 200/351 lr 0.010000 loss 1.4855 (1.5689) acc@1 0.4453 (0.4070) acc@5 0.7734 (0.7420)\n",
      "\u001b[32m[2020-06-22 17:25:28] __main__ INFO: \u001b[0mEpoch 101 Step 300/351 lr 0.010000 loss 1.5732 (1.5720) acc@1 0.4219 (0.4036) acc@5 0.7969 (0.7420)\n",
      "\u001b[32m[2020-06-22 17:25:33] __main__ INFO: \u001b[0mEpoch 101 Step 351/351 lr 0.010000 loss 1.6110 (1.5769) acc@1 0.3906 (0.4023) acc@5 0.7812 (0.7404)\n",
      "\u001b[32m[2020-06-22 17:25:33] __main__ INFO: \u001b[0mElapsed 32.76\n",
      "\u001b[32m[2020-06-22 17:25:33] __main__ INFO: \u001b[0mVal 101\n",
      "\u001b[32m[2020-06-22 17:25:34] __main__ INFO: \u001b[0mEpoch 101 loss 2.0055 acc@1 0.2880 acc@5 0.6946\n",
      "\u001b[32m[2020-06-22 17:25:34] __main__ INFO: \u001b[0mElapsed 1.03\n",
      "\u001b[32m[2020-06-22 17:25:34] __main__ INFO: \u001b[0mTrain 102 35451\n",
      "\u001b[32m[2020-06-22 17:25:43] __main__ INFO: \u001b[0mEpoch 102 Step 100/351 lr 0.010000 loss 1.6276 (1.5571) acc@1 0.3828 (0.4141) acc@5 0.7578 (0.7476)\n",
      "\u001b[32m[2020-06-22 17:25:52] __main__ INFO: \u001b[0mEpoch 102 Step 200/351 lr 0.010000 loss 1.6447 (1.5610) acc@1 0.3438 (0.4109) acc@5 0.6875 (0.7471)\n",
      "\u001b[32m[2020-06-22 17:26:02] __main__ INFO: \u001b[0mEpoch 102 Step 300/351 lr 0.010000 loss 1.5485 (1.5652) acc@1 0.4375 (0.4084) acc@5 0.7344 (0.7438)\n",
      "\u001b[32m[2020-06-22 17:26:07] __main__ INFO: \u001b[0mEpoch 102 Step 351/351 lr 0.010000 loss 1.5821 (1.5702) acc@1 0.4375 (0.4075) acc@5 0.7812 (0.7436)\n",
      "\u001b[32m[2020-06-22 17:26:07] __main__ INFO: \u001b[0mElapsed 32.76\n",
      "\u001b[32m[2020-06-22 17:26:07] __main__ INFO: \u001b[0mVal 102\n",
      "\u001b[32m[2020-06-22 17:26:08] __main__ INFO: \u001b[0mEpoch 102 loss 1.9666 acc@1 0.2978 acc@5 0.7072\n",
      "\u001b[32m[2020-06-22 17:26:08] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 17:26:08] __main__ INFO: \u001b[0mTrain 103 35802\n",
      "\u001b[32m[2020-06-22 17:26:17] __main__ INFO: \u001b[0mEpoch 103 Step 100/351 lr 0.010000 loss 1.4415 (1.5598) acc@1 0.4453 (0.4068) acc@5 0.7656 (0.7469)\n",
      "\u001b[32m[2020-06-22 17:26:26] __main__ INFO: \u001b[0mEpoch 103 Step 200/351 lr 0.010000 loss 1.5475 (1.5665) acc@1 0.4609 (0.4050) acc@5 0.7812 (0.7420)\n",
      "\u001b[32m[2020-06-22 17:26:36] __main__ INFO: \u001b[0mEpoch 103 Step 300/351 lr 0.010000 loss 1.4756 (1.5690) acc@1 0.4141 (0.4026) acc@5 0.8047 (0.7406)\n",
      "\u001b[32m[2020-06-22 17:26:40] __main__ INFO: \u001b[0mEpoch 103 Step 351/351 lr 0.010000 loss 1.5584 (1.5715) acc@1 0.4531 (0.4029) acc@5 0.6797 (0.7413)\n",
      "\u001b[32m[2020-06-22 17:26:40] __main__ INFO: \u001b[0mElapsed 32.77\n",
      "\u001b[32m[2020-06-22 17:26:40] __main__ INFO: \u001b[0mVal 103\n",
      "\u001b[32m[2020-06-22 17:26:41] __main__ INFO: \u001b[0mEpoch 103 loss 1.9766 acc@1 0.2976 acc@5 0.7086\n",
      "\u001b[32m[2020-06-22 17:26:41] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 17:26:41] __main__ INFO: \u001b[0mTrain 104 36153\n",
      "\u001b[32m[2020-06-22 17:26:51] __main__ INFO: \u001b[0mEpoch 104 Step 100/351 lr 0.010000 loss 1.4902 (1.5623) acc@1 0.4531 (0.4107) acc@5 0.7578 (0.7438)\n",
      "\u001b[32m[2020-06-22 17:27:00] __main__ INFO: \u001b[0mEpoch 104 Step 200/351 lr 0.010000 loss 1.4584 (1.5644) acc@1 0.4766 (0.4087) acc@5 0.7969 (0.7422)\n",
      "\u001b[32m[2020-06-22 17:27:09] __main__ INFO: \u001b[0mEpoch 104 Step 300/351 lr 0.010000 loss 1.6347 (1.5698) acc@1 0.3906 (0.4044) acc@5 0.6953 (0.7431)\n",
      "\u001b[32m[2020-06-22 17:27:14] __main__ INFO: \u001b[0mEpoch 104 Step 351/351 lr 0.010000 loss 1.6948 (1.5694) acc@1 0.3672 (0.4035) acc@5 0.7578 (0.7427)\n",
      "\u001b[32m[2020-06-22 17:27:14] __main__ INFO: \u001b[0mElapsed 32.77\n",
      "\u001b[32m[2020-06-22 17:27:14] __main__ INFO: \u001b[0mVal 104\n",
      "\u001b[32m[2020-06-22 17:27:15] __main__ INFO: \u001b[0mEpoch 104 loss 2.0365 acc@1 0.2908 acc@5 0.6908\n",
      "\u001b[32m[2020-06-22 17:27:15] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 17:27:15] __main__ INFO: \u001b[0mTrain 105 36504\n",
      "\u001b[32m[2020-06-22 17:27:25] __main__ INFO: \u001b[0mEpoch 105 Step 100/351 lr 0.010000 loss 1.5315 (1.5515) acc@1 0.4453 (0.4133) acc@5 0.7734 (0.7445)\n",
      "\u001b[32m[2020-06-22 17:27:34] __main__ INFO: \u001b[0mEpoch 105 Step 200/351 lr 0.010000 loss 1.3705 (1.5513) acc@1 0.4453 (0.4121) acc@5 0.7109 (0.7446)\n",
      "\u001b[32m[2020-06-22 17:27:43] __main__ INFO: \u001b[0mEpoch 105 Step 300/351 lr 0.010000 loss 1.6225 (1.5601) acc@1 0.3984 (0.4076) acc@5 0.7812 (0.7422)\n",
      "\u001b[32m[2020-06-22 17:27:48] __main__ INFO: \u001b[0mEpoch 105 Step 351/351 lr 0.010000 loss 1.4546 (1.5620) acc@1 0.4297 (0.4069) acc@5 0.7969 (0.7419)\n",
      "\u001b[32m[2020-06-22 17:27:48] __main__ INFO: \u001b[0mElapsed 32.81\n",
      "\u001b[32m[2020-06-22 17:27:48] __main__ INFO: \u001b[0mVal 105\n",
      "\u001b[32m[2020-06-22 17:27:49] __main__ INFO: \u001b[0mEpoch 105 loss 2.0022 acc@1 0.2840 acc@5 0.6934\n",
      "\u001b[32m[2020-06-22 17:27:49] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 17:27:49] __main__ INFO: \u001b[0mTrain 106 36855\n",
      "\u001b[32m[2020-06-22 17:27:59] __main__ INFO: \u001b[0mEpoch 106 Step 100/351 lr 0.010000 loss 1.4667 (1.5401) acc@1 0.4531 (0.4155) acc@5 0.7422 (0.7479)\n",
      "\u001b[32m[2020-06-22 17:28:08] __main__ INFO: \u001b[0mEpoch 106 Step 200/351 lr 0.010000 loss 1.6172 (1.5514) acc@1 0.3828 (0.4097) acc@5 0.7266 (0.7460)\n",
      "\u001b[32m[2020-06-22 17:28:17] __main__ INFO: \u001b[0mEpoch 106 Step 300/351 lr 0.010000 loss 1.6240 (1.5603) acc@1 0.3516 (0.4064) acc@5 0.6875 (0.7438)\n",
      "\u001b[32m[2020-06-22 17:28:22] __main__ INFO: \u001b[0mEpoch 106 Step 351/351 lr 0.010000 loss 1.5020 (1.5610) acc@1 0.4219 (0.4063) acc@5 0.7656 (0.7444)\n",
      "\u001b[32m[2020-06-22 17:28:22] __main__ INFO: \u001b[0mElapsed 32.77\n",
      "\u001b[32m[2020-06-22 17:28:22] __main__ INFO: \u001b[0mVal 106\n",
      "\u001b[32m[2020-06-22 17:28:23] __main__ INFO: \u001b[0mEpoch 106 loss 1.9971 acc@1 0.2976 acc@5 0.6980\n",
      "\u001b[32m[2020-06-22 17:28:23] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 17:28:23] __main__ INFO: \u001b[0mTrain 107 37206\n",
      "\u001b[32m[2020-06-22 17:28:32] __main__ INFO: \u001b[0mEpoch 107 Step 100/351 lr 0.010000 loss 1.5547 (1.5436) acc@1 0.3750 (0.4140) acc@5 0.7500 (0.7437)\n",
      "\u001b[32m[2020-06-22 17:28:42] __main__ INFO: \u001b[0mEpoch 107 Step 200/351 lr 0.010000 loss 1.7700 (1.5491) acc@1 0.3594 (0.4118) acc@5 0.6562 (0.7416)\n",
      "\u001b[32m[2020-06-22 17:28:51] __main__ INFO: \u001b[0mEpoch 107 Step 300/351 lr 0.010000 loss 1.6015 (1.5496) acc@1 0.4453 (0.4130) acc@5 0.7344 (0.7413)\n",
      "\u001b[32m[2020-06-22 17:28:56] __main__ INFO: \u001b[0mEpoch 107 Step 351/351 lr 0.010000 loss 1.6063 (1.5533) acc@1 0.3750 (0.4121) acc@5 0.7656 (0.7412)\n",
      "\u001b[32m[2020-06-22 17:28:56] __main__ INFO: \u001b[0mElapsed 32.81\n",
      "\u001b[32m[2020-06-22 17:28:56] __main__ INFO: \u001b[0mVal 107\n",
      "\u001b[32m[2020-06-22 17:28:57] __main__ INFO: \u001b[0mEpoch 107 loss 2.0517 acc@1 0.2914 acc@5 0.6932\n",
      "\u001b[32m[2020-06-22 17:28:57] __main__ INFO: \u001b[0mElapsed 1.03\n",
      "\u001b[32m[2020-06-22 17:28:57] __main__ INFO: \u001b[0mTrain 108 37557\n",
      "\u001b[32m[2020-06-22 17:29:06] __main__ INFO: \u001b[0mEpoch 108 Step 100/351 lr 0.010000 loss 1.4791 (1.5394) acc@1 0.4609 (0.4138) acc@5 0.7500 (0.7504)\n",
      "\u001b[32m[2020-06-22 17:29:16] __main__ INFO: \u001b[0mEpoch 108 Step 200/351 lr 0.010000 loss 1.5920 (1.5439) acc@1 0.4062 (0.4133) acc@5 0.7656 (0.7461)\n",
      "\u001b[32m[2020-06-22 17:29:25] __main__ INFO: \u001b[0mEpoch 108 Step 300/351 lr 0.010000 loss 1.3762 (1.5537) acc@1 0.5000 (0.4088) acc@5 0.7344 (0.7427)\n",
      "\u001b[32m[2020-06-22 17:29:30] __main__ INFO: \u001b[0mEpoch 108 Step 351/351 lr 0.010000 loss 1.6408 (1.5531) acc@1 0.3438 (0.4091) acc@5 0.6953 (0.7422)\n",
      "\u001b[32m[2020-06-22 17:29:30] __main__ INFO: \u001b[0mElapsed 32.77\n",
      "\u001b[32m[2020-06-22 17:29:30] __main__ INFO: \u001b[0mVal 108\n",
      "\u001b[32m[2020-06-22 17:29:31] __main__ INFO: \u001b[0mEpoch 108 loss 2.0191 acc@1 0.2982 acc@5 0.7046\n",
      "\u001b[32m[2020-06-22 17:29:31] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 17:29:31] __main__ INFO: \u001b[0mTrain 109 37908\n",
      "\u001b[32m[2020-06-22 17:29:40] __main__ INFO: \u001b[0mEpoch 109 Step 100/351 lr 0.010000 loss 1.5983 (1.5313) acc@1 0.3750 (0.4182) acc@5 0.7578 (0.7428)\n",
      "\u001b[32m[2020-06-22 17:29:49] __main__ INFO: \u001b[0mEpoch 109 Step 200/351 lr 0.010000 loss 1.3908 (1.5396) acc@1 0.5000 (0.4135) acc@5 0.7812 (0.7403)\n",
      "\u001b[32m[2020-06-22 17:29:59] __main__ INFO: \u001b[0mEpoch 109 Step 300/351 lr 0.010000 loss 1.5920 (1.5463) acc@1 0.3672 (0.4105) acc@5 0.6953 (0.7415)\n",
      "\u001b[32m[2020-06-22 17:30:03] __main__ INFO: \u001b[0mEpoch 109 Step 351/351 lr 0.010000 loss 1.4743 (1.5484) acc@1 0.4609 (0.4099) acc@5 0.7734 (0.7416)\n",
      "\u001b[32m[2020-06-22 17:30:03] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 17:30:03] __main__ INFO: \u001b[0mVal 109\n",
      "\u001b[32m[2020-06-22 17:30:04] __main__ INFO: \u001b[0mEpoch 109 loss 2.0454 acc@1 0.2762 acc@5 0.6896\n",
      "\u001b[32m[2020-06-22 17:30:04] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 17:30:04] __main__ INFO: \u001b[0mTrain 110 38259\n",
      "\u001b[32m[2020-06-22 17:30:14] __main__ INFO: \u001b[0mEpoch 110 Step 100/351 lr 0.010000 loss 1.5171 (1.5299) acc@1 0.3828 (0.4166) acc@5 0.7578 (0.7453)\n",
      "\u001b[32m[2020-06-22 17:30:23] __main__ INFO: \u001b[0mEpoch 110 Step 200/351 lr 0.010000 loss 1.5430 (1.5433) acc@1 0.4062 (0.4116) acc@5 0.7188 (0.7462)\n",
      "\u001b[32m[2020-06-22 17:30:32] __main__ INFO: \u001b[0mEpoch 110 Step 300/351 lr 0.010000 loss 1.5287 (1.5436) acc@1 0.4219 (0.4132) acc@5 0.7734 (0.7459)\n",
      "\u001b[32m[2020-06-22 17:30:37] __main__ INFO: \u001b[0mEpoch 110 Step 351/351 lr 0.010000 loss 1.6549 (1.5483) acc@1 0.3984 (0.4108) acc@5 0.7812 (0.7439)\n",
      "\u001b[32m[2020-06-22 17:30:37] __main__ INFO: \u001b[0mElapsed 32.77\n",
      "\u001b[32m[2020-06-22 17:30:37] __main__ INFO: \u001b[0mVal 110\n",
      "\u001b[32m[2020-06-22 17:30:38] __main__ INFO: \u001b[0mEpoch 110 loss 2.0702 acc@1 0.2916 acc@5 0.6964\n",
      "\u001b[32m[2020-06-22 17:30:38] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 17:30:38] __main__ INFO: \u001b[0mTrain 111 38610\n",
      "\u001b[32m[2020-06-22 17:30:48] __main__ INFO: \u001b[0mEpoch 111 Step 100/351 lr 0.010000 loss 1.6076 (1.5298) acc@1 0.3594 (0.4159) acc@5 0.7031 (0.7454)\n",
      "\u001b[32m[2020-06-22 17:30:57] __main__ INFO: \u001b[0mEpoch 111 Step 200/351 lr 0.010000 loss 1.3801 (1.5311) acc@1 0.4844 (0.4157) acc@5 0.8125 (0.7446)\n",
      "\u001b[32m[2020-06-22 17:31:06] __main__ INFO: \u001b[0mEpoch 111 Step 300/351 lr 0.010000 loss 1.3728 (1.5373) acc@1 0.4688 (0.4143) acc@5 0.7500 (0.7442)\n",
      "\u001b[32m[2020-06-22 17:31:11] __main__ INFO: \u001b[0mEpoch 111 Step 351/351 lr 0.010000 loss 1.4624 (1.5393) acc@1 0.4297 (0.4126) acc@5 0.7344 (0.7439)\n",
      "\u001b[32m[2020-06-22 17:31:11] __main__ INFO: \u001b[0mElapsed 32.73\n",
      "\u001b[32m[2020-06-22 17:31:11] __main__ INFO: \u001b[0mVal 111\n",
      "\u001b[32m[2020-06-22 17:31:12] __main__ INFO: \u001b[0mEpoch 111 loss 2.0362 acc@1 0.2870 acc@5 0.6946\n",
      "\u001b[32m[2020-06-22 17:31:12] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 17:31:12] __main__ INFO: \u001b[0mTrain 112 38961\n",
      "\u001b[32m[2020-06-22 17:31:21] __main__ INFO: \u001b[0mEpoch 112 Step 100/351 lr 0.010000 loss 1.5147 (1.5255) acc@1 0.4297 (0.4243) acc@5 0.7266 (0.7434)\n",
      "\u001b[32m[2020-06-22 17:31:31] __main__ INFO: \u001b[0mEpoch 112 Step 200/351 lr 0.010000 loss 1.6017 (1.5357) acc@1 0.3828 (0.4189) acc@5 0.7422 (0.7468)\n",
      "\u001b[32m[2020-06-22 17:31:40] __main__ INFO: \u001b[0mEpoch 112 Step 300/351 lr 0.010000 loss 1.5739 (1.5358) acc@1 0.3672 (0.4175) acc@5 0.7578 (0.7458)\n",
      "\u001b[32m[2020-06-22 17:31:45] __main__ INFO: \u001b[0mEpoch 112 Step 351/351 lr 0.010000 loss 1.4420 (1.5370) acc@1 0.4766 (0.4165) acc@5 0.7891 (0.7451)\n",
      "\u001b[32m[2020-06-22 17:31:45] __main__ INFO: \u001b[0mElapsed 32.78\n",
      "\u001b[32m[2020-06-22 17:31:45] __main__ INFO: \u001b[0mVal 112\n",
      "\u001b[32m[2020-06-22 17:31:46] __main__ INFO: \u001b[0mEpoch 112 loss 2.0365 acc@1 0.2968 acc@5 0.6912\n",
      "\u001b[32m[2020-06-22 17:31:46] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 17:31:46] __main__ INFO: \u001b[0mTrain 113 39312\n",
      "\u001b[32m[2020-06-22 17:31:55] __main__ INFO: \u001b[0mEpoch 113 Step 100/351 lr 0.010000 loss 1.4524 (1.5188) acc@1 0.4375 (0.4256) acc@5 0.7344 (0.7438)\n",
      "\u001b[32m[2020-06-22 17:32:05] __main__ INFO: \u001b[0mEpoch 113 Step 200/351 lr 0.010000 loss 1.4046 (1.5264) acc@1 0.4609 (0.4212) acc@5 0.7578 (0.7445)\n",
      "\u001b[32m[2020-06-22 17:32:14] __main__ INFO: \u001b[0mEpoch 113 Step 300/351 lr 0.010000 loss 1.5432 (1.5322) acc@1 0.3984 (0.4191) acc@5 0.7500 (0.7435)\n",
      "\u001b[32m[2020-06-22 17:32:19] __main__ INFO: \u001b[0mEpoch 113 Step 351/351 lr 0.010000 loss 1.3444 (1.5360) acc@1 0.4844 (0.4173) acc@5 0.7812 (0.7439)\n",
      "\u001b[32m[2020-06-22 17:32:19] __main__ INFO: \u001b[0mElapsed 32.77\n",
      "\u001b[32m[2020-06-22 17:32:19] __main__ INFO: \u001b[0mVal 113\n",
      "\u001b[32m[2020-06-22 17:32:20] __main__ INFO: \u001b[0mEpoch 113 loss 2.0549 acc@1 0.2960 acc@5 0.6926\n",
      "\u001b[32m[2020-06-22 17:32:20] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 17:32:20] __main__ INFO: \u001b[0mTrain 114 39663\n",
      "\u001b[32m[2020-06-22 17:32:29] __main__ INFO: \u001b[0mEpoch 114 Step 100/351 lr 0.010000 loss 1.6335 (1.5339) acc@1 0.4141 (0.4155) acc@5 0.7578 (0.7424)\n",
      "\u001b[32m[2020-06-22 17:32:38] __main__ INFO: \u001b[0mEpoch 114 Step 200/351 lr 0.010000 loss 1.5782 (1.5274) acc@1 0.3750 (0.4186) acc@5 0.7266 (0.7444)\n",
      "\u001b[32m[2020-06-22 17:32:48] __main__ INFO: \u001b[0mEpoch 114 Step 300/351 lr 0.010000 loss 1.5937 (1.5314) acc@1 0.4297 (0.4173) acc@5 0.7344 (0.7440)\n",
      "\u001b[32m[2020-06-22 17:32:52] __main__ INFO: \u001b[0mEpoch 114 Step 351/351 lr 0.010000 loss 1.5193 (1.5321) acc@1 0.4141 (0.4172) acc@5 0.7266 (0.7449)\n",
      "\u001b[32m[2020-06-22 17:32:53] __main__ INFO: \u001b[0mElapsed 32.78\n",
      "\u001b[32m[2020-06-22 17:32:53] __main__ INFO: \u001b[0mVal 114\n",
      "\u001b[32m[2020-06-22 17:32:54] __main__ INFO: \u001b[0mEpoch 114 loss 2.0886 acc@1 0.2914 acc@5 0.6878\n",
      "\u001b[32m[2020-06-22 17:32:54] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 17:32:54] __main__ INFO: \u001b[0mTrain 115 40014\n",
      "\u001b[32m[2020-06-22 17:33:03] __main__ INFO: \u001b[0mEpoch 115 Step 100/351 lr 0.010000 loss 1.6440 (1.5256) acc@1 0.3828 (0.4170) acc@5 0.8047 (0.7454)\n",
      "\u001b[32m[2020-06-22 17:33:12] __main__ INFO: \u001b[0mEpoch 115 Step 200/351 lr 0.010000 loss 1.5772 (1.5207) acc@1 0.3984 (0.4200) acc@5 0.7734 (0.7463)\n",
      "\u001b[32m[2020-06-22 17:33:22] __main__ INFO: \u001b[0mEpoch 115 Step 300/351 lr 0.010000 loss 1.6083 (1.5243) acc@1 0.3906 (0.4175) acc@5 0.7266 (0.7463)\n",
      "\u001b[32m[2020-06-22 17:33:26] __main__ INFO: \u001b[0mEpoch 115 Step 351/351 lr 0.010000 loss 1.5720 (1.5281) acc@1 0.4062 (0.4165) acc@5 0.7266 (0.7469)\n",
      "\u001b[32m[2020-06-22 17:33:26] __main__ INFO: \u001b[0mElapsed 32.74\n",
      "\u001b[32m[2020-06-22 17:33:26] __main__ INFO: \u001b[0mVal 115\n",
      "\u001b[32m[2020-06-22 17:33:27] __main__ INFO: \u001b[0mEpoch 115 loss 2.0874 acc@1 0.2828 acc@5 0.6882\n",
      "\u001b[32m[2020-06-22 17:33:27] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 17:33:27] __main__ INFO: \u001b[0mTrain 116 40365\n",
      "\u001b[32m[2020-06-22 17:33:37] __main__ INFO: \u001b[0mEpoch 116 Step 100/351 lr 0.010000 loss 1.5378 (1.5194) acc@1 0.4141 (0.4256) acc@5 0.6875 (0.7451)\n",
      "\u001b[32m[2020-06-22 17:33:46] __main__ INFO: \u001b[0mEpoch 116 Step 200/351 lr 0.010000 loss 1.4212 (1.5190) acc@1 0.4531 (0.4238) acc@5 0.7344 (0.7442)\n",
      "\u001b[32m[2020-06-22 17:33:55] __main__ INFO: \u001b[0mEpoch 116 Step 300/351 lr 0.010000 loss 1.4258 (1.5256) acc@1 0.4531 (0.4200) acc@5 0.7266 (0.7429)\n",
      "\u001b[32m[2020-06-22 17:34:00] __main__ INFO: \u001b[0mEpoch 116 Step 351/351 lr 0.010000 loss 1.4943 (1.5271) acc@1 0.4141 (0.4190) acc@5 0.8047 (0.7437)\n",
      "\u001b[32m[2020-06-22 17:34:00] __main__ INFO: \u001b[0mElapsed 32.86\n",
      "\u001b[32m[2020-06-22 17:34:00] __main__ INFO: \u001b[0mVal 116\n",
      "\u001b[32m[2020-06-22 17:34:01] __main__ INFO: \u001b[0mEpoch 116 loss 2.0571 acc@1 0.2868 acc@5 0.6906\n",
      "\u001b[32m[2020-06-22 17:34:01] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 17:34:01] __main__ INFO: \u001b[0mTrain 117 40716\n",
      "\u001b[32m[2020-06-22 17:34:11] __main__ INFO: \u001b[0mEpoch 117 Step 100/351 lr 0.010000 loss 1.5242 (1.5047) acc@1 0.3984 (0.4280) acc@5 0.7891 (0.7520)\n",
      "\u001b[32m[2020-06-22 17:34:20] __main__ INFO: \u001b[0mEpoch 117 Step 200/351 lr 0.010000 loss 1.4798 (1.5147) acc@1 0.4375 (0.4227) acc@5 0.7812 (0.7485)\n",
      "\u001b[32m[2020-06-22 17:34:29] __main__ INFO: \u001b[0mEpoch 117 Step 300/351 lr 0.010000 loss 1.6003 (1.5187) acc@1 0.3750 (0.4214) acc@5 0.7109 (0.7485)\n",
      "\u001b[32m[2020-06-22 17:34:34] __main__ INFO: \u001b[0mEpoch 117 Step 351/351 lr 0.010000 loss 1.5448 (1.5199) acc@1 0.4141 (0.4214) acc@5 0.7422 (0.7482)\n",
      "\u001b[32m[2020-06-22 17:34:34] __main__ INFO: \u001b[0mElapsed 32.77\n",
      "\u001b[32m[2020-06-22 17:34:34] __main__ INFO: \u001b[0mVal 117\n",
      "\u001b[32m[2020-06-22 17:34:35] __main__ INFO: \u001b[0mEpoch 117 loss 2.0690 acc@1 0.2794 acc@5 0.6898\n",
      "\u001b[32m[2020-06-22 17:34:35] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 17:34:35] __main__ INFO: \u001b[0mTrain 118 41067\n",
      "\u001b[32m[2020-06-22 17:34:45] __main__ INFO: \u001b[0mEpoch 118 Step 100/351 lr 0.010000 loss 1.5960 (1.5141) acc@1 0.3828 (0.4231) acc@5 0.6875 (0.7416)\n",
      "\u001b[32m[2020-06-22 17:34:54] __main__ INFO: \u001b[0mEpoch 118 Step 200/351 lr 0.010000 loss 1.4398 (1.5168) acc@1 0.4141 (0.4228) acc@5 0.7812 (0.7427)\n",
      "\u001b[32m[2020-06-22 17:35:03] __main__ INFO: \u001b[0mEpoch 118 Step 300/351 lr 0.010000 loss 1.4397 (1.5227) acc@1 0.4688 (0.4199) acc@5 0.7812 (0.7430)\n",
      "\u001b[32m[2020-06-22 17:35:08] __main__ INFO: \u001b[0mEpoch 118 Step 351/351 lr 0.010000 loss 1.5251 (1.5242) acc@1 0.4375 (0.4195) acc@5 0.7422 (0.7433)\n",
      "\u001b[32m[2020-06-22 17:35:08] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 17:35:08] __main__ INFO: \u001b[0mVal 118\n",
      "\u001b[32m[2020-06-22 17:35:09] __main__ INFO: \u001b[0mEpoch 118 loss 2.0621 acc@1 0.2904 acc@5 0.6956\n",
      "\u001b[32m[2020-06-22 17:35:09] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 17:35:09] __main__ INFO: \u001b[0mTrain 119 41418\n",
      "\u001b[32m[2020-06-22 17:35:18] __main__ INFO: \u001b[0mEpoch 119 Step 100/351 lr 0.010000 loss 1.4221 (1.5033) acc@1 0.4453 (0.4292) acc@5 0.7656 (0.7477)\n",
      "\u001b[32m[2020-06-22 17:35:28] __main__ INFO: \u001b[0mEpoch 119 Step 200/351 lr 0.010000 loss 1.4094 (1.5132) acc@1 0.4531 (0.4253) acc@5 0.7656 (0.7450)\n",
      "\u001b[32m[2020-06-22 17:35:37] __main__ INFO: \u001b[0mEpoch 119 Step 300/351 lr 0.010000 loss 1.5870 (1.5171) acc@1 0.3984 (0.4238) acc@5 0.7031 (0.7441)\n",
      "\u001b[32m[2020-06-22 17:35:42] __main__ INFO: \u001b[0mEpoch 119 Step 351/351 lr 0.010000 loss 1.6381 (1.5187) acc@1 0.3750 (0.4230) acc@5 0.6875 (0.7439)\n",
      "\u001b[32m[2020-06-22 17:35:42] __main__ INFO: \u001b[0mElapsed 32.74\n",
      "\u001b[32m[2020-06-22 17:35:42] __main__ INFO: \u001b[0mVal 119\n",
      "\u001b[32m[2020-06-22 17:35:43] __main__ INFO: \u001b[0mEpoch 119 loss 2.0551 acc@1 0.2926 acc@5 0.6952\n",
      "\u001b[32m[2020-06-22 17:35:43] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 17:35:43] __main__ INFO: \u001b[0mTrain 120 41769\n",
      "\u001b[32m[2020-06-22 17:35:52] __main__ INFO: \u001b[0mEpoch 120 Step 100/351 lr 0.010000 loss 1.5398 (1.5126) acc@1 0.4453 (0.4269) acc@5 0.7500 (0.7499)\n",
      "\u001b[32m[2020-06-22 17:36:01] __main__ INFO: \u001b[0mEpoch 120 Step 200/351 lr 0.010000 loss 1.7079 (1.5198) acc@1 0.3438 (0.4219) acc@5 0.6953 (0.7465)\n",
      "\u001b[32m[2020-06-22 17:36:11] __main__ INFO: \u001b[0mEpoch 120 Step 300/351 lr 0.010000 loss 1.5409 (1.5149) acc@1 0.4297 (0.4225) acc@5 0.6953 (0.7452)\n",
      "\u001b[32m[2020-06-22 17:36:16] __main__ INFO: \u001b[0mEpoch 120 Step 351/351 lr 0.010000 loss 1.7631 (1.5147) acc@1 0.3438 (0.4230) acc@5 0.7422 (0.7458)\n",
      "\u001b[32m[2020-06-22 17:36:16] __main__ INFO: \u001b[0mElapsed 32.75\n",
      "\u001b[32m[2020-06-22 17:36:16] __main__ INFO: \u001b[0mVal 120\n",
      "\u001b[32m[2020-06-22 17:36:17] __main__ INFO: \u001b[0mEpoch 120 loss 2.0844 acc@1 0.2866 acc@5 0.6904\n",
      "\u001b[32m[2020-06-22 17:36:17] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 17:36:17] __main__ INFO: \u001b[0mTrain 121 42120\n",
      "\u001b[32m[2020-06-22 17:36:26] __main__ INFO: \u001b[0mEpoch 121 Step 100/351 lr 0.001000 loss 1.5299 (1.4973) acc@1 0.3984 (0.4277) acc@5 0.7656 (0.7428)\n",
      "\u001b[32m[2020-06-22 17:36:35] __main__ INFO: \u001b[0mEpoch 121 Step 200/351 lr 0.001000 loss 1.3755 (1.4799) acc@1 0.4688 (0.4347) acc@5 0.7812 (0.7487)\n",
      "\u001b[32m[2020-06-22 17:36:45] __main__ INFO: \u001b[0mEpoch 121 Step 300/351 lr 0.001000 loss 1.4784 (1.4778) acc@1 0.3828 (0.4352) acc@5 0.7188 (0.7474)\n",
      "\u001b[32m[2020-06-22 17:36:49] __main__ INFO: \u001b[0mEpoch 121 Step 351/351 lr 0.001000 loss 1.4526 (1.4763) acc@1 0.4297 (0.4362) acc@5 0.7500 (0.7478)\n",
      "\u001b[32m[2020-06-22 17:36:49] __main__ INFO: \u001b[0mElapsed 32.78\n",
      "\u001b[32m[2020-06-22 17:36:49] __main__ INFO: \u001b[0mVal 121\n",
      "\u001b[32m[2020-06-22 17:36:50] __main__ INFO: \u001b[0mEpoch 121 loss 2.0720 acc@1 0.2998 acc@5 0.6964\n",
      "\u001b[32m[2020-06-22 17:36:50] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 17:36:50] __main__ INFO: \u001b[0mTrain 122 42471\n",
      "\u001b[32m[2020-06-22 17:37:00] __main__ INFO: \u001b[0mEpoch 122 Step 100/351 lr 0.001000 loss 1.5064 (1.4587) acc@1 0.4531 (0.4469) acc@5 0.7969 (0.7465)\n",
      "\u001b[32m[2020-06-22 17:37:09] __main__ INFO: \u001b[0mEpoch 122 Step 200/351 lr 0.001000 loss 1.4765 (1.4522) acc@1 0.4453 (0.4458) acc@5 0.7188 (0.7514)\n",
      "\u001b[32m[2020-06-22 17:37:18] __main__ INFO: \u001b[0mEpoch 122 Step 300/351 lr 0.001000 loss 1.4153 (1.4572) acc@1 0.4688 (0.4460) acc@5 0.7422 (0.7510)\n",
      "\u001b[32m[2020-06-22 17:37:23] __main__ INFO: \u001b[0mEpoch 122 Step 351/351 lr 0.001000 loss 1.4888 (1.4600) acc@1 0.4219 (0.4444) acc@5 0.7891 (0.7505)\n",
      "\u001b[32m[2020-06-22 17:37:23] __main__ INFO: \u001b[0mElapsed 32.82\n",
      "\u001b[32m[2020-06-22 17:37:23] __main__ INFO: \u001b[0mVal 122\n",
      "\u001b[32m[2020-06-22 17:37:24] __main__ INFO: \u001b[0mEpoch 122 loss 2.0716 acc@1 0.3008 acc@5 0.7040\n",
      "\u001b[32m[2020-06-22 17:37:24] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 17:37:24] __main__ INFO: \u001b[0mTrain 123 42822\n",
      "\u001b[32m[2020-06-22 17:37:34] __main__ INFO: \u001b[0mEpoch 123 Step 100/351 lr 0.001000 loss 1.4540 (1.4541) acc@1 0.5078 (0.4502) acc@5 0.7969 (0.7492)\n",
      "\u001b[32m[2020-06-22 17:37:43] __main__ INFO: \u001b[0mEpoch 123 Step 200/351 lr 0.001000 loss 1.2572 (1.4499) acc@1 0.5234 (0.4504) acc@5 0.8125 (0.7518)\n",
      "\u001b[32m[2020-06-22 17:37:52] __main__ INFO: \u001b[0mEpoch 123 Step 300/351 lr 0.001000 loss 1.3475 (1.4478) acc@1 0.4297 (0.4494) acc@5 0.7656 (0.7512)\n",
      "\u001b[32m[2020-06-22 17:37:57] __main__ INFO: \u001b[0mEpoch 123 Step 351/351 lr 0.001000 loss 1.3721 (1.4463) acc@1 0.4688 (0.4494) acc@5 0.7734 (0.7521)\n",
      "\u001b[32m[2020-06-22 17:37:57] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 17:37:57] __main__ INFO: \u001b[0mVal 123\n",
      "\u001b[32m[2020-06-22 17:37:58] __main__ INFO: \u001b[0mEpoch 123 loss 2.0657 acc@1 0.3000 acc@5 0.7012\n",
      "\u001b[32m[2020-06-22 17:37:58] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 17:37:58] __main__ INFO: \u001b[0mTrain 124 43173\n",
      "\u001b[32m[2020-06-22 17:38:08] __main__ INFO: \u001b[0mEpoch 124 Step 100/351 lr 0.001000 loss 1.1603 (1.4376) acc@1 0.5391 (0.4511) acc@5 0.7812 (0.7493)\n",
      "\u001b[32m[2020-06-22 17:38:17] __main__ INFO: \u001b[0mEpoch 124 Step 200/351 lr 0.001000 loss 1.4914 (1.4424) acc@1 0.3984 (0.4502) acc@5 0.7188 (0.7496)\n",
      "\u001b[32m[2020-06-22 17:38:26] __main__ INFO: \u001b[0mEpoch 124 Step 300/351 lr 0.001000 loss 1.4003 (1.4448) acc@1 0.4375 (0.4497) acc@5 0.7344 (0.7498)\n",
      "\u001b[32m[2020-06-22 17:38:31] __main__ INFO: \u001b[0mEpoch 124 Step 351/351 lr 0.001000 loss 1.3398 (1.4445) acc@1 0.4922 (0.4515) acc@5 0.8047 (0.7516)\n",
      "\u001b[32m[2020-06-22 17:38:31] __main__ INFO: \u001b[0mElapsed 32.78\n",
      "\u001b[32m[2020-06-22 17:38:31] __main__ INFO: \u001b[0mVal 124\n",
      "\u001b[32m[2020-06-22 17:38:32] __main__ INFO: \u001b[0mEpoch 124 loss 2.0795 acc@1 0.2924 acc@5 0.6978\n",
      "\u001b[32m[2020-06-22 17:38:32] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 17:38:32] __main__ INFO: \u001b[0mTrain 125 43524\n",
      "\u001b[32m[2020-06-22 17:38:41] __main__ INFO: \u001b[0mEpoch 125 Step 100/351 lr 0.001000 loss 1.4022 (1.4288) acc@1 0.4766 (0.4605) acc@5 0.7344 (0.7562)\n",
      "\u001b[32m[2020-06-22 17:38:51] __main__ INFO: \u001b[0mEpoch 125 Step 200/351 lr 0.001000 loss 1.4427 (1.4370) acc@1 0.4375 (0.4546) acc@5 0.7500 (0.7524)\n",
      "\u001b[32m[2020-06-22 17:39:00] __main__ INFO: \u001b[0mEpoch 125 Step 300/351 lr 0.001000 loss 1.3843 (1.4398) acc@1 0.4922 (0.4531) acc@5 0.7734 (0.7522)\n",
      "\u001b[32m[2020-06-22 17:39:05] __main__ INFO: \u001b[0mEpoch 125 Step 351/351 lr 0.001000 loss 1.3807 (1.4404) acc@1 0.5000 (0.4522) acc@5 0.7734 (0.7516)\n",
      "\u001b[32m[2020-06-22 17:39:05] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 17:39:05] __main__ INFO: \u001b[0mVal 125\n",
      "\u001b[32m[2020-06-22 17:39:06] __main__ INFO: \u001b[0mEpoch 125 loss 2.0884 acc@1 0.2996 acc@5 0.6982\n",
      "\u001b[32m[2020-06-22 17:39:06] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 17:39:06] __main__ INFO: \u001b[0mTrain 126 43875\n",
      "\u001b[32m[2020-06-22 17:39:15] __main__ INFO: \u001b[0mEpoch 126 Step 100/351 lr 0.001000 loss 1.4304 (1.4434) acc@1 0.4688 (0.4514) acc@5 0.7812 (0.7556)\n",
      "\u001b[32m[2020-06-22 17:39:25] __main__ INFO: \u001b[0mEpoch 126 Step 200/351 lr 0.001000 loss 1.4570 (1.4390) acc@1 0.4062 (0.4535) acc@5 0.7266 (0.7532)\n",
      "\u001b[32m[2020-06-22 17:39:34] __main__ INFO: \u001b[0mEpoch 126 Step 300/351 lr 0.001000 loss 1.5179 (1.4409) acc@1 0.4062 (0.4524) acc@5 0.7734 (0.7511)\n",
      "\u001b[32m[2020-06-22 17:39:39] __main__ INFO: \u001b[0mEpoch 126 Step 351/351 lr 0.001000 loss 1.4442 (1.4398) acc@1 0.4297 (0.4523) acc@5 0.7578 (0.7520)\n",
      "\u001b[32m[2020-06-22 17:39:39] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 17:39:39] __main__ INFO: \u001b[0mVal 126\n",
      "\u001b[32m[2020-06-22 17:39:40] __main__ INFO: \u001b[0mEpoch 126 loss 2.0879 acc@1 0.2950 acc@5 0.7090\n",
      "\u001b[32m[2020-06-22 17:39:40] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 17:39:40] __main__ INFO: \u001b[0mTrain 127 44226\n",
      "\u001b[32m[2020-06-22 17:39:49] __main__ INFO: \u001b[0mEpoch 127 Step 100/351 lr 0.001000 loss 1.4789 (1.4411) acc@1 0.4688 (0.4527) acc@5 0.7500 (0.7492)\n",
      "\u001b[32m[2020-06-22 17:39:58] __main__ INFO: \u001b[0mEpoch 127 Step 200/351 lr 0.001000 loss 1.4010 (1.4362) acc@1 0.4453 (0.4553) acc@5 0.7734 (0.7509)\n",
      "\u001b[32m[2020-06-22 17:40:08] __main__ INFO: \u001b[0mEpoch 127 Step 300/351 lr 0.001000 loss 1.5374 (1.4332) acc@1 0.3828 (0.4563) acc@5 0.7266 (0.7500)\n",
      "\u001b[32m[2020-06-22 17:40:13] __main__ INFO: \u001b[0mEpoch 127 Step 351/351 lr 0.001000 loss 1.4457 (1.4350) acc@1 0.4531 (0.4552) acc@5 0.7812 (0.7490)\n",
      "\u001b[32m[2020-06-22 17:40:13] __main__ INFO: \u001b[0mElapsed 32.88\n",
      "\u001b[32m[2020-06-22 17:40:13] __main__ INFO: \u001b[0mVal 127\n",
      "\u001b[32m[2020-06-22 17:40:14] __main__ INFO: \u001b[0mEpoch 127 loss 2.0946 acc@1 0.2994 acc@5 0.6976\n",
      "\u001b[32m[2020-06-22 17:40:14] __main__ INFO: \u001b[0mElapsed 1.03\n",
      "\u001b[32m[2020-06-22 17:40:14] __main__ INFO: \u001b[0mTrain 128 44577\n",
      "\u001b[32m[2020-06-22 17:40:23] __main__ INFO: \u001b[0mEpoch 128 Step 100/351 lr 0.001000 loss 1.2110 (1.4325) acc@1 0.5469 (0.4541) acc@5 0.7500 (0.7483)\n",
      "\u001b[32m[2020-06-22 17:40:32] __main__ INFO: \u001b[0mEpoch 128 Step 200/351 lr 0.001000 loss 1.4857 (1.4271) acc@1 0.4219 (0.4560) acc@5 0.7109 (0.7513)\n",
      "\u001b[32m[2020-06-22 17:40:42] __main__ INFO: \u001b[0mEpoch 128 Step 300/351 lr 0.001000 loss 1.4530 (1.4343) acc@1 0.4688 (0.4548) acc@5 0.7344 (0.7516)\n",
      "\u001b[32m[2020-06-22 17:40:46] __main__ INFO: \u001b[0mEpoch 128 Step 351/351 lr 0.001000 loss 1.3907 (1.4358) acc@1 0.4688 (0.4543) acc@5 0.7969 (0.7522)\n",
      "\u001b[32m[2020-06-22 17:40:46] __main__ INFO: \u001b[0mElapsed 32.75\n",
      "\u001b[32m[2020-06-22 17:40:46] __main__ INFO: \u001b[0mVal 128\n",
      "\u001b[32m[2020-06-22 17:40:47] __main__ INFO: \u001b[0mEpoch 128 loss 2.0972 acc@1 0.2954 acc@5 0.6976\n",
      "\u001b[32m[2020-06-22 17:40:47] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 17:40:47] __main__ INFO: \u001b[0mTrain 129 44928\n",
      "\u001b[32m[2020-06-22 17:40:57] __main__ INFO: \u001b[0mEpoch 129 Step 100/351 lr 0.001000 loss 1.5185 (1.4337) acc@1 0.4219 (0.4563) acc@5 0.6953 (0.7513)\n",
      "\u001b[32m[2020-06-22 17:41:06] __main__ INFO: \u001b[0mEpoch 129 Step 200/351 lr 0.001000 loss 1.4996 (1.4269) acc@1 0.4375 (0.4588) acc@5 0.7422 (0.7505)\n",
      "\u001b[32m[2020-06-22 17:41:15] __main__ INFO: \u001b[0mEpoch 129 Step 300/351 lr 0.001000 loss 1.6151 (1.4267) acc@1 0.3672 (0.4591) acc@5 0.7031 (0.7507)\n",
      "\u001b[32m[2020-06-22 17:41:20] __main__ INFO: \u001b[0mEpoch 129 Step 351/351 lr 0.001000 loss 1.5213 (1.4284) acc@1 0.4375 (0.4582) acc@5 0.7344 (0.7506)\n",
      "\u001b[32m[2020-06-22 17:41:20] __main__ INFO: \u001b[0mElapsed 32.77\n",
      "\u001b[32m[2020-06-22 17:41:20] __main__ INFO: \u001b[0mVal 129\n",
      "\u001b[32m[2020-06-22 17:41:21] __main__ INFO: \u001b[0mEpoch 129 loss 2.1153 acc@1 0.2878 acc@5 0.6960\n",
      "\u001b[32m[2020-06-22 17:41:21] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 17:41:21] __main__ INFO: \u001b[0mTrain 130 45279\n",
      "\u001b[32m[2020-06-22 17:41:31] __main__ INFO: \u001b[0mEpoch 130 Step 100/351 lr 0.001000 loss 1.4908 (1.4266) acc@1 0.4688 (0.4613) acc@5 0.7266 (0.7504)\n",
      "\u001b[32m[2020-06-22 17:41:40] __main__ INFO: \u001b[0mEpoch 130 Step 200/351 lr 0.001000 loss 1.4834 (1.4286) acc@1 0.4922 (0.4596) acc@5 0.7578 (0.7513)\n",
      "\u001b[32m[2020-06-22 17:41:49] __main__ INFO: \u001b[0mEpoch 130 Step 300/351 lr 0.001000 loss 1.4156 (1.4265) acc@1 0.4688 (0.4606) acc@5 0.7812 (0.7532)\n",
      "\u001b[32m[2020-06-22 17:41:54] __main__ INFO: \u001b[0mEpoch 130 Step 351/351 lr 0.001000 loss 1.4107 (1.4287) acc@1 0.4844 (0.4594) acc@5 0.7500 (0.7518)\n",
      "\u001b[32m[2020-06-22 17:41:54] __main__ INFO: \u001b[0mElapsed 32.83\n",
      "\u001b[32m[2020-06-22 17:41:54] __main__ INFO: \u001b[0mVal 130\n",
      "\u001b[32m[2020-06-22 17:41:55] __main__ INFO: \u001b[0mEpoch 130 loss 2.1143 acc@1 0.2932 acc@5 0.6964\n",
      "\u001b[32m[2020-06-22 17:41:55] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 17:41:55] __main__ INFO: \u001b[0mTrain 131 45630\n",
      "\u001b[32m[2020-06-22 17:42:05] __main__ INFO: \u001b[0mEpoch 131 Step 100/351 lr 0.001000 loss 1.5567 (1.4534) acc@1 0.4141 (0.4467) acc@5 0.7031 (0.7455)\n",
      "\u001b[32m[2020-06-22 17:42:14] __main__ INFO: \u001b[0mEpoch 131 Step 200/351 lr 0.001000 loss 1.2851 (1.4361) acc@1 0.5234 (0.4534) acc@5 0.7969 (0.7497)\n",
      "\u001b[32m[2020-06-22 17:42:23] __main__ INFO: \u001b[0mEpoch 131 Step 300/351 lr 0.001000 loss 1.4486 (1.4350) acc@1 0.4531 (0.4533) acc@5 0.7578 (0.7508)\n",
      "\u001b[32m[2020-06-22 17:42:28] __main__ INFO: \u001b[0mEpoch 131 Step 351/351 lr 0.001000 loss 1.5558 (1.4313) acc@1 0.4141 (0.4553) acc@5 0.7344 (0.7525)\n",
      "\u001b[32m[2020-06-22 17:42:28] __main__ INFO: \u001b[0mElapsed 32.81\n",
      "\u001b[32m[2020-06-22 17:42:28] __main__ INFO: \u001b[0mVal 131\n",
      "\u001b[32m[2020-06-22 17:42:29] __main__ INFO: \u001b[0mEpoch 131 loss 2.1081 acc@1 0.2962 acc@5 0.6992\n",
      "\u001b[32m[2020-06-22 17:42:29] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 17:42:29] __main__ INFO: \u001b[0mTrain 132 45981\n",
      "\u001b[32m[2020-06-22 17:42:38] __main__ INFO: \u001b[0mEpoch 132 Step 100/351 lr 0.001000 loss 1.5622 (1.4284) acc@1 0.4297 (0.4594) acc@5 0.7422 (0.7537)\n",
      "\u001b[32m[2020-06-22 17:42:48] __main__ INFO: \u001b[0mEpoch 132 Step 200/351 lr 0.001000 loss 1.3980 (1.4235) acc@1 0.4609 (0.4599) acc@5 0.7578 (0.7545)\n",
      "\u001b[32m[2020-06-22 17:42:57] __main__ INFO: \u001b[0mEpoch 132 Step 300/351 lr 0.001000 loss 1.5516 (1.4262) acc@1 0.3984 (0.4586) acc@5 0.7266 (0.7513)\n",
      "\u001b[32m[2020-06-22 17:43:02] __main__ INFO: \u001b[0mEpoch 132 Step 351/351 lr 0.001000 loss 1.3342 (1.4253) acc@1 0.4531 (0.4581) acc@5 0.8047 (0.7499)\n",
      "\u001b[32m[2020-06-22 17:43:02] __main__ INFO: \u001b[0mElapsed 32.86\n",
      "\u001b[32m[2020-06-22 17:43:02] __main__ INFO: \u001b[0mVal 132\n",
      "\u001b[32m[2020-06-22 17:43:03] __main__ INFO: \u001b[0mEpoch 132 loss 2.1202 acc@1 0.2902 acc@5 0.6936\n",
      "\u001b[32m[2020-06-22 17:43:03] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 17:43:03] __main__ INFO: \u001b[0mTrain 133 46332\n",
      "\u001b[32m[2020-06-22 17:43:12] __main__ INFO: \u001b[0mEpoch 133 Step 100/351 lr 0.001000 loss 1.3748 (1.4301) acc@1 0.4062 (0.4524) acc@5 0.7266 (0.7438)\n",
      "\u001b[32m[2020-06-22 17:43:22] __main__ INFO: \u001b[0mEpoch 133 Step 200/351 lr 0.001000 loss 1.2960 (1.4190) acc@1 0.5078 (0.4566) acc@5 0.7266 (0.7486)\n",
      "\u001b[32m[2020-06-22 17:43:31] __main__ INFO: \u001b[0mEpoch 133 Step 300/351 lr 0.001000 loss 1.4402 (1.4209) acc@1 0.4453 (0.4556) acc@5 0.7812 (0.7488)\n",
      "\u001b[32m[2020-06-22 17:43:36] __main__ INFO: \u001b[0mEpoch 133 Step 351/351 lr 0.001000 loss 1.4316 (1.4220) acc@1 0.4297 (0.4559) acc@5 0.7266 (0.7480)\n",
      "\u001b[32m[2020-06-22 17:43:36] __main__ INFO: \u001b[0mElapsed 32.78\n",
      "\u001b[32m[2020-06-22 17:43:36] __main__ INFO: \u001b[0mVal 133\n",
      "\u001b[32m[2020-06-22 17:43:37] __main__ INFO: \u001b[0mEpoch 133 loss 2.1272 acc@1 0.2968 acc@5 0.6942\n",
      "\u001b[32m[2020-06-22 17:43:37] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 17:43:37] __main__ INFO: \u001b[0mTrain 134 46683\n",
      "\u001b[32m[2020-06-22 17:43:46] __main__ INFO: \u001b[0mEpoch 134 Step 100/351 lr 0.001000 loss 1.3177 (1.4341) acc@1 0.5156 (0.4521) acc@5 0.7734 (0.7431)\n",
      "\u001b[32m[2020-06-22 17:43:55] __main__ INFO: \u001b[0mEpoch 134 Step 200/351 lr 0.001000 loss 1.3114 (1.4188) acc@1 0.4844 (0.4593) acc@5 0.7812 (0.7518)\n",
      "\u001b[32m[2020-06-22 17:44:05] __main__ INFO: \u001b[0mEpoch 134 Step 300/351 lr 0.001000 loss 1.3821 (1.4193) acc@1 0.4531 (0.4593) acc@5 0.7344 (0.7514)\n",
      "\u001b[32m[2020-06-22 17:44:10] __main__ INFO: \u001b[0mEpoch 134 Step 351/351 lr 0.001000 loss 1.3618 (1.4218) acc@1 0.4922 (0.4581) acc@5 0.7578 (0.7514)\n",
      "\u001b[32m[2020-06-22 17:44:10] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 17:44:10] __main__ INFO: \u001b[0mVal 134\n",
      "\u001b[32m[2020-06-22 17:44:11] __main__ INFO: \u001b[0mEpoch 134 loss 2.1170 acc@1 0.2952 acc@5 0.6962\n",
      "\u001b[32m[2020-06-22 17:44:11] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 17:44:11] __main__ INFO: \u001b[0mTrain 135 47034\n",
      "\u001b[32m[2020-06-22 17:44:20] __main__ INFO: \u001b[0mEpoch 135 Step 100/351 lr 0.001000 loss 1.4200 (1.4168) acc@1 0.4375 (0.4631) acc@5 0.7500 (0.7449)\n",
      "\u001b[32m[2020-06-22 17:44:29] __main__ INFO: \u001b[0mEpoch 135 Step 200/351 lr 0.001000 loss 1.4801 (1.4211) acc@1 0.3984 (0.4600) acc@5 0.6953 (0.7441)\n",
      "\u001b[32m[2020-06-22 17:44:39] __main__ INFO: \u001b[0mEpoch 135 Step 300/351 lr 0.001000 loss 1.3833 (1.4182) acc@1 0.5000 (0.4605) acc@5 0.7891 (0.7476)\n",
      "\u001b[32m[2020-06-22 17:44:43] __main__ INFO: \u001b[0mEpoch 135 Step 351/351 lr 0.001000 loss 1.3869 (1.4191) acc@1 0.4375 (0.4602) acc@5 0.8047 (0.7472)\n",
      "\u001b[32m[2020-06-22 17:44:43] __main__ INFO: \u001b[0mElapsed 32.82\n",
      "\u001b[32m[2020-06-22 17:44:43] __main__ INFO: \u001b[0mVal 135\n",
      "\u001b[32m[2020-06-22 17:44:44] __main__ INFO: \u001b[0mEpoch 135 loss 2.1299 acc@1 0.2956 acc@5 0.7038\n",
      "\u001b[32m[2020-06-22 17:44:44] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 17:44:44] __main__ INFO: \u001b[0mTrain 136 47385\n",
      "\u001b[32m[2020-06-22 17:44:54] __main__ INFO: \u001b[0mEpoch 136 Step 100/351 lr 0.001000 loss 1.2938 (1.4185) acc@1 0.5234 (0.4595) acc@5 0.7812 (0.7549)\n",
      "\u001b[32m[2020-06-22 17:45:03] __main__ INFO: \u001b[0mEpoch 136 Step 200/351 lr 0.001000 loss 1.4320 (1.4176) acc@1 0.4531 (0.4604) acc@5 0.7969 (0.7534)\n",
      "\u001b[32m[2020-06-22 17:45:12] __main__ INFO: \u001b[0mEpoch 136 Step 300/351 lr 0.001000 loss 1.3578 (1.4151) acc@1 0.4688 (0.4606) acc@5 0.7891 (0.7521)\n",
      "\u001b[32m[2020-06-22 17:45:17] __main__ INFO: \u001b[0mEpoch 136 Step 351/351 lr 0.001000 loss 1.3065 (1.4152) acc@1 0.5391 (0.4598) acc@5 0.7812 (0.7519)\n",
      "\u001b[32m[2020-06-22 17:45:17] __main__ INFO: \u001b[0mElapsed 32.77\n",
      "\u001b[32m[2020-06-22 17:45:17] __main__ INFO: \u001b[0mVal 136\n",
      "\u001b[32m[2020-06-22 17:45:18] __main__ INFO: \u001b[0mEpoch 136 loss 2.1285 acc@1 0.2996 acc@5 0.6904\n",
      "\u001b[32m[2020-06-22 17:45:18] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 17:45:18] __main__ INFO: \u001b[0mTrain 137 47736\n",
      "\u001b[32m[2020-06-22 17:45:28] __main__ INFO: \u001b[0mEpoch 137 Step 100/351 lr 0.001000 loss 1.5328 (1.3976) acc@1 0.4062 (0.4715) acc@5 0.6484 (0.7535)\n",
      "\u001b[32m[2020-06-22 17:45:37] __main__ INFO: \u001b[0mEpoch 137 Step 200/351 lr 0.001000 loss 1.3635 (1.4092) acc@1 0.4609 (0.4651) acc@5 0.7734 (0.7516)\n",
      "\u001b[32m[2020-06-22 17:45:46] __main__ INFO: \u001b[0mEpoch 137 Step 300/351 lr 0.001000 loss 1.4384 (1.4141) acc@1 0.4375 (0.4616) acc@5 0.7500 (0.7503)\n",
      "\u001b[32m[2020-06-22 17:45:51] __main__ INFO: \u001b[0mEpoch 137 Step 351/351 lr 0.001000 loss 1.4239 (1.4158) acc@1 0.4766 (0.4620) acc@5 0.7500 (0.7501)\n",
      "\u001b[32m[2020-06-22 17:45:51] __main__ INFO: \u001b[0mElapsed 32.88\n",
      "\u001b[32m[2020-06-22 17:45:51] __main__ INFO: \u001b[0mVal 137\n",
      "\u001b[32m[2020-06-22 17:45:52] __main__ INFO: \u001b[0mEpoch 137 loss 2.1405 acc@1 0.2944 acc@5 0.6966\n",
      "\u001b[32m[2020-06-22 17:45:52] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 17:45:52] __main__ INFO: \u001b[0mTrain 138 48087\n",
      "\u001b[32m[2020-06-22 17:46:02] __main__ INFO: \u001b[0mEpoch 138 Step 100/351 lr 0.001000 loss 1.2812 (1.4116) acc@1 0.5078 (0.4639) acc@5 0.7969 (0.7534)\n",
      "\u001b[32m[2020-06-22 17:46:11] __main__ INFO: \u001b[0mEpoch 138 Step 200/351 lr 0.001000 loss 1.3405 (1.4144) acc@1 0.5547 (0.4628) acc@5 0.7656 (0.7521)\n",
      "\u001b[32m[2020-06-22 17:46:20] __main__ INFO: \u001b[0mEpoch 138 Step 300/351 lr 0.001000 loss 1.4277 (1.4146) acc@1 0.4609 (0.4620) acc@5 0.7266 (0.7517)\n",
      "\u001b[32m[2020-06-22 17:46:25] __main__ INFO: \u001b[0mEpoch 138 Step 351/351 lr 0.001000 loss 1.4416 (1.4145) acc@1 0.4531 (0.4623) acc@5 0.7422 (0.7515)\n",
      "\u001b[32m[2020-06-22 17:46:25] __main__ INFO: \u001b[0mElapsed 32.81\n",
      "\u001b[32m[2020-06-22 17:46:25] __main__ INFO: \u001b[0mVal 138\n",
      "\u001b[32m[2020-06-22 17:46:26] __main__ INFO: \u001b[0mEpoch 138 loss 2.1515 acc@1 0.2960 acc@5 0.7030\n",
      "\u001b[32m[2020-06-22 17:46:26] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 17:46:26] __main__ INFO: \u001b[0mTrain 139 48438\n",
      "\u001b[32m[2020-06-22 17:46:36] __main__ INFO: \u001b[0mEpoch 139 Step 100/351 lr 0.001000 loss 1.4585 (1.4123) acc@1 0.4141 (0.4615) acc@5 0.7578 (0.7499)\n",
      "\u001b[32m[2020-06-22 17:46:45] __main__ INFO: \u001b[0mEpoch 139 Step 200/351 lr 0.001000 loss 1.3266 (1.4181) acc@1 0.5156 (0.4588) acc@5 0.7422 (0.7515)\n",
      "\u001b[32m[2020-06-22 17:46:54] __main__ INFO: \u001b[0mEpoch 139 Step 300/351 lr 0.001000 loss 1.3078 (1.4156) acc@1 0.4844 (0.4591) acc@5 0.7422 (0.7513)\n",
      "\u001b[32m[2020-06-22 17:46:59] __main__ INFO: \u001b[0mEpoch 139 Step 351/351 lr 0.001000 loss 1.3201 (1.4148) acc@1 0.5156 (0.4598) acc@5 0.7344 (0.7519)\n",
      "\u001b[32m[2020-06-22 17:46:59] __main__ INFO: \u001b[0mElapsed 32.78\n",
      "\u001b[32m[2020-06-22 17:46:59] __main__ INFO: \u001b[0mVal 139\n",
      "\u001b[32m[2020-06-22 17:47:00] __main__ INFO: \u001b[0mEpoch 139 loss 2.1524 acc@1 0.2954 acc@5 0.7092\n",
      "\u001b[32m[2020-06-22 17:47:00] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 17:47:00] __main__ INFO: \u001b[0mTrain 140 48789\n",
      "\u001b[32m[2020-06-22 17:47:09] __main__ INFO: \u001b[0mEpoch 140 Step 100/351 lr 0.001000 loss 1.3825 (1.3957) acc@1 0.5000 (0.4660) acc@5 0.7734 (0.7542)\n",
      "\u001b[32m[2020-06-22 17:47:19] __main__ INFO: \u001b[0mEpoch 140 Step 200/351 lr 0.001000 loss 1.5500 (1.3984) acc@1 0.3828 (0.4661) acc@5 0.7188 (0.7550)\n",
      "\u001b[32m[2020-06-22 17:47:28] __main__ INFO: \u001b[0mEpoch 140 Step 300/351 lr 0.001000 loss 1.5417 (1.4054) acc@1 0.4375 (0.4649) acc@5 0.7109 (0.7545)\n",
      "\u001b[32m[2020-06-22 17:47:33] __main__ INFO: \u001b[0mEpoch 140 Step 351/351 lr 0.001000 loss 1.4949 (1.4068) acc@1 0.3828 (0.4639) acc@5 0.6797 (0.7541)\n",
      "\u001b[32m[2020-06-22 17:47:33] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 17:47:33] __main__ INFO: \u001b[0mVal 140\n",
      "\u001b[32m[2020-06-22 17:47:34] __main__ INFO: \u001b[0mEpoch 140 loss 2.1640 acc@1 0.2968 acc@5 0.7066\n",
      "\u001b[32m[2020-06-22 17:47:34] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 17:47:34] __main__ INFO: \u001b[0mTrain 141 49140\n",
      "\u001b[32m[2020-06-22 17:47:43] __main__ INFO: \u001b[0mEpoch 141 Step 100/351 lr 0.001000 loss 1.3299 (1.4050) acc@1 0.4766 (0.4680) acc@5 0.8203 (0.7548)\n",
      "\u001b[32m[2020-06-22 17:47:53] __main__ INFO: \u001b[0mEpoch 141 Step 200/351 lr 0.001000 loss 1.5057 (1.4091) acc@1 0.4297 (0.4650) acc@5 0.7578 (0.7519)\n",
      "\u001b[32m[2020-06-22 17:48:02] __main__ INFO: \u001b[0mEpoch 141 Step 300/351 lr 0.001000 loss 1.4911 (1.4139) acc@1 0.4453 (0.4626) acc@5 0.7188 (0.7493)\n",
      "\u001b[32m[2020-06-22 17:48:07] __main__ INFO: \u001b[0mEpoch 141 Step 351/351 lr 0.001000 loss 1.4633 (1.4106) acc@1 0.4141 (0.4645) acc@5 0.7344 (0.7512)\n",
      "\u001b[32m[2020-06-22 17:48:07] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 17:48:07] __main__ INFO: \u001b[0mVal 141\n",
      "\u001b[32m[2020-06-22 17:48:08] __main__ INFO: \u001b[0mEpoch 141 loss 2.1547 acc@1 0.2978 acc@5 0.6912\n",
      "\u001b[32m[2020-06-22 17:48:08] __main__ INFO: \u001b[0mElapsed 1.03\n",
      "\u001b[32m[2020-06-22 17:48:08] __main__ INFO: \u001b[0mTrain 142 49491\n",
      "\u001b[32m[2020-06-22 17:48:17] __main__ INFO: \u001b[0mEpoch 142 Step 100/351 lr 0.001000 loss 1.3506 (1.4133) acc@1 0.5156 (0.4636) acc@5 0.7969 (0.7532)\n",
      "\u001b[32m[2020-06-22 17:48:26] __main__ INFO: \u001b[0mEpoch 142 Step 200/351 lr 0.001000 loss 1.4776 (1.4157) acc@1 0.4062 (0.4601) acc@5 0.6875 (0.7513)\n",
      "\u001b[32m[2020-06-22 17:48:36] __main__ INFO: \u001b[0mEpoch 142 Step 300/351 lr 0.001000 loss 1.3931 (1.4164) acc@1 0.4141 (0.4589) acc@5 0.7578 (0.7492)\n",
      "\u001b[32m[2020-06-22 17:48:40] __main__ INFO: \u001b[0mEpoch 142 Step 351/351 lr 0.001000 loss 1.4990 (1.4140) acc@1 0.4062 (0.4599) acc@5 0.7031 (0.7507)\n",
      "\u001b[32m[2020-06-22 17:48:40] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 17:48:40] __main__ INFO: \u001b[0mVal 142\n",
      "\u001b[32m[2020-06-22 17:48:42] __main__ INFO: \u001b[0mEpoch 142 loss 2.1337 acc@1 0.2980 acc@5 0.7002\n",
      "\u001b[32m[2020-06-22 17:48:42] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 17:48:42] __main__ INFO: \u001b[0mTrain 143 49842\n",
      "\u001b[32m[2020-06-22 17:48:51] __main__ INFO: \u001b[0mEpoch 143 Step 100/351 lr 0.001000 loss 1.5345 (1.4123) acc@1 0.3984 (0.4631) acc@5 0.7266 (0.7448)\n",
      "\u001b[32m[2020-06-22 17:49:00] __main__ INFO: \u001b[0mEpoch 143 Step 200/351 lr 0.001000 loss 1.3203 (1.4066) acc@1 0.5078 (0.4659) acc@5 0.7891 (0.7491)\n",
      "\u001b[32m[2020-06-22 17:49:10] __main__ INFO: \u001b[0mEpoch 143 Step 300/351 lr 0.001000 loss 1.3977 (1.4085) acc@1 0.4453 (0.4638) acc@5 0.7109 (0.7502)\n",
      "\u001b[32m[2020-06-22 17:49:14] __main__ INFO: \u001b[0mEpoch 143 Step 351/351 lr 0.001000 loss 1.4670 (1.4084) acc@1 0.3984 (0.4637) acc@5 0.6953 (0.7508)\n",
      "\u001b[32m[2020-06-22 17:49:14] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 17:49:14] __main__ INFO: \u001b[0mVal 143\n",
      "\u001b[32m[2020-06-22 17:49:15] __main__ INFO: \u001b[0mEpoch 143 loss 2.1510 acc@1 0.2970 acc@5 0.6956\n",
      "\u001b[32m[2020-06-22 17:49:15] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 17:49:15] __main__ INFO: \u001b[0mTrain 144 50193\n",
      "\u001b[32m[2020-06-22 17:49:25] __main__ INFO: \u001b[0mEpoch 144 Step 100/351 lr 0.001000 loss 1.4868 (1.4026) acc@1 0.4453 (0.4683) acc@5 0.7266 (0.7591)\n",
      "\u001b[32m[2020-06-22 17:49:34] __main__ INFO: \u001b[0mEpoch 144 Step 200/351 lr 0.001000 loss 1.4126 (1.4021) acc@1 0.4531 (0.4654) acc@5 0.7500 (0.7569)\n",
      "\u001b[32m[2020-06-22 17:49:43] __main__ INFO: \u001b[0mEpoch 144 Step 300/351 lr 0.001000 loss 1.4414 (1.4074) acc@1 0.4453 (0.4635) acc@5 0.7422 (0.7539)\n",
      "\u001b[32m[2020-06-22 17:49:48] __main__ INFO: \u001b[0mEpoch 144 Step 351/351 lr 0.001000 loss 1.4463 (1.4069) acc@1 0.4531 (0.4635) acc@5 0.7969 (0.7525)\n",
      "\u001b[32m[2020-06-22 17:49:48] __main__ INFO: \u001b[0mElapsed 32.77\n",
      "\u001b[32m[2020-06-22 17:49:48] __main__ INFO: \u001b[0mVal 144\n",
      "\u001b[32m[2020-06-22 17:49:49] __main__ INFO: \u001b[0mEpoch 144 loss 2.1537 acc@1 0.2956 acc@5 0.6978\n",
      "\u001b[32m[2020-06-22 17:49:49] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 17:49:49] __main__ INFO: \u001b[0mTrain 145 50544\n",
      "\u001b[32m[2020-06-22 17:49:59] __main__ INFO: \u001b[0mEpoch 145 Step 100/351 lr 0.001000 loss 1.3559 (1.4098) acc@1 0.4688 (0.4645) acc@5 0.7812 (0.7544)\n",
      "\u001b[32m[2020-06-22 17:50:08] __main__ INFO: \u001b[0mEpoch 145 Step 200/351 lr 0.001000 loss 1.2596 (1.4054) acc@1 0.5156 (0.4644) acc@5 0.7266 (0.7542)\n",
      "\u001b[32m[2020-06-22 17:50:17] __main__ INFO: \u001b[0mEpoch 145 Step 300/351 lr 0.001000 loss 1.4590 (1.4070) acc@1 0.4609 (0.4634) acc@5 0.7109 (0.7537)\n",
      "\u001b[32m[2020-06-22 17:50:22] __main__ INFO: \u001b[0mEpoch 145 Step 351/351 lr 0.001000 loss 1.2901 (1.4059) acc@1 0.5000 (0.4638) acc@5 0.8125 (0.7538)\n",
      "\u001b[32m[2020-06-22 17:50:22] __main__ INFO: \u001b[0mElapsed 32.83\n",
      "\u001b[32m[2020-06-22 17:50:22] __main__ INFO: \u001b[0mVal 145\n",
      "\u001b[32m[2020-06-22 17:50:23] __main__ INFO: \u001b[0mEpoch 145 loss 2.1463 acc@1 0.2998 acc@5 0.6978\n",
      "\u001b[32m[2020-06-22 17:50:23] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 17:50:23] __main__ INFO: \u001b[0mTrain 146 50895\n",
      "\u001b[32m[2020-06-22 17:50:33] __main__ INFO: \u001b[0mEpoch 146 Step 100/351 lr 0.001000 loss 1.4209 (1.3984) acc@1 0.4531 (0.4684) acc@5 0.7656 (0.7576)\n",
      "\u001b[32m[2020-06-22 17:50:42] __main__ INFO: \u001b[0mEpoch 146 Step 200/351 lr 0.001000 loss 1.4447 (1.4015) acc@1 0.3984 (0.4642) acc@5 0.7812 (0.7585)\n",
      "\u001b[32m[2020-06-22 17:50:51] __main__ INFO: \u001b[0mEpoch 146 Step 300/351 lr 0.001000 loss 1.4494 (1.4023) acc@1 0.3984 (0.4627) acc@5 0.7344 (0.7561)\n",
      "\u001b[32m[2020-06-22 17:50:56] __main__ INFO: \u001b[0mEpoch 146 Step 351/351 lr 0.001000 loss 1.4186 (1.4032) acc@1 0.4375 (0.4624) acc@5 0.7500 (0.7551)\n",
      "\u001b[32m[2020-06-22 17:50:56] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 17:50:56] __main__ INFO: \u001b[0mVal 146\n",
      "\u001b[32m[2020-06-22 17:50:57] __main__ INFO: \u001b[0mEpoch 146 loss 2.1812 acc@1 0.2994 acc@5 0.6956\n",
      "\u001b[32m[2020-06-22 17:50:57] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 17:50:57] __main__ INFO: \u001b[0mTrain 147 51246\n",
      "\u001b[32m[2020-06-22 17:51:06] __main__ INFO: \u001b[0mEpoch 147 Step 100/351 lr 0.001000 loss 1.2941 (1.3966) acc@1 0.5469 (0.4706) acc@5 0.7969 (0.7503)\n",
      "\u001b[32m[2020-06-22 17:51:16] __main__ INFO: \u001b[0mEpoch 147 Step 200/351 lr 0.001000 loss 1.4535 (1.3991) acc@1 0.4297 (0.4703) acc@5 0.7500 (0.7525)\n",
      "\u001b[32m[2020-06-22 17:51:25] __main__ INFO: \u001b[0mEpoch 147 Step 300/351 lr 0.001000 loss 1.3211 (1.4009) acc@1 0.4766 (0.4677) acc@5 0.7656 (0.7536)\n",
      "\u001b[32m[2020-06-22 17:51:30] __main__ INFO: \u001b[0mEpoch 147 Step 351/351 lr 0.001000 loss 1.4293 (1.4038) acc@1 0.4297 (0.4661) acc@5 0.6719 (0.7528)\n",
      "\u001b[32m[2020-06-22 17:51:30] __main__ INFO: \u001b[0mElapsed 32.77\n",
      "\u001b[32m[2020-06-22 17:51:30] __main__ INFO: \u001b[0mVal 147\n",
      "\u001b[32m[2020-06-22 17:51:31] __main__ INFO: \u001b[0mEpoch 147 loss 2.1901 acc@1 0.2978 acc@5 0.7006\n",
      "\u001b[32m[2020-06-22 17:51:31] __main__ INFO: \u001b[0mElapsed 1.11\n",
      "\u001b[32m[2020-06-22 17:51:31] __main__ INFO: \u001b[0mTrain 148 51597\n",
      "\u001b[32m[2020-06-22 17:51:40] __main__ INFO: \u001b[0mEpoch 148 Step 100/351 lr 0.001000 loss 1.4376 (1.3937) acc@1 0.4375 (0.4692) acc@5 0.6797 (0.7536)\n",
      "\u001b[32m[2020-06-22 17:51:50] __main__ INFO: \u001b[0mEpoch 148 Step 200/351 lr 0.001000 loss 1.3221 (1.4011) acc@1 0.5156 (0.4673) acc@5 0.7812 (0.7547)\n",
      "\u001b[32m[2020-06-22 17:51:59] __main__ INFO: \u001b[0mEpoch 148 Step 300/351 lr 0.001000 loss 1.5464 (1.4021) acc@1 0.4375 (0.4668) acc@5 0.6797 (0.7549)\n",
      "\u001b[32m[2020-06-22 17:52:04] __main__ INFO: \u001b[0mEpoch 148 Step 351/351 lr 0.001000 loss 1.5178 (1.4029) acc@1 0.3828 (0.4661) acc@5 0.6562 (0.7532)\n",
      "\u001b[32m[2020-06-22 17:52:04] __main__ INFO: \u001b[0mElapsed 32.81\n",
      "\u001b[32m[2020-06-22 17:52:04] __main__ INFO: \u001b[0mVal 148\n",
      "\u001b[32m[2020-06-22 17:52:05] __main__ INFO: \u001b[0mEpoch 148 loss 2.1970 acc@1 0.2984 acc@5 0.6976\n",
      "\u001b[32m[2020-06-22 17:52:05] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 17:52:05] __main__ INFO: \u001b[0mTrain 149 51948\n",
      "\u001b[32m[2020-06-22 17:52:14] __main__ INFO: \u001b[0mEpoch 149 Step 100/351 lr 0.001000 loss 1.3729 (1.3950) acc@1 0.4688 (0.4658) acc@5 0.7266 (0.7499)\n",
      "\u001b[32m[2020-06-22 17:52:23] __main__ INFO: \u001b[0mEpoch 149 Step 200/351 lr 0.001000 loss 1.3882 (1.3958) acc@1 0.4688 (0.4650) acc@5 0.7734 (0.7497)\n",
      "\u001b[32m[2020-06-22 17:52:33] __main__ INFO: \u001b[0mEpoch 149 Step 300/351 lr 0.001000 loss 1.5062 (1.3973) acc@1 0.4219 (0.4646) acc@5 0.6797 (0.7508)\n",
      "\u001b[32m[2020-06-22 17:52:37] __main__ INFO: \u001b[0mEpoch 149 Step 351/351 lr 0.001000 loss 1.2394 (1.3959) acc@1 0.5312 (0.4651) acc@5 0.7812 (0.7526)\n",
      "\u001b[32m[2020-06-22 17:52:37] __main__ INFO: \u001b[0mElapsed 32.75\n",
      "\u001b[32m[2020-06-22 17:52:37] __main__ INFO: \u001b[0mVal 149\n",
      "\u001b[32m[2020-06-22 17:52:39] __main__ INFO: \u001b[0mEpoch 149 loss 2.1871 acc@1 0.2978 acc@5 0.6958\n",
      "\u001b[32m[2020-06-22 17:52:39] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 17:52:39] __main__ INFO: \u001b[0mTrain 150 52299\n",
      "\u001b[32m[2020-06-22 17:52:48] __main__ INFO: \u001b[0mEpoch 150 Step 100/351 lr 0.001000 loss 1.3544 (1.4056) acc@1 0.4609 (0.4622) acc@5 0.7188 (0.7455)\n",
      "\u001b[32m[2020-06-22 17:52:57] __main__ INFO: \u001b[0mEpoch 150 Step 200/351 lr 0.001000 loss 1.4262 (1.3982) acc@1 0.4609 (0.4657) acc@5 0.7266 (0.7488)\n",
      "\u001b[32m[2020-06-22 17:53:07] __main__ INFO: \u001b[0mEpoch 150 Step 300/351 lr 0.001000 loss 1.4905 (1.3988) acc@1 0.4688 (0.4657) acc@5 0.6406 (0.7511)\n",
      "\u001b[32m[2020-06-22 17:53:11] __main__ INFO: \u001b[0mEpoch 150 Step 351/351 lr 0.001000 loss 1.3852 (1.4015) acc@1 0.4688 (0.4651) acc@5 0.6953 (0.7509)\n",
      "\u001b[32m[2020-06-22 17:53:11] __main__ INFO: \u001b[0mElapsed 32.78\n",
      "\u001b[32m[2020-06-22 17:53:11] __main__ INFO: \u001b[0mVal 150\n",
      "\u001b[32m[2020-06-22 17:53:12] __main__ INFO: \u001b[0mEpoch 150 loss 2.1882 acc@1 0.2940 acc@5 0.6952\n",
      "\u001b[32m[2020-06-22 17:53:12] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 17:53:12] __main__ INFO: \u001b[0mTrain 151 52650\n",
      "\u001b[32m[2020-06-22 17:53:22] __main__ INFO: \u001b[0mEpoch 151 Step 100/351 lr 0.001000 loss 1.2645 (1.3986) acc@1 0.5000 (0.4672) acc@5 0.7422 (0.7555)\n",
      "\u001b[32m[2020-06-22 17:53:31] __main__ INFO: \u001b[0mEpoch 151 Step 200/351 lr 0.001000 loss 1.4127 (1.3986) acc@1 0.4453 (0.4662) acc@5 0.7578 (0.7545)\n",
      "\u001b[32m[2020-06-22 17:53:40] __main__ INFO: \u001b[0mEpoch 151 Step 300/351 lr 0.001000 loss 1.5319 (1.3975) acc@1 0.3984 (0.4671) acc@5 0.7266 (0.7531)\n",
      "\u001b[32m[2020-06-22 17:53:45] __main__ INFO: \u001b[0mEpoch 151 Step 351/351 lr 0.001000 loss 1.2040 (1.3991) acc@1 0.5312 (0.4665) acc@5 0.7578 (0.7525)\n",
      "\u001b[32m[2020-06-22 17:53:45] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 17:53:45] __main__ INFO: \u001b[0mVal 151\n",
      "\u001b[32m[2020-06-22 17:53:46] __main__ INFO: \u001b[0mEpoch 151 loss 2.1952 acc@1 0.2996 acc@5 0.7004\n",
      "\u001b[32m[2020-06-22 17:53:46] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 17:53:46] __main__ INFO: \u001b[0mTrain 152 53001\n",
      "\u001b[32m[2020-06-22 17:53:56] __main__ INFO: \u001b[0mEpoch 152 Step 100/351 lr 0.001000 loss 1.2855 (1.3814) acc@1 0.5000 (0.4737) acc@5 0.7891 (0.7573)\n",
      "\u001b[32m[2020-06-22 17:54:05] __main__ INFO: \u001b[0mEpoch 152 Step 200/351 lr 0.001000 loss 1.2820 (1.3912) acc@1 0.4766 (0.4679) acc@5 0.7422 (0.7541)\n",
      "\u001b[32m[2020-06-22 17:54:14] __main__ INFO: \u001b[0mEpoch 152 Step 300/351 lr 0.001000 loss 1.5318 (1.3955) acc@1 0.3906 (0.4673) acc@5 0.7188 (0.7533)\n",
      "\u001b[32m[2020-06-22 17:54:19] __main__ INFO: \u001b[0mEpoch 152 Step 351/351 lr 0.001000 loss 1.3937 (1.3989) acc@1 0.4766 (0.4655) acc@5 0.7578 (0.7524)\n",
      "\u001b[32m[2020-06-22 17:54:19] __main__ INFO: \u001b[0mElapsed 32.76\n",
      "\u001b[32m[2020-06-22 17:54:19] __main__ INFO: \u001b[0mVal 152\n",
      "\u001b[32m[2020-06-22 17:54:20] __main__ INFO: \u001b[0mEpoch 152 loss 2.1928 acc@1 0.2944 acc@5 0.6894\n",
      "\u001b[32m[2020-06-22 17:54:20] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 17:54:20] __main__ INFO: \u001b[0mTrain 153 53352\n",
      "\u001b[32m[2020-06-22 17:54:29] __main__ INFO: \u001b[0mEpoch 153 Step 100/351 lr 0.001000 loss 1.3090 (1.3889) acc@1 0.5391 (0.4658) acc@5 0.7734 (0.7556)\n",
      "\u001b[32m[2020-06-22 17:54:39] __main__ INFO: \u001b[0mEpoch 153 Step 200/351 lr 0.001000 loss 1.3457 (1.3914) acc@1 0.4453 (0.4647) acc@5 0.7500 (0.7532)\n",
      "\u001b[32m[2020-06-22 17:54:48] __main__ INFO: \u001b[0mEpoch 153 Step 300/351 lr 0.001000 loss 1.5333 (1.3968) acc@1 0.4297 (0.4630) acc@5 0.7656 (0.7522)\n",
      "\u001b[32m[2020-06-22 17:54:53] __main__ INFO: \u001b[0mEpoch 153 Step 351/351 lr 0.001000 loss 1.3135 (1.3955) acc@1 0.4844 (0.4645) acc@5 0.7188 (0.7531)\n",
      "\u001b[32m[2020-06-22 17:54:53] __main__ INFO: \u001b[0mElapsed 32.78\n",
      "\u001b[32m[2020-06-22 17:54:53] __main__ INFO: \u001b[0mVal 153\n",
      "\u001b[32m[2020-06-22 17:54:54] __main__ INFO: \u001b[0mEpoch 153 loss 2.2094 acc@1 0.2924 acc@5 0.6944\n",
      "\u001b[32m[2020-06-22 17:54:54] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 17:54:54] __main__ INFO: \u001b[0mTrain 154 53703\n",
      "\u001b[32m[2020-06-22 17:55:03] __main__ INFO: \u001b[0mEpoch 154 Step 100/351 lr 0.001000 loss 1.4391 (1.4007) acc@1 0.4531 (0.4642) acc@5 0.7500 (0.7511)\n",
      "\u001b[32m[2020-06-22 17:55:13] __main__ INFO: \u001b[0mEpoch 154 Step 200/351 lr 0.001000 loss 1.5086 (1.3953) acc@1 0.4141 (0.4664) acc@5 0.7344 (0.7540)\n",
      "\u001b[32m[2020-06-22 17:55:22] __main__ INFO: \u001b[0mEpoch 154 Step 300/351 lr 0.001000 loss 1.5186 (1.4009) acc@1 0.3984 (0.4653) acc@5 0.7891 (0.7517)\n",
      "\u001b[32m[2020-06-22 17:55:27] __main__ INFO: \u001b[0mEpoch 154 Step 351/351 lr 0.001000 loss 1.2203 (1.3981) acc@1 0.5156 (0.4659) acc@5 0.7578 (0.7537)\n",
      "\u001b[32m[2020-06-22 17:55:27] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 17:55:27] __main__ INFO: \u001b[0mVal 154\n",
      "\u001b[32m[2020-06-22 17:55:28] __main__ INFO: \u001b[0mEpoch 154 loss 2.1885 acc@1 0.2978 acc@5 0.6976\n",
      "\u001b[32m[2020-06-22 17:55:28] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 17:55:28] __main__ INFO: \u001b[0mTrain 155 54054\n",
      "\u001b[32m[2020-06-22 17:55:37] __main__ INFO: \u001b[0mEpoch 155 Step 100/351 lr 0.001000 loss 1.3122 (1.3856) acc@1 0.4922 (0.4730) acc@5 0.7500 (0.7558)\n",
      "\u001b[32m[2020-06-22 17:55:46] __main__ INFO: \u001b[0mEpoch 155 Step 200/351 lr 0.001000 loss 1.2566 (1.3891) acc@1 0.4922 (0.4690) acc@5 0.7656 (0.7537)\n",
      "\u001b[32m[2020-06-22 17:55:56] __main__ INFO: \u001b[0mEpoch 155 Step 300/351 lr 0.001000 loss 1.3127 (1.3893) acc@1 0.5625 (0.4691) acc@5 0.8281 (0.7539)\n",
      "\u001b[32m[2020-06-22 17:56:01] __main__ INFO: \u001b[0mEpoch 155 Step 351/351 lr 0.001000 loss 1.4393 (1.3897) acc@1 0.4766 (0.4689) acc@5 0.7812 (0.7541)\n",
      "\u001b[32m[2020-06-22 17:56:01] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 17:56:01] __main__ INFO: \u001b[0mVal 155\n",
      "\u001b[32m[2020-06-22 17:56:02] __main__ INFO: \u001b[0mEpoch 155 loss 2.1957 acc@1 0.2966 acc@5 0.6972\n",
      "\u001b[32m[2020-06-22 17:56:02] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 17:56:02] __main__ INFO: \u001b[0mTrain 156 54405\n",
      "\u001b[32m[2020-06-22 17:56:11] __main__ INFO: \u001b[0mEpoch 156 Step 100/351 lr 0.001000 loss 1.3636 (1.3906) acc@1 0.4766 (0.4682) acc@5 0.7344 (0.7478)\n",
      "\u001b[32m[2020-06-22 17:56:20] __main__ INFO: \u001b[0mEpoch 156 Step 200/351 lr 0.001000 loss 1.5772 (1.3956) acc@1 0.4062 (0.4674) acc@5 0.7422 (0.7487)\n",
      "\u001b[32m[2020-06-22 17:56:30] __main__ INFO: \u001b[0mEpoch 156 Step 300/351 lr 0.001000 loss 1.2470 (1.3924) acc@1 0.5234 (0.4687) acc@5 0.7969 (0.7506)\n",
      "\u001b[32m[2020-06-22 17:56:34] __main__ INFO: \u001b[0mEpoch 156 Step 351/351 lr 0.001000 loss 1.5117 (1.3914) acc@1 0.4062 (0.4683) acc@5 0.7109 (0.7516)\n",
      "\u001b[32m[2020-06-22 17:56:34] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 17:56:34] __main__ INFO: \u001b[0mVal 156\n",
      "\u001b[32m[2020-06-22 17:56:35] __main__ INFO: \u001b[0mEpoch 156 loss 2.2004 acc@1 0.2944 acc@5 0.6986\n",
      "\u001b[32m[2020-06-22 17:56:35] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 17:56:35] __main__ INFO: \u001b[0mTrain 157 54756\n",
      "\u001b[32m[2020-06-22 17:56:45] __main__ INFO: \u001b[0mEpoch 157 Step 100/351 lr 0.001000 loss 1.2163 (1.3943) acc@1 0.5391 (0.4673) acc@5 0.7422 (0.7528)\n",
      "\u001b[32m[2020-06-22 17:56:54] __main__ INFO: \u001b[0mEpoch 157 Step 200/351 lr 0.001000 loss 1.2366 (1.3919) acc@1 0.5312 (0.4684) acc@5 0.7656 (0.7543)\n",
      "\u001b[32m[2020-06-22 17:57:03] __main__ INFO: \u001b[0mEpoch 157 Step 300/351 lr 0.001000 loss 1.4739 (1.3941) acc@1 0.4219 (0.4670) acc@5 0.7891 (0.7516)\n",
      "\u001b[32m[2020-06-22 17:57:08] __main__ INFO: \u001b[0mEpoch 157 Step 351/351 lr 0.001000 loss 1.4763 (1.3903) acc@1 0.3984 (0.4688) acc@5 0.6875 (0.7528)\n",
      "\u001b[32m[2020-06-22 17:57:08] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 17:57:08] __main__ INFO: \u001b[0mVal 157\n",
      "\u001b[32m[2020-06-22 17:57:09] __main__ INFO: \u001b[0mEpoch 157 loss 2.1807 acc@1 0.2950 acc@5 0.6976\n",
      "\u001b[32m[2020-06-22 17:57:09] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 17:57:09] __main__ INFO: \u001b[0mTrain 158 55107\n",
      "\u001b[32m[2020-06-22 17:57:19] __main__ INFO: \u001b[0mEpoch 158 Step 100/351 lr 0.001000 loss 1.4907 (1.3845) acc@1 0.4453 (0.4683) acc@5 0.7578 (0.7510)\n",
      "\u001b[32m[2020-06-22 17:57:28] __main__ INFO: \u001b[0mEpoch 158 Step 200/351 lr 0.001000 loss 1.5350 (1.3858) acc@1 0.3828 (0.4711) acc@5 0.7109 (0.7527)\n",
      "\u001b[32m[2020-06-22 17:57:37] __main__ INFO: \u001b[0mEpoch 158 Step 300/351 lr 0.001000 loss 1.4780 (1.3881) acc@1 0.4297 (0.4700) acc@5 0.7266 (0.7526)\n",
      "\u001b[32m[2020-06-22 17:57:42] __main__ INFO: \u001b[0mEpoch 158 Step 351/351 lr 0.001000 loss 1.5512 (1.3894) acc@1 0.4062 (0.4697) acc@5 0.7500 (0.7528)\n",
      "\u001b[32m[2020-06-22 17:57:42] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 17:57:42] __main__ INFO: \u001b[0mVal 158\n",
      "\u001b[32m[2020-06-22 17:57:43] __main__ INFO: \u001b[0mEpoch 158 loss 2.2038 acc@1 0.2942 acc@5 0.6954\n",
      "\u001b[32m[2020-06-22 17:57:43] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 17:57:43] __main__ INFO: \u001b[0mTrain 159 55458\n",
      "\u001b[32m[2020-06-22 17:57:53] __main__ INFO: \u001b[0mEpoch 159 Step 100/351 lr 0.001000 loss 1.3847 (1.3837) acc@1 0.4766 (0.4741) acc@5 0.7578 (0.7568)\n",
      "\u001b[32m[2020-06-22 17:58:02] __main__ INFO: \u001b[0mEpoch 159 Step 200/351 lr 0.001000 loss 1.4393 (1.3893) acc@1 0.4297 (0.4718) acc@5 0.7422 (0.7541)\n",
      "\u001b[32m[2020-06-22 17:58:11] __main__ INFO: \u001b[0mEpoch 159 Step 300/351 lr 0.001000 loss 1.3508 (1.3887) acc@1 0.4141 (0.4702) acc@5 0.7344 (0.7539)\n",
      "\u001b[32m[2020-06-22 17:58:16] __main__ INFO: \u001b[0mEpoch 159 Step 351/351 lr 0.001000 loss 1.4317 (1.3886) acc@1 0.4375 (0.4701) acc@5 0.7812 (0.7532)\n",
      "\u001b[32m[2020-06-22 17:58:16] __main__ INFO: \u001b[0mElapsed 32.75\n",
      "\u001b[32m[2020-06-22 17:58:16] __main__ INFO: \u001b[0mVal 159\n",
      "\u001b[32m[2020-06-22 17:58:17] __main__ INFO: \u001b[0mEpoch 159 loss 2.1989 acc@1 0.2932 acc@5 0.6962\n",
      "\u001b[32m[2020-06-22 17:58:17] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 17:58:17] __main__ INFO: \u001b[0mTrain 160 55809\n",
      "\u001b[32m[2020-06-22 17:58:26] __main__ INFO: \u001b[0mEpoch 160 Step 100/351 lr 0.001000 loss 1.3277 (1.3839) acc@1 0.4688 (0.4738) acc@5 0.7344 (0.7559)\n",
      "\u001b[32m[2020-06-22 17:58:36] __main__ INFO: \u001b[0mEpoch 160 Step 200/351 lr 0.001000 loss 1.3234 (1.3831) acc@1 0.4688 (0.4740) acc@5 0.7656 (0.7569)\n",
      "\u001b[32m[2020-06-22 17:58:45] __main__ INFO: \u001b[0mEpoch 160 Step 300/351 lr 0.001000 loss 1.2313 (1.3855) acc@1 0.5312 (0.4715) acc@5 0.8125 (0.7542)\n",
      "\u001b[32m[2020-06-22 17:58:50] __main__ INFO: \u001b[0mEpoch 160 Step 351/351 lr 0.001000 loss 1.3971 (1.3851) acc@1 0.4922 (0.4719) acc@5 0.7500 (0.7549)\n",
      "\u001b[32m[2020-06-22 17:58:50] __main__ INFO: \u001b[0mElapsed 32.78\n",
      "\u001b[32m[2020-06-22 17:58:50] __main__ INFO: \u001b[0mVal 160\n",
      "\u001b[32m[2020-06-22 17:58:51] __main__ INFO: \u001b[0mEpoch 160 loss 2.2184 acc@1 0.2972 acc@5 0.6956\n",
      "\u001b[32m[2020-06-22 17:58:51] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 17:58:51] __main__ INFO: \u001b[0mTrain 161 56160\n",
      "\u001b[32m[2020-06-22 17:59:00] __main__ INFO: \u001b[0mEpoch 161 Step 100/351 lr 0.001000 loss 1.2873 (1.3825) acc@1 0.5000 (0.4684) acc@5 0.8047 (0.7562)\n",
      "\u001b[32m[2020-06-22 17:59:10] __main__ INFO: \u001b[0mEpoch 161 Step 200/351 lr 0.001000 loss 1.4688 (1.3827) acc@1 0.4844 (0.4712) acc@5 0.7734 (0.7566)\n",
      "\u001b[32m[2020-06-22 17:59:19] __main__ INFO: \u001b[0mEpoch 161 Step 300/351 lr 0.001000 loss 1.3380 (1.3828) acc@1 0.5547 (0.4722) acc@5 0.8125 (0.7553)\n",
      "\u001b[32m[2020-06-22 17:59:24] __main__ INFO: \u001b[0mEpoch 161 Step 351/351 lr 0.001000 loss 1.3698 (1.3872) acc@1 0.4531 (0.4703) acc@5 0.7812 (0.7533)\n",
      "\u001b[32m[2020-06-22 17:59:24] __main__ INFO: \u001b[0mElapsed 32.77\n",
      "\u001b[32m[2020-06-22 17:59:24] __main__ INFO: \u001b[0mVal 161\n",
      "\u001b[32m[2020-06-22 17:59:25] __main__ INFO: \u001b[0mEpoch 161 loss 2.2278 acc@1 0.2960 acc@5 0.6954\n",
      "\u001b[32m[2020-06-22 17:59:25] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 17:59:25] __main__ INFO: \u001b[0mTrain 162 56511\n",
      "\u001b[32m[2020-06-22 17:59:34] __main__ INFO: \u001b[0mEpoch 162 Step 100/351 lr 0.001000 loss 1.4407 (1.3812) acc@1 0.4219 (0.4713) acc@5 0.7422 (0.7531)\n",
      "\u001b[32m[2020-06-22 17:59:43] __main__ INFO: \u001b[0mEpoch 162 Step 200/351 lr 0.001000 loss 1.2148 (1.3793) acc@1 0.5625 (0.4732) acc@5 0.8047 (0.7546)\n",
      "\u001b[32m[2020-06-22 17:59:53] __main__ INFO: \u001b[0mEpoch 162 Step 300/351 lr 0.001000 loss 1.3972 (1.3802) acc@1 0.4375 (0.4730) acc@5 0.7031 (0.7537)\n",
      "\u001b[32m[2020-06-22 17:59:57] __main__ INFO: \u001b[0mEpoch 162 Step 351/351 lr 0.001000 loss 1.3880 (1.3836) acc@1 0.4531 (0.4726) acc@5 0.7422 (0.7527)\n",
      "\u001b[32m[2020-06-22 17:59:58] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 17:59:58] __main__ INFO: \u001b[0mVal 162\n",
      "\u001b[32m[2020-06-22 17:59:59] __main__ INFO: \u001b[0mEpoch 162 loss 2.2267 acc@1 0.2942 acc@5 0.7002\n",
      "\u001b[32m[2020-06-22 17:59:59] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 17:59:59] __main__ INFO: \u001b[0mTrain 163 56862\n",
      "\u001b[32m[2020-06-22 18:00:08] __main__ INFO: \u001b[0mEpoch 163 Step 100/351 lr 0.001000 loss 1.5285 (1.3813) acc@1 0.4453 (0.4744) acc@5 0.6953 (0.7548)\n",
      "\u001b[32m[2020-06-22 18:00:17] __main__ INFO: \u001b[0mEpoch 163 Step 200/351 lr 0.001000 loss 1.1452 (1.3844) acc@1 0.5859 (0.4718) acc@5 0.7891 (0.7546)\n",
      "\u001b[32m[2020-06-22 18:00:27] __main__ INFO: \u001b[0mEpoch 163 Step 300/351 lr 0.001000 loss 1.3547 (1.3857) acc@1 0.4766 (0.4717) acc@5 0.7891 (0.7548)\n",
      "\u001b[32m[2020-06-22 18:00:31] __main__ INFO: \u001b[0mEpoch 163 Step 351/351 lr 0.001000 loss 1.3409 (1.3877) acc@1 0.4922 (0.4706) acc@5 0.7578 (0.7541)\n",
      "\u001b[32m[2020-06-22 18:00:31] __main__ INFO: \u001b[0mElapsed 32.78\n",
      "\u001b[32m[2020-06-22 18:00:31] __main__ INFO: \u001b[0mVal 163\n",
      "\u001b[32m[2020-06-22 18:00:32] __main__ INFO: \u001b[0mEpoch 163 loss 2.2519 acc@1 0.2936 acc@5 0.7124\n",
      "\u001b[32m[2020-06-22 18:00:32] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 18:00:32] __main__ INFO: \u001b[0mTrain 164 57213\n",
      "\u001b[32m[2020-06-22 18:00:42] __main__ INFO: \u001b[0mEpoch 164 Step 100/351 lr 0.001000 loss 1.4320 (1.3813) acc@1 0.4766 (0.4670) acc@5 0.7578 (0.7478)\n",
      "\u001b[32m[2020-06-22 18:00:51] __main__ INFO: \u001b[0mEpoch 164 Step 200/351 lr 0.001000 loss 1.3963 (1.3813) acc@1 0.4766 (0.4701) acc@5 0.7656 (0.7510)\n",
      "\u001b[32m[2020-06-22 18:01:00] __main__ INFO: \u001b[0mEpoch 164 Step 300/351 lr 0.001000 loss 1.3211 (1.3791) acc@1 0.4609 (0.4720) acc@5 0.7344 (0.7540)\n",
      "\u001b[32m[2020-06-22 18:01:05] __main__ INFO: \u001b[0mEpoch 164 Step 351/351 lr 0.001000 loss 1.5329 (1.3802) acc@1 0.3906 (0.4725) acc@5 0.7812 (0.7537)\n",
      "\u001b[32m[2020-06-22 18:01:05] __main__ INFO: \u001b[0mElapsed 32.74\n",
      "\u001b[32m[2020-06-22 18:01:05] __main__ INFO: \u001b[0mVal 164\n",
      "\u001b[32m[2020-06-22 18:01:06] __main__ INFO: \u001b[0mEpoch 164 loss 2.2323 acc@1 0.2978 acc@5 0.6964\n",
      "\u001b[32m[2020-06-22 18:01:06] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 18:01:06] __main__ INFO: \u001b[0mTrain 165 57564\n",
      "\u001b[32m[2020-06-22 18:01:16] __main__ INFO: \u001b[0mEpoch 165 Step 100/351 lr 0.001000 loss 1.3532 (1.3707) acc@1 0.4688 (0.4739) acc@5 0.7500 (0.7584)\n",
      "\u001b[32m[2020-06-22 18:01:25] __main__ INFO: \u001b[0mEpoch 165 Step 200/351 lr 0.001000 loss 1.6144 (1.3754) acc@1 0.4062 (0.4730) acc@5 0.7031 (0.7574)\n",
      "\u001b[32m[2020-06-22 18:01:34] __main__ INFO: \u001b[0mEpoch 165 Step 300/351 lr 0.001000 loss 1.4048 (1.3810) acc@1 0.4688 (0.4715) acc@5 0.7578 (0.7551)\n",
      "\u001b[32m[2020-06-22 18:01:39] __main__ INFO: \u001b[0mEpoch 165 Step 351/351 lr 0.001000 loss 1.2474 (1.3800) acc@1 0.4922 (0.4719) acc@5 0.7969 (0.7553)\n",
      "\u001b[32m[2020-06-22 18:01:39] __main__ INFO: \u001b[0mElapsed 32.77\n",
      "\u001b[32m[2020-06-22 18:01:39] __main__ INFO: \u001b[0mVal 165\n",
      "\u001b[32m[2020-06-22 18:01:40] __main__ INFO: \u001b[0mEpoch 165 loss 2.2335 acc@1 0.2948 acc@5 0.6988\n",
      "\u001b[32m[2020-06-22 18:01:40] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:01:40] __main__ INFO: \u001b[0mTrain 166 57915\n",
      "\u001b[32m[2020-06-22 18:01:49] __main__ INFO: \u001b[0mEpoch 166 Step 100/351 lr 0.001000 loss 1.4201 (1.3718) acc@1 0.4453 (0.4750) acc@5 0.7578 (0.7588)\n",
      "\u001b[32m[2020-06-22 18:01:59] __main__ INFO: \u001b[0mEpoch 166 Step 200/351 lr 0.001000 loss 1.4037 (1.3735) acc@1 0.4375 (0.4742) acc@5 0.7344 (0.7577)\n",
      "\u001b[32m[2020-06-22 18:02:08] __main__ INFO: \u001b[0mEpoch 166 Step 300/351 lr 0.001000 loss 1.2826 (1.3780) acc@1 0.4766 (0.4732) acc@5 0.7656 (0.7552)\n",
      "\u001b[32m[2020-06-22 18:02:13] __main__ INFO: \u001b[0mEpoch 166 Step 351/351 lr 0.001000 loss 1.3859 (1.3782) acc@1 0.4922 (0.4733) acc@5 0.7578 (0.7542)\n",
      "\u001b[32m[2020-06-22 18:02:13] __main__ INFO: \u001b[0mElapsed 32.71\n",
      "\u001b[32m[2020-06-22 18:02:13] __main__ INFO: \u001b[0mVal 166\n",
      "\u001b[32m[2020-06-22 18:02:14] __main__ INFO: \u001b[0mEpoch 166 loss 2.2408 acc@1 0.2974 acc@5 0.6914\n",
      "\u001b[32m[2020-06-22 18:02:14] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 18:02:14] __main__ INFO: \u001b[0mTrain 167 58266\n",
      "\u001b[32m[2020-06-22 18:02:23] __main__ INFO: \u001b[0mEpoch 167 Step 100/351 lr 0.001000 loss 1.4020 (1.3920) acc@1 0.5156 (0.4682) acc@5 0.7969 (0.7546)\n",
      "\u001b[32m[2020-06-22 18:02:33] __main__ INFO: \u001b[0mEpoch 167 Step 200/351 lr 0.001000 loss 1.3738 (1.3860) acc@1 0.4766 (0.4691) acc@5 0.7891 (0.7541)\n",
      "\u001b[32m[2020-06-22 18:02:42] __main__ INFO: \u001b[0mEpoch 167 Step 300/351 lr 0.001000 loss 1.2544 (1.3821) acc@1 0.5312 (0.4710) acc@5 0.8047 (0.7548)\n",
      "\u001b[32m[2020-06-22 18:02:47] __main__ INFO: \u001b[0mEpoch 167 Step 351/351 lr 0.001000 loss 1.3309 (1.3793) acc@1 0.5000 (0.4732) acc@5 0.7812 (0.7544)\n",
      "\u001b[32m[2020-06-22 18:02:47] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 18:02:47] __main__ INFO: \u001b[0mVal 167\n",
      "\u001b[32m[2020-06-22 18:02:48] __main__ INFO: \u001b[0mEpoch 167 loss 2.2265 acc@1 0.2912 acc@5 0.6996\n",
      "\u001b[32m[2020-06-22 18:02:48] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:02:48] __main__ INFO: \u001b[0mTrain 168 58617\n",
      "\u001b[32m[2020-06-22 18:02:57] __main__ INFO: \u001b[0mEpoch 168 Step 100/351 lr 0.001000 loss 1.3131 (1.3741) acc@1 0.5156 (0.4723) acc@5 0.7500 (0.7555)\n",
      "\u001b[32m[2020-06-22 18:03:06] __main__ INFO: \u001b[0mEpoch 168 Step 200/351 lr 0.001000 loss 1.6688 (1.3783) acc@1 0.3594 (0.4704) acc@5 0.6875 (0.7519)\n",
      "\u001b[32m[2020-06-22 18:03:16] __main__ INFO: \u001b[0mEpoch 168 Step 300/351 lr 0.001000 loss 1.4348 (1.3802) acc@1 0.4609 (0.4697) acc@5 0.7422 (0.7531)\n",
      "\u001b[32m[2020-06-22 18:03:20] __main__ INFO: \u001b[0mEpoch 168 Step 351/351 lr 0.001000 loss 1.4106 (1.3774) acc@1 0.4688 (0.4710) acc@5 0.7188 (0.7542)\n",
      "\u001b[32m[2020-06-22 18:03:20] __main__ INFO: \u001b[0mElapsed 32.76\n",
      "\u001b[32m[2020-06-22 18:03:20] __main__ INFO: \u001b[0mVal 168\n",
      "\u001b[32m[2020-06-22 18:03:21] __main__ INFO: \u001b[0mEpoch 168 loss 2.2245 acc@1 0.2956 acc@5 0.7010\n",
      "\u001b[32m[2020-06-22 18:03:21] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:03:21] __main__ INFO: \u001b[0mTrain 169 58968\n",
      "\u001b[32m[2020-06-22 18:03:31] __main__ INFO: \u001b[0mEpoch 169 Step 100/351 lr 0.001000 loss 1.2478 (1.3871) acc@1 0.5078 (0.4653) acc@5 0.7500 (0.7488)\n",
      "\u001b[32m[2020-06-22 18:03:40] __main__ INFO: \u001b[0mEpoch 169 Step 200/351 lr 0.001000 loss 1.5094 (1.3738) acc@1 0.4219 (0.4729) acc@5 0.7188 (0.7525)\n",
      "\u001b[32m[2020-06-22 18:03:50] __main__ INFO: \u001b[0mEpoch 169 Step 300/351 lr 0.001000 loss 1.4441 (1.3750) acc@1 0.4453 (0.4744) acc@5 0.7578 (0.7545)\n",
      "\u001b[32m[2020-06-22 18:03:54] __main__ INFO: \u001b[0mEpoch 169 Step 351/351 lr 0.001000 loss 1.4924 (1.3766) acc@1 0.4453 (0.4742) acc@5 0.7656 (0.7541)\n",
      "\u001b[32m[2020-06-22 18:03:54] __main__ INFO: \u001b[0mElapsed 32.81\n",
      "\u001b[32m[2020-06-22 18:03:54] __main__ INFO: \u001b[0mVal 169\n",
      "\u001b[32m[2020-06-22 18:03:55] __main__ INFO: \u001b[0mEpoch 169 loss 2.2492 acc@1 0.2940 acc@5 0.6960\n",
      "\u001b[32m[2020-06-22 18:03:55] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:03:55] __main__ INFO: \u001b[0mTrain 170 59319\n",
      "\u001b[32m[2020-06-22 18:04:05] __main__ INFO: \u001b[0mEpoch 170 Step 100/351 lr 0.001000 loss 1.3705 (1.3629) acc@1 0.4844 (0.4814) acc@5 0.7500 (0.7612)\n",
      "\u001b[32m[2020-06-22 18:04:14] __main__ INFO: \u001b[0mEpoch 170 Step 200/351 lr 0.001000 loss 1.3005 (1.3690) acc@1 0.4766 (0.4789) acc@5 0.7266 (0.7562)\n",
      "\u001b[32m[2020-06-22 18:04:23] __main__ INFO: \u001b[0mEpoch 170 Step 300/351 lr 0.001000 loss 1.4852 (1.3712) acc@1 0.4453 (0.4773) acc@5 0.7266 (0.7558)\n",
      "\u001b[32m[2020-06-22 18:04:28] __main__ INFO: \u001b[0mEpoch 170 Step 351/351 lr 0.001000 loss 1.4500 (1.3749) acc@1 0.4531 (0.4758) acc@5 0.6719 (0.7560)\n",
      "\u001b[32m[2020-06-22 18:04:28] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 18:04:28] __main__ INFO: \u001b[0mVal 170\n",
      "\u001b[32m[2020-06-22 18:04:29] __main__ INFO: \u001b[0mEpoch 170 loss 2.2570 acc@1 0.2880 acc@5 0.6976\n",
      "\u001b[32m[2020-06-22 18:04:29] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 18:04:29] __main__ INFO: \u001b[0mTrain 171 59670\n",
      "\u001b[32m[2020-06-22 18:04:39] __main__ INFO: \u001b[0mEpoch 171 Step 100/351 lr 0.001000 loss 1.3247 (1.3844) acc@1 0.4844 (0.4693) acc@5 0.7500 (0.7602)\n",
      "\u001b[32m[2020-06-22 18:04:48] __main__ INFO: \u001b[0mEpoch 171 Step 200/351 lr 0.001000 loss 1.4435 (1.3800) acc@1 0.4531 (0.4728) acc@5 0.6875 (0.7557)\n",
      "\u001b[32m[2020-06-22 18:04:57] __main__ INFO: \u001b[0mEpoch 171 Step 300/351 lr 0.001000 loss 1.2231 (1.3754) acc@1 0.5312 (0.4729) acc@5 0.8203 (0.7551)\n",
      "\u001b[32m[2020-06-22 18:05:02] __main__ INFO: \u001b[0mEpoch 171 Step 351/351 lr 0.001000 loss 1.3547 (1.3791) acc@1 0.4609 (0.4722) acc@5 0.8203 (0.7534)\n",
      "\u001b[32m[2020-06-22 18:05:02] __main__ INFO: \u001b[0mElapsed 32.78\n",
      "\u001b[32m[2020-06-22 18:05:02] __main__ INFO: \u001b[0mVal 171\n",
      "\u001b[32m[2020-06-22 18:05:03] __main__ INFO: \u001b[0mEpoch 171 loss 2.2554 acc@1 0.2988 acc@5 0.6940\n",
      "\u001b[32m[2020-06-22 18:05:03] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 18:05:03] __main__ INFO: \u001b[0mTrain 172 60021\n",
      "\u001b[32m[2020-06-22 18:05:12] __main__ INFO: \u001b[0mEpoch 172 Step 100/351 lr 0.001000 loss 1.3075 (1.3736) acc@1 0.5156 (0.4762) acc@5 0.7734 (0.7577)\n",
      "\u001b[32m[2020-06-22 18:05:22] __main__ INFO: \u001b[0mEpoch 172 Step 200/351 lr 0.001000 loss 1.3278 (1.3715) acc@1 0.5391 (0.4791) acc@5 0.8672 (0.7544)\n",
      "\u001b[32m[2020-06-22 18:05:31] __main__ INFO: \u001b[0mEpoch 172 Step 300/351 lr 0.001000 loss 1.2726 (1.3766) acc@1 0.5156 (0.4760) acc@5 0.7500 (0.7535)\n",
      "\u001b[32m[2020-06-22 18:05:36] __main__ INFO: \u001b[0mEpoch 172 Step 351/351 lr 0.001000 loss 1.4112 (1.3750) acc@1 0.4141 (0.4763) acc@5 0.6953 (0.7531)\n",
      "\u001b[32m[2020-06-22 18:05:36] __main__ INFO: \u001b[0mElapsed 32.81\n",
      "\u001b[32m[2020-06-22 18:05:36] __main__ INFO: \u001b[0mVal 172\n",
      "\u001b[32m[2020-06-22 18:05:37] __main__ INFO: \u001b[0mEpoch 172 loss 2.2491 acc@1 0.2944 acc@5 0.6942\n",
      "\u001b[32m[2020-06-22 18:05:37] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 18:05:37] __main__ INFO: \u001b[0mTrain 173 60372\n",
      "\u001b[32m[2020-06-22 18:05:46] __main__ INFO: \u001b[0mEpoch 173 Step 100/351 lr 0.001000 loss 1.5433 (1.3773) acc@1 0.4453 (0.4707) acc@5 0.7266 (0.7519)\n",
      "\u001b[32m[2020-06-22 18:05:56] __main__ INFO: \u001b[0mEpoch 173 Step 200/351 lr 0.001000 loss 1.3395 (1.3719) acc@1 0.4922 (0.4726) acc@5 0.7344 (0.7560)\n",
      "\u001b[32m[2020-06-22 18:06:05] __main__ INFO: \u001b[0mEpoch 173 Step 300/351 lr 0.001000 loss 1.3959 (1.3724) acc@1 0.4453 (0.4729) acc@5 0.7422 (0.7551)\n",
      "\u001b[32m[2020-06-22 18:06:10] __main__ INFO: \u001b[0mEpoch 173 Step 351/351 lr 0.001000 loss 1.3505 (1.3750) acc@1 0.4609 (0.4723) acc@5 0.7266 (0.7537)\n",
      "\u001b[32m[2020-06-22 18:06:10] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 18:06:10] __main__ INFO: \u001b[0mVal 173\n",
      "\u001b[32m[2020-06-22 18:06:11] __main__ INFO: \u001b[0mEpoch 173 loss 2.2610 acc@1 0.2956 acc@5 0.6974\n",
      "\u001b[32m[2020-06-22 18:06:11] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 18:06:11] __main__ INFO: \u001b[0mTrain 174 60723\n",
      "\u001b[32m[2020-06-22 18:06:20] __main__ INFO: \u001b[0mEpoch 174 Step 100/351 lr 0.001000 loss 1.3288 (1.3760) acc@1 0.4844 (0.4723) acc@5 0.7969 (0.7580)\n",
      "\u001b[32m[2020-06-22 18:06:29] __main__ INFO: \u001b[0mEpoch 174 Step 200/351 lr 0.001000 loss 1.4285 (1.3786) acc@1 0.4297 (0.4702) acc@5 0.7422 (0.7549)\n",
      "\u001b[32m[2020-06-22 18:06:39] __main__ INFO: \u001b[0mEpoch 174 Step 300/351 lr 0.001000 loss 1.3240 (1.3761) acc@1 0.5078 (0.4723) acc@5 0.7734 (0.7543)\n",
      "\u001b[32m[2020-06-22 18:06:44] __main__ INFO: \u001b[0mEpoch 174 Step 351/351 lr 0.001000 loss 1.2725 (1.3736) acc@1 0.5469 (0.4735) acc@5 0.7422 (0.7551)\n",
      "\u001b[32m[2020-06-22 18:06:44] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 18:06:44] __main__ INFO: \u001b[0mVal 174\n",
      "\u001b[32m[2020-06-22 18:06:45] __main__ INFO: \u001b[0mEpoch 174 loss 2.2449 acc@1 0.2970 acc@5 0.6934\n",
      "\u001b[32m[2020-06-22 18:06:45] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:06:45] __main__ INFO: \u001b[0mTrain 175 61074\n",
      "\u001b[32m[2020-06-22 18:06:54] __main__ INFO: \u001b[0mEpoch 175 Step 100/351 lr 0.001000 loss 1.2337 (1.3798) acc@1 0.5625 (0.4733) acc@5 0.8047 (0.7500)\n",
      "\u001b[32m[2020-06-22 18:07:03] __main__ INFO: \u001b[0mEpoch 175 Step 200/351 lr 0.001000 loss 1.2597 (1.3738) acc@1 0.5234 (0.4748) acc@5 0.7266 (0.7518)\n",
      "\u001b[32m[2020-06-22 18:07:13] __main__ INFO: \u001b[0mEpoch 175 Step 300/351 lr 0.001000 loss 1.2897 (1.3724) acc@1 0.5000 (0.4741) acc@5 0.7969 (0.7526)\n",
      "\u001b[32m[2020-06-22 18:07:17] __main__ INFO: \u001b[0mEpoch 175 Step 351/351 lr 0.001000 loss 1.4642 (1.3705) acc@1 0.4219 (0.4757) acc@5 0.7578 (0.7538)\n",
      "\u001b[32m[2020-06-22 18:07:17] __main__ INFO: \u001b[0mElapsed 32.74\n",
      "\u001b[32m[2020-06-22 18:07:17] __main__ INFO: \u001b[0mVal 175\n",
      "\u001b[32m[2020-06-22 18:07:18] __main__ INFO: \u001b[0mEpoch 175 loss 2.2583 acc@1 0.2936 acc@5 0.6904\n",
      "\u001b[32m[2020-06-22 18:07:18] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 18:07:18] __main__ INFO: \u001b[0mTrain 176 61425\n",
      "\u001b[32m[2020-06-22 18:07:28] __main__ INFO: \u001b[0mEpoch 176 Step 100/351 lr 0.001000 loss 1.3082 (1.3677) acc@1 0.5391 (0.4745) acc@5 0.8281 (0.7538)\n",
      "\u001b[32m[2020-06-22 18:07:37] __main__ INFO: \u001b[0mEpoch 176 Step 200/351 lr 0.001000 loss 1.2883 (1.3646) acc@1 0.4922 (0.4754) acc@5 0.7734 (0.7559)\n",
      "\u001b[32m[2020-06-22 18:07:46] __main__ INFO: \u001b[0mEpoch 176 Step 300/351 lr 0.001000 loss 1.3388 (1.3713) acc@1 0.5156 (0.4746) acc@5 0.7734 (0.7550)\n",
      "\u001b[32m[2020-06-22 18:07:51] __main__ INFO: \u001b[0mEpoch 176 Step 351/351 lr 0.001000 loss 1.2779 (1.3713) acc@1 0.5312 (0.4740) acc@5 0.7969 (0.7550)\n",
      "\u001b[32m[2020-06-22 18:07:51] __main__ INFO: \u001b[0mElapsed 32.74\n",
      "\u001b[32m[2020-06-22 18:07:51] __main__ INFO: \u001b[0mVal 176\n",
      "\u001b[32m[2020-06-22 18:07:52] __main__ INFO: \u001b[0mEpoch 176 loss 2.2568 acc@1 0.2948 acc@5 0.6942\n",
      "\u001b[32m[2020-06-22 18:07:52] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 18:07:52] __main__ INFO: \u001b[0mTrain 177 61776\n",
      "\u001b[32m[2020-06-22 18:08:02] __main__ INFO: \u001b[0mEpoch 177 Step 100/351 lr 0.001000 loss 1.3820 (1.3530) acc@1 0.4609 (0.4826) acc@5 0.7578 (0.7577)\n",
      "\u001b[32m[2020-06-22 18:08:11] __main__ INFO: \u001b[0mEpoch 177 Step 200/351 lr 0.001000 loss 1.3228 (1.3676) acc@1 0.4609 (0.4754) acc@5 0.7969 (0.7553)\n",
      "\u001b[32m[2020-06-22 18:08:20] __main__ INFO: \u001b[0mEpoch 177 Step 300/351 lr 0.001000 loss 1.3592 (1.3672) acc@1 0.5078 (0.4760) acc@5 0.7812 (0.7549)\n",
      "\u001b[32m[2020-06-22 18:08:25] __main__ INFO: \u001b[0mEpoch 177 Step 351/351 lr 0.001000 loss 1.3869 (1.3698) acc@1 0.4531 (0.4741) acc@5 0.7188 (0.7541)\n",
      "\u001b[32m[2020-06-22 18:08:25] __main__ INFO: \u001b[0mElapsed 32.81\n",
      "\u001b[32m[2020-06-22 18:08:25] __main__ INFO: \u001b[0mVal 177\n",
      "\u001b[32m[2020-06-22 18:08:26] __main__ INFO: \u001b[0mEpoch 177 loss 2.3021 acc@1 0.2906 acc@5 0.6932\n",
      "\u001b[32m[2020-06-22 18:08:26] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 18:08:26] __main__ INFO: \u001b[0mTrain 178 62127\n",
      "\u001b[32m[2020-06-22 18:08:35] __main__ INFO: \u001b[0mEpoch 178 Step 100/351 lr 0.001000 loss 1.4881 (1.3606) acc@1 0.4062 (0.4786) acc@5 0.7031 (0.7478)\n",
      "\u001b[32m[2020-06-22 18:08:45] __main__ INFO: \u001b[0mEpoch 178 Step 200/351 lr 0.001000 loss 1.3182 (1.3682) acc@1 0.5312 (0.4756) acc@5 0.7891 (0.7503)\n",
      "\u001b[32m[2020-06-22 18:08:54] __main__ INFO: \u001b[0mEpoch 178 Step 300/351 lr 0.001000 loss 1.4313 (1.3708) acc@1 0.4531 (0.4748) acc@5 0.7266 (0.7514)\n",
      "\u001b[32m[2020-06-22 18:08:59] __main__ INFO: \u001b[0mEpoch 178 Step 351/351 lr 0.001000 loss 1.3589 (1.3680) acc@1 0.5156 (0.4761) acc@5 0.8438 (0.7525)\n",
      "\u001b[32m[2020-06-22 18:08:59] __main__ INFO: \u001b[0mElapsed 32.78\n",
      "\u001b[32m[2020-06-22 18:08:59] __main__ INFO: \u001b[0mVal 178\n",
      "\u001b[32m[2020-06-22 18:09:00] __main__ INFO: \u001b[0mEpoch 178 loss 2.2727 acc@1 0.2948 acc@5 0.6934\n",
      "\u001b[32m[2020-06-22 18:09:00] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:09:00] __main__ INFO: \u001b[0mTrain 179 62478\n",
      "\u001b[32m[2020-06-22 18:09:09] __main__ INFO: \u001b[0mEpoch 179 Step 100/351 lr 0.001000 loss 1.2598 (1.3603) acc@1 0.4766 (0.4803) acc@5 0.7656 (0.7574)\n",
      "\u001b[32m[2020-06-22 18:09:19] __main__ INFO: \u001b[0mEpoch 179 Step 200/351 lr 0.001000 loss 1.4276 (1.3643) acc@1 0.4453 (0.4793) acc@5 0.7344 (0.7546)\n",
      "\u001b[32m[2020-06-22 18:09:28] __main__ INFO: \u001b[0mEpoch 179 Step 300/351 lr 0.001000 loss 1.3823 (1.3679) acc@1 0.4297 (0.4786) acc@5 0.7656 (0.7535)\n",
      "\u001b[32m[2020-06-22 18:09:33] __main__ INFO: \u001b[0mEpoch 179 Step 351/351 lr 0.001000 loss 1.3953 (1.3686) acc@1 0.4766 (0.4783) acc@5 0.7656 (0.7531)\n",
      "\u001b[32m[2020-06-22 18:09:33] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 18:09:33] __main__ INFO: \u001b[0mVal 179\n",
      "\u001b[32m[2020-06-22 18:09:34] __main__ INFO: \u001b[0mEpoch 179 loss 2.2838 acc@1 0.2950 acc@5 0.6962\n",
      "\u001b[32m[2020-06-22 18:09:34] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 18:09:34] __main__ INFO: \u001b[0mTrain 180 62829\n",
      "\u001b[32m[2020-06-22 18:09:43] __main__ INFO: \u001b[0mEpoch 180 Step 100/351 lr 0.001000 loss 1.4570 (1.3621) acc@1 0.4297 (0.4788) acc@5 0.7031 (0.7614)\n",
      "\u001b[32m[2020-06-22 18:09:52] __main__ INFO: \u001b[0mEpoch 180 Step 200/351 lr 0.001000 loss 1.3272 (1.3660) acc@1 0.4922 (0.4774) acc@5 0.7656 (0.7579)\n",
      "\u001b[32m[2020-06-22 18:10:02] __main__ INFO: \u001b[0mEpoch 180 Step 300/351 lr 0.001000 loss 1.4770 (1.3664) acc@1 0.4375 (0.4771) acc@5 0.7344 (0.7557)\n",
      "\u001b[32m[2020-06-22 18:10:06] __main__ INFO: \u001b[0mEpoch 180 Step 351/351 lr 0.001000 loss 1.4074 (1.3679) acc@1 0.5000 (0.4766) acc@5 0.7656 (0.7550)\n",
      "\u001b[32m[2020-06-22 18:10:07] __main__ INFO: \u001b[0mElapsed 32.78\n",
      "\u001b[32m[2020-06-22 18:10:07] __main__ INFO: \u001b[0mVal 180\n",
      "\u001b[32m[2020-06-22 18:10:08] __main__ INFO: \u001b[0mEpoch 180 loss 2.2693 acc@1 0.2962 acc@5 0.6974\n",
      "\u001b[32m[2020-06-22 18:10:08] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:10:08] __main__ INFO: \u001b[0mTrain 181 63180\n",
      "\u001b[32m[2020-06-22 18:10:17] __main__ INFO: \u001b[0mEpoch 181 Step 100/351 lr 0.001000 loss 1.4919 (1.3648) acc@1 0.4219 (0.4800) acc@5 0.7188 (0.7515)\n",
      "\u001b[32m[2020-06-22 18:10:26] __main__ INFO: \u001b[0mEpoch 181 Step 200/351 lr 0.001000 loss 1.2642 (1.3691) acc@1 0.5156 (0.4774) acc@5 0.8125 (0.7520)\n",
      "\u001b[32m[2020-06-22 18:10:36] __main__ INFO: \u001b[0mEpoch 181 Step 300/351 lr 0.001000 loss 1.3369 (1.3674) acc@1 0.4688 (0.4778) acc@5 0.6875 (0.7536)\n",
      "\u001b[32m[2020-06-22 18:10:40] __main__ INFO: \u001b[0mEpoch 181 Step 351/351 lr 0.001000 loss 1.3084 (1.3665) acc@1 0.4766 (0.4778) acc@5 0.7031 (0.7533)\n",
      "\u001b[32m[2020-06-22 18:10:40] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 18:10:40] __main__ INFO: \u001b[0mVal 181\n",
      "\u001b[32m[2020-06-22 18:10:41] __main__ INFO: \u001b[0mEpoch 181 loss 2.2755 acc@1 0.2942 acc@5 0.6968\n",
      "\u001b[32m[2020-06-22 18:10:41] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 18:10:41] __main__ INFO: \u001b[0mTrain 182 63531\n",
      "\u001b[32m[2020-06-22 18:10:51] __main__ INFO: \u001b[0mEpoch 182 Step 100/351 lr 0.001000 loss 1.4452 (1.3640) acc@1 0.4219 (0.4781) acc@5 0.7188 (0.7551)\n",
      "\u001b[32m[2020-06-22 18:11:00] __main__ INFO: \u001b[0mEpoch 182 Step 200/351 lr 0.001000 loss 1.4123 (1.3617) acc@1 0.4922 (0.4800) acc@5 0.8125 (0.7566)\n",
      "\u001b[32m[2020-06-22 18:11:10] __main__ INFO: \u001b[0mEpoch 182 Step 300/351 lr 0.001000 loss 1.4419 (1.3647) acc@1 0.4531 (0.4782) acc@5 0.7266 (0.7538)\n",
      "\u001b[32m[2020-06-22 18:11:14] __main__ INFO: \u001b[0mEpoch 182 Step 351/351 lr 0.001000 loss 1.4161 (1.3669) acc@1 0.4531 (0.4780) acc@5 0.7266 (0.7545)\n",
      "\u001b[32m[2020-06-22 18:11:14] __main__ INFO: \u001b[0mElapsed 32.87\n",
      "\u001b[32m[2020-06-22 18:11:14] __main__ INFO: \u001b[0mVal 182\n",
      "\u001b[32m[2020-06-22 18:11:15] __main__ INFO: \u001b[0mEpoch 182 loss 2.2802 acc@1 0.2940 acc@5 0.6950\n",
      "\u001b[32m[2020-06-22 18:11:15] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 18:11:15] __main__ INFO: \u001b[0mTrain 183 63882\n",
      "\u001b[32m[2020-06-22 18:11:25] __main__ INFO: \u001b[0mEpoch 183 Step 100/351 lr 0.001000 loss 1.2140 (1.3679) acc@1 0.5625 (0.4791) acc@5 0.7812 (0.7498)\n",
      "\u001b[32m[2020-06-22 18:11:34] __main__ INFO: \u001b[0mEpoch 183 Step 200/351 lr 0.001000 loss 1.4933 (1.3595) acc@1 0.4141 (0.4803) acc@5 0.7266 (0.7526)\n",
      "\u001b[32m[2020-06-22 18:11:43] __main__ INFO: \u001b[0mEpoch 183 Step 300/351 lr 0.001000 loss 1.2803 (1.3637) acc@1 0.5000 (0.4782) acc@5 0.7422 (0.7532)\n",
      "\u001b[32m[2020-06-22 18:11:48] __main__ INFO: \u001b[0mEpoch 183 Step 351/351 lr 0.001000 loss 1.3175 (1.3659) acc@1 0.4844 (0.4775) acc@5 0.8125 (0.7527)\n",
      "\u001b[32m[2020-06-22 18:11:48] __main__ INFO: \u001b[0mElapsed 32.83\n",
      "\u001b[32m[2020-06-22 18:11:48] __main__ INFO: \u001b[0mVal 183\n",
      "\u001b[32m[2020-06-22 18:11:49] __main__ INFO: \u001b[0mEpoch 183 loss 2.2827 acc@1 0.2916 acc@5 0.6984\n",
      "\u001b[32m[2020-06-22 18:11:49] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 18:11:49] __main__ INFO: \u001b[0mTrain 184 64233\n",
      "\u001b[32m[2020-06-22 18:11:59] __main__ INFO: \u001b[0mEpoch 184 Step 100/351 lr 0.001000 loss 1.2652 (1.3633) acc@1 0.5156 (0.4804) acc@5 0.8047 (0.7623)\n",
      "\u001b[32m[2020-06-22 18:12:08] __main__ INFO: \u001b[0mEpoch 184 Step 200/351 lr 0.001000 loss 1.3994 (1.3668) acc@1 0.4688 (0.4753) acc@5 0.7656 (0.7566)\n",
      "\u001b[32m[2020-06-22 18:12:17] __main__ INFO: \u001b[0mEpoch 184 Step 300/351 lr 0.001000 loss 1.2159 (1.3605) acc@1 0.5156 (0.4785) acc@5 0.7812 (0.7564)\n",
      "\u001b[32m[2020-06-22 18:12:22] __main__ INFO: \u001b[0mEpoch 184 Step 351/351 lr 0.001000 loss 1.4371 (1.3608) acc@1 0.4609 (0.4788) acc@5 0.7812 (0.7566)\n",
      "\u001b[32m[2020-06-22 18:12:22] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 18:12:22] __main__ INFO: \u001b[0mVal 184\n",
      "\u001b[32m[2020-06-22 18:12:23] __main__ INFO: \u001b[0mEpoch 184 loss 2.2870 acc@1 0.2942 acc@5 0.7012\n",
      "\u001b[32m[2020-06-22 18:12:23] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:12:23] __main__ INFO: \u001b[0mTrain 185 64584\n",
      "\u001b[32m[2020-06-22 18:12:33] __main__ INFO: \u001b[0mEpoch 185 Step 100/351 lr 0.001000 loss 1.2091 (1.3539) acc@1 0.5156 (0.4855) acc@5 0.7656 (0.7573)\n",
      "\u001b[32m[2020-06-22 18:12:42] __main__ INFO: \u001b[0mEpoch 185 Step 200/351 lr 0.001000 loss 1.3731 (1.3572) acc@1 0.4922 (0.4827) acc@5 0.7891 (0.7566)\n",
      "\u001b[32m[2020-06-22 18:12:51] __main__ INFO: \u001b[0mEpoch 185 Step 300/351 lr 0.001000 loss 1.5960 (1.3669) acc@1 0.3828 (0.4796) acc@5 0.6562 (0.7558)\n",
      "\u001b[32m[2020-06-22 18:12:56] __main__ INFO: \u001b[0mEpoch 185 Step 351/351 lr 0.001000 loss 1.3730 (1.3648) acc@1 0.4922 (0.4805) acc@5 0.7500 (0.7564)\n",
      "\u001b[32m[2020-06-22 18:12:56] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 18:12:56] __main__ INFO: \u001b[0mVal 185\n",
      "\u001b[32m[2020-06-22 18:12:57] __main__ INFO: \u001b[0mEpoch 185 loss 2.2746 acc@1 0.2960 acc@5 0.7070\n",
      "\u001b[32m[2020-06-22 18:12:57] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:12:57] __main__ INFO: \u001b[0mTrain 186 64935\n",
      "\u001b[32m[2020-06-22 18:13:06] __main__ INFO: \u001b[0mEpoch 186 Step 100/351 lr 0.001000 loss 1.4601 (1.3494) acc@1 0.4141 (0.4845) acc@5 0.8047 (0.7580)\n",
      "\u001b[32m[2020-06-22 18:13:16] __main__ INFO: \u001b[0mEpoch 186 Step 200/351 lr 0.001000 loss 1.3278 (1.3610) acc@1 0.4766 (0.4823) acc@5 0.7031 (0.7546)\n",
      "\u001b[32m[2020-06-22 18:13:25] __main__ INFO: \u001b[0mEpoch 186 Step 300/351 lr 0.001000 loss 1.2512 (1.3618) acc@1 0.4844 (0.4812) acc@5 0.7578 (0.7549)\n",
      "\u001b[32m[2020-06-22 18:13:30] __main__ INFO: \u001b[0mEpoch 186 Step 351/351 lr 0.001000 loss 1.4735 (1.3603) acc@1 0.3984 (0.4809) acc@5 0.7266 (0.7548)\n",
      "\u001b[32m[2020-06-22 18:13:30] __main__ INFO: \u001b[0mElapsed 32.77\n",
      "\u001b[32m[2020-06-22 18:13:30] __main__ INFO: \u001b[0mVal 186\n",
      "\u001b[32m[2020-06-22 18:13:31] __main__ INFO: \u001b[0mEpoch 186 loss 2.2800 acc@1 0.2942 acc@5 0.6938\n",
      "\u001b[32m[2020-06-22 18:13:31] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:13:31] __main__ INFO: \u001b[0mTrain 187 65286\n",
      "\u001b[32m[2020-06-22 18:13:40] __main__ INFO: \u001b[0mEpoch 187 Step 100/351 lr 0.001000 loss 1.3496 (1.3601) acc@1 0.4844 (0.4802) acc@5 0.7656 (0.7548)\n",
      "\u001b[32m[2020-06-22 18:13:49] __main__ INFO: \u001b[0mEpoch 187 Step 200/351 lr 0.001000 loss 1.3746 (1.3481) acc@1 0.4688 (0.4848) acc@5 0.7500 (0.7576)\n",
      "\u001b[32m[2020-06-22 18:13:59] __main__ INFO: \u001b[0mEpoch 187 Step 300/351 lr 0.001000 loss 1.4122 (1.3590) acc@1 0.4531 (0.4787) acc@5 0.7031 (0.7552)\n",
      "\u001b[32m[2020-06-22 18:14:04] __main__ INFO: \u001b[0mEpoch 187 Step 351/351 lr 0.001000 loss 1.2404 (1.3581) acc@1 0.5234 (0.4793) acc@5 0.7422 (0.7546)\n",
      "\u001b[32m[2020-06-22 18:14:04] __main__ INFO: \u001b[0mElapsed 32.75\n",
      "\u001b[32m[2020-06-22 18:14:04] __main__ INFO: \u001b[0mVal 187\n",
      "\u001b[32m[2020-06-22 18:14:05] __main__ INFO: \u001b[0mEpoch 187 loss 2.2930 acc@1 0.2916 acc@5 0.6930\n",
      "\u001b[32m[2020-06-22 18:14:05] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:14:05] __main__ INFO: \u001b[0mTrain 188 65637\n",
      "\u001b[32m[2020-06-22 18:14:14] __main__ INFO: \u001b[0mEpoch 188 Step 100/351 lr 0.001000 loss 1.3704 (1.3697) acc@1 0.4844 (0.4795) acc@5 0.7500 (0.7504)\n",
      "\u001b[32m[2020-06-22 18:14:23] __main__ INFO: \u001b[0mEpoch 188 Step 200/351 lr 0.001000 loss 1.2685 (1.3579) acc@1 0.4922 (0.4829) acc@5 0.7812 (0.7530)\n",
      "\u001b[32m[2020-06-22 18:14:33] __main__ INFO: \u001b[0mEpoch 188 Step 300/351 lr 0.001000 loss 1.4922 (1.3604) acc@1 0.4375 (0.4804) acc@5 0.7109 (0.7530)\n",
      "\u001b[32m[2020-06-22 18:14:37] __main__ INFO: \u001b[0mEpoch 188 Step 351/351 lr 0.001000 loss 1.4297 (1.3603) acc@1 0.4688 (0.4810) acc@5 0.7188 (0.7536)\n",
      "\u001b[32m[2020-06-22 18:14:37] __main__ INFO: \u001b[0mElapsed 32.82\n",
      "\u001b[32m[2020-06-22 18:14:37] __main__ INFO: \u001b[0mVal 188\n",
      "\u001b[32m[2020-06-22 18:14:38] __main__ INFO: \u001b[0mEpoch 188 loss 2.3115 acc@1 0.2942 acc@5 0.6912\n",
      "\u001b[32m[2020-06-22 18:14:38] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:14:38] __main__ INFO: \u001b[0mTrain 189 65988\n",
      "\u001b[32m[2020-06-22 18:14:48] __main__ INFO: \u001b[0mEpoch 189 Step 100/351 lr 0.001000 loss 1.4279 (1.3549) acc@1 0.4375 (0.4813) acc@5 0.7969 (0.7532)\n",
      "\u001b[32m[2020-06-22 18:14:57] __main__ INFO: \u001b[0mEpoch 189 Step 200/351 lr 0.001000 loss 1.3135 (1.3594) acc@1 0.5156 (0.4786) acc@5 0.7656 (0.7543)\n",
      "\u001b[32m[2020-06-22 18:15:07] __main__ INFO: \u001b[0mEpoch 189 Step 300/351 lr 0.001000 loss 1.2288 (1.3587) acc@1 0.5469 (0.4791) acc@5 0.7969 (0.7539)\n",
      "\u001b[32m[2020-06-22 18:15:11] __main__ INFO: \u001b[0mEpoch 189 Step 351/351 lr 0.001000 loss 1.4454 (1.3588) acc@1 0.4219 (0.4789) acc@5 0.7188 (0.7545)\n",
      "\u001b[32m[2020-06-22 18:15:11] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 18:15:11] __main__ INFO: \u001b[0mVal 189\n",
      "\u001b[32m[2020-06-22 18:15:12] __main__ INFO: \u001b[0mEpoch 189 loss 2.3028 acc@1 0.2952 acc@5 0.7048\n",
      "\u001b[32m[2020-06-22 18:15:12] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 18:15:12] __main__ INFO: \u001b[0mTrain 190 66339\n",
      "\u001b[32m[2020-06-22 18:15:22] __main__ INFO: \u001b[0mEpoch 190 Step 100/351 lr 0.001000 loss 1.4370 (1.3634) acc@1 0.4609 (0.4813) acc@5 0.7031 (0.7589)\n",
      "\u001b[32m[2020-06-22 18:15:31] __main__ INFO: \u001b[0mEpoch 190 Step 200/351 lr 0.001000 loss 1.2566 (1.3644) acc@1 0.4844 (0.4793) acc@5 0.7656 (0.7548)\n",
      "\u001b[32m[2020-06-22 18:15:40] __main__ INFO: \u001b[0mEpoch 190 Step 300/351 lr 0.001000 loss 1.3221 (1.3566) acc@1 0.4766 (0.4817) acc@5 0.7344 (0.7557)\n",
      "\u001b[32m[2020-06-22 18:15:45] __main__ INFO: \u001b[0mEpoch 190 Step 351/351 lr 0.001000 loss 1.5376 (1.3593) acc@1 0.4219 (0.4814) acc@5 0.7031 (0.7560)\n",
      "\u001b[32m[2020-06-22 18:15:45] __main__ INFO: \u001b[0mElapsed 32.82\n",
      "\u001b[32m[2020-06-22 18:15:45] __main__ INFO: \u001b[0mVal 190\n",
      "\u001b[32m[2020-06-22 18:15:46] __main__ INFO: \u001b[0mEpoch 190 loss 2.3064 acc@1 0.2938 acc@5 0.6946\n",
      "\u001b[32m[2020-06-22 18:15:46] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:15:46] __main__ INFO: \u001b[0mTrain 191 66690\n",
      "\u001b[32m[2020-06-22 18:15:56] __main__ INFO: \u001b[0mEpoch 191 Step 100/351 lr 0.001000 loss 1.2752 (1.3497) acc@1 0.5391 (0.4808) acc@5 0.8125 (0.7512)\n",
      "\u001b[32m[2020-06-22 18:16:05] __main__ INFO: \u001b[0mEpoch 191 Step 200/351 lr 0.001000 loss 1.3428 (1.3572) acc@1 0.5156 (0.4795) acc@5 0.7422 (0.7526)\n",
      "\u001b[32m[2020-06-22 18:16:14] __main__ INFO: \u001b[0mEpoch 191 Step 300/351 lr 0.001000 loss 1.3383 (1.3551) acc@1 0.4922 (0.4816) acc@5 0.7734 (0.7541)\n",
      "\u001b[32m[2020-06-22 18:16:19] __main__ INFO: \u001b[0mEpoch 191 Step 351/351 lr 0.001000 loss 1.1370 (1.3569) acc@1 0.5859 (0.4803) acc@5 0.8125 (0.7549)\n",
      "\u001b[32m[2020-06-22 18:16:19] __main__ INFO: \u001b[0mElapsed 32.77\n",
      "\u001b[32m[2020-06-22 18:16:19] __main__ INFO: \u001b[0mVal 191\n",
      "\u001b[32m[2020-06-22 18:16:20] __main__ INFO: \u001b[0mEpoch 191 loss 2.2919 acc@1 0.2910 acc@5 0.6948\n",
      "\u001b[32m[2020-06-22 18:16:20] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:16:20] __main__ INFO: \u001b[0mTrain 192 67041\n",
      "\u001b[32m[2020-06-22 18:16:29] __main__ INFO: \u001b[0mEpoch 192 Step 100/351 lr 0.001000 loss 1.3459 (1.3667) acc@1 0.4844 (0.4769) acc@5 0.7734 (0.7496)\n",
      "\u001b[32m[2020-06-22 18:16:39] __main__ INFO: \u001b[0mEpoch 192 Step 200/351 lr 0.001000 loss 1.3464 (1.3540) acc@1 0.4766 (0.4809) acc@5 0.7500 (0.7545)\n",
      "\u001b[32m[2020-06-22 18:16:48] __main__ INFO: \u001b[0mEpoch 192 Step 300/351 lr 0.001000 loss 1.4418 (1.3554) acc@1 0.4453 (0.4807) acc@5 0.7578 (0.7552)\n",
      "\u001b[32m[2020-06-22 18:16:53] __main__ INFO: \u001b[0mEpoch 192 Step 351/351 lr 0.001000 loss 1.3279 (1.3520) acc@1 0.4922 (0.4828) acc@5 0.8203 (0.7564)\n",
      "\u001b[32m[2020-06-22 18:16:53] __main__ INFO: \u001b[0mElapsed 32.81\n",
      "\u001b[32m[2020-06-22 18:16:53] __main__ INFO: \u001b[0mVal 192\n",
      "\u001b[32m[2020-06-22 18:16:54] __main__ INFO: \u001b[0mEpoch 192 loss 2.2946 acc@1 0.2954 acc@5 0.7010\n",
      "\u001b[32m[2020-06-22 18:16:54] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 18:16:54] __main__ INFO: \u001b[0mTrain 193 67392\n",
      "\u001b[32m[2020-06-22 18:17:03] __main__ INFO: \u001b[0mEpoch 193 Step 100/351 lr 0.001000 loss 1.3085 (1.3541) acc@1 0.4922 (0.4808) acc@5 0.7500 (0.7525)\n",
      "\u001b[32m[2020-06-22 18:17:13] __main__ INFO: \u001b[0mEpoch 193 Step 200/351 lr 0.001000 loss 1.2152 (1.3528) acc@1 0.5391 (0.4824) acc@5 0.7969 (0.7532)\n",
      "\u001b[32m[2020-06-22 18:17:22] __main__ INFO: \u001b[0mEpoch 193 Step 300/351 lr 0.001000 loss 1.2724 (1.3557) acc@1 0.5078 (0.4809) acc@5 0.7734 (0.7554)\n",
      "\u001b[32m[2020-06-22 18:17:27] __main__ INFO: \u001b[0mEpoch 193 Step 351/351 lr 0.001000 loss 1.2901 (1.3580) acc@1 0.4922 (0.4799) acc@5 0.7812 (0.7563)\n",
      "\u001b[32m[2020-06-22 18:17:27] __main__ INFO: \u001b[0mElapsed 32.77\n",
      "\u001b[32m[2020-06-22 18:17:27] __main__ INFO: \u001b[0mVal 193\n",
      "\u001b[32m[2020-06-22 18:17:28] __main__ INFO: \u001b[0mEpoch 193 loss 2.3161 acc@1 0.2860 acc@5 0.6950\n",
      "\u001b[32m[2020-06-22 18:17:28] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 18:17:28] __main__ INFO: \u001b[0mTrain 194 67743\n",
      "\u001b[32m[2020-06-22 18:17:37] __main__ INFO: \u001b[0mEpoch 194 Step 100/351 lr 0.001000 loss 1.4355 (1.3492) acc@1 0.4297 (0.4823) acc@5 0.6875 (0.7577)\n",
      "\u001b[32m[2020-06-22 18:17:46] __main__ INFO: \u001b[0mEpoch 194 Step 200/351 lr 0.001000 loss 1.3923 (1.3566) acc@1 0.5156 (0.4824) acc@5 0.7266 (0.7563)\n",
      "\u001b[32m[2020-06-22 18:17:56] __main__ INFO: \u001b[0mEpoch 194 Step 300/351 lr 0.001000 loss 1.3463 (1.3550) acc@1 0.4922 (0.4819) acc@5 0.7422 (0.7548)\n",
      "\u001b[32m[2020-06-22 18:18:01] __main__ INFO: \u001b[0mEpoch 194 Step 351/351 lr 0.001000 loss 1.3830 (1.3536) acc@1 0.5312 (0.4819) acc@5 0.7656 (0.7542)\n",
      "\u001b[32m[2020-06-22 18:18:01] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 18:18:01] __main__ INFO: \u001b[0mVal 194\n",
      "\u001b[32m[2020-06-22 18:18:02] __main__ INFO: \u001b[0mEpoch 194 loss 2.3143 acc@1 0.2922 acc@5 0.6934\n",
      "\u001b[32m[2020-06-22 18:18:02] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:18:02] __main__ INFO: \u001b[0mTrain 195 68094\n",
      "\u001b[32m[2020-06-22 18:18:11] __main__ INFO: \u001b[0mEpoch 195 Step 100/351 lr 0.001000 loss 1.3028 (1.3483) acc@1 0.5234 (0.4834) acc@5 0.7266 (0.7554)\n",
      "\u001b[32m[2020-06-22 18:18:20] __main__ INFO: \u001b[0mEpoch 195 Step 200/351 lr 0.001000 loss 1.2918 (1.3467) acc@1 0.5000 (0.4833) acc@5 0.8125 (0.7537)\n",
      "\u001b[32m[2020-06-22 18:18:30] __main__ INFO: \u001b[0mEpoch 195 Step 300/351 lr 0.001000 loss 1.3053 (1.3461) acc@1 0.5000 (0.4832) acc@5 0.7891 (0.7530)\n",
      "\u001b[32m[2020-06-22 18:18:34] __main__ INFO: \u001b[0mEpoch 195 Step 351/351 lr 0.001000 loss 1.3140 (1.3473) acc@1 0.5469 (0.4836) acc@5 0.7578 (0.7536)\n",
      "\u001b[32m[2020-06-22 18:18:34] __main__ INFO: \u001b[0mElapsed 32.78\n",
      "\u001b[32m[2020-06-22 18:18:34] __main__ INFO: \u001b[0mVal 195\n",
      "\u001b[32m[2020-06-22 18:18:35] __main__ INFO: \u001b[0mEpoch 195 loss 2.3238 acc@1 0.2960 acc@5 0.6902\n",
      "\u001b[32m[2020-06-22 18:18:35] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 18:18:35] __main__ INFO: \u001b[0mTrain 196 68445\n",
      "\u001b[32m[2020-06-22 18:18:45] __main__ INFO: \u001b[0mEpoch 196 Step 100/351 lr 0.001000 loss 1.4694 (1.3731) acc@1 0.4062 (0.4749) acc@5 0.6328 (0.7472)\n",
      "\u001b[32m[2020-06-22 18:18:54] __main__ INFO: \u001b[0mEpoch 196 Step 200/351 lr 0.001000 loss 1.3125 (1.3628) acc@1 0.5234 (0.4797) acc@5 0.7969 (0.7509)\n",
      "\u001b[32m[2020-06-22 18:19:04] __main__ INFO: \u001b[0mEpoch 196 Step 300/351 lr 0.001000 loss 1.2359 (1.3561) acc@1 0.5391 (0.4816) acc@5 0.7891 (0.7536)\n",
      "\u001b[32m[2020-06-22 18:19:08] __main__ INFO: \u001b[0mEpoch 196 Step 351/351 lr 0.001000 loss 1.2893 (1.3553) acc@1 0.5547 (0.4816) acc@5 0.7734 (0.7552)\n",
      "\u001b[32m[2020-06-22 18:19:08] __main__ INFO: \u001b[0mElapsed 32.81\n",
      "\u001b[32m[2020-06-22 18:19:08] __main__ INFO: \u001b[0mVal 196\n",
      "\u001b[32m[2020-06-22 18:19:09] __main__ INFO: \u001b[0mEpoch 196 loss 2.2948 acc@1 0.2912 acc@5 0.6964\n",
      "\u001b[32m[2020-06-22 18:19:09] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 18:19:09] __main__ INFO: \u001b[0mTrain 197 68796\n",
      "\u001b[32m[2020-06-22 18:19:19] __main__ INFO: \u001b[0mEpoch 197 Step 100/351 lr 0.001000 loss 1.4164 (1.3573) acc@1 0.4688 (0.4764) acc@5 0.7578 (0.7523)\n",
      "\u001b[32m[2020-06-22 18:19:28] __main__ INFO: \u001b[0mEpoch 197 Step 200/351 lr 0.001000 loss 1.2851 (1.3531) acc@1 0.5312 (0.4804) acc@5 0.8047 (0.7519)\n",
      "\u001b[32m[2020-06-22 18:19:37] __main__ INFO: \u001b[0mEpoch 197 Step 300/351 lr 0.001000 loss 1.2600 (1.3516) acc@1 0.5078 (0.4808) acc@5 0.7422 (0.7539)\n",
      "\u001b[32m[2020-06-22 18:19:42] __main__ INFO: \u001b[0mEpoch 197 Step 351/351 lr 0.001000 loss 1.2053 (1.3502) acc@1 0.5234 (0.4820) acc@5 0.8125 (0.7543)\n",
      "\u001b[32m[2020-06-22 18:19:42] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 18:19:42] __main__ INFO: \u001b[0mVal 197\n",
      "\u001b[32m[2020-06-22 18:19:43] __main__ INFO: \u001b[0mEpoch 197 loss 2.2994 acc@1 0.2878 acc@5 0.6874\n",
      "\u001b[32m[2020-06-22 18:19:43] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:19:43] __main__ INFO: \u001b[0mTrain 198 69147\n",
      "\u001b[32m[2020-06-22 18:19:53] __main__ INFO: \u001b[0mEpoch 198 Step 100/351 lr 0.001000 loss 1.3802 (1.3397) acc@1 0.4688 (0.4863) acc@5 0.7578 (0.7539)\n",
      "\u001b[32m[2020-06-22 18:20:02] __main__ INFO: \u001b[0mEpoch 198 Step 200/351 lr 0.001000 loss 1.4386 (1.3438) acc@1 0.4688 (0.4855) acc@5 0.7266 (0.7550)\n",
      "\u001b[32m[2020-06-22 18:20:11] __main__ INFO: \u001b[0mEpoch 198 Step 300/351 lr 0.001000 loss 1.3736 (1.3510) acc@1 0.4531 (0.4823) acc@5 0.6719 (0.7524)\n",
      "\u001b[32m[2020-06-22 18:20:16] __main__ INFO: \u001b[0mEpoch 198 Step 351/351 lr 0.001000 loss 1.3297 (1.3513) acc@1 0.4766 (0.4829) acc@5 0.7891 (0.7537)\n",
      "\u001b[32m[2020-06-22 18:20:16] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 18:20:16] __main__ INFO: \u001b[0mVal 198\n",
      "\u001b[32m[2020-06-22 18:20:17] __main__ INFO: \u001b[0mEpoch 198 loss 2.3267 acc@1 0.2922 acc@5 0.6970\n",
      "\u001b[32m[2020-06-22 18:20:17] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:20:17] __main__ INFO: \u001b[0mTrain 199 69498\n",
      "\u001b[32m[2020-06-22 18:20:26] __main__ INFO: \u001b[0mEpoch 199 Step 100/351 lr 0.001000 loss 1.2635 (1.3494) acc@1 0.5234 (0.4826) acc@5 0.7344 (0.7555)\n",
      "\u001b[32m[2020-06-22 18:20:36] __main__ INFO: \u001b[0mEpoch 199 Step 200/351 lr 0.001000 loss 1.2873 (1.3548) acc@1 0.5156 (0.4826) acc@5 0.7578 (0.7539)\n",
      "\u001b[32m[2020-06-22 18:20:45] __main__ INFO: \u001b[0mEpoch 199 Step 300/351 lr 0.001000 loss 1.3348 (1.3505) acc@1 0.5156 (0.4830) acc@5 0.7422 (0.7545)\n",
      "\u001b[32m[2020-06-22 18:20:50] __main__ INFO: \u001b[0mEpoch 199 Step 351/351 lr 0.001000 loss 1.3328 (1.3492) acc@1 0.5625 (0.4837) acc@5 0.7969 (0.7555)\n",
      "\u001b[32m[2020-06-22 18:20:50] __main__ INFO: \u001b[0mElapsed 32.83\n",
      "\u001b[32m[2020-06-22 18:20:50] __main__ INFO: \u001b[0mVal 199\n",
      "\u001b[32m[2020-06-22 18:20:51] __main__ INFO: \u001b[0mEpoch 199 loss 2.3182 acc@1 0.2944 acc@5 0.6876\n",
      "\u001b[32m[2020-06-22 18:20:51] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:20:51] __main__ INFO: \u001b[0mTrain 200 69849\n",
      "\u001b[32m[2020-06-22 18:21:00] __main__ INFO: \u001b[0mEpoch 200 Step 100/351 lr 0.001000 loss 1.2725 (1.3326) acc@1 0.5312 (0.4894) acc@5 0.7812 (0.7599)\n",
      "\u001b[32m[2020-06-22 18:21:10] __main__ INFO: \u001b[0mEpoch 200 Step 200/351 lr 0.001000 loss 1.3479 (1.3418) acc@1 0.4844 (0.4860) acc@5 0.7656 (0.7584)\n",
      "\u001b[32m[2020-06-22 18:21:19] __main__ INFO: \u001b[0mEpoch 200 Step 300/351 lr 0.001000 loss 1.4185 (1.3485) acc@1 0.4141 (0.4849) acc@5 0.7344 (0.7565)\n",
      "\u001b[32m[2020-06-22 18:21:24] __main__ INFO: \u001b[0mEpoch 200 Step 351/351 lr 0.001000 loss 1.2952 (1.3487) acc@1 0.5156 (0.4846) acc@5 0.7500 (0.7559)\n",
      "\u001b[32m[2020-06-22 18:21:24] __main__ INFO: \u001b[0mElapsed 32.78\n",
      "\u001b[32m[2020-06-22 18:21:24] __main__ INFO: \u001b[0mVal 200\n",
      "\u001b[32m[2020-06-22 18:21:25] __main__ INFO: \u001b[0mEpoch 200 loss 2.3184 acc@1 0.2860 acc@5 0.6898\n",
      "\u001b[32m[2020-06-22 18:21:25] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 18:21:25] fvcore.common.checkpoint INFO: \u001b[0mSaving checkpoint to /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00/checkpoint_00200.pth\n",
      "\u001b[32m[2020-06-22 18:21:25] __main__ INFO: \u001b[0mTrain 201 70200\n",
      "\u001b[32m[2020-06-22 18:21:34] __main__ INFO: \u001b[0mEpoch 201 Step 100/351 lr 0.001000 loss 1.3164 (1.3621) acc@1 0.5312 (0.4800) acc@5 0.7812 (0.7514)\n",
      "\u001b[32m[2020-06-22 18:21:44] __main__ INFO: \u001b[0mEpoch 201 Step 200/351 lr 0.001000 loss 1.3124 (1.3542) acc@1 0.5234 (0.4818) acc@5 0.7500 (0.7520)\n",
      "\u001b[32m[2020-06-22 18:21:53] __main__ INFO: \u001b[0mEpoch 201 Step 300/351 lr 0.001000 loss 1.3404 (1.3457) acc@1 0.5078 (0.4844) acc@5 0.7969 (0.7544)\n",
      "\u001b[32m[2020-06-22 18:21:58] __main__ INFO: \u001b[0mEpoch 201 Step 351/351 lr 0.001000 loss 1.4334 (1.3458) acc@1 0.4219 (0.4845) acc@5 0.7344 (0.7547)\n",
      "\u001b[32m[2020-06-22 18:21:58] __main__ INFO: \u001b[0mElapsed 32.83\n",
      "\u001b[32m[2020-06-22 18:21:58] __main__ INFO: \u001b[0mVal 201\n",
      "\u001b[32m[2020-06-22 18:21:59] __main__ INFO: \u001b[0mEpoch 201 loss 2.3314 acc@1 0.2904 acc@5 0.6958\n",
      "\u001b[32m[2020-06-22 18:21:59] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 18:21:59] __main__ INFO: \u001b[0mTrain 202 70551\n",
      "\u001b[32m[2020-06-22 18:22:08] __main__ INFO: \u001b[0mEpoch 202 Step 100/351 lr 0.001000 loss 1.3263 (1.3407) acc@1 0.4688 (0.4870) acc@5 0.7109 (0.7527)\n",
      "\u001b[32m[2020-06-22 18:22:17] __main__ INFO: \u001b[0mEpoch 202 Step 200/351 lr 0.001000 loss 1.3385 (1.3503) acc@1 0.5156 (0.4837) acc@5 0.7422 (0.7531)\n",
      "\u001b[32m[2020-06-22 18:22:27] __main__ INFO: \u001b[0mEpoch 202 Step 300/351 lr 0.001000 loss 1.4399 (1.3458) acc@1 0.4688 (0.4853) acc@5 0.7812 (0.7547)\n",
      "\u001b[32m[2020-06-22 18:22:31] __main__ INFO: \u001b[0mEpoch 202 Step 351/351 lr 0.001000 loss 1.5672 (1.3458) acc@1 0.3828 (0.4847) acc@5 0.7656 (0.7555)\n",
      "\u001b[32m[2020-06-22 18:22:31] __main__ INFO: \u001b[0mElapsed 32.78\n",
      "\u001b[32m[2020-06-22 18:22:31] __main__ INFO: \u001b[0mVal 202\n",
      "\u001b[32m[2020-06-22 18:22:33] __main__ INFO: \u001b[0mEpoch 202 loss 2.3562 acc@1 0.2906 acc@5 0.6882\n",
      "\u001b[32m[2020-06-22 18:22:33] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 18:22:33] __main__ INFO: \u001b[0mTrain 203 70902\n",
      "\u001b[32m[2020-06-22 18:22:42] __main__ INFO: \u001b[0mEpoch 203 Step 100/351 lr 0.001000 loss 1.2153 (1.3366) acc@1 0.5547 (0.4852) acc@5 0.8984 (0.7523)\n",
      "\u001b[32m[2020-06-22 18:22:51] __main__ INFO: \u001b[0mEpoch 203 Step 200/351 lr 0.001000 loss 1.2032 (1.3332) acc@1 0.5469 (0.4898) acc@5 0.8125 (0.7571)\n",
      "\u001b[32m[2020-06-22 18:23:01] __main__ INFO: \u001b[0mEpoch 203 Step 300/351 lr 0.001000 loss 1.1989 (1.3415) acc@1 0.5469 (0.4860) acc@5 0.8047 (0.7561)\n",
      "\u001b[32m[2020-06-22 18:23:05] __main__ INFO: \u001b[0mEpoch 203 Step 351/351 lr 0.001000 loss 1.3277 (1.3451) acc@1 0.5078 (0.4843) acc@5 0.8203 (0.7547)\n",
      "\u001b[32m[2020-06-22 18:23:05] __main__ INFO: \u001b[0mElapsed 32.75\n",
      "\u001b[32m[2020-06-22 18:23:05] __main__ INFO: \u001b[0mVal 203\n",
      "\u001b[32m[2020-06-22 18:23:06] __main__ INFO: \u001b[0mEpoch 203 loss 2.3642 acc@1 0.2932 acc@5 0.6884\n",
      "\u001b[32m[2020-06-22 18:23:06] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 18:23:06] __main__ INFO: \u001b[0mTrain 204 71253\n",
      "\u001b[32m[2020-06-22 18:23:16] __main__ INFO: \u001b[0mEpoch 204 Step 100/351 lr 0.001000 loss 1.1671 (1.3413) acc@1 0.5625 (0.4873) acc@5 0.8359 (0.7562)\n",
      "\u001b[32m[2020-06-22 18:23:25] __main__ INFO: \u001b[0mEpoch 204 Step 200/351 lr 0.001000 loss 1.1948 (1.3338) acc@1 0.5391 (0.4911) acc@5 0.7891 (0.7578)\n",
      "\u001b[32m[2020-06-22 18:23:34] __main__ INFO: \u001b[0mEpoch 204 Step 300/351 lr 0.001000 loss 1.3367 (1.3379) acc@1 0.5078 (0.4890) acc@5 0.7891 (0.7571)\n",
      "\u001b[32m[2020-06-22 18:23:39] __main__ INFO: \u001b[0mEpoch 204 Step 351/351 lr 0.001000 loss 1.3718 (1.3408) acc@1 0.4609 (0.4873) acc@5 0.7109 (0.7553)\n",
      "\u001b[32m[2020-06-22 18:23:39] __main__ INFO: \u001b[0mElapsed 32.82\n",
      "\u001b[32m[2020-06-22 18:23:39] __main__ INFO: \u001b[0mVal 204\n",
      "\u001b[32m[2020-06-22 18:23:40] __main__ INFO: \u001b[0mEpoch 204 loss 2.3491 acc@1 0.2902 acc@5 0.6900\n",
      "\u001b[32m[2020-06-22 18:23:40] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 18:23:40] __main__ INFO: \u001b[0mTrain 205 71604\n",
      "\u001b[32m[2020-06-22 18:23:50] __main__ INFO: \u001b[0mEpoch 205 Step 100/351 lr 0.001000 loss 1.2424 (1.3428) acc@1 0.5391 (0.4855) acc@5 0.7578 (0.7543)\n",
      "\u001b[32m[2020-06-22 18:23:59] __main__ INFO: \u001b[0mEpoch 205 Step 200/351 lr 0.001000 loss 1.3073 (1.3392) acc@1 0.4609 (0.4872) acc@5 0.7500 (0.7570)\n",
      "\u001b[32m[2020-06-22 18:24:08] __main__ INFO: \u001b[0mEpoch 205 Step 300/351 lr 0.001000 loss 1.2913 (1.3436) acc@1 0.5156 (0.4860) acc@5 0.7109 (0.7560)\n",
      "\u001b[32m[2020-06-22 18:24:13] __main__ INFO: \u001b[0mEpoch 205 Step 351/351 lr 0.001000 loss 1.3536 (1.3430) acc@1 0.4297 (0.4866) acc@5 0.7500 (0.7568)\n",
      "\u001b[32m[2020-06-22 18:24:13] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 18:24:13] __main__ INFO: \u001b[0mVal 205\n",
      "\u001b[32m[2020-06-22 18:24:14] __main__ INFO: \u001b[0mEpoch 205 loss 2.3440 acc@1 0.2918 acc@5 0.6924\n",
      "\u001b[32m[2020-06-22 18:24:14] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 18:24:14] __main__ INFO: \u001b[0mTrain 206 71955\n",
      "\u001b[32m[2020-06-22 18:24:24] __main__ INFO: \u001b[0mEpoch 206 Step 100/351 lr 0.001000 loss 1.4172 (1.3342) acc@1 0.4297 (0.4879) acc@5 0.7422 (0.7567)\n",
      "\u001b[32m[2020-06-22 18:24:33] __main__ INFO: \u001b[0mEpoch 206 Step 200/351 lr 0.001000 loss 1.2441 (1.3367) acc@1 0.5234 (0.4877) acc@5 0.8125 (0.7568)\n",
      "\u001b[32m[2020-06-22 18:24:42] __main__ INFO: \u001b[0mEpoch 206 Step 300/351 lr 0.001000 loss 1.4271 (1.3433) acc@1 0.4453 (0.4851) acc@5 0.7578 (0.7558)\n",
      "\u001b[32m[2020-06-22 18:24:47] __main__ INFO: \u001b[0mEpoch 206 Step 351/351 lr 0.001000 loss 1.1619 (1.3435) acc@1 0.5625 (0.4853) acc@5 0.8203 (0.7557)\n",
      "\u001b[32m[2020-06-22 18:24:47] __main__ INFO: \u001b[0mElapsed 32.82\n",
      "\u001b[32m[2020-06-22 18:24:47] __main__ INFO: \u001b[0mVal 206\n",
      "\u001b[32m[2020-06-22 18:24:48] __main__ INFO: \u001b[0mEpoch 206 loss 2.3546 acc@1 0.2838 acc@5 0.6880\n",
      "\u001b[32m[2020-06-22 18:24:48] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:24:48] __main__ INFO: \u001b[0mTrain 207 72306\n",
      "\u001b[32m[2020-06-22 18:24:57] __main__ INFO: \u001b[0mEpoch 207 Step 100/351 lr 0.001000 loss 1.1880 (1.3441) acc@1 0.5312 (0.4898) acc@5 0.7578 (0.7573)\n",
      "\u001b[32m[2020-06-22 18:25:07] __main__ INFO: \u001b[0mEpoch 207 Step 200/351 lr 0.001000 loss 1.4757 (1.3482) acc@1 0.4219 (0.4848) acc@5 0.7812 (0.7570)\n",
      "\u001b[32m[2020-06-22 18:25:16] __main__ INFO: \u001b[0mEpoch 207 Step 300/351 lr 0.001000 loss 1.3454 (1.3454) acc@1 0.4766 (0.4857) acc@5 0.7578 (0.7562)\n",
      "\u001b[32m[2020-06-22 18:25:21] __main__ INFO: \u001b[0mEpoch 207 Step 351/351 lr 0.001000 loss 1.4163 (1.3438) acc@1 0.4375 (0.4858) acc@5 0.7109 (0.7557)\n",
      "\u001b[32m[2020-06-22 18:25:21] __main__ INFO: \u001b[0mElapsed 32.75\n",
      "\u001b[32m[2020-06-22 18:25:21] __main__ INFO: \u001b[0mVal 207\n",
      "\u001b[32m[2020-06-22 18:25:22] __main__ INFO: \u001b[0mEpoch 207 loss 2.3744 acc@1 0.2922 acc@5 0.6882\n",
      "\u001b[32m[2020-06-22 18:25:22] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 18:25:22] __main__ INFO: \u001b[0mTrain 208 72657\n",
      "\u001b[32m[2020-06-22 18:25:31] __main__ INFO: \u001b[0mEpoch 208 Step 100/351 lr 0.001000 loss 1.3200 (1.3404) acc@1 0.5234 (0.4884) acc@5 0.7578 (0.7581)\n",
      "\u001b[32m[2020-06-22 18:25:40] __main__ INFO: \u001b[0mEpoch 208 Step 200/351 lr 0.001000 loss 1.5302 (1.3427) acc@1 0.3828 (0.4840) acc@5 0.7188 (0.7553)\n",
      "\u001b[32m[2020-06-22 18:25:50] __main__ INFO: \u001b[0mEpoch 208 Step 300/351 lr 0.001000 loss 1.2701 (1.3399) acc@1 0.5234 (0.4852) acc@5 0.7188 (0.7554)\n",
      "\u001b[32m[2020-06-22 18:25:54] __main__ INFO: \u001b[0mEpoch 208 Step 351/351 lr 0.001000 loss 1.4003 (1.3394) acc@1 0.4531 (0.4855) acc@5 0.7031 (0.7561)\n",
      "\u001b[32m[2020-06-22 18:25:55] __main__ INFO: \u001b[0mElapsed 32.75\n",
      "\u001b[32m[2020-06-22 18:25:55] __main__ INFO: \u001b[0mVal 208\n",
      "\u001b[32m[2020-06-22 18:25:56] __main__ INFO: \u001b[0mEpoch 208 loss 2.3506 acc@1 0.2922 acc@5 0.6952\n",
      "\u001b[32m[2020-06-22 18:25:56] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:25:56] __main__ INFO: \u001b[0mTrain 209 73008\n",
      "\u001b[32m[2020-06-22 18:26:05] __main__ INFO: \u001b[0mEpoch 209 Step 100/351 lr 0.001000 loss 1.2508 (1.3317) acc@1 0.5078 (0.4876) acc@5 0.7266 (0.7580)\n",
      "\u001b[32m[2020-06-22 18:26:14] __main__ INFO: \u001b[0mEpoch 209 Step 200/351 lr 0.001000 loss 1.3349 (1.3400) acc@1 0.5234 (0.4852) acc@5 0.8281 (0.7550)\n",
      "\u001b[32m[2020-06-22 18:26:24] __main__ INFO: \u001b[0mEpoch 209 Step 300/351 lr 0.001000 loss 1.1508 (1.3383) acc@1 0.5547 (0.4870) acc@5 0.7812 (0.7569)\n",
      "\u001b[32m[2020-06-22 18:26:28] __main__ INFO: \u001b[0mEpoch 209 Step 351/351 lr 0.001000 loss 1.4973 (1.3412) acc@1 0.4531 (0.4858) acc@5 0.6953 (0.7559)\n",
      "\u001b[32m[2020-06-22 18:26:28] __main__ INFO: \u001b[0mElapsed 32.81\n",
      "\u001b[32m[2020-06-22 18:26:28] __main__ INFO: \u001b[0mVal 209\n",
      "\u001b[32m[2020-06-22 18:26:29] __main__ INFO: \u001b[0mEpoch 209 loss 2.3700 acc@1 0.2928 acc@5 0.6966\n",
      "\u001b[32m[2020-06-22 18:26:29] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:26:29] __main__ INFO: \u001b[0mTrain 210 73359\n",
      "\u001b[32m[2020-06-22 18:26:39] __main__ INFO: \u001b[0mEpoch 210 Step 100/351 lr 0.001000 loss 1.3138 (1.3361) acc@1 0.4609 (0.4875) acc@5 0.7656 (0.7577)\n",
      "\u001b[32m[2020-06-22 18:26:48] __main__ INFO: \u001b[0mEpoch 210 Step 200/351 lr 0.001000 loss 1.1648 (1.3380) acc@1 0.5938 (0.4871) acc@5 0.8281 (0.7582)\n",
      "\u001b[32m[2020-06-22 18:26:58] __main__ INFO: \u001b[0mEpoch 210 Step 300/351 lr 0.001000 loss 1.2583 (1.3375) acc@1 0.5156 (0.4878) acc@5 0.7812 (0.7566)\n",
      "\u001b[32m[2020-06-22 18:27:02] __main__ INFO: \u001b[0mEpoch 210 Step 351/351 lr 0.001000 loss 1.2359 (1.3399) acc@1 0.5234 (0.4869) acc@5 0.8047 (0.7561)\n",
      "\u001b[32m[2020-06-22 18:27:02] __main__ INFO: \u001b[0mElapsed 32.83\n",
      "\u001b[32m[2020-06-22 18:27:02] __main__ INFO: \u001b[0mVal 210\n",
      "\u001b[32m[2020-06-22 18:27:03] __main__ INFO: \u001b[0mEpoch 210 loss 2.3842 acc@1 0.2838 acc@5 0.6880\n",
      "\u001b[32m[2020-06-22 18:27:03] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 18:27:03] __main__ INFO: \u001b[0mTrain 211 73710\n",
      "\u001b[32m[2020-06-22 18:27:13] __main__ INFO: \u001b[0mEpoch 211 Step 100/351 lr 0.001000 loss 1.4778 (1.3532) acc@1 0.4219 (0.4808) acc@5 0.7188 (0.7509)\n",
      "\u001b[32m[2020-06-22 18:27:22] __main__ INFO: \u001b[0mEpoch 211 Step 200/351 lr 0.001000 loss 1.2591 (1.3413) acc@1 0.4922 (0.4846) acc@5 0.7578 (0.7536)\n",
      "\u001b[32m[2020-06-22 18:27:31] __main__ INFO: \u001b[0mEpoch 211 Step 300/351 lr 0.001000 loss 1.2913 (1.3391) acc@1 0.5000 (0.4854) acc@5 0.7266 (0.7529)\n",
      "\u001b[32m[2020-06-22 18:27:36] __main__ INFO: \u001b[0mEpoch 211 Step 351/351 lr 0.001000 loss 1.3315 (1.3381) acc@1 0.5547 (0.4862) acc@5 0.7969 (0.7537)\n",
      "\u001b[32m[2020-06-22 18:27:36] __main__ INFO: \u001b[0mElapsed 32.82\n",
      "\u001b[32m[2020-06-22 18:27:36] __main__ INFO: \u001b[0mVal 211\n",
      "\u001b[32m[2020-06-22 18:27:37] __main__ INFO: \u001b[0mEpoch 211 loss 2.3436 acc@1 0.2816 acc@5 0.6908\n",
      "\u001b[32m[2020-06-22 18:27:37] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 18:27:37] __main__ INFO: \u001b[0mTrain 212 74061\n",
      "\u001b[32m[2020-06-22 18:27:47] __main__ INFO: \u001b[0mEpoch 212 Step 100/351 lr 0.001000 loss 1.3761 (1.3368) acc@1 0.4766 (0.4857) acc@5 0.7578 (0.7565)\n",
      "\u001b[32m[2020-06-22 18:27:56] __main__ INFO: \u001b[0mEpoch 212 Step 200/351 lr 0.001000 loss 1.3036 (1.3398) acc@1 0.4766 (0.4861) acc@5 0.7422 (0.7563)\n",
      "\u001b[32m[2020-06-22 18:28:05] __main__ INFO: \u001b[0mEpoch 212 Step 300/351 lr 0.001000 loss 1.4152 (1.3401) acc@1 0.4609 (0.4875) acc@5 0.7578 (0.7566)\n",
      "\u001b[32m[2020-06-22 18:28:10] __main__ INFO: \u001b[0mEpoch 212 Step 351/351 lr 0.001000 loss 1.2344 (1.3406) acc@1 0.5156 (0.4871) acc@5 0.7500 (0.7567)\n",
      "\u001b[32m[2020-06-22 18:28:10] __main__ INFO: \u001b[0mElapsed 32.82\n",
      "\u001b[32m[2020-06-22 18:28:10] __main__ INFO: \u001b[0mVal 212\n",
      "\u001b[32m[2020-06-22 18:28:11] __main__ INFO: \u001b[0mEpoch 212 loss 2.3593 acc@1 0.2906 acc@5 0.6890\n",
      "\u001b[32m[2020-06-22 18:28:11] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:28:11] __main__ INFO: \u001b[0mTrain 213 74412\n",
      "\u001b[32m[2020-06-22 18:28:21] __main__ INFO: \u001b[0mEpoch 213 Step 100/351 lr 0.001000 loss 1.3267 (1.3326) acc@1 0.4688 (0.4886) acc@5 0.7734 (0.7523)\n",
      "\u001b[32m[2020-06-22 18:28:30] __main__ INFO: \u001b[0mEpoch 213 Step 200/351 lr 0.001000 loss 1.3261 (1.3298) acc@1 0.4453 (0.4885) acc@5 0.7422 (0.7544)\n",
      "\u001b[32m[2020-06-22 18:28:39] __main__ INFO: \u001b[0mEpoch 213 Step 300/351 lr 0.001000 loss 1.1943 (1.3354) acc@1 0.5625 (0.4882) acc@5 0.7656 (0.7553)\n",
      "\u001b[32m[2020-06-22 18:28:44] __main__ INFO: \u001b[0mEpoch 213 Step 351/351 lr 0.001000 loss 1.3045 (1.3368) acc@1 0.4844 (0.4871) acc@5 0.7891 (0.7553)\n",
      "\u001b[32m[2020-06-22 18:28:44] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 18:28:44] __main__ INFO: \u001b[0mVal 213\n",
      "\u001b[32m[2020-06-22 18:28:45] __main__ INFO: \u001b[0mEpoch 213 loss 2.3729 acc@1 0.2910 acc@5 0.6862\n",
      "\u001b[32m[2020-06-22 18:28:45] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 18:28:45] __main__ INFO: \u001b[0mTrain 214 74763\n",
      "\u001b[32m[2020-06-22 18:28:54] __main__ INFO: \u001b[0mEpoch 214 Step 100/351 lr 0.001000 loss 1.3182 (1.3181) acc@1 0.4688 (0.4941) acc@5 0.7500 (0.7594)\n",
      "\u001b[32m[2020-06-22 18:29:04] __main__ INFO: \u001b[0mEpoch 214 Step 200/351 lr 0.001000 loss 1.4106 (1.3237) acc@1 0.4609 (0.4927) acc@5 0.7656 (0.7564)\n",
      "\u001b[32m[2020-06-22 18:29:13] __main__ INFO: \u001b[0mEpoch 214 Step 300/351 lr 0.001000 loss 1.3179 (1.3322) acc@1 0.4766 (0.4892) acc@5 0.7422 (0.7544)\n",
      "\u001b[32m[2020-06-22 18:29:18] __main__ INFO: \u001b[0mEpoch 214 Step 351/351 lr 0.001000 loss 1.2289 (1.3348) acc@1 0.5078 (0.4879) acc@5 0.7734 (0.7541)\n",
      "\u001b[32m[2020-06-22 18:29:18] __main__ INFO: \u001b[0mElapsed 32.82\n",
      "\u001b[32m[2020-06-22 18:29:18] __main__ INFO: \u001b[0mVal 214\n",
      "\u001b[32m[2020-06-22 18:29:19] __main__ INFO: \u001b[0mEpoch 214 loss 2.3744 acc@1 0.2914 acc@5 0.6868\n",
      "\u001b[32m[2020-06-22 18:29:19] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 18:29:19] __main__ INFO: \u001b[0mTrain 215 75114\n",
      "\u001b[32m[2020-06-22 18:29:28] __main__ INFO: \u001b[0mEpoch 215 Step 100/351 lr 0.001000 loss 1.3128 (1.3392) acc@1 0.4844 (0.4891) acc@5 0.7578 (0.7590)\n",
      "\u001b[32m[2020-06-22 18:29:38] __main__ INFO: \u001b[0mEpoch 215 Step 200/351 lr 0.001000 loss 1.3369 (1.3389) acc@1 0.4922 (0.4878) acc@5 0.8047 (0.7584)\n",
      "\u001b[32m[2020-06-22 18:29:47] __main__ INFO: \u001b[0mEpoch 215 Step 300/351 lr 0.001000 loss 1.3300 (1.3388) acc@1 0.5078 (0.4874) acc@5 0.7109 (0.7559)\n",
      "\u001b[32m[2020-06-22 18:29:52] __main__ INFO: \u001b[0mEpoch 215 Step 351/351 lr 0.001000 loss 1.2180 (1.3393) acc@1 0.5312 (0.4872) acc@5 0.7656 (0.7546)\n",
      "\u001b[32m[2020-06-22 18:29:52] __main__ INFO: \u001b[0mElapsed 32.81\n",
      "\u001b[32m[2020-06-22 18:29:52] __main__ INFO: \u001b[0mVal 215\n",
      "\u001b[32m[2020-06-22 18:29:53] __main__ INFO: \u001b[0mEpoch 215 loss 2.3645 acc@1 0.2894 acc@5 0.7000\n",
      "\u001b[32m[2020-06-22 18:29:53] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 18:29:53] __main__ INFO: \u001b[0mTrain 216 75465\n",
      "\u001b[32m[2020-06-22 18:30:02] __main__ INFO: \u001b[0mEpoch 216 Step 100/351 lr 0.001000 loss 1.4614 (1.3494) acc@1 0.3906 (0.4834) acc@5 0.7891 (0.7552)\n",
      "\u001b[32m[2020-06-22 18:30:11] __main__ INFO: \u001b[0mEpoch 216 Step 200/351 lr 0.001000 loss 1.3529 (1.3375) acc@1 0.4844 (0.4880) acc@5 0.7578 (0.7572)\n",
      "\u001b[32m[2020-06-22 18:30:21] __main__ INFO: \u001b[0mEpoch 216 Step 300/351 lr 0.001000 loss 1.2793 (1.3415) acc@1 0.5312 (0.4871) acc@5 0.7891 (0.7538)\n",
      "\u001b[32m[2020-06-22 18:30:25] __main__ INFO: \u001b[0mEpoch 216 Step 351/351 lr 0.001000 loss 1.3251 (1.3382) acc@1 0.5078 (0.4881) acc@5 0.7578 (0.7554)\n",
      "\u001b[32m[2020-06-22 18:30:26] __main__ INFO: \u001b[0mElapsed 32.76\n",
      "\u001b[32m[2020-06-22 18:30:26] __main__ INFO: \u001b[0mVal 216\n",
      "\u001b[32m[2020-06-22 18:30:27] __main__ INFO: \u001b[0mEpoch 216 loss 2.3824 acc@1 0.2930 acc@5 0.6892\n",
      "\u001b[32m[2020-06-22 18:30:27] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:30:27] __main__ INFO: \u001b[0mTrain 217 75816\n",
      "\u001b[32m[2020-06-22 18:30:36] __main__ INFO: \u001b[0mEpoch 217 Step 100/351 lr 0.001000 loss 1.3743 (1.3247) acc@1 0.5156 (0.4953) acc@5 0.7734 (0.7585)\n",
      "\u001b[32m[2020-06-22 18:30:45] __main__ INFO: \u001b[0mEpoch 217 Step 200/351 lr 0.001000 loss 1.2035 (1.3290) acc@1 0.5547 (0.4939) acc@5 0.7422 (0.7589)\n",
      "\u001b[32m[2020-06-22 18:30:55] __main__ INFO: \u001b[0mEpoch 217 Step 300/351 lr 0.001000 loss 1.3262 (1.3302) acc@1 0.4844 (0.4923) acc@5 0.6719 (0.7563)\n",
      "\u001b[32m[2020-06-22 18:30:59] __main__ INFO: \u001b[0mEpoch 217 Step 351/351 lr 0.001000 loss 1.3980 (1.3324) acc@1 0.4766 (0.4906) acc@5 0.7109 (0.7546)\n",
      "\u001b[32m[2020-06-22 18:30:59] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 18:30:59] __main__ INFO: \u001b[0mVal 217\n",
      "\u001b[32m[2020-06-22 18:31:00] __main__ INFO: \u001b[0mEpoch 217 loss 2.3965 acc@1 0.2924 acc@5 0.6892\n",
      "\u001b[32m[2020-06-22 18:31:00] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:31:00] __main__ INFO: \u001b[0mTrain 218 76167\n",
      "\u001b[32m[2020-06-22 18:31:10] __main__ INFO: \u001b[0mEpoch 218 Step 100/351 lr 0.001000 loss 1.2984 (1.3299) acc@1 0.5156 (0.4898) acc@5 0.8125 (0.7605)\n",
      "\u001b[32m[2020-06-22 18:31:19] __main__ INFO: \u001b[0mEpoch 218 Step 200/351 lr 0.001000 loss 1.3659 (1.3337) acc@1 0.5000 (0.4877) acc@5 0.7500 (0.7592)\n",
      "\u001b[32m[2020-06-22 18:31:28] __main__ INFO: \u001b[0mEpoch 218 Step 300/351 lr 0.001000 loss 1.3248 (1.3324) acc@1 0.5234 (0.4895) acc@5 0.7578 (0.7592)\n",
      "\u001b[32m[2020-06-22 18:31:33] __main__ INFO: \u001b[0mEpoch 218 Step 351/351 lr 0.001000 loss 1.2986 (1.3317) acc@1 0.5078 (0.4895) acc@5 0.7656 (0.7594)\n",
      "\u001b[32m[2020-06-22 18:31:33] __main__ INFO: \u001b[0mElapsed 32.78\n",
      "\u001b[32m[2020-06-22 18:31:33] __main__ INFO: \u001b[0mVal 218\n",
      "\u001b[32m[2020-06-22 18:31:34] __main__ INFO: \u001b[0mEpoch 218 loss 2.3774 acc@1 0.2910 acc@5 0.6884\n",
      "\u001b[32m[2020-06-22 18:31:34] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 18:31:34] __main__ INFO: \u001b[0mTrain 219 76518\n",
      "\u001b[32m[2020-06-22 18:31:44] __main__ INFO: \u001b[0mEpoch 219 Step 100/351 lr 0.001000 loss 1.4542 (1.3305) acc@1 0.4453 (0.4901) acc@5 0.6953 (0.7560)\n",
      "\u001b[32m[2020-06-22 18:31:53] __main__ INFO: \u001b[0mEpoch 219 Step 200/351 lr 0.001000 loss 1.4256 (1.3262) acc@1 0.4531 (0.4927) acc@5 0.6953 (0.7573)\n",
      "\u001b[32m[2020-06-22 18:32:02] __main__ INFO: \u001b[0mEpoch 219 Step 300/351 lr 0.001000 loss 1.4303 (1.3356) acc@1 0.4531 (0.4884) acc@5 0.7891 (0.7567)\n",
      "\u001b[32m[2020-06-22 18:32:07] __main__ INFO: \u001b[0mEpoch 219 Step 351/351 lr 0.001000 loss 1.3705 (1.3353) acc@1 0.4688 (0.4887) acc@5 0.7109 (0.7570)\n",
      "\u001b[32m[2020-06-22 18:32:07] __main__ INFO: \u001b[0mElapsed 32.75\n",
      "\u001b[32m[2020-06-22 18:32:07] __main__ INFO: \u001b[0mVal 219\n",
      "\u001b[32m[2020-06-22 18:32:08] __main__ INFO: \u001b[0mEpoch 219 loss 2.3835 acc@1 0.2900 acc@5 0.7082\n",
      "\u001b[32m[2020-06-22 18:32:08] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:32:08] __main__ INFO: \u001b[0mTrain 220 76869\n",
      "\u001b[32m[2020-06-22 18:32:17] __main__ INFO: \u001b[0mEpoch 220 Step 100/351 lr 0.001000 loss 1.5129 (1.3322) acc@1 0.3984 (0.4930) acc@5 0.7266 (0.7559)\n",
      "\u001b[32m[2020-06-22 18:32:27] __main__ INFO: \u001b[0mEpoch 220 Step 200/351 lr 0.001000 loss 1.2284 (1.3265) acc@1 0.5469 (0.4941) acc@5 0.7734 (0.7585)\n",
      "\u001b[32m[2020-06-22 18:32:36] __main__ INFO: \u001b[0mEpoch 220 Step 300/351 lr 0.001000 loss 1.3586 (1.3311) acc@1 0.4766 (0.4905) acc@5 0.7578 (0.7564)\n",
      "\u001b[32m[2020-06-22 18:32:41] __main__ INFO: \u001b[0mEpoch 220 Step 351/351 lr 0.001000 loss 1.3624 (1.3292) acc@1 0.5000 (0.4915) acc@5 0.7266 (0.7561)\n",
      "\u001b[32m[2020-06-22 18:32:41] __main__ INFO: \u001b[0mElapsed 32.81\n",
      "\u001b[32m[2020-06-22 18:32:41] __main__ INFO: \u001b[0mVal 220\n",
      "\u001b[32m[2020-06-22 18:32:42] __main__ INFO: \u001b[0mEpoch 220 loss 2.3706 acc@1 0.2918 acc@5 0.6902\n",
      "\u001b[32m[2020-06-22 18:32:42] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 18:32:42] __main__ INFO: \u001b[0mTrain 221 77220\n",
      "\u001b[32m[2020-06-22 18:32:51] __main__ INFO: \u001b[0mEpoch 221 Step 100/351 lr 0.001000 loss 1.2233 (1.3267) acc@1 0.5391 (0.4920) acc@5 0.8203 (0.7561)\n",
      "\u001b[32m[2020-06-22 18:33:01] __main__ INFO: \u001b[0mEpoch 221 Step 200/351 lr 0.001000 loss 1.3618 (1.3234) acc@1 0.4922 (0.4941) acc@5 0.7578 (0.7562)\n",
      "\u001b[32m[2020-06-22 18:33:10] __main__ INFO: \u001b[0mEpoch 221 Step 300/351 lr 0.001000 loss 1.2692 (1.3255) acc@1 0.5469 (0.4924) acc@5 0.7656 (0.7557)\n",
      "\u001b[32m[2020-06-22 18:33:15] __main__ INFO: \u001b[0mEpoch 221 Step 351/351 lr 0.001000 loss 1.3730 (1.3269) acc@1 0.4688 (0.4927) acc@5 0.7188 (0.7564)\n",
      "\u001b[32m[2020-06-22 18:33:15] __main__ INFO: \u001b[0mElapsed 32.77\n",
      "\u001b[32m[2020-06-22 18:33:15] __main__ INFO: \u001b[0mVal 221\n",
      "\u001b[32m[2020-06-22 18:33:16] __main__ INFO: \u001b[0mEpoch 221 loss 2.3867 acc@1 0.2956 acc@5 0.6950\n",
      "\u001b[32m[2020-06-22 18:33:16] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:33:16] __main__ INFO: \u001b[0mTrain 222 77571\n",
      "\u001b[32m[2020-06-22 18:33:25] __main__ INFO: \u001b[0mEpoch 222 Step 100/351 lr 0.001000 loss 1.3261 (1.3288) acc@1 0.4453 (0.4903) acc@5 0.7188 (0.7523)\n",
      "\u001b[32m[2020-06-22 18:33:35] __main__ INFO: \u001b[0mEpoch 222 Step 200/351 lr 0.001000 loss 1.2545 (1.3177) acc@1 0.5312 (0.4956) acc@5 0.8125 (0.7576)\n",
      "\u001b[32m[2020-06-22 18:33:44] __main__ INFO: \u001b[0mEpoch 222 Step 300/351 lr 0.001000 loss 1.3192 (1.3281) acc@1 0.5156 (0.4913) acc@5 0.7188 (0.7560)\n",
      "\u001b[32m[2020-06-22 18:33:49] __main__ INFO: \u001b[0mEpoch 222 Step 351/351 lr 0.001000 loss 1.2836 (1.3278) acc@1 0.5000 (0.4910) acc@5 0.8281 (0.7557)\n",
      "\u001b[32m[2020-06-22 18:33:49] __main__ INFO: \u001b[0mElapsed 32.82\n",
      "\u001b[32m[2020-06-22 18:33:49] __main__ INFO: \u001b[0mVal 222\n",
      "\u001b[32m[2020-06-22 18:33:50] __main__ INFO: \u001b[0mEpoch 222 loss 2.3988 acc@1 0.2870 acc@5 0.6872\n",
      "\u001b[32m[2020-06-22 18:33:50] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 18:33:50] __main__ INFO: \u001b[0mTrain 223 77922\n",
      "\u001b[32m[2020-06-22 18:33:59] __main__ INFO: \u001b[0mEpoch 223 Step 100/351 lr 0.001000 loss 1.3658 (1.3352) acc@1 0.5000 (0.4891) acc@5 0.7812 (0.7579)\n",
      "\u001b[32m[2020-06-22 18:34:08] __main__ INFO: \u001b[0mEpoch 223 Step 200/351 lr 0.001000 loss 1.1853 (1.3285) acc@1 0.5391 (0.4911) acc@5 0.7500 (0.7567)\n",
      "\u001b[32m[2020-06-22 18:34:18] __main__ INFO: \u001b[0mEpoch 223 Step 300/351 lr 0.001000 loss 1.2949 (1.3284) acc@1 0.5078 (0.4917) acc@5 0.7891 (0.7558)\n",
      "\u001b[32m[2020-06-22 18:34:22] __main__ INFO: \u001b[0mEpoch 223 Step 351/351 lr 0.001000 loss 1.2499 (1.3293) acc@1 0.5156 (0.4915) acc@5 0.8359 (0.7560)\n",
      "\u001b[32m[2020-06-22 18:34:22] __main__ INFO: \u001b[0mElapsed 32.84\n",
      "\u001b[32m[2020-06-22 18:34:22] __main__ INFO: \u001b[0mVal 223\n",
      "\u001b[32m[2020-06-22 18:34:24] __main__ INFO: \u001b[0mEpoch 223 loss 2.4019 acc@1 0.2930 acc@5 0.6988\n",
      "\u001b[32m[2020-06-22 18:34:24] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 18:34:24] __main__ INFO: \u001b[0mTrain 224 78273\n",
      "\u001b[32m[2020-06-22 18:34:33] __main__ INFO: \u001b[0mEpoch 224 Step 100/351 lr 0.001000 loss 1.3431 (1.3252) acc@1 0.4766 (0.4928) acc@5 0.7656 (0.7591)\n",
      "\u001b[32m[2020-06-22 18:34:42] __main__ INFO: \u001b[0mEpoch 224 Step 200/351 lr 0.001000 loss 1.3598 (1.3283) acc@1 0.4766 (0.4902) acc@5 0.7891 (0.7555)\n",
      "\u001b[32m[2020-06-22 18:34:52] __main__ INFO: \u001b[0mEpoch 224 Step 300/351 lr 0.001000 loss 1.4486 (1.3296) acc@1 0.4453 (0.4894) acc@5 0.7109 (0.7545)\n",
      "\u001b[32m[2020-06-22 18:34:56] __main__ INFO: \u001b[0mEpoch 224 Step 351/351 lr 0.001000 loss 1.4195 (1.3278) acc@1 0.4688 (0.4905) acc@5 0.7578 (0.7556)\n",
      "\u001b[32m[2020-06-22 18:34:56] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 18:34:56] __main__ INFO: \u001b[0mVal 224\n",
      "\u001b[32m[2020-06-22 18:34:57] __main__ INFO: \u001b[0mEpoch 224 loss 2.3937 acc@1 0.2844 acc@5 0.6904\n",
      "\u001b[32m[2020-06-22 18:34:57] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:34:57] __main__ INFO: \u001b[0mTrain 225 78624\n",
      "\u001b[32m[2020-06-22 18:35:07] __main__ INFO: \u001b[0mEpoch 225 Step 100/351 lr 0.001000 loss 1.2397 (1.3200) acc@1 0.5547 (0.4934) acc@5 0.8281 (0.7598)\n",
      "\u001b[32m[2020-06-22 18:35:16] __main__ INFO: \u001b[0mEpoch 225 Step 200/351 lr 0.001000 loss 1.3368 (1.3250) acc@1 0.4688 (0.4915) acc@5 0.7422 (0.7596)\n",
      "\u001b[32m[2020-06-22 18:35:25] __main__ INFO: \u001b[0mEpoch 225 Step 300/351 lr 0.001000 loss 1.3774 (1.3283) acc@1 0.4766 (0.4900) acc@5 0.7812 (0.7580)\n",
      "\u001b[32m[2020-06-22 18:35:30] __main__ INFO: \u001b[0mEpoch 225 Step 351/351 lr 0.001000 loss 1.5308 (1.3271) acc@1 0.4141 (0.4905) acc@5 0.7656 (0.7578)\n",
      "\u001b[32m[2020-06-22 18:35:30] __main__ INFO: \u001b[0mElapsed 32.78\n",
      "\u001b[32m[2020-06-22 18:35:30] __main__ INFO: \u001b[0mVal 225\n",
      "\u001b[32m[2020-06-22 18:35:31] __main__ INFO: \u001b[0mEpoch 225 loss 2.4246 acc@1 0.2922 acc@5 0.6942\n",
      "\u001b[32m[2020-06-22 18:35:31] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 18:35:31] __main__ INFO: \u001b[0mTrain 226 78975\n",
      "\u001b[32m[2020-06-22 18:35:41] __main__ INFO: \u001b[0mEpoch 226 Step 100/351 lr 0.001000 loss 1.1472 (1.3047) acc@1 0.5781 (0.5047) acc@5 0.7891 (0.7592)\n",
      "\u001b[32m[2020-06-22 18:35:50] __main__ INFO: \u001b[0mEpoch 226 Step 200/351 lr 0.001000 loss 1.4510 (1.3191) acc@1 0.4531 (0.4975) acc@5 0.7656 (0.7581)\n",
      "\u001b[32m[2020-06-22 18:35:59] __main__ INFO: \u001b[0mEpoch 226 Step 300/351 lr 0.001000 loss 1.4199 (1.3294) acc@1 0.4688 (0.4914) acc@5 0.7266 (0.7566)\n",
      "\u001b[32m[2020-06-22 18:36:04] __main__ INFO: \u001b[0mEpoch 226 Step 351/351 lr 0.001000 loss 1.2869 (1.3290) acc@1 0.4766 (0.4915) acc@5 0.7500 (0.7564)\n",
      "\u001b[32m[2020-06-22 18:36:04] __main__ INFO: \u001b[0mElapsed 32.77\n",
      "\u001b[32m[2020-06-22 18:36:04] __main__ INFO: \u001b[0mVal 226\n",
      "\u001b[32m[2020-06-22 18:36:05] __main__ INFO: \u001b[0mEpoch 226 loss 2.4033 acc@1 0.2838 acc@5 0.6952\n",
      "\u001b[32m[2020-06-22 18:36:05] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 18:36:05] __main__ INFO: \u001b[0mTrain 227 79326\n",
      "\u001b[32m[2020-06-22 18:36:14] __main__ INFO: \u001b[0mEpoch 227 Step 100/351 lr 0.001000 loss 1.4275 (1.3268) acc@1 0.4297 (0.4932) acc@5 0.6953 (0.7525)\n",
      "\u001b[32m[2020-06-22 18:36:24] __main__ INFO: \u001b[0mEpoch 227 Step 200/351 lr 0.001000 loss 1.4764 (1.3247) acc@1 0.4297 (0.4929) acc@5 0.6719 (0.7507)\n",
      "\u001b[32m[2020-06-22 18:36:33] __main__ INFO: \u001b[0mEpoch 227 Step 300/351 lr 0.001000 loss 1.3988 (1.3218) acc@1 0.4609 (0.4951) acc@5 0.7578 (0.7542)\n",
      "\u001b[32m[2020-06-22 18:36:38] __main__ INFO: \u001b[0mEpoch 227 Step 351/351 lr 0.001000 loss 1.3830 (1.3232) acc@1 0.4844 (0.4942) acc@5 0.7656 (0.7545)\n",
      "\u001b[32m[2020-06-22 18:36:38] __main__ INFO: \u001b[0mElapsed 32.84\n",
      "\u001b[32m[2020-06-22 18:36:38] __main__ INFO: \u001b[0mVal 227\n",
      "\u001b[32m[2020-06-22 18:36:39] __main__ INFO: \u001b[0mEpoch 227 loss 2.4283 acc@1 0.2920 acc@5 0.6894\n",
      "\u001b[32m[2020-06-22 18:36:39] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 18:36:39] __main__ INFO: \u001b[0mTrain 228 79677\n",
      "\u001b[32m[2020-06-22 18:36:48] __main__ INFO: \u001b[0mEpoch 228 Step 100/351 lr 0.001000 loss 1.2363 (1.3296) acc@1 0.5547 (0.4914) acc@5 0.7266 (0.7556)\n",
      "\u001b[32m[2020-06-22 18:36:58] __main__ INFO: \u001b[0mEpoch 228 Step 200/351 lr 0.001000 loss 1.3839 (1.3277) acc@1 0.4844 (0.4932) acc@5 0.7109 (0.7558)\n",
      "\u001b[32m[2020-06-22 18:37:07] __main__ INFO: \u001b[0mEpoch 228 Step 300/351 lr 0.001000 loss 1.3830 (1.3239) acc@1 0.5312 (0.4948) acc@5 0.7891 (0.7572)\n",
      "\u001b[32m[2020-06-22 18:37:12] __main__ INFO: \u001b[0mEpoch 228 Step 351/351 lr 0.001000 loss 1.2510 (1.3263) acc@1 0.5469 (0.4934) acc@5 0.7891 (0.7566)\n",
      "\u001b[32m[2020-06-22 18:37:12] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 18:37:12] __main__ INFO: \u001b[0mVal 228\n",
      "\u001b[32m[2020-06-22 18:37:13] __main__ INFO: \u001b[0mEpoch 228 loss 2.4223 acc@1 0.2822 acc@5 0.6998\n",
      "\u001b[32m[2020-06-22 18:37:13] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:37:13] __main__ INFO: \u001b[0mTrain 229 80028\n",
      "\u001b[32m[2020-06-22 18:37:22] __main__ INFO: \u001b[0mEpoch 229 Step 100/351 lr 0.001000 loss 1.4705 (1.3308) acc@1 0.3984 (0.4881) acc@5 0.7031 (0.7570)\n",
      "\u001b[32m[2020-06-22 18:37:31] __main__ INFO: \u001b[0mEpoch 229 Step 200/351 lr 0.001000 loss 1.3812 (1.3170) acc@1 0.4609 (0.4928) acc@5 0.7500 (0.7578)\n",
      "\u001b[32m[2020-06-22 18:37:41] __main__ INFO: \u001b[0mEpoch 229 Step 300/351 lr 0.001000 loss 1.2996 (1.3224) acc@1 0.5000 (0.4919) acc@5 0.7578 (0.7583)\n",
      "\u001b[32m[2020-06-22 18:37:46] __main__ INFO: \u001b[0mEpoch 229 Step 351/351 lr 0.001000 loss 1.3419 (1.3230) acc@1 0.4688 (0.4907) acc@5 0.7109 (0.7562)\n",
      "\u001b[32m[2020-06-22 18:37:46] __main__ INFO: \u001b[0mElapsed 32.77\n",
      "\u001b[32m[2020-06-22 18:37:46] __main__ INFO: \u001b[0mVal 229\n",
      "\u001b[32m[2020-06-22 18:37:47] __main__ INFO: \u001b[0mEpoch 229 loss 2.4165 acc@1 0.2880 acc@5 0.6920\n",
      "\u001b[32m[2020-06-22 18:37:47] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 18:37:47] __main__ INFO: \u001b[0mTrain 230 80379\n",
      "\u001b[32m[2020-06-22 18:37:56] __main__ INFO: \u001b[0mEpoch 230 Step 100/351 lr 0.001000 loss 1.2844 (1.3199) acc@1 0.5000 (0.4938) acc@5 0.7578 (0.7521)\n",
      "\u001b[32m[2020-06-22 18:38:05] __main__ INFO: \u001b[0mEpoch 230 Step 200/351 lr 0.001000 loss 1.4247 (1.3180) acc@1 0.4375 (0.4930) acc@5 0.7188 (0.7546)\n",
      "\u001b[32m[2020-06-22 18:38:15] __main__ INFO: \u001b[0mEpoch 230 Step 300/351 lr 0.001000 loss 1.4931 (1.3193) acc@1 0.4062 (0.4916) acc@5 0.6953 (0.7556)\n",
      "\u001b[32m[2020-06-22 18:38:19] __main__ INFO: \u001b[0mEpoch 230 Step 351/351 lr 0.001000 loss 1.2406 (1.3216) acc@1 0.5391 (0.4912) acc@5 0.7969 (0.7553)\n",
      "\u001b[32m[2020-06-22 18:38:19] __main__ INFO: \u001b[0mElapsed 32.78\n",
      "\u001b[32m[2020-06-22 18:38:19] __main__ INFO: \u001b[0mVal 230\n",
      "\u001b[32m[2020-06-22 18:38:20] __main__ INFO: \u001b[0mEpoch 230 loss 2.4476 acc@1 0.2880 acc@5 0.6918\n",
      "\u001b[32m[2020-06-22 18:38:20] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:38:20] __main__ INFO: \u001b[0mTrain 231 80730\n",
      "\u001b[32m[2020-06-22 18:38:30] __main__ INFO: \u001b[0mEpoch 231 Step 100/351 lr 0.001000 loss 1.1861 (1.3223) acc@1 0.5547 (0.4916) acc@5 0.7578 (0.7540)\n",
      "\u001b[32m[2020-06-22 18:38:39] __main__ INFO: \u001b[0mEpoch 231 Step 200/351 lr 0.001000 loss 1.3117 (1.3214) acc@1 0.5156 (0.4923) acc@5 0.7891 (0.7560)\n",
      "\u001b[32m[2020-06-22 18:38:48] __main__ INFO: \u001b[0mEpoch 231 Step 300/351 lr 0.001000 loss 1.2116 (1.3211) acc@1 0.5625 (0.4928) acc@5 0.7734 (0.7533)\n",
      "\u001b[32m[2020-06-22 18:38:53] __main__ INFO: \u001b[0mEpoch 231 Step 351/351 lr 0.001000 loss 1.5305 (1.3236) acc@1 0.4141 (0.4922) acc@5 0.6875 (0.7537)\n",
      "\u001b[32m[2020-06-22 18:38:53] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 18:38:53] __main__ INFO: \u001b[0mVal 231\n",
      "\u001b[32m[2020-06-22 18:38:54] __main__ INFO: \u001b[0mEpoch 231 loss 2.4328 acc@1 0.2888 acc@5 0.6932\n",
      "\u001b[32m[2020-06-22 18:38:54] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 18:38:54] __main__ INFO: \u001b[0mTrain 232 81081\n",
      "\u001b[32m[2020-06-22 18:39:04] __main__ INFO: \u001b[0mEpoch 232 Step 100/351 lr 0.001000 loss 1.4931 (1.3347) acc@1 0.4453 (0.4839) acc@5 0.6953 (0.7502)\n",
      "\u001b[32m[2020-06-22 18:39:13] __main__ INFO: \u001b[0mEpoch 232 Step 200/351 lr 0.001000 loss 1.3424 (1.3272) acc@1 0.5078 (0.4895) acc@5 0.7812 (0.7527)\n",
      "\u001b[32m[2020-06-22 18:39:22] __main__ INFO: \u001b[0mEpoch 232 Step 300/351 lr 0.001000 loss 1.3930 (1.3236) acc@1 0.4531 (0.4902) acc@5 0.7031 (0.7531)\n",
      "\u001b[32m[2020-06-22 18:39:27] __main__ INFO: \u001b[0mEpoch 232 Step 351/351 lr 0.001000 loss 1.3708 (1.3218) acc@1 0.4375 (0.4914) acc@5 0.7656 (0.7544)\n",
      "\u001b[32m[2020-06-22 18:39:27] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 18:39:27] __main__ INFO: \u001b[0mVal 232\n",
      "\u001b[32m[2020-06-22 18:39:28] __main__ INFO: \u001b[0mEpoch 232 loss 2.4066 acc@1 0.2914 acc@5 0.6914\n",
      "\u001b[32m[2020-06-22 18:39:28] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:39:28] __main__ INFO: \u001b[0mTrain 233 81432\n",
      "\u001b[32m[2020-06-22 18:39:38] __main__ INFO: \u001b[0mEpoch 233 Step 100/351 lr 0.001000 loss 1.2526 (1.3228) acc@1 0.5000 (0.4970) acc@5 0.7500 (0.7518)\n",
      "\u001b[32m[2020-06-22 18:39:47] __main__ INFO: \u001b[0mEpoch 233 Step 200/351 lr 0.001000 loss 1.5015 (1.3221) acc@1 0.4141 (0.4936) acc@5 0.7188 (0.7565)\n",
      "\u001b[32m[2020-06-22 18:39:56] __main__ INFO: \u001b[0mEpoch 233 Step 300/351 lr 0.001000 loss 1.3919 (1.3191) acc@1 0.4766 (0.4958) acc@5 0.7656 (0.7574)\n",
      "\u001b[32m[2020-06-22 18:40:01] __main__ INFO: \u001b[0mEpoch 233 Step 351/351 lr 0.001000 loss 1.4812 (1.3203) acc@1 0.4141 (0.4947) acc@5 0.6875 (0.7556)\n",
      "\u001b[32m[2020-06-22 18:40:01] __main__ INFO: \u001b[0mElapsed 32.83\n",
      "\u001b[32m[2020-06-22 18:40:01] __main__ INFO: \u001b[0mVal 233\n",
      "\u001b[32m[2020-06-22 18:40:02] __main__ INFO: \u001b[0mEpoch 233 loss 2.4192 acc@1 0.2880 acc@5 0.6870\n",
      "\u001b[32m[2020-06-22 18:40:02] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:40:02] __main__ INFO: \u001b[0mTrain 234 81783\n",
      "\u001b[32m[2020-06-22 18:40:11] __main__ INFO: \u001b[0mEpoch 234 Step 100/351 lr 0.001000 loss 1.3752 (1.3153) acc@1 0.4922 (0.4940) acc@5 0.7656 (0.7595)\n",
      "\u001b[32m[2020-06-22 18:40:21] __main__ INFO: \u001b[0mEpoch 234 Step 200/351 lr 0.001000 loss 1.3701 (1.3182) acc@1 0.4844 (0.4922) acc@5 0.7891 (0.7551)\n",
      "\u001b[32m[2020-06-22 18:40:30] __main__ INFO: \u001b[0mEpoch 234 Step 300/351 lr 0.001000 loss 1.1424 (1.3172) acc@1 0.5859 (0.4930) acc@5 0.7969 (0.7583)\n",
      "\u001b[32m[2020-06-22 18:40:35] __main__ INFO: \u001b[0mEpoch 234 Step 351/351 lr 0.001000 loss 1.1862 (1.3192) acc@1 0.5625 (0.4923) acc@5 0.7734 (0.7573)\n",
      "\u001b[32m[2020-06-22 18:40:35] __main__ INFO: \u001b[0mElapsed 32.75\n",
      "\u001b[32m[2020-06-22 18:40:35] __main__ INFO: \u001b[0mVal 234\n",
      "\u001b[32m[2020-06-22 18:40:36] __main__ INFO: \u001b[0mEpoch 234 loss 2.4405 acc@1 0.2894 acc@5 0.6896\n",
      "\u001b[32m[2020-06-22 18:40:36] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 18:40:36] __main__ INFO: \u001b[0mTrain 235 82134\n",
      "\u001b[32m[2020-06-22 18:40:45] __main__ INFO: \u001b[0mEpoch 235 Step 100/351 lr 0.001000 loss 1.4532 (1.3308) acc@1 0.4688 (0.4889) acc@5 0.6875 (0.7491)\n",
      "\u001b[32m[2020-06-22 18:40:55] __main__ INFO: \u001b[0mEpoch 235 Step 200/351 lr 0.001000 loss 1.1961 (1.3181) acc@1 0.5547 (0.4955) acc@5 0.7734 (0.7527)\n",
      "\u001b[32m[2020-06-22 18:41:04] __main__ INFO: \u001b[0mEpoch 235 Step 300/351 lr 0.001000 loss 1.3307 (1.3157) acc@1 0.5312 (0.4963) acc@5 0.8359 (0.7551)\n",
      "\u001b[32m[2020-06-22 18:41:09] __main__ INFO: \u001b[0mEpoch 235 Step 351/351 lr 0.001000 loss 1.3147 (1.3175) acc@1 0.5234 (0.4951) acc@5 0.7656 (0.7561)\n",
      "\u001b[32m[2020-06-22 18:41:09] __main__ INFO: \u001b[0mElapsed 32.76\n",
      "\u001b[32m[2020-06-22 18:41:09] __main__ INFO: \u001b[0mVal 235\n",
      "\u001b[32m[2020-06-22 18:41:10] __main__ INFO: \u001b[0mEpoch 235 loss 2.4389 acc@1 0.2818 acc@5 0.6878\n",
      "\u001b[32m[2020-06-22 18:41:10] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 18:41:10] __main__ INFO: \u001b[0mTrain 236 82485\n",
      "\u001b[32m[2020-06-22 18:41:19] __main__ INFO: \u001b[0mEpoch 236 Step 100/351 lr 0.001000 loss 1.4116 (1.2941) acc@1 0.4922 (0.5045) acc@5 0.7266 (0.7588)\n",
      "\u001b[32m[2020-06-22 18:41:28] __main__ INFO: \u001b[0mEpoch 236 Step 200/351 lr 0.001000 loss 1.1254 (1.3083) acc@1 0.5469 (0.4999) acc@5 0.7812 (0.7612)\n",
      "\u001b[32m[2020-06-22 18:41:38] __main__ INFO: \u001b[0mEpoch 236 Step 300/351 lr 0.001000 loss 1.2859 (1.3153) acc@1 0.5000 (0.4968) acc@5 0.7422 (0.7594)\n",
      "\u001b[32m[2020-06-22 18:41:42] __main__ INFO: \u001b[0mEpoch 236 Step 351/351 lr 0.001000 loss 1.2487 (1.3151) acc@1 0.5312 (0.4974) acc@5 0.8047 (0.7596)\n",
      "\u001b[32m[2020-06-22 18:41:42] __main__ INFO: \u001b[0mElapsed 32.78\n",
      "\u001b[32m[2020-06-22 18:41:42] __main__ INFO: \u001b[0mVal 236\n",
      "\u001b[32m[2020-06-22 18:41:44] __main__ INFO: \u001b[0mEpoch 236 loss 2.4266 acc@1 0.2832 acc@5 0.6920\n",
      "\u001b[32m[2020-06-22 18:41:44] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 18:41:44] __main__ INFO: \u001b[0mTrain 237 82836\n",
      "\u001b[32m[2020-06-22 18:41:53] __main__ INFO: \u001b[0mEpoch 237 Step 100/351 lr 0.001000 loss 1.3447 (1.3137) acc@1 0.4531 (0.4965) acc@5 0.8125 (0.7539)\n",
      "\u001b[32m[2020-06-22 18:42:02] __main__ INFO: \u001b[0mEpoch 237 Step 200/351 lr 0.001000 loss 1.1273 (1.3188) acc@1 0.5547 (0.4948) acc@5 0.7578 (0.7534)\n",
      "\u001b[32m[2020-06-22 18:42:12] __main__ INFO: \u001b[0mEpoch 237 Step 300/351 lr 0.001000 loss 1.2735 (1.3178) acc@1 0.5312 (0.4958) acc@5 0.7422 (0.7548)\n",
      "\u001b[32m[2020-06-22 18:42:16] __main__ INFO: \u001b[0mEpoch 237 Step 351/351 lr 0.001000 loss 1.4162 (1.3193) acc@1 0.4531 (0.4951) acc@5 0.6719 (0.7552)\n",
      "\u001b[32m[2020-06-22 18:42:16] __main__ INFO: \u001b[0mElapsed 32.81\n",
      "\u001b[32m[2020-06-22 18:42:16] __main__ INFO: \u001b[0mVal 237\n",
      "\u001b[32m[2020-06-22 18:42:17] __main__ INFO: \u001b[0mEpoch 237 loss 2.4486 acc@1 0.2860 acc@5 0.7058\n",
      "\u001b[32m[2020-06-22 18:42:17] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 18:42:17] __main__ INFO: \u001b[0mTrain 238 83187\n",
      "\u001b[32m[2020-06-22 18:42:27] __main__ INFO: \u001b[0mEpoch 238 Step 100/351 lr 0.001000 loss 1.4272 (1.3080) acc@1 0.4766 (0.4995) acc@5 0.7344 (0.7638)\n",
      "\u001b[32m[2020-06-22 18:42:36] __main__ INFO: \u001b[0mEpoch 238 Step 200/351 lr 0.001000 loss 1.3005 (1.3141) acc@1 0.5312 (0.4978) acc@5 0.8125 (0.7627)\n",
      "\u001b[32m[2020-06-22 18:42:45] __main__ INFO: \u001b[0mEpoch 238 Step 300/351 lr 0.001000 loss 1.3849 (1.3193) acc@1 0.4844 (0.4959) acc@5 0.7578 (0.7588)\n",
      "\u001b[32m[2020-06-22 18:42:50] __main__ INFO: \u001b[0mEpoch 238 Step 351/351 lr 0.001000 loss 1.5238 (1.3216) acc@1 0.4766 (0.4949) acc@5 0.7344 (0.7575)\n",
      "\u001b[32m[2020-06-22 18:42:50] __main__ INFO: \u001b[0mElapsed 32.82\n",
      "\u001b[32m[2020-06-22 18:42:50] __main__ INFO: \u001b[0mVal 238\n",
      "\u001b[32m[2020-06-22 18:42:51] __main__ INFO: \u001b[0mEpoch 238 loss 2.4656 acc@1 0.2904 acc@5 0.7014\n",
      "\u001b[32m[2020-06-22 18:42:51] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 18:42:51] __main__ INFO: \u001b[0mTrain 239 83538\n",
      "\u001b[32m[2020-06-22 18:43:01] __main__ INFO: \u001b[0mEpoch 239 Step 100/351 lr 0.001000 loss 1.2799 (1.3053) acc@1 0.5078 (0.4984) acc@5 0.7578 (0.7586)\n",
      "\u001b[32m[2020-06-22 18:43:10] __main__ INFO: \u001b[0mEpoch 239 Step 200/351 lr 0.001000 loss 1.3764 (1.3128) acc@1 0.4609 (0.4980) acc@5 0.7031 (0.7548)\n",
      "\u001b[32m[2020-06-22 18:43:19] __main__ INFO: \u001b[0mEpoch 239 Step 300/351 lr 0.001000 loss 1.1630 (1.3106) acc@1 0.5625 (0.4996) acc@5 0.8047 (0.7569)\n",
      "\u001b[32m[2020-06-22 18:43:24] __main__ INFO: \u001b[0mEpoch 239 Step 351/351 lr 0.001000 loss 1.3040 (1.3146) acc@1 0.5469 (0.4979) acc@5 0.7734 (0.7559)\n",
      "\u001b[32m[2020-06-22 18:43:24] __main__ INFO: \u001b[0mElapsed 32.82\n",
      "\u001b[32m[2020-06-22 18:43:24] __main__ INFO: \u001b[0mVal 239\n",
      "\u001b[32m[2020-06-22 18:43:25] __main__ INFO: \u001b[0mEpoch 239 loss 2.4357 acc@1 0.2808 acc@5 0.6922\n",
      "\u001b[32m[2020-06-22 18:43:25] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:43:25] __main__ INFO: \u001b[0mTrain 240 83889\n",
      "\u001b[32m[2020-06-22 18:43:35] __main__ INFO: \u001b[0mEpoch 240 Step 100/351 lr 0.001000 loss 1.1780 (1.3097) acc@1 0.5312 (0.4976) acc@5 0.7578 (0.7583)\n",
      "\u001b[32m[2020-06-22 18:43:44] __main__ INFO: \u001b[0mEpoch 240 Step 200/351 lr 0.001000 loss 1.2737 (1.3125) acc@1 0.5000 (0.4964) acc@5 0.7734 (0.7569)\n",
      "\u001b[32m[2020-06-22 18:43:53] __main__ INFO: \u001b[0mEpoch 240 Step 300/351 lr 0.001000 loss 1.2604 (1.3139) acc@1 0.5078 (0.4951) acc@5 0.7891 (0.7561)\n",
      "\u001b[32m[2020-06-22 18:43:58] __main__ INFO: \u001b[0mEpoch 240 Step 351/351 lr 0.001000 loss 1.2358 (1.3148) acc@1 0.5156 (0.4945) acc@5 0.7266 (0.7561)\n",
      "\u001b[32m[2020-06-22 18:43:58] __main__ INFO: \u001b[0mElapsed 32.77\n",
      "\u001b[32m[2020-06-22 18:43:58] __main__ INFO: \u001b[0mVal 240\n",
      "\u001b[32m[2020-06-22 18:43:59] __main__ INFO: \u001b[0mEpoch 240 loss 2.4112 acc@1 0.2866 acc@5 0.6940\n",
      "\u001b[32m[2020-06-22 18:43:59] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 18:43:59] __main__ INFO: \u001b[0mTrain 241 84240\n",
      "\u001b[32m[2020-06-22 18:44:08] __main__ INFO: \u001b[0mEpoch 241 Step 100/351 lr 0.001000 loss 1.3692 (1.3183) acc@1 0.4609 (0.4971) acc@5 0.6875 (0.7573)\n",
      "\u001b[32m[2020-06-22 18:44:18] __main__ INFO: \u001b[0mEpoch 241 Step 200/351 lr 0.001000 loss 1.3363 (1.3112) acc@1 0.4375 (0.4984) acc@5 0.7031 (0.7570)\n",
      "\u001b[32m[2020-06-22 18:44:27] __main__ INFO: \u001b[0mEpoch 241 Step 300/351 lr 0.001000 loss 1.3460 (1.3125) acc@1 0.4844 (0.4958) acc@5 0.7188 (0.7575)\n",
      "\u001b[32m[2020-06-22 18:44:32] __main__ INFO: \u001b[0mEpoch 241 Step 351/351 lr 0.001000 loss 1.2252 (1.3132) acc@1 0.5781 (0.4951) acc@5 0.7969 (0.7573)\n",
      "\u001b[32m[2020-06-22 18:44:32] __main__ INFO: \u001b[0mElapsed 32.81\n",
      "\u001b[32m[2020-06-22 18:44:32] __main__ INFO: \u001b[0mVal 241\n",
      "\u001b[32m[2020-06-22 18:44:33] __main__ INFO: \u001b[0mEpoch 241 loss 2.4617 acc@1 0.2888 acc@5 0.6882\n",
      "\u001b[32m[2020-06-22 18:44:33] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 18:44:33] __main__ INFO: \u001b[0mTrain 242 84591\n",
      "\u001b[32m[2020-06-22 18:44:42] __main__ INFO: \u001b[0mEpoch 242 Step 100/351 lr 0.001000 loss 1.4584 (1.3093) acc@1 0.4297 (0.4999) acc@5 0.7422 (0.7570)\n",
      "\u001b[32m[2020-06-22 18:44:52] __main__ INFO: \u001b[0mEpoch 242 Step 200/351 lr 0.001000 loss 1.3713 (1.3160) acc@1 0.4922 (0.4961) acc@5 0.7500 (0.7539)\n",
      "\u001b[32m[2020-06-22 18:45:01] __main__ INFO: \u001b[0mEpoch 242 Step 300/351 lr 0.001000 loss 1.4563 (1.3183) acc@1 0.4453 (0.4948) acc@5 0.7188 (0.7535)\n",
      "\u001b[32m[2020-06-22 18:45:06] __main__ INFO: \u001b[0mEpoch 242 Step 351/351 lr 0.001000 loss 1.1359 (1.3157) acc@1 0.5625 (0.4955) acc@5 0.7969 (0.7539)\n",
      "\u001b[32m[2020-06-22 18:45:06] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 18:45:06] __main__ INFO: \u001b[0mVal 242\n",
      "\u001b[32m[2020-06-22 18:45:07] __main__ INFO: \u001b[0mEpoch 242 loss 2.4092 acc@1 0.2894 acc@5 0.7018\n",
      "\u001b[32m[2020-06-22 18:45:07] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 18:45:07] __main__ INFO: \u001b[0mTrain 243 84942\n",
      "\u001b[32m[2020-06-22 18:45:16] __main__ INFO: \u001b[0mEpoch 243 Step 100/351 lr 0.001000 loss 1.3501 (1.2989) acc@1 0.4609 (0.4991) acc@5 0.7500 (0.7595)\n",
      "\u001b[32m[2020-06-22 18:45:25] __main__ INFO: \u001b[0mEpoch 243 Step 200/351 lr 0.001000 loss 1.2607 (1.3141) acc@1 0.5078 (0.4944) acc@5 0.7500 (0.7548)\n",
      "\u001b[32m[2020-06-22 18:45:35] __main__ INFO: \u001b[0mEpoch 243 Step 300/351 lr 0.001000 loss 1.3080 (1.3150) acc@1 0.4844 (0.4942) acc@5 0.7422 (0.7566)\n",
      "\u001b[32m[2020-06-22 18:45:40] __main__ INFO: \u001b[0mEpoch 243 Step 351/351 lr 0.001000 loss 1.4003 (1.3136) acc@1 0.4922 (0.4954) acc@5 0.7578 (0.7577)\n",
      "\u001b[32m[2020-06-22 18:45:40] __main__ INFO: \u001b[0mElapsed 32.84\n",
      "\u001b[32m[2020-06-22 18:45:40] __main__ INFO: \u001b[0mVal 243\n",
      "\u001b[32m[2020-06-22 18:45:41] __main__ INFO: \u001b[0mEpoch 243 loss 2.4277 acc@1 0.2894 acc@5 0.7004\n",
      "\u001b[32m[2020-06-22 18:45:41] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 18:45:41] __main__ INFO: \u001b[0mTrain 244 85293\n",
      "\u001b[32m[2020-06-22 18:45:50] __main__ INFO: \u001b[0mEpoch 244 Step 100/351 lr 0.001000 loss 1.2627 (1.3102) acc@1 0.5078 (0.5034) acc@5 0.7344 (0.7511)\n",
      "\u001b[32m[2020-06-22 18:45:59] __main__ INFO: \u001b[0mEpoch 244 Step 200/351 lr 0.001000 loss 1.2736 (1.3136) acc@1 0.5234 (0.4980) acc@5 0.7891 (0.7535)\n",
      "\u001b[32m[2020-06-22 18:46:09] __main__ INFO: \u001b[0mEpoch 244 Step 300/351 lr 0.001000 loss 1.2967 (1.3112) acc@1 0.5312 (0.4979) acc@5 0.7422 (0.7550)\n",
      "\u001b[32m[2020-06-22 18:46:13] __main__ INFO: \u001b[0mEpoch 244 Step 351/351 lr 0.001000 loss 1.4120 (1.3127) acc@1 0.4609 (0.4965) acc@5 0.7344 (0.7555)\n",
      "\u001b[32m[2020-06-22 18:46:13] __main__ INFO: \u001b[0mElapsed 32.81\n",
      "\u001b[32m[2020-06-22 18:46:13] __main__ INFO: \u001b[0mVal 244\n",
      "\u001b[32m[2020-06-22 18:46:14] __main__ INFO: \u001b[0mEpoch 244 loss 2.4701 acc@1 0.2894 acc@5 0.6910\n",
      "\u001b[32m[2020-06-22 18:46:14] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:46:14] __main__ INFO: \u001b[0mTrain 245 85644\n",
      "\u001b[32m[2020-06-22 18:46:24] __main__ INFO: \u001b[0mEpoch 245 Step 100/351 lr 0.001000 loss 1.3209 (1.3039) acc@1 0.5000 (0.5003) acc@5 0.7656 (0.7566)\n",
      "\u001b[32m[2020-06-22 18:46:33] __main__ INFO: \u001b[0mEpoch 245 Step 200/351 lr 0.001000 loss 1.4265 (1.3090) acc@1 0.4297 (0.4976) acc@5 0.6719 (0.7561)\n",
      "\u001b[32m[2020-06-22 18:46:43] __main__ INFO: \u001b[0mEpoch 245 Step 300/351 lr 0.001000 loss 1.2536 (1.3134) acc@1 0.5391 (0.4965) acc@5 0.7578 (0.7557)\n",
      "\u001b[32m[2020-06-22 18:46:47] __main__ INFO: \u001b[0mEpoch 245 Step 351/351 lr 0.001000 loss 1.3553 (1.3121) acc@1 0.4688 (0.4972) acc@5 0.6875 (0.7555)\n",
      "\u001b[32m[2020-06-22 18:46:47] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 18:46:47] __main__ INFO: \u001b[0mVal 245\n",
      "\u001b[32m[2020-06-22 18:46:48] __main__ INFO: \u001b[0mEpoch 245 loss 2.4436 acc@1 0.2904 acc@5 0.6926\n",
      "\u001b[32m[2020-06-22 18:46:48] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:46:48] __main__ INFO: \u001b[0mTrain 246 85995\n",
      "\u001b[32m[2020-06-22 18:46:58] __main__ INFO: \u001b[0mEpoch 246 Step 100/351 lr 0.001000 loss 1.4098 (1.3137) acc@1 0.4531 (0.4913) acc@5 0.6953 (0.7577)\n",
      "\u001b[32m[2020-06-22 18:47:07] __main__ INFO: \u001b[0mEpoch 246 Step 200/351 lr 0.001000 loss 1.1709 (1.3102) acc@1 0.5391 (0.4932) acc@5 0.7500 (0.7597)\n",
      "\u001b[32m[2020-06-22 18:47:16] __main__ INFO: \u001b[0mEpoch 246 Step 300/351 lr 0.001000 loss 1.3343 (1.3166) acc@1 0.4844 (0.4929) acc@5 0.7422 (0.7573)\n",
      "\u001b[32m[2020-06-22 18:47:21] __main__ INFO: \u001b[0mEpoch 246 Step 351/351 lr 0.001000 loss 1.2063 (1.3145) acc@1 0.5234 (0.4938) acc@5 0.7500 (0.7585)\n",
      "\u001b[32m[2020-06-22 18:47:21] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 18:47:21] __main__ INFO: \u001b[0mVal 246\n",
      "\u001b[32m[2020-06-22 18:47:22] __main__ INFO: \u001b[0mEpoch 246 loss 2.4487 acc@1 0.2890 acc@5 0.6918\n",
      "\u001b[32m[2020-06-22 18:47:22] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:47:22] __main__ INFO: \u001b[0mTrain 247 86346\n",
      "\u001b[32m[2020-06-22 18:47:32] __main__ INFO: \u001b[0mEpoch 247 Step 100/351 lr 0.001000 loss 1.4090 (1.3095) acc@1 0.4062 (0.4972) acc@5 0.6875 (0.7541)\n",
      "\u001b[32m[2020-06-22 18:47:41] __main__ INFO: \u001b[0mEpoch 247 Step 200/351 lr 0.001000 loss 1.4492 (1.3057) acc@1 0.4141 (0.4993) acc@5 0.6641 (0.7567)\n",
      "\u001b[32m[2020-06-22 18:47:50] __main__ INFO: \u001b[0mEpoch 247 Step 300/351 lr 0.001000 loss 1.2096 (1.3037) acc@1 0.5469 (0.5004) acc@5 0.7578 (0.7562)\n",
      "\u001b[32m[2020-06-22 18:47:55] __main__ INFO: \u001b[0mEpoch 247 Step 351/351 lr 0.001000 loss 1.2940 (1.3062) acc@1 0.4609 (0.4999) acc@5 0.7500 (0.7562)\n",
      "\u001b[32m[2020-06-22 18:47:55] __main__ INFO: \u001b[0mElapsed 32.78\n",
      "\u001b[32m[2020-06-22 18:47:55] __main__ INFO: \u001b[0mVal 247\n",
      "\u001b[32m[2020-06-22 18:47:56] __main__ INFO: \u001b[0mEpoch 247 loss 2.4488 acc@1 0.2898 acc@5 0.6962\n",
      "\u001b[32m[2020-06-22 18:47:56] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:47:56] __main__ INFO: \u001b[0mTrain 248 86697\n",
      "\u001b[32m[2020-06-22 18:48:05] __main__ INFO: \u001b[0mEpoch 248 Step 100/351 lr 0.001000 loss 1.1584 (1.3175) acc@1 0.5703 (0.4922) acc@5 0.7578 (0.7522)\n",
      "\u001b[32m[2020-06-22 18:48:15] __main__ INFO: \u001b[0mEpoch 248 Step 200/351 lr 0.001000 loss 1.1440 (1.3129) acc@1 0.5781 (0.4945) acc@5 0.8047 (0.7557)\n",
      "\u001b[32m[2020-06-22 18:48:24] __main__ INFO: \u001b[0mEpoch 248 Step 300/351 lr 0.001000 loss 1.2449 (1.3082) acc@1 0.5078 (0.4962) acc@5 0.7656 (0.7547)\n",
      "\u001b[32m[2020-06-22 18:48:29] __main__ INFO: \u001b[0mEpoch 248 Step 351/351 lr 0.001000 loss 1.3124 (1.3057) acc@1 0.5391 (0.4974) acc@5 0.7188 (0.7559)\n",
      "\u001b[32m[2020-06-22 18:48:29] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 18:48:29] __main__ INFO: \u001b[0mVal 248\n",
      "\u001b[32m[2020-06-22 18:48:30] __main__ INFO: \u001b[0mEpoch 248 loss 2.4562 acc@1 0.2892 acc@5 0.6952\n",
      "\u001b[32m[2020-06-22 18:48:30] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 18:48:30] __main__ INFO: \u001b[0mTrain 249 87048\n",
      "\u001b[32m[2020-06-22 18:48:39] __main__ INFO: \u001b[0mEpoch 249 Step 100/351 lr 0.001000 loss 1.1796 (1.3056) acc@1 0.5469 (0.4988) acc@5 0.7734 (0.7578)\n",
      "\u001b[32m[2020-06-22 18:48:49] __main__ INFO: \u001b[0mEpoch 249 Step 200/351 lr 0.001000 loss 1.2263 (1.3047) acc@1 0.5234 (0.4983) acc@5 0.7969 (0.7575)\n",
      "\u001b[32m[2020-06-22 18:48:58] __main__ INFO: \u001b[0mEpoch 249 Step 300/351 lr 0.001000 loss 1.2939 (1.3075) acc@1 0.5234 (0.4958) acc@5 0.7500 (0.7568)\n",
      "\u001b[32m[2020-06-22 18:49:03] __main__ INFO: \u001b[0mEpoch 249 Step 351/351 lr 0.001000 loss 1.2166 (1.3125) acc@1 0.5234 (0.4939) acc@5 0.7344 (0.7560)\n",
      "\u001b[32m[2020-06-22 18:49:03] __main__ INFO: \u001b[0mElapsed 32.84\n",
      "\u001b[32m[2020-06-22 18:49:03] __main__ INFO: \u001b[0mVal 249\n",
      "\u001b[32m[2020-06-22 18:49:04] __main__ INFO: \u001b[0mEpoch 249 loss 2.4607 acc@1 0.2910 acc@5 0.6938\n",
      "\u001b[32m[2020-06-22 18:49:04] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:49:04] __main__ INFO: \u001b[0mTrain 250 87399\n",
      "\u001b[32m[2020-06-22 18:49:13] __main__ INFO: \u001b[0mEpoch 250 Step 100/351 lr 0.001000 loss 1.2040 (1.2989) acc@1 0.5547 (0.5043) acc@5 0.7500 (0.7574)\n",
      "\u001b[32m[2020-06-22 18:49:23] __main__ INFO: \u001b[0mEpoch 250 Step 200/351 lr 0.001000 loss 1.4686 (1.3087) acc@1 0.4141 (0.5015) acc@5 0.7812 (0.7563)\n",
      "\u001b[32m[2020-06-22 18:49:32] __main__ INFO: \u001b[0mEpoch 250 Step 300/351 lr 0.001000 loss 1.2756 (1.3072) acc@1 0.4922 (0.4997) acc@5 0.6484 (0.7557)\n",
      "\u001b[32m[2020-06-22 18:49:37] __main__ INFO: \u001b[0mEpoch 250 Step 351/351 lr 0.001000 loss 1.3129 (1.3084) acc@1 0.4609 (0.4992) acc@5 0.7578 (0.7563)\n",
      "\u001b[32m[2020-06-22 18:49:37] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 18:49:37] __main__ INFO: \u001b[0mVal 250\n",
      "\u001b[32m[2020-06-22 18:49:38] __main__ INFO: \u001b[0mEpoch 250 loss 2.4705 acc@1 0.2868 acc@5 0.6852\n",
      "\u001b[32m[2020-06-22 18:49:38] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 18:49:38] __main__ INFO: \u001b[0mTrain 251 87750\n",
      "\u001b[32m[2020-06-22 18:49:47] __main__ INFO: \u001b[0mEpoch 251 Step 100/351 lr 0.001000 loss 1.3720 (1.2965) acc@1 0.4766 (0.5067) acc@5 0.7500 (0.7568)\n",
      "\u001b[32m[2020-06-22 18:49:56] __main__ INFO: \u001b[0mEpoch 251 Step 200/351 lr 0.001000 loss 1.2754 (1.3096) acc@1 0.5000 (0.4997) acc@5 0.7734 (0.7553)\n",
      "\u001b[32m[2020-06-22 18:50:06] __main__ INFO: \u001b[0mEpoch 251 Step 300/351 lr 0.001000 loss 1.2986 (1.3057) acc@1 0.5078 (0.4993) acc@5 0.8125 (0.7572)\n",
      "\u001b[32m[2020-06-22 18:50:11] __main__ INFO: \u001b[0mEpoch 251 Step 351/351 lr 0.001000 loss 1.2804 (1.3051) acc@1 0.5234 (0.5000) acc@5 0.7734 (0.7580)\n",
      "\u001b[32m[2020-06-22 18:50:11] __main__ INFO: \u001b[0mElapsed 32.94\n",
      "\u001b[32m[2020-06-22 18:50:11] __main__ INFO: \u001b[0mVal 251\n",
      "\u001b[32m[2020-06-22 18:50:12] __main__ INFO: \u001b[0mEpoch 251 loss 2.4483 acc@1 0.2774 acc@5 0.6872\n",
      "\u001b[32m[2020-06-22 18:50:12] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 18:50:12] __main__ INFO: \u001b[0mTrain 252 88101\n",
      "\u001b[32m[2020-06-22 18:50:21] __main__ INFO: \u001b[0mEpoch 252 Step 100/351 lr 0.001000 loss 1.4046 (1.3122) acc@1 0.4375 (0.4968) acc@5 0.7266 (0.7582)\n",
      "\u001b[32m[2020-06-22 18:50:30] __main__ INFO: \u001b[0mEpoch 252 Step 200/351 lr 0.001000 loss 1.3307 (1.3065) acc@1 0.4844 (0.4979) acc@5 0.7891 (0.7553)\n",
      "\u001b[32m[2020-06-22 18:50:40] __main__ INFO: \u001b[0mEpoch 252 Step 300/351 lr 0.001000 loss 1.2933 (1.3046) acc@1 0.5234 (0.4990) acc@5 0.7500 (0.7579)\n",
      "\u001b[32m[2020-06-22 18:50:44] __main__ INFO: \u001b[0mEpoch 252 Step 351/351 lr 0.001000 loss 1.2922 (1.3053) acc@1 0.5156 (0.4991) acc@5 0.7422 (0.7589)\n",
      "\u001b[32m[2020-06-22 18:50:44] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 18:50:44] __main__ INFO: \u001b[0mVal 252\n",
      "\u001b[32m[2020-06-22 18:50:46] __main__ INFO: \u001b[0mEpoch 252 loss 2.4549 acc@1 0.2898 acc@5 0.7024\n",
      "\u001b[32m[2020-06-22 18:50:46] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 18:50:46] __main__ INFO: \u001b[0mTrain 253 88452\n",
      "\u001b[32m[2020-06-22 18:50:55] __main__ INFO: \u001b[0mEpoch 253 Step 100/351 lr 0.001000 loss 1.5241 (1.3141) acc@1 0.4375 (0.4985) acc@5 0.6953 (0.7570)\n",
      "\u001b[32m[2020-06-22 18:51:04] __main__ INFO: \u001b[0mEpoch 253 Step 200/351 lr 0.001000 loss 1.2701 (1.3088) acc@1 0.5000 (0.4964) acc@5 0.7266 (0.7574)\n",
      "\u001b[32m[2020-06-22 18:51:14] __main__ INFO: \u001b[0mEpoch 253 Step 300/351 lr 0.001000 loss 1.4882 (1.3052) acc@1 0.4062 (0.4988) acc@5 0.6797 (0.7585)\n",
      "\u001b[32m[2020-06-22 18:51:18] __main__ INFO: \u001b[0mEpoch 253 Step 351/351 lr 0.001000 loss 1.3331 (1.3068) acc@1 0.5391 (0.4980) acc@5 0.7578 (0.7577)\n",
      "\u001b[32m[2020-06-22 18:51:18] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 18:51:18] __main__ INFO: \u001b[0mVal 253\n",
      "\u001b[32m[2020-06-22 18:51:19] __main__ INFO: \u001b[0mEpoch 253 loss 2.4729 acc@1 0.2904 acc@5 0.6906\n",
      "\u001b[32m[2020-06-22 18:51:19] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 18:51:19] __main__ INFO: \u001b[0mTrain 254 88803\n",
      "\u001b[32m[2020-06-22 18:51:29] __main__ INFO: \u001b[0mEpoch 254 Step 100/351 lr 0.001000 loss 1.3064 (1.3032) acc@1 0.4844 (0.4985) acc@5 0.7891 (0.7609)\n",
      "\u001b[32m[2020-06-22 18:51:38] __main__ INFO: \u001b[0mEpoch 254 Step 200/351 lr 0.001000 loss 1.2134 (1.3084) acc@1 0.5703 (0.4990) acc@5 0.7969 (0.7572)\n",
      "\u001b[32m[2020-06-22 18:51:47] __main__ INFO: \u001b[0mEpoch 254 Step 300/351 lr 0.001000 loss 1.2158 (1.3075) acc@1 0.5000 (0.4993) acc@5 0.7656 (0.7588)\n",
      "\u001b[32m[2020-06-22 18:51:52] __main__ INFO: \u001b[0mEpoch 254 Step 351/351 lr 0.001000 loss 1.2488 (1.3044) acc@1 0.5000 (0.5004) acc@5 0.7578 (0.7594)\n",
      "\u001b[32m[2020-06-22 18:51:52] __main__ INFO: \u001b[0mElapsed 32.82\n",
      "\u001b[32m[2020-06-22 18:51:52] __main__ INFO: \u001b[0mVal 254\n",
      "\u001b[32m[2020-06-22 18:51:53] __main__ INFO: \u001b[0mEpoch 254 loss 2.4644 acc@1 0.2884 acc@5 0.6912\n",
      "\u001b[32m[2020-06-22 18:51:53] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:51:53] __main__ INFO: \u001b[0mTrain 255 89154\n",
      "\u001b[32m[2020-06-22 18:52:03] __main__ INFO: \u001b[0mEpoch 255 Step 100/351 lr 0.001000 loss 1.3221 (1.3033) acc@1 0.4844 (0.4998) acc@5 0.7656 (0.7548)\n",
      "\u001b[32m[2020-06-22 18:52:12] __main__ INFO: \u001b[0mEpoch 255 Step 200/351 lr 0.001000 loss 1.1559 (1.3031) acc@1 0.5391 (0.5011) acc@5 0.7578 (0.7561)\n",
      "\u001b[32m[2020-06-22 18:52:21] __main__ INFO: \u001b[0mEpoch 255 Step 300/351 lr 0.001000 loss 1.2621 (1.3011) acc@1 0.5703 (0.5026) acc@5 0.8125 (0.7587)\n",
      "\u001b[32m[2020-06-22 18:52:26] __main__ INFO: \u001b[0mEpoch 255 Step 351/351 lr 0.001000 loss 1.3679 (1.3062) acc@1 0.4766 (0.5004) acc@5 0.7422 (0.7584)\n",
      "\u001b[32m[2020-06-22 18:52:26] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 18:52:26] __main__ INFO: \u001b[0mVal 255\n",
      "\u001b[32m[2020-06-22 18:52:27] __main__ INFO: \u001b[0mEpoch 255 loss 2.4867 acc@1 0.2854 acc@5 0.7010\n",
      "\u001b[32m[2020-06-22 18:52:27] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 18:52:27] __main__ INFO: \u001b[0mTrain 256 89505\n",
      "\u001b[32m[2020-06-22 18:52:37] __main__ INFO: \u001b[0mEpoch 256 Step 100/351 lr 0.001000 loss 1.2951 (1.3023) acc@1 0.5156 (0.4977) acc@5 0.7891 (0.7545)\n",
      "\u001b[32m[2020-06-22 18:52:46] __main__ INFO: \u001b[0mEpoch 256 Step 200/351 lr 0.001000 loss 1.2077 (1.3034) acc@1 0.5078 (0.4980) acc@5 0.6953 (0.7573)\n",
      "\u001b[32m[2020-06-22 18:52:55] __main__ INFO: \u001b[0mEpoch 256 Step 300/351 lr 0.001000 loss 1.2458 (1.3045) acc@1 0.5078 (0.4982) acc@5 0.7969 (0.7561)\n",
      "\u001b[32m[2020-06-22 18:53:00] __main__ INFO: \u001b[0mEpoch 256 Step 351/351 lr 0.001000 loss 1.3611 (1.3052) acc@1 0.4766 (0.4978) acc@5 0.7188 (0.7559)\n",
      "\u001b[32m[2020-06-22 18:53:00] __main__ INFO: \u001b[0mElapsed 32.82\n",
      "\u001b[32m[2020-06-22 18:53:00] __main__ INFO: \u001b[0mVal 256\n",
      "\u001b[32m[2020-06-22 18:53:01] __main__ INFO: \u001b[0mEpoch 256 loss 2.5078 acc@1 0.2856 acc@5 0.6958\n",
      "\u001b[32m[2020-06-22 18:53:01] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 18:53:01] __main__ INFO: \u001b[0mTrain 257 89856\n",
      "\u001b[32m[2020-06-22 18:53:10] __main__ INFO: \u001b[0mEpoch 257 Step 100/351 lr 0.001000 loss 1.4118 (1.3091) acc@1 0.4375 (0.4958) acc@5 0.7422 (0.7584)\n",
      "\u001b[32m[2020-06-22 18:53:20] __main__ INFO: \u001b[0mEpoch 257 Step 200/351 lr 0.001000 loss 1.1924 (1.3085) acc@1 0.5547 (0.4975) acc@5 0.7344 (0.7548)\n",
      "\u001b[32m[2020-06-22 18:53:29] __main__ INFO: \u001b[0mEpoch 257 Step 300/351 lr 0.001000 loss 1.2307 (1.3031) acc@1 0.5156 (0.5004) acc@5 0.7656 (0.7571)\n",
      "\u001b[32m[2020-06-22 18:53:34] __main__ INFO: \u001b[0mEpoch 257 Step 351/351 lr 0.001000 loss 1.1983 (1.3019) acc@1 0.4922 (0.5009) acc@5 0.7969 (0.7568)\n",
      "\u001b[32m[2020-06-22 18:53:34] __main__ INFO: \u001b[0mElapsed 32.77\n",
      "\u001b[32m[2020-06-22 18:53:34] __main__ INFO: \u001b[0mVal 257\n",
      "\u001b[32m[2020-06-22 18:53:35] __main__ INFO: \u001b[0mEpoch 257 loss 2.4954 acc@1 0.2870 acc@5 0.6898\n",
      "\u001b[32m[2020-06-22 18:53:35] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:53:35] __main__ INFO: \u001b[0mTrain 258 90207\n",
      "\u001b[32m[2020-06-22 18:53:44] __main__ INFO: \u001b[0mEpoch 258 Step 100/351 lr 0.001000 loss 1.3126 (1.2870) acc@1 0.5000 (0.5063) acc@5 0.7891 (0.7595)\n",
      "\u001b[32m[2020-06-22 18:53:54] __main__ INFO: \u001b[0mEpoch 258 Step 200/351 lr 0.001000 loss 1.2380 (1.2928) acc@1 0.5000 (0.5056) acc@5 0.7266 (0.7594)\n",
      "\u001b[32m[2020-06-22 18:54:03] __main__ INFO: \u001b[0mEpoch 258 Step 300/351 lr 0.001000 loss 1.5325 (1.2989) acc@1 0.3750 (0.5016) acc@5 0.7422 (0.7564)\n",
      "\u001b[32m[2020-06-22 18:54:08] __main__ INFO: \u001b[0mEpoch 258 Step 351/351 lr 0.001000 loss 1.1824 (1.3039) acc@1 0.5234 (0.4991) acc@5 0.8125 (0.7551)\n",
      "\u001b[32m[2020-06-22 18:54:08] __main__ INFO: \u001b[0mElapsed 32.74\n",
      "\u001b[32m[2020-06-22 18:54:08] __main__ INFO: \u001b[0mVal 258\n",
      "\u001b[32m[2020-06-22 18:54:09] __main__ INFO: \u001b[0mEpoch 258 loss 2.4567 acc@1 0.2784 acc@5 0.6920\n",
      "\u001b[32m[2020-06-22 18:54:09] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:54:09] __main__ INFO: \u001b[0mTrain 259 90558\n",
      "\u001b[32m[2020-06-22 18:54:18] __main__ INFO: \u001b[0mEpoch 259 Step 100/351 lr 0.001000 loss 1.1900 (1.3060) acc@1 0.5078 (0.4989) acc@5 0.7578 (0.7566)\n",
      "\u001b[32m[2020-06-22 18:54:27] __main__ INFO: \u001b[0mEpoch 259 Step 200/351 lr 0.001000 loss 1.3540 (1.3065) acc@1 0.4922 (0.5004) acc@5 0.7422 (0.7559)\n",
      "\u001b[32m[2020-06-22 18:54:37] __main__ INFO: \u001b[0mEpoch 259 Step 300/351 lr 0.001000 loss 1.2552 (1.3039) acc@1 0.5391 (0.5017) acc@5 0.7656 (0.7568)\n",
      "\u001b[32m[2020-06-22 18:54:42] __main__ INFO: \u001b[0mEpoch 259 Step 351/351 lr 0.001000 loss 1.3668 (1.3027) acc@1 0.4922 (0.5011) acc@5 0.7812 (0.7563)\n",
      "\u001b[32m[2020-06-22 18:54:42] __main__ INFO: \u001b[0mElapsed 32.89\n",
      "\u001b[32m[2020-06-22 18:54:42] __main__ INFO: \u001b[0mVal 259\n",
      "\u001b[32m[2020-06-22 18:54:43] __main__ INFO: \u001b[0mEpoch 259 loss 2.5150 acc@1 0.2906 acc@5 0.6916\n",
      "\u001b[32m[2020-06-22 18:54:43] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 18:54:43] __main__ INFO: \u001b[0mTrain 260 90909\n",
      "\u001b[32m[2020-06-22 18:54:52] __main__ INFO: \u001b[0mEpoch 260 Step 100/351 lr 0.001000 loss 1.3505 (1.2914) acc@1 0.4922 (0.5065) acc@5 0.7188 (0.7572)\n",
      "\u001b[32m[2020-06-22 18:55:01] __main__ INFO: \u001b[0mEpoch 260 Step 200/351 lr 0.001000 loss 1.4446 (1.2956) acc@1 0.4297 (0.5029) acc@5 0.7344 (0.7540)\n",
      "\u001b[32m[2020-06-22 18:55:11] __main__ INFO: \u001b[0mEpoch 260 Step 300/351 lr 0.001000 loss 1.2006 (1.2960) acc@1 0.5391 (0.5015) acc@5 0.8203 (0.7554)\n",
      "\u001b[32m[2020-06-22 18:55:15] __main__ INFO: \u001b[0mEpoch 260 Step 351/351 lr 0.001000 loss 1.4979 (1.3021) acc@1 0.4219 (0.4986) acc@5 0.7500 (0.7549)\n",
      "\u001b[32m[2020-06-22 18:55:15] __main__ INFO: \u001b[0mElapsed 32.83\n",
      "\u001b[32m[2020-06-22 18:55:15] __main__ INFO: \u001b[0mVal 260\n",
      "\u001b[32m[2020-06-22 18:55:16] __main__ INFO: \u001b[0mEpoch 260 loss 2.5310 acc@1 0.2900 acc@5 0.6928\n",
      "\u001b[32m[2020-06-22 18:55:16] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 18:55:16] __main__ INFO: \u001b[0mTrain 261 91260\n",
      "\u001b[32m[2020-06-22 18:55:26] __main__ INFO: \u001b[0mEpoch 261 Step 100/351 lr 0.001000 loss 1.1795 (1.2851) acc@1 0.5859 (0.5078) acc@5 0.7891 (0.7639)\n",
      "\u001b[32m[2020-06-22 18:55:35] __main__ INFO: \u001b[0mEpoch 261 Step 200/351 lr 0.001000 loss 1.3166 (1.2976) acc@1 0.4844 (0.5018) acc@5 0.7500 (0.7580)\n",
      "\u001b[32m[2020-06-22 18:55:45] __main__ INFO: \u001b[0mEpoch 261 Step 300/351 lr 0.001000 loss 1.3169 (1.2984) acc@1 0.4531 (0.4998) acc@5 0.7188 (0.7580)\n",
      "\u001b[32m[2020-06-22 18:55:49] __main__ INFO: \u001b[0mEpoch 261 Step 351/351 lr 0.001000 loss 1.3617 (1.2969) acc@1 0.4688 (0.5008) acc@5 0.7891 (0.7582)\n",
      "\u001b[32m[2020-06-22 18:55:49] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 18:55:49] __main__ INFO: \u001b[0mVal 261\n",
      "\u001b[32m[2020-06-22 18:55:50] __main__ INFO: \u001b[0mEpoch 261 loss 2.5185 acc@1 0.2814 acc@5 0.6862\n",
      "\u001b[32m[2020-06-22 18:55:50] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:55:50] __main__ INFO: \u001b[0mTrain 262 91611\n",
      "\u001b[32m[2020-06-22 18:56:00] __main__ INFO: \u001b[0mEpoch 262 Step 100/351 lr 0.001000 loss 1.3124 (1.2896) acc@1 0.5156 (0.5084) acc@5 0.7812 (0.7638)\n",
      "\u001b[32m[2020-06-22 18:56:09] __main__ INFO: \u001b[0mEpoch 262 Step 200/351 lr 0.001000 loss 1.2091 (1.2996) acc@1 0.5391 (0.5031) acc@5 0.7812 (0.7582)\n",
      "\u001b[32m[2020-06-22 18:56:18] __main__ INFO: \u001b[0mEpoch 262 Step 300/351 lr 0.001000 loss 1.3606 (1.2969) acc@1 0.4766 (0.5037) acc@5 0.7266 (0.7582)\n",
      "\u001b[32m[2020-06-22 18:56:23] __main__ INFO: \u001b[0mEpoch 262 Step 351/351 lr 0.001000 loss 1.3332 (1.3007) acc@1 0.5391 (0.5013) acc@5 0.7422 (0.7570)\n",
      "\u001b[32m[2020-06-22 18:56:23] __main__ INFO: \u001b[0mElapsed 32.76\n",
      "\u001b[32m[2020-06-22 18:56:23] __main__ INFO: \u001b[0mVal 262\n",
      "\u001b[32m[2020-06-22 18:56:24] __main__ INFO: \u001b[0mEpoch 262 loss 2.5261 acc@1 0.2886 acc@5 0.6912\n",
      "\u001b[32m[2020-06-22 18:56:24] __main__ INFO: \u001b[0mElapsed 1.03\n",
      "\u001b[32m[2020-06-22 18:56:24] __main__ INFO: \u001b[0mTrain 263 91962\n",
      "\u001b[32m[2020-06-22 18:56:34] __main__ INFO: \u001b[0mEpoch 263 Step 100/351 lr 0.001000 loss 1.3300 (1.2784) acc@1 0.4609 (0.5131) acc@5 0.7500 (0.7617)\n",
      "\u001b[32m[2020-06-22 18:56:43] __main__ INFO: \u001b[0mEpoch 263 Step 200/351 lr 0.001000 loss 1.2846 (1.2893) acc@1 0.4922 (0.5083) acc@5 0.7188 (0.7601)\n",
      "\u001b[32m[2020-06-22 18:56:52] __main__ INFO: \u001b[0mEpoch 263 Step 300/351 lr 0.001000 loss 1.2295 (1.3006) acc@1 0.5391 (0.5028) acc@5 0.8047 (0.7577)\n",
      "\u001b[32m[2020-06-22 18:56:57] __main__ INFO: \u001b[0mEpoch 263 Step 351/351 lr 0.001000 loss 1.3686 (1.2988) acc@1 0.4844 (0.5038) acc@5 0.7109 (0.7575)\n",
      "\u001b[32m[2020-06-22 18:56:57] __main__ INFO: \u001b[0mElapsed 32.77\n",
      "\u001b[32m[2020-06-22 18:56:57] __main__ INFO: \u001b[0mVal 263\n",
      "\u001b[32m[2020-06-22 18:56:58] __main__ INFO: \u001b[0mEpoch 263 loss 2.4782 acc@1 0.2898 acc@5 0.6938\n",
      "\u001b[32m[2020-06-22 18:56:58] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:56:58] __main__ INFO: \u001b[0mTrain 264 92313\n",
      "\u001b[32m[2020-06-22 18:57:07] __main__ INFO: \u001b[0mEpoch 264 Step 100/351 lr 0.001000 loss 1.3721 (1.2917) acc@1 0.4766 (0.5045) acc@5 0.7344 (0.7570)\n",
      "\u001b[32m[2020-06-22 18:57:17] __main__ INFO: \u001b[0mEpoch 264 Step 200/351 lr 0.001000 loss 1.3210 (1.2993) acc@1 0.5234 (0.5015) acc@5 0.7422 (0.7559)\n",
      "\u001b[32m[2020-06-22 18:57:26] __main__ INFO: \u001b[0mEpoch 264 Step 300/351 lr 0.001000 loss 1.2004 (1.2975) acc@1 0.5391 (0.5021) acc@5 0.7891 (0.7565)\n",
      "\u001b[32m[2020-06-22 18:57:31] __main__ INFO: \u001b[0mEpoch 264 Step 351/351 lr 0.001000 loss 1.3110 (1.2991) acc@1 0.4922 (0.5019) acc@5 0.7344 (0.7569)\n",
      "\u001b[32m[2020-06-22 18:57:31] __main__ INFO: \u001b[0mElapsed 32.84\n",
      "\u001b[32m[2020-06-22 18:57:31] __main__ INFO: \u001b[0mVal 264\n",
      "\u001b[32m[2020-06-22 18:57:32] __main__ INFO: \u001b[0mEpoch 264 loss 2.5028 acc@1 0.2880 acc@5 0.6854\n",
      "\u001b[32m[2020-06-22 18:57:32] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 18:57:32] __main__ INFO: \u001b[0mTrain 265 92664\n",
      "\u001b[32m[2020-06-22 18:57:41] __main__ INFO: \u001b[0mEpoch 265 Step 100/351 lr 0.001000 loss 1.2887 (1.2968) acc@1 0.5391 (0.5007) acc@5 0.7812 (0.7580)\n",
      "\u001b[32m[2020-06-22 18:57:51] __main__ INFO: \u001b[0mEpoch 265 Step 200/351 lr 0.001000 loss 1.4104 (1.2992) acc@1 0.4609 (0.4989) acc@5 0.7031 (0.7582)\n",
      "\u001b[32m[2020-06-22 18:58:00] __main__ INFO: \u001b[0mEpoch 265 Step 300/351 lr 0.001000 loss 1.4195 (1.3000) acc@1 0.4297 (0.4983) acc@5 0.7344 (0.7581)\n",
      "\u001b[32m[2020-06-22 18:58:05] __main__ INFO: \u001b[0mEpoch 265 Step 351/351 lr 0.001000 loss 1.2595 (1.2993) acc@1 0.5391 (0.4994) acc@5 0.7422 (0.7586)\n",
      "\u001b[32m[2020-06-22 18:58:05] __main__ INFO: \u001b[0mElapsed 32.78\n",
      "\u001b[32m[2020-06-22 18:58:05] __main__ INFO: \u001b[0mVal 265\n",
      "\u001b[32m[2020-06-22 18:58:06] __main__ INFO: \u001b[0mEpoch 265 loss 2.4985 acc@1 0.2898 acc@5 0.6868\n",
      "\u001b[32m[2020-06-22 18:58:06] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 18:58:06] __main__ INFO: \u001b[0mTrain 266 93015\n",
      "\u001b[32m[2020-06-22 18:58:15] __main__ INFO: \u001b[0mEpoch 266 Step 100/351 lr 0.001000 loss 1.2945 (1.2987) acc@1 0.5234 (0.5035) acc@5 0.7656 (0.7541)\n",
      "\u001b[32m[2020-06-22 18:58:24] __main__ INFO: \u001b[0mEpoch 266 Step 200/351 lr 0.001000 loss 1.3179 (1.3005) acc@1 0.4922 (0.5005) acc@5 0.7109 (0.7542)\n",
      "\u001b[32m[2020-06-22 18:58:34] __main__ INFO: \u001b[0mEpoch 266 Step 300/351 lr 0.001000 loss 1.3577 (1.2976) acc@1 0.4688 (0.5022) acc@5 0.7812 (0.7560)\n",
      "\u001b[32m[2020-06-22 18:58:39] __main__ INFO: \u001b[0mEpoch 266 Step 351/351 lr 0.001000 loss 1.1786 (1.2968) acc@1 0.5391 (0.5025) acc@5 0.7969 (0.7566)\n",
      "\u001b[32m[2020-06-22 18:58:39] __main__ INFO: \u001b[0mElapsed 32.82\n",
      "\u001b[32m[2020-06-22 18:58:39] __main__ INFO: \u001b[0mVal 266\n",
      "\u001b[32m[2020-06-22 18:58:40] __main__ INFO: \u001b[0mEpoch 266 loss 2.5368 acc@1 0.2904 acc@5 0.6958\n",
      "\u001b[32m[2020-06-22 18:58:40] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 18:58:40] __main__ INFO: \u001b[0mTrain 267 93366\n",
      "\u001b[32m[2020-06-22 18:58:49] __main__ INFO: \u001b[0mEpoch 267 Step 100/351 lr 0.001000 loss 1.1055 (1.2905) acc@1 0.6016 (0.5025) acc@5 0.7656 (0.7531)\n",
      "\u001b[32m[2020-06-22 18:58:58] __main__ INFO: \u001b[0mEpoch 267 Step 200/351 lr 0.001000 loss 1.2194 (1.2937) acc@1 0.5547 (0.5032) acc@5 0.8047 (0.7539)\n",
      "\u001b[32m[2020-06-22 18:59:08] __main__ INFO: \u001b[0mEpoch 267 Step 300/351 lr 0.001000 loss 1.3310 (1.2899) acc@1 0.5078 (0.5062) acc@5 0.7734 (0.7575)\n",
      "\u001b[32m[2020-06-22 18:59:12] __main__ INFO: \u001b[0mEpoch 267 Step 351/351 lr 0.001000 loss 1.2786 (1.2959) acc@1 0.5625 (0.5040) acc@5 0.7500 (0.7565)\n",
      "\u001b[32m[2020-06-22 18:59:12] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 18:59:12] __main__ INFO: \u001b[0mVal 267\n",
      "\u001b[32m[2020-06-22 18:59:13] __main__ INFO: \u001b[0mEpoch 267 loss 2.5283 acc@1 0.2896 acc@5 0.6908\n",
      "\u001b[32m[2020-06-22 18:59:13] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 18:59:13] __main__ INFO: \u001b[0mTrain 268 93717\n",
      "\u001b[32m[2020-06-22 18:59:23] __main__ INFO: \u001b[0mEpoch 268 Step 100/351 lr 0.001000 loss 1.1208 (1.2884) acc@1 0.5547 (0.5017) acc@5 0.7734 (0.7579)\n",
      "\u001b[32m[2020-06-22 18:59:32] __main__ INFO: \u001b[0mEpoch 268 Step 200/351 lr 0.001000 loss 1.2775 (1.2920) acc@1 0.5156 (0.5009) acc@5 0.7578 (0.7571)\n",
      "\u001b[32m[2020-06-22 18:59:41] __main__ INFO: \u001b[0mEpoch 268 Step 300/351 lr 0.001000 loss 1.4739 (1.2961) acc@1 0.4062 (0.4990) acc@5 0.7109 (0.7561)\n",
      "\u001b[32m[2020-06-22 18:59:46] __main__ INFO: \u001b[0mEpoch 268 Step 351/351 lr 0.001000 loss 1.4046 (1.2938) acc@1 0.4922 (0.5002) acc@5 0.8203 (0.7577)\n",
      "\u001b[32m[2020-06-22 18:59:46] __main__ INFO: \u001b[0mElapsed 32.78\n",
      "\u001b[32m[2020-06-22 18:59:46] __main__ INFO: \u001b[0mVal 268\n",
      "\u001b[32m[2020-06-22 18:59:47] __main__ INFO: \u001b[0mEpoch 268 loss 2.5253 acc@1 0.2912 acc@5 0.6922\n",
      "\u001b[32m[2020-06-22 18:59:47] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 18:59:47] __main__ INFO: \u001b[0mTrain 269 94068\n",
      "\u001b[32m[2020-06-22 18:59:57] __main__ INFO: \u001b[0mEpoch 269 Step 100/351 lr 0.001000 loss 1.2790 (1.2960) acc@1 0.5000 (0.5021) acc@5 0.7891 (0.7540)\n",
      "\u001b[32m[2020-06-22 19:00:06] __main__ INFO: \u001b[0mEpoch 269 Step 200/351 lr 0.001000 loss 1.1954 (1.2947) acc@1 0.5469 (0.5003) acc@5 0.7500 (0.7564)\n",
      "\u001b[32m[2020-06-22 19:00:15] __main__ INFO: \u001b[0mEpoch 269 Step 300/351 lr 0.001000 loss 1.2606 (1.2945) acc@1 0.5156 (0.5005) acc@5 0.8047 (0.7579)\n",
      "\u001b[32m[2020-06-22 19:00:20] __main__ INFO: \u001b[0mEpoch 269 Step 351/351 lr 0.001000 loss 1.4040 (1.2974) acc@1 0.4844 (0.4995) acc@5 0.7422 (0.7578)\n",
      "\u001b[32m[2020-06-22 19:00:20] __main__ INFO: \u001b[0mElapsed 32.82\n",
      "\u001b[32m[2020-06-22 19:00:20] __main__ INFO: \u001b[0mVal 269\n",
      "\u001b[32m[2020-06-22 19:00:21] __main__ INFO: \u001b[0mEpoch 269 loss 2.5405 acc@1 0.2832 acc@5 0.6932\n",
      "\u001b[32m[2020-06-22 19:00:21] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 19:00:21] __main__ INFO: \u001b[0mTrain 270 94419\n",
      "\u001b[32m[2020-06-22 19:00:31] __main__ INFO: \u001b[0mEpoch 270 Step 100/351 lr 0.001000 loss 1.3577 (1.2825) acc@1 0.5000 (0.5075) acc@5 0.7422 (0.7594)\n",
      "\u001b[32m[2020-06-22 19:00:40] __main__ INFO: \u001b[0mEpoch 270 Step 200/351 lr 0.001000 loss 1.1519 (1.2838) acc@1 0.5781 (0.5088) acc@5 0.8516 (0.7607)\n",
      "\u001b[32m[2020-06-22 19:00:49] __main__ INFO: \u001b[0mEpoch 270 Step 300/351 lr 0.001000 loss 1.0766 (1.2881) acc@1 0.5859 (0.5062) acc@5 0.7969 (0.7582)\n",
      "\u001b[32m[2020-06-22 19:00:54] __main__ INFO: \u001b[0mEpoch 270 Step 351/351 lr 0.001000 loss 1.3848 (1.2935) acc@1 0.4297 (0.5040) acc@5 0.7031 (0.7574)\n",
      "\u001b[32m[2020-06-22 19:00:54] __main__ INFO: \u001b[0mElapsed 32.85\n",
      "\u001b[32m[2020-06-22 19:00:54] __main__ INFO: \u001b[0mVal 270\n",
      "\u001b[32m[2020-06-22 19:00:55] __main__ INFO: \u001b[0mEpoch 270 loss 2.5697 acc@1 0.2834 acc@5 0.6846\n",
      "\u001b[32m[2020-06-22 19:00:55] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 19:00:55] __main__ INFO: \u001b[0mTrain 271 94770\n",
      "\u001b[32m[2020-06-22 19:01:05] __main__ INFO: \u001b[0mEpoch 271 Step 100/351 lr 0.001000 loss 1.3296 (1.2769) acc@1 0.4688 (0.5127) acc@5 0.7109 (0.7596)\n",
      "\u001b[32m[2020-06-22 19:01:14] __main__ INFO: \u001b[0mEpoch 271 Step 200/351 lr 0.001000 loss 1.1880 (1.2864) acc@1 0.5547 (0.5086) acc@5 0.7734 (0.7589)\n",
      "\u001b[32m[2020-06-22 19:01:23] __main__ INFO: \u001b[0mEpoch 271 Step 300/351 lr 0.001000 loss 1.2594 (1.2931) acc@1 0.5078 (0.5045) acc@5 0.7578 (0.7574)\n",
      "\u001b[32m[2020-06-22 19:01:28] __main__ INFO: \u001b[0mEpoch 271 Step 351/351 lr 0.001000 loss 1.1653 (1.2947) acc@1 0.5469 (0.5036) acc@5 0.7734 (0.7570)\n",
      "\u001b[32m[2020-06-22 19:01:28] __main__ INFO: \u001b[0mElapsed 32.81\n",
      "\u001b[32m[2020-06-22 19:01:28] __main__ INFO: \u001b[0mVal 271\n",
      "\u001b[32m[2020-06-22 19:01:29] __main__ INFO: \u001b[0mEpoch 271 loss 2.5256 acc@1 0.2890 acc@5 0.6916\n",
      "\u001b[32m[2020-06-22 19:01:29] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 19:01:29] __main__ INFO: \u001b[0mTrain 272 95121\n",
      "\u001b[32m[2020-06-22 19:01:38] __main__ INFO: \u001b[0mEpoch 272 Step 100/351 lr 0.001000 loss 1.2598 (1.3005) acc@1 0.5312 (0.4989) acc@5 0.7812 (0.7555)\n",
      "\u001b[32m[2020-06-22 19:01:48] __main__ INFO: \u001b[0mEpoch 272 Step 200/351 lr 0.001000 loss 1.3111 (1.2953) acc@1 0.5000 (0.5019) acc@5 0.7734 (0.7589)\n",
      "\u001b[32m[2020-06-22 19:01:57] __main__ INFO: \u001b[0mEpoch 272 Step 300/351 lr 0.001000 loss 1.1944 (1.2937) acc@1 0.5625 (0.5035) acc@5 0.7109 (0.7577)\n",
      "\u001b[32m[2020-06-22 19:02:02] __main__ INFO: \u001b[0mEpoch 272 Step 351/351 lr 0.001000 loss 1.3850 (1.2944) acc@1 0.4609 (0.5030) acc@5 0.7188 (0.7581)\n",
      "\u001b[32m[2020-06-22 19:02:02] __main__ INFO: \u001b[0mElapsed 32.83\n",
      "\u001b[32m[2020-06-22 19:02:02] __main__ INFO: \u001b[0mVal 272\n",
      "\u001b[32m[2020-06-22 19:02:03] __main__ INFO: \u001b[0mEpoch 272 loss 2.5340 acc@1 0.2910 acc@5 0.6932\n",
      "\u001b[32m[2020-06-22 19:02:03] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 19:02:03] __main__ INFO: \u001b[0mTrain 273 95472\n",
      "\u001b[32m[2020-06-22 19:02:12] __main__ INFO: \u001b[0mEpoch 273 Step 100/351 lr 0.001000 loss 1.2813 (1.2789) acc@1 0.5078 (0.5147) acc@5 0.8281 (0.7578)\n",
      "\u001b[32m[2020-06-22 19:02:22] __main__ INFO: \u001b[0mEpoch 273 Step 200/351 lr 0.001000 loss 1.3156 (1.2881) acc@1 0.5000 (0.5087) acc@5 0.7422 (0.7553)\n",
      "\u001b[32m[2020-06-22 19:02:31] __main__ INFO: \u001b[0mEpoch 273 Step 300/351 lr 0.001000 loss 1.2616 (1.2874) acc@1 0.5078 (0.5082) acc@5 0.7422 (0.7561)\n",
      "\u001b[32m[2020-06-22 19:02:36] __main__ INFO: \u001b[0mEpoch 273 Step 351/351 lr 0.001000 loss 1.3276 (1.2917) acc@1 0.4766 (0.5062) acc@5 0.7500 (0.7555)\n",
      "\u001b[32m[2020-06-22 19:02:36] __main__ INFO: \u001b[0mElapsed 32.82\n",
      "\u001b[32m[2020-06-22 19:02:36] __main__ INFO: \u001b[0mVal 273\n",
      "\u001b[32m[2020-06-22 19:02:37] __main__ INFO: \u001b[0mEpoch 273 loss 2.5801 acc@1 0.2794 acc@5 0.6900\n",
      "\u001b[32m[2020-06-22 19:02:37] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 19:02:37] __main__ INFO: \u001b[0mTrain 274 95823\n",
      "\u001b[32m[2020-06-22 19:02:46] __main__ INFO: \u001b[0mEpoch 274 Step 100/351 lr 0.001000 loss 1.0641 (1.2957) acc@1 0.5938 (0.5041) acc@5 0.7500 (0.7593)\n",
      "\u001b[32m[2020-06-22 19:02:55] __main__ INFO: \u001b[0mEpoch 274 Step 200/351 lr 0.001000 loss 1.2199 (1.2961) acc@1 0.5312 (0.5039) acc@5 0.7188 (0.7580)\n",
      "\u001b[32m[2020-06-22 19:03:05] __main__ INFO: \u001b[0mEpoch 274 Step 300/351 lr 0.001000 loss 1.4164 (1.2955) acc@1 0.4297 (0.5030) acc@5 0.7266 (0.7566)\n",
      "\u001b[32m[2020-06-22 19:03:10] __main__ INFO: \u001b[0mEpoch 274 Step 351/351 lr 0.001000 loss 1.3443 (1.2942) acc@1 0.4609 (0.5033) acc@5 0.7656 (0.7562)\n",
      "\u001b[32m[2020-06-22 19:03:10] __main__ INFO: \u001b[0mElapsed 32.83\n",
      "\u001b[32m[2020-06-22 19:03:10] __main__ INFO: \u001b[0mVal 274\n",
      "\u001b[32m[2020-06-22 19:03:11] __main__ INFO: \u001b[0mEpoch 274 loss 2.5665 acc@1 0.2866 acc@5 0.7006\n",
      "\u001b[32m[2020-06-22 19:03:11] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 19:03:11] __main__ INFO: \u001b[0mTrain 275 96174\n",
      "\u001b[32m[2020-06-22 19:03:20] __main__ INFO: \u001b[0mEpoch 275 Step 100/351 lr 0.001000 loss 1.2857 (1.2839) acc@1 0.5156 (0.5090) acc@5 0.7422 (0.7554)\n",
      "\u001b[32m[2020-06-22 19:03:29] __main__ INFO: \u001b[0mEpoch 275 Step 200/351 lr 0.001000 loss 1.3876 (1.2946) acc@1 0.4922 (0.5040) acc@5 0.6875 (0.7562)\n",
      "\u001b[32m[2020-06-22 19:03:39] __main__ INFO: \u001b[0mEpoch 275 Step 300/351 lr 0.001000 loss 1.3627 (1.2929) acc@1 0.4844 (0.5044) acc@5 0.7031 (0.7560)\n",
      "\u001b[32m[2020-06-22 19:03:43] __main__ INFO: \u001b[0mEpoch 275 Step 351/351 lr 0.001000 loss 1.1586 (1.2939) acc@1 0.5234 (0.5037) acc@5 0.7891 (0.7559)\n",
      "\u001b[32m[2020-06-22 19:03:43] __main__ INFO: \u001b[0mElapsed 32.87\n",
      "\u001b[32m[2020-06-22 19:03:43] __main__ INFO: \u001b[0mVal 275\n",
      "\u001b[32m[2020-06-22 19:03:45] __main__ INFO: \u001b[0mEpoch 275 loss 2.5264 acc@1 0.2826 acc@5 0.6876\n",
      "\u001b[32m[2020-06-22 19:03:45] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 19:03:45] __main__ INFO: \u001b[0mTrain 276 96525\n",
      "\u001b[32m[2020-06-22 19:03:54] __main__ INFO: \u001b[0mEpoch 276 Step 100/351 lr 0.001000 loss 1.2862 (1.2844) acc@1 0.5156 (0.5059) acc@5 0.7578 (0.7538)\n",
      "\u001b[32m[2020-06-22 19:04:03] __main__ INFO: \u001b[0mEpoch 276 Step 200/351 lr 0.001000 loss 1.1708 (1.2915) acc@1 0.5312 (0.5051) acc@5 0.7422 (0.7553)\n",
      "\u001b[32m[2020-06-22 19:04:13] __main__ INFO: \u001b[0mEpoch 276 Step 300/351 lr 0.001000 loss 1.1656 (1.2873) acc@1 0.5781 (0.5057) acc@5 0.7344 (0.7536)\n",
      "\u001b[32m[2020-06-22 19:04:17] __main__ INFO: \u001b[0mEpoch 276 Step 351/351 lr 0.001000 loss 1.2954 (1.2873) acc@1 0.4844 (0.5061) acc@5 0.7344 (0.7545)\n",
      "\u001b[32m[2020-06-22 19:04:17] __main__ INFO: \u001b[0mElapsed 32.81\n",
      "\u001b[32m[2020-06-22 19:04:17] __main__ INFO: \u001b[0mVal 276\n",
      "\u001b[32m[2020-06-22 19:04:18] __main__ INFO: \u001b[0mEpoch 276 loss 2.5397 acc@1 0.2770 acc@5 0.6916\n",
      "\u001b[32m[2020-06-22 19:04:18] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 19:04:18] __main__ INFO: \u001b[0mTrain 277 96876\n",
      "\u001b[32m[2020-06-22 19:04:28] __main__ INFO: \u001b[0mEpoch 277 Step 100/351 lr 0.001000 loss 1.2670 (1.2842) acc@1 0.5000 (0.5120) acc@5 0.7500 (0.7584)\n",
      "\u001b[32m[2020-06-22 19:04:37] __main__ INFO: \u001b[0mEpoch 277 Step 200/351 lr 0.001000 loss 1.1264 (1.2848) acc@1 0.5625 (0.5085) acc@5 0.8203 (0.7563)\n",
      "\u001b[32m[2020-06-22 19:04:46] __main__ INFO: \u001b[0mEpoch 277 Step 300/351 lr 0.001000 loss 1.3458 (1.2888) acc@1 0.4844 (0.5068) acc@5 0.7031 (0.7546)\n",
      "\u001b[32m[2020-06-22 19:04:51] __main__ INFO: \u001b[0mEpoch 277 Step 351/351 lr 0.001000 loss 1.3940 (1.2895) acc@1 0.4531 (0.5064) acc@5 0.7266 (0.7555)\n",
      "\u001b[32m[2020-06-22 19:04:51] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 19:04:51] __main__ INFO: \u001b[0mVal 277\n",
      "\u001b[32m[2020-06-22 19:04:52] __main__ INFO: \u001b[0mEpoch 277 loss 2.5387 acc@1 0.2846 acc@5 0.6984\n",
      "\u001b[32m[2020-06-22 19:04:52] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 19:04:52] __main__ INFO: \u001b[0mTrain 278 97227\n",
      "\u001b[32m[2020-06-22 19:05:02] __main__ INFO: \u001b[0mEpoch 278 Step 100/351 lr 0.001000 loss 1.2676 (1.2993) acc@1 0.5156 (0.4981) acc@5 0.7344 (0.7569)\n",
      "\u001b[32m[2020-06-22 19:05:11] __main__ INFO: \u001b[0mEpoch 278 Step 200/351 lr 0.001000 loss 1.1960 (1.2847) acc@1 0.5078 (0.5061) acc@5 0.7734 (0.7581)\n",
      "\u001b[32m[2020-06-22 19:05:20] __main__ INFO: \u001b[0mEpoch 278 Step 300/351 lr 0.001000 loss 1.6235 (1.2887) acc@1 0.3750 (0.5047) acc@5 0.6875 (0.7587)\n",
      "\u001b[32m[2020-06-22 19:05:25] __main__ INFO: \u001b[0mEpoch 278 Step 351/351 lr 0.001000 loss 1.2368 (1.2899) acc@1 0.5156 (0.5047) acc@5 0.7969 (0.7585)\n",
      "\u001b[32m[2020-06-22 19:05:25] __main__ INFO: \u001b[0mElapsed 32.82\n",
      "\u001b[32m[2020-06-22 19:05:25] __main__ INFO: \u001b[0mVal 278\n",
      "\u001b[32m[2020-06-22 19:05:26] __main__ INFO: \u001b[0mEpoch 278 loss 2.5674 acc@1 0.2876 acc@5 0.6934\n",
      "\u001b[32m[2020-06-22 19:05:26] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 19:05:26] __main__ INFO: \u001b[0mTrain 279 97578\n",
      "\u001b[32m[2020-06-22 19:05:36] __main__ INFO: \u001b[0mEpoch 279 Step 100/351 lr 0.001000 loss 1.3852 (1.2793) acc@1 0.5156 (0.5080) acc@5 0.7266 (0.7588)\n",
      "\u001b[32m[2020-06-22 19:05:45] __main__ INFO: \u001b[0mEpoch 279 Step 200/351 lr 0.001000 loss 1.3497 (1.2858) acc@1 0.4844 (0.5052) acc@5 0.7109 (0.7565)\n",
      "\u001b[32m[2020-06-22 19:05:54] __main__ INFO: \u001b[0mEpoch 279 Step 300/351 lr 0.001000 loss 1.1276 (1.2888) acc@1 0.5547 (0.5041) acc@5 0.7891 (0.7576)\n",
      "\u001b[32m[2020-06-22 19:05:59] __main__ INFO: \u001b[0mEpoch 279 Step 351/351 lr 0.001000 loss 1.2707 (1.2909) acc@1 0.4844 (0.5033) acc@5 0.8047 (0.7578)\n",
      "\u001b[32m[2020-06-22 19:05:59] __main__ INFO: \u001b[0mElapsed 32.74\n",
      "\u001b[32m[2020-06-22 19:05:59] __main__ INFO: \u001b[0mVal 279\n",
      "\u001b[32m[2020-06-22 19:06:00] __main__ INFO: \u001b[0mEpoch 279 loss 2.5728 acc@1 0.2886 acc@5 0.7042\n",
      "\u001b[32m[2020-06-22 19:06:00] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 19:06:00] __main__ INFO: \u001b[0mTrain 280 97929\n",
      "\u001b[32m[2020-06-22 19:06:09] __main__ INFO: \u001b[0mEpoch 280 Step 100/351 lr 0.001000 loss 1.2237 (1.2899) acc@1 0.5391 (0.5057) acc@5 0.7969 (0.7526)\n",
      "\u001b[32m[2020-06-22 19:06:19] __main__ INFO: \u001b[0mEpoch 280 Step 200/351 lr 0.001000 loss 1.2845 (1.2830) acc@1 0.5078 (0.5074) acc@5 0.7031 (0.7555)\n",
      "\u001b[32m[2020-06-22 19:06:28] __main__ INFO: \u001b[0mEpoch 280 Step 300/351 lr 0.001000 loss 1.3969 (1.2845) acc@1 0.4297 (0.5050) acc@5 0.7422 (0.7557)\n",
      "\u001b[32m[2020-06-22 19:06:33] __main__ INFO: \u001b[0mEpoch 280 Step 351/351 lr 0.001000 loss 1.2482 (1.2871) acc@1 0.5234 (0.5042) acc@5 0.7500 (0.7557)\n",
      "\u001b[32m[2020-06-22 19:06:33] __main__ INFO: \u001b[0mElapsed 32.81\n",
      "\u001b[32m[2020-06-22 19:06:33] __main__ INFO: \u001b[0mVal 280\n",
      "\u001b[32m[2020-06-22 19:06:34] __main__ INFO: \u001b[0mEpoch 280 loss 2.5706 acc@1 0.2922 acc@5 0.6912\n",
      "\u001b[32m[2020-06-22 19:06:34] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 19:06:34] __main__ INFO: \u001b[0mTrain 281 98280\n",
      "\u001b[32m[2020-06-22 19:06:43] __main__ INFO: \u001b[0mEpoch 281 Step 100/351 lr 0.001000 loss 1.5064 (1.2821) acc@1 0.3906 (0.5089) acc@5 0.6328 (0.7605)\n",
      "\u001b[32m[2020-06-22 19:06:53] __main__ INFO: \u001b[0mEpoch 281 Step 200/351 lr 0.001000 loss 1.3884 (1.2851) acc@1 0.4609 (0.5086) acc@5 0.7422 (0.7594)\n",
      "\u001b[32m[2020-06-22 19:07:02] __main__ INFO: \u001b[0mEpoch 281 Step 300/351 lr 0.001000 loss 1.2817 (1.2843) acc@1 0.4766 (0.5079) acc@5 0.8281 (0.7586)\n",
      "\u001b[32m[2020-06-22 19:07:07] __main__ INFO: \u001b[0mEpoch 281 Step 351/351 lr 0.001000 loss 1.2090 (1.2875) acc@1 0.5547 (0.5061) acc@5 0.8203 (0.7580)\n",
      "\u001b[32m[2020-06-22 19:07:07] __main__ INFO: \u001b[0mElapsed 32.83\n",
      "\u001b[32m[2020-06-22 19:07:07] __main__ INFO: \u001b[0mVal 281\n",
      "\u001b[32m[2020-06-22 19:07:08] __main__ INFO: \u001b[0mEpoch 281 loss 2.5469 acc@1 0.2858 acc@5 0.7040\n",
      "\u001b[32m[2020-06-22 19:07:08] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 19:07:08] __main__ INFO: \u001b[0mTrain 282 98631\n",
      "\u001b[32m[2020-06-22 19:07:17] __main__ INFO: \u001b[0mEpoch 282 Step 100/351 lr 0.001000 loss 1.3591 (1.2794) acc@1 0.4766 (0.5079) acc@5 0.7344 (0.7608)\n",
      "\u001b[32m[2020-06-22 19:07:26] __main__ INFO: \u001b[0mEpoch 282 Step 200/351 lr 0.001000 loss 1.1965 (1.2833) acc@1 0.5078 (0.5062) acc@5 0.7734 (0.7577)\n",
      "\u001b[32m[2020-06-22 19:07:36] __main__ INFO: \u001b[0mEpoch 282 Step 300/351 lr 0.001000 loss 1.4364 (1.2840) acc@1 0.4688 (0.5057) acc@5 0.7422 (0.7564)\n",
      "\u001b[32m[2020-06-22 19:07:40] __main__ INFO: \u001b[0mEpoch 282 Step 351/351 lr 0.001000 loss 1.4026 (1.2858) acc@1 0.4766 (0.5051) acc@5 0.7734 (0.7569)\n",
      "\u001b[32m[2020-06-22 19:07:41] __main__ INFO: \u001b[0mElapsed 32.82\n",
      "\u001b[32m[2020-06-22 19:07:41] __main__ INFO: \u001b[0mVal 282\n",
      "\u001b[32m[2020-06-22 19:07:42] __main__ INFO: \u001b[0mEpoch 282 loss 2.5518 acc@1 0.2866 acc@5 0.6916\n",
      "\u001b[32m[2020-06-22 19:07:42] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 19:07:42] __main__ INFO: \u001b[0mTrain 283 98982\n",
      "\u001b[32m[2020-06-22 19:07:51] __main__ INFO: \u001b[0mEpoch 283 Step 100/351 lr 0.001000 loss 1.2272 (1.2850) acc@1 0.5391 (0.5122) acc@5 0.8125 (0.7591)\n",
      "\u001b[32m[2020-06-22 19:08:00] __main__ INFO: \u001b[0mEpoch 283 Step 200/351 lr 0.001000 loss 1.2868 (1.2871) acc@1 0.4844 (0.5094) acc@5 0.7109 (0.7587)\n",
      "\u001b[32m[2020-06-22 19:08:10] __main__ INFO: \u001b[0mEpoch 283 Step 300/351 lr 0.001000 loss 1.2402 (1.2899) acc@1 0.5000 (0.5071) acc@5 0.7891 (0.7568)\n",
      "\u001b[32m[2020-06-22 19:08:14] __main__ INFO: \u001b[0mEpoch 283 Step 351/351 lr 0.001000 loss 1.2800 (1.2858) acc@1 0.4844 (0.5083) acc@5 0.7812 (0.7576)\n",
      "\u001b[32m[2020-06-22 19:08:14] __main__ INFO: \u001b[0mElapsed 32.82\n",
      "\u001b[32m[2020-06-22 19:08:14] __main__ INFO: \u001b[0mVal 283\n",
      "\u001b[32m[2020-06-22 19:08:15] __main__ INFO: \u001b[0mEpoch 283 loss 2.5492 acc@1 0.2860 acc@5 0.6890\n",
      "\u001b[32m[2020-06-22 19:08:15] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 19:08:15] __main__ INFO: \u001b[0mTrain 284 99333\n",
      "\u001b[32m[2020-06-22 19:08:25] __main__ INFO: \u001b[0mEpoch 284 Step 100/351 lr 0.001000 loss 1.3390 (1.2904) acc@1 0.4922 (0.5051) acc@5 0.7734 (0.7596)\n",
      "\u001b[32m[2020-06-22 19:08:34] __main__ INFO: \u001b[0mEpoch 284 Step 200/351 lr 0.001000 loss 1.2657 (1.2871) acc@1 0.5234 (0.5066) acc@5 0.7500 (0.7588)\n",
      "\u001b[32m[2020-06-22 19:08:44] __main__ INFO: \u001b[0mEpoch 284 Step 300/351 lr 0.001000 loss 1.4187 (1.2822) acc@1 0.4688 (0.5085) acc@5 0.7344 (0.7591)\n",
      "\u001b[32m[2020-06-22 19:08:48] __main__ INFO: \u001b[0mEpoch 284 Step 351/351 lr 0.001000 loss 1.1933 (1.2835) acc@1 0.5312 (0.5075) acc@5 0.7266 (0.7584)\n",
      "\u001b[32m[2020-06-22 19:08:48] __main__ INFO: \u001b[0mElapsed 32.82\n",
      "\u001b[32m[2020-06-22 19:08:48] __main__ INFO: \u001b[0mVal 284\n",
      "\u001b[32m[2020-06-22 19:08:49] __main__ INFO: \u001b[0mEpoch 284 loss 2.5792 acc@1 0.2866 acc@5 0.6838\n",
      "\u001b[32m[2020-06-22 19:08:49] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 19:08:49] __main__ INFO: \u001b[0mTrain 285 99684\n",
      "\u001b[32m[2020-06-22 19:08:59] __main__ INFO: \u001b[0mEpoch 285 Step 100/351 lr 0.001000 loss 1.1414 (1.2754) acc@1 0.5391 (0.5096) acc@5 0.8125 (0.7546)\n",
      "\u001b[32m[2020-06-22 19:09:08] __main__ INFO: \u001b[0mEpoch 285 Step 200/351 lr 0.001000 loss 1.3614 (1.2781) acc@1 0.4609 (0.5089) acc@5 0.7031 (0.7564)\n",
      "\u001b[32m[2020-06-22 19:09:17] __main__ INFO: \u001b[0mEpoch 285 Step 300/351 lr 0.001000 loss 1.5070 (1.2822) acc@1 0.3984 (0.5061) acc@5 0.7656 (0.7577)\n",
      "\u001b[32m[2020-06-22 19:09:22] __main__ INFO: \u001b[0mEpoch 285 Step 351/351 lr 0.001000 loss 1.2962 (1.2844) acc@1 0.4922 (0.5062) acc@5 0.7734 (0.7586)\n",
      "\u001b[32m[2020-06-22 19:09:22] __main__ INFO: \u001b[0mElapsed 32.81\n",
      "\u001b[32m[2020-06-22 19:09:22] __main__ INFO: \u001b[0mVal 285\n",
      "\u001b[32m[2020-06-22 19:09:23] __main__ INFO: \u001b[0mEpoch 285 loss 2.5665 acc@1 0.2852 acc@5 0.6916\n",
      "\u001b[32m[2020-06-22 19:09:23] __main__ INFO: \u001b[0mElapsed 1.03\n",
      "\u001b[32m[2020-06-22 19:09:23] __main__ INFO: \u001b[0mTrain 286 100035\n",
      "\u001b[32m[2020-06-22 19:09:33] __main__ INFO: \u001b[0mEpoch 286 Step 100/351 lr 0.001000 loss 1.3257 (1.2820) acc@1 0.4922 (0.5098) acc@5 0.8047 (0.7567)\n",
      "\u001b[32m[2020-06-22 19:09:42] __main__ INFO: \u001b[0mEpoch 286 Step 200/351 lr 0.001000 loss 1.4005 (1.2815) acc@1 0.4453 (0.5096) acc@5 0.7109 (0.7566)\n",
      "\u001b[32m[2020-06-22 19:09:51] __main__ INFO: \u001b[0mEpoch 286 Step 300/351 lr 0.001000 loss 1.3424 (1.2842) acc@1 0.4922 (0.5077) acc@5 0.7812 (0.7576)\n",
      "\u001b[32m[2020-06-22 19:09:56] __main__ INFO: \u001b[0mEpoch 286 Step 351/351 lr 0.001000 loss 1.2213 (1.2823) acc@1 0.5625 (0.5088) acc@5 0.8359 (0.7583)\n",
      "\u001b[32m[2020-06-22 19:09:56] __main__ INFO: \u001b[0mElapsed 32.83\n",
      "\u001b[32m[2020-06-22 19:09:56] __main__ INFO: \u001b[0mVal 286\n",
      "\u001b[32m[2020-06-22 19:09:57] __main__ INFO: \u001b[0mEpoch 286 loss 2.5447 acc@1 0.2906 acc@5 0.6922\n",
      "\u001b[32m[2020-06-22 19:09:57] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 19:09:57] __main__ INFO: \u001b[0mTrain 287 100386\n",
      "\u001b[32m[2020-06-22 19:10:06] __main__ INFO: \u001b[0mEpoch 287 Step 100/351 lr 0.001000 loss 1.2413 (1.2712) acc@1 0.5156 (0.5119) acc@5 0.7344 (0.7580)\n",
      "\u001b[32m[2020-06-22 19:10:16] __main__ INFO: \u001b[0mEpoch 287 Step 200/351 lr 0.001000 loss 1.3769 (1.2801) acc@1 0.4688 (0.5089) acc@5 0.7734 (0.7542)\n",
      "\u001b[32m[2020-06-22 19:10:25] __main__ INFO: \u001b[0mEpoch 287 Step 300/351 lr 0.001000 loss 1.2571 (1.2838) acc@1 0.5000 (0.5085) acc@5 0.7266 (0.7565)\n",
      "\u001b[32m[2020-06-22 19:10:30] __main__ INFO: \u001b[0mEpoch 287 Step 351/351 lr 0.001000 loss 1.3490 (1.2809) acc@1 0.4766 (0.5094) acc@5 0.7266 (0.7567)\n",
      "\u001b[32m[2020-06-22 19:10:30] __main__ INFO: \u001b[0mElapsed 32.78\n",
      "\u001b[32m[2020-06-22 19:10:30] __main__ INFO: \u001b[0mVal 287\n",
      "\u001b[32m[2020-06-22 19:10:31] __main__ INFO: \u001b[0mEpoch 287 loss 2.5511 acc@1 0.2860 acc@5 0.6904\n",
      "\u001b[32m[2020-06-22 19:10:31] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 19:10:31] __main__ INFO: \u001b[0mTrain 288 100737\n",
      "\u001b[32m[2020-06-22 19:10:40] __main__ INFO: \u001b[0mEpoch 288 Step 100/351 lr 0.001000 loss 1.2195 (1.2801) acc@1 0.5547 (0.5046) acc@5 0.7500 (0.7572)\n",
      "\u001b[32m[2020-06-22 19:10:50] __main__ INFO: \u001b[0mEpoch 288 Step 200/351 lr 0.001000 loss 1.3100 (1.2860) acc@1 0.5078 (0.5045) acc@5 0.7812 (0.7570)\n",
      "\u001b[32m[2020-06-22 19:10:59] __main__ INFO: \u001b[0mEpoch 288 Step 300/351 lr 0.001000 loss 1.2559 (1.2874) acc@1 0.5156 (0.5046) acc@5 0.7188 (0.7571)\n",
      "\u001b[32m[2020-06-22 19:11:04] __main__ INFO: \u001b[0mEpoch 288 Step 351/351 lr 0.001000 loss 1.1903 (1.2854) acc@1 0.5547 (0.5059) acc@5 0.8203 (0.7582)\n",
      "\u001b[32m[2020-06-22 19:11:04] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 19:11:04] __main__ INFO: \u001b[0mVal 288\n",
      "\u001b[32m[2020-06-22 19:11:05] __main__ INFO: \u001b[0mEpoch 288 loss 2.5233 acc@1 0.2792 acc@5 0.6916\n",
      "\u001b[32m[2020-06-22 19:11:05] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 19:11:05] __main__ INFO: \u001b[0mTrain 289 101088\n",
      "\u001b[32m[2020-06-22 19:11:14] __main__ INFO: \u001b[0mEpoch 289 Step 100/351 lr 0.001000 loss 1.0623 (1.2665) acc@1 0.5859 (0.5134) acc@5 0.7578 (0.7655)\n",
      "\u001b[32m[2020-06-22 19:11:24] __main__ INFO: \u001b[0mEpoch 289 Step 200/351 lr 0.001000 loss 1.2843 (1.2769) acc@1 0.4844 (0.5092) acc@5 0.7266 (0.7605)\n",
      "\u001b[32m[2020-06-22 19:11:33] __main__ INFO: \u001b[0mEpoch 289 Step 300/351 lr 0.001000 loss 1.1704 (1.2770) acc@1 0.5625 (0.5105) acc@5 0.8203 (0.7590)\n",
      "\u001b[32m[2020-06-22 19:11:38] __main__ INFO: \u001b[0mEpoch 289 Step 351/351 lr 0.001000 loss 1.2565 (1.2812) acc@1 0.5781 (0.5089) acc@5 0.7734 (0.7578)\n",
      "\u001b[32m[2020-06-22 19:11:38] __main__ INFO: \u001b[0mElapsed 32.82\n",
      "\u001b[32m[2020-06-22 19:11:38] __main__ INFO: \u001b[0mVal 289\n",
      "\u001b[32m[2020-06-22 19:11:39] __main__ INFO: \u001b[0mEpoch 289 loss 2.5645 acc@1 0.2844 acc@5 0.6912\n",
      "\u001b[32m[2020-06-22 19:11:39] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 19:11:39] __main__ INFO: \u001b[0mTrain 290 101439\n",
      "\u001b[32m[2020-06-22 19:11:48] __main__ INFO: \u001b[0mEpoch 290 Step 100/351 lr 0.001000 loss 1.2704 (1.2706) acc@1 0.4766 (0.5088) acc@5 0.7422 (0.7590)\n",
      "\u001b[32m[2020-06-22 19:11:57] __main__ INFO: \u001b[0mEpoch 290 Step 200/351 lr 0.001000 loss 1.2412 (1.2843) acc@1 0.5234 (0.5074) acc@5 0.7500 (0.7593)\n",
      "\u001b[32m[2020-06-22 19:12:07] __main__ INFO: \u001b[0mEpoch 290 Step 300/351 lr 0.001000 loss 1.1032 (1.2803) acc@1 0.5547 (0.5075) acc@5 0.8203 (0.7598)\n",
      "\u001b[32m[2020-06-22 19:12:11] __main__ INFO: \u001b[0mEpoch 290 Step 351/351 lr 0.001000 loss 1.2681 (1.2797) acc@1 0.4688 (0.5079) acc@5 0.7422 (0.7601)\n",
      "\u001b[32m[2020-06-22 19:12:11] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 19:12:11] __main__ INFO: \u001b[0mVal 290\n",
      "\u001b[32m[2020-06-22 19:12:13] __main__ INFO: \u001b[0mEpoch 290 loss 2.5313 acc@1 0.2896 acc@5 0.6886\n",
      "\u001b[32m[2020-06-22 19:12:13] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 19:12:13] __main__ INFO: \u001b[0mTrain 291 101790\n",
      "\u001b[32m[2020-06-22 19:12:22] __main__ INFO: \u001b[0mEpoch 291 Step 100/351 lr 0.001000 loss 1.2679 (1.2841) acc@1 0.5312 (0.5054) acc@5 0.7344 (0.7524)\n",
      "\u001b[32m[2020-06-22 19:12:31] __main__ INFO: \u001b[0mEpoch 291 Step 200/351 lr 0.001000 loss 1.2832 (1.2840) acc@1 0.5234 (0.5061) acc@5 0.7734 (0.7547)\n",
      "\u001b[32m[2020-06-22 19:12:41] __main__ INFO: \u001b[0mEpoch 291 Step 300/351 lr 0.001000 loss 1.3252 (1.2829) acc@1 0.5469 (0.5061) acc@5 0.7578 (0.7560)\n",
      "\u001b[32m[2020-06-22 19:12:45] __main__ INFO: \u001b[0mEpoch 291 Step 351/351 lr 0.001000 loss 1.1877 (1.2795) acc@1 0.5312 (0.5074) acc@5 0.7422 (0.7566)\n",
      "\u001b[32m[2020-06-22 19:12:45] __main__ INFO: \u001b[0mElapsed 32.84\n",
      "\u001b[32m[2020-06-22 19:12:45] __main__ INFO: \u001b[0mVal 291\n",
      "\u001b[32m[2020-06-22 19:12:46] __main__ INFO: \u001b[0mEpoch 291 loss 2.5609 acc@1 0.2796 acc@5 0.6954\n",
      "\u001b[32m[2020-06-22 19:12:46] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 19:12:46] __main__ INFO: \u001b[0mTrain 292 102141\n",
      "\u001b[32m[2020-06-22 19:12:56] __main__ INFO: \u001b[0mEpoch 292 Step 100/351 lr 0.001000 loss 1.3668 (1.2782) acc@1 0.4375 (0.5120) acc@5 0.7734 (0.7561)\n",
      "\u001b[32m[2020-06-22 19:13:05] __main__ INFO: \u001b[0mEpoch 292 Step 200/351 lr 0.001000 loss 1.0699 (1.2731) acc@1 0.5547 (0.5120) acc@5 0.8203 (0.7569)\n",
      "\u001b[32m[2020-06-22 19:13:14] __main__ INFO: \u001b[0mEpoch 292 Step 300/351 lr 0.001000 loss 1.1993 (1.2822) acc@1 0.5703 (0.5072) acc@5 0.7891 (0.7549)\n",
      "\u001b[32m[2020-06-22 19:13:19] __main__ INFO: \u001b[0mEpoch 292 Step 351/351 lr 0.001000 loss 1.3864 (1.2825) acc@1 0.4688 (0.5065) acc@5 0.7500 (0.7553)\n",
      "\u001b[32m[2020-06-22 19:13:19] __main__ INFO: \u001b[0mElapsed 32.76\n",
      "\u001b[32m[2020-06-22 19:13:19] __main__ INFO: \u001b[0mVal 292\n",
      "\u001b[32m[2020-06-22 19:13:20] __main__ INFO: \u001b[0mEpoch 292 loss 2.6046 acc@1 0.2836 acc@5 0.6896\n",
      "\u001b[32m[2020-06-22 19:13:20] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 19:13:20] __main__ INFO: \u001b[0mTrain 293 102492\n",
      "\u001b[32m[2020-06-22 19:13:30] __main__ INFO: \u001b[0mEpoch 293 Step 100/351 lr 0.001000 loss 1.3532 (1.2734) acc@1 0.4609 (0.5066) acc@5 0.7656 (0.7552)\n",
      "\u001b[32m[2020-06-22 19:13:39] __main__ INFO: \u001b[0mEpoch 293 Step 200/351 lr 0.001000 loss 1.1075 (1.2823) acc@1 0.5625 (0.5062) acc@5 0.8672 (0.7567)\n",
      "\u001b[32m[2020-06-22 19:13:48] __main__ INFO: \u001b[0mEpoch 293 Step 300/351 lr 0.001000 loss 1.2654 (1.2826) acc@1 0.5156 (0.5060) acc@5 0.7344 (0.7573)\n",
      "\u001b[32m[2020-06-22 19:13:53] __main__ INFO: \u001b[0mEpoch 293 Step 351/351 lr 0.001000 loss 1.1906 (1.2827) acc@1 0.5312 (0.5054) acc@5 0.7578 (0.7574)\n",
      "\u001b[32m[2020-06-22 19:13:53] __main__ INFO: \u001b[0mElapsed 32.78\n",
      "\u001b[32m[2020-06-22 19:13:53] __main__ INFO: \u001b[0mVal 293\n",
      "\u001b[32m[2020-06-22 19:13:54] __main__ INFO: \u001b[0mEpoch 293 loss 2.5408 acc@1 0.2892 acc@5 0.6964\n",
      "\u001b[32m[2020-06-22 19:13:54] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 19:13:54] __main__ INFO: \u001b[0mTrain 294 102843\n",
      "\u001b[32m[2020-06-22 19:14:04] __main__ INFO: \u001b[0mEpoch 294 Step 100/351 lr 0.001000 loss 1.1301 (1.2760) acc@1 0.5859 (0.5106) acc@5 0.7891 (0.7544)\n",
      "\u001b[32m[2020-06-22 19:14:13] __main__ INFO: \u001b[0mEpoch 294 Step 200/351 lr 0.001000 loss 1.1592 (1.2799) acc@1 0.5547 (0.5087) acc@5 0.7812 (0.7543)\n",
      "\u001b[32m[2020-06-22 19:14:22] __main__ INFO: \u001b[0mEpoch 294 Step 300/351 lr 0.001000 loss 1.2609 (1.2758) acc@1 0.5234 (0.5098) acc@5 0.7734 (0.7553)\n",
      "\u001b[32m[2020-06-22 19:14:27] __main__ INFO: \u001b[0mEpoch 294 Step 351/351 lr 0.001000 loss 1.4463 (1.2754) acc@1 0.4062 (0.5100) acc@5 0.6875 (0.7551)\n",
      "\u001b[32m[2020-06-22 19:14:27] __main__ INFO: \u001b[0mElapsed 32.81\n",
      "\u001b[32m[2020-06-22 19:14:27] __main__ INFO: \u001b[0mVal 294\n",
      "\u001b[32m[2020-06-22 19:14:28] __main__ INFO: \u001b[0mEpoch 294 loss 2.5931 acc@1 0.2866 acc@5 0.6974\n",
      "\u001b[32m[2020-06-22 19:14:28] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 19:14:28] __main__ INFO: \u001b[0mTrain 295 103194\n",
      "\u001b[32m[2020-06-22 19:14:37] __main__ INFO: \u001b[0mEpoch 295 Step 100/351 lr 0.001000 loss 1.2777 (1.2839) acc@1 0.5078 (0.5041) acc@5 0.7656 (0.7560)\n",
      "\u001b[32m[2020-06-22 19:14:47] __main__ INFO: \u001b[0mEpoch 295 Step 200/351 lr 0.001000 loss 1.1309 (1.2805) acc@1 0.5703 (0.5079) acc@5 0.8125 (0.7575)\n",
      "\u001b[32m[2020-06-22 19:14:56] __main__ INFO: \u001b[0mEpoch 295 Step 300/351 lr 0.001000 loss 1.3100 (1.2766) acc@1 0.4844 (0.5085) acc@5 0.7969 (0.7574)\n",
      "\u001b[32m[2020-06-22 19:15:01] __main__ INFO: \u001b[0mEpoch 295 Step 351/351 lr 0.001000 loss 1.2754 (1.2771) acc@1 0.4688 (0.5080) acc@5 0.7422 (0.7574)\n",
      "\u001b[32m[2020-06-22 19:15:01] __main__ INFO: \u001b[0mElapsed 32.84\n",
      "\u001b[32m[2020-06-22 19:15:01] __main__ INFO: \u001b[0mVal 295\n",
      "\u001b[32m[2020-06-22 19:15:02] __main__ INFO: \u001b[0mEpoch 295 loss 2.5895 acc@1 0.2854 acc@5 0.6906\n",
      "\u001b[32m[2020-06-22 19:15:02] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 19:15:02] __main__ INFO: \u001b[0mTrain 296 103545\n",
      "\u001b[32m[2020-06-22 19:15:11] __main__ INFO: \u001b[0mEpoch 296 Step 100/351 lr 0.001000 loss 1.3175 (1.2811) acc@1 0.4609 (0.5074) acc@5 0.7734 (0.7594)\n",
      "\u001b[32m[2020-06-22 19:15:21] __main__ INFO: \u001b[0mEpoch 296 Step 200/351 lr 0.001000 loss 1.1636 (1.2800) acc@1 0.5625 (0.5071) acc@5 0.7578 (0.7558)\n",
      "\u001b[32m[2020-06-22 19:15:30] __main__ INFO: \u001b[0mEpoch 296 Step 300/351 lr 0.001000 loss 1.3505 (1.2792) acc@1 0.5391 (0.5084) acc@5 0.7891 (0.7562)\n",
      "\u001b[32m[2020-06-22 19:15:35] __main__ INFO: \u001b[0mEpoch 296 Step 351/351 lr 0.001000 loss 1.2182 (1.2765) acc@1 0.5469 (0.5101) acc@5 0.8047 (0.7579)\n",
      "\u001b[32m[2020-06-22 19:15:35] __main__ INFO: \u001b[0mElapsed 32.84\n",
      "\u001b[32m[2020-06-22 19:15:35] __main__ INFO: \u001b[0mVal 296\n",
      "\u001b[32m[2020-06-22 19:15:36] __main__ INFO: \u001b[0mEpoch 296 loss 2.5678 acc@1 0.2858 acc@5 0.6866\n",
      "\u001b[32m[2020-06-22 19:15:36] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 19:15:36] __main__ INFO: \u001b[0mTrain 297 103896\n",
      "\u001b[32m[2020-06-22 19:15:45] __main__ INFO: \u001b[0mEpoch 297 Step 100/351 lr 0.001000 loss 1.3679 (1.2654) acc@1 0.4609 (0.5114) acc@5 0.7422 (0.7639)\n",
      "\u001b[32m[2020-06-22 19:15:54] __main__ INFO: \u001b[0mEpoch 297 Step 200/351 lr 0.001000 loss 1.2883 (1.2719) acc@1 0.5000 (0.5115) acc@5 0.7266 (0.7600)\n",
      "\u001b[32m[2020-06-22 19:16:04] __main__ INFO: \u001b[0mEpoch 297 Step 300/351 lr 0.001000 loss 1.1623 (1.2713) acc@1 0.5703 (0.5117) acc@5 0.7812 (0.7605)\n",
      "\u001b[32m[2020-06-22 19:16:09] __main__ INFO: \u001b[0mEpoch 297 Step 351/351 lr 0.001000 loss 1.4625 (1.2759) acc@1 0.4531 (0.5095) acc@5 0.7031 (0.7595)\n",
      "\u001b[32m[2020-06-22 19:16:09] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 19:16:09] __main__ INFO: \u001b[0mVal 297\n",
      "\u001b[32m[2020-06-22 19:16:10] __main__ INFO: \u001b[0mEpoch 297 loss 2.6229 acc@1 0.2876 acc@5 0.6920\n",
      "\u001b[32m[2020-06-22 19:16:10] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 19:16:10] __main__ INFO: \u001b[0mTrain 298 104247\n",
      "\u001b[32m[2020-06-22 19:16:19] __main__ INFO: \u001b[0mEpoch 298 Step 100/351 lr 0.001000 loss 1.1932 (1.2718) acc@1 0.5703 (0.5127) acc@5 0.7891 (0.7598)\n",
      "\u001b[32m[2020-06-22 19:16:28] __main__ INFO: \u001b[0mEpoch 298 Step 200/351 lr 0.001000 loss 1.3289 (1.2730) acc@1 0.4844 (0.5119) acc@5 0.6875 (0.7566)\n",
      "\u001b[32m[2020-06-22 19:16:38] __main__ INFO: \u001b[0mEpoch 298 Step 300/351 lr 0.001000 loss 1.2987 (1.2737) acc@1 0.4766 (0.5116) acc@5 0.7500 (0.7572)\n",
      "\u001b[32m[2020-06-22 19:16:42] __main__ INFO: \u001b[0mEpoch 298 Step 351/351 lr 0.001000 loss 1.2779 (1.2745) acc@1 0.5312 (0.5109) acc@5 0.7500 (0.7567)\n",
      "\u001b[32m[2020-06-22 19:16:42] __main__ INFO: \u001b[0mElapsed 32.83\n",
      "\u001b[32m[2020-06-22 19:16:42] __main__ INFO: \u001b[0mVal 298\n",
      "\u001b[32m[2020-06-22 19:16:44] __main__ INFO: \u001b[0mEpoch 298 loss 2.5635 acc@1 0.2868 acc@5 0.6858\n",
      "\u001b[32m[2020-06-22 19:16:44] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 19:16:44] __main__ INFO: \u001b[0mTrain 299 104598\n",
      "\u001b[32m[2020-06-22 19:16:53] __main__ INFO: \u001b[0mEpoch 299 Step 100/351 lr 0.001000 loss 1.1911 (1.2783) acc@1 0.5469 (0.5083) acc@5 0.7578 (0.7552)\n",
      "\u001b[32m[2020-06-22 19:17:02] __main__ INFO: \u001b[0mEpoch 299 Step 200/351 lr 0.001000 loss 1.2174 (1.2795) acc@1 0.5234 (0.5073) acc@5 0.7344 (0.7554)\n",
      "\u001b[32m[2020-06-22 19:17:12] __main__ INFO: \u001b[0mEpoch 299 Step 300/351 lr 0.001000 loss 1.4138 (1.2806) acc@1 0.4609 (0.5077) acc@5 0.7266 (0.7569)\n",
      "\u001b[32m[2020-06-22 19:17:16] __main__ INFO: \u001b[0mEpoch 299 Step 351/351 lr 0.001000 loss 1.2743 (1.2794) acc@1 0.5156 (0.5080) acc@5 0.7656 (0.7581)\n",
      "\u001b[32m[2020-06-22 19:17:16] __main__ INFO: \u001b[0mElapsed 32.78\n",
      "\u001b[32m[2020-06-22 19:17:16] __main__ INFO: \u001b[0mVal 299\n",
      "\u001b[32m[2020-06-22 19:17:17] __main__ INFO: \u001b[0mEpoch 299 loss 2.5811 acc@1 0.2834 acc@5 0.6872\n",
      "\u001b[32m[2020-06-22 19:17:17] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 19:17:17] __main__ INFO: \u001b[0mTrain 300 104949\n",
      "\u001b[32m[2020-06-22 19:17:27] __main__ INFO: \u001b[0mEpoch 300 Step 100/351 lr 0.001000 loss 1.3761 (1.2614) acc@1 0.4766 (0.5167) acc@5 0.7500 (0.7604)\n",
      "\u001b[32m[2020-06-22 19:17:36] __main__ INFO: \u001b[0mEpoch 300 Step 200/351 lr 0.001000 loss 1.2094 (1.2680) acc@1 0.5312 (0.5131) acc@5 0.7344 (0.7582)\n",
      "\u001b[32m[2020-06-22 19:17:45] __main__ INFO: \u001b[0mEpoch 300 Step 300/351 lr 0.001000 loss 1.3892 (1.2734) acc@1 0.4453 (0.5118) acc@5 0.7578 (0.7577)\n",
      "\u001b[32m[2020-06-22 19:17:50] __main__ INFO: \u001b[0mEpoch 300 Step 351/351 lr 0.001000 loss 1.2833 (1.2754) acc@1 0.5156 (0.5106) acc@5 0.7656 (0.7568)\n",
      "\u001b[32m[2020-06-22 19:17:50] __main__ INFO: \u001b[0mElapsed 32.82\n",
      "\u001b[32m[2020-06-22 19:17:50] __main__ INFO: \u001b[0mVal 300\n",
      "\u001b[32m[2020-06-22 19:17:51] __main__ INFO: \u001b[0mEpoch 300 loss 2.5855 acc@1 0.2862 acc@5 0.6898\n",
      "\u001b[32m[2020-06-22 19:17:51] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 19:17:51] fvcore.common.checkpoint INFO: \u001b[0mSaving checkpoint to /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00/checkpoint_00300.pth\n",
      "\u001b[32m[2020-06-22 19:17:51] __main__ INFO: \u001b[0mTrain 301 105300\n",
      "\u001b[32m[2020-06-22 19:18:01] __main__ INFO: \u001b[0mEpoch 301 Step 100/351 lr 0.001000 loss 1.4121 (1.2747) acc@1 0.4609 (0.5112) acc@5 0.7188 (0.7574)\n",
      "\u001b[32m[2020-06-22 19:18:10] __main__ INFO: \u001b[0mEpoch 301 Step 200/351 lr 0.001000 loss 1.2900 (1.2728) acc@1 0.5000 (0.5122) acc@5 0.7109 (0.7569)\n",
      "\u001b[32m[2020-06-22 19:18:19] __main__ INFO: \u001b[0mEpoch 301 Step 300/351 lr 0.001000 loss 1.2234 (1.2752) acc@1 0.5312 (0.5109) acc@5 0.7578 (0.7567)\n",
      "\u001b[32m[2020-06-22 19:18:24] __main__ INFO: \u001b[0mEpoch 301 Step 351/351 lr 0.001000 loss 1.4383 (1.2736) acc@1 0.4844 (0.5111) acc@5 0.7266 (0.7575)\n",
      "\u001b[32m[2020-06-22 19:18:24] __main__ INFO: \u001b[0mElapsed 32.85\n",
      "\u001b[32m[2020-06-22 19:18:24] __main__ INFO: \u001b[0mVal 301\n",
      "\u001b[32m[2020-06-22 19:18:25] __main__ INFO: \u001b[0mEpoch 301 loss 2.5986 acc@1 0.2878 acc@5 0.6930\n",
      "\u001b[32m[2020-06-22 19:18:25] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 19:18:25] __main__ INFO: \u001b[0mTrain 302 105651\n",
      "\u001b[32m[2020-06-22 19:18:35] __main__ INFO: \u001b[0mEpoch 302 Step 100/351 lr 0.001000 loss 1.4185 (1.2642) acc@1 0.4609 (0.5157) acc@5 0.7656 (0.7638)\n",
      "\u001b[32m[2020-06-22 19:18:44] __main__ INFO: \u001b[0mEpoch 302 Step 200/351 lr 0.001000 loss 1.4150 (1.2746) acc@1 0.4688 (0.5121) acc@5 0.7500 (0.7583)\n",
      "\u001b[32m[2020-06-22 19:18:53] __main__ INFO: \u001b[0mEpoch 302 Step 300/351 lr 0.001000 loss 1.3263 (1.2706) acc@1 0.4922 (0.5130) acc@5 0.6875 (0.7589)\n",
      "\u001b[32m[2020-06-22 19:18:58] __main__ INFO: \u001b[0mEpoch 302 Step 351/351 lr 0.001000 loss 1.3210 (1.2723) acc@1 0.5078 (0.5120) acc@5 0.7891 (0.7581)\n",
      "\u001b[32m[2020-06-22 19:18:58] __main__ INFO: \u001b[0mElapsed 32.87\n",
      "\u001b[32m[2020-06-22 19:18:58] __main__ INFO: \u001b[0mVal 302\n",
      "\u001b[32m[2020-06-22 19:18:59] __main__ INFO: \u001b[0mEpoch 302 loss 2.5653 acc@1 0.2888 acc@5 0.6944\n",
      "\u001b[32m[2020-06-22 19:18:59] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 19:18:59] __main__ INFO: \u001b[0mTrain 303 106002\n",
      "\u001b[32m[2020-06-22 19:19:08] __main__ INFO: \u001b[0mEpoch 303 Step 100/351 lr 0.001000 loss 1.3645 (1.2723) acc@1 0.4766 (0.5091) acc@5 0.6953 (0.7642)\n",
      "\u001b[32m[2020-06-22 19:19:18] __main__ INFO: \u001b[0mEpoch 303 Step 200/351 lr 0.001000 loss 1.2408 (1.2785) acc@1 0.5391 (0.5067) acc@5 0.7812 (0.7579)\n",
      "\u001b[32m[2020-06-22 19:19:27] __main__ INFO: \u001b[0mEpoch 303 Step 300/351 lr 0.001000 loss 1.3646 (1.2759) acc@1 0.5078 (0.5085) acc@5 0.7812 (0.7591)\n",
      "\u001b[32m[2020-06-22 19:19:32] __main__ INFO: \u001b[0mEpoch 303 Step 351/351 lr 0.001000 loss 1.3343 (1.2742) acc@1 0.4453 (0.5092) acc@5 0.7500 (0.7597)\n",
      "\u001b[32m[2020-06-22 19:19:32] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 19:19:32] __main__ INFO: \u001b[0mVal 303\n",
      "\u001b[32m[2020-06-22 19:19:33] __main__ INFO: \u001b[0mEpoch 303 loss 2.5880 acc@1 0.2868 acc@5 0.6918\n",
      "\u001b[32m[2020-06-22 19:19:33] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 19:19:33] __main__ INFO: \u001b[0mTrain 304 106353\n",
      "\u001b[32m[2020-06-22 19:19:42] __main__ INFO: \u001b[0mEpoch 304 Step 100/351 lr 0.001000 loss 1.2299 (1.2794) acc@1 0.5312 (0.5078) acc@5 0.7812 (0.7531)\n",
      "\u001b[32m[2020-06-22 19:19:52] __main__ INFO: \u001b[0mEpoch 304 Step 200/351 lr 0.001000 loss 1.2593 (1.2821) acc@1 0.5391 (0.5082) acc@5 0.7891 (0.7543)\n",
      "\u001b[32m[2020-06-22 19:20:01] __main__ INFO: \u001b[0mEpoch 304 Step 300/351 lr 0.001000 loss 1.2127 (1.2727) acc@1 0.5234 (0.5117) acc@5 0.7500 (0.7568)\n",
      "\u001b[32m[2020-06-22 19:20:06] __main__ INFO: \u001b[0mEpoch 304 Step 351/351 lr 0.001000 loss 1.3051 (1.2746) acc@1 0.5000 (0.5110) acc@5 0.7891 (0.7575)\n",
      "\u001b[32m[2020-06-22 19:20:06] __main__ INFO: \u001b[0mElapsed 32.83\n",
      "\u001b[32m[2020-06-22 19:20:06] __main__ INFO: \u001b[0mVal 304\n",
      "\u001b[32m[2020-06-22 19:20:07] __main__ INFO: \u001b[0mEpoch 304 loss 2.5669 acc@1 0.2846 acc@5 0.6944\n",
      "\u001b[32m[2020-06-22 19:20:07] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 19:20:07] __main__ INFO: \u001b[0mTrain 305 106704\n",
      "\u001b[32m[2020-06-22 19:20:16] __main__ INFO: \u001b[0mEpoch 305 Step 100/351 lr 0.001000 loss 1.3331 (1.2757) acc@1 0.5000 (0.5091) acc@5 0.7734 (0.7584)\n",
      "\u001b[32m[2020-06-22 19:20:26] __main__ INFO: \u001b[0mEpoch 305 Step 200/351 lr 0.001000 loss 1.1526 (1.2767) acc@1 0.5469 (0.5082) acc@5 0.7812 (0.7593)\n",
      "\u001b[32m[2020-06-22 19:20:35] __main__ INFO: \u001b[0mEpoch 305 Step 300/351 lr 0.001000 loss 1.1614 (1.2740) acc@1 0.5625 (0.5089) acc@5 0.7656 (0.7593)\n",
      "\u001b[32m[2020-06-22 19:20:40] __main__ INFO: \u001b[0mEpoch 305 Step 351/351 lr 0.001000 loss 1.3593 (1.2728) acc@1 0.5000 (0.5095) acc@5 0.7578 (0.7592)\n",
      "\u001b[32m[2020-06-22 19:20:40] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 19:20:40] __main__ INFO: \u001b[0mVal 305\n",
      "\u001b[32m[2020-06-22 19:20:41] __main__ INFO: \u001b[0mEpoch 305 loss 2.5933 acc@1 0.2840 acc@5 0.6970\n",
      "\u001b[32m[2020-06-22 19:20:41] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 19:20:41] __main__ INFO: \u001b[0mTrain 306 107055\n",
      "\u001b[32m[2020-06-22 19:20:50] __main__ INFO: \u001b[0mEpoch 306 Step 100/351 lr 0.001000 loss 1.3271 (1.2681) acc@1 0.5000 (0.5114) acc@5 0.8047 (0.7620)\n",
      "\u001b[32m[2020-06-22 19:20:59] __main__ INFO: \u001b[0mEpoch 306 Step 200/351 lr 0.001000 loss 1.2971 (1.2754) acc@1 0.4688 (0.5097) acc@5 0.7344 (0.7594)\n",
      "\u001b[32m[2020-06-22 19:21:09] __main__ INFO: \u001b[0mEpoch 306 Step 300/351 lr 0.001000 loss 1.1103 (1.2700) acc@1 0.5781 (0.5122) acc@5 0.7734 (0.7599)\n",
      "\u001b[32m[2020-06-22 19:21:13] __main__ INFO: \u001b[0mEpoch 306 Step 351/351 lr 0.001000 loss 1.3329 (1.2736) acc@1 0.4766 (0.5109) acc@5 0.6953 (0.7582)\n",
      "\u001b[32m[2020-06-22 19:21:14] __main__ INFO: \u001b[0mElapsed 32.83\n",
      "\u001b[32m[2020-06-22 19:21:14] __main__ INFO: \u001b[0mVal 306\n",
      "\u001b[32m[2020-06-22 19:21:15] __main__ INFO: \u001b[0mEpoch 306 loss 2.6034 acc@1 0.2880 acc@5 0.6910\n",
      "\u001b[32m[2020-06-22 19:21:15] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 19:21:15] __main__ INFO: \u001b[0mTrain 307 107406\n",
      "\u001b[32m[2020-06-22 19:21:24] __main__ INFO: \u001b[0mEpoch 307 Step 100/351 lr 0.001000 loss 1.3844 (1.2601) acc@1 0.4453 (0.5156) acc@5 0.7656 (0.7641)\n",
      "\u001b[32m[2020-06-22 19:21:33] __main__ INFO: \u001b[0mEpoch 307 Step 200/351 lr 0.001000 loss 1.3231 (1.2598) acc@1 0.4688 (0.5155) acc@5 0.7344 (0.7619)\n",
      "\u001b[32m[2020-06-22 19:21:43] __main__ INFO: \u001b[0mEpoch 307 Step 300/351 lr 0.001000 loss 1.3299 (1.2662) acc@1 0.5312 (0.5122) acc@5 0.7891 (0.7586)\n",
      "\u001b[32m[2020-06-22 19:21:47] __main__ INFO: \u001b[0mEpoch 307 Step 351/351 lr 0.001000 loss 1.2862 (1.2682) acc@1 0.5391 (0.5121) acc@5 0.7656 (0.7589)\n",
      "\u001b[32m[2020-06-22 19:21:47] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 19:21:47] __main__ INFO: \u001b[0mVal 307\n",
      "\u001b[32m[2020-06-22 19:21:48] __main__ INFO: \u001b[0mEpoch 307 loss 2.6365 acc@1 0.2834 acc@5 0.6848\n",
      "\u001b[32m[2020-06-22 19:21:48] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 19:21:48] __main__ INFO: \u001b[0mTrain 308 107757\n",
      "\u001b[32m[2020-06-22 19:21:58] __main__ INFO: \u001b[0mEpoch 308 Step 100/351 lr 0.001000 loss 1.2076 (1.2527) acc@1 0.5547 (0.5188) acc@5 0.8438 (0.7612)\n",
      "\u001b[32m[2020-06-22 19:22:07] __main__ INFO: \u001b[0mEpoch 308 Step 200/351 lr 0.001000 loss 1.2961 (1.2679) acc@1 0.5234 (0.5122) acc@5 0.8125 (0.7580)\n",
      "\u001b[32m[2020-06-22 19:22:16] __main__ INFO: \u001b[0mEpoch 308 Step 300/351 lr 0.001000 loss 1.1890 (1.2694) acc@1 0.5312 (0.5118) acc@5 0.7266 (0.7587)\n",
      "\u001b[32m[2020-06-22 19:22:21] __main__ INFO: \u001b[0mEpoch 308 Step 351/351 lr 0.001000 loss 1.2830 (1.2728) acc@1 0.5078 (0.5101) acc@5 0.7656 (0.7583)\n",
      "\u001b[32m[2020-06-22 19:22:21] __main__ INFO: \u001b[0mElapsed 32.86\n",
      "\u001b[32m[2020-06-22 19:22:21] __main__ INFO: \u001b[0mVal 308\n",
      "\u001b[32m[2020-06-22 19:22:22] __main__ INFO: \u001b[0mEpoch 308 loss 2.6251 acc@1 0.2904 acc@5 0.6960\n",
      "\u001b[32m[2020-06-22 19:22:22] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 19:22:22] __main__ INFO: \u001b[0mTrain 309 108108\n",
      "\u001b[32m[2020-06-22 19:22:32] __main__ INFO: \u001b[0mEpoch 309 Step 100/351 lr 0.001000 loss 1.2687 (1.2766) acc@1 0.5078 (0.5088) acc@5 0.7891 (0.7567)\n",
      "\u001b[32m[2020-06-22 19:22:41] __main__ INFO: \u001b[0mEpoch 309 Step 200/351 lr 0.001000 loss 1.2331 (1.2786) acc@1 0.5234 (0.5093) acc@5 0.7578 (0.7558)\n",
      "\u001b[32m[2020-06-22 19:22:50] __main__ INFO: \u001b[0mEpoch 309 Step 300/351 lr 0.001000 loss 1.3270 (1.2756) acc@1 0.4453 (0.5100) acc@5 0.7031 (0.7574)\n",
      "\u001b[32m[2020-06-22 19:22:55] __main__ INFO: \u001b[0mEpoch 309 Step 351/351 lr 0.001000 loss 1.1857 (1.2741) acc@1 0.5234 (0.5108) acc@5 0.7812 (0.7584)\n",
      "\u001b[32m[2020-06-22 19:22:55] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 19:22:55] __main__ INFO: \u001b[0mVal 309\n",
      "\u001b[32m[2020-06-22 19:22:56] __main__ INFO: \u001b[0mEpoch 309 loss 2.6184 acc@1 0.2816 acc@5 0.6942\n",
      "\u001b[32m[2020-06-22 19:22:56] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 19:22:56] __main__ INFO: \u001b[0mTrain 310 108459\n",
      "\u001b[32m[2020-06-22 19:23:06] __main__ INFO: \u001b[0mEpoch 310 Step 100/351 lr 0.001000 loss 1.2036 (1.2703) acc@1 0.5312 (0.5127) acc@5 0.7578 (0.7558)\n",
      "\u001b[32m[2020-06-22 19:23:15] __main__ INFO: \u001b[0mEpoch 310 Step 200/351 lr 0.001000 loss 1.0651 (1.2662) acc@1 0.5781 (0.5123) acc@5 0.7969 (0.7552)\n",
      "\u001b[32m[2020-06-22 19:23:24] __main__ INFO: \u001b[0mEpoch 310 Step 300/351 lr 0.001000 loss 1.3230 (1.2706) acc@1 0.4766 (0.5104) acc@5 0.7031 (0.7551)\n",
      "\u001b[32m[2020-06-22 19:23:29] __main__ INFO: \u001b[0mEpoch 310 Step 351/351 lr 0.001000 loss 1.2206 (1.2681) acc@1 0.5156 (0.5122) acc@5 0.7500 (0.7564)\n",
      "\u001b[32m[2020-06-22 19:23:29] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 19:23:29] __main__ INFO: \u001b[0mVal 310\n",
      "\u001b[32m[2020-06-22 19:23:30] __main__ INFO: \u001b[0mEpoch 310 loss 2.6133 acc@1 0.2800 acc@5 0.6886\n",
      "\u001b[32m[2020-06-22 19:23:30] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 19:23:30] __main__ INFO: \u001b[0mTrain 311 108810\n",
      "\u001b[32m[2020-06-22 19:23:39] __main__ INFO: \u001b[0mEpoch 311 Step 100/351 lr 0.001000 loss 1.0516 (1.2724) acc@1 0.6016 (0.5162) acc@5 0.7891 (0.7579)\n",
      "\u001b[32m[2020-06-22 19:23:49] __main__ INFO: \u001b[0mEpoch 311 Step 200/351 lr 0.001000 loss 1.2298 (1.2640) acc@1 0.5234 (0.5153) acc@5 0.7344 (0.7575)\n",
      "\u001b[32m[2020-06-22 19:23:58] __main__ INFO: \u001b[0mEpoch 311 Step 300/351 lr 0.001000 loss 1.3386 (1.2653) acc@1 0.4922 (0.5147) acc@5 0.7344 (0.7576)\n",
      "\u001b[32m[2020-06-22 19:24:03] __main__ INFO: \u001b[0mEpoch 311 Step 351/351 lr 0.001000 loss 1.3257 (1.2679) acc@1 0.4844 (0.5138) acc@5 0.7500 (0.7568)\n",
      "\u001b[32m[2020-06-22 19:24:03] __main__ INFO: \u001b[0mElapsed 32.81\n",
      "\u001b[32m[2020-06-22 19:24:03] __main__ INFO: \u001b[0mVal 311\n",
      "\u001b[32m[2020-06-22 19:24:04] __main__ INFO: \u001b[0mEpoch 311 loss 2.6523 acc@1 0.2848 acc@5 0.7048\n",
      "\u001b[32m[2020-06-22 19:24:04] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 19:24:04] __main__ INFO: \u001b[0mTrain 312 109161\n",
      "\u001b[32m[2020-06-22 19:24:13] __main__ INFO: \u001b[0mEpoch 312 Step 100/351 lr 0.001000 loss 1.3141 (1.2842) acc@1 0.4922 (0.5027) acc@5 0.7031 (0.7538)\n",
      "\u001b[32m[2020-06-22 19:24:23] __main__ INFO: \u001b[0mEpoch 312 Step 200/351 lr 0.001000 loss 1.0028 (1.2770) acc@1 0.6094 (0.5074) acc@5 0.7578 (0.7550)\n",
      "\u001b[32m[2020-06-22 19:24:32] __main__ INFO: \u001b[0mEpoch 312 Step 300/351 lr 0.001000 loss 1.2505 (1.2688) acc@1 0.5156 (0.5117) acc@5 0.7500 (0.7570)\n",
      "\u001b[32m[2020-06-22 19:24:37] __main__ INFO: \u001b[0mEpoch 312 Step 351/351 lr 0.001000 loss 1.2279 (1.2679) acc@1 0.5312 (0.5118) acc@5 0.7656 (0.7573)\n",
      "\u001b[32m[2020-06-22 19:24:37] __main__ INFO: \u001b[0mElapsed 32.86\n",
      "\u001b[32m[2020-06-22 19:24:37] __main__ INFO: \u001b[0mVal 312\n",
      "\u001b[32m[2020-06-22 19:24:38] __main__ INFO: \u001b[0mEpoch 312 loss 2.6189 acc@1 0.2856 acc@5 0.6830\n",
      "\u001b[32m[2020-06-22 19:24:38] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 19:24:38] __main__ INFO: \u001b[0mTrain 313 109512\n",
      "\u001b[32m[2020-06-22 19:24:47] __main__ INFO: \u001b[0mEpoch 313 Step 100/351 lr 0.001000 loss 1.1307 (1.2719) acc@1 0.6094 (0.5161) acc@5 0.8125 (0.7593)\n",
      "\u001b[32m[2020-06-22 19:24:56] __main__ INFO: \u001b[0mEpoch 313 Step 200/351 lr 0.001000 loss 1.0652 (1.2773) acc@1 0.5938 (0.5112) acc@5 0.7500 (0.7554)\n",
      "\u001b[32m[2020-06-22 19:25:06] __main__ INFO: \u001b[0mEpoch 313 Step 300/351 lr 0.001000 loss 1.1561 (1.2708) acc@1 0.5312 (0.5113) acc@5 0.7812 (0.7571)\n",
      "\u001b[32m[2020-06-22 19:25:11] __main__ INFO: \u001b[0mEpoch 313 Step 351/351 lr 0.001000 loss 1.2743 (1.2718) acc@1 0.4766 (0.5102) acc@5 0.7266 (0.7559)\n",
      "\u001b[32m[2020-06-22 19:25:11] __main__ INFO: \u001b[0mElapsed 32.76\n",
      "\u001b[32m[2020-06-22 19:25:11] __main__ INFO: \u001b[0mVal 313\n",
      "\u001b[32m[2020-06-22 19:25:12] __main__ INFO: \u001b[0mEpoch 313 loss 2.6332 acc@1 0.2790 acc@5 0.6836\n",
      "\u001b[32m[2020-06-22 19:25:12] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 19:25:12] __main__ INFO: \u001b[0mTrain 314 109863\n",
      "\u001b[32m[2020-06-22 19:25:21] __main__ INFO: \u001b[0mEpoch 314 Step 100/351 lr 0.001000 loss 1.2697 (1.2701) acc@1 0.5000 (0.5142) acc@5 0.7422 (0.7573)\n",
      "\u001b[32m[2020-06-22 19:25:30] __main__ INFO: \u001b[0mEpoch 314 Step 200/351 lr 0.001000 loss 1.3228 (1.2676) acc@1 0.5000 (0.5154) acc@5 0.7734 (0.7622)\n",
      "\u001b[32m[2020-06-22 19:25:40] __main__ INFO: \u001b[0mEpoch 314 Step 300/351 lr 0.001000 loss 1.1740 (1.2699) acc@1 0.5625 (0.5134) acc@5 0.7344 (0.7592)\n",
      "\u001b[32m[2020-06-22 19:25:44] __main__ INFO: \u001b[0mEpoch 314 Step 351/351 lr 0.001000 loss 1.3031 (1.2696) acc@1 0.5000 (0.5135) acc@5 0.7656 (0.7584)\n",
      "\u001b[32m[2020-06-22 19:25:44] __main__ INFO: \u001b[0mElapsed 32.81\n",
      "\u001b[32m[2020-06-22 19:25:44] __main__ INFO: \u001b[0mVal 314\n",
      "\u001b[32m[2020-06-22 19:25:45] __main__ INFO: \u001b[0mEpoch 314 loss 2.6266 acc@1 0.2776 acc@5 0.6894\n",
      "\u001b[32m[2020-06-22 19:25:45] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 19:25:45] __main__ INFO: \u001b[0mTrain 315 110214\n",
      "\u001b[32m[2020-06-22 19:25:55] __main__ INFO: \u001b[0mEpoch 315 Step 100/351 lr 0.001000 loss 1.1533 (1.2634) acc@1 0.5547 (0.5128) acc@5 0.7266 (0.7545)\n",
      "\u001b[32m[2020-06-22 19:26:04] __main__ INFO: \u001b[0mEpoch 315 Step 200/351 lr 0.001000 loss 1.2128 (1.2590) acc@1 0.5391 (0.5143) acc@5 0.7500 (0.7566)\n",
      "\u001b[32m[2020-06-22 19:26:14] __main__ INFO: \u001b[0mEpoch 315 Step 300/351 lr 0.001000 loss 1.2515 (1.2672) acc@1 0.5547 (0.5102) acc@5 0.8438 (0.7575)\n",
      "\u001b[32m[2020-06-22 19:26:18] __main__ INFO: \u001b[0mEpoch 315 Step 351/351 lr 0.001000 loss 1.4043 (1.2665) acc@1 0.4922 (0.5116) acc@5 0.7656 (0.7586)\n",
      "\u001b[32m[2020-06-22 19:26:18] __main__ INFO: \u001b[0mElapsed 32.84\n",
      "\u001b[32m[2020-06-22 19:26:18] __main__ INFO: \u001b[0mVal 315\n",
      "\u001b[32m[2020-06-22 19:26:19] __main__ INFO: \u001b[0mEpoch 315 loss 2.6082 acc@1 0.2854 acc@5 0.6918\n",
      "\u001b[32m[2020-06-22 19:26:19] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 19:26:19] __main__ INFO: \u001b[0mTrain 316 110565\n",
      "\u001b[32m[2020-06-22 19:26:29] __main__ INFO: \u001b[0mEpoch 316 Step 100/351 lr 0.001000 loss 1.1873 (1.2604) acc@1 0.5078 (0.5115) acc@5 0.7266 (0.7591)\n",
      "\u001b[32m[2020-06-22 19:26:38] __main__ INFO: \u001b[0mEpoch 316 Step 200/351 lr 0.001000 loss 1.2238 (1.2591) acc@1 0.5547 (0.5145) acc@5 0.7578 (0.7598)\n",
      "\u001b[32m[2020-06-22 19:26:47] __main__ INFO: \u001b[0mEpoch 316 Step 300/351 lr 0.001000 loss 1.4289 (1.2647) acc@1 0.4453 (0.5132) acc@5 0.6562 (0.7586)\n",
      "\u001b[32m[2020-06-22 19:26:52] __main__ INFO: \u001b[0mEpoch 316 Step 351/351 lr 0.001000 loss 1.2633 (1.2681) acc@1 0.4766 (0.5117) acc@5 0.7266 (0.7571)\n",
      "\u001b[32m[2020-06-22 19:26:52] __main__ INFO: \u001b[0mElapsed 32.82\n",
      "\u001b[32m[2020-06-22 19:26:52] __main__ INFO: \u001b[0mVal 316\n",
      "\u001b[32m[2020-06-22 19:26:53] __main__ INFO: \u001b[0mEpoch 316 loss 2.6612 acc@1 0.2850 acc@5 0.6910\n",
      "\u001b[32m[2020-06-22 19:26:53] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 19:26:53] __main__ INFO: \u001b[0mTrain 317 110916\n",
      "\u001b[32m[2020-06-22 19:27:03] __main__ INFO: \u001b[0mEpoch 317 Step 100/351 lr 0.001000 loss 1.1746 (1.2661) acc@1 0.5000 (0.5123) acc@5 0.7422 (0.7570)\n",
      "\u001b[32m[2020-06-22 19:27:12] __main__ INFO: \u001b[0mEpoch 317 Step 200/351 lr 0.001000 loss 1.2122 (1.2696) acc@1 0.5391 (0.5085) acc@5 0.7422 (0.7559)\n",
      "\u001b[32m[2020-06-22 19:27:21] __main__ INFO: \u001b[0mEpoch 317 Step 300/351 lr 0.001000 loss 1.2301 (1.2694) acc@1 0.5156 (0.5092) acc@5 0.7734 (0.7575)\n",
      "\u001b[32m[2020-06-22 19:27:26] __main__ INFO: \u001b[0mEpoch 317 Step 351/351 lr 0.001000 loss 1.0717 (1.2691) acc@1 0.5703 (0.5097) acc@5 0.7812 (0.7577)\n",
      "\u001b[32m[2020-06-22 19:27:26] __main__ INFO: \u001b[0mElapsed 32.81\n",
      "\u001b[32m[2020-06-22 19:27:26] __main__ INFO: \u001b[0mVal 317\n",
      "\u001b[32m[2020-06-22 19:27:27] __main__ INFO: \u001b[0mEpoch 317 loss 2.6038 acc@1 0.2874 acc@5 0.6928\n",
      "\u001b[32m[2020-06-22 19:27:27] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 19:27:27] __main__ INFO: \u001b[0mTrain 318 111267\n",
      "\u001b[32m[2020-06-22 19:27:37] __main__ INFO: \u001b[0mEpoch 318 Step 100/351 lr 0.001000 loss 1.0730 (1.2734) acc@1 0.6016 (0.5099) acc@5 0.7891 (0.7572)\n",
      "\u001b[32m[2020-06-22 19:27:46] __main__ INFO: \u001b[0mEpoch 318 Step 200/351 lr 0.001000 loss 1.2662 (1.2651) acc@1 0.5156 (0.5130) acc@5 0.7891 (0.7582)\n",
      "\u001b[32m[2020-06-22 19:27:55] __main__ INFO: \u001b[0mEpoch 318 Step 300/351 lr 0.001000 loss 1.1234 (1.2670) acc@1 0.5547 (0.5124) acc@5 0.8047 (0.7582)\n",
      "\u001b[32m[2020-06-22 19:28:00] __main__ INFO: \u001b[0mEpoch 318 Step 351/351 lr 0.001000 loss 1.3696 (1.2667) acc@1 0.4844 (0.5123) acc@5 0.7422 (0.7576)\n",
      "\u001b[32m[2020-06-22 19:28:00] __main__ INFO: \u001b[0mElapsed 32.82\n",
      "\u001b[32m[2020-06-22 19:28:00] __main__ INFO: \u001b[0mVal 318\n",
      "\u001b[32m[2020-06-22 19:28:01] __main__ INFO: \u001b[0mEpoch 318 loss 2.6210 acc@1 0.2878 acc@5 0.6996\n",
      "\u001b[32m[2020-06-22 19:28:01] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 19:28:01] __main__ INFO: \u001b[0mTrain 319 111618\n",
      "\u001b[32m[2020-06-22 19:28:10] __main__ INFO: \u001b[0mEpoch 319 Step 100/351 lr 0.001000 loss 1.2172 (1.2569) acc@1 0.5391 (0.5158) acc@5 0.7734 (0.7612)\n",
      "\u001b[32m[2020-06-22 19:28:20] __main__ INFO: \u001b[0mEpoch 319 Step 200/351 lr 0.001000 loss 1.3116 (1.2627) acc@1 0.4922 (0.5123) acc@5 0.7109 (0.7567)\n",
      "\u001b[32m[2020-06-22 19:28:29] __main__ INFO: \u001b[0mEpoch 319 Step 300/351 lr 0.001000 loss 1.1831 (1.2665) acc@1 0.5547 (0.5107) acc@5 0.7422 (0.7565)\n",
      "\u001b[32m[2020-06-22 19:28:34] __main__ INFO: \u001b[0mEpoch 319 Step 351/351 lr 0.001000 loss 1.3185 (1.2674) acc@1 0.5000 (0.5096) acc@5 0.7891 (0.7564)\n",
      "\u001b[32m[2020-06-22 19:28:34] __main__ INFO: \u001b[0mElapsed 32.89\n",
      "\u001b[32m[2020-06-22 19:28:34] __main__ INFO: \u001b[0mVal 319\n",
      "\u001b[32m[2020-06-22 19:28:35] __main__ INFO: \u001b[0mEpoch 319 loss 2.6065 acc@1 0.2818 acc@5 0.6908\n",
      "\u001b[32m[2020-06-22 19:28:35] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 19:28:35] __main__ INFO: \u001b[0mTrain 320 111969\n",
      "\u001b[32m[2020-06-22 19:28:44] __main__ INFO: \u001b[0mEpoch 320 Step 100/351 lr 0.001000 loss 1.2530 (1.2626) acc@1 0.4922 (0.5152) acc@5 0.7656 (0.7541)\n",
      "\u001b[32m[2020-06-22 19:28:54] __main__ INFO: \u001b[0mEpoch 320 Step 200/351 lr 0.001000 loss 1.3231 (1.2615) acc@1 0.4922 (0.5148) acc@5 0.7500 (0.7563)\n",
      "\u001b[32m[2020-06-22 19:29:03] __main__ INFO: \u001b[0mEpoch 320 Step 300/351 lr 0.001000 loss 1.3002 (1.2625) acc@1 0.5156 (0.5144) acc@5 0.7812 (0.7575)\n",
      "\u001b[32m[2020-06-22 19:29:08] __main__ INFO: \u001b[0mEpoch 320 Step 351/351 lr 0.001000 loss 1.2681 (1.2660) acc@1 0.5156 (0.5130) acc@5 0.7344 (0.7572)\n",
      "\u001b[32m[2020-06-22 19:29:08] __main__ INFO: \u001b[0mElapsed 32.76\n",
      "\u001b[32m[2020-06-22 19:29:08] __main__ INFO: \u001b[0mVal 320\n",
      "\u001b[32m[2020-06-22 19:29:09] __main__ INFO: \u001b[0mEpoch 320 loss 2.6406 acc@1 0.2882 acc@5 0.6840\n",
      "\u001b[32m[2020-06-22 19:29:09] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 19:29:09] __main__ INFO: \u001b[0mTrain 321 112320\n",
      "\u001b[32m[2020-06-22 19:29:18] __main__ INFO: \u001b[0mEpoch 321 Step 100/351 lr 0.001000 loss 1.3568 (1.2539) acc@1 0.5000 (0.5191) acc@5 0.7578 (0.7632)\n",
      "\u001b[32m[2020-06-22 19:29:27] __main__ INFO: \u001b[0mEpoch 321 Step 200/351 lr 0.001000 loss 1.1861 (1.2653) acc@1 0.5391 (0.5130) acc@5 0.7656 (0.7583)\n",
      "\u001b[32m[2020-06-22 19:29:37] __main__ INFO: \u001b[0mEpoch 321 Step 300/351 lr 0.001000 loss 1.2239 (1.2645) acc@1 0.5312 (0.5134) acc@5 0.7812 (0.7588)\n",
      "\u001b[32m[2020-06-22 19:29:41] __main__ INFO: \u001b[0mEpoch 321 Step 351/351 lr 0.001000 loss 1.2630 (1.2617) acc@1 0.4844 (0.5138) acc@5 0.7500 (0.7591)\n",
      "\u001b[32m[2020-06-22 19:29:42] __main__ INFO: \u001b[0mElapsed 32.78\n",
      "\u001b[32m[2020-06-22 19:29:42] __main__ INFO: \u001b[0mVal 321\n",
      "\u001b[32m[2020-06-22 19:29:43] __main__ INFO: \u001b[0mEpoch 321 loss 2.6305 acc@1 0.2924 acc@5 0.7008\n",
      "\u001b[32m[2020-06-22 19:29:43] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 19:29:43] __main__ INFO: \u001b[0mTrain 322 112671\n",
      "\u001b[32m[2020-06-22 19:29:52] __main__ INFO: \u001b[0mEpoch 322 Step 100/351 lr 0.001000 loss 1.1584 (1.2603) acc@1 0.5547 (0.5151) acc@5 0.7734 (0.7585)\n",
      "\u001b[32m[2020-06-22 19:30:01] __main__ INFO: \u001b[0mEpoch 322 Step 200/351 lr 0.001000 loss 1.2285 (1.2654) acc@1 0.5703 (0.5128) acc@5 0.8203 (0.7543)\n",
      "\u001b[32m[2020-06-22 19:30:11] __main__ INFO: \u001b[0mEpoch 322 Step 300/351 lr 0.001000 loss 1.2353 (1.2650) acc@1 0.5469 (0.5146) acc@5 0.7812 (0.7562)\n",
      "\u001b[32m[2020-06-22 19:30:15] __main__ INFO: \u001b[0mEpoch 322 Step 351/351 lr 0.001000 loss 1.3044 (1.2632) acc@1 0.5078 (0.5156) acc@5 0.7812 (0.7557)\n",
      "\u001b[32m[2020-06-22 19:30:15] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 19:30:15] __main__ INFO: \u001b[0mVal 322\n",
      "\u001b[32m[2020-06-22 19:30:16] __main__ INFO: \u001b[0mEpoch 322 loss 2.6085 acc@1 0.2818 acc@5 0.6968\n",
      "\u001b[32m[2020-06-22 19:30:16] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 19:30:16] __main__ INFO: \u001b[0mTrain 323 113022\n",
      "\u001b[32m[2020-06-22 19:30:26] __main__ INFO: \u001b[0mEpoch 323 Step 100/351 lr 0.001000 loss 1.3984 (1.2756) acc@1 0.4609 (0.5088) acc@5 0.7422 (0.7604)\n",
      "\u001b[32m[2020-06-22 19:30:35] __main__ INFO: \u001b[0mEpoch 323 Step 200/351 lr 0.001000 loss 1.2926 (1.2734) acc@1 0.5312 (0.5094) acc@5 0.7812 (0.7602)\n",
      "\u001b[32m[2020-06-22 19:30:44] __main__ INFO: \u001b[0mEpoch 323 Step 300/351 lr 0.001000 loss 1.1785 (1.2702) acc@1 0.5547 (0.5106) acc@5 0.8125 (0.7597)\n",
      "\u001b[32m[2020-06-22 19:30:49] __main__ INFO: \u001b[0mEpoch 323 Step 351/351 lr 0.001000 loss 1.0897 (1.2691) acc@1 0.6172 (0.5106) acc@5 0.7969 (0.7585)\n",
      "\u001b[32m[2020-06-22 19:30:49] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 19:30:49] __main__ INFO: \u001b[0mVal 323\n",
      "\u001b[32m[2020-06-22 19:30:50] __main__ INFO: \u001b[0mEpoch 323 loss 2.6174 acc@1 0.2822 acc@5 0.6844\n",
      "\u001b[32m[2020-06-22 19:30:50] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 19:30:50] __main__ INFO: \u001b[0mTrain 324 113373\n",
      "\u001b[32m[2020-06-22 19:31:00] __main__ INFO: \u001b[0mEpoch 324 Step 100/351 lr 0.001000 loss 1.2967 (1.2669) acc@1 0.4922 (0.5123) acc@5 0.8125 (0.7599)\n",
      "\u001b[32m[2020-06-22 19:31:09] __main__ INFO: \u001b[0mEpoch 324 Step 200/351 lr 0.001000 loss 1.2597 (1.2683) acc@1 0.5312 (0.5128) acc@5 0.7422 (0.7596)\n",
      "\u001b[32m[2020-06-22 19:31:18] __main__ INFO: \u001b[0mEpoch 324 Step 300/351 lr 0.001000 loss 1.3506 (1.2658) acc@1 0.4844 (0.5142) acc@5 0.7500 (0.7591)\n",
      "\u001b[32m[2020-06-22 19:31:23] __main__ INFO: \u001b[0mEpoch 324 Step 351/351 lr 0.001000 loss 1.1758 (1.2667) acc@1 0.5469 (0.5133) acc@5 0.7891 (0.7590)\n",
      "\u001b[32m[2020-06-22 19:31:23] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 19:31:23] __main__ INFO: \u001b[0mVal 324\n",
      "\u001b[32m[2020-06-22 19:31:24] __main__ INFO: \u001b[0mEpoch 324 loss 2.6137 acc@1 0.2838 acc@5 0.6886\n",
      "\u001b[32m[2020-06-22 19:31:24] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 19:31:24] __main__ INFO: \u001b[0mTrain 325 113724\n",
      "\u001b[32m[2020-06-22 19:31:34] __main__ INFO: \u001b[0mEpoch 325 Step 100/351 lr 0.001000 loss 1.3335 (1.2554) acc@1 0.4766 (0.5168) acc@5 0.7109 (0.7577)\n",
      "\u001b[32m[2020-06-22 19:31:43] __main__ INFO: \u001b[0mEpoch 325 Step 200/351 lr 0.001000 loss 1.1820 (1.2555) acc@1 0.5469 (0.5152) acc@5 0.7500 (0.7569)\n",
      "\u001b[32m[2020-06-22 19:31:52] __main__ INFO: \u001b[0mEpoch 325 Step 300/351 lr 0.001000 loss 1.2370 (1.2583) acc@1 0.5469 (0.5142) acc@5 0.7109 (0.7546)\n",
      "\u001b[32m[2020-06-22 19:31:57] __main__ INFO: \u001b[0mEpoch 325 Step 351/351 lr 0.001000 loss 1.2446 (1.2596) acc@1 0.5156 (0.5139) acc@5 0.7344 (0.7549)\n",
      "\u001b[32m[2020-06-22 19:31:57] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 19:31:57] __main__ INFO: \u001b[0mVal 325\n",
      "\u001b[32m[2020-06-22 19:31:58] __main__ INFO: \u001b[0mEpoch 325 loss 2.6166 acc@1 0.2784 acc@5 0.6842\n",
      "\u001b[32m[2020-06-22 19:31:58] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 19:31:58] __main__ INFO: \u001b[0mTrain 326 114075\n",
      "\u001b[32m[2020-06-22 19:32:07] __main__ INFO: \u001b[0mEpoch 326 Step 100/351 lr 0.001000 loss 1.3206 (1.2589) acc@1 0.5000 (0.5137) acc@5 0.7500 (0.7554)\n",
      "\u001b[32m[2020-06-22 19:32:17] __main__ INFO: \u001b[0mEpoch 326 Step 200/351 lr 0.001000 loss 1.1945 (1.2582) acc@1 0.5312 (0.5152) acc@5 0.7734 (0.7591)\n",
      "\u001b[32m[2020-06-22 19:32:26] __main__ INFO: \u001b[0mEpoch 326 Step 300/351 lr 0.001000 loss 1.3503 (1.2592) acc@1 0.4609 (0.5157) acc@5 0.7891 (0.7595)\n",
      "\u001b[32m[2020-06-22 19:32:31] __main__ INFO: \u001b[0mEpoch 326 Step 351/351 lr 0.001000 loss 1.2580 (1.2617) acc@1 0.5000 (0.5148) acc@5 0.7578 (0.7590)\n",
      "\u001b[32m[2020-06-22 19:32:31] __main__ INFO: \u001b[0mElapsed 32.88\n",
      "\u001b[32m[2020-06-22 19:32:31] __main__ INFO: \u001b[0mVal 326\n",
      "\u001b[32m[2020-06-22 19:32:32] __main__ INFO: \u001b[0mEpoch 326 loss 2.6774 acc@1 0.2806 acc@5 0.6858\n",
      "\u001b[32m[2020-06-22 19:32:32] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 19:32:32] __main__ INFO: \u001b[0mTrain 327 114426\n",
      "\u001b[32m[2020-06-22 19:32:41] __main__ INFO: \u001b[0mEpoch 327 Step 100/351 lr 0.001000 loss 1.1834 (1.2636) acc@1 0.5469 (0.5120) acc@5 0.7344 (0.7538)\n",
      "\u001b[32m[2020-06-22 19:32:51] __main__ INFO: \u001b[0mEpoch 327 Step 200/351 lr 0.001000 loss 1.2520 (1.2613) acc@1 0.5078 (0.5148) acc@5 0.7734 (0.7591)\n",
      "\u001b[32m[2020-06-22 19:33:00] __main__ INFO: \u001b[0mEpoch 327 Step 300/351 lr 0.001000 loss 1.1091 (1.2629) acc@1 0.5391 (0.5145) acc@5 0.7812 (0.7594)\n",
      "\u001b[32m[2020-06-22 19:33:05] __main__ INFO: \u001b[0mEpoch 327 Step 351/351 lr 0.001000 loss 1.4332 (1.2624) acc@1 0.4453 (0.5145) acc@5 0.7422 (0.7591)\n",
      "\u001b[32m[2020-06-22 19:33:05] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 19:33:05] __main__ INFO: \u001b[0mVal 327\n",
      "\u001b[32m[2020-06-22 19:33:06] __main__ INFO: \u001b[0mEpoch 327 loss 2.6847 acc@1 0.2916 acc@5 0.6938\n",
      "\u001b[32m[2020-06-22 19:33:06] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 19:33:06] __main__ INFO: \u001b[0mTrain 328 114777\n",
      "\u001b[32m[2020-06-22 19:33:15] __main__ INFO: \u001b[0mEpoch 328 Step 100/351 lr 0.001000 loss 1.2378 (1.2567) acc@1 0.5000 (0.5196) acc@5 0.8047 (0.7633)\n",
      "\u001b[32m[2020-06-22 19:33:24] __main__ INFO: \u001b[0mEpoch 328 Step 200/351 lr 0.001000 loss 1.3262 (1.2587) acc@1 0.5234 (0.5175) acc@5 0.7578 (0.7601)\n",
      "\u001b[32m[2020-06-22 19:33:34] __main__ INFO: \u001b[0mEpoch 328 Step 300/351 lr 0.001000 loss 1.1497 (1.2583) acc@1 0.5703 (0.5164) acc@5 0.7656 (0.7603)\n",
      "\u001b[32m[2020-06-22 19:33:39] __main__ INFO: \u001b[0mEpoch 328 Step 351/351 lr 0.001000 loss 1.1628 (1.2604) acc@1 0.5625 (0.5158) acc@5 0.8438 (0.7591)\n",
      "\u001b[32m[2020-06-22 19:33:39] __main__ INFO: \u001b[0mElapsed 32.82\n",
      "\u001b[32m[2020-06-22 19:33:39] __main__ INFO: \u001b[0mVal 328\n",
      "\u001b[32m[2020-06-22 19:33:40] __main__ INFO: \u001b[0mEpoch 328 loss 2.6544 acc@1 0.2838 acc@5 0.6842\n",
      "\u001b[32m[2020-06-22 19:33:40] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 19:33:40] __main__ INFO: \u001b[0mTrain 329 115128\n",
      "\u001b[32m[2020-06-22 19:33:49] __main__ INFO: \u001b[0mEpoch 329 Step 100/351 lr 0.001000 loss 1.2416 (1.2539) acc@1 0.5000 (0.5211) acc@5 0.7422 (0.7598)\n",
      "\u001b[32m[2020-06-22 19:33:58] __main__ INFO: \u001b[0mEpoch 329 Step 200/351 lr 0.001000 loss 1.2042 (1.2558) acc@1 0.5469 (0.5179) acc@5 0.7109 (0.7577)\n",
      "\u001b[32m[2020-06-22 19:34:08] __main__ INFO: \u001b[0mEpoch 329 Step 300/351 lr 0.001000 loss 1.2989 (1.2602) acc@1 0.4922 (0.5153) acc@5 0.7656 (0.7574)\n",
      "\u001b[32m[2020-06-22 19:34:12] __main__ INFO: \u001b[0mEpoch 329 Step 351/351 lr 0.001000 loss 1.4461 (1.2608) acc@1 0.4531 (0.5157) acc@5 0.7344 (0.7581)\n",
      "\u001b[32m[2020-06-22 19:34:12] __main__ INFO: \u001b[0mElapsed 32.82\n",
      "\u001b[32m[2020-06-22 19:34:12] __main__ INFO: \u001b[0mVal 329\n",
      "\u001b[32m[2020-06-22 19:34:14] __main__ INFO: \u001b[0mEpoch 329 loss 2.6889 acc@1 0.2818 acc@5 0.6830\n",
      "\u001b[32m[2020-06-22 19:34:14] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 19:34:14] __main__ INFO: \u001b[0mTrain 330 115479\n",
      "\u001b[32m[2020-06-22 19:34:23] __main__ INFO: \u001b[0mEpoch 330 Step 100/351 lr 0.001000 loss 1.2710 (1.2600) acc@1 0.5078 (0.5120) acc@5 0.7656 (0.7570)\n",
      "\u001b[32m[2020-06-22 19:34:32] __main__ INFO: \u001b[0mEpoch 330 Step 200/351 lr 0.001000 loss 1.4670 (1.2531) acc@1 0.4688 (0.5166) acc@5 0.6797 (0.7590)\n",
      "\u001b[32m[2020-06-22 19:34:42] __main__ INFO: \u001b[0mEpoch 330 Step 300/351 lr 0.001000 loss 1.2085 (1.2588) acc@1 0.5469 (0.5140) acc@5 0.7422 (0.7572)\n",
      "\u001b[32m[2020-06-22 19:34:46] __main__ INFO: \u001b[0mEpoch 330 Step 351/351 lr 0.001000 loss 1.2229 (1.2596) acc@1 0.5391 (0.5142) acc@5 0.7422 (0.7572)\n",
      "\u001b[32m[2020-06-22 19:34:46] __main__ INFO: \u001b[0mElapsed 32.82\n",
      "\u001b[32m[2020-06-22 19:34:46] __main__ INFO: \u001b[0mVal 330\n",
      "\u001b[32m[2020-06-22 19:34:47] __main__ INFO: \u001b[0mEpoch 330 loss 2.6665 acc@1 0.2798 acc@5 0.6982\n",
      "\u001b[32m[2020-06-22 19:34:47] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 19:34:47] __main__ INFO: \u001b[0mTrain 331 115830\n",
      "\u001b[32m[2020-06-22 19:34:57] __main__ INFO: \u001b[0mEpoch 331 Step 100/351 lr 0.001000 loss 1.2962 (1.2577) acc@1 0.5312 (0.5161) acc@5 0.7500 (0.7622)\n",
      "\u001b[32m[2020-06-22 19:35:06] __main__ INFO: \u001b[0mEpoch 331 Step 200/351 lr 0.001000 loss 1.3854 (1.2580) acc@1 0.4609 (0.5163) acc@5 0.6562 (0.7600)\n",
      "\u001b[32m[2020-06-22 19:35:15] __main__ INFO: \u001b[0mEpoch 331 Step 300/351 lr 0.001000 loss 1.4506 (1.2602) acc@1 0.4531 (0.5162) acc@5 0.7812 (0.7589)\n",
      "\u001b[32m[2020-06-22 19:35:20] __main__ INFO: \u001b[0mEpoch 331 Step 351/351 lr 0.001000 loss 1.4558 (1.2616) acc@1 0.4219 (0.5154) acc@5 0.6875 (0.7576)\n",
      "\u001b[32m[2020-06-22 19:35:20] __main__ INFO: \u001b[0mElapsed 32.77\n",
      "\u001b[32m[2020-06-22 19:35:20] __main__ INFO: \u001b[0mVal 331\n",
      "\u001b[32m[2020-06-22 19:35:21] __main__ INFO: \u001b[0mEpoch 331 loss 2.6866 acc@1 0.2782 acc@5 0.6892\n",
      "\u001b[32m[2020-06-22 19:35:21] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 19:35:21] __main__ INFO: \u001b[0mTrain 332 116181\n",
      "\u001b[32m[2020-06-22 19:35:31] __main__ INFO: \u001b[0mEpoch 332 Step 100/351 lr 0.001000 loss 1.2284 (1.2422) acc@1 0.5469 (0.5211) acc@5 0.7812 (0.7635)\n",
      "\u001b[32m[2020-06-22 19:35:40] __main__ INFO: \u001b[0mEpoch 332 Step 200/351 lr 0.001000 loss 1.3804 (1.2603) acc@1 0.4375 (0.5146) acc@5 0.7109 (0.7586)\n",
      "\u001b[32m[2020-06-22 19:35:49] __main__ INFO: \u001b[0mEpoch 332 Step 300/351 lr 0.001000 loss 1.3254 (1.2608) acc@1 0.5234 (0.5151) acc@5 0.7188 (0.7566)\n",
      "\u001b[32m[2020-06-22 19:35:54] __main__ INFO: \u001b[0mEpoch 332 Step 351/351 lr 0.001000 loss 1.1698 (1.2587) acc@1 0.5391 (0.5158) acc@5 0.6953 (0.7576)\n",
      "\u001b[32m[2020-06-22 19:35:54] __main__ INFO: \u001b[0mElapsed 32.77\n",
      "\u001b[32m[2020-06-22 19:35:54] __main__ INFO: \u001b[0mVal 332\n",
      "\u001b[32m[2020-06-22 19:35:55] __main__ INFO: \u001b[0mEpoch 332 loss 2.6367 acc@1 0.2860 acc@5 0.6970\n",
      "\u001b[32m[2020-06-22 19:35:55] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 19:35:55] __main__ INFO: \u001b[0mTrain 333 116532\n",
      "\u001b[32m[2020-06-22 19:36:04] __main__ INFO: \u001b[0mEpoch 333 Step 100/351 lr 0.001000 loss 1.2343 (1.2644) acc@1 0.5703 (0.5112) acc@5 0.8047 (0.7566)\n",
      "\u001b[32m[2020-06-22 19:36:14] __main__ INFO: \u001b[0mEpoch 333 Step 200/351 lr 0.001000 loss 1.2789 (1.2619) acc@1 0.4844 (0.5141) acc@5 0.7578 (0.7557)\n",
      "\u001b[32m[2020-06-22 19:36:23] __main__ INFO: \u001b[0mEpoch 333 Step 300/351 lr 0.001000 loss 1.2512 (1.2574) acc@1 0.5078 (0.5155) acc@5 0.7578 (0.7573)\n",
      "\u001b[32m[2020-06-22 19:36:28] __main__ INFO: \u001b[0mEpoch 333 Step 351/351 lr 0.001000 loss 1.1724 (1.2586) acc@1 0.5547 (0.5147) acc@5 0.8203 (0.7585)\n",
      "\u001b[32m[2020-06-22 19:36:28] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 19:36:28] __main__ INFO: \u001b[0mVal 333\n",
      "\u001b[32m[2020-06-22 19:36:29] __main__ INFO: \u001b[0mEpoch 333 loss 2.6717 acc@1 0.2840 acc@5 0.6956\n",
      "\u001b[32m[2020-06-22 19:36:29] __main__ INFO: \u001b[0mElapsed 1.13\n",
      "\u001b[32m[2020-06-22 19:36:29] __main__ INFO: \u001b[0mTrain 334 116883\n",
      "\u001b[32m[2020-06-22 19:36:38] __main__ INFO: \u001b[0mEpoch 334 Step 100/351 lr 0.001000 loss 1.2969 (1.2617) acc@1 0.5391 (0.5152) acc@5 0.7266 (0.7592)\n",
      "\u001b[32m[2020-06-22 19:36:48] __main__ INFO: \u001b[0mEpoch 334 Step 200/351 lr 0.001000 loss 1.1520 (1.2569) acc@1 0.5938 (0.5156) acc@5 0.7891 (0.7582)\n",
      "\u001b[32m[2020-06-22 19:36:57] __main__ INFO: \u001b[0mEpoch 334 Step 300/351 lr 0.001000 loss 1.1995 (1.2526) acc@1 0.5547 (0.5177) acc@5 0.7578 (0.7598)\n",
      "\u001b[32m[2020-06-22 19:37:02] __main__ INFO: \u001b[0mEpoch 334 Step 351/351 lr 0.001000 loss 1.4065 (1.2589) acc@1 0.4609 (0.5153) acc@5 0.7422 (0.7592)\n",
      "\u001b[32m[2020-06-22 19:37:02] __main__ INFO: \u001b[0mElapsed 32.86\n",
      "\u001b[32m[2020-06-22 19:37:02] __main__ INFO: \u001b[0mVal 334\n",
      "\u001b[32m[2020-06-22 19:37:03] __main__ INFO: \u001b[0mEpoch 334 loss 2.7041 acc@1 0.2830 acc@5 0.6896\n",
      "\u001b[32m[2020-06-22 19:37:03] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 19:37:03] __main__ INFO: \u001b[0mTrain 335 117234\n",
      "\u001b[32m[2020-06-22 19:37:12] __main__ INFO: \u001b[0mEpoch 335 Step 100/351 lr 0.001000 loss 1.5227 (1.2497) acc@1 0.4609 (0.5230) acc@5 0.7344 (0.7584)\n",
      "\u001b[32m[2020-06-22 19:37:22] __main__ INFO: \u001b[0mEpoch 335 Step 200/351 lr 0.001000 loss 1.3637 (1.2597) acc@1 0.4453 (0.5169) acc@5 0.7969 (0.7555)\n",
      "\u001b[32m[2020-06-22 19:37:31] __main__ INFO: \u001b[0mEpoch 335 Step 300/351 lr 0.001000 loss 1.3848 (1.2623) acc@1 0.5000 (0.5157) acc@5 0.7266 (0.7566)\n",
      "\u001b[32m[2020-06-22 19:37:36] __main__ INFO: \u001b[0mEpoch 335 Step 351/351 lr 0.001000 loss 1.1668 (1.2588) acc@1 0.5312 (0.5165) acc@5 0.7734 (0.7577)\n",
      "\u001b[32m[2020-06-22 19:37:36] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 19:37:36] __main__ INFO: \u001b[0mVal 335\n",
      "\u001b[32m[2020-06-22 19:37:37] __main__ INFO: \u001b[0mEpoch 335 loss 2.6394 acc@1 0.2912 acc@5 0.6976\n",
      "\u001b[32m[2020-06-22 19:37:37] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 19:37:37] __main__ INFO: \u001b[0mTrain 336 117585\n",
      "\u001b[32m[2020-06-22 19:37:46] __main__ INFO: \u001b[0mEpoch 336 Step 100/351 lr 0.001000 loss 1.1757 (1.2524) acc@1 0.5625 (0.5199) acc@5 0.7422 (0.7591)\n",
      "\u001b[32m[2020-06-22 19:37:56] __main__ INFO: \u001b[0mEpoch 336 Step 200/351 lr 0.001000 loss 1.0640 (1.2532) acc@1 0.6250 (0.5162) acc@5 0.8281 (0.7592)\n",
      "\u001b[32m[2020-06-22 19:38:05] __main__ INFO: \u001b[0mEpoch 336 Step 300/351 lr 0.001000 loss 1.1405 (1.2601) acc@1 0.5469 (0.5139) acc@5 0.8281 (0.7576)\n",
      "\u001b[32m[2020-06-22 19:38:10] __main__ INFO: \u001b[0mEpoch 336 Step 351/351 lr 0.001000 loss 1.2530 (1.2571) acc@1 0.5078 (0.5156) acc@5 0.6562 (0.7573)\n",
      "\u001b[32m[2020-06-22 19:38:10] __main__ INFO: \u001b[0mElapsed 32.81\n",
      "\u001b[32m[2020-06-22 19:38:10] __main__ INFO: \u001b[0mVal 336\n",
      "\u001b[32m[2020-06-22 19:38:11] __main__ INFO: \u001b[0mEpoch 336 loss 2.6510 acc@1 0.2848 acc@5 0.6868\n",
      "\u001b[32m[2020-06-22 19:38:11] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 19:38:11] __main__ INFO: \u001b[0mTrain 337 117936\n",
      "\u001b[32m[2020-06-22 19:38:20] __main__ INFO: \u001b[0mEpoch 337 Step 100/351 lr 0.001000 loss 1.3248 (1.2509) acc@1 0.4922 (0.5180) acc@5 0.7344 (0.7572)\n",
      "\u001b[32m[2020-06-22 19:38:29] __main__ INFO: \u001b[0mEpoch 337 Step 200/351 lr 0.001000 loss 1.3386 (1.2514) acc@1 0.4844 (0.5185) acc@5 0.7109 (0.7602)\n",
      "\u001b[32m[2020-06-22 19:38:39] __main__ INFO: \u001b[0mEpoch 337 Step 300/351 lr 0.001000 loss 1.2381 (1.2552) acc@1 0.4922 (0.5171) acc@5 0.7578 (0.7606)\n",
      "\u001b[32m[2020-06-22 19:38:43] __main__ INFO: \u001b[0mEpoch 337 Step 351/351 lr 0.001000 loss 1.3708 (1.2580) acc@1 0.4688 (0.5164) acc@5 0.7578 (0.7600)\n",
      "\u001b[32m[2020-06-22 19:38:43] __main__ INFO: \u001b[0mElapsed 32.77\n",
      "\u001b[32m[2020-06-22 19:38:43] __main__ INFO: \u001b[0mVal 337\n",
      "\u001b[32m[2020-06-22 19:38:45] __main__ INFO: \u001b[0mEpoch 337 loss 2.6959 acc@1 0.2926 acc@5 0.6936\n",
      "\u001b[32m[2020-06-22 19:38:45] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 19:38:45] __main__ INFO: \u001b[0mTrain 338 118287\n",
      "\u001b[32m[2020-06-22 19:38:54] __main__ INFO: \u001b[0mEpoch 338 Step 100/351 lr 0.001000 loss 1.2022 (1.2504) acc@1 0.5547 (0.5188) acc@5 0.7344 (0.7614)\n",
      "\u001b[32m[2020-06-22 19:39:03] __main__ INFO: \u001b[0mEpoch 338 Step 200/351 lr 0.001000 loss 1.1834 (1.2522) acc@1 0.5312 (0.5165) acc@5 0.7969 (0.7600)\n",
      "\u001b[32m[2020-06-22 19:39:13] __main__ INFO: \u001b[0mEpoch 338 Step 300/351 lr 0.001000 loss 1.3462 (1.2537) acc@1 0.4375 (0.5161) acc@5 0.7344 (0.7598)\n",
      "\u001b[32m[2020-06-22 19:39:17] __main__ INFO: \u001b[0mEpoch 338 Step 351/351 lr 0.001000 loss 1.3215 (1.2552) acc@1 0.5078 (0.5154) acc@5 0.6875 (0.7598)\n",
      "\u001b[32m[2020-06-22 19:39:17] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 19:39:17] __main__ INFO: \u001b[0mVal 338\n",
      "\u001b[32m[2020-06-22 19:39:18] __main__ INFO: \u001b[0mEpoch 338 loss 2.6901 acc@1 0.2798 acc@5 0.6876\n",
      "\u001b[32m[2020-06-22 19:39:18] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 19:39:18] __main__ INFO: \u001b[0mTrain 339 118638\n",
      "\u001b[32m[2020-06-22 19:39:28] __main__ INFO: \u001b[0mEpoch 339 Step 100/351 lr 0.001000 loss 1.1313 (1.2598) acc@1 0.5703 (0.5156) acc@5 0.7891 (0.7582)\n",
      "\u001b[32m[2020-06-22 19:39:37] __main__ INFO: \u001b[0mEpoch 339 Step 200/351 lr 0.001000 loss 1.2022 (1.2574) acc@1 0.5625 (0.5165) acc@5 0.7422 (0.7600)\n",
      "\u001b[32m[2020-06-22 19:39:46] __main__ INFO: \u001b[0mEpoch 339 Step 300/351 lr 0.001000 loss 1.2206 (1.2548) acc@1 0.5469 (0.5173) acc@5 0.7734 (0.7593)\n",
      "\u001b[32m[2020-06-22 19:39:51] __main__ INFO: \u001b[0mEpoch 339 Step 351/351 lr 0.001000 loss 1.3676 (1.2573) acc@1 0.4609 (0.5163) acc@5 0.7578 (0.7591)\n",
      "\u001b[32m[2020-06-22 19:39:51] __main__ INFO: \u001b[0mElapsed 32.84\n",
      "\u001b[32m[2020-06-22 19:39:51] __main__ INFO: \u001b[0mVal 339\n",
      "\u001b[32m[2020-06-22 19:39:52] __main__ INFO: \u001b[0mEpoch 339 loss 2.6658 acc@1 0.2888 acc@5 0.6868\n",
      "\u001b[32m[2020-06-22 19:39:52] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 19:39:52] __main__ INFO: \u001b[0mTrain 340 118989\n",
      "\u001b[32m[2020-06-22 19:40:02] __main__ INFO: \u001b[0mEpoch 340 Step 100/351 lr 0.001000 loss 1.2962 (1.2567) acc@1 0.5312 (0.5173) acc@5 0.7656 (0.7561)\n",
      "\u001b[32m[2020-06-22 19:40:11] __main__ INFO: \u001b[0mEpoch 340 Step 200/351 lr 0.001000 loss 1.3820 (1.2485) acc@1 0.5000 (0.5188) acc@5 0.7656 (0.7586)\n",
      "\u001b[32m[2020-06-22 19:40:20] __main__ INFO: \u001b[0mEpoch 340 Step 300/351 lr 0.001000 loss 1.2058 (1.2585) acc@1 0.5312 (0.5142) acc@5 0.8281 (0.7569)\n",
      "\u001b[32m[2020-06-22 19:40:25] __main__ INFO: \u001b[0mEpoch 340 Step 351/351 lr 0.001000 loss 1.2940 (1.2568) acc@1 0.5078 (0.5149) acc@5 0.7422 (0.7579)\n",
      "\u001b[32m[2020-06-22 19:40:25] __main__ INFO: \u001b[0mElapsed 32.84\n",
      "\u001b[32m[2020-06-22 19:40:25] __main__ INFO: \u001b[0mVal 340\n",
      "\u001b[32m[2020-06-22 19:40:26] __main__ INFO: \u001b[0mEpoch 340 loss 2.6601 acc@1 0.2794 acc@5 0.6958\n",
      "\u001b[32m[2020-06-22 19:40:26] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 19:40:26] __main__ INFO: \u001b[0mTrain 341 119340\n",
      "\u001b[32m[2020-06-22 19:40:36] __main__ INFO: \u001b[0mEpoch 341 Step 100/351 lr 0.001000 loss 1.2266 (1.2371) acc@1 0.5234 (0.5266) acc@5 0.8125 (0.7634)\n",
      "\u001b[32m[2020-06-22 19:40:45] __main__ INFO: \u001b[0mEpoch 341 Step 200/351 lr 0.001000 loss 1.2358 (1.2476) acc@1 0.5391 (0.5198) acc@5 0.7891 (0.7612)\n",
      "\u001b[32m[2020-06-22 19:40:54] __main__ INFO: \u001b[0mEpoch 341 Step 300/351 lr 0.001000 loss 1.3743 (1.2519) acc@1 0.4609 (0.5185) acc@5 0.6797 (0.7595)\n",
      "\u001b[32m[2020-06-22 19:40:59] __main__ INFO: \u001b[0mEpoch 341 Step 351/351 lr 0.001000 loss 1.1656 (1.2528) acc@1 0.5469 (0.5177) acc@5 0.7891 (0.7593)\n",
      "\u001b[32m[2020-06-22 19:40:59] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 19:40:59] __main__ INFO: \u001b[0mVal 341\n",
      "\u001b[32m[2020-06-22 19:41:00] __main__ INFO: \u001b[0mEpoch 341 loss 2.6524 acc@1 0.2836 acc@5 0.7010\n",
      "\u001b[32m[2020-06-22 19:41:00] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 19:41:00] __main__ INFO: \u001b[0mTrain 342 119691\n",
      "\u001b[32m[2020-06-22 19:41:09] __main__ INFO: \u001b[0mEpoch 342 Step 100/351 lr 0.001000 loss 1.1275 (1.2497) acc@1 0.5391 (0.5197) acc@5 0.7734 (0.7585)\n",
      "\u001b[32m[2020-06-22 19:41:19] __main__ INFO: \u001b[0mEpoch 342 Step 200/351 lr 0.001000 loss 1.3959 (1.2557) acc@1 0.4453 (0.5173) acc@5 0.7188 (0.7579)\n",
      "\u001b[32m[2020-06-22 19:41:28] __main__ INFO: \u001b[0mEpoch 342 Step 300/351 lr 0.001000 loss 1.2099 (1.2551) acc@1 0.5312 (0.5184) acc@5 0.7266 (0.7584)\n",
      "\u001b[32m[2020-06-22 19:41:33] __main__ INFO: \u001b[0mEpoch 342 Step 351/351 lr 0.001000 loss 1.2116 (1.2570) acc@1 0.5078 (0.5178) acc@5 0.7969 (0.7589)\n",
      "\u001b[32m[2020-06-22 19:41:33] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 19:41:33] __main__ INFO: \u001b[0mVal 342\n",
      "\u001b[32m[2020-06-22 19:41:34] __main__ INFO: \u001b[0mEpoch 342 loss 2.6709 acc@1 0.2798 acc@5 0.6956\n",
      "\u001b[32m[2020-06-22 19:41:34] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 19:41:34] __main__ INFO: \u001b[0mTrain 343 120042\n",
      "\u001b[32m[2020-06-22 19:41:43] __main__ INFO: \u001b[0mEpoch 343 Step 100/351 lr 0.001000 loss 1.2301 (1.2581) acc@1 0.5625 (0.5173) acc@5 0.7734 (0.7570)\n",
      "\u001b[32m[2020-06-22 19:41:53] __main__ INFO: \u001b[0mEpoch 343 Step 200/351 lr 0.001000 loss 1.3720 (1.2596) acc@1 0.4297 (0.5151) acc@5 0.6797 (0.7573)\n",
      "\u001b[32m[2020-06-22 19:42:02] __main__ INFO: \u001b[0mEpoch 343 Step 300/351 lr 0.001000 loss 1.1967 (1.2560) acc@1 0.5625 (0.5173) acc@5 0.7969 (0.7595)\n",
      "\u001b[32m[2020-06-22 19:42:07] __main__ INFO: \u001b[0mEpoch 343 Step 351/351 lr 0.001000 loss 1.2232 (1.2570) acc@1 0.5000 (0.5168) acc@5 0.7344 (0.7581)\n",
      "\u001b[32m[2020-06-22 19:42:07] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 19:42:07] __main__ INFO: \u001b[0mVal 343\n",
      "\u001b[32m[2020-06-22 19:42:08] __main__ INFO: \u001b[0mEpoch 343 loss 2.6504 acc@1 0.2918 acc@5 0.6942\n",
      "\u001b[32m[2020-06-22 19:42:08] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 19:42:08] __main__ INFO: \u001b[0mTrain 344 120393\n",
      "\u001b[32m[2020-06-22 19:42:17] __main__ INFO: \u001b[0mEpoch 344 Step 100/351 lr 0.001000 loss 1.1341 (1.2284) acc@1 0.5469 (0.5270) acc@5 0.7891 (0.7605)\n",
      "\u001b[32m[2020-06-22 19:42:26] __main__ INFO: \u001b[0mEpoch 344 Step 200/351 lr 0.001000 loss 1.1423 (1.2396) acc@1 0.5781 (0.5236) acc@5 0.7734 (0.7610)\n",
      "\u001b[32m[2020-06-22 19:42:36] __main__ INFO: \u001b[0mEpoch 344 Step 300/351 lr 0.001000 loss 1.2467 (1.2495) acc@1 0.5000 (0.5205) acc@5 0.7812 (0.7595)\n",
      "\u001b[32m[2020-06-22 19:42:41] __main__ INFO: \u001b[0mEpoch 344 Step 351/351 lr 0.001000 loss 1.3561 (1.2533) acc@1 0.4766 (0.5184) acc@5 0.7422 (0.7583)\n",
      "\u001b[32m[2020-06-22 19:42:41] __main__ INFO: \u001b[0mElapsed 32.84\n",
      "\u001b[32m[2020-06-22 19:42:41] __main__ INFO: \u001b[0mVal 344\n",
      "\u001b[32m[2020-06-22 19:42:42] __main__ INFO: \u001b[0mEpoch 344 loss 2.6975 acc@1 0.2886 acc@5 0.7110\n",
      "\u001b[32m[2020-06-22 19:42:42] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 19:42:42] __main__ INFO: \u001b[0mTrain 345 120744\n",
      "\u001b[32m[2020-06-22 19:42:51] __main__ INFO: \u001b[0mEpoch 345 Step 100/351 lr 0.001000 loss 1.1179 (1.2634) acc@1 0.5781 (0.5135) acc@5 0.7500 (0.7560)\n",
      "\u001b[32m[2020-06-22 19:43:00] __main__ INFO: \u001b[0mEpoch 345 Step 200/351 lr 0.001000 loss 1.3390 (1.2580) acc@1 0.4922 (0.5164) acc@5 0.7812 (0.7586)\n",
      "\u001b[32m[2020-06-22 19:43:10] __main__ INFO: \u001b[0mEpoch 345 Step 300/351 lr 0.001000 loss 1.0881 (1.2542) acc@1 0.6016 (0.5182) acc@5 0.7812 (0.7579)\n",
      "\u001b[32m[2020-06-22 19:43:14] __main__ INFO: \u001b[0mEpoch 345 Step 351/351 lr 0.001000 loss 1.3155 (1.2561) acc@1 0.5078 (0.5177) acc@5 0.6875 (0.7574)\n",
      "\u001b[32m[2020-06-22 19:43:14] __main__ INFO: \u001b[0mElapsed 32.82\n",
      "\u001b[32m[2020-06-22 19:43:14] __main__ INFO: \u001b[0mVal 345\n",
      "\u001b[32m[2020-06-22 19:43:15] __main__ INFO: \u001b[0mEpoch 345 loss 2.6956 acc@1 0.2786 acc@5 0.6894\n",
      "\u001b[32m[2020-06-22 19:43:15] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 19:43:16] __main__ INFO: \u001b[0mTrain 346 121095\n",
      "\u001b[32m[2020-06-22 19:43:25] __main__ INFO: \u001b[0mEpoch 346 Step 100/351 lr 0.001000 loss 1.2146 (1.2471) acc@1 0.5234 (0.5202) acc@5 0.7812 (0.7598)\n",
      "\u001b[32m[2020-06-22 19:43:34] __main__ INFO: \u001b[0mEpoch 346 Step 200/351 lr 0.001000 loss 1.2564 (1.2478) acc@1 0.5078 (0.5196) acc@5 0.7500 (0.7571)\n",
      "\u001b[32m[2020-06-22 19:43:44] __main__ INFO: \u001b[0mEpoch 346 Step 300/351 lr 0.001000 loss 1.3422 (1.2544) acc@1 0.5078 (0.5173) acc@5 0.7500 (0.7569)\n",
      "\u001b[32m[2020-06-22 19:43:48] __main__ INFO: \u001b[0mEpoch 346 Step 351/351 lr 0.001000 loss 1.1992 (1.2544) acc@1 0.5469 (0.5179) acc@5 0.7969 (0.7569)\n",
      "\u001b[32m[2020-06-22 19:43:48] __main__ INFO: \u001b[0mElapsed 32.78\n",
      "\u001b[32m[2020-06-22 19:43:48] __main__ INFO: \u001b[0mVal 346\n",
      "\u001b[32m[2020-06-22 19:43:49] __main__ INFO: \u001b[0mEpoch 346 loss 2.6889 acc@1 0.2808 acc@5 0.6902\n",
      "\u001b[32m[2020-06-22 19:43:49] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 19:43:49] __main__ INFO: \u001b[0mTrain 347 121446\n",
      "\u001b[32m[2020-06-22 19:43:59] __main__ INFO: \u001b[0mEpoch 347 Step 100/351 lr 0.001000 loss 1.2805 (1.2409) acc@1 0.5234 (0.5213) acc@5 0.8203 (0.7619)\n",
      "\u001b[32m[2020-06-22 19:44:08] __main__ INFO: \u001b[0mEpoch 347 Step 200/351 lr 0.001000 loss 1.1536 (1.2498) acc@1 0.5938 (0.5186) acc@5 0.8125 (0.7612)\n",
      "\u001b[32m[2020-06-22 19:44:17] __main__ INFO: \u001b[0mEpoch 347 Step 300/351 lr 0.001000 loss 1.3699 (1.2494) acc@1 0.4688 (0.5187) acc@5 0.7188 (0.7614)\n",
      "\u001b[32m[2020-06-22 19:44:22] __main__ INFO: \u001b[0mEpoch 347 Step 351/351 lr 0.001000 loss 1.1435 (1.2524) acc@1 0.5625 (0.5182) acc@5 0.7969 (0.7598)\n",
      "\u001b[32m[2020-06-22 19:44:22] __main__ INFO: \u001b[0mElapsed 32.77\n",
      "\u001b[32m[2020-06-22 19:44:22] __main__ INFO: \u001b[0mVal 347\n",
      "\u001b[32m[2020-06-22 19:44:23] __main__ INFO: \u001b[0mEpoch 347 loss 2.6786 acc@1 0.2834 acc@5 0.6950\n",
      "\u001b[32m[2020-06-22 19:44:23] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 19:44:23] __main__ INFO: \u001b[0mTrain 348 121797\n",
      "\u001b[32m[2020-06-22 19:44:33] __main__ INFO: \u001b[0mEpoch 348 Step 100/351 lr 0.001000 loss 1.1962 (1.2399) acc@1 0.5312 (0.5216) acc@5 0.7969 (0.7610)\n",
      "\u001b[32m[2020-06-22 19:44:42] __main__ INFO: \u001b[0mEpoch 348 Step 200/351 lr 0.001000 loss 1.4370 (1.2531) acc@1 0.4141 (0.5150) acc@5 0.6328 (0.7545)\n",
      "\u001b[32m[2020-06-22 19:44:51] __main__ INFO: \u001b[0mEpoch 348 Step 300/351 lr 0.001000 loss 1.0906 (1.2506) acc@1 0.6172 (0.5181) acc@5 0.7734 (0.7577)\n",
      "\u001b[32m[2020-06-22 19:44:56] __main__ INFO: \u001b[0mEpoch 348 Step 351/351 lr 0.001000 loss 1.4510 (1.2516) acc@1 0.4375 (0.5183) acc@5 0.7109 (0.7593)\n",
      "\u001b[32m[2020-06-22 19:44:56] __main__ INFO: \u001b[0mElapsed 32.78\n",
      "\u001b[32m[2020-06-22 19:44:56] __main__ INFO: \u001b[0mVal 348\n",
      "\u001b[32m[2020-06-22 19:44:57] __main__ INFO: \u001b[0mEpoch 348 loss 2.6694 acc@1 0.2816 acc@5 0.6848\n",
      "\u001b[32m[2020-06-22 19:44:57] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 19:44:57] __main__ INFO: \u001b[0mTrain 349 122148\n",
      "\u001b[32m[2020-06-22 19:45:06] __main__ INFO: \u001b[0mEpoch 349 Step 100/351 lr 0.001000 loss 1.4471 (1.2484) acc@1 0.4375 (0.5163) acc@5 0.7031 (0.7552)\n",
      "\u001b[32m[2020-06-22 19:45:16] __main__ INFO: \u001b[0mEpoch 349 Step 200/351 lr 0.001000 loss 1.2634 (1.2596) acc@1 0.5234 (0.5142) acc@5 0.7578 (0.7549)\n",
      "\u001b[32m[2020-06-22 19:45:25] __main__ INFO: \u001b[0mEpoch 349 Step 300/351 lr 0.001000 loss 1.2555 (1.2509) acc@1 0.5469 (0.5171) acc@5 0.8047 (0.7574)\n",
      "\u001b[32m[2020-06-22 19:45:30] __main__ INFO: \u001b[0mEpoch 349 Step 351/351 lr 0.001000 loss 1.2719 (1.2519) acc@1 0.4844 (0.5166) acc@5 0.7188 (0.7563)\n",
      "\u001b[32m[2020-06-22 19:45:30] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 19:45:30] __main__ INFO: \u001b[0mVal 349\n",
      "\u001b[32m[2020-06-22 19:45:31] __main__ INFO: \u001b[0mEpoch 349 loss 2.7275 acc@1 0.2826 acc@5 0.6948\n",
      "\u001b[32m[2020-06-22 19:45:31] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-06-22 19:45:31] __main__ INFO: \u001b[0mTrain 350 122499\n",
      "\u001b[32m[2020-06-22 19:45:40] __main__ INFO: \u001b[0mEpoch 350 Step 100/351 lr 0.001000 loss 1.2965 (1.2669) acc@1 0.4688 (0.5114) acc@5 0.7422 (0.7545)\n",
      "\u001b[32m[2020-06-22 19:45:50] __main__ INFO: \u001b[0mEpoch 350 Step 200/351 lr 0.001000 loss 1.2182 (1.2551) acc@1 0.5078 (0.5143) acc@5 0.7188 (0.7566)\n",
      "\u001b[32m[2020-06-22 19:45:59] __main__ INFO: \u001b[0mEpoch 350 Step 300/351 lr 0.001000 loss 1.0421 (1.2522) acc@1 0.6094 (0.5171) acc@5 0.7969 (0.7578)\n",
      "\u001b[32m[2020-06-22 19:46:04] __main__ INFO: \u001b[0mEpoch 350 Step 351/351 lr 0.001000 loss 1.2557 (1.2505) acc@1 0.5547 (0.5178) acc@5 0.7422 (0.7587)\n",
      "\u001b[32m[2020-06-22 19:46:04] __main__ INFO: \u001b[0mElapsed 32.87\n",
      "\u001b[32m[2020-06-22 19:46:04] __main__ INFO: \u001b[0mVal 350\n",
      "\u001b[32m[2020-06-22 19:46:05] __main__ INFO: \u001b[0mEpoch 350 loss 2.6954 acc@1 0.2892 acc@5 0.6958\n",
      "\u001b[32m[2020-06-22 19:46:05] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 19:46:05] __main__ INFO: \u001b[0mTrain 351 122850\n",
      "\u001b[32m[2020-06-22 19:46:14] __main__ INFO: \u001b[0mEpoch 351 Step 100/351 lr 0.001000 loss 1.2406 (1.2558) acc@1 0.5469 (0.5177) acc@5 0.7734 (0.7584)\n",
      "\u001b[32m[2020-06-22 19:46:24] __main__ INFO: \u001b[0mEpoch 351 Step 200/351 lr 0.001000 loss 1.2881 (1.2474) acc@1 0.4766 (0.5193) acc@5 0.7266 (0.7602)\n",
      "\u001b[32m[2020-06-22 19:46:33] __main__ INFO: \u001b[0mEpoch 351 Step 300/351 lr 0.001000 loss 1.1662 (1.2527) acc@1 0.5469 (0.5171) acc@5 0.8359 (0.7599)\n",
      "\u001b[32m[2020-06-22 19:46:38] __main__ INFO: \u001b[0mEpoch 351 Step 351/351 lr 0.001000 loss 1.2293 (1.2521) acc@1 0.5078 (0.5166) acc@5 0.7500 (0.7599)\n",
      "\u001b[32m[2020-06-22 19:46:38] __main__ INFO: \u001b[0mElapsed 32.83\n",
      "\u001b[32m[2020-06-22 19:46:38] __main__ INFO: \u001b[0mVal 351\n",
      "\u001b[32m[2020-06-22 19:46:39] __main__ INFO: \u001b[0mEpoch 351 loss 2.6800 acc@1 0.2920 acc@5 0.6952\n",
      "\u001b[32m[2020-06-22 19:46:39] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 19:46:39] __main__ INFO: \u001b[0mTrain 352 123201\n",
      "\u001b[32m[2020-06-22 19:46:48] __main__ INFO: \u001b[0mEpoch 352 Step 100/351 lr 0.001000 loss 1.2591 (1.2515) acc@1 0.5078 (0.5207) acc@5 0.7578 (0.7595)\n",
      "\u001b[32m[2020-06-22 19:46:57] __main__ INFO: \u001b[0mEpoch 352 Step 200/351 lr 0.001000 loss 1.0701 (1.2503) acc@1 0.6094 (0.5188) acc@5 0.8047 (0.7580)\n",
      "\u001b[32m[2020-06-22 19:47:07] __main__ INFO: \u001b[0mEpoch 352 Step 300/351 lr 0.001000 loss 1.1628 (1.2488) acc@1 0.5625 (0.5190) acc@5 0.7266 (0.7603)\n",
      "\u001b[32m[2020-06-22 19:47:12] __main__ INFO: \u001b[0mEpoch 352 Step 351/351 lr 0.001000 loss 1.2406 (1.2498) acc@1 0.5469 (0.5179) acc@5 0.7656 (0.7601)\n",
      "\u001b[32m[2020-06-22 19:47:12] __main__ INFO: \u001b[0mElapsed 32.84\n",
      "\u001b[32m[2020-06-22 19:47:12] __main__ INFO: \u001b[0mVal 352\n",
      "\u001b[32m[2020-06-22 19:47:13] __main__ INFO: \u001b[0mEpoch 352 loss 2.6828 acc@1 0.2894 acc@5 0.7042\n",
      "\u001b[32m[2020-06-22 19:47:13] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 19:47:13] __main__ INFO: \u001b[0mTrain 353 123552\n",
      "\u001b[32m[2020-06-22 19:47:22] __main__ INFO: \u001b[0mEpoch 353 Step 100/351 lr 0.001000 loss 1.3987 (1.2522) acc@1 0.4688 (0.5180) acc@5 0.6953 (0.7492)\n",
      "\u001b[32m[2020-06-22 19:47:31] __main__ INFO: \u001b[0mEpoch 353 Step 200/351 lr 0.001000 loss 1.3826 (1.2460) acc@1 0.4531 (0.5194) acc@5 0.7500 (0.7555)\n",
      "\u001b[32m[2020-06-22 19:47:41] __main__ INFO: \u001b[0mEpoch 353 Step 300/351 lr 0.001000 loss 1.3441 (1.2510) acc@1 0.4609 (0.5183) acc@5 0.7734 (0.7572)\n",
      "\u001b[32m[2020-06-22 19:47:45] __main__ INFO: \u001b[0mEpoch 353 Step 351/351 lr 0.001000 loss 0.9754 (1.2501) acc@1 0.6250 (0.5189) acc@5 0.8125 (0.7573)\n",
      "\u001b[32m[2020-06-22 19:47:45] __main__ INFO: \u001b[0mElapsed 32.73\n",
      "\u001b[32m[2020-06-22 19:47:45] __main__ INFO: \u001b[0mVal 353\n",
      "\u001b[32m[2020-06-22 19:47:46] __main__ INFO: \u001b[0mEpoch 353 loss 2.6705 acc@1 0.2938 acc@5 0.7038\n",
      "\u001b[32m[2020-06-22 19:47:46] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 19:47:46] __main__ INFO: \u001b[0mTrain 354 123903\n",
      "\u001b[32m[2020-06-22 19:47:56] __main__ INFO: \u001b[0mEpoch 354 Step 100/351 lr 0.001000 loss 1.3599 (1.2451) acc@1 0.4844 (0.5198) acc@5 0.7812 (0.7579)\n",
      "\u001b[32m[2020-06-22 19:48:05] __main__ INFO: \u001b[0mEpoch 354 Step 200/351 lr 0.001000 loss 1.0462 (1.2495) acc@1 0.5703 (0.5179) acc@5 0.7812 (0.7596)\n",
      "\u001b[32m[2020-06-22 19:48:14] __main__ INFO: \u001b[0mEpoch 354 Step 300/351 lr 0.001000 loss 1.2745 (1.2461) acc@1 0.5156 (0.5203) acc@5 0.7969 (0.7608)\n",
      "\u001b[32m[2020-06-22 19:48:19] __main__ INFO: \u001b[0mEpoch 354 Step 351/351 lr 0.001000 loss 1.3483 (1.2479) acc@1 0.4844 (0.5191) acc@5 0.7578 (0.7596)\n",
      "\u001b[32m[2020-06-22 19:48:19] __main__ INFO: \u001b[0mElapsed 32.78\n",
      "\u001b[32m[2020-06-22 19:48:19] __main__ INFO: \u001b[0mVal 354\n",
      "\u001b[32m[2020-06-22 19:48:20] __main__ INFO: \u001b[0mEpoch 354 loss 2.6997 acc@1 0.2858 acc@5 0.6850\n",
      "\u001b[32m[2020-06-22 19:48:20] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 19:48:20] __main__ INFO: \u001b[0mTrain 355 124254\n",
      "\u001b[32m[2020-06-22 19:48:30] __main__ INFO: \u001b[0mEpoch 355 Step 100/351 lr 0.001000 loss 1.3350 (1.2360) acc@1 0.4688 (0.5264) acc@5 0.7656 (0.7590)\n",
      "\u001b[32m[2020-06-22 19:48:39] __main__ INFO: \u001b[0mEpoch 355 Step 200/351 lr 0.001000 loss 1.3748 (1.2542) acc@1 0.4531 (0.5172) acc@5 0.7656 (0.7562)\n",
      "\u001b[32m[2020-06-22 19:48:48] __main__ INFO: \u001b[0mEpoch 355 Step 300/351 lr 0.001000 loss 1.1532 (1.2527) acc@1 0.5703 (0.5177) acc@5 0.7500 (0.7594)\n",
      "\u001b[32m[2020-06-22 19:48:53] __main__ INFO: \u001b[0mEpoch 355 Step 351/351 lr 0.001000 loss 1.2791 (1.2521) acc@1 0.4531 (0.5175) acc@5 0.7188 (0.7591)\n",
      "\u001b[32m[2020-06-22 19:48:53] __main__ INFO: \u001b[0mElapsed 32.84\n",
      "\u001b[32m[2020-06-22 19:48:53] __main__ INFO: \u001b[0mVal 355\n",
      "\u001b[32m[2020-06-22 19:48:54] __main__ INFO: \u001b[0mEpoch 355 loss 2.7326 acc@1 0.2916 acc@5 0.6976\n",
      "\u001b[32m[2020-06-22 19:48:54] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 19:48:54] __main__ INFO: \u001b[0mTrain 356 124605\n",
      "\u001b[32m[2020-06-22 19:49:04] __main__ INFO: \u001b[0mEpoch 356 Step 100/351 lr 0.001000 loss 1.1786 (1.2445) acc@1 0.5859 (0.5223) acc@5 0.8047 (0.7576)\n",
      "\u001b[32m[2020-06-22 19:49:13] __main__ INFO: \u001b[0mEpoch 356 Step 200/351 lr 0.001000 loss 1.1769 (1.2480) acc@1 0.5469 (0.5190) acc@5 0.7812 (0.7578)\n",
      "\u001b[32m[2020-06-22 19:49:22] __main__ INFO: \u001b[0mEpoch 356 Step 300/351 lr 0.001000 loss 1.3058 (1.2481) acc@1 0.5312 (0.5191) acc@5 0.8203 (0.7567)\n",
      "\u001b[32m[2020-06-22 19:49:27] __main__ INFO: \u001b[0mEpoch 356 Step 351/351 lr 0.001000 loss 1.3982 (1.2481) acc@1 0.4375 (0.5192) acc@5 0.7031 (0.7567)\n",
      "\u001b[32m[2020-06-22 19:49:27] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 19:49:27] __main__ INFO: \u001b[0mVal 356\n",
      "\u001b[32m[2020-06-22 19:49:28] __main__ INFO: \u001b[0mEpoch 356 loss 2.7104 acc@1 0.2874 acc@5 0.6980\n",
      "\u001b[32m[2020-06-22 19:49:28] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 19:49:28] __main__ INFO: \u001b[0mTrain 357 124956\n",
      "\u001b[32m[2020-06-22 19:49:37] __main__ INFO: \u001b[0mEpoch 357 Step 100/351 lr 0.001000 loss 1.2733 (1.2591) acc@1 0.5156 (0.5178) acc@5 0.7969 (0.7597)\n",
      "\u001b[32m[2020-06-22 19:49:47] __main__ INFO: \u001b[0mEpoch 357 Step 200/351 lr 0.001000 loss 1.3181 (1.2560) acc@1 0.5000 (0.5188) acc@5 0.7812 (0.7584)\n",
      "\u001b[32m[2020-06-22 19:49:56] __main__ INFO: \u001b[0mEpoch 357 Step 300/351 lr 0.001000 loss 1.0181 (1.2526) acc@1 0.6172 (0.5187) acc@5 0.7656 (0.7587)\n",
      "\u001b[32m[2020-06-22 19:50:01] __main__ INFO: \u001b[0mEpoch 357 Step 351/351 lr 0.001000 loss 1.1190 (1.2517) acc@1 0.5703 (0.5187) acc@5 0.8281 (0.7589)\n",
      "\u001b[32m[2020-06-22 19:50:01] __main__ INFO: \u001b[0mElapsed 32.78\n",
      "\u001b[32m[2020-06-22 19:50:01] __main__ INFO: \u001b[0mVal 357\n",
      "\u001b[32m[2020-06-22 19:50:02] __main__ INFO: \u001b[0mEpoch 357 loss 2.7079 acc@1 0.2798 acc@5 0.6956\n",
      "\u001b[32m[2020-06-22 19:50:02] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 19:50:02] __main__ INFO: \u001b[0mTrain 358 125307\n",
      "\u001b[32m[2020-06-22 19:50:11] __main__ INFO: \u001b[0mEpoch 358 Step 100/351 lr 0.001000 loss 1.4093 (1.2471) acc@1 0.4609 (0.5198) acc@5 0.7422 (0.7572)\n",
      "\u001b[32m[2020-06-22 19:50:21] __main__ INFO: \u001b[0mEpoch 358 Step 200/351 lr 0.001000 loss 1.2359 (1.2472) acc@1 0.5078 (0.5198) acc@5 0.7969 (0.7572)\n",
      "\u001b[32m[2020-06-22 19:50:30] __main__ INFO: \u001b[0mEpoch 358 Step 300/351 lr 0.001000 loss 1.3566 (1.2472) acc@1 0.4922 (0.5195) acc@5 0.7188 (0.7578)\n",
      "\u001b[32m[2020-06-22 19:50:35] __main__ INFO: \u001b[0mEpoch 358 Step 351/351 lr 0.001000 loss 1.3066 (1.2499) acc@1 0.4609 (0.5184) acc@5 0.6875 (0.7573)\n",
      "\u001b[32m[2020-06-22 19:50:35] __main__ INFO: \u001b[0mElapsed 32.81\n",
      "\u001b[32m[2020-06-22 19:50:35] __main__ INFO: \u001b[0mVal 358\n",
      "\u001b[32m[2020-06-22 19:50:36] __main__ INFO: \u001b[0mEpoch 358 loss 2.7163 acc@1 0.2816 acc@5 0.6854\n",
      "\u001b[32m[2020-06-22 19:50:36] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 19:50:36] __main__ INFO: \u001b[0mTrain 359 125658\n",
      "\u001b[32m[2020-06-22 19:50:45] __main__ INFO: \u001b[0mEpoch 359 Step 100/351 lr 0.001000 loss 1.1202 (1.2387) acc@1 0.5625 (0.5221) acc@5 0.8359 (0.7588)\n",
      "\u001b[32m[2020-06-22 19:50:54] __main__ INFO: \u001b[0mEpoch 359 Step 200/351 lr 0.001000 loss 1.2434 (1.2425) acc@1 0.5312 (0.5215) acc@5 0.7734 (0.7616)\n",
      "\u001b[32m[2020-06-22 19:51:04] __main__ INFO: \u001b[0mEpoch 359 Step 300/351 lr 0.001000 loss 1.2656 (1.2434) acc@1 0.4922 (0.5219) acc@5 0.7734 (0.7592)\n",
      "\u001b[32m[2020-06-22 19:51:08] __main__ INFO: \u001b[0mEpoch 359 Step 351/351 lr 0.001000 loss 1.4368 (1.2490) acc@1 0.4531 (0.5199) acc@5 0.7422 (0.7578)\n",
      "\u001b[32m[2020-06-22 19:51:08] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 19:51:08] __main__ INFO: \u001b[0mVal 359\n",
      "\u001b[32m[2020-06-22 19:51:10] __main__ INFO: \u001b[0mEpoch 359 loss 2.7703 acc@1 0.2912 acc@5 0.7014\n",
      "\u001b[32m[2020-06-22 19:51:10] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 19:51:10] __main__ INFO: \u001b[0mTrain 360 126009\n",
      "\u001b[32m[2020-06-22 19:51:19] __main__ INFO: \u001b[0mEpoch 360 Step 100/351 lr 0.001000 loss 1.1956 (1.2492) acc@1 0.5391 (0.5198) acc@5 0.7812 (0.7548)\n",
      "\u001b[32m[2020-06-22 19:51:28] __main__ INFO: \u001b[0mEpoch 360 Step 200/351 lr 0.001000 loss 1.2268 (1.2484) acc@1 0.5312 (0.5190) acc@5 0.7109 (0.7566)\n",
      "\u001b[32m[2020-06-22 19:51:38] __main__ INFO: \u001b[0mEpoch 360 Step 300/351 lr 0.001000 loss 1.3000 (1.2477) acc@1 0.5234 (0.5202) acc@5 0.7578 (0.7595)\n",
      "\u001b[32m[2020-06-22 19:51:42] __main__ INFO: \u001b[0mEpoch 360 Step 351/351 lr 0.001000 loss 0.9484 (1.2484) acc@1 0.6484 (0.5198) acc@5 0.8359 (0.7601)\n",
      "\u001b[32m[2020-06-22 19:51:42] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 19:51:42] __main__ INFO: \u001b[0mVal 360\n",
      "\u001b[32m[2020-06-22 19:51:43] __main__ INFO: \u001b[0mEpoch 360 loss 2.6968 acc@1 0.2796 acc@5 0.6914\n",
      "\u001b[32m[2020-06-22 19:51:43] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 19:51:43] __main__ INFO: \u001b[0mTrain 361 126360\n",
      "\u001b[32m[2020-06-22 19:51:53] __main__ INFO: \u001b[0mEpoch 361 Step 100/351 lr 0.001000 loss 1.1799 (1.2562) acc@1 0.5469 (0.5140) acc@5 0.7734 (0.7504)\n",
      "\u001b[32m[2020-06-22 19:52:02] __main__ INFO: \u001b[0mEpoch 361 Step 200/351 lr 0.001000 loss 1.1278 (1.2451) acc@1 0.5391 (0.5206) acc@5 0.7188 (0.7540)\n",
      "\u001b[32m[2020-06-22 19:52:11] __main__ INFO: \u001b[0mEpoch 361 Step 300/351 lr 0.001000 loss 1.2879 (1.2475) acc@1 0.5234 (0.5196) acc@5 0.7422 (0.7555)\n",
      "\u001b[32m[2020-06-22 19:52:16] __main__ INFO: \u001b[0mEpoch 361 Step 351/351 lr 0.001000 loss 0.9795 (1.2457) acc@1 0.6250 (0.5196) acc@5 0.8125 (0.7564)\n",
      "\u001b[32m[2020-06-22 19:52:16] __main__ INFO: \u001b[0mElapsed 32.73\n",
      "\u001b[32m[2020-06-22 19:52:16] __main__ INFO: \u001b[0mVal 361\n",
      "\u001b[32m[2020-06-22 19:52:17] __main__ INFO: \u001b[0mEpoch 361 loss 2.6715 acc@1 0.2878 acc@5 0.6964\n",
      "\u001b[32m[2020-06-22 19:52:17] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 19:52:17] __main__ INFO: \u001b[0mTrain 362 126711\n",
      "\u001b[32m[2020-06-22 19:52:27] __main__ INFO: \u001b[0mEpoch 362 Step 100/351 lr 0.001000 loss 1.2419 (1.2326) acc@1 0.5078 (0.5250) acc@5 0.7422 (0.7603)\n",
      "\u001b[32m[2020-06-22 19:52:36] __main__ INFO: \u001b[0mEpoch 362 Step 200/351 lr 0.001000 loss 1.2203 (1.2402) acc@1 0.5469 (0.5220) acc@5 0.7891 (0.7593)\n",
      "\u001b[32m[2020-06-22 19:52:45] __main__ INFO: \u001b[0mEpoch 362 Step 300/351 lr 0.001000 loss 1.2881 (1.2471) acc@1 0.5469 (0.5188) acc@5 0.8281 (0.7593)\n",
      "\u001b[32m[2020-06-22 19:52:50] __main__ INFO: \u001b[0mEpoch 362 Step 351/351 lr 0.001000 loss 1.0816 (1.2471) acc@1 0.6250 (0.5184) acc@5 0.7812 (0.7588)\n",
      "\u001b[32m[2020-06-22 19:52:50] __main__ INFO: \u001b[0mElapsed 32.85\n",
      "\u001b[32m[2020-06-22 19:52:50] __main__ INFO: \u001b[0mVal 362\n",
      "\u001b[32m[2020-06-22 19:52:51] __main__ INFO: \u001b[0mEpoch 362 loss 2.7191 acc@1 0.2800 acc@5 0.6924\n",
      "\u001b[32m[2020-06-22 19:52:51] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 19:52:51] __main__ INFO: \u001b[0mTrain 363 127062\n",
      "\u001b[32m[2020-06-22 19:53:01] __main__ INFO: \u001b[0mEpoch 363 Step 100/351 lr 0.001000 loss 1.0538 (1.2386) acc@1 0.5625 (0.5234) acc@5 0.8359 (0.7591)\n",
      "\u001b[32m[2020-06-22 19:53:10] __main__ INFO: \u001b[0mEpoch 363 Step 200/351 lr 0.001000 loss 1.1067 (1.2395) acc@1 0.5781 (0.5239) acc@5 0.8125 (0.7616)\n",
      "\u001b[32m[2020-06-22 19:53:19] __main__ INFO: \u001b[0mEpoch 363 Step 300/351 lr 0.001000 loss 1.2852 (1.2430) acc@1 0.4844 (0.5216) acc@5 0.7578 (0.7605)\n",
      "\u001b[32m[2020-06-22 19:53:24] __main__ INFO: \u001b[0mEpoch 363 Step 351/351 lr 0.001000 loss 1.1405 (1.2447) acc@1 0.5391 (0.5206) acc@5 0.7969 (0.7588)\n",
      "\u001b[32m[2020-06-22 19:53:24] __main__ INFO: \u001b[0mElapsed 32.86\n",
      "\u001b[32m[2020-06-22 19:53:24] __main__ INFO: \u001b[0mVal 363\n",
      "\u001b[32m[2020-06-22 19:53:25] __main__ INFO: \u001b[0mEpoch 363 loss 2.7557 acc@1 0.2918 acc@5 0.7026\n",
      "\u001b[32m[2020-06-22 19:53:25] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 19:53:25] __main__ INFO: \u001b[0mTrain 364 127413\n",
      "\u001b[32m[2020-06-22 19:53:34] __main__ INFO: \u001b[0mEpoch 364 Step 100/351 lr 0.001000 loss 1.2434 (1.2475) acc@1 0.5234 (0.5195) acc@5 0.7500 (0.7607)\n",
      "\u001b[32m[2020-06-22 19:53:44] __main__ INFO: \u001b[0mEpoch 364 Step 200/351 lr 0.001000 loss 1.3476 (1.2437) acc@1 0.4844 (0.5220) acc@5 0.7500 (0.7602)\n",
      "\u001b[32m[2020-06-22 19:53:53] __main__ INFO: \u001b[0mEpoch 364 Step 300/351 lr 0.001000 loss 1.2269 (1.2456) acc@1 0.4766 (0.5201) acc@5 0.7266 (0.7578)\n",
      "\u001b[32m[2020-06-22 19:53:58] __main__ INFO: \u001b[0mEpoch 364 Step 351/351 lr 0.001000 loss 1.1537 (1.2483) acc@1 0.5391 (0.5191) acc@5 0.7812 (0.7580)\n",
      "\u001b[32m[2020-06-22 19:53:58] __main__ INFO: \u001b[0mElapsed 32.75\n",
      "\u001b[32m[2020-06-22 19:53:58] __main__ INFO: \u001b[0mVal 364\n",
      "\u001b[32m[2020-06-22 19:53:59] __main__ INFO: \u001b[0mEpoch 364 loss 2.7344 acc@1 0.2826 acc@5 0.6874\n",
      "\u001b[32m[2020-06-22 19:53:59] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 19:53:59] __main__ INFO: \u001b[0mTrain 365 127764\n",
      "\u001b[32m[2020-06-22 19:54:08] __main__ INFO: \u001b[0mEpoch 365 Step 100/351 lr 0.001000 loss 1.2826 (1.2418) acc@1 0.4922 (0.5202) acc@5 0.7578 (0.7528)\n",
      "\u001b[32m[2020-06-22 19:54:18] __main__ INFO: \u001b[0mEpoch 365 Step 200/351 lr 0.001000 loss 1.1933 (1.2352) acc@1 0.5156 (0.5213) acc@5 0.7188 (0.7548)\n",
      "\u001b[32m[2020-06-22 19:54:27] __main__ INFO: \u001b[0mEpoch 365 Step 300/351 lr 0.001000 loss 1.2551 (1.2401) acc@1 0.5156 (0.5195) acc@5 0.7969 (0.7578)\n",
      "\u001b[32m[2020-06-22 19:54:32] __main__ INFO: \u001b[0mEpoch 365 Step 351/351 lr 0.001000 loss 1.2034 (1.2411) acc@1 0.5469 (0.5193) acc@5 0.7500 (0.7576)\n",
      "\u001b[32m[2020-06-22 19:54:32] __main__ INFO: \u001b[0mElapsed 32.86\n",
      "\u001b[32m[2020-06-22 19:54:32] __main__ INFO: \u001b[0mVal 365\n",
      "\u001b[32m[2020-06-22 19:54:33] __main__ INFO: \u001b[0mEpoch 365 loss 2.7570 acc@1 0.2868 acc@5 0.6888\n",
      "\u001b[32m[2020-06-22 19:54:33] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 19:54:33] __main__ INFO: \u001b[0mTrain 366 128115\n",
      "\u001b[32m[2020-06-22 19:54:42] __main__ INFO: \u001b[0mEpoch 366 Step 100/351 lr 0.001000 loss 1.3757 (1.2414) acc@1 0.4844 (0.5242) acc@5 0.7188 (0.7610)\n",
      "\u001b[32m[2020-06-22 19:54:51] __main__ INFO: \u001b[0mEpoch 366 Step 200/351 lr 0.001000 loss 1.2962 (1.2449) acc@1 0.5156 (0.5224) acc@5 0.7188 (0.7589)\n",
      "\u001b[32m[2020-06-22 19:55:01] __main__ INFO: \u001b[0mEpoch 366 Step 300/351 lr 0.001000 loss 1.2781 (1.2437) acc@1 0.4922 (0.5235) acc@5 0.6797 (0.7588)\n",
      "\u001b[32m[2020-06-22 19:55:06] __main__ INFO: \u001b[0mEpoch 366 Step 351/351 lr 0.001000 loss 1.0824 (1.2437) acc@1 0.6172 (0.5231) acc@5 0.8047 (0.7589)\n",
      "\u001b[32m[2020-06-22 19:55:06] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 19:55:06] __main__ INFO: \u001b[0mVal 366\n",
      "\u001b[32m[2020-06-22 19:55:07] __main__ INFO: \u001b[0mEpoch 366 loss 2.7273 acc@1 0.2832 acc@5 0.6974\n",
      "\u001b[32m[2020-06-22 19:55:07] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 19:55:07] __main__ INFO: \u001b[0mTrain 367 128466\n",
      "\u001b[32m[2020-06-22 19:55:16] __main__ INFO: \u001b[0mEpoch 367 Step 100/351 lr 0.001000 loss 1.4062 (1.2353) acc@1 0.4609 (0.5252) acc@5 0.7031 (0.7581)\n",
      "\u001b[32m[2020-06-22 19:55:25] __main__ INFO: \u001b[0mEpoch 367 Step 200/351 lr 0.001000 loss 1.3170 (1.2507) acc@1 0.5000 (0.5199) acc@5 0.7422 (0.7558)\n",
      "\u001b[32m[2020-06-22 19:55:35] __main__ INFO: \u001b[0mEpoch 367 Step 300/351 lr 0.001000 loss 1.3245 (1.2433) acc@1 0.4922 (0.5220) acc@5 0.7422 (0.7566)\n",
      "\u001b[32m[2020-06-22 19:55:39] __main__ INFO: \u001b[0mEpoch 367 Step 351/351 lr 0.001000 loss 1.3165 (1.2426) acc@1 0.4844 (0.5224) acc@5 0.8125 (0.7569)\n",
      "\u001b[32m[2020-06-22 19:55:39] __main__ INFO: \u001b[0mElapsed 32.84\n",
      "\u001b[32m[2020-06-22 19:55:39] __main__ INFO: \u001b[0mVal 367\n",
      "\u001b[32m[2020-06-22 19:55:40] __main__ INFO: \u001b[0mEpoch 367 loss 2.7457 acc@1 0.2828 acc@5 0.7052\n",
      "\u001b[32m[2020-06-22 19:55:40] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 19:55:40] __main__ INFO: \u001b[0mTrain 368 128817\n",
      "\u001b[32m[2020-06-22 19:55:50] __main__ INFO: \u001b[0mEpoch 368 Step 100/351 lr 0.001000 loss 1.1594 (1.2355) acc@1 0.5547 (0.5235) acc@5 0.7891 (0.7645)\n",
      "\u001b[32m[2020-06-22 19:55:59] __main__ INFO: \u001b[0mEpoch 368 Step 200/351 lr 0.001000 loss 1.2542 (1.2460) acc@1 0.5000 (0.5177) acc@5 0.7344 (0.7600)\n",
      "\u001b[32m[2020-06-22 19:56:09] __main__ INFO: \u001b[0mEpoch 368 Step 300/351 lr 0.001000 loss 1.2408 (1.2453) acc@1 0.5156 (0.5180) acc@5 0.7812 (0.7602)\n",
      "\u001b[32m[2020-06-22 19:56:13] __main__ INFO: \u001b[0mEpoch 368 Step 351/351 lr 0.001000 loss 1.3302 (1.2441) acc@1 0.5078 (0.5191) acc@5 0.7344 (0.7585)\n",
      "\u001b[32m[2020-06-22 19:56:13] __main__ INFO: \u001b[0mElapsed 32.83\n",
      "\u001b[32m[2020-06-22 19:56:13] __main__ INFO: \u001b[0mVal 368\n",
      "\u001b[32m[2020-06-22 19:56:14] __main__ INFO: \u001b[0mEpoch 368 loss 2.7486 acc@1 0.2854 acc@5 0.7024\n",
      "\u001b[32m[2020-06-22 19:56:14] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 19:56:14] __main__ INFO: \u001b[0mTrain 369 129168\n",
      "\u001b[32m[2020-06-22 19:56:24] __main__ INFO: \u001b[0mEpoch 369 Step 100/351 lr 0.001000 loss 1.2573 (1.2345) acc@1 0.4766 (0.5248) acc@5 0.7500 (0.7627)\n",
      "\u001b[32m[2020-06-22 19:56:33] __main__ INFO: \u001b[0mEpoch 369 Step 200/351 lr 0.001000 loss 1.3281 (1.2407) acc@1 0.4766 (0.5224) acc@5 0.7266 (0.7600)\n",
      "\u001b[32m[2020-06-22 19:56:42] __main__ INFO: \u001b[0mEpoch 369 Step 300/351 lr 0.001000 loss 1.1948 (1.2377) acc@1 0.5469 (0.5233) acc@5 0.8438 (0.7595)\n",
      "\u001b[32m[2020-06-22 19:56:47] __main__ INFO: \u001b[0mEpoch 369 Step 351/351 lr 0.001000 loss 1.3108 (1.2410) acc@1 0.5078 (0.5217) acc@5 0.7109 (0.7586)\n",
      "\u001b[32m[2020-06-22 19:56:47] __main__ INFO: \u001b[0mElapsed 32.84\n",
      "\u001b[32m[2020-06-22 19:56:47] __main__ INFO: \u001b[0mVal 369\n",
      "\u001b[32m[2020-06-22 19:56:48] __main__ INFO: \u001b[0mEpoch 369 loss 2.7552 acc@1 0.2788 acc@5 0.6864\n",
      "\u001b[32m[2020-06-22 19:56:48] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 19:56:48] __main__ INFO: \u001b[0mTrain 370 129519\n",
      "\u001b[32m[2020-06-22 19:56:58] __main__ INFO: \u001b[0mEpoch 370 Step 100/351 lr 0.001000 loss 1.2092 (1.2384) acc@1 0.5156 (0.5239) acc@5 0.7344 (0.7656)\n",
      "\u001b[32m[2020-06-22 19:57:07] __main__ INFO: \u001b[0mEpoch 370 Step 200/351 lr 0.001000 loss 1.2193 (1.2464) acc@1 0.5078 (0.5201) acc@5 0.6953 (0.7582)\n",
      "\u001b[32m[2020-06-22 19:57:16] __main__ INFO: \u001b[0mEpoch 370 Step 300/351 lr 0.001000 loss 1.2702 (1.2467) acc@1 0.4844 (0.5200) acc@5 0.7188 (0.7576)\n",
      "\u001b[32m[2020-06-22 19:57:21] __main__ INFO: \u001b[0mEpoch 370 Step 351/351 lr 0.001000 loss 1.1710 (1.2443) acc@1 0.5547 (0.5214) acc@5 0.7812 (0.7590)\n",
      "\u001b[32m[2020-06-22 19:57:21] __main__ INFO: \u001b[0mElapsed 32.82\n",
      "\u001b[32m[2020-06-22 19:57:21] __main__ INFO: \u001b[0mVal 370\n",
      "\u001b[32m[2020-06-22 19:57:22] __main__ INFO: \u001b[0mEpoch 370 loss 2.7028 acc@1 0.2868 acc@5 0.6924\n",
      "\u001b[32m[2020-06-22 19:57:22] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 19:57:22] __main__ INFO: \u001b[0mTrain 371 129870\n",
      "\u001b[32m[2020-06-22 19:57:32] __main__ INFO: \u001b[0mEpoch 371 Step 100/351 lr 0.001000 loss 1.2123 (1.2399) acc@1 0.5234 (0.5245) acc@5 0.8359 (0.7596)\n",
      "\u001b[32m[2020-06-22 19:57:41] __main__ INFO: \u001b[0mEpoch 371 Step 200/351 lr 0.001000 loss 1.4177 (1.2393) acc@1 0.4375 (0.5260) acc@5 0.7500 (0.7609)\n",
      "\u001b[32m[2020-06-22 19:57:50] __main__ INFO: \u001b[0mEpoch 371 Step 300/351 lr 0.001000 loss 1.1206 (1.2424) acc@1 0.5625 (0.5244) acc@5 0.8438 (0.7598)\n",
      "\u001b[32m[2020-06-22 19:57:55] __main__ INFO: \u001b[0mEpoch 371 Step 351/351 lr 0.001000 loss 0.9850 (1.2413) acc@1 0.6172 (0.5247) acc@5 0.7500 (0.7603)\n",
      "\u001b[32m[2020-06-22 19:57:55] __main__ INFO: \u001b[0mElapsed 32.84\n",
      "\u001b[32m[2020-06-22 19:57:55] __main__ INFO: \u001b[0mVal 371\n",
      "\u001b[32m[2020-06-22 19:57:56] __main__ INFO: \u001b[0mEpoch 371 loss 2.7486 acc@1 0.2836 acc@5 0.6992\n",
      "\u001b[32m[2020-06-22 19:57:56] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 19:57:56] __main__ INFO: \u001b[0mTrain 372 130221\n",
      "\u001b[32m[2020-06-22 19:58:05] __main__ INFO: \u001b[0mEpoch 372 Step 100/351 lr 0.001000 loss 1.3991 (1.2533) acc@1 0.4922 (0.5130) acc@5 0.7031 (0.7563)\n",
      "\u001b[32m[2020-06-22 19:58:15] __main__ INFO: \u001b[0mEpoch 372 Step 200/351 lr 0.001000 loss 1.3104 (1.2468) acc@1 0.5156 (0.5171) acc@5 0.7656 (0.7560)\n",
      "\u001b[32m[2020-06-22 19:58:24] __main__ INFO: \u001b[0mEpoch 372 Step 300/351 lr 0.001000 loss 1.3124 (1.2429) acc@1 0.4766 (0.5210) acc@5 0.7266 (0.7576)\n",
      "\u001b[32m[2020-06-22 19:58:29] __main__ INFO: \u001b[0mEpoch 372 Step 351/351 lr 0.001000 loss 1.2023 (1.2401) acc@1 0.5547 (0.5215) acc@5 0.8125 (0.7587)\n",
      "\u001b[32m[2020-06-22 19:58:29] __main__ INFO: \u001b[0mElapsed 32.75\n",
      "\u001b[32m[2020-06-22 19:58:29] __main__ INFO: \u001b[0mVal 372\n",
      "\u001b[32m[2020-06-22 19:58:30] __main__ INFO: \u001b[0mEpoch 372 loss 2.7354 acc@1 0.2812 acc@5 0.6936\n",
      "\u001b[32m[2020-06-22 19:58:30] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 19:58:30] __main__ INFO: \u001b[0mTrain 373 130572\n",
      "\u001b[32m[2020-06-22 19:58:39] __main__ INFO: \u001b[0mEpoch 373 Step 100/351 lr 0.001000 loss 1.1472 (1.2493) acc@1 0.5703 (0.5187) acc@5 0.7500 (0.7551)\n",
      "\u001b[32m[2020-06-22 19:58:49] __main__ INFO: \u001b[0mEpoch 373 Step 200/351 lr 0.001000 loss 1.2055 (1.2464) acc@1 0.5547 (0.5203) acc@5 0.7891 (0.7566)\n",
      "\u001b[32m[2020-06-22 19:58:58] __main__ INFO: \u001b[0mEpoch 373 Step 300/351 lr 0.001000 loss 1.2879 (1.2423) acc@1 0.5234 (0.5216) acc@5 0.7266 (0.7590)\n",
      "\u001b[32m[2020-06-22 19:59:03] __main__ INFO: \u001b[0mEpoch 373 Step 351/351 lr 0.001000 loss 1.2236 (1.2423) acc@1 0.5547 (0.5217) acc@5 0.8203 (0.7594)\n",
      "\u001b[32m[2020-06-22 19:59:03] __main__ INFO: \u001b[0mElapsed 32.88\n",
      "\u001b[32m[2020-06-22 19:59:03] __main__ INFO: \u001b[0mVal 373\n",
      "\u001b[32m[2020-06-22 19:59:04] __main__ INFO: \u001b[0mEpoch 373 loss 2.7183 acc@1 0.2910 acc@5 0.7010\n",
      "\u001b[32m[2020-06-22 19:59:04] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 19:59:04] __main__ INFO: \u001b[0mTrain 374 130923\n",
      "\u001b[32m[2020-06-22 19:59:13] __main__ INFO: \u001b[0mEpoch 374 Step 100/351 lr 0.001000 loss 1.0822 (1.2246) acc@1 0.5859 (0.5280) acc@5 0.7578 (0.7639)\n",
      "\u001b[32m[2020-06-22 19:59:22] __main__ INFO: \u001b[0mEpoch 374 Step 200/351 lr 0.001000 loss 1.3874 (1.2387) acc@1 0.4922 (0.5242) acc@5 0.6875 (0.7607)\n",
      "\u001b[32m[2020-06-22 19:59:32] __main__ INFO: \u001b[0mEpoch 374 Step 300/351 lr 0.001000 loss 1.3671 (1.2421) acc@1 0.4531 (0.5230) acc@5 0.6875 (0.7605)\n",
      "\u001b[32m[2020-06-22 19:59:37] __main__ INFO: \u001b[0mEpoch 374 Step 351/351 lr 0.001000 loss 1.1989 (1.2428) acc@1 0.5312 (0.5222) acc@5 0.7969 (0.7601)\n",
      "\u001b[32m[2020-06-22 19:59:37] __main__ INFO: \u001b[0mElapsed 32.86\n",
      "\u001b[32m[2020-06-22 19:59:37] __main__ INFO: \u001b[0mVal 374\n",
      "\u001b[32m[2020-06-22 19:59:38] __main__ INFO: \u001b[0mEpoch 374 loss 2.7287 acc@1 0.2794 acc@5 0.6968\n",
      "\u001b[32m[2020-06-22 19:59:38] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 19:59:38] __main__ INFO: \u001b[0mTrain 375 131274\n",
      "\u001b[32m[2020-06-22 19:59:47] __main__ INFO: \u001b[0mEpoch 375 Step 100/351 lr 0.001000 loss 1.2790 (1.2237) acc@1 0.5625 (0.5263) acc@5 0.7500 (0.7590)\n",
      "\u001b[32m[2020-06-22 19:59:56] __main__ INFO: \u001b[0mEpoch 375 Step 200/351 lr 0.001000 loss 1.1527 (1.2369) acc@1 0.5625 (0.5222) acc@5 0.7969 (0.7595)\n",
      "\u001b[32m[2020-06-22 20:00:06] __main__ INFO: \u001b[0mEpoch 375 Step 300/351 lr 0.001000 loss 1.2896 (1.2384) acc@1 0.4766 (0.5228) acc@5 0.7109 (0.7606)\n",
      "\u001b[32m[2020-06-22 20:00:11] __main__ INFO: \u001b[0mEpoch 375 Step 351/351 lr 0.001000 loss 1.2560 (1.2427) acc@1 0.5078 (0.5213) acc@5 0.7344 (0.7592)\n",
      "\u001b[32m[2020-06-22 20:00:11] __main__ INFO: \u001b[0mElapsed 32.96\n",
      "\u001b[32m[2020-06-22 20:00:11] __main__ INFO: \u001b[0mVal 375\n",
      "\u001b[32m[2020-06-22 20:00:12] __main__ INFO: \u001b[0mEpoch 375 loss 2.7808 acc@1 0.2860 acc@5 0.6964\n",
      "\u001b[32m[2020-06-22 20:00:12] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 20:00:12] __main__ INFO: \u001b[0mTrain 376 131625\n",
      "\u001b[32m[2020-06-22 20:00:21] __main__ INFO: \u001b[0mEpoch 376 Step 100/351 lr 0.001000 loss 1.1910 (1.2179) acc@1 0.5469 (0.5338) acc@5 0.7734 (0.7652)\n",
      "\u001b[32m[2020-06-22 20:00:30] __main__ INFO: \u001b[0mEpoch 376 Step 200/351 lr 0.001000 loss 1.3665 (1.2255) acc@1 0.4531 (0.5297) acc@5 0.7422 (0.7618)\n",
      "\u001b[32m[2020-06-22 20:00:40] __main__ INFO: \u001b[0mEpoch 376 Step 300/351 lr 0.001000 loss 1.0851 (1.2353) acc@1 0.6094 (0.5262) acc@5 0.8438 (0.7605)\n",
      "\u001b[32m[2020-06-22 20:00:45] __main__ INFO: \u001b[0mEpoch 376 Step 351/351 lr 0.001000 loss 1.1745 (1.2394) acc@1 0.5469 (0.5237) acc@5 0.7734 (0.7595)\n",
      "\u001b[32m[2020-06-22 20:00:45] __main__ INFO: \u001b[0mElapsed 32.87\n",
      "\u001b[32m[2020-06-22 20:00:45] __main__ INFO: \u001b[0mVal 376\n",
      "\u001b[32m[2020-06-22 20:00:46] __main__ INFO: \u001b[0mEpoch 376 loss 2.7471 acc@1 0.2844 acc@5 0.6980\n",
      "\u001b[32m[2020-06-22 20:00:46] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 20:00:46] __main__ INFO: \u001b[0mTrain 377 131976\n",
      "\u001b[32m[2020-06-22 20:00:55] __main__ INFO: \u001b[0mEpoch 377 Step 100/351 lr 0.001000 loss 1.1354 (1.2200) acc@1 0.5391 (0.5312) acc@5 0.7500 (0.7667)\n",
      "\u001b[32m[2020-06-22 20:01:04] __main__ INFO: \u001b[0mEpoch 377 Step 200/351 lr 0.001000 loss 1.0964 (1.2329) acc@1 0.5938 (0.5254) acc@5 0.7812 (0.7620)\n",
      "\u001b[32m[2020-06-22 20:01:14] __main__ INFO: \u001b[0mEpoch 377 Step 300/351 lr 0.001000 loss 1.1954 (1.2328) acc@1 0.5391 (0.5241) acc@5 0.7500 (0.7596)\n",
      "\u001b[32m[2020-06-22 20:01:18] __main__ INFO: \u001b[0mEpoch 377 Step 351/351 lr 0.001000 loss 1.2621 (1.2378) acc@1 0.5156 (0.5225) acc@5 0.7500 (0.7594)\n",
      "\u001b[32m[2020-06-22 20:01:18] __main__ INFO: \u001b[0mElapsed 32.81\n",
      "\u001b[32m[2020-06-22 20:01:18] __main__ INFO: \u001b[0mVal 377\n",
      "\u001b[32m[2020-06-22 20:01:19] __main__ INFO: \u001b[0mEpoch 377 loss 2.7894 acc@1 0.2818 acc@5 0.6844\n",
      "\u001b[32m[2020-06-22 20:01:19] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 20:01:19] __main__ INFO: \u001b[0mTrain 378 132327\n",
      "\u001b[32m[2020-06-22 20:01:29] __main__ INFO: \u001b[0mEpoch 378 Step 100/351 lr 0.001000 loss 1.2759 (1.2439) acc@1 0.4922 (0.5241) acc@5 0.7969 (0.7589)\n",
      "\u001b[32m[2020-06-22 20:01:38] __main__ INFO: \u001b[0mEpoch 378 Step 200/351 lr 0.001000 loss 1.3197 (1.2399) acc@1 0.4766 (0.5258) acc@5 0.7656 (0.7577)\n",
      "\u001b[32m[2020-06-22 20:01:47] __main__ INFO: \u001b[0mEpoch 378 Step 300/351 lr 0.001000 loss 1.3490 (1.2387) acc@1 0.4922 (0.5253) acc@5 0.7109 (0.7585)\n",
      "\u001b[32m[2020-06-22 20:01:52] __main__ INFO: \u001b[0mEpoch 378 Step 351/351 lr 0.001000 loss 1.2382 (1.2387) acc@1 0.5391 (0.5251) acc@5 0.7812 (0.7586)\n",
      "\u001b[32m[2020-06-22 20:01:52] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 20:01:52] __main__ INFO: \u001b[0mVal 378\n",
      "\u001b[32m[2020-06-22 20:01:53] __main__ INFO: \u001b[0mEpoch 378 loss 2.7657 acc@1 0.2800 acc@5 0.6854\n",
      "\u001b[32m[2020-06-22 20:01:53] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 20:01:53] __main__ INFO: \u001b[0mTrain 379 132678\n",
      "\u001b[32m[2020-06-22 20:02:03] __main__ INFO: \u001b[0mEpoch 379 Step 100/351 lr 0.001000 loss 1.2637 (1.2385) acc@1 0.4922 (0.5222) acc@5 0.7031 (0.7542)\n",
      "\u001b[32m[2020-06-22 20:02:12] __main__ INFO: \u001b[0mEpoch 379 Step 200/351 lr 0.001000 loss 1.2550 (1.2408) acc@1 0.4844 (0.5212) acc@5 0.7500 (0.7556)\n",
      "\u001b[32m[2020-06-22 20:02:21] __main__ INFO: \u001b[0mEpoch 379 Step 300/351 lr 0.001000 loss 1.1844 (1.2367) acc@1 0.5234 (0.5232) acc@5 0.7812 (0.7571)\n",
      "\u001b[32m[2020-06-22 20:02:26] __main__ INFO: \u001b[0mEpoch 379 Step 351/351 lr 0.001000 loss 1.2534 (1.2372) acc@1 0.5312 (0.5228) acc@5 0.7734 (0.7585)\n",
      "\u001b[32m[2020-06-22 20:02:26] __main__ INFO: \u001b[0mElapsed 32.76\n",
      "\u001b[32m[2020-06-22 20:02:26] __main__ INFO: \u001b[0mVal 379\n",
      "\u001b[32m[2020-06-22 20:02:27] __main__ INFO: \u001b[0mEpoch 379 loss 2.7994 acc@1 0.2732 acc@5 0.6928\n",
      "\u001b[32m[2020-06-22 20:02:27] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 20:02:27] __main__ INFO: \u001b[0mTrain 380 133029\n",
      "\u001b[32m[2020-06-22 20:02:37] __main__ INFO: \u001b[0mEpoch 380 Step 100/351 lr 0.001000 loss 1.2983 (1.2478) acc@1 0.5234 (0.5178) acc@5 0.7188 (0.7587)\n",
      "\u001b[32m[2020-06-22 20:02:46] __main__ INFO: \u001b[0mEpoch 380 Step 200/351 lr 0.001000 loss 1.0832 (1.2452) acc@1 0.6016 (0.5220) acc@5 0.7812 (0.7586)\n",
      "\u001b[32m[2020-06-22 20:02:55] __main__ INFO: \u001b[0mEpoch 380 Step 300/351 lr 0.001000 loss 1.3277 (1.2452) acc@1 0.4844 (0.5212) acc@5 0.7891 (0.7577)\n",
      "\u001b[32m[2020-06-22 20:03:00] __main__ INFO: \u001b[0mEpoch 380 Step 351/351 lr 0.001000 loss 1.0824 (1.2406) acc@1 0.5625 (0.5223) acc@5 0.7891 (0.7584)\n",
      "\u001b[32m[2020-06-22 20:03:00] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 20:03:00] __main__ INFO: \u001b[0mVal 380\n",
      "\u001b[32m[2020-06-22 20:03:01] __main__ INFO: \u001b[0mEpoch 380 loss 2.7431 acc@1 0.2738 acc@5 0.6970\n",
      "\u001b[32m[2020-06-22 20:03:01] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 20:03:01] __main__ INFO: \u001b[0mTrain 381 133380\n",
      "\u001b[32m[2020-06-22 20:03:10] __main__ INFO: \u001b[0mEpoch 381 Step 100/351 lr 0.001000 loss 1.3168 (1.2349) acc@1 0.4922 (0.5271) acc@5 0.7500 (0.7605)\n",
      "\u001b[32m[2020-06-22 20:03:20] __main__ INFO: \u001b[0mEpoch 381 Step 200/351 lr 0.001000 loss 1.3344 (1.2387) acc@1 0.4844 (0.5235) acc@5 0.6875 (0.7595)\n",
      "\u001b[32m[2020-06-22 20:03:29] __main__ INFO: \u001b[0mEpoch 381 Step 300/351 lr 0.001000 loss 1.3187 (1.2409) acc@1 0.4922 (0.5222) acc@5 0.7344 (0.7588)\n",
      "\u001b[32m[2020-06-22 20:03:34] __main__ INFO: \u001b[0mEpoch 381 Step 351/351 lr 0.001000 loss 1.2262 (1.2398) acc@1 0.5391 (0.5223) acc@5 0.7812 (0.7598)\n",
      "\u001b[32m[2020-06-22 20:03:34] __main__ INFO: \u001b[0mElapsed 32.84\n",
      "\u001b[32m[2020-06-22 20:03:34] __main__ INFO: \u001b[0mVal 381\n",
      "\u001b[32m[2020-06-22 20:03:35] __main__ INFO: \u001b[0mEpoch 381 loss 2.7084 acc@1 0.2732 acc@5 0.6974\n",
      "\u001b[32m[2020-06-22 20:03:35] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 20:03:35] __main__ INFO: \u001b[0mTrain 382 133731\n",
      "\u001b[32m[2020-06-22 20:03:44] __main__ INFO: \u001b[0mEpoch 382 Step 100/351 lr 0.001000 loss 1.2638 (1.2459) acc@1 0.5000 (0.5240) acc@5 0.6797 (0.7637)\n",
      "\u001b[32m[2020-06-22 20:03:54] __main__ INFO: \u001b[0mEpoch 382 Step 200/351 lr 0.001000 loss 1.1895 (1.2395) acc@1 0.5234 (0.5243) acc@5 0.7500 (0.7622)\n",
      "\u001b[32m[2020-06-22 20:04:03] __main__ INFO: \u001b[0mEpoch 382 Step 300/351 lr 0.001000 loss 1.1707 (1.2386) acc@1 0.5469 (0.5232) acc@5 0.8203 (0.7591)\n",
      "\u001b[32m[2020-06-22 20:04:08] __main__ INFO: \u001b[0mEpoch 382 Step 351/351 lr 0.001000 loss 1.1380 (1.2414) acc@1 0.5469 (0.5222) acc@5 0.7734 (0.7578)\n",
      "\u001b[32m[2020-06-22 20:04:08] __main__ INFO: \u001b[0mElapsed 32.84\n",
      "\u001b[32m[2020-06-22 20:04:08] __main__ INFO: \u001b[0mVal 382\n",
      "\u001b[32m[2020-06-22 20:04:09] __main__ INFO: \u001b[0mEpoch 382 loss 2.7765 acc@1 0.2826 acc@5 0.6968\n",
      "\u001b[32m[2020-06-22 20:04:09] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 20:04:09] __main__ INFO: \u001b[0mTrain 383 134082\n",
      "\u001b[32m[2020-06-22 20:04:18] __main__ INFO: \u001b[0mEpoch 383 Step 100/351 lr 0.001000 loss 1.1078 (1.2340) acc@1 0.5547 (0.5269) acc@5 0.7500 (0.7597)\n",
      "\u001b[32m[2020-06-22 20:04:28] __main__ INFO: \u001b[0mEpoch 383 Step 200/351 lr 0.001000 loss 1.2111 (1.2324) acc@1 0.5547 (0.5270) acc@5 0.7266 (0.7602)\n",
      "\u001b[32m[2020-06-22 20:04:37] __main__ INFO: \u001b[0mEpoch 383 Step 300/351 lr 0.001000 loss 1.0888 (1.2363) acc@1 0.5625 (0.5253) acc@5 0.7812 (0.7610)\n",
      "\u001b[32m[2020-06-22 20:04:42] __main__ INFO: \u001b[0mEpoch 383 Step 351/351 lr 0.001000 loss 1.1235 (1.2378) acc@1 0.5312 (0.5240) acc@5 0.7578 (0.7601)\n",
      "\u001b[32m[2020-06-22 20:04:42] __main__ INFO: \u001b[0mElapsed 32.81\n",
      "\u001b[32m[2020-06-22 20:04:42] __main__ INFO: \u001b[0mVal 383\n",
      "\u001b[32m[2020-06-22 20:04:43] __main__ INFO: \u001b[0mEpoch 383 loss 2.7478 acc@1 0.2760 acc@5 0.6876\n",
      "\u001b[32m[2020-06-22 20:04:43] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 20:04:43] __main__ INFO: \u001b[0mTrain 384 134433\n",
      "\u001b[32m[2020-06-22 20:04:52] __main__ INFO: \u001b[0mEpoch 384 Step 100/351 lr 0.001000 loss 1.0650 (1.2375) acc@1 0.5859 (0.5220) acc@5 0.7500 (0.7582)\n",
      "\u001b[32m[2020-06-22 20:05:01] __main__ INFO: \u001b[0mEpoch 384 Step 200/351 lr 0.001000 loss 1.1825 (1.2429) acc@1 0.5234 (0.5206) acc@5 0.8203 (0.7557)\n",
      "\u001b[32m[2020-06-22 20:05:11] __main__ INFO: \u001b[0mEpoch 384 Step 300/351 lr 0.001000 loss 1.3152 (1.2431) acc@1 0.5000 (0.5215) acc@5 0.7422 (0.7570)\n",
      "\u001b[32m[2020-06-22 20:05:15] __main__ INFO: \u001b[0mEpoch 384 Step 351/351 lr 0.001000 loss 1.1347 (1.2408) acc@1 0.5938 (0.5226) acc@5 0.7734 (0.7577)\n",
      "\u001b[32m[2020-06-22 20:05:15] __main__ INFO: \u001b[0mElapsed 32.84\n",
      "\u001b[32m[2020-06-22 20:05:15] __main__ INFO: \u001b[0mVal 384\n",
      "\u001b[32m[2020-06-22 20:05:17] __main__ INFO: \u001b[0mEpoch 384 loss 2.7579 acc@1 0.2840 acc@5 0.6876\n",
      "\u001b[32m[2020-06-22 20:05:17] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 20:05:17] __main__ INFO: \u001b[0mTrain 385 134784\n",
      "\u001b[32m[2020-06-22 20:05:26] __main__ INFO: \u001b[0mEpoch 385 Step 100/351 lr 0.001000 loss 1.2226 (1.2200) acc@1 0.5703 (0.5299) acc@5 0.7969 (0.7627)\n",
      "\u001b[32m[2020-06-22 20:05:35] __main__ INFO: \u001b[0mEpoch 385 Step 200/351 lr 0.001000 loss 1.3268 (1.2309) acc@1 0.4844 (0.5248) acc@5 0.7578 (0.7589)\n",
      "\u001b[32m[2020-06-22 20:05:45] __main__ INFO: \u001b[0mEpoch 385 Step 300/351 lr 0.001000 loss 1.2635 (1.2354) acc@1 0.4922 (0.5231) acc@5 0.7344 (0.7580)\n",
      "\u001b[32m[2020-06-22 20:05:49] __main__ INFO: \u001b[0mEpoch 385 Step 351/351 lr 0.001000 loss 1.2317 (1.2383) acc@1 0.5469 (0.5222) acc@5 0.7891 (0.7567)\n",
      "\u001b[32m[2020-06-22 20:05:49] __main__ INFO: \u001b[0mElapsed 32.81\n",
      "\u001b[32m[2020-06-22 20:05:49] __main__ INFO: \u001b[0mVal 385\n",
      "\u001b[32m[2020-06-22 20:05:50] __main__ INFO: \u001b[0mEpoch 385 loss 2.8168 acc@1 0.2862 acc@5 0.6906\n",
      "\u001b[32m[2020-06-22 20:05:50] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 20:05:50] __main__ INFO: \u001b[0mTrain 386 135135\n",
      "\u001b[32m[2020-06-22 20:06:00] __main__ INFO: \u001b[0mEpoch 386 Step 100/351 lr 0.001000 loss 1.3129 (1.2302) acc@1 0.4922 (0.5274) acc@5 0.7734 (0.7623)\n",
      "\u001b[32m[2020-06-22 20:06:09] __main__ INFO: \u001b[0mEpoch 386 Step 200/351 lr 0.001000 loss 1.3687 (1.2356) acc@1 0.4531 (0.5230) acc@5 0.7656 (0.7612)\n",
      "\u001b[32m[2020-06-22 20:06:18] __main__ INFO: \u001b[0mEpoch 386 Step 300/351 lr 0.001000 loss 1.2149 (1.2368) acc@1 0.5547 (0.5218) acc@5 0.7891 (0.7595)\n",
      "\u001b[32m[2020-06-22 20:06:23] __main__ INFO: \u001b[0mEpoch 386 Step 351/351 lr 0.001000 loss 1.2640 (1.2378) acc@1 0.5312 (0.5221) acc@5 0.7500 (0.7589)\n",
      "\u001b[32m[2020-06-22 20:06:23] __main__ INFO: \u001b[0mElapsed 32.81\n",
      "\u001b[32m[2020-06-22 20:06:23] __main__ INFO: \u001b[0mVal 386\n",
      "\u001b[32m[2020-06-22 20:06:24] __main__ INFO: \u001b[0mEpoch 386 loss 2.7476 acc@1 0.2870 acc@5 0.6960\n",
      "\u001b[32m[2020-06-22 20:06:24] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 20:06:24] __main__ INFO: \u001b[0mTrain 387 135486\n",
      "\u001b[32m[2020-06-22 20:06:34] __main__ INFO: \u001b[0mEpoch 387 Step 100/351 lr 0.001000 loss 1.0767 (1.2379) acc@1 0.5625 (0.5232) acc@5 0.7656 (0.7581)\n",
      "\u001b[32m[2020-06-22 20:06:43] __main__ INFO: \u001b[0mEpoch 387 Step 200/351 lr 0.001000 loss 1.2542 (1.2338) acc@1 0.5000 (0.5241) acc@5 0.7109 (0.7599)\n",
      "\u001b[32m[2020-06-22 20:06:52] __main__ INFO: \u001b[0mEpoch 387 Step 300/351 lr 0.001000 loss 1.2291 (1.2318) acc@1 0.5000 (0.5248) acc@5 0.7500 (0.7600)\n",
      "\u001b[32m[2020-06-22 20:06:57] __main__ INFO: \u001b[0mEpoch 387 Step 351/351 lr 0.001000 loss 1.3223 (1.2365) acc@1 0.4844 (0.5235) acc@5 0.7578 (0.7582)\n",
      "\u001b[32m[2020-06-22 20:06:57] __main__ INFO: \u001b[0mElapsed 32.88\n",
      "\u001b[32m[2020-06-22 20:06:57] __main__ INFO: \u001b[0mVal 387\n",
      "\u001b[32m[2020-06-22 20:06:58] __main__ INFO: \u001b[0mEpoch 387 loss 2.7978 acc@1 0.2828 acc@5 0.6972\n",
      "\u001b[32m[2020-06-22 20:06:58] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 20:06:58] __main__ INFO: \u001b[0mTrain 388 135837\n",
      "\u001b[32m[2020-06-22 20:07:08] __main__ INFO: \u001b[0mEpoch 388 Step 100/351 lr 0.001000 loss 1.3621 (1.2403) acc@1 0.4688 (0.5224) acc@5 0.7500 (0.7580)\n",
      "\u001b[32m[2020-06-22 20:07:17] __main__ INFO: \u001b[0mEpoch 388 Step 200/351 lr 0.001000 loss 1.2381 (1.2370) acc@1 0.5234 (0.5243) acc@5 0.7969 (0.7603)\n",
      "\u001b[32m[2020-06-22 20:07:26] __main__ INFO: \u001b[0mEpoch 388 Step 300/351 lr 0.001000 loss 1.1606 (1.2346) acc@1 0.5469 (0.5252) acc@5 0.7578 (0.7610)\n",
      "\u001b[32m[2020-06-22 20:07:31] __main__ INFO: \u001b[0mEpoch 388 Step 351/351 lr 0.001000 loss 1.1823 (1.2355) acc@1 0.5234 (0.5245) acc@5 0.7500 (0.7601)\n",
      "\u001b[32m[2020-06-22 20:07:31] __main__ INFO: \u001b[0mElapsed 32.82\n",
      "\u001b[32m[2020-06-22 20:07:31] __main__ INFO: \u001b[0mVal 388\n",
      "\u001b[32m[2020-06-22 20:07:32] __main__ INFO: \u001b[0mEpoch 388 loss 2.8047 acc@1 0.2824 acc@5 0.6958\n",
      "\u001b[32m[2020-06-22 20:07:32] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 20:07:32] __main__ INFO: \u001b[0mTrain 389 136188\n",
      "\u001b[32m[2020-06-22 20:07:42] __main__ INFO: \u001b[0mEpoch 389 Step 100/351 lr 0.001000 loss 1.1592 (1.2260) acc@1 0.5625 (0.5269) acc@5 0.7891 (0.7573)\n",
      "\u001b[32m[2020-06-22 20:07:51] __main__ INFO: \u001b[0mEpoch 389 Step 200/351 lr 0.001000 loss 1.2481 (1.2309) acc@1 0.4766 (0.5252) acc@5 0.7422 (0.7558)\n",
      "\u001b[32m[2020-06-22 20:08:00] __main__ INFO: \u001b[0mEpoch 389 Step 300/351 lr 0.001000 loss 1.1665 (1.2322) acc@1 0.6016 (0.5262) acc@5 0.7734 (0.7559)\n",
      "\u001b[32m[2020-06-22 20:08:05] __main__ INFO: \u001b[0mEpoch 389 Step 351/351 lr 0.001000 loss 1.2428 (1.2357) acc@1 0.5391 (0.5244) acc@5 0.7578 (0.7559)\n",
      "\u001b[32m[2020-06-22 20:08:05] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 20:08:05] __main__ INFO: \u001b[0mVal 389\n",
      "\u001b[32m[2020-06-22 20:08:06] __main__ INFO: \u001b[0mEpoch 389 loss 2.7840 acc@1 0.2844 acc@5 0.6870\n",
      "\u001b[32m[2020-06-22 20:08:06] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 20:08:06] __main__ INFO: \u001b[0mTrain 390 136539\n",
      "\u001b[32m[2020-06-22 20:08:15] __main__ INFO: \u001b[0mEpoch 390 Step 100/351 lr 0.001000 loss 1.3053 (1.2343) acc@1 0.4844 (0.5293) acc@5 0.7500 (0.7636)\n",
      "\u001b[32m[2020-06-22 20:08:25] __main__ INFO: \u001b[0mEpoch 390 Step 200/351 lr 0.001000 loss 1.3984 (1.2320) acc@1 0.4688 (0.5284) acc@5 0.7969 (0.7619)\n",
      "\u001b[32m[2020-06-22 20:08:34] __main__ INFO: \u001b[0mEpoch 390 Step 300/351 lr 0.001000 loss 1.1752 (1.2343) acc@1 0.5625 (0.5262) acc@5 0.8047 (0.7600)\n",
      "\u001b[32m[2020-06-22 20:08:39] __main__ INFO: \u001b[0mEpoch 390 Step 351/351 lr 0.001000 loss 1.2429 (1.2340) acc@1 0.5391 (0.5263) acc@5 0.7734 (0.7603)\n",
      "\u001b[32m[2020-06-22 20:08:39] __main__ INFO: \u001b[0mElapsed 32.80\n",
      "\u001b[32m[2020-06-22 20:08:39] __main__ INFO: \u001b[0mVal 390\n",
      "\u001b[32m[2020-06-22 20:08:40] __main__ INFO: \u001b[0mEpoch 390 loss 2.7973 acc@1 0.2836 acc@5 0.7000\n",
      "\u001b[32m[2020-06-22 20:08:40] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 20:08:40] __main__ INFO: \u001b[0mTrain 391 136890\n",
      "\u001b[32m[2020-06-22 20:08:49] __main__ INFO: \u001b[0mEpoch 391 Step 100/351 lr 0.001000 loss 1.2179 (1.2357) acc@1 0.5000 (0.5202) acc@5 0.7344 (0.7554)\n",
      "\u001b[32m[2020-06-22 20:08:58] __main__ INFO: \u001b[0mEpoch 391 Step 200/351 lr 0.001000 loss 1.1306 (1.2343) acc@1 0.5547 (0.5218) acc@5 0.7969 (0.7606)\n",
      "\u001b[32m[2020-06-22 20:09:08] __main__ INFO: \u001b[0mEpoch 391 Step 300/351 lr 0.001000 loss 1.2576 (1.2364) acc@1 0.4922 (0.5205) acc@5 0.7031 (0.7590)\n",
      "\u001b[32m[2020-06-22 20:09:13] __main__ INFO: \u001b[0mEpoch 391 Step 351/351 lr 0.001000 loss 1.3930 (1.2367) acc@1 0.5000 (0.5207) acc@5 0.7031 (0.7589)\n",
      "\u001b[32m[2020-06-22 20:09:13] __main__ INFO: \u001b[0mElapsed 32.76\n",
      "\u001b[32m[2020-06-22 20:09:13] __main__ INFO: \u001b[0mVal 391\n",
      "\u001b[32m[2020-06-22 20:09:14] __main__ INFO: \u001b[0mEpoch 391 loss 2.7937 acc@1 0.2750 acc@5 0.6928\n",
      "\u001b[32m[2020-06-22 20:09:14] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 20:09:14] __main__ INFO: \u001b[0mTrain 392 137241\n",
      "\u001b[32m[2020-06-22 20:09:23] __main__ INFO: \u001b[0mEpoch 392 Step 100/351 lr 0.001000 loss 1.1801 (1.2375) acc@1 0.5547 (0.5241) acc@5 0.7344 (0.7646)\n",
      "\u001b[32m[2020-06-22 20:09:32] __main__ INFO: \u001b[0mEpoch 392 Step 200/351 lr 0.001000 loss 1.1988 (1.2373) acc@1 0.5312 (0.5229) acc@5 0.7656 (0.7611)\n",
      "\u001b[32m[2020-06-22 20:09:42] __main__ INFO: \u001b[0mEpoch 392 Step 300/351 lr 0.001000 loss 1.3550 (1.2339) acc@1 0.5000 (0.5239) acc@5 0.7422 (0.7604)\n",
      "\u001b[32m[2020-06-22 20:09:46] __main__ INFO: \u001b[0mEpoch 392 Step 351/351 lr 0.001000 loss 1.3517 (1.2369) acc@1 0.4609 (0.5220) acc@5 0.7266 (0.7583)\n",
      "\u001b[32m[2020-06-22 20:09:46] __main__ INFO: \u001b[0mElapsed 32.79\n",
      "\u001b[32m[2020-06-22 20:09:46] __main__ INFO: \u001b[0mVal 392\n",
      "\u001b[32m[2020-06-22 20:09:47] __main__ INFO: \u001b[0mEpoch 392 loss 2.7726 acc@1 0.2836 acc@5 0.6874\n",
      "\u001b[32m[2020-06-22 20:09:47] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 20:09:47] __main__ INFO: \u001b[0mTrain 393 137592\n",
      "\u001b[32m[2020-06-22 20:09:57] __main__ INFO: \u001b[0mEpoch 393 Step 100/351 lr 0.001000 loss 1.1276 (1.2338) acc@1 0.5859 (0.5241) acc@5 0.7891 (0.7533)\n",
      "\u001b[32m[2020-06-22 20:10:06] __main__ INFO: \u001b[0mEpoch 393 Step 200/351 lr 0.001000 loss 1.0956 (1.2298) acc@1 0.5703 (0.5252) acc@5 0.7734 (0.7589)\n",
      "\u001b[32m[2020-06-22 20:10:15] __main__ INFO: \u001b[0mEpoch 393 Step 300/351 lr 0.001000 loss 1.2522 (1.2329) acc@1 0.5703 (0.5245) acc@5 0.7422 (0.7600)\n",
      "\u001b[32m[2020-06-22 20:10:20] __main__ INFO: \u001b[0mEpoch 393 Step 351/351 lr 0.001000 loss 1.2209 (1.2345) acc@1 0.5234 (0.5247) acc@5 0.7422 (0.7594)\n",
      "\u001b[32m[2020-06-22 20:10:20] __main__ INFO: \u001b[0mElapsed 32.78\n",
      "\u001b[32m[2020-06-22 20:10:20] __main__ INFO: \u001b[0mVal 393\n",
      "\u001b[32m[2020-06-22 20:10:21] __main__ INFO: \u001b[0mEpoch 393 loss 2.7943 acc@1 0.2842 acc@5 0.6960\n",
      "\u001b[32m[2020-06-22 20:10:21] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 20:10:21] __main__ INFO: \u001b[0mTrain 394 137943\n",
      "\u001b[32m[2020-06-22 20:10:31] __main__ INFO: \u001b[0mEpoch 394 Step 100/351 lr 0.001000 loss 1.1216 (1.2395) acc@1 0.5547 (0.5246) acc@5 0.8125 (0.7550)\n",
      "\u001b[32m[2020-06-22 20:10:40] __main__ INFO: \u001b[0mEpoch 394 Step 200/351 lr 0.001000 loss 1.1976 (1.2267) acc@1 0.5234 (0.5298) acc@5 0.7500 (0.7596)\n",
      "\u001b[32m[2020-06-22 20:10:49] __main__ INFO: \u001b[0mEpoch 394 Step 300/351 lr 0.001000 loss 1.2278 (1.2313) acc@1 0.5312 (0.5265) acc@5 0.7578 (0.7614)\n",
      "\u001b[32m[2020-06-22 20:10:54] __main__ INFO: \u001b[0mEpoch 394 Step 351/351 lr 0.001000 loss 1.2854 (1.2330) acc@1 0.4844 (0.5257) acc@5 0.7969 (0.7602)\n",
      "\u001b[32m[2020-06-22 20:10:54] __main__ INFO: \u001b[0mElapsed 32.81\n",
      "\u001b[32m[2020-06-22 20:10:54] __main__ INFO: \u001b[0mVal 394\n",
      "\u001b[32m[2020-06-22 20:10:55] __main__ INFO: \u001b[0mEpoch 394 loss 2.8169 acc@1 0.2730 acc@5 0.6852\n",
      "\u001b[32m[2020-06-22 20:10:55] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 20:10:55] __main__ INFO: \u001b[0mTrain 395 138294\n",
      "\u001b[32m[2020-06-22 20:11:05] __main__ INFO: \u001b[0mEpoch 395 Step 100/351 lr 0.001000 loss 1.4125 (1.2302) acc@1 0.4141 (0.5248) acc@5 0.7344 (0.7574)\n",
      "\u001b[32m[2020-06-22 20:11:14] __main__ INFO: \u001b[0mEpoch 395 Step 200/351 lr 0.001000 loss 1.2271 (1.2385) acc@1 0.5156 (0.5211) acc@5 0.7734 (0.7564)\n",
      "\u001b[32m[2020-06-22 20:11:23] __main__ INFO: \u001b[0mEpoch 395 Step 300/351 lr 0.001000 loss 1.2292 (1.2377) acc@1 0.5000 (0.5227) acc@5 0.8125 (0.7584)\n",
      "\u001b[32m[2020-06-22 20:11:28] __main__ INFO: \u001b[0mEpoch 395 Step 351/351 lr 0.001000 loss 1.2764 (1.2342) acc@1 0.4766 (0.5238) acc@5 0.7500 (0.7599)\n",
      "\u001b[32m[2020-06-22 20:11:28] __main__ INFO: \u001b[0mElapsed 32.81\n",
      "\u001b[32m[2020-06-22 20:11:28] __main__ INFO: \u001b[0mVal 395\n",
      "\u001b[32m[2020-06-22 20:11:29] __main__ INFO: \u001b[0mEpoch 395 loss 2.8065 acc@1 0.2814 acc@5 0.6770\n",
      "\u001b[32m[2020-06-22 20:11:29] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 20:11:29] __main__ INFO: \u001b[0mTrain 396 138645\n",
      "\u001b[32m[2020-06-22 20:11:38] __main__ INFO: \u001b[0mEpoch 396 Step 100/351 lr 0.001000 loss 1.2102 (1.2399) acc@1 0.5547 (0.5241) acc@5 0.7344 (0.7516)\n",
      "\u001b[32m[2020-06-22 20:11:48] __main__ INFO: \u001b[0mEpoch 396 Step 200/351 lr 0.001000 loss 1.1223 (1.2361) acc@1 0.5781 (0.5258) acc@5 0.7656 (0.7545)\n",
      "\u001b[32m[2020-06-22 20:11:57] __main__ INFO: \u001b[0mEpoch 396 Step 300/351 lr 0.001000 loss 1.1942 (1.2328) acc@1 0.5391 (0.5257) acc@5 0.7500 (0.7574)\n",
      "\u001b[32m[2020-06-22 20:12:02] __main__ INFO: \u001b[0mEpoch 396 Step 351/351 lr 0.001000 loss 1.0119 (1.2351) acc@1 0.6250 (0.5249) acc@5 0.8359 (0.7577)\n",
      "\u001b[32m[2020-06-22 20:12:02] __main__ INFO: \u001b[0mElapsed 32.86\n",
      "\u001b[32m[2020-06-22 20:12:02] __main__ INFO: \u001b[0mVal 396\n",
      "\u001b[32m[2020-06-22 20:12:03] __main__ INFO: \u001b[0mEpoch 396 loss 2.7923 acc@1 0.2770 acc@5 0.6906\n",
      "\u001b[32m[2020-06-22 20:12:03] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 20:12:03] __main__ INFO: \u001b[0mTrain 397 138996\n",
      "\u001b[32m[2020-06-22 20:12:12] __main__ INFO: \u001b[0mEpoch 397 Step 100/351 lr 0.001000 loss 1.3947 (1.2357) acc@1 0.5000 (0.5260) acc@5 0.6875 (0.7565)\n",
      "\u001b[32m[2020-06-22 20:12:22] __main__ INFO: \u001b[0mEpoch 397 Step 200/351 lr 0.001000 loss 1.2251 (1.2404) acc@1 0.5391 (0.5237) acc@5 0.7500 (0.7574)\n",
      "\u001b[32m[2020-06-22 20:12:31] __main__ INFO: \u001b[0mEpoch 397 Step 300/351 lr 0.001000 loss 1.1775 (1.2398) acc@1 0.5312 (0.5225) acc@5 0.7578 (0.7574)\n",
      "\u001b[32m[2020-06-22 20:12:36] __main__ INFO: \u001b[0mEpoch 397 Step 351/351 lr 0.001000 loss 1.2474 (1.2374) acc@1 0.5234 (0.5236) acc@5 0.7188 (0.7588)\n",
      "\u001b[32m[2020-06-22 20:12:36] __main__ INFO: \u001b[0mElapsed 32.83\n",
      "\u001b[32m[2020-06-22 20:12:36] __main__ INFO: \u001b[0mVal 397\n",
      "\u001b[32m[2020-06-22 20:12:37] __main__ INFO: \u001b[0mEpoch 397 loss 2.7923 acc@1 0.2804 acc@5 0.6986\n",
      "\u001b[32m[2020-06-22 20:12:37] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 20:12:37] __main__ INFO: \u001b[0mTrain 398 139347\n",
      "\u001b[32m[2020-06-22 20:12:46] __main__ INFO: \u001b[0mEpoch 398 Step 100/351 lr 0.001000 loss 1.2532 (1.2333) acc@1 0.5312 (0.5230) acc@5 0.7656 (0.7606)\n",
      "\u001b[32m[2020-06-22 20:12:56] __main__ INFO: \u001b[0mEpoch 398 Step 200/351 lr 0.001000 loss 1.3364 (1.2351) acc@1 0.4609 (0.5220) acc@5 0.7344 (0.7604)\n",
      "\u001b[32m[2020-06-22 20:13:05] __main__ INFO: \u001b[0mEpoch 398 Step 300/351 lr 0.001000 loss 1.3039 (1.2319) acc@1 0.4766 (0.5240) acc@5 0.7344 (0.7602)\n",
      "\u001b[32m[2020-06-22 20:13:10] __main__ INFO: \u001b[0mEpoch 398 Step 351/351 lr 0.001000 loss 1.2331 (1.2323) acc@1 0.5000 (0.5243) acc@5 0.7578 (0.7599)\n",
      "\u001b[32m[2020-06-22 20:13:10] __main__ INFO: \u001b[0mElapsed 32.75\n",
      "\u001b[32m[2020-06-22 20:13:10] __main__ INFO: \u001b[0mVal 398\n",
      "\u001b[32m[2020-06-22 20:13:11] __main__ INFO: \u001b[0mEpoch 398 loss 2.8509 acc@1 0.2808 acc@5 0.6898\n",
      "\u001b[32m[2020-06-22 20:13:11] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 20:13:11] __main__ INFO: \u001b[0mTrain 399 139698\n",
      "\u001b[32m[2020-06-22 20:13:20] __main__ INFO: \u001b[0mEpoch 399 Step 100/351 lr 0.001000 loss 1.1129 (1.2470) acc@1 0.5703 (0.5212) acc@5 0.7969 (0.7523)\n",
      "\u001b[32m[2020-06-22 20:13:29] __main__ INFO: \u001b[0mEpoch 399 Step 200/351 lr 0.001000 loss 1.2988 (1.2348) acc@1 0.4922 (0.5239) acc@5 0.6641 (0.7544)\n",
      "\u001b[32m[2020-06-22 20:13:39] __main__ INFO: \u001b[0mEpoch 399 Step 300/351 lr 0.001000 loss 1.2704 (1.2332) acc@1 0.5000 (0.5243) acc@5 0.8203 (0.7563)\n",
      "\u001b[32m[2020-06-22 20:13:43] __main__ INFO: \u001b[0mEpoch 399 Step 351/351 lr 0.001000 loss 1.3466 (1.2324) acc@1 0.4766 (0.5244) acc@5 0.7500 (0.7578)\n",
      "\u001b[32m[2020-06-22 20:13:44] __main__ INFO: \u001b[0mElapsed 32.83\n",
      "\u001b[32m[2020-06-22 20:13:44] __main__ INFO: \u001b[0mVal 399\n",
      "\u001b[32m[2020-06-22 20:13:45] __main__ INFO: \u001b[0mEpoch 399 loss 2.8154 acc@1 0.2830 acc@5 0.6954\n",
      "\u001b[32m[2020-06-22 20:13:45] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 20:13:45] __main__ INFO: \u001b[0mTrain 400 140049\n",
      "\u001b[32m[2020-06-22 20:13:54] __main__ INFO: \u001b[0mEpoch 400 Step 100/351 lr 0.001000 loss 1.1724 (1.2275) acc@1 0.5469 (0.5299) acc@5 0.8047 (0.7624)\n",
      "\u001b[32m[2020-06-22 20:14:03] __main__ INFO: \u001b[0mEpoch 400 Step 200/351 lr 0.001000 loss 1.1932 (1.2312) acc@1 0.5547 (0.5255) acc@5 0.7891 (0.7573)\n",
      "\u001b[32m[2020-06-22 20:14:13] __main__ INFO: \u001b[0mEpoch 400 Step 300/351 lr 0.001000 loss 1.2014 (1.2334) acc@1 0.5469 (0.5255) acc@5 0.7812 (0.7591)\n",
      "\u001b[32m[2020-06-22 20:14:17] __main__ INFO: \u001b[0mEpoch 400 Step 351/351 lr 0.001000 loss 1.3041 (1.2336) acc@1 0.5078 (0.5258) acc@5 0.7891 (0.7586)\n",
      "\u001b[32m[2020-06-22 20:14:17] __main__ INFO: \u001b[0mElapsed 32.81\n",
      "\u001b[32m[2020-06-22 20:14:17] __main__ INFO: \u001b[0mVal 400\n",
      "\u001b[32m[2020-06-22 20:14:18] __main__ INFO: \u001b[0mEpoch 400 loss 2.8119 acc@1 0.2818 acc@5 0.6930\n",
      "\u001b[32m[2020-06-22 20:14:18] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 20:14:18] fvcore.common.checkpoint INFO: \u001b[0mSaving checkpoint to /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00/checkpoint_00400.pth\n"
     ]
    }
   ],
   "source": [
    "# Train the model per the settings specified in the original paper\n",
    "os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "!python train.py --config configs/cifar/resnet.yaml \\\n",
    "    model.resnet.depth 32 \\\n",
    "    train.batch_size 128 \\\n",
    "    dataset.name CIFAR10_RA_3_20 \\\n",
    "    train.base_lr 0.1 \\\n",
    "    train.output_dir /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00 \\\n",
    "    scheduler.epochs 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-06-22 21:02:32] __main__ INFO: \u001b[0mdevice: cuda\n",
      "cudnn:\n",
      "  benchmark: True\n",
      "  deterministic: False\n",
      "dataset:\n",
      "  name: CIFAR10\n",
      "  dataset_dir: ~/.torch/datasets/CIFAR10\n",
      "  image_size: 32\n",
      "  n_channels: 3\n",
      "  n_classes: 10\n",
      "model:\n",
      "  type: cifar\n",
      "  name: resnet\n",
      "  init_mode: kaiming_fan_out\n",
      "  vgg:\n",
      "    n_channels: [64, 128, 256, 512, 512]\n",
      "    n_layers: [2, 2, 3, 3, 3]\n",
      "    use_bn: True\n",
      "  resnet:\n",
      "    depth: 32\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "  resnet_preact:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "  wrn:\n",
      "    depth: 28\n",
      "    initial_channels: 16\n",
      "    widening_factor: 10\n",
      "    drop_rate: 0.0\n",
      "  densenet:\n",
      "    depth: 100\n",
      "    n_blocks: [6, 12, 24, 16]\n",
      "    block_type: bottleneck\n",
      "    growth_rate: 12\n",
      "    drop_rate: 0.0\n",
      "    compression_rate: 0.5\n",
      "  pyramidnet:\n",
      "    depth: 272\n",
      "    n_blocks: [3, 24, 36, 3]\n",
      "    initial_channels: 16\n",
      "    block_type: bottleneck\n",
      "    alpha: 200\n",
      "  resnext:\n",
      "    depth: 29\n",
      "    n_blocks: [3, 4, 6, 3]\n",
      "    initial_channels: 64\n",
      "    cardinality: 8\n",
      "    base_channels: 4\n",
      "  shake_shake:\n",
      "    depth: 26\n",
      "    initial_channels: 96\n",
      "    shake_forward: True\n",
      "    shake_backward: True\n",
      "    shake_image: True\n",
      "  se_resnet_preact:\n",
      "    depth: 110\n",
      "    initial_channels: 16\n",
      "    se_reduction: 16\n",
      "    block_type: basic\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "train:\n",
      "  checkpoint: /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00/checkpoint_00400.pth\n",
      "  resume: False\n",
      "  precision: O0\n",
      "  batch_size: 128\n",
      "  subdivision: 1\n",
      "  optimizer: sgd\n",
      "  base_lr: 0.001\n",
      "  momentum: 0.9\n",
      "  nesterov: True\n",
      "  weight_decay: 0.0001\n",
      "  no_weight_decay_on_bn: False\n",
      "  gradient_clip: 0\n",
      "  start_epoch: 0\n",
      "  seed: 0\n",
      "  val_first: True\n",
      "  val_period: 1\n",
      "  val_ratio: 0.1\n",
      "  use_test_as_val: False\n",
      "  output_dir: /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00_resume400_50\n",
      "  log_period: 100\n",
      "  checkpoint_period: 100\n",
      "  use_tensorboard: True\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: True\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "  distributed: False\n",
      "  dist:\n",
      "    backend: nccl\n",
      "    init_method: env://\n",
      "    world_size: -1\n",
      "    node_rank: -1\n",
      "    local_rank: 0\n",
      "    use_sync_bn: False\n",
      "tensorboard:\n",
      "  train_images: False\n",
      "  val_images: False\n",
      "  model_params: False\n",
      "optim:\n",
      "  adam:\n",
      "    betas: (0.9, 0.999)\n",
      "  lars:\n",
      "    eps: 1e-09\n",
      "    threshold: 0.01\n",
      "  adabound:\n",
      "    betas: (0.9, 0.999)\n",
      "    final_lr: 0.1\n",
      "    gamma: 0.001\n",
      "scheduler:\n",
      "  epochs: 50\n",
      "  warmup:\n",
      "    type: none\n",
      "    epochs: 0\n",
      "    start_factor: 0.001\n",
      "    exponent: 4\n",
      "  type: multistep\n",
      "  milestones: [80, 120]\n",
      "  lr_decay: 0.1\n",
      "  lr_min_factor: 0.001\n",
      "  T0: 10\n",
      "  T_mul: 1.0\n",
      "validation:\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: False\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "augmentation:\n",
      "  use_random_crop: True\n",
      "  use_random_horizontal_flip: True\n",
      "  use_cutout: False\n",
      "  use_random_erasing: False\n",
      "  use_dual_cutout: False\n",
      "  use_mixup: False\n",
      "  use_ricap: False\n",
      "  use_cutmix: False\n",
      "  use_label_smoothing: False\n",
      "  random_crop:\n",
      "    padding: 4\n",
      "    fill: 0\n",
      "    padding_mode: constant\n",
      "  random_horizontal_flip:\n",
      "    prob: 0.5\n",
      "  cutout:\n",
      "    prob: 1.0\n",
      "    mask_size: 16\n",
      "    cut_inside: False\n",
      "    mask_color: 0\n",
      "    dual_cutout_alpha: 0.1\n",
      "  random_erasing:\n",
      "    prob: 0.5\n",
      "    area_ratio_range: [0.02, 0.4]\n",
      "    min_aspect_ratio: 0.3\n",
      "    max_attempt: 20\n",
      "  mixup:\n",
      "    alpha: 1.0\n",
      "  ricap:\n",
      "    beta: 0.3\n",
      "  cutmix:\n",
      "    alpha: 1.0\n",
      "  label_smoothing:\n",
      "    epsilon: 0.1\n",
      "tta:\n",
      "  use_resize: False\n",
      "  use_center_crop: False\n",
      "  resize: 256\n",
      "test:\n",
      "  checkpoint: ''\n",
      "  output_dir: ''\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    pin_memory: False\n",
      "\u001b[32m[2020-06-22 21:02:32] __main__ INFO: \u001b[0menv_info:\n",
      "  pytorch_version: 1.4.0\n",
      "  cuda_version: 10.1\n",
      "  cudnn_version: 7603\n",
      "  num_gpus: 1\n",
      "  gpu_name: Tesla K80\n",
      "  gpu_capability: 3.7\n",
      "Files already downloaded and verified\n",
      "\u001b[32m[2020-06-22 21:02:35] __main__ INFO: \u001b[0mMACs  : 69.76M\n",
      "\u001b[32m[2020-06-22 21:02:35] __main__ INFO: \u001b[0m#params: 466.91K\n",
      "Selected optimization level O0:  Pure FP32 training.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n",
      "\u001b[32m[2020-06-22 21:02:35] __main__ INFO: \u001b[0mVal 0\n",
      "\u001b[32m[2020-06-22 21:02:36] __main__ INFO: \u001b[0mEpoch 0 loss 4.3871 acc@1 0.4566 acc@5 0.8822\n",
      "\u001b[32m[2020-06-22 21:02:36] __main__ INFO: \u001b[0mElapsed 1.44\n",
      "\u001b[32m[2020-06-22 21:02:36] __main__ INFO: \u001b[0mTrain 1 0\n",
      "\u001b[32m[2020-06-22 21:02:46] __main__ INFO: \u001b[0mEpoch 1 Step 100/351 lr 0.001000 loss 0.9477 (1.0944) acc@1 0.6641 (0.6888) acc@5 0.9688 (0.9619)\n",
      "\u001b[32m[2020-06-22 21:02:55] __main__ INFO: \u001b[0mEpoch 1 Step 200/351 lr 0.001000 loss 0.9364 (0.9444) acc@1 0.7109 (0.7183) acc@5 0.9766 (0.9712)\n",
      "\u001b[32m[2020-06-22 21:03:04] __main__ INFO: \u001b[0mEpoch 1 Step 300/351 lr 0.001000 loss 0.8392 (0.8831) acc@1 0.6797 (0.7278) acc@5 0.9766 (0.9748)\n",
      "\u001b[32m[2020-06-22 21:03:09] __main__ INFO: \u001b[0mEpoch 1 Step 351/351 lr 0.001000 loss 0.6987 (0.8565) acc@1 0.7812 (0.7334) acc@5 0.9688 (0.9761)\n",
      "\u001b[32m[2020-06-22 21:03:09] __main__ INFO: \u001b[0mElapsed 32.30\n",
      "\u001b[32m[2020-06-22 21:03:09] __main__ INFO: \u001b[0mVal 1\n",
      "\u001b[32m[2020-06-22 21:03:10] __main__ INFO: \u001b[0mEpoch 1 loss 0.7400 acc@1 0.7626 acc@5 0.9830\n",
      "\u001b[32m[2020-06-22 21:03:10] __main__ INFO: \u001b[0mElapsed 1.04\n",
      "\u001b[32m[2020-06-22 21:03:10] __main__ INFO: \u001b[0mTrain 2 351\n",
      "\u001b[32m[2020-06-22 21:03:19] __main__ INFO: \u001b[0mEpoch 2 Step 100/351 lr 0.001000 loss 0.6150 (0.6748) acc@1 0.7812 (0.7718) acc@5 0.9922 (0.9852)\n",
      "\u001b[32m[2020-06-22 21:03:28] __main__ INFO: \u001b[0mEpoch 2 Step 200/351 lr 0.001000 loss 0.7549 (0.6592) acc@1 0.7188 (0.7770) acc@5 0.9688 (0.9847)\n",
      "\u001b[32m[2020-06-22 21:03:37] __main__ INFO: \u001b[0mEpoch 2 Step 300/351 lr 0.001000 loss 0.5068 (0.6499) acc@1 0.8438 (0.7784) acc@5 0.9922 (0.9846)\n",
      "\u001b[32m[2020-06-22 21:03:42] __main__ INFO: \u001b[0mEpoch 2 Step 351/351 lr 0.001000 loss 0.5810 (0.6443) acc@1 0.7891 (0.7802) acc@5 0.9766 (0.9848)\n",
      "\u001b[32m[2020-06-22 21:03:42] __main__ INFO: \u001b[0mElapsed 32.14\n",
      "\u001b[32m[2020-06-22 21:03:42] __main__ INFO: \u001b[0mVal 2\n",
      "\u001b[32m[2020-06-22 21:03:43] __main__ INFO: \u001b[0mEpoch 2 loss 0.6579 acc@1 0.7852 acc@5 0.9868\n",
      "\u001b[32m[2020-06-22 21:03:43] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 21:03:43] __main__ INFO: \u001b[0mTrain 3 702\n",
      "\u001b[32m[2020-06-22 21:03:52] __main__ INFO: \u001b[0mEpoch 3 Step 100/351 lr 0.001000 loss 0.6382 (0.5859) acc@1 0.7891 (0.7991) acc@5 0.9844 (0.9884)\n",
      "\u001b[32m[2020-06-22 21:04:01] __main__ INFO: \u001b[0mEpoch 3 Step 200/351 lr 0.001000 loss 0.5798 (0.5915) acc@1 0.7891 (0.7945) acc@5 0.9844 (0.9879)\n",
      "\u001b[32m[2020-06-22 21:04:11] __main__ INFO: \u001b[0mEpoch 3 Step 300/351 lr 0.001000 loss 0.4560 (0.5937) acc@1 0.8594 (0.7957) acc@5 0.9844 (0.9879)\n",
      "\u001b[32m[2020-06-22 21:04:15] __main__ INFO: \u001b[0mEpoch 3 Step 351/351 lr 0.001000 loss 0.5519 (0.5935) acc@1 0.7812 (0.7954) acc@5 0.9922 (0.9881)\n",
      "\u001b[32m[2020-06-22 21:04:15] __main__ INFO: \u001b[0mElapsed 32.25\n",
      "\u001b[32m[2020-06-22 21:04:15] __main__ INFO: \u001b[0mVal 3\n",
      "\u001b[32m[2020-06-22 21:04:16] __main__ INFO: \u001b[0mEpoch 3 loss 0.6293 acc@1 0.7926 acc@5 0.9874\n",
      "\u001b[32m[2020-06-22 21:04:16] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 21:04:16] __main__ INFO: \u001b[0mTrain 4 1053\n",
      "\u001b[32m[2020-06-22 21:04:26] __main__ INFO: \u001b[0mEpoch 4 Step 100/351 lr 0.001000 loss 0.4699 (0.5616) acc@1 0.8828 (0.8084) acc@5 0.9844 (0.9891)\n",
      "\u001b[32m[2020-06-22 21:04:35] __main__ INFO: \u001b[0mEpoch 4 Step 200/351 lr 0.001000 loss 0.5489 (0.5658) acc@1 0.8203 (0.8045) acc@5 0.9844 (0.9889)\n",
      "\u001b[32m[2020-06-22 21:04:44] __main__ INFO: \u001b[0mEpoch 4 Step 300/351 lr 0.001000 loss 0.5574 (0.5628) acc@1 0.7812 (0.8057) acc@5 0.9922 (0.9894)\n",
      "\u001b[32m[2020-06-22 21:04:49] __main__ INFO: \u001b[0mEpoch 4 Step 351/351 lr 0.001000 loss 0.4657 (0.5626) acc@1 0.8281 (0.8056) acc@5 1.0000 (0.9896)\n",
      "\u001b[32m[2020-06-22 21:04:49] __main__ INFO: \u001b[0mElapsed 32.33\n",
      "\u001b[32m[2020-06-22 21:04:49] __main__ INFO: \u001b[0mVal 4\n",
      "\u001b[32m[2020-06-22 21:04:50] __main__ INFO: \u001b[0mEpoch 4 loss 0.6082 acc@1 0.7962 acc@5 0.9874\n",
      "\u001b[32m[2020-06-22 21:04:50] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-06-22 21:04:50] __main__ INFO: \u001b[0mTrain 5 1404\n",
      "\u001b[32m[2020-06-22 21:04:59] __main__ INFO: \u001b[0mEpoch 5 Step 100/351 lr 0.001000 loss 0.4896 (0.5413) acc@1 0.8359 (0.8116) acc@5 1.0000 (0.9906)\n",
      "\u001b[32m[2020-06-22 21:05:08] __main__ INFO: \u001b[0mEpoch 5 Step 200/351 lr 0.001000 loss 0.5906 (0.5381) acc@1 0.8125 (0.8127) acc@5 1.0000 (0.9907)\n",
      "\u001b[32m[2020-06-22 21:05:17] __main__ INFO: \u001b[0mEpoch 5 Step 300/351 lr 0.001000 loss 0.5573 (0.5364) acc@1 0.8125 (0.8130) acc@5 1.0000 (0.9909)\n",
      "\u001b[32m[2020-06-22 21:05:22] __main__ INFO: \u001b[0mEpoch 5 Step 351/351 lr 0.001000 loss 0.4671 (0.5369) acc@1 0.8438 (0.8125) acc@5 1.0000 (0.9907)\n",
      "\u001b[32m[2020-06-22 21:05:22] __main__ INFO: \u001b[0mElapsed 32.38\n",
      "\u001b[32m[2020-06-22 21:05:22] __main__ INFO: \u001b[0mVal 5\n",
      "\u001b[32m[2020-06-22 21:05:23] __main__ INFO: \u001b[0mEpoch 5 loss 0.5906 acc@1 0.8020 acc@5 0.9888\n",
      "\u001b[32m[2020-06-22 21:05:23] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 21:05:23] __main__ INFO: \u001b[0mTrain 6 1755\n",
      "\u001b[32m[2020-06-22 21:05:33] __main__ INFO: \u001b[0mEpoch 6 Step 100/351 lr 0.001000 loss 0.5452 (0.5198) acc@1 0.8281 (0.8179) acc@5 0.9844 (0.9895)\n",
      "\u001b[32m[2020-06-22 21:05:42] __main__ INFO: \u001b[0mEpoch 6 Step 200/351 lr 0.001000 loss 0.4628 (0.5211) acc@1 0.8516 (0.8187) acc@5 0.9922 (0.9903)\n",
      "\u001b[32m[2020-06-22 21:05:51] __main__ INFO: \u001b[0mEpoch 6 Step 300/351 lr 0.001000 loss 0.3769 (0.5201) acc@1 0.8594 (0.8201) acc@5 0.9844 (0.9908)\n",
      "\u001b[32m[2020-06-22 21:05:56] __main__ INFO: \u001b[0mEpoch 6 Step 351/351 lr 0.001000 loss 0.5703 (0.5220) acc@1 0.7891 (0.8185) acc@5 1.0000 (0.9909)\n",
      "\u001b[32m[2020-06-22 21:05:56] __main__ INFO: \u001b[0mElapsed 32.51\n",
      "\u001b[32m[2020-06-22 21:05:56] __main__ INFO: \u001b[0mVal 6\n",
      "\u001b[32m[2020-06-22 21:05:57] __main__ INFO: \u001b[0mEpoch 6 loss 0.5812 acc@1 0.8064 acc@5 0.9892\n",
      "\u001b[32m[2020-06-22 21:05:57] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 21:05:57] __main__ INFO: \u001b[0mTrain 7 2106\n",
      "\u001b[32m[2020-06-22 21:06:06] __main__ INFO: \u001b[0mEpoch 7 Step 100/351 lr 0.001000 loss 0.5018 (0.4909) acc@1 0.8438 (0.8288) acc@5 0.9922 (0.9930)\n",
      "\u001b[32m[2020-06-22 21:06:15] __main__ INFO: \u001b[0mEpoch 7 Step 200/351 lr 0.001000 loss 0.4950 (0.4985) acc@1 0.8516 (0.8259) acc@5 0.9844 (0.9923)\n",
      "\u001b[32m[2020-06-22 21:06:24] __main__ INFO: \u001b[0mEpoch 7 Step 300/351 lr 0.001000 loss 0.4818 (0.5006) acc@1 0.8125 (0.8259) acc@5 1.0000 (0.9917)\n",
      "\u001b[32m[2020-06-22 21:06:29] __main__ INFO: \u001b[0mEpoch 7 Step 351/351 lr 0.001000 loss 0.4025 (0.5041) acc@1 0.8594 (0.8239) acc@5 0.9922 (0.9913)\n",
      "\u001b[32m[2020-06-22 21:06:29] __main__ INFO: \u001b[0mElapsed 32.41\n",
      "\u001b[32m[2020-06-22 21:06:29] __main__ INFO: \u001b[0mVal 7\n",
      "\u001b[32m[2020-06-22 21:06:30] __main__ INFO: \u001b[0mEpoch 7 loss 0.5708 acc@1 0.8080 acc@5 0.9896\n",
      "\u001b[32m[2020-06-22 21:06:30] __main__ INFO: \u001b[0mElapsed 1.13\n",
      "\u001b[32m[2020-06-22 21:06:30] __main__ INFO: \u001b[0mTrain 8 2457\n",
      "\u001b[32m[2020-06-22 21:06:40] __main__ INFO: \u001b[0mEpoch 8 Step 100/351 lr 0.001000 loss 0.4227 (0.4881) acc@1 0.8828 (0.8313) acc@5 0.9922 (0.9914)\n",
      "\u001b[32m[2020-06-22 21:06:49] __main__ INFO: \u001b[0mEpoch 8 Step 200/351 lr 0.001000 loss 0.4232 (0.4855) acc@1 0.8594 (0.8330) acc@5 0.9922 (0.9916)\n",
      "\u001b[32m[2020-06-22 21:06:58] __main__ INFO: \u001b[0mEpoch 8 Step 300/351 lr 0.001000 loss 0.5808 (0.4883) acc@1 0.8203 (0.8308) acc@5 0.9922 (0.9920)\n",
      "\u001b[32m[2020-06-22 21:07:03] __main__ INFO: \u001b[0mEpoch 8 Step 351/351 lr 0.001000 loss 0.5308 (0.4919) acc@1 0.7969 (0.8294) acc@5 0.9766 (0.9919)\n",
      "\u001b[32m[2020-06-22 21:07:03] __main__ INFO: \u001b[0mElapsed 32.46\n",
      "\u001b[32m[2020-06-22 21:07:03] __main__ INFO: \u001b[0mVal 8\n",
      "\u001b[32m[2020-06-22 21:07:04] __main__ INFO: \u001b[0mEpoch 8 loss 0.5592 acc@1 0.8142 acc@5 0.9894\n",
      "\u001b[32m[2020-06-22 21:07:04] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 21:07:04] __main__ INFO: \u001b[0mTrain 9 2808\n",
      "\u001b[32m[2020-06-22 21:07:13] __main__ INFO: \u001b[0mEpoch 9 Step 100/351 lr 0.001000 loss 0.5654 (0.4872) acc@1 0.7891 (0.8295) acc@5 0.9922 (0.9926)\n",
      "\u001b[32m[2020-06-22 21:07:22] __main__ INFO: \u001b[0mEpoch 9 Step 200/351 lr 0.001000 loss 0.4600 (0.4771) acc@1 0.8516 (0.8331) acc@5 1.0000 (0.9925)\n",
      "\u001b[32m[2020-06-22 21:07:31] __main__ INFO: \u001b[0mEpoch 9 Step 300/351 lr 0.001000 loss 0.5010 (0.4788) acc@1 0.8203 (0.8327) acc@5 0.9922 (0.9928)\n",
      "\u001b[32m[2020-06-22 21:07:36] __main__ INFO: \u001b[0mEpoch 9 Step 351/351 lr 0.001000 loss 0.4453 (0.4783) acc@1 0.8594 (0.8329) acc@5 1.0000 (0.9929)\n",
      "\u001b[32m[2020-06-22 21:07:36] __main__ INFO: \u001b[0mElapsed 32.34\n",
      "\u001b[32m[2020-06-22 21:07:36] __main__ INFO: \u001b[0mVal 9\n",
      "\u001b[32m[2020-06-22 21:07:37] __main__ INFO: \u001b[0mEpoch 9 loss 0.5515 acc@1 0.8174 acc@5 0.9894\n",
      "\u001b[32m[2020-06-22 21:07:37] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 21:07:37] __main__ INFO: \u001b[0mTrain 10 3159\n",
      "\u001b[32m[2020-06-22 21:07:47] __main__ INFO: \u001b[0mEpoch 10 Step 100/351 lr 0.001000 loss 0.3417 (0.4560) acc@1 0.8984 (0.8425) acc@5 0.9922 (0.9937)\n",
      "\u001b[32m[2020-06-22 21:07:56] __main__ INFO: \u001b[0mEpoch 10 Step 200/351 lr 0.001000 loss 0.5168 (0.4632) acc@1 0.8125 (0.8396) acc@5 1.0000 (0.9931)\n",
      "\u001b[32m[2020-06-22 21:08:05] __main__ INFO: \u001b[0mEpoch 10 Step 300/351 lr 0.001000 loss 0.4017 (0.4682) acc@1 0.8438 (0.8377) acc@5 1.0000 (0.9922)\n",
      "\u001b[32m[2020-06-22 21:08:10] __main__ INFO: \u001b[0mEpoch 10 Step 351/351 lr 0.001000 loss 0.4554 (0.4665) acc@1 0.8594 (0.8380) acc@5 0.9922 (0.9923)\n",
      "\u001b[32m[2020-06-22 21:08:10] __main__ INFO: \u001b[0mElapsed 32.38\n",
      "\u001b[32m[2020-06-22 21:08:10] __main__ INFO: \u001b[0mVal 10\n",
      "\u001b[32m[2020-06-22 21:08:11] __main__ INFO: \u001b[0mEpoch 10 loss 0.5420 acc@1 0.8208 acc@5 0.9910\n",
      "\u001b[32m[2020-06-22 21:08:11] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 21:08:11] __main__ INFO: \u001b[0mTrain 11 3510\n",
      "\u001b[32m[2020-06-22 21:08:20] __main__ INFO: \u001b[0mEpoch 11 Step 100/351 lr 0.001000 loss 0.3958 (0.4636) acc@1 0.8594 (0.8405) acc@5 1.0000 (0.9920)\n",
      "\u001b[32m[2020-06-22 21:08:29] __main__ INFO: \u001b[0mEpoch 11 Step 200/351 lr 0.001000 loss 0.5442 (0.4631) acc@1 0.7969 (0.8408) acc@5 1.0000 (0.9930)\n",
      "\u001b[32m[2020-06-22 21:08:38] __main__ INFO: \u001b[0mEpoch 11 Step 300/351 lr 0.001000 loss 0.6609 (0.4610) acc@1 0.7500 (0.8411) acc@5 1.0000 (0.9929)\n",
      "\u001b[32m[2020-06-22 21:08:43] __main__ INFO: \u001b[0mEpoch 11 Step 351/351 lr 0.001000 loss 0.5172 (0.4605) acc@1 0.7969 (0.8414) acc@5 1.0000 (0.9930)\n",
      "\u001b[32m[2020-06-22 21:08:43] __main__ INFO: \u001b[0mElapsed 32.38\n",
      "\u001b[32m[2020-06-22 21:08:43] __main__ INFO: \u001b[0mVal 11\n",
      "\u001b[32m[2020-06-22 21:08:44] __main__ INFO: \u001b[0mEpoch 11 loss 0.5365 acc@1 0.8220 acc@5 0.9898\n",
      "\u001b[32m[2020-06-22 21:08:44] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 21:08:44] __main__ INFO: \u001b[0mTrain 12 3861\n",
      "\u001b[32m[2020-06-22 21:08:53] __main__ INFO: \u001b[0mEpoch 12 Step 100/351 lr 0.001000 loss 0.5669 (0.4553) acc@1 0.8047 (0.8410) acc@5 0.9844 (0.9928)\n",
      "\u001b[32m[2020-06-22 21:09:03] __main__ INFO: \u001b[0mEpoch 12 Step 200/351 lr 0.001000 loss 0.5713 (0.4520) acc@1 0.7734 (0.8406) acc@5 0.9922 (0.9934)\n",
      "\u001b[32m[2020-06-22 21:09:12] __main__ INFO: \u001b[0mEpoch 12 Step 300/351 lr 0.001000 loss 0.4265 (0.4497) acc@1 0.8672 (0.8424) acc@5 0.9844 (0.9932)\n",
      "\u001b[32m[2020-06-22 21:09:17] __main__ INFO: \u001b[0mEpoch 12 Step 351/351 lr 0.001000 loss 0.4546 (0.4472) acc@1 0.8516 (0.8428) acc@5 1.0000 (0.9934)\n",
      "\u001b[32m[2020-06-22 21:09:17] __main__ INFO: \u001b[0mElapsed 32.37\n",
      "\u001b[32m[2020-06-22 21:09:17] __main__ INFO: \u001b[0mVal 12\n",
      "\u001b[32m[2020-06-22 21:09:18] __main__ INFO: \u001b[0mEpoch 12 loss 0.5314 acc@1 0.8240 acc@5 0.9906\n",
      "\u001b[32m[2020-06-22 21:09:18] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 21:09:18] __main__ INFO: \u001b[0mTrain 13 4212\n",
      "\u001b[32m[2020-06-22 21:09:27] __main__ INFO: \u001b[0mEpoch 13 Step 100/351 lr 0.001000 loss 0.5164 (0.4297) acc@1 0.8203 (0.8480) acc@5 0.9766 (0.9938)\n",
      "\u001b[32m[2020-06-22 21:09:36] __main__ INFO: \u001b[0mEpoch 13 Step 200/351 lr 0.001000 loss 0.4046 (0.4313) acc@1 0.8594 (0.8480) acc@5 1.0000 (0.9935)\n",
      "\u001b[32m[2020-06-22 21:09:45] __main__ INFO: \u001b[0mEpoch 13 Step 300/351 lr 0.001000 loss 0.2987 (0.4338) acc@1 0.8828 (0.8479) acc@5 0.9922 (0.9934)\n",
      "\u001b[32m[2020-06-22 21:09:50] __main__ INFO: \u001b[0mEpoch 13 Step 351/351 lr 0.001000 loss 0.3908 (0.4358) acc@1 0.8906 (0.8475) acc@5 1.0000 (0.9931)\n",
      "\u001b[32m[2020-06-22 21:09:50] __main__ INFO: \u001b[0mElapsed 32.38\n",
      "\u001b[32m[2020-06-22 21:09:50] __main__ INFO: \u001b[0mVal 13\n",
      "\u001b[32m[2020-06-22 21:09:51] __main__ INFO: \u001b[0mEpoch 13 loss 0.5235 acc@1 0.8278 acc@5 0.9910\n",
      "\u001b[32m[2020-06-22 21:09:51] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 21:09:51] __main__ INFO: \u001b[0mTrain 14 4563\n",
      "\u001b[32m[2020-06-22 21:10:00] __main__ INFO: \u001b[0mEpoch 14 Step 100/351 lr 0.001000 loss 0.4663 (0.4281) acc@1 0.8125 (0.8492) acc@5 0.9922 (0.9930)\n",
      "\u001b[32m[2020-06-22 21:10:10] __main__ INFO: \u001b[0mEpoch 14 Step 200/351 lr 0.001000 loss 0.3094 (0.4298) acc@1 0.9062 (0.8484) acc@5 1.0000 (0.9930)\n",
      "\u001b[32m[2020-06-22 21:10:19] __main__ INFO: \u001b[0mEpoch 14 Step 300/351 lr 0.001000 loss 0.4448 (0.4277) acc@1 0.8359 (0.8500) acc@5 0.9922 (0.9933)\n",
      "\u001b[32m[2020-06-22 21:10:23] __main__ INFO: \u001b[0mEpoch 14 Step 351/351 lr 0.001000 loss 0.4606 (0.4268) acc@1 0.8203 (0.8510) acc@5 1.0000 (0.9933)\n",
      "\u001b[32m[2020-06-22 21:10:23] __main__ INFO: \u001b[0mElapsed 32.37\n",
      "\u001b[32m[2020-06-22 21:10:23] __main__ INFO: \u001b[0mVal 14\n",
      "\u001b[32m[2020-06-22 21:10:25] __main__ INFO: \u001b[0mEpoch 14 loss 0.5208 acc@1 0.8270 acc@5 0.9914\n",
      "\u001b[32m[2020-06-22 21:10:25] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-22 21:10:25] __main__ INFO: \u001b[0mTrain 15 4914\n",
      "\u001b[32m[2020-06-22 21:10:34] __main__ INFO: \u001b[0mEpoch 15 Step 100/351 lr 0.001000 loss 0.4040 (0.4246) acc@1 0.8516 (0.8525) acc@5 0.9922 (0.9941)\n",
      "\u001b[32m[2020-06-22 21:10:43] __main__ INFO: \u001b[0mEpoch 15 Step 200/351 lr 0.001000 loss 0.4859 (0.4226) acc@1 0.8359 (0.8537) acc@5 0.9844 (0.9940)\n",
      "\u001b[32m[2020-06-22 21:10:52] __main__ INFO: \u001b[0mEpoch 15 Step 300/351 lr 0.001000 loss 0.4660 (0.4231) acc@1 0.8359 (0.8525) acc@5 0.9922 (0.9940)\n",
      "\u001b[32m[2020-06-22 21:10:57] __main__ INFO: \u001b[0mEpoch 15 Step 351/351 lr 0.001000 loss 0.4507 (0.4230) acc@1 0.8594 (0.8523) acc@5 1.0000 (0.9939)\n",
      "\u001b[32m[2020-06-22 21:10:57] __main__ INFO: \u001b[0mElapsed 32.38\n",
      "\u001b[32m[2020-06-22 21:10:57] __main__ INFO: \u001b[0mVal 15\n",
      "\u001b[32m[2020-06-22 21:10:58] __main__ INFO: \u001b[0mEpoch 15 loss 0.5214 acc@1 0.8304 acc@5 0.9912\n",
      "\u001b[32m[2020-06-22 21:10:58] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 21:10:58] __main__ INFO: \u001b[0mTrain 16 5265\n",
      "\u001b[32m[2020-06-22 21:11:07] __main__ INFO: \u001b[0mEpoch 16 Step 100/351 lr 0.001000 loss 0.4310 (0.4152) acc@1 0.8125 (0.8586) acc@5 1.0000 (0.9937)\n",
      "\u001b[32m[2020-06-22 21:11:16] __main__ INFO: \u001b[0mEpoch 16 Step 200/351 lr 0.001000 loss 0.3800 (0.4149) acc@1 0.8750 (0.8563) acc@5 1.0000 (0.9936)\n",
      "\u001b[32m[2020-06-22 21:11:26] __main__ INFO: \u001b[0mEpoch 16 Step 300/351 lr 0.001000 loss 0.4638 (0.4121) acc@1 0.8359 (0.8570) acc@5 1.0000 (0.9942)\n",
      "\u001b[32m[2020-06-22 21:11:30] __main__ INFO: \u001b[0mEpoch 16 Step 351/351 lr 0.001000 loss 0.3783 (0.4129) acc@1 0.8516 (0.8570) acc@5 1.0000 (0.9943)\n",
      "\u001b[32m[2020-06-22 21:11:30] __main__ INFO: \u001b[0mElapsed 32.39\n",
      "\u001b[32m[2020-06-22 21:11:30] __main__ INFO: \u001b[0mVal 16\n",
      "\u001b[32m[2020-06-22 21:11:31] __main__ INFO: \u001b[0mEpoch 16 loss 0.5153 acc@1 0.8318 acc@5 0.9914\n",
      "\u001b[32m[2020-06-22 21:11:31] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 21:11:31] __main__ INFO: \u001b[0mTrain 17 5616\n",
      "\u001b[32m[2020-06-22 21:11:41] __main__ INFO: \u001b[0mEpoch 17 Step 100/351 lr 0.001000 loss 0.4145 (0.4143) acc@1 0.8828 (0.8529) acc@5 0.9922 (0.9947)\n",
      "\u001b[32m[2020-06-22 21:11:50] __main__ INFO: \u001b[0mEpoch 17 Step 200/351 lr 0.001000 loss 0.5501 (0.4078) acc@1 0.8125 (0.8561) acc@5 0.9844 (0.9952)\n",
      "\u001b[32m[2020-06-22 21:11:59] __main__ INFO: \u001b[0mEpoch 17 Step 300/351 lr 0.001000 loss 0.3996 (0.4050) acc@1 0.8750 (0.8574) acc@5 0.9844 (0.9948)\n",
      "\u001b[32m[2020-06-22 21:12:04] __main__ INFO: \u001b[0mEpoch 17 Step 351/351 lr 0.001000 loss 0.3238 (0.4050) acc@1 0.8906 (0.8577) acc@5 1.0000 (0.9947)\n",
      "\u001b[32m[2020-06-22 21:12:04] __main__ INFO: \u001b[0mElapsed 32.38\n",
      "\u001b[32m[2020-06-22 21:12:04] __main__ INFO: \u001b[0mVal 17\n",
      "\u001b[32m[2020-06-22 21:12:05] __main__ INFO: \u001b[0mEpoch 17 loss 0.5191 acc@1 0.8294 acc@5 0.9912\n",
      "\u001b[32m[2020-06-22 21:12:05] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 21:12:05] __main__ INFO: \u001b[0mTrain 18 5967\n",
      "\u001b[32m[2020-06-22 21:12:14] __main__ INFO: \u001b[0mEpoch 18 Step 100/351 lr 0.001000 loss 0.6104 (0.4115) acc@1 0.7812 (0.8552) acc@5 0.9922 (0.9946)\n",
      "\u001b[32m[2020-06-22 21:12:23] __main__ INFO: \u001b[0mEpoch 18 Step 200/351 lr 0.001000 loss 0.5195 (0.4021) acc@1 0.8281 (0.8577) acc@5 0.9844 (0.9953)\n",
      "\u001b[32m[2020-06-22 21:12:33] __main__ INFO: \u001b[0mEpoch 18 Step 300/351 lr 0.001000 loss 0.4205 (0.4019) acc@1 0.8516 (0.8594) acc@5 1.0000 (0.9948)\n",
      "\u001b[32m[2020-06-22 21:12:37] __main__ INFO: \u001b[0mEpoch 18 Step 351/351 lr 0.001000 loss 0.4279 (0.4006) acc@1 0.8516 (0.8598) acc@5 0.9844 (0.9948)\n",
      "\u001b[32m[2020-06-22 21:12:37] __main__ INFO: \u001b[0mElapsed 32.40\n",
      "\u001b[32m[2020-06-22 21:12:37] __main__ INFO: \u001b[0mVal 18\n",
      "\u001b[32m[2020-06-22 21:12:38] __main__ INFO: \u001b[0mEpoch 18 loss 0.5083 acc@1 0.8306 acc@5 0.9916\n",
      "\u001b[32m[2020-06-22 21:12:38] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 21:12:38] __main__ INFO: \u001b[0mTrain 19 6318\n",
      "\u001b[32m[2020-06-22 21:12:48] __main__ INFO: \u001b[0mEpoch 19 Step 100/351 lr 0.001000 loss 0.3758 (0.3982) acc@1 0.8906 (0.8632) acc@5 1.0000 (0.9951)\n",
      "\u001b[32m[2020-06-22 21:12:57] __main__ INFO: \u001b[0mEpoch 19 Step 200/351 lr 0.001000 loss 0.4539 (0.3948) acc@1 0.8438 (0.8627) acc@5 0.9922 (0.9948)\n",
      "\u001b[32m[2020-06-22 21:13:06] __main__ INFO: \u001b[0mEpoch 19 Step 300/351 lr 0.001000 loss 0.4876 (0.3930) acc@1 0.8438 (0.8630) acc@5 0.9844 (0.9945)\n",
      "\u001b[32m[2020-06-22 21:13:11] __main__ INFO: \u001b[0mEpoch 19 Step 351/351 lr 0.001000 loss 0.4482 (0.3928) acc@1 0.8203 (0.8622) acc@5 0.9922 (0.9946)\n",
      "\u001b[32m[2020-06-22 21:13:11] __main__ INFO: \u001b[0mElapsed 32.42\n",
      "\u001b[32m[2020-06-22 21:13:11] __main__ INFO: \u001b[0mVal 19\n",
      "\u001b[32m[2020-06-22 21:13:12] __main__ INFO: \u001b[0mEpoch 19 loss 0.5055 acc@1 0.8348 acc@5 0.9912\n",
      "\u001b[32m[2020-06-22 21:13:12] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-22 21:13:12] __main__ INFO: \u001b[0mTrain 20 6669\n",
      "\u001b[32m[2020-06-22 21:13:21] __main__ INFO: \u001b[0mEpoch 20 Step 100/351 lr 0.001000 loss 0.3010 (0.3784) acc@1 0.8828 (0.8680) acc@5 0.9922 (0.9951)\n",
      "\u001b[32m[2020-06-22 21:13:30] __main__ INFO: \u001b[0mEpoch 20 Step 200/351 lr 0.001000 loss 0.4519 (0.3802) acc@1 0.8438 (0.8665) acc@5 0.9844 (0.9951)\n",
      "\u001b[32m[2020-06-22 21:13:40] __main__ INFO: \u001b[0mEpoch 20 Step 300/351 lr 0.001000 loss 0.4513 (0.3821) acc@1 0.8125 (0.8667) acc@5 1.0000 (0.9949)\n",
      "\u001b[32m[2020-06-22 21:13:44] __main__ INFO: \u001b[0mEpoch 20 Step 351/351 lr 0.001000 loss 0.3321 (0.3819) acc@1 0.8906 (0.8665) acc@5 0.9922 (0.9949)\n",
      "\u001b[32m[2020-06-22 21:13:44] __main__ INFO: \u001b[0mElapsed 32.39\n",
      "\u001b[32m[2020-06-22 21:13:44] __main__ INFO: \u001b[0mVal 20\n",
      "\u001b[32m[2020-06-22 21:13:45] __main__ INFO: \u001b[0mEpoch 20 loss 0.5006 acc@1 0.8348 acc@5 0.9920\n",
      "\u001b[32m[2020-06-22 21:13:45] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 21:13:45] __main__ INFO: \u001b[0mTrain 21 7020\n",
      "\u001b[32m[2020-06-22 21:13:55] __main__ INFO: \u001b[0mEpoch 21 Step 100/351 lr 0.001000 loss 0.4649 (0.3749) acc@1 0.8281 (0.8691) acc@5 0.9922 (0.9955)\n",
      "\u001b[32m[2020-06-22 21:14:04] __main__ INFO: \u001b[0mEpoch 21 Step 200/351 lr 0.001000 loss 0.4866 (0.3774) acc@1 0.8125 (0.8670) acc@5 1.0000 (0.9952)\n",
      "\u001b[32m[2020-06-22 21:14:13] __main__ INFO: \u001b[0mEpoch 21 Step 300/351 lr 0.001000 loss 0.4038 (0.3800) acc@1 0.8438 (0.8665) acc@5 0.9922 (0.9951)\n",
      "\u001b[32m[2020-06-22 21:14:18] __main__ INFO: \u001b[0mEpoch 21 Step 351/351 lr 0.001000 loss 0.3801 (0.3799) acc@1 0.8672 (0.8665) acc@5 1.0000 (0.9953)\n",
      "\u001b[32m[2020-06-22 21:14:18] __main__ INFO: \u001b[0mElapsed 32.39\n",
      "\u001b[32m[2020-06-22 21:14:18] __main__ INFO: \u001b[0mVal 21\n",
      "\u001b[32m[2020-06-22 21:14:19] __main__ INFO: \u001b[0mEpoch 21 loss 0.4954 acc@1 0.8378 acc@5 0.9914\n",
      "\u001b[32m[2020-06-22 21:14:19] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 21:14:19] __main__ INFO: \u001b[0mTrain 22 7371\n",
      "\u001b[32m[2020-06-22 21:14:28] __main__ INFO: \u001b[0mEpoch 22 Step 100/351 lr 0.001000 loss 0.3508 (0.3678) acc@1 0.9141 (0.8718) acc@5 0.9844 (0.9959)\n",
      "\u001b[32m[2020-06-22 21:14:37] __main__ INFO: \u001b[0mEpoch 22 Step 200/351 lr 0.001000 loss 0.4607 (0.3726) acc@1 0.8203 (0.8704) acc@5 0.9922 (0.9954)\n",
      "\u001b[32m[2020-06-22 21:14:46] __main__ INFO: \u001b[0mEpoch 22 Step 300/351 lr 0.001000 loss 0.2471 (0.3740) acc@1 0.9141 (0.8696) acc@5 1.0000 (0.9954)\n",
      "\u001b[32m[2020-06-22 21:14:51] __main__ INFO: \u001b[0mEpoch 22 Step 351/351 lr 0.001000 loss 0.4401 (0.3713) acc@1 0.8828 (0.8703) acc@5 0.9844 (0.9954)\n",
      "\u001b[32m[2020-06-22 21:14:51] __main__ INFO: \u001b[0mElapsed 32.34\n",
      "\u001b[32m[2020-06-22 21:14:51] __main__ INFO: \u001b[0mVal 22\n",
      "\u001b[32m[2020-06-22 21:14:52] __main__ INFO: \u001b[0mEpoch 22 loss 0.4932 acc@1 0.8384 acc@5 0.9922\n",
      "\u001b[32m[2020-06-22 21:14:52] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-06-22 21:14:52] __main__ INFO: \u001b[0mTrain 23 7722\n",
      "\u001b[32m[2020-06-22 21:15:02] __main__ INFO: \u001b[0mEpoch 23 Step 100/351 lr 0.001000 loss 0.2532 (0.3752) acc@1 0.9062 (0.8679) acc@5 1.0000 (0.9955)\n",
      "\u001b[32m[2020-06-22 21:15:11] __main__ INFO: \u001b[0mEpoch 23 Step 200/351 lr 0.001000 loss 0.2965 (0.3718) acc@1 0.8906 (0.8708) acc@5 1.0000 (0.9954)\n",
      "\u001b[32m[2020-06-22 21:15:20] __main__ INFO: \u001b[0mEpoch 23 Step 300/351 lr 0.001000 loss 0.3734 (0.3666) acc@1 0.8750 (0.8716) acc@5 1.0000 (0.9955)\n",
      "\u001b[32m[2020-06-22 21:15:25] __main__ INFO: \u001b[0mEpoch 23 Step 351/351 lr 0.001000 loss 0.5041 (0.3643) acc@1 0.8281 (0.8728) acc@5 0.9922 (0.9956)\n",
      "\u001b[32m[2020-06-22 21:15:25] __main__ INFO: \u001b[0mElapsed 32.44\n",
      "\u001b[32m[2020-06-22 21:15:25] __main__ INFO: \u001b[0mVal 23\n",
      "\u001b[32m[2020-06-22 21:15:26] __main__ INFO: \u001b[0mEpoch 23 loss 0.4955 acc@1 0.8384 acc@5 0.9926\n",
      "\u001b[32m[2020-06-22 21:15:26] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 21:15:26] __main__ INFO: \u001b[0mTrain 24 8073\n",
      "\u001b[32m[2020-06-22 21:15:35] __main__ INFO: \u001b[0mEpoch 24 Step 100/351 lr 0.001000 loss 0.2811 (0.3660) acc@1 0.8984 (0.8752) acc@5 1.0000 (0.9959)\n",
      "\u001b[32m[2020-06-22 21:15:44] __main__ INFO: \u001b[0mEpoch 24 Step 200/351 lr 0.001000 loss 0.3037 (0.3634) acc@1 0.8828 (0.8746) acc@5 1.0000 (0.9961)\n",
      "\u001b[32m[2020-06-22 21:15:53] __main__ INFO: \u001b[0mEpoch 24 Step 300/351 lr 0.001000 loss 0.4164 (0.3618) acc@1 0.8672 (0.8745) acc@5 0.9922 (0.9960)\n",
      "\u001b[32m[2020-06-22 21:15:58] __main__ INFO: \u001b[0mEpoch 24 Step 351/351 lr 0.001000 loss 0.2475 (0.3619) acc@1 0.9141 (0.8740) acc@5 1.0000 (0.9960)\n",
      "\u001b[32m[2020-06-22 21:15:58] __main__ INFO: \u001b[0mElapsed 32.46\n",
      "\u001b[32m[2020-06-22 21:15:58] __main__ INFO: \u001b[0mVal 24\n",
      "\u001b[32m[2020-06-22 21:15:59] __main__ INFO: \u001b[0mEpoch 24 loss 0.4907 acc@1 0.8444 acc@5 0.9918\n",
      "\u001b[32m[2020-06-22 21:15:59] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 21:15:59] __main__ INFO: \u001b[0mTrain 25 8424\n",
      "\u001b[32m[2020-06-22 21:16:09] __main__ INFO: \u001b[0mEpoch 25 Step 100/351 lr 0.001000 loss 0.2417 (0.3557) acc@1 0.8906 (0.8726) acc@5 1.0000 (0.9961)\n",
      "\u001b[32m[2020-06-22 21:16:18] __main__ INFO: \u001b[0mEpoch 25 Step 200/351 lr 0.001000 loss 0.3238 (0.3605) acc@1 0.8984 (0.8725) acc@5 1.0000 (0.9957)\n",
      "\u001b[32m[2020-06-22 21:16:27] __main__ INFO: \u001b[0mEpoch 25 Step 300/351 lr 0.001000 loss 0.3952 (0.3600) acc@1 0.8984 (0.8734) acc@5 1.0000 (0.9957)\n",
      "\u001b[32m[2020-06-22 21:16:32] __main__ INFO: \u001b[0mEpoch 25 Step 351/351 lr 0.001000 loss 0.2900 (0.3584) acc@1 0.9219 (0.8737) acc@5 0.9844 (0.9957)\n",
      "\u001b[32m[2020-06-22 21:16:32] __main__ INFO: \u001b[0mElapsed 32.37\n",
      "\u001b[32m[2020-06-22 21:16:32] __main__ INFO: \u001b[0mVal 25\n",
      "\u001b[32m[2020-06-22 21:16:33] __main__ INFO: \u001b[0mEpoch 25 loss 0.4931 acc@1 0.8364 acc@5 0.9928\n",
      "\u001b[32m[2020-06-22 21:16:33] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 21:16:33] __main__ INFO: \u001b[0mTrain 26 8775\n",
      "\u001b[32m[2020-06-22 21:16:42] __main__ INFO: \u001b[0mEpoch 26 Step 100/351 lr 0.001000 loss 0.3183 (0.3480) acc@1 0.9219 (0.8759) acc@5 1.0000 (0.9964)\n",
      "\u001b[32m[2020-06-22 21:16:51] __main__ INFO: \u001b[0mEpoch 26 Step 200/351 lr 0.001000 loss 0.3505 (0.3498) acc@1 0.8828 (0.8763) acc@5 1.0000 (0.9958)\n",
      "\u001b[32m[2020-06-22 21:17:00] __main__ INFO: \u001b[0mEpoch 26 Step 300/351 lr 0.001000 loss 0.3380 (0.3485) acc@1 0.8750 (0.8763) acc@5 0.9922 (0.9959)\n",
      "\u001b[32m[2020-06-22 21:17:05] __main__ INFO: \u001b[0mEpoch 26 Step 351/351 lr 0.001000 loss 0.2467 (0.3490) acc@1 0.8906 (0.8764) acc@5 1.0000 (0.9960)\n",
      "\u001b[32m[2020-06-22 21:17:05] __main__ INFO: \u001b[0mElapsed 32.36\n",
      "\u001b[32m[2020-06-22 21:17:05] __main__ INFO: \u001b[0mVal 26\n",
      "\u001b[32m[2020-06-22 21:17:06] __main__ INFO: \u001b[0mEpoch 26 loss 0.4913 acc@1 0.8406 acc@5 0.9930\n",
      "\u001b[32m[2020-06-22 21:17:06] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-22 21:17:06] __main__ INFO: \u001b[0mTrain 27 9126\n",
      "\u001b[32m[2020-06-22 21:17:15] __main__ INFO: \u001b[0mEpoch 27 Step 100/351 lr 0.001000 loss 0.3280 (0.3369) acc@1 0.8906 (0.8825) acc@5 0.9922 (0.9961)\n",
      "\u001b[32m[2020-06-22 21:17:25] __main__ INFO: \u001b[0mEpoch 27 Step 200/351 lr 0.001000 loss 0.3436 (0.3418) acc@1 0.8672 (0.8814) acc@5 1.0000 (0.9957)\n",
      "\u001b[32m[2020-06-22 21:17:34] __main__ INFO: \u001b[0mEpoch 27 Step 300/351 lr 0.001000 loss 0.2001 (0.3433) acc@1 0.9219 (0.8809) acc@5 0.9922 (0.9958)\n",
      "\u001b[32m[2020-06-22 21:17:38] __main__ INFO: \u001b[0mEpoch 27 Step 351/351 lr 0.001000 loss 0.3174 (0.3445) acc@1 0.9141 (0.8801) acc@5 0.9922 (0.9957)\n",
      "\u001b[32m[2020-06-22 21:17:39] __main__ INFO: \u001b[0mElapsed 32.38\n",
      "\u001b[32m[2020-06-22 21:17:39] __main__ INFO: \u001b[0mVal 27\n",
      "\u001b[32m[2020-06-22 21:17:40] __main__ INFO: \u001b[0mEpoch 27 loss 0.4914 acc@1 0.8388 acc@5 0.9926\n",
      "\u001b[32m[2020-06-22 21:17:40] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 21:17:40] __main__ INFO: \u001b[0mTrain 28 9477\n",
      "\u001b[32m[2020-06-22 21:17:49] __main__ INFO: \u001b[0mEpoch 28 Step 100/351 lr 0.001000 loss 0.2311 (0.3243) acc@1 0.9062 (0.8877) acc@5 1.0000 (0.9962)\n",
      "\u001b[32m[2020-06-22 21:17:58] __main__ INFO: \u001b[0mEpoch 28 Step 200/351 lr 0.001000 loss 0.2663 (0.3302) acc@1 0.9062 (0.8845) acc@5 1.0000 (0.9956)\n",
      "\u001b[32m[2020-06-22 21:18:07] __main__ INFO: \u001b[0mEpoch 28 Step 300/351 lr 0.001000 loss 0.2979 (0.3351) acc@1 0.8906 (0.8830) acc@5 1.0000 (0.9958)\n",
      "\u001b[32m[2020-06-22 21:18:12] __main__ INFO: \u001b[0mEpoch 28 Step 351/351 lr 0.001000 loss 0.3148 (0.3384) acc@1 0.8750 (0.8819) acc@5 0.9922 (0.9957)\n",
      "\u001b[32m[2020-06-22 21:18:12] __main__ INFO: \u001b[0mElapsed 32.37\n",
      "\u001b[32m[2020-06-22 21:18:12] __main__ INFO: \u001b[0mVal 28\n",
      "\u001b[32m[2020-06-22 21:18:13] __main__ INFO: \u001b[0mEpoch 28 loss 0.4890 acc@1 0.8430 acc@5 0.9924\n",
      "\u001b[32m[2020-06-22 21:18:13] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 21:18:13] __main__ INFO: \u001b[0mTrain 29 9828\n",
      "\u001b[32m[2020-06-22 21:18:22] __main__ INFO: \u001b[0mEpoch 29 Step 100/351 lr 0.001000 loss 0.3492 (0.3367) acc@1 0.8828 (0.8836) acc@5 0.9922 (0.9962)\n",
      "\u001b[32m[2020-06-22 21:18:32] __main__ INFO: \u001b[0mEpoch 29 Step 200/351 lr 0.001000 loss 0.4360 (0.3364) acc@1 0.8359 (0.8817) acc@5 1.0000 (0.9964)\n",
      "\u001b[32m[2020-06-22 21:18:41] __main__ INFO: \u001b[0mEpoch 29 Step 300/351 lr 0.001000 loss 0.2890 (0.3349) acc@1 0.9219 (0.8831) acc@5 1.0000 (0.9965)\n",
      "\u001b[32m[2020-06-22 21:18:45] __main__ INFO: \u001b[0mEpoch 29 Step 351/351 lr 0.001000 loss 0.2765 (0.3352) acc@1 0.9219 (0.8828) acc@5 1.0000 (0.9965)\n",
      "\u001b[32m[2020-06-22 21:18:45] __main__ INFO: \u001b[0mElapsed 32.41\n",
      "\u001b[32m[2020-06-22 21:18:45] __main__ INFO: \u001b[0mVal 29\n",
      "\u001b[32m[2020-06-22 21:18:47] __main__ INFO: \u001b[0mEpoch 29 loss 0.4839 acc@1 0.8454 acc@5 0.9934\n",
      "\u001b[32m[2020-06-22 21:18:47] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-22 21:18:47] __main__ INFO: \u001b[0mTrain 30 10179\n",
      "\u001b[32m[2020-06-22 21:18:56] __main__ INFO: \u001b[0mEpoch 30 Step 100/351 lr 0.001000 loss 0.3019 (0.3304) acc@1 0.8984 (0.8824) acc@5 1.0000 (0.9968)\n",
      "\u001b[32m[2020-06-22 21:19:05] __main__ INFO: \u001b[0mEpoch 30 Step 200/351 lr 0.001000 loss 0.2570 (0.3314) acc@1 0.9141 (0.8840) acc@5 1.0000 (0.9966)\n",
      "\u001b[32m[2020-06-22 21:19:14] __main__ INFO: \u001b[0mEpoch 30 Step 300/351 lr 0.001000 loss 0.3750 (0.3316) acc@1 0.8516 (0.8841) acc@5 0.9922 (0.9966)\n",
      "\u001b[32m[2020-06-22 21:19:19] __main__ INFO: \u001b[0mEpoch 30 Step 351/351 lr 0.001000 loss 0.3287 (0.3303) acc@1 0.8906 (0.8842) acc@5 1.0000 (0.9966)\n",
      "\u001b[32m[2020-06-22 21:19:19] __main__ INFO: \u001b[0mElapsed 32.36\n",
      "\u001b[32m[2020-06-22 21:19:19] __main__ INFO: \u001b[0mVal 30\n",
      "\u001b[32m[2020-06-22 21:19:20] __main__ INFO: \u001b[0mEpoch 30 loss 0.4806 acc@1 0.8438 acc@5 0.9930\n",
      "\u001b[32m[2020-06-22 21:19:20] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 21:19:20] __main__ INFO: \u001b[0mTrain 31 10530\n",
      "\u001b[32m[2020-06-22 21:19:29] __main__ INFO: \u001b[0mEpoch 31 Step 100/351 lr 0.001000 loss 0.3825 (0.3248) acc@1 0.8672 (0.8836) acc@5 0.9922 (0.9955)\n",
      "\u001b[32m[2020-06-22 21:19:38] __main__ INFO: \u001b[0mEpoch 31 Step 200/351 lr 0.001000 loss 0.3737 (0.3254) acc@1 0.8906 (0.8838) acc@5 1.0000 (0.9964)\n",
      "\u001b[32m[2020-06-22 21:19:48] __main__ INFO: \u001b[0mEpoch 31 Step 300/351 lr 0.001000 loss 0.2511 (0.3227) acc@1 0.9141 (0.8851) acc@5 1.0000 (0.9964)\n",
      "\u001b[32m[2020-06-22 21:19:52] __main__ INFO: \u001b[0mEpoch 31 Step 351/351 lr 0.001000 loss 0.2843 (0.3251) acc@1 0.8828 (0.8843) acc@5 1.0000 (0.9964)\n",
      "\u001b[32m[2020-06-22 21:19:52] __main__ INFO: \u001b[0mElapsed 32.39\n",
      "\u001b[32m[2020-06-22 21:19:52] __main__ INFO: \u001b[0mVal 31\n",
      "\u001b[32m[2020-06-22 21:19:53] __main__ INFO: \u001b[0mEpoch 31 loss 0.4881 acc@1 0.8444 acc@5 0.9932\n",
      "\u001b[32m[2020-06-22 21:19:53] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-22 21:19:53] __main__ INFO: \u001b[0mTrain 32 10881\n",
      "\u001b[32m[2020-06-22 21:20:03] __main__ INFO: \u001b[0mEpoch 32 Step 100/351 lr 0.001000 loss 0.2309 (0.3254) acc@1 0.9219 (0.8834) acc@5 1.0000 (0.9972)\n",
      "\u001b[32m[2020-06-22 21:20:12] __main__ INFO: \u001b[0mEpoch 32 Step 200/351 lr 0.001000 loss 0.2253 (0.3210) acc@1 0.9297 (0.8856) acc@5 1.0000 (0.9972)\n",
      "\u001b[32m[2020-06-22 21:20:21] __main__ INFO: \u001b[0mEpoch 32 Step 300/351 lr 0.001000 loss 0.3546 (0.3185) acc@1 0.8594 (0.8869) acc@5 1.0000 (0.9970)\n",
      "\u001b[32m[2020-06-22 21:20:26] __main__ INFO: \u001b[0mEpoch 32 Step 351/351 lr 0.001000 loss 0.2941 (0.3184) acc@1 0.8672 (0.8870) acc@5 1.0000 (0.9970)\n",
      "\u001b[32m[2020-06-22 21:20:26] __main__ INFO: \u001b[0mElapsed 32.38\n",
      "\u001b[32m[2020-06-22 21:20:26] __main__ INFO: \u001b[0mVal 32\n",
      "\u001b[32m[2020-06-22 21:20:27] __main__ INFO: \u001b[0mEpoch 32 loss 0.4814 acc@1 0.8438 acc@5 0.9922\n",
      "\u001b[32m[2020-06-22 21:20:27] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 21:20:27] __main__ INFO: \u001b[0mTrain 33 11232\n",
      "\u001b[32m[2020-06-22 21:20:36] __main__ INFO: \u001b[0mEpoch 33 Step 100/351 lr 0.001000 loss 0.2803 (0.3130) acc@1 0.9141 (0.8913) acc@5 0.9922 (0.9970)\n",
      "\u001b[32m[2020-06-22 21:20:45] __main__ INFO: \u001b[0mEpoch 33 Step 200/351 lr 0.001000 loss 0.3095 (0.3124) acc@1 0.9062 (0.8920) acc@5 0.9922 (0.9968)\n",
      "\u001b[32m[2020-06-22 21:20:55] __main__ INFO: \u001b[0mEpoch 33 Step 300/351 lr 0.001000 loss 0.3423 (0.3140) acc@1 0.8516 (0.8905) acc@5 1.0000 (0.9966)\n",
      "\u001b[32m[2020-06-22 21:20:59] __main__ INFO: \u001b[0mEpoch 33 Step 351/351 lr 0.001000 loss 0.3568 (0.3152) acc@1 0.8672 (0.8896) acc@5 1.0000 (0.9968)\n",
      "\u001b[32m[2020-06-22 21:20:59] __main__ INFO: \u001b[0mElapsed 32.32\n",
      "\u001b[32m[2020-06-22 21:20:59] __main__ INFO: \u001b[0mVal 33\n",
      "\u001b[32m[2020-06-22 21:21:00] __main__ INFO: \u001b[0mEpoch 33 loss 0.4868 acc@1 0.8466 acc@5 0.9932\n",
      "\u001b[32m[2020-06-22 21:21:00] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-22 21:21:00] __main__ INFO: \u001b[0mTrain 34 11583\n",
      "\u001b[32m[2020-06-22 21:21:10] __main__ INFO: \u001b[0mEpoch 34 Step 100/351 lr 0.001000 loss 0.2727 (0.3158) acc@1 0.9141 (0.8893) acc@5 1.0000 (0.9969)\n",
      "\u001b[32m[2020-06-22 21:21:19] __main__ INFO: \u001b[0mEpoch 34 Step 200/351 lr 0.001000 loss 0.3234 (0.3075) acc@1 0.8984 (0.8916) acc@5 1.0000 (0.9971)\n",
      "\u001b[32m[2020-06-22 21:21:28] __main__ INFO: \u001b[0mEpoch 34 Step 300/351 lr 0.001000 loss 0.2407 (0.3108) acc@1 0.9219 (0.8906) acc@5 0.9922 (0.9971)\n",
      "\u001b[32m[2020-06-22 21:21:33] __main__ INFO: \u001b[0mEpoch 34 Step 351/351 lr 0.001000 loss 0.2576 (0.3091) acc@1 0.9219 (0.8913) acc@5 1.0000 (0.9972)\n",
      "\u001b[32m[2020-06-22 21:21:33] __main__ INFO: \u001b[0mElapsed 32.41\n",
      "\u001b[32m[2020-06-22 21:21:33] __main__ INFO: \u001b[0mVal 34\n",
      "\u001b[32m[2020-06-22 21:21:34] __main__ INFO: \u001b[0mEpoch 34 loss 0.4850 acc@1 0.8454 acc@5 0.9920\n",
      "\u001b[32m[2020-06-22 21:21:34] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 21:21:34] __main__ INFO: \u001b[0mTrain 35 11934\n",
      "\u001b[32m[2020-06-22 21:21:43] __main__ INFO: \u001b[0mEpoch 35 Step 100/351 lr 0.001000 loss 0.3896 (0.3002) acc@1 0.8594 (0.8936) acc@5 0.9922 (0.9969)\n",
      "\u001b[32m[2020-06-22 21:21:52] __main__ INFO: \u001b[0mEpoch 35 Step 200/351 lr 0.001000 loss 0.3737 (0.3039) acc@1 0.8906 (0.8935) acc@5 0.9922 (0.9970)\n",
      "\u001b[32m[2020-06-22 21:22:01] __main__ INFO: \u001b[0mEpoch 35 Step 300/351 lr 0.001000 loss 0.3203 (0.3057) acc@1 0.9062 (0.8926) acc@5 1.0000 (0.9969)\n",
      "\u001b[32m[2020-06-22 21:22:06] __main__ INFO: \u001b[0mEpoch 35 Step 351/351 lr 0.001000 loss 0.3560 (0.3065) acc@1 0.8438 (0.8920) acc@5 1.0000 (0.9968)\n",
      "\u001b[32m[2020-06-22 21:22:06] __main__ INFO: \u001b[0mElapsed 32.30\n",
      "\u001b[32m[2020-06-22 21:22:06] __main__ INFO: \u001b[0mVal 35\n",
      "\u001b[32m[2020-06-22 21:22:07] __main__ INFO: \u001b[0mEpoch 35 loss 0.4819 acc@1 0.8472 acc@5 0.9922\n",
      "\u001b[32m[2020-06-22 21:22:07] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 21:22:07] __main__ INFO: \u001b[0mTrain 36 12285\n",
      "\u001b[32m[2020-06-22 21:22:16] __main__ INFO: \u001b[0mEpoch 36 Step 100/351 lr 0.001000 loss 0.2513 (0.2973) acc@1 0.9219 (0.8979) acc@5 1.0000 (0.9959)\n",
      "\u001b[32m[2020-06-22 21:22:26] __main__ INFO: \u001b[0mEpoch 36 Step 200/351 lr 0.001000 loss 0.2057 (0.2997) acc@1 0.9453 (0.8955) acc@5 0.9922 (0.9967)\n",
      "\u001b[32m[2020-06-22 21:22:35] __main__ INFO: \u001b[0mEpoch 36 Step 300/351 lr 0.001000 loss 0.2834 (0.3018) acc@1 0.8984 (0.8944) acc@5 1.0000 (0.9967)\n",
      "\u001b[32m[2020-06-22 21:22:40] __main__ INFO: \u001b[0mEpoch 36 Step 351/351 lr 0.001000 loss 0.3502 (0.2991) acc@1 0.8828 (0.8948) acc@5 1.0000 (0.9971)\n",
      "\u001b[32m[2020-06-22 21:22:40] __main__ INFO: \u001b[0mElapsed 32.40\n",
      "\u001b[32m[2020-06-22 21:22:40] __main__ INFO: \u001b[0mVal 36\n",
      "\u001b[32m[2020-06-22 21:22:41] __main__ INFO: \u001b[0mEpoch 36 loss 0.4853 acc@1 0.8476 acc@5 0.9932\n",
      "\u001b[32m[2020-06-22 21:22:41] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-22 21:22:41] __main__ INFO: \u001b[0mTrain 37 12636\n",
      "\u001b[32m[2020-06-22 21:22:50] __main__ INFO: \u001b[0mEpoch 37 Step 100/351 lr 0.001000 loss 0.3987 (0.2964) acc@1 0.8125 (0.8963) acc@5 1.0000 (0.9968)\n",
      "\u001b[32m[2020-06-22 21:22:59] __main__ INFO: \u001b[0mEpoch 37 Step 200/351 lr 0.001000 loss 0.2848 (0.2980) acc@1 0.8906 (0.8967) acc@5 1.0000 (0.9971)\n",
      "\u001b[32m[2020-06-22 21:23:08] __main__ INFO: \u001b[0mEpoch 37 Step 300/351 lr 0.001000 loss 0.3759 (0.2963) acc@1 0.8594 (0.8962) acc@5 1.0000 (0.9974)\n",
      "\u001b[32m[2020-06-22 21:23:13] __main__ INFO: \u001b[0mEpoch 37 Step 351/351 lr 0.001000 loss 0.2280 (0.2964) acc@1 0.9219 (0.8958) acc@5 1.0000 (0.9974)\n",
      "\u001b[32m[2020-06-22 21:23:13] __main__ INFO: \u001b[0mElapsed 32.39\n",
      "\u001b[32m[2020-06-22 21:23:13] __main__ INFO: \u001b[0mVal 37\n",
      "\u001b[32m[2020-06-22 21:23:14] __main__ INFO: \u001b[0mEpoch 37 loss 0.4829 acc@1 0.8496 acc@5 0.9928\n",
      "\u001b[32m[2020-06-22 21:23:14] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-22 21:23:14] __main__ INFO: \u001b[0mTrain 38 12987\n",
      "\u001b[32m[2020-06-22 21:23:23] __main__ INFO: \u001b[0mEpoch 38 Step 100/351 lr 0.001000 loss 0.3360 (0.2975) acc@1 0.8906 (0.8967) acc@5 1.0000 (0.9974)\n",
      "\u001b[32m[2020-06-22 21:23:33] __main__ INFO: \u001b[0mEpoch 38 Step 200/351 lr 0.001000 loss 0.2642 (0.2972) acc@1 0.9297 (0.8969) acc@5 1.0000 (0.9973)\n",
      "\u001b[32m[2020-06-22 21:23:42] __main__ INFO: \u001b[0mEpoch 38 Step 300/351 lr 0.001000 loss 0.3492 (0.2948) acc@1 0.8906 (0.8971) acc@5 0.9922 (0.9975)\n",
      "\u001b[32m[2020-06-22 21:23:46] __main__ INFO: \u001b[0mEpoch 38 Step 351/351 lr 0.001000 loss 0.3196 (0.2940) acc@1 0.8672 (0.8969) acc@5 0.9922 (0.9975)\n",
      "\u001b[32m[2020-06-22 21:23:46] __main__ INFO: \u001b[0mElapsed 32.29\n",
      "\u001b[32m[2020-06-22 21:23:46] __main__ INFO: \u001b[0mVal 38\n",
      "\u001b[32m[2020-06-22 21:23:48] __main__ INFO: \u001b[0mEpoch 38 loss 0.4888 acc@1 0.8440 acc@5 0.9930\n",
      "\u001b[32m[2020-06-22 21:23:48] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 21:23:48] __main__ INFO: \u001b[0mTrain 39 13338\n",
      "\u001b[32m[2020-06-22 21:23:57] __main__ INFO: \u001b[0mEpoch 39 Step 100/351 lr 0.001000 loss 0.2430 (0.2789) acc@1 0.9141 (0.9040) acc@5 0.9922 (0.9973)\n",
      "\u001b[32m[2020-06-22 21:24:06] __main__ INFO: \u001b[0mEpoch 39 Step 200/351 lr 0.001000 loss 0.2218 (0.2862) acc@1 0.9219 (0.9004) acc@5 1.0000 (0.9972)\n",
      "\u001b[32m[2020-06-22 21:24:15] __main__ INFO: \u001b[0mEpoch 39 Step 300/351 lr 0.001000 loss 0.3052 (0.2878) acc@1 0.8984 (0.8989) acc@5 1.0000 (0.9976)\n",
      "\u001b[32m[2020-06-22 21:24:20] __main__ INFO: \u001b[0mEpoch 39 Step 351/351 lr 0.001000 loss 0.3310 (0.2895) acc@1 0.8828 (0.8986) acc@5 0.9922 (0.9973)\n",
      "\u001b[32m[2020-06-22 21:24:20] __main__ INFO: \u001b[0mElapsed 32.41\n",
      "\u001b[32m[2020-06-22 21:24:20] __main__ INFO: \u001b[0mVal 39\n",
      "\u001b[32m[2020-06-22 21:24:21] __main__ INFO: \u001b[0mEpoch 39 loss 0.4869 acc@1 0.8486 acc@5 0.9928\n",
      "\u001b[32m[2020-06-22 21:24:21] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-22 21:24:21] __main__ INFO: \u001b[0mTrain 40 13689\n",
      "\u001b[32m[2020-06-22 21:24:30] __main__ INFO: \u001b[0mEpoch 40 Step 100/351 lr 0.001000 loss 0.2809 (0.2855) acc@1 0.8906 (0.9005) acc@5 1.0000 (0.9977)\n",
      "\u001b[32m[2020-06-22 21:24:40] __main__ INFO: \u001b[0mEpoch 40 Step 200/351 lr 0.001000 loss 0.3761 (0.2839) acc@1 0.8828 (0.9002) acc@5 0.9922 (0.9978)\n",
      "\u001b[32m[2020-06-22 21:24:49] __main__ INFO: \u001b[0mEpoch 40 Step 300/351 lr 0.001000 loss 0.3078 (0.2824) acc@1 0.8906 (0.8996) acc@5 1.0000 (0.9977)\n",
      "\u001b[32m[2020-06-22 21:24:53] __main__ INFO: \u001b[0mEpoch 40 Step 351/351 lr 0.001000 loss 0.4766 (0.2836) acc@1 0.8359 (0.8995) acc@5 0.9922 (0.9975)\n",
      "\u001b[32m[2020-06-22 21:24:53] __main__ INFO: \u001b[0mElapsed 32.37\n",
      "\u001b[32m[2020-06-22 21:24:53] __main__ INFO: \u001b[0mVal 40\n",
      "\u001b[32m[2020-06-22 21:24:54] __main__ INFO: \u001b[0mEpoch 40 loss 0.4896 acc@1 0.8452 acc@5 0.9932\n",
      "\u001b[32m[2020-06-22 21:24:54] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 21:24:54] __main__ INFO: \u001b[0mTrain 41 14040\n",
      "\u001b[32m[2020-06-22 21:25:04] __main__ INFO: \u001b[0mEpoch 41 Step 100/351 lr 0.001000 loss 0.2357 (0.2816) acc@1 0.9375 (0.9004) acc@5 0.9922 (0.9976)\n",
      "\u001b[32m[2020-06-22 21:25:13] __main__ INFO: \u001b[0mEpoch 41 Step 200/351 lr 0.001000 loss 0.2685 (0.2826) acc@1 0.9062 (0.8997) acc@5 0.9922 (0.9977)\n",
      "\u001b[32m[2020-06-22 21:25:22] __main__ INFO: \u001b[0mEpoch 41 Step 300/351 lr 0.001000 loss 0.1256 (0.2799) acc@1 0.9688 (0.9010) acc@5 0.9922 (0.9977)\n",
      "\u001b[32m[2020-06-22 21:25:27] __main__ INFO: \u001b[0mEpoch 41 Step 351/351 lr 0.001000 loss 0.3073 (0.2816) acc@1 0.8594 (0.9003) acc@5 1.0000 (0.9976)\n",
      "\u001b[32m[2020-06-22 21:25:27] __main__ INFO: \u001b[0mElapsed 32.37\n",
      "\u001b[32m[2020-06-22 21:25:27] __main__ INFO: \u001b[0mVal 41\n",
      "\u001b[32m[2020-06-22 21:25:28] __main__ INFO: \u001b[0mEpoch 41 loss 0.4861 acc@1 0.8512 acc@5 0.9932\n",
      "\u001b[32m[2020-06-22 21:25:28] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 21:25:28] __main__ INFO: \u001b[0mTrain 42 14391\n",
      "\u001b[32m[2020-06-22 21:25:37] __main__ INFO: \u001b[0mEpoch 42 Step 100/351 lr 0.001000 loss 0.3384 (0.2844) acc@1 0.8906 (0.8998) acc@5 0.9922 (0.9981)\n",
      "\u001b[32m[2020-06-22 21:25:46] __main__ INFO: \u001b[0mEpoch 42 Step 200/351 lr 0.001000 loss 0.3137 (0.2776) acc@1 0.9062 (0.9018) acc@5 1.0000 (0.9979)\n",
      "\u001b[32m[2020-06-22 21:25:56] __main__ INFO: \u001b[0mEpoch 42 Step 300/351 lr 0.001000 loss 0.2312 (0.2775) acc@1 0.9219 (0.9024) acc@5 1.0000 (0.9975)\n",
      "\u001b[32m[2020-06-22 21:26:00] __main__ INFO: \u001b[0mEpoch 42 Step 351/351 lr 0.001000 loss 0.2395 (0.2791) acc@1 0.9219 (0.9022) acc@5 1.0000 (0.9974)\n",
      "\u001b[32m[2020-06-22 21:26:00] __main__ INFO: \u001b[0mElapsed 32.35\n",
      "\u001b[32m[2020-06-22 21:26:00] __main__ INFO: \u001b[0mVal 42\n",
      "\u001b[32m[2020-06-22 21:26:01] __main__ INFO: \u001b[0mEpoch 42 loss 0.4841 acc@1 0.8532 acc@5 0.9924\n",
      "\u001b[32m[2020-06-22 21:26:01] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 21:26:01] __main__ INFO: \u001b[0mTrain 43 14742\n",
      "\u001b[32m[2020-06-22 21:26:11] __main__ INFO: \u001b[0mEpoch 43 Step 100/351 lr 0.001000 loss 0.3858 (0.2719) acc@1 0.8672 (0.9052) acc@5 1.0000 (0.9971)\n",
      "\u001b[32m[2020-06-22 21:26:20] __main__ INFO: \u001b[0mEpoch 43 Step 200/351 lr 0.001000 loss 0.2583 (0.2715) acc@1 0.9219 (0.9038) acc@5 1.0000 (0.9974)\n",
      "\u001b[32m[2020-06-22 21:26:29] __main__ INFO: \u001b[0mEpoch 43 Step 300/351 lr 0.001000 loss 0.2973 (0.2741) acc@1 0.8906 (0.9027) acc@5 1.0000 (0.9976)\n",
      "\u001b[32m[2020-06-22 21:26:34] __main__ INFO: \u001b[0mEpoch 43 Step 351/351 lr 0.001000 loss 0.1469 (0.2742) acc@1 0.9531 (0.9029) acc@5 1.0000 (0.9975)\n",
      "\u001b[32m[2020-06-22 21:26:34] __main__ INFO: \u001b[0mElapsed 32.31\n",
      "\u001b[32m[2020-06-22 21:26:34] __main__ INFO: \u001b[0mVal 43\n",
      "\u001b[32m[2020-06-22 21:26:35] __main__ INFO: \u001b[0mEpoch 43 loss 0.4837 acc@1 0.8508 acc@5 0.9922\n",
      "\u001b[32m[2020-06-22 21:26:35] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 21:26:35] __main__ INFO: \u001b[0mTrain 44 15093\n",
      "\u001b[32m[2020-06-22 21:26:44] __main__ INFO: \u001b[0mEpoch 44 Step 100/351 lr 0.001000 loss 0.2294 (0.2718) acc@1 0.9219 (0.9052) acc@5 1.0000 (0.9973)\n",
      "\u001b[32m[2020-06-22 21:26:53] __main__ INFO: \u001b[0mEpoch 44 Step 200/351 lr 0.001000 loss 0.3084 (0.2735) acc@1 0.9062 (0.9053) acc@5 1.0000 (0.9972)\n",
      "\u001b[32m[2020-06-22 21:27:02] __main__ INFO: \u001b[0mEpoch 44 Step 300/351 lr 0.001000 loss 0.1757 (0.2720) acc@1 0.9531 (0.9057) acc@5 1.0000 (0.9975)\n",
      "\u001b[32m[2020-06-22 21:27:07] __main__ INFO: \u001b[0mEpoch 44 Step 351/351 lr 0.001000 loss 0.2104 (0.2724) acc@1 0.9141 (0.9051) acc@5 1.0000 (0.9976)\n",
      "\u001b[32m[2020-06-22 21:27:07] __main__ INFO: \u001b[0mElapsed 32.26\n",
      "\u001b[32m[2020-06-22 21:27:07] __main__ INFO: \u001b[0mVal 44\n",
      "\u001b[32m[2020-06-22 21:27:08] __main__ INFO: \u001b[0mEpoch 44 loss 0.4843 acc@1 0.8504 acc@5 0.9930\n",
      "\u001b[32m[2020-06-22 21:27:08] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 21:27:08] __main__ INFO: \u001b[0mTrain 45 15444\n",
      "\u001b[32m[2020-06-22 21:27:17] __main__ INFO: \u001b[0mEpoch 45 Step 100/351 lr 0.001000 loss 0.2478 (0.2713) acc@1 0.8984 (0.9047) acc@5 1.0000 (0.9985)\n",
      "\u001b[32m[2020-06-22 21:27:26] __main__ INFO: \u001b[0mEpoch 45 Step 200/351 lr 0.001000 loss 0.2539 (0.2711) acc@1 0.9062 (0.9051) acc@5 0.9922 (0.9984)\n",
      "\u001b[32m[2020-06-22 21:27:36] __main__ INFO: \u001b[0mEpoch 45 Step 300/351 lr 0.001000 loss 0.3005 (0.2687) acc@1 0.8828 (0.9057) acc@5 1.0000 (0.9980)\n",
      "\u001b[32m[2020-06-22 21:27:40] __main__ INFO: \u001b[0mEpoch 45 Step 351/351 lr 0.001000 loss 0.2332 (0.2686) acc@1 0.9297 (0.9058) acc@5 1.0000 (0.9981)\n",
      "\u001b[32m[2020-06-22 21:27:40] __main__ INFO: \u001b[0mElapsed 32.35\n",
      "\u001b[32m[2020-06-22 21:27:40] __main__ INFO: \u001b[0mVal 45\n",
      "\u001b[32m[2020-06-22 21:27:41] __main__ INFO: \u001b[0mEpoch 45 loss 0.4889 acc@1 0.8502 acc@5 0.9936\n",
      "\u001b[32m[2020-06-22 21:27:41] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-22 21:27:41] __main__ INFO: \u001b[0mTrain 46 15795\n",
      "\u001b[32m[2020-06-22 21:27:51] __main__ INFO: \u001b[0mEpoch 46 Step 100/351 lr 0.001000 loss 0.2090 (0.2594) acc@1 0.9219 (0.9098) acc@5 1.0000 (0.9986)\n",
      "\u001b[32m[2020-06-22 21:28:00] __main__ INFO: \u001b[0mEpoch 46 Step 200/351 lr 0.001000 loss 0.2895 (0.2593) acc@1 0.8828 (0.9092) acc@5 0.9922 (0.9979)\n",
      "\u001b[32m[2020-06-22 21:28:09] __main__ INFO: \u001b[0mEpoch 46 Step 300/351 lr 0.001000 loss 0.3333 (0.2599) acc@1 0.9062 (0.9089) acc@5 0.9922 (0.9979)\n",
      "\u001b[32m[2020-06-22 21:28:14] __main__ INFO: \u001b[0mEpoch 46 Step 351/351 lr 0.001000 loss 0.2617 (0.2603) acc@1 0.9062 (0.9084) acc@5 1.0000 (0.9978)\n",
      "\u001b[32m[2020-06-22 21:28:14] __main__ INFO: \u001b[0mElapsed 32.39\n",
      "\u001b[32m[2020-06-22 21:28:14] __main__ INFO: \u001b[0mVal 46\n",
      "\u001b[32m[2020-06-22 21:28:15] __main__ INFO: \u001b[0mEpoch 46 loss 0.4826 acc@1 0.8510 acc@5 0.9924\n",
      "\u001b[32m[2020-06-22 21:28:15] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 21:28:15] __main__ INFO: \u001b[0mTrain 47 16146\n",
      "\u001b[32m[2020-06-22 21:28:24] __main__ INFO: \u001b[0mEpoch 47 Step 100/351 lr 0.001000 loss 0.2694 (0.2567) acc@1 0.9062 (0.9098) acc@5 1.0000 (0.9979)\n",
      "\u001b[32m[2020-06-22 21:28:33] __main__ INFO: \u001b[0mEpoch 47 Step 200/351 lr 0.001000 loss 0.2114 (0.2556) acc@1 0.9141 (0.9093) acc@5 1.0000 (0.9975)\n",
      "\u001b[32m[2020-06-22 21:28:43] __main__ INFO: \u001b[0mEpoch 47 Step 300/351 lr 0.001000 loss 0.2610 (0.2570) acc@1 0.8828 (0.9089) acc@5 0.9922 (0.9977)\n",
      "\u001b[32m[2020-06-22 21:28:47] __main__ INFO: \u001b[0mEpoch 47 Step 351/351 lr 0.001000 loss 0.2894 (0.2601) acc@1 0.8828 (0.9078) acc@5 1.0000 (0.9978)\n",
      "\u001b[32m[2020-06-22 21:28:47] __main__ INFO: \u001b[0mElapsed 32.38\n",
      "\u001b[32m[2020-06-22 21:28:47] __main__ INFO: \u001b[0mVal 47\n",
      "\u001b[32m[2020-06-22 21:28:48] __main__ INFO: \u001b[0mEpoch 47 loss 0.4848 acc@1 0.8528 acc@5 0.9926\n",
      "\u001b[32m[2020-06-22 21:28:48] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 21:28:48] __main__ INFO: \u001b[0mTrain 48 16497\n",
      "\u001b[32m[2020-06-22 21:28:58] __main__ INFO: \u001b[0mEpoch 48 Step 100/351 lr 0.001000 loss 0.2177 (0.2497) acc@1 0.9453 (0.9124) acc@5 1.0000 (0.9980)\n",
      "\u001b[32m[2020-06-22 21:29:07] __main__ INFO: \u001b[0mEpoch 48 Step 200/351 lr 0.001000 loss 0.2093 (0.2488) acc@1 0.9141 (0.9129) acc@5 1.0000 (0.9980)\n",
      "\u001b[32m[2020-06-22 21:29:16] __main__ INFO: \u001b[0mEpoch 48 Step 300/351 lr 0.001000 loss 0.1896 (0.2520) acc@1 0.9375 (0.9128) acc@5 1.0000 (0.9980)\n",
      "\u001b[32m[2020-06-22 21:29:21] __main__ INFO: \u001b[0mEpoch 48 Step 351/351 lr 0.001000 loss 0.2722 (0.2547) acc@1 0.9062 (0.9116) acc@5 1.0000 (0.9979)\n",
      "\u001b[32m[2020-06-22 21:29:21] __main__ INFO: \u001b[0mElapsed 32.42\n",
      "\u001b[32m[2020-06-22 21:29:21] __main__ INFO: \u001b[0mVal 48\n",
      "\u001b[32m[2020-06-22 21:29:22] __main__ INFO: \u001b[0mEpoch 48 loss 0.4839 acc@1 0.8520 acc@5 0.9934\n",
      "\u001b[32m[2020-06-22 21:29:22] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 21:29:22] __main__ INFO: \u001b[0mTrain 49 16848\n",
      "\u001b[32m[2020-06-22 21:29:31] __main__ INFO: \u001b[0mEpoch 49 Step 100/351 lr 0.001000 loss 0.2312 (0.2484) acc@1 0.9219 (0.9145) acc@5 1.0000 (0.9985)\n",
      "\u001b[32m[2020-06-22 21:29:40] __main__ INFO: \u001b[0mEpoch 49 Step 200/351 lr 0.001000 loss 0.3297 (0.2512) acc@1 0.8672 (0.9126) acc@5 0.9922 (0.9980)\n",
      "\u001b[32m[2020-06-22 21:29:50] __main__ INFO: \u001b[0mEpoch 49 Step 300/351 lr 0.001000 loss 0.1786 (0.2518) acc@1 0.9531 (0.9127) acc@5 1.0000 (0.9980)\n",
      "\u001b[32m[2020-06-22 21:29:54] __main__ INFO: \u001b[0mEpoch 49 Step 351/351 lr 0.001000 loss 0.2989 (0.2520) acc@1 0.8750 (0.9119) acc@5 1.0000 (0.9981)\n",
      "\u001b[32m[2020-06-22 21:29:54] __main__ INFO: \u001b[0mElapsed 32.33\n",
      "\u001b[32m[2020-06-22 21:29:54] __main__ INFO: \u001b[0mVal 49\n",
      "\u001b[32m[2020-06-22 21:29:55] __main__ INFO: \u001b[0mEpoch 49 loss 0.4847 acc@1 0.8508 acc@5 0.9932\n",
      "\u001b[32m[2020-06-22 21:29:55] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 21:29:55] __main__ INFO: \u001b[0mTrain 50 17199\n",
      "\u001b[32m[2020-06-22 21:30:05] __main__ INFO: \u001b[0mEpoch 50 Step 100/351 lr 0.001000 loss 0.4066 (0.2490) acc@1 0.8828 (0.9127) acc@5 0.9922 (0.9983)\n",
      "\u001b[32m[2020-06-22 21:30:14] __main__ INFO: \u001b[0mEpoch 50 Step 200/351 lr 0.001000 loss 0.2492 (0.2495) acc@1 0.9219 (0.9125) acc@5 1.0000 (0.9982)\n",
      "\u001b[32m[2020-06-22 21:30:23] __main__ INFO: \u001b[0mEpoch 50 Step 300/351 lr 0.001000 loss 0.1999 (0.2495) acc@1 0.9297 (0.9124) acc@5 1.0000 (0.9982)\n",
      "\u001b[32m[2020-06-22 21:30:28] __main__ INFO: \u001b[0mEpoch 50 Step 351/351 lr 0.001000 loss 0.1961 (0.2510) acc@1 0.9375 (0.9115) acc@5 1.0000 (0.9982)\n",
      "\u001b[32m[2020-06-22 21:30:28] __main__ INFO: \u001b[0mElapsed 32.33\n",
      "\u001b[32m[2020-06-22 21:30:28] __main__ INFO: \u001b[0mVal 50\n",
      "\u001b[32m[2020-06-22 21:30:29] __main__ INFO: \u001b[0mEpoch 50 loss 0.4821 acc@1 0.8538 acc@5 0.9928\n",
      "\u001b[32m[2020-06-22 21:30:29] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-06-22 21:30:29] fvcore.common.checkpoint INFO: \u001b[0mSaving checkpoint to /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00_resume400_50/checkpoint_00050.pth\n"
     ]
    }
   ],
   "source": [
    "# Resume training with the un-augmented data\n",
    "os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "#!python train.py --config configs/cifar/resnet.yaml \\\n",
    "!python train.py --config /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00/config.yaml \\\n",
    "    train.checkpoint /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00/checkpoint_00400.pth \\\n",
    "    dataset.name CIFAR10 \\\n",
    "    train.base_lr .001 \\\n",
    "    train.output_dir /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00_resume400_50 \\\n",
    "    scheduler.epochs 50\n",
    "\n",
    "#### Set LEARNING RATE based on ending LR\n",
    "#    train.resume True \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-06-22 21:51:12] __main__ INFO: \u001b[0mdevice: cuda\n",
      "cudnn:\n",
      "  benchmark: True\n",
      "  deterministic: False\n",
      "dataset:\n",
      "  name: CIFAR10\n",
      "  dataset_dir: ~/.torch/datasets/CIFAR10\n",
      "  image_size: 32\n",
      "  n_channels: 3\n",
      "  n_classes: 10\n",
      "model:\n",
      "  type: cifar\n",
      "  name: resnet\n",
      "  init_mode: kaiming_fan_out\n",
      "  vgg:\n",
      "    n_channels: [64, 128, 256, 512, 512]\n",
      "    n_layers: [2, 2, 3, 3, 3]\n",
      "    use_bn: True\n",
      "  resnet:\n",
      "    depth: 32\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "  resnet_preact:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "  wrn:\n",
      "    depth: 28\n",
      "    initial_channels: 16\n",
      "    widening_factor: 10\n",
      "    drop_rate: 0.0\n",
      "  densenet:\n",
      "    depth: 100\n",
      "    n_blocks: [6, 12, 24, 16]\n",
      "    block_type: bottleneck\n",
      "    growth_rate: 12\n",
      "    drop_rate: 0.0\n",
      "    compression_rate: 0.5\n",
      "  pyramidnet:\n",
      "    depth: 272\n",
      "    n_blocks: [3, 24, 36, 3]\n",
      "    initial_channels: 16\n",
      "    block_type: bottleneck\n",
      "    alpha: 200\n",
      "  resnext:\n",
      "    depth: 29\n",
      "    n_blocks: [3, 4, 6, 3]\n",
      "    initial_channels: 64\n",
      "    cardinality: 8\n",
      "    base_channels: 4\n",
      "  shake_shake:\n",
      "    depth: 26\n",
      "    initial_channels: 96\n",
      "    shake_forward: True\n",
      "    shake_backward: True\n",
      "    shake_image: True\n",
      "  se_resnet_preact:\n",
      "    depth: 110\n",
      "    initial_channels: 16\n",
      "    se_reduction: 16\n",
      "    block_type: basic\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "train:\n",
      "  checkpoint: /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00/checkpoint_00300.pth\n",
      "  resume: False\n",
      "  precision: O0\n",
      "  batch_size: 128\n",
      "  subdivision: 1\n",
      "  optimizer: sgd\n",
      "  base_lr: 0.001\n",
      "  momentum: 0.9\n",
      "  nesterov: True\n",
      "  weight_decay: 0.0001\n",
      "  no_weight_decay_on_bn: False\n",
      "  gradient_clip: 0\n",
      "  start_epoch: 0\n",
      "  seed: 0\n",
      "  val_first: True\n",
      "  val_period: 1\n",
      "  val_ratio: 0.1\n",
      "  use_test_as_val: False\n",
      "  output_dir: /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00_resume300_150\n",
      "  log_period: 100\n",
      "  checkpoint_period: 100\n",
      "  use_tensorboard: True\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: True\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "  distributed: False\n",
      "  dist:\n",
      "    backend: nccl\n",
      "    init_method: env://\n",
      "    world_size: -1\n",
      "    node_rank: -1\n",
      "    local_rank: 0\n",
      "    use_sync_bn: False\n",
      "tensorboard:\n",
      "  train_images: False\n",
      "  val_images: False\n",
      "  model_params: False\n",
      "optim:\n",
      "  adam:\n",
      "    betas: (0.9, 0.999)\n",
      "  lars:\n",
      "    eps: 1e-09\n",
      "    threshold: 0.01\n",
      "  adabound:\n",
      "    betas: (0.9, 0.999)\n",
      "    final_lr: 0.1\n",
      "    gamma: 0.001\n",
      "scheduler:\n",
      "  epochs: 150\n",
      "  warmup:\n",
      "    type: none\n",
      "    epochs: 0\n",
      "    start_factor: 0.001\n",
      "    exponent: 4\n",
      "  type: multistep\n",
      "  milestones: [80, 120]\n",
      "  lr_decay: 0.1\n",
      "  lr_min_factor: 0.001\n",
      "  T0: 10\n",
      "  T_mul: 1.0\n",
      "validation:\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: False\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "augmentation:\n",
      "  use_random_crop: True\n",
      "  use_random_horizontal_flip: True\n",
      "  use_cutout: False\n",
      "  use_random_erasing: False\n",
      "  use_dual_cutout: False\n",
      "  use_mixup: False\n",
      "  use_ricap: False\n",
      "  use_cutmix: False\n",
      "  use_label_smoothing: False\n",
      "  random_crop:\n",
      "    padding: 4\n",
      "    fill: 0\n",
      "    padding_mode: constant\n",
      "  random_horizontal_flip:\n",
      "    prob: 0.5\n",
      "  cutout:\n",
      "    prob: 1.0\n",
      "    mask_size: 16\n",
      "    cut_inside: False\n",
      "    mask_color: 0\n",
      "    dual_cutout_alpha: 0.1\n",
      "  random_erasing:\n",
      "    prob: 0.5\n",
      "    area_ratio_range: [0.02, 0.4]\n",
      "    min_aspect_ratio: 0.3\n",
      "    max_attempt: 20\n",
      "  mixup:\n",
      "    alpha: 1.0\n",
      "  ricap:\n",
      "    beta: 0.3\n",
      "  cutmix:\n",
      "    alpha: 1.0\n",
      "  label_smoothing:\n",
      "    epsilon: 0.1\n",
      "tta:\n",
      "  use_resize: False\n",
      "  use_center_crop: False\n",
      "  resize: 256\n",
      "test:\n",
      "  checkpoint: ''\n",
      "  output_dir: ''\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    pin_memory: False\n",
      "\u001b[32m[2020-06-22 21:51:12] __main__ INFO: \u001b[0menv_info:\n",
      "  pytorch_version: 1.4.0\n",
      "  cuda_version: 10.1\n",
      "  cudnn_version: 7603\n",
      "  num_gpus: 1\n",
      "  gpu_name: Tesla K80\n",
      "  gpu_capability: 3.7\n",
      "Files already downloaded and verified\n",
      "\u001b[32m[2020-06-22 21:51:15] __main__ INFO: \u001b[0mMACs  : 69.76M\n",
      "\u001b[32m[2020-06-22 21:51:15] __main__ INFO: \u001b[0m#params: 466.91K\n",
      "Selected optimization level O0:  Pure FP32 training.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n",
      "\u001b[32m[2020-06-22 21:51:15] __main__ INFO: \u001b[0mVal 0\n",
      "\u001b[32m[2020-06-22 21:51:16] __main__ INFO: \u001b[0mEpoch 0 loss 3.5949 acc@1 0.4784 acc@5 0.8880\n",
      "\u001b[32m[2020-06-22 21:51:16] __main__ INFO: \u001b[0mElapsed 1.43\n",
      "\u001b[32m[2020-06-22 21:51:16] __main__ INFO: \u001b[0mTrain 1 0\n",
      "\u001b[32m[2020-06-22 21:51:26] __main__ INFO: \u001b[0mEpoch 1 Step 100/351 lr 0.001000 loss 0.9270 (1.0481) acc@1 0.6797 (0.6879) acc@5 0.9453 (0.9629)\n",
      "\u001b[32m[2020-06-22 21:51:35] __main__ INFO: \u001b[0mEpoch 1 Step 200/351 lr 0.001000 loss 0.9444 (0.9139) acc@1 0.7188 (0.7175) acc@5 0.9766 (0.9716)\n",
      "\u001b[32m[2020-06-22 21:51:44] __main__ INFO: \u001b[0mEpoch 1 Step 300/351 lr 0.001000 loss 0.8472 (0.8610) acc@1 0.6875 (0.7276) acc@5 0.9609 (0.9752)\n",
      "\u001b[32m[2020-06-22 21:51:49] __main__ INFO: \u001b[0mEpoch 1 Step 351/351 lr 0.001000 loss 0.7327 (0.8382) acc@1 0.7734 (0.7325) acc@5 0.9766 (0.9765)\n",
      "\u001b[32m[2020-06-22 21:51:49] __main__ INFO: \u001b[0mElapsed 32.39\n",
      "\u001b[32m[2020-06-22 21:51:49] __main__ INFO: \u001b[0mVal 1\n",
      "\u001b[32m[2020-06-22 21:51:50] __main__ INFO: \u001b[0mEpoch 1 loss 0.7297 acc@1 0.7654 acc@5 0.9858\n",
      "\u001b[32m[2020-06-22 21:51:50] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 21:51:50] __main__ INFO: \u001b[0mTrain 2 351\n",
      "\u001b[32m[2020-06-22 21:51:59] __main__ INFO: \u001b[0mEpoch 2 Step 100/351 lr 0.001000 loss 0.6626 (0.6756) acc@1 0.7500 (0.7737) acc@5 0.9922 (0.9859)\n",
      "\u001b[32m[2020-06-22 21:52:08] __main__ INFO: \u001b[0mEpoch 2 Step 200/351 lr 0.001000 loss 0.7393 (0.6613) acc@1 0.7344 (0.7764) acc@5 0.9688 (0.9846)\n",
      "\u001b[32m[2020-06-22 21:52:17] __main__ INFO: \u001b[0mEpoch 2 Step 300/351 lr 0.001000 loss 0.5022 (0.6535) acc@1 0.8438 (0.7779) acc@5 0.9922 (0.9845)\n",
      "\u001b[32m[2020-06-22 21:52:22] __main__ INFO: \u001b[0mEpoch 2 Step 351/351 lr 0.001000 loss 0.5917 (0.6490) acc@1 0.7969 (0.7794) acc@5 0.9844 (0.9848)\n",
      "\u001b[32m[2020-06-22 21:52:22] __main__ INFO: \u001b[0mElapsed 32.19\n",
      "\u001b[32m[2020-06-22 21:52:22] __main__ INFO: \u001b[0mVal 2\n",
      "\u001b[32m[2020-06-22 21:52:23] __main__ INFO: \u001b[0mEpoch 2 loss 0.6525 acc@1 0.7834 acc@5 0.9874\n",
      "\u001b[32m[2020-06-22 21:52:23] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 21:52:23] __main__ INFO: \u001b[0mTrain 3 702\n",
      "\u001b[32m[2020-06-22 21:52:32] __main__ INFO: \u001b[0mEpoch 3 Step 100/351 lr 0.001000 loss 0.6452 (0.5928) acc@1 0.7500 (0.7963) acc@5 0.9766 (0.9884)\n",
      "\u001b[32m[2020-06-22 21:52:42] __main__ INFO: \u001b[0mEpoch 3 Step 200/351 lr 0.001000 loss 0.5680 (0.5956) acc@1 0.7891 (0.7931) acc@5 1.0000 (0.9885)\n",
      "\u001b[32m[2020-06-22 21:52:51] __main__ INFO: \u001b[0mEpoch 3 Step 300/351 lr 0.001000 loss 0.4652 (0.5983) acc@1 0.8594 (0.7939) acc@5 0.9766 (0.9884)\n",
      "\u001b[32m[2020-06-22 21:52:55] __main__ INFO: \u001b[0mEpoch 3 Step 351/351 lr 0.001000 loss 0.5590 (0.5986) acc@1 0.8125 (0.7936) acc@5 0.9922 (0.9885)\n",
      "\u001b[32m[2020-06-22 21:52:55] __main__ INFO: \u001b[0mElapsed 32.27\n",
      "\u001b[32m[2020-06-22 21:52:55] __main__ INFO: \u001b[0mVal 3\n",
      "\u001b[32m[2020-06-22 21:52:56] __main__ INFO: \u001b[0mEpoch 3 loss 0.6271 acc@1 0.7906 acc@5 0.9884\n",
      "\u001b[32m[2020-06-22 21:52:56] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 21:52:56] __main__ INFO: \u001b[0mTrain 4 1053\n",
      "\u001b[32m[2020-06-22 21:53:06] __main__ INFO: \u001b[0mEpoch 4 Step 100/351 lr 0.001000 loss 0.4786 (0.5662) acc@1 0.8672 (0.8037) acc@5 0.9844 (0.9892)\n",
      "\u001b[32m[2020-06-22 21:53:15] __main__ INFO: \u001b[0mEpoch 4 Step 200/351 lr 0.001000 loss 0.5665 (0.5708) acc@1 0.8203 (0.8022) acc@5 0.9766 (0.9888)\n",
      "\u001b[32m[2020-06-22 21:53:24] __main__ INFO: \u001b[0mEpoch 4 Step 300/351 lr 0.001000 loss 0.5569 (0.5677) acc@1 0.7891 (0.8043) acc@5 0.9922 (0.9894)\n",
      "\u001b[32m[2020-06-22 21:53:29] __main__ INFO: \u001b[0mEpoch 4 Step 351/351 lr 0.001000 loss 0.4568 (0.5672) acc@1 0.8125 (0.8049) acc@5 1.0000 (0.9897)\n",
      "\u001b[32m[2020-06-22 21:53:29] __main__ INFO: \u001b[0mElapsed 32.42\n",
      "\u001b[32m[2020-06-22 21:53:29] __main__ INFO: \u001b[0mVal 4\n",
      "\u001b[32m[2020-06-22 21:53:30] __main__ INFO: \u001b[0mEpoch 4 loss 0.6082 acc@1 0.7966 acc@5 0.9876\n",
      "\u001b[32m[2020-06-22 21:53:30] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 21:53:30] __main__ INFO: \u001b[0mTrain 5 1404\n",
      "\u001b[32m[2020-06-22 21:53:39] __main__ INFO: \u001b[0mEpoch 5 Step 100/351 lr 0.001000 loss 0.4856 (0.5484) acc@1 0.8359 (0.8076) acc@5 1.0000 (0.9891)\n",
      "\u001b[32m[2020-06-22 21:53:49] __main__ INFO: \u001b[0mEpoch 5 Step 200/351 lr 0.001000 loss 0.5935 (0.5459) acc@1 0.7969 (0.8084) acc@5 1.0000 (0.9897)\n",
      "\u001b[32m[2020-06-22 21:53:58] __main__ INFO: \u001b[0mEpoch 5 Step 300/351 lr 0.001000 loss 0.5472 (0.5448) acc@1 0.8281 (0.8096) acc@5 1.0000 (0.9899)\n",
      "\u001b[32m[2020-06-22 21:54:02] __main__ INFO: \u001b[0mEpoch 5 Step 351/351 lr 0.001000 loss 0.4616 (0.5449) acc@1 0.8359 (0.8094) acc@5 1.0000 (0.9899)\n",
      "\u001b[32m[2020-06-22 21:54:03] __main__ INFO: \u001b[0mElapsed 32.56\n",
      "\u001b[32m[2020-06-22 21:54:03] __main__ INFO: \u001b[0mVal 5\n",
      "\u001b[32m[2020-06-22 21:54:04] __main__ INFO: \u001b[0mEpoch 5 loss 0.5901 acc@1 0.7998 acc@5 0.9886\n",
      "\u001b[32m[2020-06-22 21:54:04] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-22 21:54:04] __main__ INFO: \u001b[0mTrain 6 1755\n",
      "\u001b[32m[2020-06-22 21:54:13] __main__ INFO: \u001b[0mEpoch 6 Step 100/351 lr 0.001000 loss 0.5385 (0.5276) acc@1 0.8359 (0.8153) acc@5 0.9922 (0.9902)\n",
      "\u001b[32m[2020-06-22 21:54:22] __main__ INFO: \u001b[0mEpoch 6 Step 200/351 lr 0.001000 loss 0.4637 (0.5292) acc@1 0.8438 (0.8155) acc@5 0.9922 (0.9906)\n",
      "\u001b[32m[2020-06-22 21:54:31] __main__ INFO: \u001b[0mEpoch 6 Step 300/351 lr 0.001000 loss 0.4158 (0.5279) acc@1 0.8359 (0.8166) acc@5 0.9844 (0.9907)\n",
      "\u001b[32m[2020-06-22 21:54:36] __main__ INFO: \u001b[0mEpoch 6 Step 351/351 lr 0.001000 loss 0.5703 (0.5301) acc@1 0.7891 (0.8150) acc@5 1.0000 (0.9906)\n",
      "\u001b[32m[2020-06-22 21:54:36] __main__ INFO: \u001b[0mElapsed 32.53\n",
      "\u001b[32m[2020-06-22 21:54:36] __main__ INFO: \u001b[0mVal 6\n",
      "\u001b[32m[2020-06-22 21:54:37] __main__ INFO: \u001b[0mEpoch 6 loss 0.5810 acc@1 0.8058 acc@5 0.9898\n",
      "\u001b[32m[2020-06-22 21:54:37] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 21:54:37] __main__ INFO: \u001b[0mTrain 7 2106\n",
      "\u001b[32m[2020-06-22 21:54:47] __main__ INFO: \u001b[0mEpoch 7 Step 100/351 lr 0.001000 loss 0.5480 (0.5011) acc@1 0.7812 (0.8268) acc@5 0.9922 (0.9933)\n",
      "\u001b[32m[2020-06-22 21:54:56] __main__ INFO: \u001b[0mEpoch 7 Step 200/351 lr 0.001000 loss 0.5042 (0.5081) acc@1 0.8594 (0.8247) acc@5 0.9844 (0.9918)\n",
      "\u001b[32m[2020-06-22 21:55:05] __main__ INFO: \u001b[0mEpoch 7 Step 300/351 lr 0.001000 loss 0.4720 (0.5091) acc@1 0.8281 (0.8246) acc@5 0.9844 (0.9913)\n",
      "\u001b[32m[2020-06-22 21:55:10] __main__ INFO: \u001b[0mEpoch 7 Step 351/351 lr 0.001000 loss 0.3999 (0.5125) acc@1 0.8359 (0.8229) acc@5 1.0000 (0.9910)\n",
      "\u001b[32m[2020-06-22 21:55:10] __main__ INFO: \u001b[0mElapsed 32.46\n",
      "\u001b[32m[2020-06-22 21:55:10] __main__ INFO: \u001b[0mVal 7\n",
      "\u001b[32m[2020-06-22 21:55:11] __main__ INFO: \u001b[0mEpoch 7 loss 0.5705 acc@1 0.8068 acc@5 0.9890\n",
      "\u001b[32m[2020-06-22 21:55:11] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-22 21:55:11] __main__ INFO: \u001b[0mTrain 8 2457\n",
      "\u001b[32m[2020-06-22 21:55:20] __main__ INFO: \u001b[0mEpoch 8 Step 100/351 lr 0.001000 loss 0.4321 (0.4982) acc@1 0.8672 (0.8288) acc@5 0.9922 (0.9912)\n",
      "\u001b[32m[2020-06-22 21:55:29] __main__ INFO: \u001b[0mEpoch 8 Step 200/351 lr 0.001000 loss 0.4041 (0.4951) acc@1 0.8828 (0.8310) acc@5 0.9922 (0.9916)\n",
      "\u001b[32m[2020-06-22 21:55:38] __main__ INFO: \u001b[0mEpoch 8 Step 300/351 lr 0.001000 loss 0.5838 (0.4976) acc@1 0.7969 (0.8279) acc@5 0.9844 (0.9917)\n",
      "\u001b[32m[2020-06-22 21:55:43] __main__ INFO: \u001b[0mEpoch 8 Step 351/351 lr 0.001000 loss 0.5096 (0.5011) acc@1 0.8359 (0.8263) acc@5 0.9844 (0.9914)\n",
      "\u001b[32m[2020-06-22 21:55:43] __main__ INFO: \u001b[0mElapsed 32.40\n",
      "\u001b[32m[2020-06-22 21:55:43] __main__ INFO: \u001b[0mVal 8\n",
      "\u001b[32m[2020-06-22 21:55:44] __main__ INFO: \u001b[0mEpoch 8 loss 0.5587 acc@1 0.8116 acc@5 0.9906\n",
      "\u001b[32m[2020-06-22 21:55:44] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 21:55:44] __main__ INFO: \u001b[0mTrain 9 2808\n",
      "\u001b[32m[2020-06-22 21:55:54] __main__ INFO: \u001b[0mEpoch 9 Step 100/351 lr 0.001000 loss 0.5608 (0.4968) acc@1 0.8125 (0.8273) acc@5 0.9922 (0.9923)\n",
      "\u001b[32m[2020-06-22 21:56:03] __main__ INFO: \u001b[0mEpoch 9 Step 200/351 lr 0.001000 loss 0.4486 (0.4861) acc@1 0.8281 (0.8309) acc@5 1.0000 (0.9927)\n",
      "\u001b[32m[2020-06-22 21:56:12] __main__ INFO: \u001b[0mEpoch 9 Step 300/351 lr 0.001000 loss 0.5139 (0.4867) acc@1 0.8203 (0.8307) acc@5 1.0000 (0.9924)\n",
      "\u001b[32m[2020-06-22 21:56:17] __main__ INFO: \u001b[0mEpoch 9 Step 351/351 lr 0.001000 loss 0.4577 (0.4861) acc@1 0.8438 (0.8308) acc@5 1.0000 (0.9925)\n",
      "\u001b[32m[2020-06-22 21:56:17] __main__ INFO: \u001b[0mElapsed 32.45\n",
      "\u001b[32m[2020-06-22 21:56:17] __main__ INFO: \u001b[0mVal 9\n",
      "\u001b[32m[2020-06-22 21:56:18] __main__ INFO: \u001b[0mEpoch 9 loss 0.5523 acc@1 0.8174 acc@5 0.9896\n",
      "\u001b[32m[2020-06-22 21:56:18] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 21:56:18] __main__ INFO: \u001b[0mTrain 10 3159\n",
      "\u001b[32m[2020-06-22 21:56:27] __main__ INFO: \u001b[0mEpoch 10 Step 100/351 lr 0.001000 loss 0.3344 (0.4639) acc@1 0.8984 (0.8384) acc@5 0.9922 (0.9938)\n",
      "\u001b[32m[2020-06-22 21:56:36] __main__ INFO: \u001b[0mEpoch 10 Step 200/351 lr 0.001000 loss 0.5461 (0.4738) acc@1 0.8203 (0.8349) acc@5 1.0000 (0.9930)\n",
      "\u001b[32m[2020-06-22 21:56:45] __main__ INFO: \u001b[0mEpoch 10 Step 300/351 lr 0.001000 loss 0.3892 (0.4774) acc@1 0.8594 (0.8342) acc@5 1.0000 (0.9922)\n",
      "\u001b[32m[2020-06-22 21:56:50] __main__ INFO: \u001b[0mEpoch 10 Step 351/351 lr 0.001000 loss 0.4629 (0.4760) acc@1 0.8516 (0.8340) acc@5 0.9922 (0.9923)\n",
      "\u001b[32m[2020-06-22 21:56:50] __main__ INFO: \u001b[0mElapsed 32.41\n",
      "\u001b[32m[2020-06-22 21:56:50] __main__ INFO: \u001b[0mVal 10\n",
      "\u001b[32m[2020-06-22 21:56:51] __main__ INFO: \u001b[0mEpoch 10 loss 0.5407 acc@1 0.8184 acc@5 0.9902\n",
      "\u001b[32m[2020-06-22 21:56:51] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 21:56:51] __main__ INFO: \u001b[0mTrain 11 3510\n",
      "\u001b[32m[2020-06-22 21:57:01] __main__ INFO: \u001b[0mEpoch 11 Step 100/351 lr 0.001000 loss 0.4240 (0.4732) acc@1 0.8516 (0.8367) acc@5 1.0000 (0.9912)\n",
      "\u001b[32m[2020-06-22 21:57:10] __main__ INFO: \u001b[0mEpoch 11 Step 200/351 lr 0.001000 loss 0.5824 (0.4736) acc@1 0.7891 (0.8370) acc@5 1.0000 (0.9925)\n",
      "\u001b[32m[2020-06-22 21:57:19] __main__ INFO: \u001b[0mEpoch 11 Step 300/351 lr 0.001000 loss 0.6785 (0.4705) acc@1 0.7656 (0.8380) acc@5 1.0000 (0.9926)\n",
      "\u001b[32m[2020-06-22 21:57:24] __main__ INFO: \u001b[0mEpoch 11 Step 351/351 lr 0.001000 loss 0.5178 (0.4694) acc@1 0.7969 (0.8384) acc@5 0.9922 (0.9927)\n",
      "\u001b[32m[2020-06-22 21:57:24] __main__ INFO: \u001b[0mElapsed 32.42\n",
      "\u001b[32m[2020-06-22 21:57:24] __main__ INFO: \u001b[0mVal 11\n",
      "\u001b[32m[2020-06-22 21:57:25] __main__ INFO: \u001b[0mEpoch 11 loss 0.5375 acc@1 0.8186 acc@5 0.9906\n",
      "\u001b[32m[2020-06-22 21:57:25] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 21:57:25] __main__ INFO: \u001b[0mTrain 12 3861\n",
      "\u001b[32m[2020-06-22 21:57:34] __main__ INFO: \u001b[0mEpoch 12 Step 100/351 lr 0.001000 loss 0.5720 (0.4652) acc@1 0.8047 (0.8398) acc@5 0.9844 (0.9927)\n",
      "\u001b[32m[2020-06-22 21:57:43] __main__ INFO: \u001b[0mEpoch 12 Step 200/351 lr 0.001000 loss 0.5974 (0.4627) acc@1 0.7891 (0.8390) acc@5 0.9922 (0.9933)\n",
      "\u001b[32m[2020-06-22 21:57:52] __main__ INFO: \u001b[0mEpoch 12 Step 300/351 lr 0.001000 loss 0.4108 (0.4607) acc@1 0.8906 (0.8400) acc@5 0.9922 (0.9929)\n",
      "\u001b[32m[2020-06-22 21:57:57] __main__ INFO: \u001b[0mEpoch 12 Step 351/351 lr 0.001000 loss 0.4731 (0.4575) acc@1 0.8594 (0.8402) acc@5 1.0000 (0.9931)\n",
      "\u001b[32m[2020-06-22 21:57:57] __main__ INFO: \u001b[0mElapsed 32.48\n",
      "\u001b[32m[2020-06-22 21:57:57] __main__ INFO: \u001b[0mVal 12\n",
      "\u001b[32m[2020-06-22 21:57:58] __main__ INFO: \u001b[0mEpoch 12 loss 0.5293 acc@1 0.8246 acc@5 0.9896\n",
      "\u001b[32m[2020-06-22 21:57:58] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 21:57:58] __main__ INFO: \u001b[0mTrain 13 4212\n",
      "\u001b[32m[2020-06-22 21:58:08] __main__ INFO: \u001b[0mEpoch 13 Step 100/351 lr 0.001000 loss 0.5570 (0.4407) acc@1 0.8203 (0.8456) acc@5 0.9844 (0.9931)\n",
      "\u001b[32m[2020-06-22 21:58:17] __main__ INFO: \u001b[0mEpoch 13 Step 200/351 lr 0.001000 loss 0.4207 (0.4437) acc@1 0.8594 (0.8443) acc@5 1.0000 (0.9929)\n",
      "\u001b[32m[2020-06-22 21:58:26] __main__ INFO: \u001b[0mEpoch 13 Step 300/351 lr 0.001000 loss 0.3108 (0.4457) acc@1 0.8984 (0.8440) acc@5 1.0000 (0.9929)\n",
      "\u001b[32m[2020-06-22 21:58:31] __main__ INFO: \u001b[0mEpoch 13 Step 351/351 lr 0.001000 loss 0.3999 (0.4477) acc@1 0.8672 (0.8438) acc@5 1.0000 (0.9926)\n",
      "\u001b[32m[2020-06-22 21:58:31] __main__ INFO: \u001b[0mElapsed 32.39\n",
      "\u001b[32m[2020-06-22 21:58:31] __main__ INFO: \u001b[0mVal 13\n",
      "\u001b[32m[2020-06-22 21:58:32] __main__ INFO: \u001b[0mEpoch 13 loss 0.5237 acc@1 0.8280 acc@5 0.9906\n",
      "\u001b[32m[2020-06-22 21:58:32] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 21:58:32] __main__ INFO: \u001b[0mTrain 14 4563\n",
      "\u001b[32m[2020-06-22 21:58:41] __main__ INFO: \u001b[0mEpoch 14 Step 100/351 lr 0.001000 loss 0.4663 (0.4423) acc@1 0.8203 (0.8471) acc@5 0.9922 (0.9928)\n",
      "\u001b[32m[2020-06-22 21:58:50] __main__ INFO: \u001b[0mEpoch 14 Step 200/351 lr 0.001000 loss 0.3106 (0.4424) acc@1 0.9062 (0.8452) acc@5 1.0000 (0.9929)\n",
      "\u001b[32m[2020-06-22 21:58:59] __main__ INFO: \u001b[0mEpoch 14 Step 300/351 lr 0.001000 loss 0.4615 (0.4400) acc@1 0.8359 (0.8458) acc@5 0.9922 (0.9933)\n",
      "\u001b[32m[2020-06-22 21:59:04] __main__ INFO: \u001b[0mEpoch 14 Step 351/351 lr 0.001000 loss 0.4738 (0.4390) acc@1 0.8125 (0.8470) acc@5 1.0000 (0.9933)\n",
      "\u001b[32m[2020-06-22 21:59:04] __main__ INFO: \u001b[0mElapsed 32.44\n",
      "\u001b[32m[2020-06-22 21:59:04] __main__ INFO: \u001b[0mVal 14\n",
      "\u001b[32m[2020-06-22 21:59:05] __main__ INFO: \u001b[0mEpoch 14 loss 0.5194 acc@1 0.8260 acc@5 0.9898\n",
      "\u001b[32m[2020-06-22 21:59:05] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 21:59:05] __main__ INFO: \u001b[0mTrain 15 4914\n",
      "\u001b[32m[2020-06-22 21:59:15] __main__ INFO: \u001b[0mEpoch 15 Step 100/351 lr 0.001000 loss 0.4101 (0.4357) acc@1 0.8359 (0.8498) acc@5 0.9922 (0.9939)\n",
      "\u001b[32m[2020-06-22 21:59:24] __main__ INFO: \u001b[0mEpoch 15 Step 200/351 lr 0.001000 loss 0.5093 (0.4331) acc@1 0.8203 (0.8510) acc@5 0.9844 (0.9937)\n",
      "\u001b[32m[2020-06-22 21:59:33] __main__ INFO: \u001b[0mEpoch 15 Step 300/351 lr 0.001000 loss 0.4781 (0.4337) acc@1 0.8359 (0.8496) acc@5 0.9922 (0.9937)\n",
      "\u001b[32m[2020-06-22 21:59:38] __main__ INFO: \u001b[0mEpoch 15 Step 351/351 lr 0.001000 loss 0.4499 (0.4336) acc@1 0.8438 (0.8493) acc@5 1.0000 (0.9935)\n",
      "\u001b[32m[2020-06-22 21:59:38] __main__ INFO: \u001b[0mElapsed 32.43\n",
      "\u001b[32m[2020-06-22 21:59:38] __main__ INFO: \u001b[0mVal 15\n",
      "\u001b[32m[2020-06-22 21:59:39] __main__ INFO: \u001b[0mEpoch 15 loss 0.5195 acc@1 0.8266 acc@5 0.9906\n",
      "\u001b[32m[2020-06-22 21:59:39] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 21:59:39] __main__ INFO: \u001b[0mTrain 16 5265\n",
      "\u001b[32m[2020-06-22 21:59:48] __main__ INFO: \u001b[0mEpoch 16 Step 100/351 lr 0.001000 loss 0.4891 (0.4273) acc@1 0.7969 (0.8509) acc@5 0.9922 (0.9937)\n",
      "\u001b[32m[2020-06-22 21:59:57] __main__ INFO: \u001b[0mEpoch 16 Step 200/351 lr 0.001000 loss 0.4116 (0.4273) acc@1 0.8594 (0.8504) acc@5 1.0000 (0.9934)\n",
      "\u001b[32m[2020-06-22 22:00:06] __main__ INFO: \u001b[0mEpoch 16 Step 300/351 lr 0.001000 loss 0.4963 (0.4239) acc@1 0.7969 (0.8514) acc@5 1.0000 (0.9941)\n",
      "\u001b[32m[2020-06-22 22:00:11] __main__ INFO: \u001b[0mEpoch 16 Step 351/351 lr 0.001000 loss 0.3851 (0.4253) acc@1 0.8594 (0.8508) acc@5 0.9922 (0.9941)\n",
      "\u001b[32m[2020-06-22 22:00:11] __main__ INFO: \u001b[0mElapsed 32.39\n",
      "\u001b[32m[2020-06-22 22:00:11] __main__ INFO: \u001b[0mVal 16\n",
      "\u001b[32m[2020-06-22 22:00:12] __main__ INFO: \u001b[0mEpoch 16 loss 0.5141 acc@1 0.8298 acc@5 0.9908\n",
      "\u001b[32m[2020-06-22 22:00:12] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 22:00:12] __main__ INFO: \u001b[0mTrain 17 5616\n",
      "\u001b[32m[2020-06-22 22:00:21] __main__ INFO: \u001b[0mEpoch 17 Step 100/351 lr 0.001000 loss 0.4224 (0.4270) acc@1 0.8594 (0.8522) acc@5 1.0000 (0.9943)\n",
      "\u001b[32m[2020-06-22 22:00:31] __main__ INFO: \u001b[0mEpoch 17 Step 200/351 lr 0.001000 loss 0.5684 (0.4206) acc@1 0.7891 (0.8536) acc@5 0.9844 (0.9945)\n",
      "\u001b[32m[2020-06-22 22:00:40] __main__ INFO: \u001b[0mEpoch 17 Step 300/351 lr 0.001000 loss 0.3866 (0.4179) acc@1 0.8828 (0.8550) acc@5 0.9922 (0.9942)\n",
      "\u001b[32m[2020-06-22 22:00:45] __main__ INFO: \u001b[0mEpoch 17 Step 351/351 lr 0.001000 loss 0.3513 (0.4175) acc@1 0.8594 (0.8553) acc@5 1.0000 (0.9941)\n",
      "\u001b[32m[2020-06-22 22:00:45] __main__ INFO: \u001b[0mElapsed 32.44\n",
      "\u001b[32m[2020-06-22 22:00:45] __main__ INFO: \u001b[0mVal 17\n",
      "\u001b[32m[2020-06-22 22:00:46] __main__ INFO: \u001b[0mEpoch 17 loss 0.5141 acc@1 0.8310 acc@5 0.9912\n",
      "\u001b[32m[2020-06-22 22:00:46] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 22:00:46] __main__ INFO: \u001b[0mTrain 18 5967\n",
      "\u001b[32m[2020-06-22 22:00:55] __main__ INFO: \u001b[0mEpoch 18 Step 100/351 lr 0.001000 loss 0.6402 (0.4229) acc@1 0.7734 (0.8539) acc@5 0.9922 (0.9948)\n",
      "\u001b[32m[2020-06-22 22:01:04] __main__ INFO: \u001b[0mEpoch 18 Step 200/351 lr 0.001000 loss 0.5370 (0.4157) acc@1 0.8281 (0.8543) acc@5 0.9844 (0.9948)\n",
      "\u001b[32m[2020-06-22 22:01:13] __main__ INFO: \u001b[0mEpoch 18 Step 300/351 lr 0.001000 loss 0.4336 (0.4147) acc@1 0.8672 (0.8557) acc@5 1.0000 (0.9945)\n",
      "\u001b[32m[2020-06-22 22:01:18] __main__ INFO: \u001b[0mEpoch 18 Step 351/351 lr 0.001000 loss 0.4354 (0.4128) acc@1 0.8516 (0.8563) acc@5 0.9922 (0.9944)\n",
      "\u001b[32m[2020-06-22 22:01:18] __main__ INFO: \u001b[0mElapsed 32.35\n",
      "\u001b[32m[2020-06-22 22:01:18] __main__ INFO: \u001b[0mVal 18\n",
      "\u001b[32m[2020-06-22 22:01:19] __main__ INFO: \u001b[0mEpoch 18 loss 0.5040 acc@1 0.8340 acc@5 0.9914\n",
      "\u001b[32m[2020-06-22 22:01:19] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 22:01:19] __main__ INFO: \u001b[0mTrain 19 6318\n",
      "\u001b[32m[2020-06-22 22:01:28] __main__ INFO: \u001b[0mEpoch 19 Step 100/351 lr 0.001000 loss 0.4006 (0.4110) acc@1 0.9062 (0.8595) acc@5 1.0000 (0.9945)\n",
      "\u001b[32m[2020-06-22 22:01:38] __main__ INFO: \u001b[0mEpoch 19 Step 200/351 lr 0.001000 loss 0.4607 (0.4076) acc@1 0.8359 (0.8584) acc@5 0.9922 (0.9941)\n",
      "\u001b[32m[2020-06-22 22:01:47] __main__ INFO: \u001b[0mEpoch 19 Step 300/351 lr 0.001000 loss 0.5122 (0.4058) acc@1 0.8359 (0.8590) acc@5 0.9922 (0.9940)\n",
      "\u001b[32m[2020-06-22 22:01:52] __main__ INFO: \u001b[0mEpoch 19 Step 351/351 lr 0.001000 loss 0.4560 (0.4057) acc@1 0.8203 (0.8587) acc@5 0.9766 (0.9939)\n",
      "\u001b[32m[2020-06-22 22:01:52] __main__ INFO: \u001b[0mElapsed 32.44\n",
      "\u001b[32m[2020-06-22 22:01:52] __main__ INFO: \u001b[0mVal 19\n",
      "\u001b[32m[2020-06-22 22:01:53] __main__ INFO: \u001b[0mEpoch 19 loss 0.4995 acc@1 0.8356 acc@5 0.9918\n",
      "\u001b[32m[2020-06-22 22:01:53] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 22:01:53] __main__ INFO: \u001b[0mTrain 20 6669\n",
      "\u001b[32m[2020-06-22 22:02:02] __main__ INFO: \u001b[0mEpoch 20 Step 100/351 lr 0.001000 loss 0.3347 (0.3908) acc@1 0.8750 (0.8620) acc@5 0.9844 (0.9949)\n",
      "\u001b[32m[2020-06-22 22:02:11] __main__ INFO: \u001b[0mEpoch 20 Step 200/351 lr 0.001000 loss 0.4482 (0.3945) acc@1 0.8438 (0.8614) acc@5 0.9844 (0.9948)\n",
      "\u001b[32m[2020-06-22 22:02:20] __main__ INFO: \u001b[0mEpoch 20 Step 300/351 lr 0.001000 loss 0.4711 (0.3959) acc@1 0.8438 (0.8619) acc@5 1.0000 (0.9948)\n",
      "\u001b[32m[2020-06-22 22:02:25] __main__ INFO: \u001b[0mEpoch 20 Step 351/351 lr 0.001000 loss 0.3480 (0.3958) acc@1 0.8828 (0.8614) acc@5 0.9922 (0.9947)\n",
      "\u001b[32m[2020-06-22 22:02:25] __main__ INFO: \u001b[0mElapsed 32.39\n",
      "\u001b[32m[2020-06-22 22:02:25] __main__ INFO: \u001b[0mVal 20\n",
      "\u001b[32m[2020-06-22 22:02:26] __main__ INFO: \u001b[0mEpoch 20 loss 0.4985 acc@1 0.8304 acc@5 0.9914\n",
      "\u001b[32m[2020-06-22 22:02:26] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 22:02:26] __main__ INFO: \u001b[0mTrain 21 7020\n",
      "\u001b[32m[2020-06-22 22:02:35] __main__ INFO: \u001b[0mEpoch 21 Step 100/351 lr 0.001000 loss 0.4834 (0.3884) acc@1 0.8359 (0.8666) acc@5 0.9922 (0.9948)\n",
      "\u001b[32m[2020-06-22 22:02:45] __main__ INFO: \u001b[0mEpoch 21 Step 200/351 lr 0.001000 loss 0.4962 (0.3907) acc@1 0.8125 (0.8639) acc@5 1.0000 (0.9952)\n",
      "\u001b[32m[2020-06-22 22:02:54] __main__ INFO: \u001b[0mEpoch 21 Step 300/351 lr 0.001000 loss 0.3912 (0.3924) acc@1 0.8672 (0.8628) acc@5 0.9922 (0.9949)\n",
      "\u001b[32m[2020-06-22 22:02:58] __main__ INFO: \u001b[0mEpoch 21 Step 351/351 lr 0.001000 loss 0.4228 (0.3928) acc@1 0.8438 (0.8623) acc@5 0.9922 (0.9950)\n",
      "\u001b[32m[2020-06-22 22:02:58] __main__ INFO: \u001b[0mElapsed 32.40\n",
      "\u001b[32m[2020-06-22 22:02:58] __main__ INFO: \u001b[0mVal 21\n",
      "\u001b[32m[2020-06-22 22:02:59] __main__ INFO: \u001b[0mEpoch 21 loss 0.4949 acc@1 0.8354 acc@5 0.9914\n",
      "\u001b[32m[2020-06-22 22:03:00] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 22:03:00] __main__ INFO: \u001b[0mTrain 22 7371\n",
      "\u001b[32m[2020-06-22 22:03:09] __main__ INFO: \u001b[0mEpoch 22 Step 100/351 lr 0.001000 loss 0.3290 (0.3810) acc@1 0.9141 (0.8641) acc@5 0.9922 (0.9959)\n",
      "\u001b[32m[2020-06-22 22:03:18] __main__ INFO: \u001b[0mEpoch 22 Step 200/351 lr 0.001000 loss 0.4675 (0.3862) acc@1 0.8281 (0.8641) acc@5 0.9922 (0.9956)\n",
      "\u001b[32m[2020-06-22 22:03:27] __main__ INFO: \u001b[0mEpoch 22 Step 300/351 lr 0.001000 loss 0.2557 (0.3878) acc@1 0.9219 (0.8632) acc@5 1.0000 (0.9955)\n",
      "\u001b[32m[2020-06-22 22:03:32] __main__ INFO: \u001b[0mEpoch 22 Step 351/351 lr 0.001000 loss 0.4463 (0.3849) acc@1 0.8828 (0.8640) acc@5 0.9922 (0.9955)\n",
      "\u001b[32m[2020-06-22 22:03:32] __main__ INFO: \u001b[0mElapsed 32.46\n",
      "\u001b[32m[2020-06-22 22:03:32] __main__ INFO: \u001b[0mVal 22\n",
      "\u001b[32m[2020-06-22 22:03:33] __main__ INFO: \u001b[0mEpoch 22 loss 0.4918 acc@1 0.8370 acc@5 0.9916\n",
      "\u001b[32m[2020-06-22 22:03:33] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 22:03:33] __main__ INFO: \u001b[0mTrain 23 7722\n",
      "\u001b[32m[2020-06-22 22:03:42] __main__ INFO: \u001b[0mEpoch 23 Step 100/351 lr 0.001000 loss 0.2943 (0.3887) acc@1 0.8906 (0.8626) acc@5 1.0000 (0.9954)\n",
      "\u001b[32m[2020-06-22 22:03:52] __main__ INFO: \u001b[0mEpoch 23 Step 200/351 lr 0.001000 loss 0.3236 (0.3857) acc@1 0.8906 (0.8650) acc@5 1.0000 (0.9950)\n",
      "\u001b[32m[2020-06-22 22:04:01] __main__ INFO: \u001b[0mEpoch 23 Step 300/351 lr 0.001000 loss 0.4174 (0.3797) acc@1 0.8594 (0.8676) acc@5 1.0000 (0.9952)\n",
      "\u001b[32m[2020-06-22 22:04:05] __main__ INFO: \u001b[0mEpoch 23 Step 351/351 lr 0.001000 loss 0.5239 (0.3776) acc@1 0.8359 (0.8684) acc@5 0.9844 (0.9953)\n",
      "\u001b[32m[2020-06-22 22:04:05] __main__ INFO: \u001b[0mElapsed 32.41\n",
      "\u001b[32m[2020-06-22 22:04:05] __main__ INFO: \u001b[0mVal 23\n",
      "\u001b[32m[2020-06-22 22:04:07] __main__ INFO: \u001b[0mEpoch 23 loss 0.4922 acc@1 0.8362 acc@5 0.9924\n",
      "\u001b[32m[2020-06-22 22:04:07] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-06-22 22:04:07] __main__ INFO: \u001b[0mTrain 24 8073\n",
      "\u001b[32m[2020-06-22 22:04:16] __main__ INFO: \u001b[0mEpoch 24 Step 100/351 lr 0.001000 loss 0.3177 (0.3800) acc@1 0.8672 (0.8660) acc@5 1.0000 (0.9962)\n",
      "\u001b[32m[2020-06-22 22:04:25] __main__ INFO: \u001b[0mEpoch 24 Step 200/351 lr 0.001000 loss 0.3261 (0.3769) acc@1 0.8906 (0.8675) acc@5 1.0000 (0.9957)\n",
      "\u001b[32m[2020-06-22 22:04:34] __main__ INFO: \u001b[0mEpoch 24 Step 300/351 lr 0.001000 loss 0.4108 (0.3752) acc@1 0.8516 (0.8681) acc@5 0.9922 (0.9957)\n",
      "\u001b[32m[2020-06-22 22:04:39] __main__ INFO: \u001b[0mEpoch 24 Step 351/351 lr 0.001000 loss 0.2460 (0.3750) acc@1 0.9219 (0.8684) acc@5 1.0000 (0.9956)\n",
      "\u001b[32m[2020-06-22 22:04:39] __main__ INFO: \u001b[0mElapsed 32.38\n",
      "\u001b[32m[2020-06-22 22:04:39] __main__ INFO: \u001b[0mVal 24\n",
      "\u001b[32m[2020-06-22 22:04:40] __main__ INFO: \u001b[0mEpoch 24 loss 0.4874 acc@1 0.8416 acc@5 0.9918\n",
      "\u001b[32m[2020-06-22 22:04:40] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 22:04:40] __main__ INFO: \u001b[0mTrain 25 8424\n",
      "\u001b[32m[2020-06-22 22:04:49] __main__ INFO: \u001b[0mEpoch 25 Step 100/351 lr 0.001000 loss 0.2561 (0.3686) acc@1 0.8750 (0.8670) acc@5 1.0000 (0.9961)\n",
      "\u001b[32m[2020-06-22 22:04:59] __main__ INFO: \u001b[0mEpoch 25 Step 200/351 lr 0.001000 loss 0.3168 (0.3748) acc@1 0.8828 (0.8669) acc@5 1.0000 (0.9953)\n",
      "\u001b[32m[2020-06-22 22:05:08] __main__ INFO: \u001b[0mEpoch 25 Step 300/351 lr 0.001000 loss 0.4091 (0.3734) acc@1 0.8594 (0.8676) acc@5 1.0000 (0.9953)\n",
      "\u001b[32m[2020-06-22 22:05:12] __main__ INFO: \u001b[0mEpoch 25 Step 351/351 lr 0.001000 loss 0.3083 (0.3721) acc@1 0.9141 (0.8683) acc@5 0.9766 (0.9951)\n",
      "\u001b[32m[2020-06-22 22:05:12] __main__ INFO: \u001b[0mElapsed 32.45\n",
      "\u001b[32m[2020-06-22 22:05:12] __main__ INFO: \u001b[0mVal 25\n",
      "\u001b[32m[2020-06-22 22:05:14] __main__ INFO: \u001b[0mEpoch 25 loss 0.4888 acc@1 0.8418 acc@5 0.9930\n",
      "\u001b[32m[2020-06-22 22:05:14] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 22:05:14] __main__ INFO: \u001b[0mTrain 26 8775\n",
      "\u001b[32m[2020-06-22 22:05:23] __main__ INFO: \u001b[0mEpoch 26 Step 100/351 lr 0.001000 loss 0.3460 (0.3640) acc@1 0.8906 (0.8703) acc@5 1.0000 (0.9964)\n",
      "\u001b[32m[2020-06-22 22:05:32] __main__ INFO: \u001b[0mEpoch 26 Step 200/351 lr 0.001000 loss 0.3322 (0.3639) acc@1 0.8672 (0.8711) acc@5 1.0000 (0.9959)\n",
      "\u001b[32m[2020-06-22 22:05:41] __main__ INFO: \u001b[0mEpoch 26 Step 300/351 lr 0.001000 loss 0.3568 (0.3625) acc@1 0.8672 (0.8715) acc@5 0.9922 (0.9960)\n",
      "\u001b[32m[2020-06-22 22:05:46] __main__ INFO: \u001b[0mEpoch 26 Step 351/351 lr 0.001000 loss 0.2551 (0.3633) acc@1 0.8984 (0.8715) acc@5 1.0000 (0.9961)\n",
      "\u001b[32m[2020-06-22 22:05:46] __main__ INFO: \u001b[0mElapsed 32.40\n",
      "\u001b[32m[2020-06-22 22:05:46] __main__ INFO: \u001b[0mVal 26\n",
      "\u001b[32m[2020-06-22 22:05:47] __main__ INFO: \u001b[0mEpoch 26 loss 0.4845 acc@1 0.8422 acc@5 0.9928\n",
      "\u001b[32m[2020-06-22 22:05:47] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 22:05:47] __main__ INFO: \u001b[0mTrain 27 9126\n",
      "\u001b[32m[2020-06-22 22:05:56] __main__ INFO: \u001b[0mEpoch 27 Step 100/351 lr 0.001000 loss 0.3457 (0.3514) acc@1 0.8828 (0.8774) acc@5 1.0000 (0.9970)\n",
      "\u001b[32m[2020-06-22 22:06:05] __main__ INFO: \u001b[0mEpoch 27 Step 200/351 lr 0.001000 loss 0.3731 (0.3587) acc@1 0.8672 (0.8741) acc@5 1.0000 (0.9961)\n",
      "\u001b[32m[2020-06-22 22:06:15] __main__ INFO: \u001b[0mEpoch 27 Step 300/351 lr 0.001000 loss 0.1896 (0.3586) acc@1 0.9297 (0.8746) acc@5 0.9922 (0.9958)\n",
      "\u001b[32m[2020-06-22 22:06:19] __main__ INFO: \u001b[0mEpoch 27 Step 351/351 lr 0.001000 loss 0.3442 (0.3602) acc@1 0.8906 (0.8737) acc@5 0.9922 (0.9957)\n",
      "\u001b[32m[2020-06-22 22:06:19] __main__ INFO: \u001b[0mElapsed 32.40\n",
      "\u001b[32m[2020-06-22 22:06:19] __main__ INFO: \u001b[0mVal 27\n",
      "\u001b[32m[2020-06-22 22:06:20] __main__ INFO: \u001b[0mEpoch 27 loss 0.4869 acc@1 0.8394 acc@5 0.9924\n",
      "\u001b[32m[2020-06-22 22:06:20] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-06-22 22:06:20] __main__ INFO: \u001b[0mTrain 28 9477\n",
      "\u001b[32m[2020-06-22 22:06:30] __main__ INFO: \u001b[0mEpoch 28 Step 100/351 lr 0.001000 loss 0.2759 (0.3372) acc@1 0.8984 (0.8809) acc@5 1.0000 (0.9963)\n",
      "\u001b[32m[2020-06-22 22:06:39] __main__ INFO: \u001b[0mEpoch 28 Step 200/351 lr 0.001000 loss 0.3060 (0.3438) acc@1 0.8672 (0.8788) acc@5 1.0000 (0.9957)\n",
      "\u001b[32m[2020-06-22 22:06:48] __main__ INFO: \u001b[0mEpoch 28 Step 300/351 lr 0.001000 loss 0.3331 (0.3496) acc@1 0.8672 (0.8767) acc@5 1.0000 (0.9960)\n",
      "\u001b[32m[2020-06-22 22:06:53] __main__ INFO: \u001b[0mEpoch 28 Step 351/351 lr 0.001000 loss 0.3308 (0.3527) acc@1 0.8516 (0.8759) acc@5 0.9844 (0.9957)\n",
      "\u001b[32m[2020-06-22 22:06:53] __main__ INFO: \u001b[0mElapsed 32.42\n",
      "\u001b[32m[2020-06-22 22:06:53] __main__ INFO: \u001b[0mVal 28\n",
      "\u001b[32m[2020-06-22 22:06:54] __main__ INFO: \u001b[0mEpoch 28 loss 0.4821 acc@1 0.8452 acc@5 0.9928\n",
      "\u001b[32m[2020-06-22 22:06:54] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 22:06:54] __main__ INFO: \u001b[0mTrain 29 9828\n",
      "\u001b[32m[2020-06-22 22:07:03] __main__ INFO: \u001b[0mEpoch 29 Step 100/351 lr 0.001000 loss 0.3669 (0.3536) acc@1 0.8594 (0.8766) acc@5 0.9922 (0.9961)\n",
      "\u001b[32m[2020-06-22 22:07:13] __main__ INFO: \u001b[0mEpoch 29 Step 200/351 lr 0.001000 loss 0.4509 (0.3517) acc@1 0.8203 (0.8765) acc@5 1.0000 (0.9961)\n",
      "\u001b[32m[2020-06-22 22:07:22] __main__ INFO: \u001b[0mEpoch 29 Step 300/351 lr 0.001000 loss 0.3120 (0.3498) acc@1 0.8984 (0.8780) acc@5 1.0000 (0.9962)\n",
      "\u001b[32m[2020-06-22 22:07:26] __main__ INFO: \u001b[0mEpoch 29 Step 351/351 lr 0.001000 loss 0.2914 (0.3502) acc@1 0.9062 (0.8777) acc@5 1.0000 (0.9961)\n",
      "\u001b[32m[2020-06-22 22:07:26] __main__ INFO: \u001b[0mElapsed 32.42\n",
      "\u001b[32m[2020-06-22 22:07:26] __main__ INFO: \u001b[0mVal 29\n",
      "\u001b[32m[2020-06-22 22:07:27] __main__ INFO: \u001b[0mEpoch 29 loss 0.4812 acc@1 0.8456 acc@5 0.9912\n",
      "\u001b[32m[2020-06-22 22:07:27] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 22:07:27] __main__ INFO: \u001b[0mTrain 30 10179\n",
      "\u001b[32m[2020-06-22 22:07:37] __main__ INFO: \u001b[0mEpoch 30 Step 100/351 lr 0.001000 loss 0.3314 (0.3487) acc@1 0.8906 (0.8758) acc@5 1.0000 (0.9967)\n",
      "\u001b[32m[2020-06-22 22:07:46] __main__ INFO: \u001b[0mEpoch 30 Step 200/351 lr 0.001000 loss 0.2681 (0.3466) acc@1 0.8984 (0.8784) acc@5 1.0000 (0.9961)\n",
      "\u001b[32m[2020-06-22 22:07:55] __main__ INFO: \u001b[0mEpoch 30 Step 300/351 lr 0.001000 loss 0.4062 (0.3455) acc@1 0.8594 (0.8777) acc@5 0.9922 (0.9962)\n",
      "\u001b[32m[2020-06-22 22:08:00] __main__ INFO: \u001b[0mEpoch 30 Step 351/351 lr 0.001000 loss 0.3002 (0.3445) acc@1 0.8906 (0.8787) acc@5 1.0000 (0.9961)\n",
      "\u001b[32m[2020-06-22 22:08:00] __main__ INFO: \u001b[0mElapsed 32.39\n",
      "\u001b[32m[2020-06-22 22:08:00] __main__ INFO: \u001b[0mVal 30\n",
      "\u001b[32m[2020-06-22 22:08:01] __main__ INFO: \u001b[0mEpoch 30 loss 0.4758 acc@1 0.8426 acc@5 0.9924\n",
      "\u001b[32m[2020-06-22 22:08:01] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-22 22:08:01] __main__ INFO: \u001b[0mTrain 31 10530\n",
      "\u001b[32m[2020-06-22 22:08:10] __main__ INFO: \u001b[0mEpoch 31 Step 100/351 lr 0.001000 loss 0.3981 (0.3390) acc@1 0.8750 (0.8805) acc@5 0.9922 (0.9959)\n",
      "\u001b[32m[2020-06-22 22:08:19] __main__ INFO: \u001b[0mEpoch 31 Step 200/351 lr 0.001000 loss 0.3782 (0.3405) acc@1 0.8672 (0.8796) acc@5 1.0000 (0.9962)\n",
      "\u001b[32m[2020-06-22 22:08:29] __main__ INFO: \u001b[0mEpoch 31 Step 300/351 lr 0.001000 loss 0.2654 (0.3370) acc@1 0.9062 (0.8817) acc@5 1.0000 (0.9963)\n",
      "\u001b[32m[2020-06-22 22:08:33] __main__ INFO: \u001b[0mEpoch 31 Step 351/351 lr 0.001000 loss 0.3439 (0.3394) acc@1 0.8594 (0.8807) acc@5 1.0000 (0.9964)\n",
      "\u001b[32m[2020-06-22 22:08:33] __main__ INFO: \u001b[0mElapsed 32.41\n",
      "\u001b[32m[2020-06-22 22:08:33] __main__ INFO: \u001b[0mVal 31\n",
      "\u001b[32m[2020-06-22 22:08:34] __main__ INFO: \u001b[0mEpoch 31 loss 0.4859 acc@1 0.8428 acc@5 0.9920\n",
      "\u001b[32m[2020-06-22 22:08:34] __main__ INFO: \u001b[0mElapsed 1.12\n",
      "\u001b[32m[2020-06-22 22:08:34] __main__ INFO: \u001b[0mTrain 32 10881\n",
      "\u001b[32m[2020-06-22 22:08:44] __main__ INFO: \u001b[0mEpoch 32 Step 100/351 lr 0.001000 loss 0.2533 (0.3402) acc@1 0.8984 (0.8793) acc@5 1.0000 (0.9965)\n",
      "\u001b[32m[2020-06-22 22:08:53] __main__ INFO: \u001b[0mEpoch 32 Step 200/351 lr 0.001000 loss 0.2508 (0.3371) acc@1 0.9297 (0.8802) acc@5 1.0000 (0.9966)\n",
      "\u001b[32m[2020-06-22 22:09:02] __main__ INFO: \u001b[0mEpoch 32 Step 300/351 lr 0.001000 loss 0.3842 (0.3351) acc@1 0.8359 (0.8807) acc@5 0.9922 (0.9966)\n",
      "\u001b[32m[2020-06-22 22:09:07] __main__ INFO: \u001b[0mEpoch 32 Step 351/351 lr 0.001000 loss 0.3241 (0.3353) acc@1 0.8672 (0.8805) acc@5 1.0000 (0.9966)\n",
      "\u001b[32m[2020-06-22 22:09:07] __main__ INFO: \u001b[0mElapsed 32.44\n",
      "\u001b[32m[2020-06-22 22:09:07] __main__ INFO: \u001b[0mVal 32\n",
      "\u001b[32m[2020-06-22 22:09:08] __main__ INFO: \u001b[0mEpoch 32 loss 0.4785 acc@1 0.8464 acc@5 0.9920\n",
      "\u001b[32m[2020-06-22 22:09:08] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 22:09:08] __main__ INFO: \u001b[0mTrain 33 11232\n",
      "\u001b[32m[2020-06-22 22:09:17] __main__ INFO: \u001b[0mEpoch 33 Step 100/351 lr 0.001000 loss 0.2793 (0.3317) acc@1 0.9141 (0.8845) acc@5 1.0000 (0.9970)\n",
      "\u001b[32m[2020-06-22 22:09:27] __main__ INFO: \u001b[0mEpoch 33 Step 200/351 lr 0.001000 loss 0.3215 (0.3316) acc@1 0.8828 (0.8843) acc@5 0.9844 (0.9966)\n",
      "\u001b[32m[2020-06-22 22:09:36] __main__ INFO: \u001b[0mEpoch 33 Step 300/351 lr 0.001000 loss 0.3368 (0.3321) acc@1 0.8594 (0.8826) acc@5 1.0000 (0.9965)\n",
      "\u001b[32m[2020-06-22 22:09:40] __main__ INFO: \u001b[0mEpoch 33 Step 351/351 lr 0.001000 loss 0.3560 (0.3331) acc@1 0.8594 (0.8821) acc@5 1.0000 (0.9966)\n",
      "\u001b[32m[2020-06-22 22:09:40] __main__ INFO: \u001b[0mElapsed 32.48\n",
      "\u001b[32m[2020-06-22 22:09:40] __main__ INFO: \u001b[0mVal 33\n",
      "\u001b[32m[2020-06-22 22:09:42] __main__ INFO: \u001b[0mEpoch 33 loss 0.4794 acc@1 0.8448 acc@5 0.9920\n",
      "\u001b[32m[2020-06-22 22:09:42] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 22:09:42] __main__ INFO: \u001b[0mTrain 34 11583\n",
      "\u001b[32m[2020-06-22 22:09:51] __main__ INFO: \u001b[0mEpoch 34 Step 100/351 lr 0.001000 loss 0.2721 (0.3324) acc@1 0.9297 (0.8812) acc@5 1.0000 (0.9966)\n",
      "\u001b[32m[2020-06-22 22:10:00] __main__ INFO: \u001b[0mEpoch 34 Step 200/351 lr 0.001000 loss 0.3404 (0.3229) acc@1 0.8984 (0.8861) acc@5 1.0000 (0.9968)\n",
      "\u001b[32m[2020-06-22 22:10:09] __main__ INFO: \u001b[0mEpoch 34 Step 300/351 lr 0.001000 loss 0.2361 (0.3252) acc@1 0.9141 (0.8860) acc@5 0.9922 (0.9966)\n",
      "\u001b[32m[2020-06-22 22:10:14] __main__ INFO: \u001b[0mEpoch 34 Step 351/351 lr 0.001000 loss 0.2814 (0.3238) acc@1 0.8750 (0.8864) acc@5 1.0000 (0.9966)\n",
      "\u001b[32m[2020-06-22 22:10:14] __main__ INFO: \u001b[0mElapsed 32.40\n",
      "\u001b[32m[2020-06-22 22:10:14] __main__ INFO: \u001b[0mVal 34\n",
      "\u001b[32m[2020-06-22 22:10:15] __main__ INFO: \u001b[0mEpoch 34 loss 0.4793 acc@1 0.8426 acc@5 0.9922\n",
      "\u001b[32m[2020-06-22 22:10:15] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 22:10:15] __main__ INFO: \u001b[0mTrain 35 11934\n",
      "\u001b[32m[2020-06-22 22:10:24] __main__ INFO: \u001b[0mEpoch 35 Step 100/351 lr 0.001000 loss 0.3704 (0.3178) acc@1 0.8750 (0.8891) acc@5 0.9766 (0.9970)\n",
      "\u001b[32m[2020-06-22 22:10:34] __main__ INFO: \u001b[0mEpoch 35 Step 200/351 lr 0.001000 loss 0.4051 (0.3214) acc@1 0.8984 (0.8873) acc@5 0.9922 (0.9971)\n",
      "\u001b[32m[2020-06-22 22:10:43] __main__ INFO: \u001b[0mEpoch 35 Step 300/351 lr 0.001000 loss 0.3270 (0.3231) acc@1 0.8906 (0.8866) acc@5 1.0000 (0.9967)\n",
      "\u001b[32m[2020-06-22 22:10:47] __main__ INFO: \u001b[0mEpoch 35 Step 351/351 lr 0.001000 loss 0.3694 (0.3235) acc@1 0.8516 (0.8863) acc@5 1.0000 (0.9968)\n",
      "\u001b[32m[2020-06-22 22:10:47] __main__ INFO: \u001b[0mElapsed 32.37\n",
      "\u001b[32m[2020-06-22 22:10:47] __main__ INFO: \u001b[0mVal 35\n",
      "\u001b[32m[2020-06-22 22:10:48] __main__ INFO: \u001b[0mEpoch 35 loss 0.4714 acc@1 0.8434 acc@5 0.9924\n",
      "\u001b[32m[2020-06-22 22:10:48] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 22:10:48] __main__ INFO: \u001b[0mTrain 36 12285\n",
      "\u001b[32m[2020-06-22 22:10:58] __main__ INFO: \u001b[0mEpoch 36 Step 100/351 lr 0.001000 loss 0.2590 (0.3130) acc@1 0.9297 (0.8927) acc@5 1.0000 (0.9959)\n",
      "\u001b[32m[2020-06-22 22:11:07] __main__ INFO: \u001b[0mEpoch 36 Step 200/351 lr 0.001000 loss 0.2376 (0.3150) acc@1 0.8984 (0.8898) acc@5 1.0000 (0.9965)\n",
      "\u001b[32m[2020-06-22 22:11:16] __main__ INFO: \u001b[0mEpoch 36 Step 300/351 lr 0.001000 loss 0.2979 (0.3174) acc@1 0.8828 (0.8881) acc@5 1.0000 (0.9965)\n",
      "\u001b[32m[2020-06-22 22:11:21] __main__ INFO: \u001b[0mEpoch 36 Step 351/351 lr 0.001000 loss 0.4156 (0.3157) acc@1 0.8906 (0.8886) acc@5 1.0000 (0.9967)\n",
      "\u001b[32m[2020-06-22 22:11:21] __main__ INFO: \u001b[0mElapsed 32.37\n",
      "\u001b[32m[2020-06-22 22:11:21] __main__ INFO: \u001b[0mVal 36\n",
      "\u001b[32m[2020-06-22 22:11:22] __main__ INFO: \u001b[0mEpoch 36 loss 0.4723 acc@1 0.8458 acc@5 0.9928\n",
      "\u001b[32m[2020-06-22 22:11:22] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 22:11:22] __main__ INFO: \u001b[0mTrain 37 12636\n",
      "\u001b[32m[2020-06-22 22:11:31] __main__ INFO: \u001b[0mEpoch 37 Step 100/351 lr 0.001000 loss 0.3948 (0.3125) acc@1 0.8281 (0.8934) acc@5 1.0000 (0.9970)\n",
      "\u001b[32m[2020-06-22 22:11:40] __main__ INFO: \u001b[0mEpoch 37 Step 200/351 lr 0.001000 loss 0.3263 (0.3146) acc@1 0.8984 (0.8917) acc@5 1.0000 (0.9971)\n",
      "\u001b[32m[2020-06-22 22:11:50] __main__ INFO: \u001b[0mEpoch 37 Step 300/351 lr 0.001000 loss 0.3748 (0.3128) acc@1 0.8750 (0.8911) acc@5 1.0000 (0.9972)\n",
      "\u001b[32m[2020-06-22 22:11:54] __main__ INFO: \u001b[0mEpoch 37 Step 351/351 lr 0.001000 loss 0.2636 (0.3131) acc@1 0.9219 (0.8913) acc@5 1.0000 (0.9971)\n",
      "\u001b[32m[2020-06-22 22:11:54] __main__ INFO: \u001b[0mElapsed 32.36\n",
      "\u001b[32m[2020-06-22 22:11:54] __main__ INFO: \u001b[0mVal 37\n",
      "\u001b[32m[2020-06-22 22:11:55] __main__ INFO: \u001b[0mEpoch 37 loss 0.4764 acc@1 0.8440 acc@5 0.9922\n",
      "\u001b[32m[2020-06-22 22:11:55] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 22:11:55] __main__ INFO: \u001b[0mTrain 38 12987\n",
      "\u001b[32m[2020-06-22 22:12:05] __main__ INFO: \u001b[0mEpoch 38 Step 100/351 lr 0.001000 loss 0.3434 (0.3172) acc@1 0.8750 (0.8891) acc@5 1.0000 (0.9965)\n",
      "\u001b[32m[2020-06-22 22:12:14] __main__ INFO: \u001b[0mEpoch 38 Step 200/351 lr 0.001000 loss 0.2617 (0.3150) acc@1 0.9297 (0.8908) acc@5 1.0000 (0.9966)\n",
      "\u001b[32m[2020-06-22 22:12:23] __main__ INFO: \u001b[0mEpoch 38 Step 300/351 lr 0.001000 loss 0.3564 (0.3125) acc@1 0.8828 (0.8911) acc@5 1.0000 (0.9969)\n",
      "\u001b[32m[2020-06-22 22:12:28] __main__ INFO: \u001b[0mEpoch 38 Step 351/351 lr 0.001000 loss 0.3167 (0.3117) acc@1 0.8828 (0.8916) acc@5 0.9844 (0.9969)\n",
      "\u001b[32m[2020-06-22 22:12:28] __main__ INFO: \u001b[0mElapsed 32.36\n",
      "\u001b[32m[2020-06-22 22:12:28] __main__ INFO: \u001b[0mVal 38\n",
      "\u001b[32m[2020-06-22 22:12:29] __main__ INFO: \u001b[0mEpoch 38 loss 0.4753 acc@1 0.8462 acc@5 0.9926\n",
      "\u001b[32m[2020-06-22 22:12:29] __main__ INFO: \u001b[0mElapsed 1.13\n",
      "\u001b[32m[2020-06-22 22:12:29] __main__ INFO: \u001b[0mTrain 39 13338\n",
      "\u001b[32m[2020-06-22 22:12:38] __main__ INFO: \u001b[0mEpoch 39 Step 100/351 lr 0.001000 loss 0.2806 (0.3015) acc@1 0.8906 (0.8946) acc@5 0.9922 (0.9973)\n",
      "\u001b[32m[2020-06-22 22:12:47] __main__ INFO: \u001b[0mEpoch 39 Step 200/351 lr 0.001000 loss 0.2425 (0.3048) acc@1 0.9062 (0.8935) acc@5 1.0000 (0.9975)\n",
      "\u001b[32m[2020-06-22 22:12:57] __main__ INFO: \u001b[0mEpoch 39 Step 300/351 lr 0.001000 loss 0.3262 (0.3056) acc@1 0.8750 (0.8924) acc@5 1.0000 (0.9976)\n",
      "\u001b[32m[2020-06-22 22:13:01] __main__ INFO: \u001b[0mEpoch 39 Step 351/351 lr 0.001000 loss 0.3430 (0.3072) acc@1 0.8750 (0.8919) acc@5 0.9922 (0.9974)\n",
      "\u001b[32m[2020-06-22 22:13:01] __main__ INFO: \u001b[0mElapsed 32.45\n",
      "\u001b[32m[2020-06-22 22:13:01] __main__ INFO: \u001b[0mVal 39\n",
      "\u001b[32m[2020-06-22 22:13:02] __main__ INFO: \u001b[0mEpoch 39 loss 0.4726 acc@1 0.8454 acc@5 0.9934\n",
      "\u001b[32m[2020-06-22 22:13:02] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 22:13:02] __main__ INFO: \u001b[0mTrain 40 13689\n",
      "\u001b[32m[2020-06-22 22:13:12] __main__ INFO: \u001b[0mEpoch 40 Step 100/351 lr 0.001000 loss 0.2894 (0.3013) acc@1 0.8984 (0.8953) acc@5 1.0000 (0.9975)\n",
      "\u001b[32m[2020-06-22 22:13:21] __main__ INFO: \u001b[0mEpoch 40 Step 200/351 lr 0.001000 loss 0.3585 (0.3012) acc@1 0.8906 (0.8938) acc@5 0.9922 (0.9974)\n",
      "\u001b[32m[2020-06-22 22:13:30] __main__ INFO: \u001b[0mEpoch 40 Step 300/351 lr 0.001000 loss 0.3063 (0.2984) acc@1 0.8906 (0.8943) acc@5 1.0000 (0.9973)\n",
      "\u001b[32m[2020-06-22 22:13:35] __main__ INFO: \u001b[0mEpoch 40 Step 351/351 lr 0.001000 loss 0.5014 (0.3004) acc@1 0.8281 (0.8937) acc@5 0.9922 (0.9972)\n",
      "\u001b[32m[2020-06-22 22:13:35] __main__ INFO: \u001b[0mElapsed 32.39\n",
      "\u001b[32m[2020-06-22 22:13:35] __main__ INFO: \u001b[0mVal 40\n",
      "\u001b[32m[2020-06-22 22:13:36] __main__ INFO: \u001b[0mEpoch 40 loss 0.4748 acc@1 0.8476 acc@5 0.9922\n",
      "\u001b[32m[2020-06-22 22:13:36] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 22:13:36] __main__ INFO: \u001b[0mTrain 41 14040\n",
      "\u001b[32m[2020-06-22 22:13:45] __main__ INFO: \u001b[0mEpoch 41 Step 100/351 lr 0.001000 loss 0.2598 (0.2959) acc@1 0.9297 (0.8948) acc@5 0.9922 (0.9973)\n",
      "\u001b[32m[2020-06-22 22:13:54] __main__ INFO: \u001b[0mEpoch 41 Step 200/351 lr 0.001000 loss 0.2806 (0.2998) acc@1 0.8984 (0.8941) acc@5 0.9922 (0.9973)\n",
      "\u001b[32m[2020-06-22 22:14:03] __main__ INFO: \u001b[0mEpoch 41 Step 300/351 lr 0.001000 loss 0.1357 (0.2960) acc@1 0.9766 (0.8952) acc@5 0.9922 (0.9974)\n",
      "\u001b[32m[2020-06-22 22:14:08] __main__ INFO: \u001b[0mEpoch 41 Step 351/351 lr 0.001000 loss 0.3087 (0.2985) acc@1 0.8594 (0.8939) acc@5 1.0000 (0.9973)\n",
      "\u001b[32m[2020-06-22 22:14:08] __main__ INFO: \u001b[0mElapsed 32.38\n",
      "\u001b[32m[2020-06-22 22:14:08] __main__ INFO: \u001b[0mVal 41\n",
      "\u001b[32m[2020-06-22 22:14:09] __main__ INFO: \u001b[0mEpoch 41 loss 0.4727 acc@1 0.8484 acc@5 0.9932\n",
      "\u001b[32m[2020-06-22 22:14:09] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 22:14:09] __main__ INFO: \u001b[0mTrain 42 14391\n",
      "\u001b[32m[2020-06-22 22:14:19] __main__ INFO: \u001b[0mEpoch 42 Step 100/351 lr 0.001000 loss 0.3492 (0.3004) acc@1 0.8672 (0.8960) acc@5 0.9922 (0.9970)\n",
      "\u001b[32m[2020-06-22 22:14:28] __main__ INFO: \u001b[0mEpoch 42 Step 200/351 lr 0.001000 loss 0.3378 (0.2936) acc@1 0.8828 (0.8965) acc@5 1.0000 (0.9973)\n",
      "\u001b[32m[2020-06-22 22:14:37] __main__ INFO: \u001b[0mEpoch 42 Step 300/351 lr 0.001000 loss 0.2631 (0.2929) acc@1 0.9062 (0.8967) acc@5 0.9922 (0.9971)\n",
      "\u001b[32m[2020-06-22 22:14:42] __main__ INFO: \u001b[0mEpoch 42 Step 351/351 lr 0.001000 loss 0.2468 (0.2946) acc@1 0.9062 (0.8959) acc@5 1.0000 (0.9971)\n",
      "\u001b[32m[2020-06-22 22:14:42] __main__ INFO: \u001b[0mElapsed 32.40\n",
      "\u001b[32m[2020-06-22 22:14:42] __main__ INFO: \u001b[0mVal 42\n",
      "\u001b[32m[2020-06-22 22:14:43] __main__ INFO: \u001b[0mEpoch 42 loss 0.4649 acc@1 0.8488 acc@5 0.9924\n",
      "\u001b[32m[2020-06-22 22:14:43] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 22:14:43] __main__ INFO: \u001b[0mTrain 43 14742\n",
      "\u001b[32m[2020-06-22 22:14:52] __main__ INFO: \u001b[0mEpoch 43 Step 100/351 lr 0.001000 loss 0.4239 (0.2873) acc@1 0.8438 (0.8999) acc@5 1.0000 (0.9972)\n",
      "\u001b[32m[2020-06-22 22:15:01] __main__ INFO: \u001b[0mEpoch 43 Step 200/351 lr 0.001000 loss 0.2838 (0.2863) acc@1 0.9297 (0.8986) acc@5 1.0000 (0.9971)\n",
      "\u001b[32m[2020-06-22 22:15:10] __main__ INFO: \u001b[0mEpoch 43 Step 300/351 lr 0.001000 loss 0.2837 (0.2890) acc@1 0.9062 (0.8979) acc@5 1.0000 (0.9973)\n",
      "\u001b[32m[2020-06-22 22:15:15] __main__ INFO: \u001b[0mEpoch 43 Step 351/351 lr 0.001000 loss 0.1610 (0.2895) acc@1 0.9609 (0.8978) acc@5 1.0000 (0.9971)\n",
      "\u001b[32m[2020-06-22 22:15:15] __main__ INFO: \u001b[0mElapsed 32.41\n",
      "\u001b[32m[2020-06-22 22:15:15] __main__ INFO: \u001b[0mVal 43\n",
      "\u001b[32m[2020-06-22 22:15:16] __main__ INFO: \u001b[0mEpoch 43 loss 0.4652 acc@1 0.8514 acc@5 0.9928\n",
      "\u001b[32m[2020-06-22 22:15:16] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 22:15:16] __main__ INFO: \u001b[0mTrain 44 15093\n",
      "\u001b[32m[2020-06-22 22:15:26] __main__ INFO: \u001b[0mEpoch 44 Step 100/351 lr 0.001000 loss 0.2401 (0.2884) acc@1 0.9062 (0.8977) acc@5 1.0000 (0.9977)\n",
      "\u001b[32m[2020-06-22 22:15:35] __main__ INFO: \u001b[0mEpoch 44 Step 200/351 lr 0.001000 loss 0.3215 (0.2900) acc@1 0.8594 (0.8978) acc@5 1.0000 (0.9975)\n",
      "\u001b[32m[2020-06-22 22:15:44] __main__ INFO: \u001b[0mEpoch 44 Step 300/351 lr 0.001000 loss 0.2020 (0.2898) acc@1 0.9219 (0.8978) acc@5 1.0000 (0.9974)\n",
      "\u001b[32m[2020-06-22 22:15:49] __main__ INFO: \u001b[0mEpoch 44 Step 351/351 lr 0.001000 loss 0.2369 (0.2899) acc@1 0.8828 (0.8973) acc@5 1.0000 (0.9974)\n",
      "\u001b[32m[2020-06-22 22:15:49] __main__ INFO: \u001b[0mElapsed 32.44\n",
      "\u001b[32m[2020-06-22 22:15:49] __main__ INFO: \u001b[0mVal 44\n",
      "\u001b[32m[2020-06-22 22:15:50] __main__ INFO: \u001b[0mEpoch 44 loss 0.4655 acc@1 0.8488 acc@5 0.9928\n",
      "\u001b[32m[2020-06-22 22:15:50] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 22:15:50] __main__ INFO: \u001b[0mTrain 45 15444\n",
      "\u001b[32m[2020-06-22 22:15:59] __main__ INFO: \u001b[0mEpoch 45 Step 100/351 lr 0.001000 loss 0.2847 (0.2897) acc@1 0.8906 (0.8962) acc@5 1.0000 (0.9980)\n",
      "\u001b[32m[2020-06-22 22:16:08] __main__ INFO: \u001b[0mEpoch 45 Step 200/351 lr 0.001000 loss 0.2859 (0.2888) acc@1 0.8906 (0.8971) acc@5 1.0000 (0.9977)\n",
      "\u001b[32m[2020-06-22 22:16:17] __main__ INFO: \u001b[0mEpoch 45 Step 300/351 lr 0.001000 loss 0.3131 (0.2872) acc@1 0.8906 (0.8982) acc@5 1.0000 (0.9974)\n",
      "\u001b[32m[2020-06-22 22:16:22] __main__ INFO: \u001b[0mEpoch 45 Step 351/351 lr 0.001000 loss 0.2484 (0.2865) acc@1 0.9531 (0.8989) acc@5 1.0000 (0.9976)\n",
      "\u001b[32m[2020-06-22 22:16:22] __main__ INFO: \u001b[0mElapsed 32.42\n",
      "\u001b[32m[2020-06-22 22:16:22] __main__ INFO: \u001b[0mVal 45\n",
      "\u001b[32m[2020-06-22 22:16:23] __main__ INFO: \u001b[0mEpoch 45 loss 0.4740 acc@1 0.8468 acc@5 0.9936\n",
      "\u001b[32m[2020-06-22 22:16:23] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 22:16:23] __main__ INFO: \u001b[0mTrain 46 15795\n",
      "\u001b[32m[2020-06-22 22:16:33] __main__ INFO: \u001b[0mEpoch 46 Step 100/351 lr 0.001000 loss 0.2301 (0.2789) acc@1 0.9141 (0.9029) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-06-22 22:16:42] __main__ INFO: \u001b[0mEpoch 46 Step 200/351 lr 0.001000 loss 0.2897 (0.2781) acc@1 0.8906 (0.9020) acc@5 0.9922 (0.9980)\n",
      "\u001b[32m[2020-06-22 22:16:51] __main__ INFO: \u001b[0mEpoch 46 Step 300/351 lr 0.001000 loss 0.3375 (0.2795) acc@1 0.8906 (0.9018) acc@5 0.9922 (0.9979)\n",
      "\u001b[32m[2020-06-22 22:16:56] __main__ INFO: \u001b[0mEpoch 46 Step 351/351 lr 0.001000 loss 0.2674 (0.2797) acc@1 0.9297 (0.9017) acc@5 1.0000 (0.9978)\n",
      "\u001b[32m[2020-06-22 22:16:56] __main__ INFO: \u001b[0mElapsed 32.46\n",
      "\u001b[32m[2020-06-22 22:16:56] __main__ INFO: \u001b[0mVal 46\n",
      "\u001b[32m[2020-06-22 22:16:57] __main__ INFO: \u001b[0mEpoch 46 loss 0.4676 acc@1 0.8498 acc@5 0.9918\n",
      "\u001b[32m[2020-06-22 22:16:57] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 22:16:57] __main__ INFO: \u001b[0mTrain 47 16146\n",
      "\u001b[32m[2020-06-22 22:17:06] __main__ INFO: \u001b[0mEpoch 47 Step 100/351 lr 0.001000 loss 0.3067 (0.2773) acc@1 0.8750 (0.9040) acc@5 1.0000 (0.9980)\n",
      "\u001b[32m[2020-06-22 22:17:15] __main__ INFO: \u001b[0mEpoch 47 Step 200/351 lr 0.001000 loss 0.2597 (0.2753) acc@1 0.9141 (0.9032) acc@5 1.0000 (0.9977)\n",
      "\u001b[32m[2020-06-22 22:17:24] __main__ INFO: \u001b[0mEpoch 47 Step 300/351 lr 0.001000 loss 0.2948 (0.2761) acc@1 0.8828 (0.9023) acc@5 0.9922 (0.9977)\n",
      "\u001b[32m[2020-06-22 22:17:29] __main__ INFO: \u001b[0mEpoch 47 Step 351/351 lr 0.001000 loss 0.3416 (0.2789) acc@1 0.8906 (0.9009) acc@5 1.0000 (0.9977)\n",
      "\u001b[32m[2020-06-22 22:17:29] __main__ INFO: \u001b[0mElapsed 32.38\n",
      "\u001b[32m[2020-06-22 22:17:29] __main__ INFO: \u001b[0mVal 47\n",
      "\u001b[32m[2020-06-22 22:17:30] __main__ INFO: \u001b[0mEpoch 47 loss 0.4701 acc@1 0.8492 acc@5 0.9916\n",
      "\u001b[32m[2020-06-22 22:17:30] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 22:17:30] __main__ INFO: \u001b[0mTrain 48 16497\n",
      "\u001b[32m[2020-06-22 22:17:39] __main__ INFO: \u001b[0mEpoch 48 Step 100/351 lr 0.001000 loss 0.2156 (0.2692) acc@1 0.9375 (0.9041) acc@5 1.0000 (0.9976)\n",
      "\u001b[32m[2020-06-22 22:17:49] __main__ INFO: \u001b[0mEpoch 48 Step 200/351 lr 0.001000 loss 0.1927 (0.2695) acc@1 0.9141 (0.9044) acc@5 1.0000 (0.9980)\n",
      "\u001b[32m[2020-06-22 22:17:58] __main__ INFO: \u001b[0mEpoch 48 Step 300/351 lr 0.001000 loss 0.2224 (0.2723) acc@1 0.9062 (0.9035) acc@5 1.0000 (0.9979)\n",
      "\u001b[32m[2020-06-22 22:18:03] __main__ INFO: \u001b[0mEpoch 48 Step 351/351 lr 0.001000 loss 0.2736 (0.2753) acc@1 0.9062 (0.9026) acc@5 1.0000 (0.9978)\n",
      "\u001b[32m[2020-06-22 22:18:03] __main__ INFO: \u001b[0mElapsed 32.42\n",
      "\u001b[32m[2020-06-22 22:18:03] __main__ INFO: \u001b[0mVal 48\n",
      "\u001b[32m[2020-06-22 22:18:04] __main__ INFO: \u001b[0mEpoch 48 loss 0.4682 acc@1 0.8510 acc@5 0.9922\n",
      "\u001b[32m[2020-06-22 22:18:04] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 22:18:04] __main__ INFO: \u001b[0mTrain 49 16848\n",
      "\u001b[32m[2020-06-22 22:18:13] __main__ INFO: \u001b[0mEpoch 49 Step 100/351 lr 0.001000 loss 0.2556 (0.2710) acc@1 0.9062 (0.9028) acc@5 1.0000 (0.9981)\n",
      "\u001b[32m[2020-06-22 22:18:22] __main__ INFO: \u001b[0mEpoch 49 Step 200/351 lr 0.001000 loss 0.3910 (0.2692) acc@1 0.8516 (0.9048) acc@5 1.0000 (0.9980)\n",
      "\u001b[32m[2020-06-22 22:18:31] __main__ INFO: \u001b[0mEpoch 49 Step 300/351 lr 0.001000 loss 0.2037 (0.2704) acc@1 0.9219 (0.9045) acc@5 1.0000 (0.9977)\n",
      "\u001b[32m[2020-06-22 22:18:36] __main__ INFO: \u001b[0mEpoch 49 Step 351/351 lr 0.001000 loss 0.3491 (0.2706) acc@1 0.8516 (0.9041) acc@5 1.0000 (0.9977)\n",
      "\u001b[32m[2020-06-22 22:18:36] __main__ INFO: \u001b[0mElapsed 32.39\n",
      "\u001b[32m[2020-06-22 22:18:36] __main__ INFO: \u001b[0mVal 49\n",
      "\u001b[32m[2020-06-22 22:18:37] __main__ INFO: \u001b[0mEpoch 49 loss 0.4655 acc@1 0.8514 acc@5 0.9932\n",
      "\u001b[32m[2020-06-22 22:18:37] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 22:18:37] __main__ INFO: \u001b[0mTrain 50 17199\n",
      "\u001b[32m[2020-06-22 22:18:46] __main__ INFO: \u001b[0mEpoch 50 Step 100/351 lr 0.001000 loss 0.4525 (0.2682) acc@1 0.8594 (0.9085) acc@5 0.9922 (0.9980)\n",
      "\u001b[32m[2020-06-22 22:18:56] __main__ INFO: \u001b[0mEpoch 50 Step 200/351 lr 0.001000 loss 0.2435 (0.2683) acc@1 0.9062 (0.9073) acc@5 0.9922 (0.9980)\n",
      "\u001b[32m[2020-06-22 22:19:05] __main__ INFO: \u001b[0mEpoch 50 Step 300/351 lr 0.001000 loss 0.2147 (0.2674) acc@1 0.9219 (0.9065) acc@5 1.0000 (0.9980)\n",
      "\u001b[32m[2020-06-22 22:19:09] __main__ INFO: \u001b[0mEpoch 50 Step 351/351 lr 0.001000 loss 0.2200 (0.2682) acc@1 0.9062 (0.9060) acc@5 1.0000 (0.9979)\n",
      "\u001b[32m[2020-06-22 22:19:10] __main__ INFO: \u001b[0mElapsed 32.37\n",
      "\u001b[32m[2020-06-22 22:19:10] __main__ INFO: \u001b[0mVal 50\n",
      "\u001b[32m[2020-06-22 22:19:11] __main__ INFO: \u001b[0mEpoch 50 loss 0.4615 acc@1 0.8508 acc@5 0.9932\n",
      "\u001b[32m[2020-06-22 22:19:11] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 22:19:11] __main__ INFO: \u001b[0mTrain 51 17550\n",
      "\u001b[32m[2020-06-22 22:19:20] __main__ INFO: \u001b[0mEpoch 51 Step 100/351 lr 0.001000 loss 0.2581 (0.2531) acc@1 0.8984 (0.9134) acc@5 0.9922 (0.9976)\n",
      "\u001b[32m[2020-06-22 22:19:29] __main__ INFO: \u001b[0mEpoch 51 Step 200/351 lr 0.001000 loss 0.2067 (0.2615) acc@1 0.9297 (0.9088) acc@5 1.0000 (0.9978)\n",
      "\u001b[32m[2020-06-22 22:19:38] __main__ INFO: \u001b[0mEpoch 51 Step 300/351 lr 0.001000 loss 0.1680 (0.2646) acc@1 0.9219 (0.9077) acc@5 1.0000 (0.9978)\n",
      "\u001b[32m[2020-06-22 22:19:43] __main__ INFO: \u001b[0mEpoch 51 Step 351/351 lr 0.001000 loss 0.2419 (0.2674) acc@1 0.9141 (0.9067) acc@5 1.0000 (0.9979)\n",
      "\u001b[32m[2020-06-22 22:19:43] __main__ INFO: \u001b[0mElapsed 32.40\n",
      "\u001b[32m[2020-06-22 22:19:43] __main__ INFO: \u001b[0mVal 51\n",
      "\u001b[32m[2020-06-22 22:19:44] __main__ INFO: \u001b[0mEpoch 51 loss 0.4621 acc@1 0.8532 acc@5 0.9936\n",
      "\u001b[32m[2020-06-22 22:19:44] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-22 22:19:44] __main__ INFO: \u001b[0mTrain 52 17901\n",
      "\u001b[32m[2020-06-22 22:19:53] __main__ INFO: \u001b[0mEpoch 52 Step 100/351 lr 0.001000 loss 0.3384 (0.2663) acc@1 0.8516 (0.9063) acc@5 0.9922 (0.9987)\n",
      "\u001b[32m[2020-06-22 22:20:03] __main__ INFO: \u001b[0mEpoch 52 Step 200/351 lr 0.001000 loss 0.1683 (0.2668) acc@1 0.9453 (0.9068) acc@5 1.0000 (0.9986)\n",
      "\u001b[32m[2020-06-22 22:20:12] __main__ INFO: \u001b[0mEpoch 52 Step 300/351 lr 0.001000 loss 0.3175 (0.2638) acc@1 0.9141 (0.9071) acc@5 1.0000 (0.9982)\n",
      "\u001b[32m[2020-06-22 22:20:16] __main__ INFO: \u001b[0mEpoch 52 Step 351/351 lr 0.001000 loss 0.2612 (0.2637) acc@1 0.8750 (0.9067) acc@5 1.0000 (0.9981)\n",
      "\u001b[32m[2020-06-22 22:20:16] __main__ INFO: \u001b[0mElapsed 32.39\n",
      "\u001b[32m[2020-06-22 22:20:16] __main__ INFO: \u001b[0mVal 52\n",
      "\u001b[32m[2020-06-22 22:20:18] __main__ INFO: \u001b[0mEpoch 52 loss 0.4657 acc@1 0.8512 acc@5 0.9934\n",
      "\u001b[32m[2020-06-22 22:20:18] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 22:20:18] __main__ INFO: \u001b[0mTrain 53 18252\n",
      "\u001b[32m[2020-06-22 22:20:27] __main__ INFO: \u001b[0mEpoch 53 Step 100/351 lr 0.001000 loss 0.2563 (0.2469) acc@1 0.8984 (0.9125) acc@5 1.0000 (0.9983)\n",
      "\u001b[32m[2020-06-22 22:20:36] __main__ INFO: \u001b[0mEpoch 53 Step 200/351 lr 0.001000 loss 0.2602 (0.2540) acc@1 0.9297 (0.9105) acc@5 1.0000 (0.9979)\n",
      "\u001b[32m[2020-06-22 22:20:45] __main__ INFO: \u001b[0mEpoch 53 Step 300/351 lr 0.001000 loss 0.2206 (0.2568) acc@1 0.8984 (0.9086) acc@5 1.0000 (0.9982)\n",
      "\u001b[32m[2020-06-22 22:20:50] __main__ INFO: \u001b[0mEpoch 53 Step 351/351 lr 0.001000 loss 0.2774 (0.2583) acc@1 0.9062 (0.9079) acc@5 1.0000 (0.9981)\n",
      "\u001b[32m[2020-06-22 22:20:50] __main__ INFO: \u001b[0mElapsed 32.40\n",
      "\u001b[32m[2020-06-22 22:20:50] __main__ INFO: \u001b[0mVal 53\n",
      "\u001b[32m[2020-06-22 22:20:51] __main__ INFO: \u001b[0mEpoch 53 loss 0.4606 acc@1 0.8548 acc@5 0.9930\n",
      "\u001b[32m[2020-06-22 22:20:51] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 22:20:51] __main__ INFO: \u001b[0mTrain 54 18603\n",
      "\u001b[32m[2020-06-22 22:21:00] __main__ INFO: \u001b[0mEpoch 54 Step 100/351 lr 0.001000 loss 0.2961 (0.2537) acc@1 0.9062 (0.9119) acc@5 0.9922 (0.9980)\n",
      "\u001b[32m[2020-06-22 22:21:09] __main__ INFO: \u001b[0mEpoch 54 Step 200/351 lr 0.001000 loss 0.2352 (0.2586) acc@1 0.9141 (0.9099) acc@5 0.9922 (0.9982)\n",
      "\u001b[32m[2020-06-22 22:21:19] __main__ INFO: \u001b[0mEpoch 54 Step 300/351 lr 0.001000 loss 0.2590 (0.2574) acc@1 0.9141 (0.9100) acc@5 1.0000 (0.9983)\n",
      "\u001b[32m[2020-06-22 22:21:23] __main__ INFO: \u001b[0mEpoch 54 Step 351/351 lr 0.001000 loss 0.3206 (0.2575) acc@1 0.8750 (0.9102) acc@5 1.0000 (0.9983)\n",
      "\u001b[32m[2020-06-22 22:21:23] __main__ INFO: \u001b[0mElapsed 32.40\n",
      "\u001b[32m[2020-06-22 22:21:23] __main__ INFO: \u001b[0mVal 54\n",
      "\u001b[32m[2020-06-22 22:21:24] __main__ INFO: \u001b[0mEpoch 54 loss 0.4643 acc@1 0.8524 acc@5 0.9920\n",
      "\u001b[32m[2020-06-22 22:21:24] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 22:21:24] __main__ INFO: \u001b[0mTrain 55 18954\n",
      "\u001b[32m[2020-06-22 22:21:34] __main__ INFO: \u001b[0mEpoch 55 Step 100/351 lr 0.001000 loss 0.2241 (0.2464) acc@1 0.9297 (0.9145) acc@5 1.0000 (0.9977)\n",
      "\u001b[32m[2020-06-22 22:21:43] __main__ INFO: \u001b[0mEpoch 55 Step 200/351 lr 0.001000 loss 0.1391 (0.2487) acc@1 0.9609 (0.9137) acc@5 1.0000 (0.9978)\n",
      "\u001b[32m[2020-06-22 22:21:52] __main__ INFO: \u001b[0mEpoch 55 Step 300/351 lr 0.001000 loss 0.2088 (0.2519) acc@1 0.9453 (0.9122) acc@5 1.0000 (0.9977)\n",
      "\u001b[32m[2020-06-22 22:21:57] __main__ INFO: \u001b[0mEpoch 55 Step 351/351 lr 0.001000 loss 0.1481 (0.2517) acc@1 0.9531 (0.9121) acc@5 1.0000 (0.9978)\n",
      "\u001b[32m[2020-06-22 22:21:57] __main__ INFO: \u001b[0mElapsed 32.39\n",
      "\u001b[32m[2020-06-22 22:21:57] __main__ INFO: \u001b[0mVal 55\n",
      "\u001b[32m[2020-06-22 22:21:58] __main__ INFO: \u001b[0mEpoch 55 loss 0.4689 acc@1 0.8550 acc@5 0.9932\n",
      "\u001b[32m[2020-06-22 22:21:58] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 22:21:58] __main__ INFO: \u001b[0mTrain 56 19305\n",
      "\u001b[32m[2020-06-22 22:22:07] __main__ INFO: \u001b[0mEpoch 56 Step 100/351 lr 0.001000 loss 0.2077 (0.2465) acc@1 0.9219 (0.9134) acc@5 1.0000 (0.9980)\n",
      "\u001b[32m[2020-06-22 22:22:16] __main__ INFO: \u001b[0mEpoch 56 Step 200/351 lr 0.001000 loss 0.2702 (0.2500) acc@1 0.9219 (0.9125) acc@5 1.0000 (0.9980)\n",
      "\u001b[32m[2020-06-22 22:22:26] __main__ INFO: \u001b[0mEpoch 56 Step 300/351 lr 0.001000 loss 0.2557 (0.2515) acc@1 0.9062 (0.9121) acc@5 1.0000 (0.9983)\n",
      "\u001b[32m[2020-06-22 22:22:30] __main__ INFO: \u001b[0mEpoch 56 Step 351/351 lr 0.001000 loss 0.2720 (0.2511) acc@1 0.9062 (0.9123) acc@5 1.0000 (0.9984)\n",
      "\u001b[32m[2020-06-22 22:22:30] __main__ INFO: \u001b[0mElapsed 32.37\n",
      "\u001b[32m[2020-06-22 22:22:30] __main__ INFO: \u001b[0mVal 56\n",
      "\u001b[32m[2020-06-22 22:22:31] __main__ INFO: \u001b[0mEpoch 56 loss 0.4621 acc@1 0.8562 acc@5 0.9932\n",
      "\u001b[32m[2020-06-22 22:22:31] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 22:22:31] __main__ INFO: \u001b[0mTrain 57 19656\n",
      "\u001b[32m[2020-06-22 22:22:41] __main__ INFO: \u001b[0mEpoch 57 Step 100/351 lr 0.001000 loss 0.1732 (0.2435) acc@1 0.9219 (0.9164) acc@5 1.0000 (0.9987)\n",
      "\u001b[32m[2020-06-22 22:22:50] __main__ INFO: \u001b[0mEpoch 57 Step 200/351 lr 0.001000 loss 0.2591 (0.2450) acc@1 0.9062 (0.9151) acc@5 1.0000 (0.9985)\n",
      "\u001b[32m[2020-06-22 22:22:59] __main__ INFO: \u001b[0mEpoch 57 Step 300/351 lr 0.001000 loss 0.2069 (0.2469) acc@1 0.9375 (0.9133) acc@5 1.0000 (0.9985)\n",
      "\u001b[32m[2020-06-22 22:23:04] __main__ INFO: \u001b[0mEpoch 57 Step 351/351 lr 0.001000 loss 0.2645 (0.2464) acc@1 0.9375 (0.9137) acc@5 0.9922 (0.9984)\n",
      "\u001b[32m[2020-06-22 22:23:04] __main__ INFO: \u001b[0mElapsed 32.45\n",
      "\u001b[32m[2020-06-22 22:23:04] __main__ INFO: \u001b[0mVal 57\n",
      "\u001b[32m[2020-06-22 22:23:05] __main__ INFO: \u001b[0mEpoch 57 loss 0.4659 acc@1 0.8534 acc@5 0.9930\n",
      "\u001b[32m[2020-06-22 22:23:05] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 22:23:05] __main__ INFO: \u001b[0mTrain 58 20007\n",
      "\u001b[32m[2020-06-22 22:23:14] __main__ INFO: \u001b[0mEpoch 58 Step 100/351 lr 0.001000 loss 0.1351 (0.2428) acc@1 0.9531 (0.9135) acc@5 1.0000 (0.9985)\n",
      "\u001b[32m[2020-06-22 22:23:23] __main__ INFO: \u001b[0mEpoch 58 Step 200/351 lr 0.001000 loss 0.2481 (0.2419) acc@1 0.9219 (0.9133) acc@5 1.0000 (0.9985)\n",
      "\u001b[32m[2020-06-22 22:23:33] __main__ INFO: \u001b[0mEpoch 58 Step 300/351 lr 0.001000 loss 0.2244 (0.2470) acc@1 0.9219 (0.9130) acc@5 1.0000 (0.9984)\n",
      "\u001b[32m[2020-06-22 22:23:37] __main__ INFO: \u001b[0mEpoch 58 Step 351/351 lr 0.001000 loss 0.2367 (0.2463) acc@1 0.9141 (0.9129) acc@5 0.9922 (0.9985)\n",
      "\u001b[32m[2020-06-22 22:23:37] __main__ INFO: \u001b[0mElapsed 32.42\n",
      "\u001b[32m[2020-06-22 22:23:37] __main__ INFO: \u001b[0mVal 58\n",
      "\u001b[32m[2020-06-22 22:23:38] __main__ INFO: \u001b[0mEpoch 58 loss 0.4666 acc@1 0.8528 acc@5 0.9934\n",
      "\u001b[32m[2020-06-22 22:23:38] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 22:23:38] __main__ INFO: \u001b[0mTrain 59 20358\n",
      "\u001b[32m[2020-06-22 22:23:48] __main__ INFO: \u001b[0mEpoch 59 Step 100/351 lr 0.001000 loss 0.2572 (0.2325) acc@1 0.8984 (0.9155) acc@5 1.0000 (0.9984)\n",
      "\u001b[32m[2020-06-22 22:23:57] __main__ INFO: \u001b[0mEpoch 59 Step 200/351 lr 0.001000 loss 0.1827 (0.2374) acc@1 0.9297 (0.9158) acc@5 1.0000 (0.9984)\n",
      "\u001b[32m[2020-06-22 22:24:06] __main__ INFO: \u001b[0mEpoch 59 Step 300/351 lr 0.001000 loss 0.2661 (0.2400) acc@1 0.9219 (0.9148) acc@5 1.0000 (0.9982)\n",
      "\u001b[32m[2020-06-22 22:24:11] __main__ INFO: \u001b[0mEpoch 59 Step 351/351 lr 0.001000 loss 0.2455 (0.2393) acc@1 0.9297 (0.9151) acc@5 0.9922 (0.9982)\n",
      "\u001b[32m[2020-06-22 22:24:11] __main__ INFO: \u001b[0mElapsed 32.39\n",
      "\u001b[32m[2020-06-22 22:24:11] __main__ INFO: \u001b[0mVal 59\n",
      "\u001b[32m[2020-06-22 22:24:12] __main__ INFO: \u001b[0mEpoch 59 loss 0.4714 acc@1 0.8548 acc@5 0.9926\n",
      "\u001b[32m[2020-06-22 22:24:12] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 22:24:12] __main__ INFO: \u001b[0mTrain 60 20709\n",
      "\u001b[32m[2020-06-22 22:24:21] __main__ INFO: \u001b[0mEpoch 60 Step 100/351 lr 0.001000 loss 0.2224 (0.2383) acc@1 0.9062 (0.9157) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-06-22 22:24:30] __main__ INFO: \u001b[0mEpoch 60 Step 200/351 lr 0.001000 loss 0.2334 (0.2341) acc@1 0.9062 (0.9178) acc@5 1.0000 (0.9986)\n",
      "\u001b[32m[2020-06-22 22:24:40] __main__ INFO: \u001b[0mEpoch 60 Step 300/351 lr 0.001000 loss 0.3034 (0.2365) acc@1 0.8906 (0.9176) acc@5 1.0000 (0.9986)\n",
      "\u001b[32m[2020-06-22 22:24:44] __main__ INFO: \u001b[0mEpoch 60 Step 351/351 lr 0.001000 loss 0.1731 (0.2370) acc@1 0.9531 (0.9170) acc@5 0.9922 (0.9986)\n",
      "\u001b[32m[2020-06-22 22:24:44] __main__ INFO: \u001b[0mElapsed 32.42\n",
      "\u001b[32m[2020-06-22 22:24:44] __main__ INFO: \u001b[0mVal 60\n",
      "\u001b[32m[2020-06-22 22:24:45] __main__ INFO: \u001b[0mEpoch 60 loss 0.4725 acc@1 0.8520 acc@5 0.9916\n",
      "\u001b[32m[2020-06-22 22:24:45] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-22 22:24:45] __main__ INFO: \u001b[0mTrain 61 21060\n",
      "\u001b[32m[2020-06-22 22:24:55] __main__ INFO: \u001b[0mEpoch 61 Step 100/351 lr 0.001000 loss 0.1605 (0.2230) acc@1 0.9453 (0.9223) acc@5 0.9922 (0.9987)\n",
      "\u001b[32m[2020-06-22 22:25:04] __main__ INFO: \u001b[0mEpoch 61 Step 200/351 lr 0.001000 loss 0.2505 (0.2269) acc@1 0.9219 (0.9210) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-06-22 22:25:13] __main__ INFO: \u001b[0mEpoch 61 Step 300/351 lr 0.001000 loss 0.1597 (0.2300) acc@1 0.9531 (0.9197) acc@5 0.9922 (0.9986)\n",
      "\u001b[32m[2020-06-22 22:25:18] __main__ INFO: \u001b[0mEpoch 61 Step 351/351 lr 0.001000 loss 0.2542 (0.2309) acc@1 0.9062 (0.9193) acc@5 1.0000 (0.9985)\n",
      "\u001b[32m[2020-06-22 22:25:18] __main__ INFO: \u001b[0mElapsed 32.40\n",
      "\u001b[32m[2020-06-22 22:25:18] __main__ INFO: \u001b[0mVal 61\n",
      "\u001b[32m[2020-06-22 22:25:19] __main__ INFO: \u001b[0mEpoch 61 loss 0.4748 acc@1 0.8528 acc@5 0.9918\n",
      "\u001b[32m[2020-06-22 22:25:19] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 22:25:19] __main__ INFO: \u001b[0mTrain 62 21411\n",
      "\u001b[32m[2020-06-22 22:25:28] __main__ INFO: \u001b[0mEpoch 62 Step 100/351 lr 0.001000 loss 0.1768 (0.2321) acc@1 0.9141 (0.9198) acc@5 1.0000 (0.9987)\n",
      "\u001b[32m[2020-06-22 22:25:37] __main__ INFO: \u001b[0mEpoch 62 Step 200/351 lr 0.001000 loss 0.1366 (0.2316) acc@1 0.9688 (0.9193) acc@5 1.0000 (0.9986)\n",
      "\u001b[32m[2020-06-22 22:25:46] __main__ INFO: \u001b[0mEpoch 62 Step 300/351 lr 0.001000 loss 0.2648 (0.2320) acc@1 0.8984 (0.9187) acc@5 0.9922 (0.9985)\n",
      "\u001b[32m[2020-06-22 22:25:51] __main__ INFO: \u001b[0mEpoch 62 Step 351/351 lr 0.001000 loss 0.1783 (0.2328) acc@1 0.9297 (0.9181) acc@5 1.0000 (0.9986)\n",
      "\u001b[32m[2020-06-22 22:25:51] __main__ INFO: \u001b[0mElapsed 32.40\n",
      "\u001b[32m[2020-06-22 22:25:51] __main__ INFO: \u001b[0mVal 62\n",
      "\u001b[32m[2020-06-22 22:25:52] __main__ INFO: \u001b[0mEpoch 62 loss 0.4717 acc@1 0.8522 acc@5 0.9930\n",
      "\u001b[32m[2020-06-22 22:25:52] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 22:25:52] __main__ INFO: \u001b[0mTrain 63 21762\n",
      "\u001b[32m[2020-06-22 22:26:02] __main__ INFO: \u001b[0mEpoch 63 Step 100/351 lr 0.001000 loss 0.3032 (0.2278) acc@1 0.9141 (0.9206) acc@5 1.0000 (0.9984)\n",
      "\u001b[32m[2020-06-22 22:26:11] __main__ INFO: \u001b[0mEpoch 63 Step 200/351 lr 0.001000 loss 0.3316 (0.2302) acc@1 0.8906 (0.9199) acc@5 1.0000 (0.9985)\n",
      "\u001b[32m[2020-06-22 22:26:20] __main__ INFO: \u001b[0mEpoch 63 Step 300/351 lr 0.001000 loss 0.2085 (0.2284) acc@1 0.9297 (0.9199) acc@5 1.0000 (0.9987)\n",
      "\u001b[32m[2020-06-22 22:26:25] __main__ INFO: \u001b[0mEpoch 63 Step 351/351 lr 0.001000 loss 0.2815 (0.2273) acc@1 0.9141 (0.9202) acc@5 1.0000 (0.9986)\n",
      "\u001b[32m[2020-06-22 22:26:25] __main__ INFO: \u001b[0mElapsed 32.39\n",
      "\u001b[32m[2020-06-22 22:26:25] __main__ INFO: \u001b[0mVal 63\n",
      "\u001b[32m[2020-06-22 22:26:26] __main__ INFO: \u001b[0mEpoch 63 loss 0.4652 acc@1 0.8546 acc@5 0.9924\n",
      "\u001b[32m[2020-06-22 22:26:26] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 22:26:26] __main__ INFO: \u001b[0mTrain 64 22113\n",
      "\u001b[32m[2020-06-22 22:26:35] __main__ INFO: \u001b[0mEpoch 64 Step 100/351 lr 0.001000 loss 0.2090 (0.2230) acc@1 0.9219 (0.9223) acc@5 0.9922 (0.9988)\n",
      "\u001b[32m[2020-06-22 22:26:44] __main__ INFO: \u001b[0mEpoch 64 Step 200/351 lr 0.001000 loss 0.1825 (0.2221) acc@1 0.9531 (0.9221) acc@5 1.0000 (0.9984)\n",
      "\u001b[32m[2020-06-22 22:26:53] __main__ INFO: \u001b[0mEpoch 64 Step 300/351 lr 0.001000 loss 0.1597 (0.2225) acc@1 0.9531 (0.9223) acc@5 1.0000 (0.9984)\n",
      "\u001b[32m[2020-06-22 22:26:58] __main__ INFO: \u001b[0mEpoch 64 Step 351/351 lr 0.001000 loss 0.2470 (0.2239) acc@1 0.9375 (0.9219) acc@5 1.0000 (0.9983)\n",
      "\u001b[32m[2020-06-22 22:26:58] __main__ INFO: \u001b[0mElapsed 32.44\n",
      "\u001b[32m[2020-06-22 22:26:58] __main__ INFO: \u001b[0mVal 64\n",
      "\u001b[32m[2020-06-22 22:26:59] __main__ INFO: \u001b[0mEpoch 64 loss 0.4723 acc@1 0.8540 acc@5 0.9912\n",
      "\u001b[32m[2020-06-22 22:26:59] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 22:26:59] __main__ INFO: \u001b[0mTrain 65 22464\n",
      "\u001b[32m[2020-06-22 22:27:09] __main__ INFO: \u001b[0mEpoch 65 Step 100/351 lr 0.001000 loss 0.1755 (0.2191) acc@1 0.9453 (0.9224) acc@5 1.0000 (0.9985)\n",
      "\u001b[32m[2020-06-22 22:27:18] __main__ INFO: \u001b[0mEpoch 65 Step 200/351 lr 0.001000 loss 0.1465 (0.2219) acc@1 0.9453 (0.9209) acc@5 1.0000 (0.9987)\n",
      "\u001b[32m[2020-06-22 22:27:27] __main__ INFO: \u001b[0mEpoch 65 Step 300/351 lr 0.001000 loss 0.2144 (0.2248) acc@1 0.9219 (0.9202) acc@5 0.9922 (0.9984)\n",
      "\u001b[32m[2020-06-22 22:27:32] __main__ INFO: \u001b[0mEpoch 65 Step 351/351 lr 0.001000 loss 0.2515 (0.2258) acc@1 0.9219 (0.9197) acc@5 1.0000 (0.9983)\n",
      "\u001b[32m[2020-06-22 22:27:32] __main__ INFO: \u001b[0mElapsed 32.38\n",
      "\u001b[32m[2020-06-22 22:27:32] __main__ INFO: \u001b[0mVal 65\n",
      "\u001b[32m[2020-06-22 22:27:33] __main__ INFO: \u001b[0mEpoch 65 loss 0.4776 acc@1 0.8536 acc@5 0.9922\n",
      "\u001b[32m[2020-06-22 22:27:33] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 22:27:33] __main__ INFO: \u001b[0mTrain 66 22815\n",
      "\u001b[32m[2020-06-22 22:27:42] __main__ INFO: \u001b[0mEpoch 66 Step 100/351 lr 0.001000 loss 0.1978 (0.2224) acc@1 0.9531 (0.9230) acc@5 1.0000 (0.9983)\n",
      "\u001b[32m[2020-06-22 22:27:51] __main__ INFO: \u001b[0mEpoch 66 Step 200/351 lr 0.001000 loss 0.2046 (0.2207) acc@1 0.9531 (0.9238) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-06-22 22:28:00] __main__ INFO: \u001b[0mEpoch 66 Step 300/351 lr 0.001000 loss 0.2618 (0.2242) acc@1 0.9062 (0.9218) acc@5 1.0000 (0.9986)\n",
      "\u001b[32m[2020-06-22 22:28:05] __main__ INFO: \u001b[0mEpoch 66 Step 351/351 lr 0.001000 loss 0.1934 (0.2238) acc@1 0.9453 (0.9220) acc@5 1.0000 (0.9987)\n",
      "\u001b[32m[2020-06-22 22:28:05] __main__ INFO: \u001b[0mElapsed 32.40\n",
      "\u001b[32m[2020-06-22 22:28:05] __main__ INFO: \u001b[0mVal 66\n",
      "\u001b[32m[2020-06-22 22:28:06] __main__ INFO: \u001b[0mEpoch 66 loss 0.4721 acc@1 0.8560 acc@5 0.9918\n",
      "\u001b[32m[2020-06-22 22:28:06] __main__ INFO: \u001b[0mElapsed 1.11\n",
      "\u001b[32m[2020-06-22 22:28:06] __main__ INFO: \u001b[0mTrain 67 23166\n",
      "\u001b[32m[2020-06-22 22:28:16] __main__ INFO: \u001b[0mEpoch 67 Step 100/351 lr 0.001000 loss 0.2497 (0.2205) acc@1 0.9062 (0.9210) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-22 22:28:25] __main__ INFO: \u001b[0mEpoch 67 Step 200/351 lr 0.001000 loss 0.3055 (0.2198) acc@1 0.8984 (0.9223) acc@5 0.9922 (0.9988)\n",
      "\u001b[32m[2020-06-22 22:28:34] __main__ INFO: \u001b[0mEpoch 67 Step 300/351 lr 0.001000 loss 0.2774 (0.2202) acc@1 0.9141 (0.9218) acc@5 0.9844 (0.9988)\n",
      "\u001b[32m[2020-06-22 22:28:39] __main__ INFO: \u001b[0mEpoch 67 Step 351/351 lr 0.001000 loss 0.1729 (0.2210) acc@1 0.9219 (0.9217) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-06-22 22:28:39] __main__ INFO: \u001b[0mElapsed 32.41\n",
      "\u001b[32m[2020-06-22 22:28:39] __main__ INFO: \u001b[0mVal 67\n",
      "\u001b[32m[2020-06-22 22:28:40] __main__ INFO: \u001b[0mEpoch 67 loss 0.4753 acc@1 0.8548 acc@5 0.9924\n",
      "\u001b[32m[2020-06-22 22:28:40] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 22:28:40] __main__ INFO: \u001b[0mTrain 68 23517\n",
      "\u001b[32m[2020-06-22 22:28:49] __main__ INFO: \u001b[0mEpoch 68 Step 100/351 lr 0.001000 loss 0.1671 (0.2106) acc@1 0.9531 (0.9251) acc@5 1.0000 (0.9989)\n",
      "\u001b[32m[2020-06-22 22:28:58] __main__ INFO: \u001b[0mEpoch 68 Step 200/351 lr 0.001000 loss 0.1693 (0.2133) acc@1 0.9375 (0.9247) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-06-22 22:29:07] __main__ INFO: \u001b[0mEpoch 68 Step 300/351 lr 0.001000 loss 0.2239 (0.2137) acc@1 0.9141 (0.9244) acc@5 1.0000 (0.9989)\n",
      "\u001b[32m[2020-06-22 22:29:12] __main__ INFO: \u001b[0mEpoch 68 Step 351/351 lr 0.001000 loss 0.1794 (0.2149) acc@1 0.9141 (0.9241) acc@5 1.0000 (0.9989)\n",
      "\u001b[32m[2020-06-22 22:29:12] __main__ INFO: \u001b[0mElapsed 32.41\n",
      "\u001b[32m[2020-06-22 22:29:12] __main__ INFO: \u001b[0mVal 68\n",
      "\u001b[32m[2020-06-22 22:29:13] __main__ INFO: \u001b[0mEpoch 68 loss 0.4770 acc@1 0.8592 acc@5 0.9916\n",
      "\u001b[32m[2020-06-22 22:29:13] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 22:29:13] __main__ INFO: \u001b[0mTrain 69 23868\n",
      "\u001b[32m[2020-06-22 22:29:23] __main__ INFO: \u001b[0mEpoch 69 Step 100/351 lr 0.001000 loss 0.1471 (0.2123) acc@1 0.9531 (0.9253) acc@5 1.0000 (0.9984)\n",
      "\u001b[32m[2020-06-22 22:29:32] __main__ INFO: \u001b[0mEpoch 69 Step 200/351 lr 0.001000 loss 0.1970 (0.2131) acc@1 0.9531 (0.9259) acc@5 1.0000 (0.9985)\n",
      "\u001b[32m[2020-06-22 22:29:41] __main__ INFO: \u001b[0mEpoch 69 Step 300/351 lr 0.001000 loss 0.2122 (0.2168) acc@1 0.9141 (0.9249) acc@5 1.0000 (0.9985)\n",
      "\u001b[32m[2020-06-22 22:29:46] __main__ INFO: \u001b[0mEpoch 69 Step 351/351 lr 0.001000 loss 0.2713 (0.2147) acc@1 0.9062 (0.9255) acc@5 1.0000 (0.9986)\n",
      "\u001b[32m[2020-06-22 22:29:46] __main__ INFO: \u001b[0mElapsed 32.41\n",
      "\u001b[32m[2020-06-22 22:29:46] __main__ INFO: \u001b[0mVal 69\n",
      "\u001b[32m[2020-06-22 22:29:47] __main__ INFO: \u001b[0mEpoch 69 loss 0.4766 acc@1 0.8550 acc@5 0.9924\n",
      "\u001b[32m[2020-06-22 22:29:47] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 22:29:47] __main__ INFO: \u001b[0mTrain 70 24219\n",
      "\u001b[32m[2020-06-22 22:29:56] __main__ INFO: \u001b[0mEpoch 70 Step 100/351 lr 0.001000 loss 0.2431 (0.2061) acc@1 0.9219 (0.9292) acc@5 0.9922 (0.9992)\n",
      "\u001b[32m[2020-06-22 22:30:05] __main__ INFO: \u001b[0mEpoch 70 Step 200/351 lr 0.001000 loss 0.2240 (0.2084) acc@1 0.8984 (0.9271) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-22 22:30:14] __main__ INFO: \u001b[0mEpoch 70 Step 300/351 lr 0.001000 loss 0.2273 (0.2111) acc@1 0.9219 (0.9251) acc@5 1.0000 (0.9989)\n",
      "\u001b[32m[2020-06-22 22:30:19] __main__ INFO: \u001b[0mEpoch 70 Step 351/351 lr 0.001000 loss 0.2199 (0.2137) acc@1 0.9297 (0.9243) acc@5 0.9922 (0.9989)\n",
      "\u001b[32m[2020-06-22 22:30:19] __main__ INFO: \u001b[0mElapsed 32.39\n",
      "\u001b[32m[2020-06-22 22:30:19] __main__ INFO: \u001b[0mVal 70\n",
      "\u001b[32m[2020-06-22 22:30:20] __main__ INFO: \u001b[0mEpoch 70 loss 0.4747 acc@1 0.8558 acc@5 0.9920\n",
      "\u001b[32m[2020-06-22 22:30:20] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 22:30:20] __main__ INFO: \u001b[0mTrain 71 24570\n",
      "\u001b[32m[2020-06-22 22:30:29] __main__ INFO: \u001b[0mEpoch 71 Step 100/351 lr 0.001000 loss 0.1818 (0.2104) acc@1 0.9375 (0.9284) acc@5 1.0000 (0.9986)\n",
      "\u001b[32m[2020-06-22 22:30:39] __main__ INFO: \u001b[0mEpoch 71 Step 200/351 lr 0.001000 loss 0.2760 (0.2094) acc@1 0.9141 (0.9282) acc@5 0.9844 (0.9987)\n",
      "\u001b[32m[2020-06-22 22:30:48] __main__ INFO: \u001b[0mEpoch 71 Step 300/351 lr 0.001000 loss 0.2454 (0.2100) acc@1 0.9297 (0.9270) acc@5 1.0000 (0.9987)\n",
      "\u001b[32m[2020-06-22 22:30:53] __main__ INFO: \u001b[0mEpoch 71 Step 351/351 lr 0.001000 loss 0.2543 (0.2091) acc@1 0.9062 (0.9273) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-06-22 22:30:53] __main__ INFO: \u001b[0mElapsed 32.43\n",
      "\u001b[32m[2020-06-22 22:30:53] __main__ INFO: \u001b[0mVal 71\n",
      "\u001b[32m[2020-06-22 22:30:54] __main__ INFO: \u001b[0mEpoch 71 loss 0.4751 acc@1 0.8584 acc@5 0.9924\n",
      "\u001b[32m[2020-06-22 22:30:54] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 22:30:54] __main__ INFO: \u001b[0mTrain 72 24921\n",
      "\u001b[32m[2020-06-22 22:31:03] __main__ INFO: \u001b[0mEpoch 72 Step 100/351 lr 0.001000 loss 0.2155 (0.2056) acc@1 0.9062 (0.9280) acc@5 1.0000 (0.9989)\n",
      "\u001b[32m[2020-06-22 22:31:12] __main__ INFO: \u001b[0mEpoch 72 Step 200/351 lr 0.001000 loss 0.2336 (0.2046) acc@1 0.9062 (0.9280) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-22 22:31:21] __main__ INFO: \u001b[0mEpoch 72 Step 300/351 lr 0.001000 loss 0.2546 (0.2026) acc@1 0.9297 (0.9281) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-22 22:31:26] __main__ INFO: \u001b[0mEpoch 72 Step 351/351 lr 0.001000 loss 0.1750 (0.2050) acc@1 0.9375 (0.9269) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-22 22:31:26] __main__ INFO: \u001b[0mElapsed 32.43\n",
      "\u001b[32m[2020-06-22 22:31:26] __main__ INFO: \u001b[0mVal 72\n",
      "\u001b[32m[2020-06-22 22:31:27] __main__ INFO: \u001b[0mEpoch 72 loss 0.4785 acc@1 0.8564 acc@5 0.9938\n",
      "\u001b[32m[2020-06-22 22:31:27] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 22:31:27] __main__ INFO: \u001b[0mTrain 73 25272\n",
      "\u001b[32m[2020-06-22 22:31:36] __main__ INFO: \u001b[0mEpoch 73 Step 100/351 lr 0.001000 loss 0.1532 (0.2126) acc@1 0.9297 (0.9241) acc@5 1.0000 (0.9984)\n",
      "\u001b[32m[2020-06-22 22:31:46] __main__ INFO: \u001b[0mEpoch 73 Step 200/351 lr 0.001000 loss 0.1635 (0.2053) acc@1 0.9531 (0.9275) acc@5 1.0000 (0.9985)\n",
      "\u001b[32m[2020-06-22 22:31:55] __main__ INFO: \u001b[0mEpoch 73 Step 300/351 lr 0.001000 loss 0.1548 (0.2062) acc@1 0.9531 (0.9277) acc@5 1.0000 (0.9984)\n",
      "\u001b[32m[2020-06-22 22:32:00] __main__ INFO: \u001b[0mEpoch 73 Step 351/351 lr 0.001000 loss 0.2525 (0.2060) acc@1 0.8906 (0.9280) acc@5 1.0000 (0.9986)\n",
      "\u001b[32m[2020-06-22 22:32:00] __main__ INFO: \u001b[0mElapsed 32.40\n",
      "\u001b[32m[2020-06-22 22:32:00] __main__ INFO: \u001b[0mVal 73\n",
      "\u001b[32m[2020-06-22 22:32:01] __main__ INFO: \u001b[0mEpoch 73 loss 0.4831 acc@1 0.8554 acc@5 0.9928\n",
      "\u001b[32m[2020-06-22 22:32:01] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 22:32:01] __main__ INFO: \u001b[0mTrain 74 25623\n",
      "\u001b[32m[2020-06-22 22:32:10] __main__ INFO: \u001b[0mEpoch 74 Step 100/351 lr 0.001000 loss 0.1670 (0.2048) acc@1 0.9453 (0.9286) acc@5 0.9922 (0.9987)\n",
      "\u001b[32m[2020-06-22 22:32:19] __main__ INFO: \u001b[0mEpoch 74 Step 200/351 lr 0.001000 loss 0.1934 (0.2061) acc@1 0.9453 (0.9283) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-06-22 22:32:28] __main__ INFO: \u001b[0mEpoch 74 Step 300/351 lr 0.001000 loss 0.1799 (0.2064) acc@1 0.9375 (0.9280) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-06-22 22:32:33] __main__ INFO: \u001b[0mEpoch 74 Step 351/351 lr 0.001000 loss 0.2437 (0.2064) acc@1 0.9141 (0.9277) acc@5 1.0000 (0.9987)\n",
      "\u001b[32m[2020-06-22 22:32:33] __main__ INFO: \u001b[0mElapsed 32.41\n",
      "\u001b[32m[2020-06-22 22:32:33] __main__ INFO: \u001b[0mVal 74\n",
      "\u001b[32m[2020-06-22 22:32:34] __main__ INFO: \u001b[0mEpoch 74 loss 0.4843 acc@1 0.8546 acc@5 0.9914\n",
      "\u001b[32m[2020-06-22 22:32:34] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 22:32:34] __main__ INFO: \u001b[0mTrain 75 25974\n",
      "\u001b[32m[2020-06-22 22:32:43] __main__ INFO: \u001b[0mEpoch 75 Step 100/351 lr 0.001000 loss 0.2405 (0.1929) acc@1 0.9141 (0.9341) acc@5 0.9922 (0.9988)\n",
      "\u001b[32m[2020-06-22 22:32:53] __main__ INFO: \u001b[0mEpoch 75 Step 200/351 lr 0.001000 loss 0.1761 (0.1983) acc@1 0.9375 (0.9318) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-06-22 22:33:02] __main__ INFO: \u001b[0mEpoch 75 Step 300/351 lr 0.001000 loss 0.2769 (0.2026) acc@1 0.8906 (0.9301) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-06-22 22:33:07] __main__ INFO: \u001b[0mEpoch 75 Step 351/351 lr 0.001000 loss 0.0987 (0.2021) acc@1 0.9844 (0.9296) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-06-22 22:33:07] __main__ INFO: \u001b[0mElapsed 32.42\n",
      "\u001b[32m[2020-06-22 22:33:07] __main__ INFO: \u001b[0mVal 75\n",
      "\u001b[32m[2020-06-22 22:33:08] __main__ INFO: \u001b[0mEpoch 75 loss 0.4792 acc@1 0.8570 acc@5 0.9926\n",
      "\u001b[32m[2020-06-22 22:33:08] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-22 22:33:08] __main__ INFO: \u001b[0mTrain 76 26325\n",
      "\u001b[32m[2020-06-22 22:33:17] __main__ INFO: \u001b[0mEpoch 76 Step 100/351 lr 0.001000 loss 0.1541 (0.1967) acc@1 0.9453 (0.9302) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 22:33:26] __main__ INFO: \u001b[0mEpoch 76 Step 200/351 lr 0.001000 loss 0.3056 (0.1969) acc@1 0.9141 (0.9307) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-22 22:33:35] __main__ INFO: \u001b[0mEpoch 76 Step 300/351 lr 0.001000 loss 0.1846 (0.1952) acc@1 0.9219 (0.9319) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-22 22:33:40] __main__ INFO: \u001b[0mEpoch 76 Step 351/351 lr 0.001000 loss 0.2540 (0.1962) acc@1 0.9062 (0.9315) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-22 22:33:40] __main__ INFO: \u001b[0mElapsed 32.41\n",
      "\u001b[32m[2020-06-22 22:33:40] __main__ INFO: \u001b[0mVal 76\n",
      "\u001b[32m[2020-06-22 22:33:41] __main__ INFO: \u001b[0mEpoch 76 loss 0.4891 acc@1 0.8560 acc@5 0.9914\n",
      "\u001b[32m[2020-06-22 22:33:41] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 22:33:41] __main__ INFO: \u001b[0mTrain 77 26676\n",
      "\u001b[32m[2020-06-22 22:33:50] __main__ INFO: \u001b[0mEpoch 77 Step 100/351 lr 0.001000 loss 0.2466 (0.1893) acc@1 0.9141 (0.9329) acc@5 1.0000 (0.9989)\n",
      "\u001b[32m[2020-06-22 22:34:00] __main__ INFO: \u001b[0mEpoch 77 Step 200/351 lr 0.001000 loss 0.2771 (0.1935) acc@1 0.8984 (0.9308) acc@5 0.9922 (0.9990)\n",
      "\u001b[32m[2020-06-22 22:34:09] __main__ INFO: \u001b[0mEpoch 77 Step 300/351 lr 0.001000 loss 0.2116 (0.1971) acc@1 0.9219 (0.9296) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-22 22:34:14] __main__ INFO: \u001b[0mEpoch 77 Step 351/351 lr 0.001000 loss 0.1964 (0.1970) acc@1 0.9453 (0.9300) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-22 22:34:14] __main__ INFO: \u001b[0mElapsed 32.48\n",
      "\u001b[32m[2020-06-22 22:34:14] __main__ INFO: \u001b[0mVal 77\n",
      "\u001b[32m[2020-06-22 22:34:15] __main__ INFO: \u001b[0mEpoch 77 loss 0.4827 acc@1 0.8542 acc@5 0.9930\n",
      "\u001b[32m[2020-06-22 22:34:15] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 22:34:15] __main__ INFO: \u001b[0mTrain 78 27027\n",
      "\u001b[32m[2020-06-22 22:34:24] __main__ INFO: \u001b[0mEpoch 78 Step 100/351 lr 0.001000 loss 0.1287 (0.1977) acc@1 0.9453 (0.9327) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-22 22:34:33] __main__ INFO: \u001b[0mEpoch 78 Step 200/351 lr 0.001000 loss 0.2149 (0.1919) acc@1 0.9297 (0.9339) acc@5 0.9922 (0.9992)\n",
      "\u001b[32m[2020-06-22 22:34:42] __main__ INFO: \u001b[0mEpoch 78 Step 300/351 lr 0.001000 loss 0.1277 (0.1949) acc@1 0.9688 (0.9324) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-22 22:34:47] __main__ INFO: \u001b[0mEpoch 78 Step 351/351 lr 0.001000 loss 0.1736 (0.1954) acc@1 0.9375 (0.9319) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 22:34:47] __main__ INFO: \u001b[0mElapsed 32.46\n",
      "\u001b[32m[2020-06-22 22:34:47] __main__ INFO: \u001b[0mVal 78\n",
      "\u001b[32m[2020-06-22 22:34:48] __main__ INFO: \u001b[0mEpoch 78 loss 0.4887 acc@1 0.8552 acc@5 0.9920\n",
      "\u001b[32m[2020-06-22 22:34:48] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-22 22:34:48] __main__ INFO: \u001b[0mTrain 79 27378\n",
      "\u001b[32m[2020-06-22 22:34:58] __main__ INFO: \u001b[0mEpoch 79 Step 100/351 lr 0.001000 loss 0.1661 (0.1869) acc@1 0.9297 (0.9330) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-06-22 22:35:07] __main__ INFO: \u001b[0mEpoch 79 Step 200/351 lr 0.001000 loss 0.2661 (0.1887) acc@1 0.8984 (0.9332) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-22 22:35:16] __main__ INFO: \u001b[0mEpoch 79 Step 300/351 lr 0.001000 loss 0.2255 (0.1917) acc@1 0.9141 (0.9326) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-22 22:35:21] __main__ INFO: \u001b[0mEpoch 79 Step 351/351 lr 0.001000 loss 0.2189 (0.1931) acc@1 0.9375 (0.9322) acc@5 0.9922 (0.9990)\n",
      "\u001b[32m[2020-06-22 22:35:21] __main__ INFO: \u001b[0mElapsed 32.48\n",
      "\u001b[32m[2020-06-22 22:35:21] __main__ INFO: \u001b[0mVal 79\n",
      "\u001b[32m[2020-06-22 22:35:22] __main__ INFO: \u001b[0mEpoch 79 loss 0.4871 acc@1 0.8540 acc@5 0.9926\n",
      "\u001b[32m[2020-06-22 22:35:22] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 22:35:22] __main__ INFO: \u001b[0mTrain 80 27729\n",
      "\u001b[32m[2020-06-22 22:35:31] __main__ INFO: \u001b[0mEpoch 80 Step 100/351 lr 0.001000 loss 0.3048 (0.1789) acc@1 0.8828 (0.9389) acc@5 1.0000 (0.9989)\n",
      "\u001b[32m[2020-06-22 22:35:40] __main__ INFO: \u001b[0mEpoch 80 Step 200/351 lr 0.001000 loss 0.2124 (0.1840) acc@1 0.9062 (0.9362) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-22 22:35:50] __main__ INFO: \u001b[0mEpoch 80 Step 300/351 lr 0.001000 loss 0.2949 (0.1861) acc@1 0.9531 (0.9352) acc@5 0.9922 (0.9990)\n",
      "\u001b[32m[2020-06-22 22:35:54] __main__ INFO: \u001b[0mEpoch 80 Step 351/351 lr 0.001000 loss 0.2581 (0.1887) acc@1 0.8984 (0.9344) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-22 22:35:54] __main__ INFO: \u001b[0mElapsed 32.43\n",
      "\u001b[32m[2020-06-22 22:35:54] __main__ INFO: \u001b[0mVal 80\n",
      "\u001b[32m[2020-06-22 22:35:55] __main__ INFO: \u001b[0mEpoch 80 loss 0.4992 acc@1 0.8560 acc@5 0.9928\n",
      "\u001b[32m[2020-06-22 22:35:55] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 22:35:55] __main__ INFO: \u001b[0mTrain 81 28080\n",
      "\u001b[32m[2020-06-22 22:36:05] __main__ INFO: \u001b[0mEpoch 81 Step 100/351 lr 0.000100 loss 0.2181 (0.1813) acc@1 0.9219 (0.9372) acc@5 1.0000 (0.9987)\n",
      "\u001b[32m[2020-06-22 22:36:14] __main__ INFO: \u001b[0mEpoch 81 Step 200/351 lr 0.000100 loss 0.1240 (0.1820) acc@1 0.9688 (0.9371) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-22 22:36:23] __main__ INFO: \u001b[0mEpoch 81 Step 300/351 lr 0.000100 loss 0.2102 (0.1801) acc@1 0.9141 (0.9378) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 22:36:28] __main__ INFO: \u001b[0mEpoch 81 Step 351/351 lr 0.000100 loss 0.1242 (0.1794) acc@1 0.9688 (0.9381) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 22:36:28] __main__ INFO: \u001b[0mElapsed 32.49\n",
      "\u001b[32m[2020-06-22 22:36:28] __main__ INFO: \u001b[0mVal 81\n",
      "\u001b[32m[2020-06-22 22:36:29] __main__ INFO: \u001b[0mEpoch 81 loss 0.4913 acc@1 0.8560 acc@5 0.9934\n",
      "\u001b[32m[2020-06-22 22:36:29] __main__ INFO: \u001b[0mElapsed 1.13\n",
      "\u001b[32m[2020-06-22 22:36:29] __main__ INFO: \u001b[0mTrain 82 28431\n",
      "\u001b[32m[2020-06-22 22:36:38] __main__ INFO: \u001b[0mEpoch 82 Step 100/351 lr 0.000100 loss 0.1851 (0.1725) acc@1 0.9297 (0.9429) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 22:36:48] __main__ INFO: \u001b[0mEpoch 82 Step 200/351 lr 0.000100 loss 0.1681 (0.1743) acc@1 0.9297 (0.9414) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 22:36:57] __main__ INFO: \u001b[0mEpoch 82 Step 300/351 lr 0.000100 loss 0.2330 (0.1750) acc@1 0.9219 (0.9401) acc@5 0.9922 (0.9991)\n",
      "\u001b[32m[2020-06-22 22:37:01] __main__ INFO: \u001b[0mEpoch 82 Step 351/351 lr 0.000100 loss 0.1325 (0.1745) acc@1 0.9688 (0.9408) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 22:37:01] __main__ INFO: \u001b[0mElapsed 32.51\n",
      "\u001b[32m[2020-06-22 22:37:01] __main__ INFO: \u001b[0mVal 82\n",
      "\u001b[32m[2020-06-22 22:37:02] __main__ INFO: \u001b[0mEpoch 82 loss 0.4926 acc@1 0.8582 acc@5 0.9926\n",
      "\u001b[32m[2020-06-22 22:37:02] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 22:37:02] __main__ INFO: \u001b[0mTrain 83 28782\n",
      "\u001b[32m[2020-06-22 22:37:12] __main__ INFO: \u001b[0mEpoch 83 Step 100/351 lr 0.000100 loss 0.2035 (0.1771) acc@1 0.9141 (0.9399) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-22 22:37:21] __main__ INFO: \u001b[0mEpoch 83 Step 200/351 lr 0.000100 loss 0.0945 (0.1791) acc@1 0.9766 (0.9380) acc@5 1.0000 (0.9989)\n",
      "\u001b[32m[2020-06-22 22:37:30] __main__ INFO: \u001b[0mEpoch 83 Step 300/351 lr 0.000100 loss 0.2118 (0.1766) acc@1 0.9141 (0.9385) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-22 22:37:35] __main__ INFO: \u001b[0mEpoch 83 Step 351/351 lr 0.000100 loss 0.1139 (0.1778) acc@1 0.9688 (0.9377) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-22 22:37:35] __main__ INFO: \u001b[0mElapsed 32.47\n",
      "\u001b[32m[2020-06-22 22:37:35] __main__ INFO: \u001b[0mVal 83\n",
      "\u001b[32m[2020-06-22 22:37:36] __main__ INFO: \u001b[0mEpoch 83 loss 0.4891 acc@1 0.8578 acc@5 0.9924\n",
      "\u001b[32m[2020-06-22 22:37:36] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 22:37:36] __main__ INFO: \u001b[0mTrain 84 29133\n",
      "\u001b[32m[2020-06-22 22:37:45] __main__ INFO: \u001b[0mEpoch 84 Step 100/351 lr 0.000100 loss 0.1722 (0.1753) acc@1 0.9297 (0.9403) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-22 22:37:55] __main__ INFO: \u001b[0mEpoch 84 Step 200/351 lr 0.000100 loss 0.1968 (0.1732) acc@1 0.9219 (0.9409) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 22:38:04] __main__ INFO: \u001b[0mEpoch 84 Step 300/351 lr 0.000100 loss 0.1250 (0.1751) acc@1 0.9609 (0.9397) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-22 22:38:08] __main__ INFO: \u001b[0mEpoch 84 Step 351/351 lr 0.000100 loss 0.2366 (0.1770) acc@1 0.9219 (0.9393) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-22 22:38:08] __main__ INFO: \u001b[0mElapsed 32.46\n",
      "\u001b[32m[2020-06-22 22:38:08] __main__ INFO: \u001b[0mVal 84\n",
      "\u001b[32m[2020-06-22 22:38:10] __main__ INFO: \u001b[0mEpoch 84 loss 0.4912 acc@1 0.8574 acc@5 0.9924\n",
      "\u001b[32m[2020-06-22 22:38:10] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 22:38:10] __main__ INFO: \u001b[0mTrain 85 29484\n",
      "\u001b[32m[2020-06-22 22:38:19] __main__ INFO: \u001b[0mEpoch 85 Step 100/351 lr 0.000100 loss 0.2273 (0.1702) acc@1 0.9219 (0.9409) acc@5 1.0000 (0.9989)\n",
      "\u001b[32m[2020-06-22 22:38:28] __main__ INFO: \u001b[0mEpoch 85 Step 200/351 lr 0.000100 loss 0.1677 (0.1693) acc@1 0.9297 (0.9415) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-22 22:38:37] __main__ INFO: \u001b[0mEpoch 85 Step 300/351 lr 0.000100 loss 0.1655 (0.1738) acc@1 0.9219 (0.9392) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 22:38:42] __main__ INFO: \u001b[0mEpoch 85 Step 351/351 lr 0.000100 loss 0.2143 (0.1761) acc@1 0.9531 (0.9382) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 22:38:42] __main__ INFO: \u001b[0mElapsed 32.43\n",
      "\u001b[32m[2020-06-22 22:38:42] __main__ INFO: \u001b[0mVal 85\n",
      "\u001b[32m[2020-06-22 22:38:43] __main__ INFO: \u001b[0mEpoch 85 loss 0.4894 acc@1 0.8568 acc@5 0.9924\n",
      "\u001b[32m[2020-06-22 22:38:43] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 22:38:43] __main__ INFO: \u001b[0mTrain 86 29835\n",
      "\u001b[32m[2020-06-22 22:38:52] __main__ INFO: \u001b[0mEpoch 86 Step 100/351 lr 0.000100 loss 0.1662 (0.1764) acc@1 0.9609 (0.9384) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 22:39:02] __main__ INFO: \u001b[0mEpoch 86 Step 200/351 lr 0.000100 loss 0.2002 (0.1744) acc@1 0.9688 (0.9396) acc@5 0.9922 (0.9992)\n",
      "\u001b[32m[2020-06-22 22:39:11] __main__ INFO: \u001b[0mEpoch 86 Step 300/351 lr 0.000100 loss 0.2740 (0.1753) acc@1 0.8984 (0.9389) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-22 22:39:15] __main__ INFO: \u001b[0mEpoch 86 Step 351/351 lr 0.000100 loss 0.1693 (0.1766) acc@1 0.9453 (0.9388) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-22 22:39:16] __main__ INFO: \u001b[0mElapsed 32.45\n",
      "\u001b[32m[2020-06-22 22:39:16] __main__ INFO: \u001b[0mVal 86\n",
      "\u001b[32m[2020-06-22 22:39:17] __main__ INFO: \u001b[0mEpoch 86 loss 0.4910 acc@1 0.8578 acc@5 0.9922\n",
      "\u001b[32m[2020-06-22 22:39:17] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 22:39:17] __main__ INFO: \u001b[0mTrain 87 30186\n",
      "\u001b[32m[2020-06-22 22:39:26] __main__ INFO: \u001b[0mEpoch 87 Step 100/351 lr 0.000100 loss 0.2004 (0.1685) acc@1 0.9297 (0.9409) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-22 22:39:35] __main__ INFO: \u001b[0mEpoch 87 Step 200/351 lr 0.000100 loss 0.1432 (0.1709) acc@1 0.9609 (0.9405) acc@5 0.9922 (0.9995)\n",
      "\u001b[32m[2020-06-22 22:39:44] __main__ INFO: \u001b[0mEpoch 87 Step 300/351 lr 0.000100 loss 0.1728 (0.1705) acc@1 0.9297 (0.9409) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 22:39:49] __main__ INFO: \u001b[0mEpoch 87 Step 351/351 lr 0.000100 loss 0.2037 (0.1722) acc@1 0.9375 (0.9405) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 22:39:49] __main__ INFO: \u001b[0mElapsed 32.48\n",
      "\u001b[32m[2020-06-22 22:39:49] __main__ INFO: \u001b[0mVal 87\n",
      "\u001b[32m[2020-06-22 22:39:50] __main__ INFO: \u001b[0mEpoch 87 loss 0.4910 acc@1 0.8584 acc@5 0.9926\n",
      "\u001b[32m[2020-06-22 22:39:50] __main__ INFO: \u001b[0mElapsed 1.11\n",
      "\u001b[32m[2020-06-22 22:39:50] __main__ INFO: \u001b[0mTrain 88 30537\n",
      "\u001b[32m[2020-06-22 22:39:59] __main__ INFO: \u001b[0mEpoch 88 Step 100/351 lr 0.000100 loss 0.1415 (0.1713) acc@1 0.9531 (0.9393) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-06-22 22:40:09] __main__ INFO: \u001b[0mEpoch 88 Step 200/351 lr 0.000100 loss 0.1620 (0.1783) acc@1 0.9453 (0.9375) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-22 22:40:18] __main__ INFO: \u001b[0mEpoch 88 Step 300/351 lr 0.000100 loss 0.1575 (0.1774) acc@1 0.9375 (0.9379) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-22 22:40:23] __main__ INFO: \u001b[0mEpoch 88 Step 351/351 lr 0.000100 loss 0.1175 (0.1767) acc@1 0.9609 (0.9379) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-22 22:40:23] __main__ INFO: \u001b[0mElapsed 32.39\n",
      "\u001b[32m[2020-06-22 22:40:23] __main__ INFO: \u001b[0mVal 88\n",
      "\u001b[32m[2020-06-22 22:40:24] __main__ INFO: \u001b[0mEpoch 88 loss 0.4897 acc@1 0.8570 acc@5 0.9924\n",
      "\u001b[32m[2020-06-22 22:40:24] __main__ INFO: \u001b[0mElapsed 1.11\n",
      "\u001b[32m[2020-06-22 22:40:24] __main__ INFO: \u001b[0mTrain 89 30888\n",
      "\u001b[32m[2020-06-22 22:40:33] __main__ INFO: \u001b[0mEpoch 89 Step 100/351 lr 0.000100 loss 0.1495 (0.1635) acc@1 0.9609 (0.9433) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-22 22:40:42] __main__ INFO: \u001b[0mEpoch 89 Step 200/351 lr 0.000100 loss 0.2366 (0.1682) acc@1 0.9141 (0.9406) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-22 22:40:51] __main__ INFO: \u001b[0mEpoch 89 Step 300/351 lr 0.000100 loss 0.2182 (0.1678) acc@1 0.8984 (0.9415) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-22 22:40:56] __main__ INFO: \u001b[0mEpoch 89 Step 351/351 lr 0.000100 loss 0.1693 (0.1688) acc@1 0.9375 (0.9411) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 22:40:56] __main__ INFO: \u001b[0mElapsed 32.46\n",
      "\u001b[32m[2020-06-22 22:40:56] __main__ INFO: \u001b[0mVal 89\n",
      "\u001b[32m[2020-06-22 22:40:57] __main__ INFO: \u001b[0mEpoch 89 loss 0.4892 acc@1 0.8572 acc@5 0.9924\n",
      "\u001b[32m[2020-06-22 22:40:57] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 22:40:57] __main__ INFO: \u001b[0mTrain 90 31239\n",
      "\u001b[32m[2020-06-22 22:41:07] __main__ INFO: \u001b[0mEpoch 90 Step 100/351 lr 0.000100 loss 0.1159 (0.1646) acc@1 0.9609 (0.9441) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 22:41:16] __main__ INFO: \u001b[0mEpoch 90 Step 200/351 lr 0.000100 loss 0.2044 (0.1702) acc@1 0.9219 (0.9416) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-22 22:41:25] __main__ INFO: \u001b[0mEpoch 90 Step 300/351 lr 0.000100 loss 0.2352 (0.1713) acc@1 0.9141 (0.9408) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 22:41:30] __main__ INFO: \u001b[0mEpoch 90 Step 351/351 lr 0.000100 loss 0.1729 (0.1722) acc@1 0.9531 (0.9405) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 22:41:30] __main__ INFO: \u001b[0mElapsed 32.40\n",
      "\u001b[32m[2020-06-22 22:41:30] __main__ INFO: \u001b[0mVal 90\n",
      "\u001b[32m[2020-06-22 22:41:31] __main__ INFO: \u001b[0mEpoch 90 loss 0.4869 acc@1 0.8578 acc@5 0.9930\n",
      "\u001b[32m[2020-06-22 22:41:31] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 22:41:31] __main__ INFO: \u001b[0mTrain 91 31590\n",
      "\u001b[32m[2020-06-22 22:41:40] __main__ INFO: \u001b[0mEpoch 91 Step 100/351 lr 0.000100 loss 0.1236 (0.1737) acc@1 0.9531 (0.9413) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 22:41:49] __main__ INFO: \u001b[0mEpoch 91 Step 200/351 lr 0.000100 loss 0.0937 (0.1730) acc@1 0.9609 (0.9410) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-22 22:41:58] __main__ INFO: \u001b[0mEpoch 91 Step 300/351 lr 0.000100 loss 0.0881 (0.1729) acc@1 0.9844 (0.9404) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 22:42:03] __main__ INFO: \u001b[0mEpoch 91 Step 351/351 lr 0.000100 loss 0.2162 (0.1731) acc@1 0.9062 (0.9405) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 22:42:03] __main__ INFO: \u001b[0mElapsed 32.49\n",
      "\u001b[32m[2020-06-22 22:42:03] __main__ INFO: \u001b[0mVal 91\n",
      "\u001b[32m[2020-06-22 22:42:04] __main__ INFO: \u001b[0mEpoch 91 loss 0.4887 acc@1 0.8570 acc@5 0.9930\n",
      "\u001b[32m[2020-06-22 22:42:04] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-22 22:42:04] __main__ INFO: \u001b[0mTrain 92 31941\n",
      "\u001b[32m[2020-06-22 22:42:14] __main__ INFO: \u001b[0mEpoch 92 Step 100/351 lr 0.000100 loss 0.2335 (0.1689) acc@1 0.9219 (0.9447) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-22 22:42:23] __main__ INFO: \u001b[0mEpoch 92 Step 200/351 lr 0.000100 loss 0.2066 (0.1742) acc@1 0.9141 (0.9403) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-22 22:42:32] __main__ INFO: \u001b[0mEpoch 92 Step 300/351 lr 0.000100 loss 0.2110 (0.1718) acc@1 0.9141 (0.9408) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 22:42:37] __main__ INFO: \u001b[0mEpoch 92 Step 351/351 lr 0.000100 loss 0.1787 (0.1724) acc@1 0.9375 (0.9402) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 22:42:37] __main__ INFO: \u001b[0mElapsed 32.47\n",
      "\u001b[32m[2020-06-22 22:42:37] __main__ INFO: \u001b[0mVal 92\n",
      "\u001b[32m[2020-06-22 22:42:38] __main__ INFO: \u001b[0mEpoch 92 loss 0.4855 acc@1 0.8578 acc@5 0.9934\n",
      "\u001b[32m[2020-06-22 22:42:38] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 22:42:38] __main__ INFO: \u001b[0mTrain 93 32292\n",
      "\u001b[32m[2020-06-22 22:42:47] __main__ INFO: \u001b[0mEpoch 93 Step 100/351 lr 0.000100 loss 0.1715 (0.1798) acc@1 0.9531 (0.9370) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-22 22:42:56] __main__ INFO: \u001b[0mEpoch 93 Step 200/351 lr 0.000100 loss 0.1187 (0.1772) acc@1 0.9609 (0.9380) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-22 22:43:06] __main__ INFO: \u001b[0mEpoch 93 Step 300/351 lr 0.000100 loss 0.1648 (0.1759) acc@1 0.9297 (0.9388) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-22 22:43:10] __main__ INFO: \u001b[0mEpoch 93 Step 351/351 lr 0.000100 loss 0.1605 (0.1756) acc@1 0.9609 (0.9392) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-22 22:43:10] __main__ INFO: \u001b[0mElapsed 32.48\n",
      "\u001b[32m[2020-06-22 22:43:10] __main__ INFO: \u001b[0mVal 93\n",
      "\u001b[32m[2020-06-22 22:43:11] __main__ INFO: \u001b[0mEpoch 93 loss 0.4887 acc@1 0.8576 acc@5 0.9932\n",
      "\u001b[32m[2020-06-22 22:43:11] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 22:43:11] __main__ INFO: \u001b[0mTrain 94 32643\n",
      "\u001b[32m[2020-06-22 22:43:21] __main__ INFO: \u001b[0mEpoch 94 Step 100/351 lr 0.000100 loss 0.2333 (0.1713) acc@1 0.9219 (0.9424) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-22 22:43:30] __main__ INFO: \u001b[0mEpoch 94 Step 200/351 lr 0.000100 loss 0.1716 (0.1736) acc@1 0.9375 (0.9406) acc@5 0.9922 (0.9992)\n",
      "\u001b[32m[2020-06-22 22:43:39] __main__ INFO: \u001b[0mEpoch 94 Step 300/351 lr 0.000100 loss 0.1942 (0.1742) acc@1 0.9141 (0.9400) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 22:43:44] __main__ INFO: \u001b[0mEpoch 94 Step 351/351 lr 0.000100 loss 0.1396 (0.1744) acc@1 0.9609 (0.9396) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-22 22:43:44] __main__ INFO: \u001b[0mElapsed 32.46\n",
      "\u001b[32m[2020-06-22 22:43:44] __main__ INFO: \u001b[0mVal 94\n",
      "\u001b[32m[2020-06-22 22:43:45] __main__ INFO: \u001b[0mEpoch 94 loss 0.4886 acc@1 0.8566 acc@5 0.9934\n",
      "\u001b[32m[2020-06-22 22:43:45] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 22:43:45] __main__ INFO: \u001b[0mTrain 95 32994\n",
      "\u001b[32m[2020-06-22 22:43:54] __main__ INFO: \u001b[0mEpoch 95 Step 100/351 lr 0.000100 loss 0.1504 (0.1671) acc@1 0.9297 (0.9430) acc@5 0.9922 (0.9991)\n",
      "\u001b[32m[2020-06-22 22:44:03] __main__ INFO: \u001b[0mEpoch 95 Step 200/351 lr 0.000100 loss 0.2196 (0.1699) acc@1 0.9141 (0.9418) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-22 22:44:13] __main__ INFO: \u001b[0mEpoch 95 Step 300/351 lr 0.000100 loss 0.1237 (0.1703) acc@1 0.9766 (0.9415) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-22 22:44:17] __main__ INFO: \u001b[0mEpoch 95 Step 351/351 lr 0.000100 loss 0.1061 (0.1704) acc@1 0.9766 (0.9415) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-22 22:44:17] __main__ INFO: \u001b[0mElapsed 32.47\n",
      "\u001b[32m[2020-06-22 22:44:17] __main__ INFO: \u001b[0mVal 95\n",
      "\u001b[32m[2020-06-22 22:44:18] __main__ INFO: \u001b[0mEpoch 95 loss 0.4875 acc@1 0.8582 acc@5 0.9928\n",
      "\u001b[32m[2020-06-22 22:44:18] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-22 22:44:18] __main__ INFO: \u001b[0mTrain 96 33345\n",
      "\u001b[32m[2020-06-22 22:44:28] __main__ INFO: \u001b[0mEpoch 96 Step 100/351 lr 0.000100 loss 0.1606 (0.1656) acc@1 0.9453 (0.9428) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-22 22:44:37] __main__ INFO: \u001b[0mEpoch 96 Step 200/351 lr 0.000100 loss 0.1532 (0.1678) acc@1 0.9375 (0.9420) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 22:44:46] __main__ INFO: \u001b[0mEpoch 96 Step 300/351 lr 0.000100 loss 0.2004 (0.1663) acc@1 0.9062 (0.9426) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 22:44:51] __main__ INFO: \u001b[0mEpoch 96 Step 351/351 lr 0.000100 loss 0.2013 (0.1670) acc@1 0.9453 (0.9420) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 22:44:51] __main__ INFO: \u001b[0mElapsed 32.43\n",
      "\u001b[32m[2020-06-22 22:44:51] __main__ INFO: \u001b[0mVal 96\n",
      "\u001b[32m[2020-06-22 22:44:52] __main__ INFO: \u001b[0mEpoch 96 loss 0.4868 acc@1 0.8590 acc@5 0.9926\n",
      "\u001b[32m[2020-06-22 22:44:52] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 22:44:52] __main__ INFO: \u001b[0mTrain 97 33696\n",
      "\u001b[32m[2020-06-22 22:45:01] __main__ INFO: \u001b[0mEpoch 97 Step 100/351 lr 0.000100 loss 0.1285 (0.1691) acc@1 0.9609 (0.9424) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-22 22:45:11] __main__ INFO: \u001b[0mEpoch 97 Step 200/351 lr 0.000100 loss 0.1647 (0.1703) acc@1 0.9531 (0.9406) acc@5 0.9922 (0.9991)\n",
      "\u001b[32m[2020-06-22 22:45:20] __main__ INFO: \u001b[0mEpoch 97 Step 300/351 lr 0.000100 loss 0.1479 (0.1701) acc@1 0.9375 (0.9408) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-22 22:45:24] __main__ INFO: \u001b[0mEpoch 97 Step 351/351 lr 0.000100 loss 0.1845 (0.1692) acc@1 0.9297 (0.9407) acc@5 0.9922 (0.9991)\n",
      "\u001b[32m[2020-06-22 22:45:24] __main__ INFO: \u001b[0mElapsed 32.47\n",
      "\u001b[32m[2020-06-22 22:45:24] __main__ INFO: \u001b[0mVal 97\n",
      "\u001b[32m[2020-06-22 22:45:26] __main__ INFO: \u001b[0mEpoch 97 loss 0.4908 acc@1 0.8596 acc@5 0.9932\n",
      "\u001b[32m[2020-06-22 22:45:26] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 22:45:26] __main__ INFO: \u001b[0mTrain 98 34047\n",
      "\u001b[32m[2020-06-22 22:45:35] __main__ INFO: \u001b[0mEpoch 98 Step 100/351 lr 0.000100 loss 0.1833 (0.1713) acc@1 0.9219 (0.9397) acc@5 0.9922 (0.9994)\n",
      "\u001b[32m[2020-06-22 22:45:44] __main__ INFO: \u001b[0mEpoch 98 Step 200/351 lr 0.000100 loss 0.1382 (0.1695) acc@1 0.9453 (0.9403) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 22:45:53] __main__ INFO: \u001b[0mEpoch 98 Step 300/351 lr 0.000100 loss 0.1661 (0.1706) acc@1 0.9375 (0.9399) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 22:45:58] __main__ INFO: \u001b[0mEpoch 98 Step 351/351 lr 0.000100 loss 0.1823 (0.1722) acc@1 0.9453 (0.9399) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 22:45:58] __main__ INFO: \u001b[0mElapsed 32.51\n",
      "\u001b[32m[2020-06-22 22:45:58] __main__ INFO: \u001b[0mVal 98\n",
      "\u001b[32m[2020-06-22 22:45:59] __main__ INFO: \u001b[0mEpoch 98 loss 0.4914 acc@1 0.8584 acc@5 0.9928\n",
      "\u001b[32m[2020-06-22 22:45:59] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-06-22 22:45:59] __main__ INFO: \u001b[0mTrain 99 34398\n",
      "\u001b[32m[2020-06-22 22:46:08] __main__ INFO: \u001b[0mEpoch 99 Step 100/351 lr 0.000100 loss 0.1340 (0.1598) acc@1 0.9609 (0.9461) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-22 22:46:18] __main__ INFO: \u001b[0mEpoch 99 Step 200/351 lr 0.000100 loss 0.1212 (0.1703) acc@1 0.9531 (0.9418) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-22 22:46:27] __main__ INFO: \u001b[0mEpoch 99 Step 300/351 lr 0.000100 loss 0.2339 (0.1711) acc@1 0.9062 (0.9413) acc@5 0.9844 (0.9989)\n",
      "\u001b[32m[2020-06-22 22:46:32] __main__ INFO: \u001b[0mEpoch 99 Step 351/351 lr 0.000100 loss 0.1664 (0.1712) acc@1 0.9297 (0.9407) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-22 22:46:32] __main__ INFO: \u001b[0mElapsed 32.46\n",
      "\u001b[32m[2020-06-22 22:46:32] __main__ INFO: \u001b[0mVal 99\n",
      "\u001b[32m[2020-06-22 22:46:33] __main__ INFO: \u001b[0mEpoch 99 loss 0.4881 acc@1 0.8590 acc@5 0.9928\n",
      "\u001b[32m[2020-06-22 22:46:33] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 22:46:33] __main__ INFO: \u001b[0mTrain 100 34749\n",
      "\u001b[32m[2020-06-22 22:46:42] __main__ INFO: \u001b[0mEpoch 100 Step 100/351 lr 0.000100 loss 0.2031 (0.1723) acc@1 0.9453 (0.9422) acc@5 0.9844 (0.9991)\n",
      "\u001b[32m[2020-06-22 22:46:51] __main__ INFO: \u001b[0mEpoch 100 Step 200/351 lr 0.000100 loss 0.2113 (0.1714) acc@1 0.9219 (0.9417) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 22:47:00] __main__ INFO: \u001b[0mEpoch 100 Step 300/351 lr 0.000100 loss 0.1372 (0.1714) acc@1 0.9531 (0.9419) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 22:47:05] __main__ INFO: \u001b[0mEpoch 100 Step 351/351 lr 0.000100 loss 0.1952 (0.1708) acc@1 0.9453 (0.9418) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 22:47:05] __main__ INFO: \u001b[0mElapsed 32.49\n",
      "\u001b[32m[2020-06-22 22:47:05] __main__ INFO: \u001b[0mVal 100\n",
      "\u001b[32m[2020-06-22 22:47:06] __main__ INFO: \u001b[0mEpoch 100 loss 0.4912 acc@1 0.8580 acc@5 0.9930\n",
      "\u001b[32m[2020-06-22 22:47:06] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 22:47:06] fvcore.common.checkpoint INFO: \u001b[0mSaving checkpoint to /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00_resume300_150/checkpoint_00100.pth\n",
      "\u001b[32m[2020-06-22 22:47:06] __main__ INFO: \u001b[0mTrain 101 35100\n",
      "\u001b[32m[2020-06-22 22:47:16] __main__ INFO: \u001b[0mEpoch 101 Step 100/351 lr 0.000100 loss 0.1751 (0.1668) acc@1 0.9688 (0.9418) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-22 22:47:25] __main__ INFO: \u001b[0mEpoch 101 Step 200/351 lr 0.000100 loss 0.1006 (0.1682) acc@1 0.9844 (0.9408) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-22 22:47:34] __main__ INFO: \u001b[0mEpoch 101 Step 300/351 lr 0.000100 loss 0.2093 (0.1684) acc@1 0.9453 (0.9411) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 22:47:39] __main__ INFO: \u001b[0mEpoch 101 Step 351/351 lr 0.000100 loss 0.1806 (0.1686) acc@1 0.9375 (0.9411) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 22:47:39] __main__ INFO: \u001b[0mElapsed 32.43\n",
      "\u001b[32m[2020-06-22 22:47:39] __main__ INFO: \u001b[0mVal 101\n",
      "\u001b[32m[2020-06-22 22:47:40] __main__ INFO: \u001b[0mEpoch 101 loss 0.4900 acc@1 0.8582 acc@5 0.9932\n",
      "\u001b[32m[2020-06-22 22:47:40] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 22:47:40] __main__ INFO: \u001b[0mTrain 102 35451\n",
      "\u001b[32m[2020-06-22 22:47:49] __main__ INFO: \u001b[0mEpoch 102 Step 100/351 lr 0.000100 loss 0.2172 (0.1683) acc@1 0.9453 (0.9395) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 22:47:58] __main__ INFO: \u001b[0mEpoch 102 Step 200/351 lr 0.000100 loss 0.2019 (0.1687) acc@1 0.9375 (0.9414) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 22:48:07] __main__ INFO: \u001b[0mEpoch 102 Step 300/351 lr 0.000100 loss 0.1336 (0.1702) acc@1 0.9453 (0.9407) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 22:48:12] __main__ INFO: \u001b[0mEpoch 102 Step 351/351 lr 0.000100 loss 0.2024 (0.1702) acc@1 0.9219 (0.9407) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 22:48:12] __main__ INFO: \u001b[0mElapsed 32.42\n",
      "\u001b[32m[2020-06-22 22:48:12] __main__ INFO: \u001b[0mVal 102\n",
      "\u001b[32m[2020-06-22 22:48:13] __main__ INFO: \u001b[0mEpoch 102 loss 0.4875 acc@1 0.8602 acc@5 0.9930\n",
      "\u001b[32m[2020-06-22 22:48:13] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 22:48:13] __main__ INFO: \u001b[0mTrain 103 35802\n",
      "\u001b[32m[2020-06-22 22:48:23] __main__ INFO: \u001b[0mEpoch 103 Step 100/351 lr 0.000100 loss 0.1587 (0.1677) acc@1 0.9453 (0.9423) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 22:48:32] __main__ INFO: \u001b[0mEpoch 103 Step 200/351 lr 0.000100 loss 0.1380 (0.1702) acc@1 0.9609 (0.9413) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 22:48:41] __main__ INFO: \u001b[0mEpoch 103 Step 300/351 lr 0.000100 loss 0.1948 (0.1705) acc@1 0.9453 (0.9414) acc@5 0.9922 (0.9993)\n",
      "\u001b[32m[2020-06-22 22:48:46] __main__ INFO: \u001b[0mEpoch 103 Step 351/351 lr 0.000100 loss 0.1686 (0.1696) acc@1 0.9297 (0.9417) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 22:48:46] __main__ INFO: \u001b[0mElapsed 32.51\n",
      "\u001b[32m[2020-06-22 22:48:46] __main__ INFO: \u001b[0mVal 103\n",
      "\u001b[32m[2020-06-22 22:48:47] __main__ INFO: \u001b[0mEpoch 103 loss 0.4922 acc@1 0.8572 acc@5 0.9932\n",
      "\u001b[32m[2020-06-22 22:48:47] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 22:48:47] __main__ INFO: \u001b[0mTrain 104 36153\n",
      "\u001b[32m[2020-06-22 22:48:56] __main__ INFO: \u001b[0mEpoch 104 Step 100/351 lr 0.000100 loss 0.2297 (0.1685) acc@1 0.9062 (0.9410) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 22:49:05] __main__ INFO: \u001b[0mEpoch 104 Step 200/351 lr 0.000100 loss 0.1731 (0.1666) acc@1 0.9453 (0.9428) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 22:49:15] __main__ INFO: \u001b[0mEpoch 104 Step 300/351 lr 0.000100 loss 0.0874 (0.1629) acc@1 0.9766 (0.9443) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 22:49:19] __main__ INFO: \u001b[0mEpoch 104 Step 351/351 lr 0.000100 loss 0.1697 (0.1644) acc@1 0.9453 (0.9438) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 22:49:19] __main__ INFO: \u001b[0mElapsed 32.48\n",
      "\u001b[32m[2020-06-22 22:49:19] __main__ INFO: \u001b[0mVal 104\n",
      "\u001b[32m[2020-06-22 22:49:20] __main__ INFO: \u001b[0mEpoch 104 loss 0.4924 acc@1 0.8586 acc@5 0.9926\n",
      "\u001b[32m[2020-06-22 22:49:20] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 22:49:20] __main__ INFO: \u001b[0mTrain 105 36504\n",
      "\u001b[32m[2020-06-22 22:49:30] __main__ INFO: \u001b[0mEpoch 105 Step 100/351 lr 0.000100 loss 0.2075 (0.1719) acc@1 0.9219 (0.9405) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-06-22 22:49:39] __main__ INFO: \u001b[0mEpoch 105 Step 200/351 lr 0.000100 loss 0.1948 (0.1696) acc@1 0.9219 (0.9415) acc@5 1.0000 (0.9989)\n",
      "\u001b[32m[2020-06-22 22:49:48] __main__ INFO: \u001b[0mEpoch 105 Step 300/351 lr 0.000100 loss 0.1788 (0.1695) acc@1 0.9219 (0.9413) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 22:49:53] __main__ INFO: \u001b[0mEpoch 105 Step 351/351 lr 0.000100 loss 0.1969 (0.1697) acc@1 0.9375 (0.9412) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 22:49:53] __main__ INFO: \u001b[0mElapsed 32.43\n",
      "\u001b[32m[2020-06-22 22:49:53] __main__ INFO: \u001b[0mVal 105\n",
      "\u001b[32m[2020-06-22 22:49:54] __main__ INFO: \u001b[0mEpoch 105 loss 0.4899 acc@1 0.8576 acc@5 0.9936\n",
      "\u001b[32m[2020-06-22 22:49:54] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 22:49:54] __main__ INFO: \u001b[0mTrain 106 36855\n",
      "\u001b[32m[2020-06-22 22:50:03] __main__ INFO: \u001b[0mEpoch 106 Step 100/351 lr 0.000100 loss 0.1450 (0.1762) acc@1 0.9531 (0.9391) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-22 22:50:12] __main__ INFO: \u001b[0mEpoch 106 Step 200/351 lr 0.000100 loss 0.1393 (0.1734) acc@1 0.9609 (0.9403) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 22:50:22] __main__ INFO: \u001b[0mEpoch 106 Step 300/351 lr 0.000100 loss 0.1296 (0.1703) acc@1 0.9453 (0.9418) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 22:50:26] __main__ INFO: \u001b[0mEpoch 106 Step 351/351 lr 0.000100 loss 0.1513 (0.1702) acc@1 0.9375 (0.9419) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 22:50:26] __main__ INFO: \u001b[0mElapsed 32.47\n",
      "\u001b[32m[2020-06-22 22:50:26] __main__ INFO: \u001b[0mVal 106\n",
      "\u001b[32m[2020-06-22 22:50:28] __main__ INFO: \u001b[0mEpoch 106 loss 0.4889 acc@1 0.8584 acc@5 0.9932\n",
      "\u001b[32m[2020-06-22 22:50:28] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-22 22:50:28] __main__ INFO: \u001b[0mTrain 107 37206\n",
      "\u001b[32m[2020-06-22 22:50:37] __main__ INFO: \u001b[0mEpoch 107 Step 100/351 lr 0.000100 loss 0.1562 (0.1696) acc@1 0.9375 (0.9402) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 22:50:46] __main__ INFO: \u001b[0mEpoch 107 Step 200/351 lr 0.000100 loss 0.2104 (0.1717) acc@1 0.9297 (0.9401) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 22:50:55] __main__ INFO: \u001b[0mEpoch 107 Step 300/351 lr 0.000100 loss 0.1471 (0.1715) acc@1 0.9453 (0.9399) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-22 22:51:00] __main__ INFO: \u001b[0mEpoch 107 Step 351/351 lr 0.000100 loss 0.2026 (0.1726) acc@1 0.9219 (0.9395) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 22:51:00] __main__ INFO: \u001b[0mElapsed 32.43\n",
      "\u001b[32m[2020-06-22 22:51:00] __main__ INFO: \u001b[0mVal 107\n",
      "\u001b[32m[2020-06-22 22:51:01] __main__ INFO: \u001b[0mEpoch 107 loss 0.4905 acc@1 0.8592 acc@5 0.9932\n",
      "\u001b[32m[2020-06-22 22:51:01] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 22:51:01] __main__ INFO: \u001b[0mTrain 108 37557\n",
      "\u001b[32m[2020-06-22 22:51:10] __main__ INFO: \u001b[0mEpoch 108 Step 100/351 lr 0.000100 loss 0.1505 (0.1687) acc@1 0.9453 (0.9411) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-22 22:51:20] __main__ INFO: \u001b[0mEpoch 108 Step 200/351 lr 0.000100 loss 0.1208 (0.1672) acc@1 0.9531 (0.9418) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 22:51:29] __main__ INFO: \u001b[0mEpoch 108 Step 300/351 lr 0.000100 loss 0.1104 (0.1686) acc@1 0.9609 (0.9408) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 22:51:34] __main__ INFO: \u001b[0mEpoch 108 Step 351/351 lr 0.000100 loss 0.1460 (0.1692) acc@1 0.9453 (0.9405) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 22:51:34] __main__ INFO: \u001b[0mElapsed 32.52\n",
      "\u001b[32m[2020-06-22 22:51:34] __main__ INFO: \u001b[0mVal 108\n",
      "\u001b[32m[2020-06-22 22:51:35] __main__ INFO: \u001b[0mEpoch 108 loss 0.4883 acc@1 0.8584 acc@5 0.9934\n",
      "\u001b[32m[2020-06-22 22:51:35] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-22 22:51:35] __main__ INFO: \u001b[0mTrain 109 37908\n",
      "\u001b[32m[2020-06-22 22:51:44] __main__ INFO: \u001b[0mEpoch 109 Step 100/351 lr 0.000100 loss 0.1405 (0.1639) acc@1 0.9531 (0.9420) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-22 22:51:53] __main__ INFO: \u001b[0mEpoch 109 Step 200/351 lr 0.000100 loss 0.0872 (0.1680) acc@1 0.9766 (0.9410) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 22:52:02] __main__ INFO: \u001b[0mEpoch 109 Step 300/351 lr 0.000100 loss 0.1264 (0.1668) acc@1 0.9844 (0.9421) acc@5 0.9922 (0.9992)\n",
      "\u001b[32m[2020-06-22 22:52:07] __main__ INFO: \u001b[0mEpoch 109 Step 351/351 lr 0.000100 loss 0.2181 (0.1665) acc@1 0.9219 (0.9422) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 22:52:07] __main__ INFO: \u001b[0mElapsed 32.45\n",
      "\u001b[32m[2020-06-22 22:52:07] __main__ INFO: \u001b[0mVal 109\n",
      "\u001b[32m[2020-06-22 22:52:08] __main__ INFO: \u001b[0mEpoch 109 loss 0.4889 acc@1 0.8582 acc@5 0.9934\n",
      "\u001b[32m[2020-06-22 22:52:08] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 22:52:08] __main__ INFO: \u001b[0mTrain 110 38259\n",
      "\u001b[32m[2020-06-22 22:52:17] __main__ INFO: \u001b[0mEpoch 110 Step 100/351 lr 0.000100 loss 0.1596 (0.1606) acc@1 0.9375 (0.9459) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 22:52:27] __main__ INFO: \u001b[0mEpoch 110 Step 200/351 lr 0.000100 loss 0.1272 (0.1611) acc@1 0.9531 (0.9451) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 22:52:36] __main__ INFO: \u001b[0mEpoch 110 Step 300/351 lr 0.000100 loss 0.2349 (0.1643) acc@1 0.9141 (0.9432) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 22:52:41] __main__ INFO: \u001b[0mEpoch 110 Step 351/351 lr 0.000100 loss 0.1031 (0.1643) acc@1 0.9844 (0.9431) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 22:52:41] __main__ INFO: \u001b[0mElapsed 32.45\n",
      "\u001b[32m[2020-06-22 22:52:41] __main__ INFO: \u001b[0mVal 110\n",
      "\u001b[32m[2020-06-22 22:52:42] __main__ INFO: \u001b[0mEpoch 110 loss 0.4873 acc@1 0.8596 acc@5 0.9932\n",
      "\u001b[32m[2020-06-22 22:52:42] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 22:52:42] __main__ INFO: \u001b[0mTrain 111 38610\n",
      "\u001b[32m[2020-06-22 22:52:51] __main__ INFO: \u001b[0mEpoch 111 Step 100/351 lr 0.000100 loss 0.2196 (0.1746) acc@1 0.9219 (0.9391) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-22 22:53:00] __main__ INFO: \u001b[0mEpoch 111 Step 200/351 lr 0.000100 loss 0.1326 (0.1698) acc@1 0.9531 (0.9401) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 22:53:09] __main__ INFO: \u001b[0mEpoch 111 Step 300/351 lr 0.000100 loss 0.0886 (0.1663) acc@1 0.9609 (0.9414) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 22:53:14] __main__ INFO: \u001b[0mEpoch 111 Step 351/351 lr 0.000100 loss 0.1324 (0.1662) acc@1 0.9453 (0.9414) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 22:53:14] __main__ INFO: \u001b[0mElapsed 32.46\n",
      "\u001b[32m[2020-06-22 22:53:14] __main__ INFO: \u001b[0mVal 111\n",
      "\u001b[32m[2020-06-22 22:53:15] __main__ INFO: \u001b[0mEpoch 111 loss 0.4866 acc@1 0.8592 acc@5 0.9928\n",
      "\u001b[32m[2020-06-22 22:53:15] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 22:53:15] __main__ INFO: \u001b[0mTrain 112 38961\n",
      "\u001b[32m[2020-06-22 22:53:25] __main__ INFO: \u001b[0mEpoch 112 Step 100/351 lr 0.000100 loss 0.1389 (0.1640) acc@1 0.9609 (0.9452) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-22 22:53:34] __main__ INFO: \u001b[0mEpoch 112 Step 200/351 lr 0.000100 loss 0.1480 (0.1662) acc@1 0.9375 (0.9428) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-22 22:53:43] __main__ INFO: \u001b[0mEpoch 112 Step 300/351 lr 0.000100 loss 0.1227 (0.1650) acc@1 0.9531 (0.9424) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-22 22:53:48] __main__ INFO: \u001b[0mEpoch 112 Step 351/351 lr 0.000100 loss 0.2440 (0.1660) acc@1 0.8906 (0.9425) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-22 22:53:48] __main__ INFO: \u001b[0mElapsed 32.46\n",
      "\u001b[32m[2020-06-22 22:53:48] __main__ INFO: \u001b[0mVal 112\n",
      "\u001b[32m[2020-06-22 22:53:49] __main__ INFO: \u001b[0mEpoch 112 loss 0.4908 acc@1 0.8592 acc@5 0.9924\n",
      "\u001b[32m[2020-06-22 22:53:49] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-22 22:53:49] __main__ INFO: \u001b[0mTrain 113 39312\n",
      "\u001b[32m[2020-06-22 22:53:58] __main__ INFO: \u001b[0mEpoch 113 Step 100/351 lr 0.000100 loss 0.1332 (0.1635) acc@1 0.9375 (0.9416) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-22 22:54:07] __main__ INFO: \u001b[0mEpoch 113 Step 200/351 lr 0.000100 loss 0.2031 (0.1619) acc@1 0.9453 (0.9434) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 22:54:16] __main__ INFO: \u001b[0mEpoch 113 Step 300/351 lr 0.000100 loss 0.1589 (0.1658) acc@1 0.9531 (0.9429) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 22:54:21] __main__ INFO: \u001b[0mEpoch 113 Step 351/351 lr 0.000100 loss 0.1189 (0.1663) acc@1 0.9688 (0.9431) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 22:54:21] __main__ INFO: \u001b[0mElapsed 32.44\n",
      "\u001b[32m[2020-06-22 22:54:21] __main__ INFO: \u001b[0mVal 113\n",
      "\u001b[32m[2020-06-22 22:54:22] __main__ INFO: \u001b[0mEpoch 113 loss 0.4898 acc@1 0.8574 acc@5 0.9928\n",
      "\u001b[32m[2020-06-22 22:54:22] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 22:54:22] __main__ INFO: \u001b[0mTrain 114 39663\n",
      "\u001b[32m[2020-06-22 22:54:32] __main__ INFO: \u001b[0mEpoch 114 Step 100/351 lr 0.000100 loss 0.2341 (0.1620) acc@1 0.9297 (0.9452) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-22 22:54:41] __main__ INFO: \u001b[0mEpoch 114 Step 200/351 lr 0.000100 loss 0.1218 (0.1646) acc@1 0.9766 (0.9437) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-22 22:54:50] __main__ INFO: \u001b[0mEpoch 114 Step 300/351 lr 0.000100 loss 0.2424 (0.1656) acc@1 0.9141 (0.9431) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-22 22:54:55] __main__ INFO: \u001b[0mEpoch 114 Step 351/351 lr 0.000100 loss 0.1225 (0.1664) acc@1 0.9609 (0.9426) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-22 22:54:55] __main__ INFO: \u001b[0mElapsed 32.53\n",
      "\u001b[32m[2020-06-22 22:54:55] __main__ INFO: \u001b[0mVal 114\n",
      "\u001b[32m[2020-06-22 22:54:56] __main__ INFO: \u001b[0mEpoch 114 loss 0.4913 acc@1 0.8594 acc@5 0.9928\n",
      "\u001b[32m[2020-06-22 22:54:56] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-06-22 22:54:56] __main__ INFO: \u001b[0mTrain 115 40014\n",
      "\u001b[32m[2020-06-22 22:55:05] __main__ INFO: \u001b[0mEpoch 115 Step 100/351 lr 0.000100 loss 0.1921 (0.1652) acc@1 0.9375 (0.9417) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 22:55:14] __main__ INFO: \u001b[0mEpoch 115 Step 200/351 lr 0.000100 loss 0.1244 (0.1643) acc@1 0.9531 (0.9425) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 22:55:24] __main__ INFO: \u001b[0mEpoch 115 Step 300/351 lr 0.000100 loss 0.1511 (0.1675) acc@1 0.9453 (0.9417) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 22:55:28] __main__ INFO: \u001b[0mEpoch 115 Step 351/351 lr 0.000100 loss 0.1453 (0.1653) acc@1 0.9609 (0.9427) acc@5 0.9922 (0.9993)\n",
      "\u001b[32m[2020-06-22 22:55:28] __main__ INFO: \u001b[0mElapsed 32.44\n",
      "\u001b[32m[2020-06-22 22:55:28] __main__ INFO: \u001b[0mVal 115\n",
      "\u001b[32m[2020-06-22 22:55:29] __main__ INFO: \u001b[0mEpoch 115 loss 0.4892 acc@1 0.8576 acc@5 0.9930\n",
      "\u001b[32m[2020-06-22 22:55:29] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 22:55:29] __main__ INFO: \u001b[0mTrain 116 40365\n",
      "\u001b[32m[2020-06-22 22:55:39] __main__ INFO: \u001b[0mEpoch 116 Step 100/351 lr 0.000100 loss 0.1802 (0.1595) acc@1 0.9297 (0.9452) acc@5 0.9922 (0.9992)\n",
      "\u001b[32m[2020-06-22 22:55:48] __main__ INFO: \u001b[0mEpoch 116 Step 200/351 lr 0.000100 loss 0.1252 (0.1641) acc@1 0.9688 (0.9439) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 22:55:57] __main__ INFO: \u001b[0mEpoch 116 Step 300/351 lr 0.000100 loss 0.1399 (0.1640) acc@1 0.9453 (0.9440) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 22:56:02] __main__ INFO: \u001b[0mEpoch 116 Step 351/351 lr 0.000100 loss 0.1420 (0.1646) acc@1 0.9531 (0.9435) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 22:56:02] __main__ INFO: \u001b[0mElapsed 32.42\n",
      "\u001b[32m[2020-06-22 22:56:02] __main__ INFO: \u001b[0mVal 116\n",
      "\u001b[32m[2020-06-22 22:56:03] __main__ INFO: \u001b[0mEpoch 116 loss 0.4886 acc@1 0.8558 acc@5 0.9926\n",
      "\u001b[32m[2020-06-22 22:56:03] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 22:56:03] __main__ INFO: \u001b[0mTrain 117 40716\n",
      "\u001b[32m[2020-06-22 22:56:12] __main__ INFO: \u001b[0mEpoch 117 Step 100/351 lr 0.000100 loss 0.1386 (0.1691) acc@1 0.9688 (0.9409) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 22:56:21] __main__ INFO: \u001b[0mEpoch 117 Step 200/351 lr 0.000100 loss 0.1418 (0.1646) acc@1 0.9609 (0.9429) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 22:56:31] __main__ INFO: \u001b[0mEpoch 117 Step 300/351 lr 0.000100 loss 0.1627 (0.1620) acc@1 0.9531 (0.9446) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 22:56:35] __main__ INFO: \u001b[0mEpoch 117 Step 351/351 lr 0.000100 loss 0.1121 (0.1617) acc@1 0.9609 (0.9448) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 22:56:35] __main__ INFO: \u001b[0mElapsed 32.46\n",
      "\u001b[32m[2020-06-22 22:56:35] __main__ INFO: \u001b[0mVal 117\n",
      "\u001b[32m[2020-06-22 22:56:36] __main__ INFO: \u001b[0mEpoch 117 loss 0.4903 acc@1 0.8556 acc@5 0.9924\n",
      "\u001b[32m[2020-06-22 22:56:36] __main__ INFO: \u001b[0mElapsed 1.11\n",
      "\u001b[32m[2020-06-22 22:56:36] __main__ INFO: \u001b[0mTrain 118 41067\n",
      "\u001b[32m[2020-06-22 22:56:46] __main__ INFO: \u001b[0mEpoch 118 Step 100/351 lr 0.000100 loss 0.1839 (0.1609) acc@1 0.9375 (0.9444) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-22 22:56:55] __main__ INFO: \u001b[0mEpoch 118 Step 200/351 lr 0.000100 loss 0.1388 (0.1609) acc@1 0.9453 (0.9448) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-22 22:57:04] __main__ INFO: \u001b[0mEpoch 118 Step 300/351 lr 0.000100 loss 0.1716 (0.1615) acc@1 0.9453 (0.9452) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-22 22:57:09] __main__ INFO: \u001b[0mEpoch 118 Step 351/351 lr 0.000100 loss 0.1237 (0.1622) acc@1 0.9609 (0.9447) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-22 22:57:09] __main__ INFO: \u001b[0mElapsed 32.44\n",
      "\u001b[32m[2020-06-22 22:57:09] __main__ INFO: \u001b[0mVal 118\n",
      "\u001b[32m[2020-06-22 22:57:10] __main__ INFO: \u001b[0mEpoch 118 loss 0.4889 acc@1 0.8584 acc@5 0.9926\n",
      "\u001b[32m[2020-06-22 22:57:10] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 22:57:10] __main__ INFO: \u001b[0mTrain 119 41418\n",
      "\u001b[32m[2020-06-22 22:57:19] __main__ INFO: \u001b[0mEpoch 119 Step 100/351 lr 0.000100 loss 0.1566 (0.1714) acc@1 0.9453 (0.9399) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-22 22:57:29] __main__ INFO: \u001b[0mEpoch 119 Step 200/351 lr 0.000100 loss 0.1306 (0.1683) acc@1 0.9609 (0.9422) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 22:57:38] __main__ INFO: \u001b[0mEpoch 119 Step 300/351 lr 0.000100 loss 0.1757 (0.1647) acc@1 0.9453 (0.9432) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 22:57:43] __main__ INFO: \u001b[0mEpoch 119 Step 351/351 lr 0.000100 loss 0.1590 (0.1642) acc@1 0.9453 (0.9432) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 22:57:43] __main__ INFO: \u001b[0mElapsed 32.51\n",
      "\u001b[32m[2020-06-22 22:57:43] __main__ INFO: \u001b[0mVal 119\n",
      "\u001b[32m[2020-06-22 22:57:44] __main__ INFO: \u001b[0mEpoch 119 loss 0.4893 acc@1 0.8588 acc@5 0.9930\n",
      "\u001b[32m[2020-06-22 22:57:44] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 22:57:44] __main__ INFO: \u001b[0mTrain 120 41769\n",
      "\u001b[32m[2020-06-22 22:57:53] __main__ INFO: \u001b[0mEpoch 120 Step 100/351 lr 0.000100 loss 0.2284 (0.1659) acc@1 0.9219 (0.9417) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-22 22:58:02] __main__ INFO: \u001b[0mEpoch 120 Step 200/351 lr 0.000100 loss 0.1278 (0.1628) acc@1 0.9609 (0.9440) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-22 22:58:11] __main__ INFO: \u001b[0mEpoch 120 Step 300/351 lr 0.000100 loss 0.1360 (0.1630) acc@1 0.9453 (0.9437) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-22 22:58:16] __main__ INFO: \u001b[0mEpoch 120 Step 351/351 lr 0.000100 loss 0.1185 (0.1640) acc@1 0.9766 (0.9435) acc@5 0.9922 (0.9994)\n",
      "\u001b[32m[2020-06-22 22:58:16] __main__ INFO: \u001b[0mElapsed 32.42\n",
      "\u001b[32m[2020-06-22 22:58:16] __main__ INFO: \u001b[0mVal 120\n",
      "\u001b[32m[2020-06-22 22:58:17] __main__ INFO: \u001b[0mEpoch 120 loss 0.4868 acc@1 0.8574 acc@5 0.9926\n",
      "\u001b[32m[2020-06-22 22:58:17] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 22:58:17] __main__ INFO: \u001b[0mTrain 121 42120\n",
      "\u001b[32m[2020-06-22 22:58:26] __main__ INFO: \u001b[0mEpoch 121 Step 100/351 lr 0.000010 loss 0.1842 (0.1636) acc@1 0.9531 (0.9455) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 22:58:36] __main__ INFO: \u001b[0mEpoch 121 Step 200/351 lr 0.000010 loss 0.1951 (0.1623) acc@1 0.9297 (0.9446) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 22:58:45] __main__ INFO: \u001b[0mEpoch 121 Step 300/351 lr 0.000010 loss 0.1501 (0.1639) acc@1 0.9531 (0.9439) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 22:58:50] __main__ INFO: \u001b[0mEpoch 121 Step 351/351 lr 0.000010 loss 0.1297 (0.1635) acc@1 0.9609 (0.9439) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 22:58:50] __main__ INFO: \u001b[0mElapsed 32.46\n",
      "\u001b[32m[2020-06-22 22:58:50] __main__ INFO: \u001b[0mVal 121\n",
      "\u001b[32m[2020-06-22 22:58:51] __main__ INFO: \u001b[0mEpoch 121 loss 0.4896 acc@1 0.8584 acc@5 0.9928\n",
      "\u001b[32m[2020-06-22 22:58:51] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-22 22:58:51] __main__ INFO: \u001b[0mTrain 122 42471\n",
      "\u001b[32m[2020-06-22 22:59:00] __main__ INFO: \u001b[0mEpoch 122 Step 100/351 lr 0.000010 loss 0.1178 (0.1592) acc@1 0.9766 (0.9445) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-22 22:59:09] __main__ INFO: \u001b[0mEpoch 122 Step 200/351 lr 0.000010 loss 0.1231 (0.1579) acc@1 0.9453 (0.9451) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-22 22:59:18] __main__ INFO: \u001b[0mEpoch 122 Step 300/351 lr 0.000010 loss 0.1818 (0.1615) acc@1 0.9297 (0.9441) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 22:59:23] __main__ INFO: \u001b[0mEpoch 122 Step 351/351 lr 0.000010 loss 0.1836 (0.1625) acc@1 0.9219 (0.9442) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 22:59:23] __main__ INFO: \u001b[0mElapsed 32.46\n",
      "\u001b[32m[2020-06-22 22:59:23] __main__ INFO: \u001b[0mVal 122\n",
      "\u001b[32m[2020-06-22 22:59:24] __main__ INFO: \u001b[0mEpoch 122 loss 0.4891 acc@1 0.8568 acc@5 0.9924\n",
      "\u001b[32m[2020-06-22 22:59:24] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 22:59:24] __main__ INFO: \u001b[0mTrain 123 42822\n",
      "\u001b[32m[2020-06-22 22:59:34] __main__ INFO: \u001b[0mEpoch 123 Step 100/351 lr 0.000010 loss 0.2253 (0.1601) acc@1 0.9062 (0.9455) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 22:59:43] __main__ INFO: \u001b[0mEpoch 123 Step 200/351 lr 0.000010 loss 0.1110 (0.1597) acc@1 0.9609 (0.9447) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 22:59:52] __main__ INFO: \u001b[0mEpoch 123 Step 300/351 lr 0.000010 loss 0.1501 (0.1627) acc@1 0.9453 (0.9432) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 22:59:57] __main__ INFO: \u001b[0mEpoch 123 Step 351/351 lr 0.000010 loss 0.1257 (0.1614) acc@1 0.9609 (0.9434) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 22:59:57] __main__ INFO: \u001b[0mElapsed 32.47\n",
      "\u001b[32m[2020-06-22 22:59:57] __main__ INFO: \u001b[0mVal 123\n",
      "\u001b[32m[2020-06-22 22:59:58] __main__ INFO: \u001b[0mEpoch 123 loss 0.4898 acc@1 0.8570 acc@5 0.9926\n",
      "\u001b[32m[2020-06-22 22:59:58] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 22:59:58] __main__ INFO: \u001b[0mTrain 124 43173\n",
      "\u001b[32m[2020-06-22 23:00:07] __main__ INFO: \u001b[0mEpoch 124 Step 100/351 lr 0.000010 loss 0.1729 (0.1716) acc@1 0.9531 (0.9402) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 23:00:16] __main__ INFO: \u001b[0mEpoch 124 Step 200/351 lr 0.000010 loss 0.1988 (0.1647) acc@1 0.9453 (0.9428) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 23:00:26] __main__ INFO: \u001b[0mEpoch 124 Step 300/351 lr 0.000010 loss 0.1789 (0.1629) acc@1 0.9453 (0.9439) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-22 23:00:30] __main__ INFO: \u001b[0mEpoch 124 Step 351/351 lr 0.000010 loss 0.1781 (0.1641) acc@1 0.9141 (0.9436) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 23:00:30] __main__ INFO: \u001b[0mElapsed 32.50\n",
      "\u001b[32m[2020-06-22 23:00:30] __main__ INFO: \u001b[0mVal 124\n",
      "\u001b[32m[2020-06-22 23:00:31] __main__ INFO: \u001b[0mEpoch 124 loss 0.4871 acc@1 0.8590 acc@5 0.9932\n",
      "\u001b[32m[2020-06-22 23:00:31] __main__ INFO: \u001b[0mElapsed 1.12\n",
      "\u001b[32m[2020-06-22 23:00:31] __main__ INFO: \u001b[0mTrain 125 43524\n",
      "\u001b[32m[2020-06-22 23:00:41] __main__ INFO: \u001b[0mEpoch 125 Step 100/351 lr 0.000010 loss 0.0870 (0.1616) acc@1 0.9844 (0.9452) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 23:00:50] __main__ INFO: \u001b[0mEpoch 125 Step 200/351 lr 0.000010 loss 0.1507 (0.1612) acc@1 0.9453 (0.9447) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 23:00:59] __main__ INFO: \u001b[0mEpoch 125 Step 300/351 lr 0.000010 loss 0.1588 (0.1616) acc@1 0.9531 (0.9441) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 23:01:04] __main__ INFO: \u001b[0mEpoch 125 Step 351/351 lr 0.000010 loss 0.1585 (0.1620) acc@1 0.9375 (0.9442) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 23:01:04] __main__ INFO: \u001b[0mElapsed 32.44\n",
      "\u001b[32m[2020-06-22 23:01:04] __main__ INFO: \u001b[0mVal 125\n",
      "\u001b[32m[2020-06-22 23:01:05] __main__ INFO: \u001b[0mEpoch 125 loss 0.4901 acc@1 0.8588 acc@5 0.9926\n",
      "\u001b[32m[2020-06-22 23:01:05] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 23:01:05] __main__ INFO: \u001b[0mTrain 126 43875\n",
      "\u001b[32m[2020-06-22 23:01:14] __main__ INFO: \u001b[0mEpoch 126 Step 100/351 lr 0.000010 loss 0.1934 (0.1707) acc@1 0.9062 (0.9393) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-22 23:01:23] __main__ INFO: \u001b[0mEpoch 126 Step 200/351 lr 0.000010 loss 0.1332 (0.1654) acc@1 0.9688 (0.9429) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 23:01:33] __main__ INFO: \u001b[0mEpoch 126 Step 300/351 lr 0.000010 loss 0.1658 (0.1659) acc@1 0.9531 (0.9418) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 23:01:37] __main__ INFO: \u001b[0mEpoch 126 Step 351/351 lr 0.000010 loss 0.1108 (0.1646) acc@1 0.9688 (0.9424) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 23:01:37] __main__ INFO: \u001b[0mElapsed 32.38\n",
      "\u001b[32m[2020-06-22 23:01:37] __main__ INFO: \u001b[0mVal 126\n",
      "\u001b[32m[2020-06-22 23:01:38] __main__ INFO: \u001b[0mEpoch 126 loss 0.4871 acc@1 0.8576 acc@5 0.9930\n",
      "\u001b[32m[2020-06-22 23:01:38] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 23:01:38] __main__ INFO: \u001b[0mTrain 127 44226\n",
      "\u001b[32m[2020-06-22 23:01:48] __main__ INFO: \u001b[0mEpoch 127 Step 100/351 lr 0.000010 loss 0.1473 (0.1612) acc@1 0.9531 (0.9445) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-22 23:01:57] __main__ INFO: \u001b[0mEpoch 127 Step 200/351 lr 0.000010 loss 0.1697 (0.1588) acc@1 0.9531 (0.9456) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-22 23:02:06] __main__ INFO: \u001b[0mEpoch 127 Step 300/351 lr 0.000010 loss 0.1826 (0.1597) acc@1 0.9453 (0.9447) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-22 23:02:11] __main__ INFO: \u001b[0mEpoch 127 Step 351/351 lr 0.000010 loss 0.1681 (0.1597) acc@1 0.9219 (0.9445) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 23:02:11] __main__ INFO: \u001b[0mElapsed 32.37\n",
      "\u001b[32m[2020-06-22 23:02:11] __main__ INFO: \u001b[0mVal 127\n",
      "\u001b[32m[2020-06-22 23:02:12] __main__ INFO: \u001b[0mEpoch 127 loss 0.4912 acc@1 0.8582 acc@5 0.9928\n",
      "\u001b[32m[2020-06-22 23:02:12] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 23:02:12] __main__ INFO: \u001b[0mTrain 128 44577\n",
      "\u001b[32m[2020-06-22 23:02:21] __main__ INFO: \u001b[0mEpoch 128 Step 100/351 lr 0.000010 loss 0.1404 (0.1631) acc@1 0.9609 (0.9443) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 23:02:30] __main__ INFO: \u001b[0mEpoch 128 Step 200/351 lr 0.000010 loss 0.1784 (0.1602) acc@1 0.9375 (0.9451) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 23:02:39] __main__ INFO: \u001b[0mEpoch 128 Step 300/351 lr 0.000010 loss 0.1935 (0.1617) acc@1 0.9531 (0.9440) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 23:02:44] __main__ INFO: \u001b[0mEpoch 128 Step 351/351 lr 0.000010 loss 0.2215 (0.1615) acc@1 0.9141 (0.9442) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 23:02:44] __main__ INFO: \u001b[0mElapsed 32.40\n",
      "\u001b[32m[2020-06-22 23:02:44] __main__ INFO: \u001b[0mVal 128\n",
      "\u001b[32m[2020-06-22 23:02:45] __main__ INFO: \u001b[0mEpoch 128 loss 0.4880 acc@1 0.8596 acc@5 0.9932\n",
      "\u001b[32m[2020-06-22 23:02:45] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 23:02:45] __main__ INFO: \u001b[0mTrain 129 44928\n",
      "\u001b[32m[2020-06-22 23:02:55] __main__ INFO: \u001b[0mEpoch 129 Step 100/351 lr 0.000010 loss 0.1887 (0.1558) acc@1 0.9531 (0.9451) acc@5 0.9922 (0.9994)\n",
      "\u001b[32m[2020-06-22 23:03:04] __main__ INFO: \u001b[0mEpoch 129 Step 200/351 lr 0.000010 loss 0.1635 (0.1580) acc@1 0.9297 (0.9443) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-22 23:03:13] __main__ INFO: \u001b[0mEpoch 129 Step 300/351 lr 0.000010 loss 0.1753 (0.1602) acc@1 0.9453 (0.9434) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-22 23:03:18] __main__ INFO: \u001b[0mEpoch 129 Step 351/351 lr 0.000010 loss 0.1647 (0.1614) acc@1 0.9297 (0.9434) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-22 23:03:18] __main__ INFO: \u001b[0mElapsed 32.39\n",
      "\u001b[32m[2020-06-22 23:03:18] __main__ INFO: \u001b[0mVal 129\n",
      "\u001b[32m[2020-06-22 23:03:19] __main__ INFO: \u001b[0mEpoch 129 loss 0.4896 acc@1 0.8590 acc@5 0.9930\n",
      "\u001b[32m[2020-06-22 23:03:19] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 23:03:19] __main__ INFO: \u001b[0mTrain 130 45279\n",
      "\u001b[32m[2020-06-22 23:03:28] __main__ INFO: \u001b[0mEpoch 130 Step 100/351 lr 0.000010 loss 0.1135 (0.1589) acc@1 0.9766 (0.9463) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-22 23:03:37] __main__ INFO: \u001b[0mEpoch 130 Step 200/351 lr 0.000010 loss 0.1845 (0.1616) acc@1 0.9141 (0.9443) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-22 23:03:46] __main__ INFO: \u001b[0mEpoch 130 Step 300/351 lr 0.000010 loss 0.1376 (0.1614) acc@1 0.9531 (0.9448) acc@5 0.9922 (0.9995)\n",
      "\u001b[32m[2020-06-22 23:03:51] __main__ INFO: \u001b[0mEpoch 130 Step 351/351 lr 0.000010 loss 0.1797 (0.1608) acc@1 0.9375 (0.9448) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-22 23:03:51] __main__ INFO: \u001b[0mElapsed 32.41\n",
      "\u001b[32m[2020-06-22 23:03:51] __main__ INFO: \u001b[0mVal 130\n",
      "\u001b[32m[2020-06-22 23:03:52] __main__ INFO: \u001b[0mEpoch 130 loss 0.4886 acc@1 0.8590 acc@5 0.9926\n",
      "\u001b[32m[2020-06-22 23:03:52] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-22 23:03:52] __main__ INFO: \u001b[0mTrain 131 45630\n",
      "\u001b[32m[2020-06-22 23:04:02] __main__ INFO: \u001b[0mEpoch 131 Step 100/351 lr 0.000010 loss 0.1991 (0.1620) acc@1 0.9141 (0.9463) acc@5 0.9922 (0.9991)\n",
      "\u001b[32m[2020-06-22 23:04:11] __main__ INFO: \u001b[0mEpoch 131 Step 200/351 lr 0.000010 loss 0.2104 (0.1644) acc@1 0.8906 (0.9434) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 23:04:20] __main__ INFO: \u001b[0mEpoch 131 Step 300/351 lr 0.000010 loss 0.1446 (0.1628) acc@1 0.9531 (0.9440) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 23:04:25] __main__ INFO: \u001b[0mEpoch 131 Step 351/351 lr 0.000010 loss 0.2043 (0.1627) acc@1 0.9141 (0.9441) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 23:04:25] __main__ INFO: \u001b[0mElapsed 32.39\n",
      "\u001b[32m[2020-06-22 23:04:25] __main__ INFO: \u001b[0mVal 131\n",
      "\u001b[32m[2020-06-22 23:04:26] __main__ INFO: \u001b[0mEpoch 131 loss 0.4949 acc@1 0.8576 acc@5 0.9932\n",
      "\u001b[32m[2020-06-22 23:04:26] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 23:04:26] __main__ INFO: \u001b[0mTrain 132 45981\n",
      "\u001b[32m[2020-06-22 23:04:35] __main__ INFO: \u001b[0mEpoch 132 Step 100/351 lr 0.000010 loss 0.2102 (0.1638) acc@1 0.9141 (0.9441) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-22 23:04:44] __main__ INFO: \u001b[0mEpoch 132 Step 200/351 lr 0.000010 loss 0.1359 (0.1646) acc@1 0.9531 (0.9434) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 23:04:53] __main__ INFO: \u001b[0mEpoch 132 Step 300/351 lr 0.000010 loss 0.2869 (0.1656) acc@1 0.8906 (0.9428) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-22 23:04:58] __main__ INFO: \u001b[0mEpoch 132 Step 351/351 lr 0.000010 loss 0.1291 (0.1642) acc@1 0.9609 (0.9434) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-22 23:04:58] __main__ INFO: \u001b[0mElapsed 32.36\n",
      "\u001b[32m[2020-06-22 23:04:58] __main__ INFO: \u001b[0mVal 132\n",
      "\u001b[32m[2020-06-22 23:04:59] __main__ INFO: \u001b[0mEpoch 132 loss 0.4870 acc@1 0.8596 acc@5 0.9920\n",
      "\u001b[32m[2020-06-22 23:04:59] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 23:04:59] __main__ INFO: \u001b[0mTrain 133 46332\n",
      "\u001b[32m[2020-06-22 23:05:08] __main__ INFO: \u001b[0mEpoch 133 Step 100/351 lr 0.000010 loss 0.1738 (0.1600) acc@1 0.9375 (0.9455) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 23:05:18] __main__ INFO: \u001b[0mEpoch 133 Step 200/351 lr 0.000010 loss 0.1173 (0.1593) acc@1 0.9453 (0.9452) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 23:05:27] __main__ INFO: \u001b[0mEpoch 133 Step 300/351 lr 0.000010 loss 0.1656 (0.1618) acc@1 0.9453 (0.9445) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 23:05:31] __main__ INFO: \u001b[0mEpoch 133 Step 351/351 lr 0.000010 loss 0.1918 (0.1628) acc@1 0.9453 (0.9440) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 23:05:32] __main__ INFO: \u001b[0mElapsed 32.40\n",
      "\u001b[32m[2020-06-22 23:05:32] __main__ INFO: \u001b[0mVal 133\n",
      "\u001b[32m[2020-06-22 23:05:33] __main__ INFO: \u001b[0mEpoch 133 loss 0.4905 acc@1 0.8568 acc@5 0.9930\n",
      "\u001b[32m[2020-06-22 23:05:33] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 23:05:33] __main__ INFO: \u001b[0mTrain 134 46683\n",
      "\u001b[32m[2020-06-22 23:05:42] __main__ INFO: \u001b[0mEpoch 134 Step 100/351 lr 0.000010 loss 0.1334 (0.1589) acc@1 0.9453 (0.9457) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-22 23:05:51] __main__ INFO: \u001b[0mEpoch 134 Step 200/351 lr 0.000010 loss 0.1704 (0.1608) acc@1 0.9141 (0.9448) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-22 23:06:00] __main__ INFO: \u001b[0mEpoch 134 Step 300/351 lr 0.000010 loss 0.2428 (0.1617) acc@1 0.8984 (0.9443) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 23:06:05] __main__ INFO: \u001b[0mEpoch 134 Step 351/351 lr 0.000010 loss 0.1081 (0.1620) acc@1 0.9766 (0.9443) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 23:06:05] __main__ INFO: \u001b[0mElapsed 32.38\n",
      "\u001b[32m[2020-06-22 23:06:05] __main__ INFO: \u001b[0mVal 134\n",
      "\u001b[32m[2020-06-22 23:06:06] __main__ INFO: \u001b[0mEpoch 134 loss 0.4904 acc@1 0.8586 acc@5 0.9930\n",
      "\u001b[32m[2020-06-22 23:06:06] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 23:06:06] __main__ INFO: \u001b[0mTrain 135 47034\n",
      "\u001b[32m[2020-06-22 23:06:15] __main__ INFO: \u001b[0mEpoch 135 Step 100/351 lr 0.000010 loss 0.1989 (0.1686) acc@1 0.9453 (0.9422) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 23:06:25] __main__ INFO: \u001b[0mEpoch 135 Step 200/351 lr 0.000010 loss 0.1640 (0.1642) acc@1 0.9609 (0.9439) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 23:06:34] __main__ INFO: \u001b[0mEpoch 135 Step 300/351 lr 0.000010 loss 0.1938 (0.1630) acc@1 0.9375 (0.9445) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 23:06:38] __main__ INFO: \u001b[0mEpoch 135 Step 351/351 lr 0.000010 loss 0.2119 (0.1642) acc@1 0.9375 (0.9444) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 23:06:38] __main__ INFO: \u001b[0mElapsed 32.43\n",
      "\u001b[32m[2020-06-22 23:06:38] __main__ INFO: \u001b[0mVal 135\n",
      "\u001b[32m[2020-06-22 23:06:40] __main__ INFO: \u001b[0mEpoch 135 loss 0.4896 acc@1 0.8566 acc@5 0.9926\n",
      "\u001b[32m[2020-06-22 23:06:40] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 23:06:40] __main__ INFO: \u001b[0mTrain 136 47385\n",
      "\u001b[32m[2020-06-22 23:06:49] __main__ INFO: \u001b[0mEpoch 136 Step 100/351 lr 0.000010 loss 0.1050 (0.1595) acc@1 0.9688 (0.9455) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-22 23:06:58] __main__ INFO: \u001b[0mEpoch 136 Step 200/351 lr 0.000010 loss 0.1137 (0.1618) acc@1 0.9609 (0.9440) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 23:07:07] __main__ INFO: \u001b[0mEpoch 136 Step 300/351 lr 0.000010 loss 0.1804 (0.1645) acc@1 0.9453 (0.9429) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-22 23:07:12] __main__ INFO: \u001b[0mEpoch 136 Step 351/351 lr 0.000010 loss 0.1727 (0.1629) acc@1 0.9141 (0.9434) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-22 23:07:12] __main__ INFO: \u001b[0mElapsed 32.38\n",
      "\u001b[32m[2020-06-22 23:07:12] __main__ INFO: \u001b[0mVal 136\n",
      "\u001b[32m[2020-06-22 23:07:13] __main__ INFO: \u001b[0mEpoch 136 loss 0.4897 acc@1 0.8560 acc@5 0.9928\n",
      "\u001b[32m[2020-06-22 23:07:13] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-06-22 23:07:13] __main__ INFO: \u001b[0mTrain 137 47736\n",
      "\u001b[32m[2020-06-22 23:07:22] __main__ INFO: \u001b[0mEpoch 137 Step 100/351 lr 0.000010 loss 0.1834 (0.1670) acc@1 0.9375 (0.9414) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-22 23:07:32] __main__ INFO: \u001b[0mEpoch 137 Step 200/351 lr 0.000010 loss 0.1820 (0.1674) acc@1 0.9375 (0.9421) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 23:07:41] __main__ INFO: \u001b[0mEpoch 137 Step 300/351 lr 0.000010 loss 0.1484 (0.1646) acc@1 0.9375 (0.9436) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-22 23:07:45] __main__ INFO: \u001b[0mEpoch 137 Step 351/351 lr 0.000010 loss 0.1797 (0.1637) acc@1 0.9141 (0.9434) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-22 23:07:45] __main__ INFO: \u001b[0mElapsed 32.42\n",
      "\u001b[32m[2020-06-22 23:07:45] __main__ INFO: \u001b[0mVal 137\n",
      "\u001b[32m[2020-06-22 23:07:47] __main__ INFO: \u001b[0mEpoch 137 loss 0.4871 acc@1 0.8610 acc@5 0.9932\n",
      "\u001b[32m[2020-06-22 23:07:47] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-22 23:07:47] __main__ INFO: \u001b[0mTrain 138 48087\n",
      "\u001b[32m[2020-06-22 23:07:56] __main__ INFO: \u001b[0mEpoch 138 Step 100/351 lr 0.000010 loss 0.1304 (0.1552) acc@1 0.9531 (0.9472) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-22 23:08:05] __main__ INFO: \u001b[0mEpoch 138 Step 200/351 lr 0.000010 loss 0.1535 (0.1597) acc@1 0.9531 (0.9450) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-22 23:08:14] __main__ INFO: \u001b[0mEpoch 138 Step 300/351 lr 0.000010 loss 0.1360 (0.1637) acc@1 0.9375 (0.9435) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 23:08:19] __main__ INFO: \u001b[0mEpoch 138 Step 351/351 lr 0.000010 loss 0.1247 (0.1635) acc@1 0.9531 (0.9434) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 23:08:19] __main__ INFO: \u001b[0mElapsed 32.38\n",
      "\u001b[32m[2020-06-22 23:08:19] __main__ INFO: \u001b[0mVal 138\n",
      "\u001b[32m[2020-06-22 23:08:20] __main__ INFO: \u001b[0mEpoch 138 loss 0.4913 acc@1 0.8602 acc@5 0.9930\n",
      "\u001b[32m[2020-06-22 23:08:20] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 23:08:20] __main__ INFO: \u001b[0mTrain 139 48438\n",
      "\u001b[32m[2020-06-22 23:08:29] __main__ INFO: \u001b[0mEpoch 139 Step 100/351 lr 0.000010 loss 0.2074 (0.1573) acc@1 0.9141 (0.9450) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 23:08:38] __main__ INFO: \u001b[0mEpoch 139 Step 200/351 lr 0.000010 loss 0.1843 (0.1590) acc@1 0.9219 (0.9448) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 23:08:48] __main__ INFO: \u001b[0mEpoch 139 Step 300/351 lr 0.000010 loss 0.1479 (0.1621) acc@1 0.9453 (0.9435) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 23:08:52] __main__ INFO: \u001b[0mEpoch 139 Step 351/351 lr 0.000010 loss 0.1752 (0.1608) acc@1 0.9609 (0.9443) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 23:08:52] __main__ INFO: \u001b[0mElapsed 32.34\n",
      "\u001b[32m[2020-06-22 23:08:52] __main__ INFO: \u001b[0mVal 139\n",
      "\u001b[32m[2020-06-22 23:08:53] __main__ INFO: \u001b[0mEpoch 139 loss 0.4878 acc@1 0.8570 acc@5 0.9926\n",
      "\u001b[32m[2020-06-22 23:08:53] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-22 23:08:53] __main__ INFO: \u001b[0mTrain 140 48789\n",
      "\u001b[32m[2020-06-22 23:09:03] __main__ INFO: \u001b[0mEpoch 140 Step 100/351 lr 0.000010 loss 0.1802 (0.1616) acc@1 0.9297 (0.9458) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 23:09:12] __main__ INFO: \u001b[0mEpoch 140 Step 200/351 lr 0.000010 loss 0.3093 (0.1615) acc@1 0.8906 (0.9449) acc@5 0.9922 (0.9994)\n",
      "\u001b[32m[2020-06-22 23:09:21] __main__ INFO: \u001b[0mEpoch 140 Step 300/351 lr 0.000010 loss 0.1665 (0.1610) acc@1 0.9219 (0.9453) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-22 23:09:26] __main__ INFO: \u001b[0mEpoch 140 Step 351/351 lr 0.000010 loss 0.1118 (0.1606) acc@1 0.9688 (0.9455) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 23:09:26] __main__ INFO: \u001b[0mElapsed 32.36\n",
      "\u001b[32m[2020-06-22 23:09:26] __main__ INFO: \u001b[0mVal 140\n",
      "\u001b[32m[2020-06-22 23:09:27] __main__ INFO: \u001b[0mEpoch 140 loss 0.4913 acc@1 0.8574 acc@5 0.9932\n",
      "\u001b[32m[2020-06-22 23:09:27] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 23:09:27] __main__ INFO: \u001b[0mTrain 141 49140\n",
      "\u001b[32m[2020-06-22 23:09:36] __main__ INFO: \u001b[0mEpoch 141 Step 100/351 lr 0.000010 loss 0.1017 (0.1576) acc@1 0.9844 (0.9446) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-22 23:09:45] __main__ INFO: \u001b[0mEpoch 141 Step 200/351 lr 0.000010 loss 0.1724 (0.1604) acc@1 0.9297 (0.9446) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 23:09:55] __main__ INFO: \u001b[0mEpoch 141 Step 300/351 lr 0.000010 loss 0.1649 (0.1622) acc@1 0.9531 (0.9440) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 23:09:59] __main__ INFO: \u001b[0mEpoch 141 Step 351/351 lr 0.000010 loss 0.1165 (0.1613) acc@1 0.9453 (0.9448) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 23:09:59] __main__ INFO: \u001b[0mElapsed 32.42\n",
      "\u001b[32m[2020-06-22 23:09:59] __main__ INFO: \u001b[0mVal 141\n",
      "\u001b[32m[2020-06-22 23:10:00] __main__ INFO: \u001b[0mEpoch 141 loss 0.4928 acc@1 0.8558 acc@5 0.9922\n",
      "\u001b[32m[2020-06-22 23:10:00] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-22 23:10:00] __main__ INFO: \u001b[0mTrain 142 49491\n",
      "\u001b[32m[2020-06-22 23:10:10] __main__ INFO: \u001b[0mEpoch 142 Step 100/351 lr 0.000010 loss 0.1133 (0.1535) acc@1 0.9531 (0.9477) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 23:10:19] __main__ INFO: \u001b[0mEpoch 142 Step 200/351 lr 0.000010 loss 0.2005 (0.1576) acc@1 0.9531 (0.9450) acc@5 0.9922 (0.9992)\n",
      "\u001b[32m[2020-06-22 23:10:28] __main__ INFO: \u001b[0mEpoch 142 Step 300/351 lr 0.000010 loss 0.2131 (0.1610) acc@1 0.9375 (0.9443) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 23:10:33] __main__ INFO: \u001b[0mEpoch 142 Step 351/351 lr 0.000010 loss 0.1222 (0.1602) acc@1 0.9766 (0.9446) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 23:10:33] __main__ INFO: \u001b[0mElapsed 32.39\n",
      "\u001b[32m[2020-06-22 23:10:33] __main__ INFO: \u001b[0mVal 142\n",
      "\u001b[32m[2020-06-22 23:10:34] __main__ INFO: \u001b[0mEpoch 142 loss 0.4916 acc@1 0.8588 acc@5 0.9930\n",
      "\u001b[32m[2020-06-22 23:10:34] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-22 23:10:34] __main__ INFO: \u001b[0mTrain 143 49842\n",
      "\u001b[32m[2020-06-22 23:10:43] __main__ INFO: \u001b[0mEpoch 143 Step 100/351 lr 0.000010 loss 0.1429 (0.1644) acc@1 0.9375 (0.9448) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 23:10:52] __main__ INFO: \u001b[0mEpoch 143 Step 200/351 lr 0.000010 loss 0.1656 (0.1612) acc@1 0.9453 (0.9453) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 23:11:01] __main__ INFO: \u001b[0mEpoch 143 Step 300/351 lr 0.000010 loss 0.2294 (0.1632) acc@1 0.9141 (0.9444) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 23:11:06] __main__ INFO: \u001b[0mEpoch 143 Step 351/351 lr 0.000010 loss 0.2373 (0.1639) acc@1 0.9141 (0.9441) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 23:11:06] __main__ INFO: \u001b[0mElapsed 32.39\n",
      "\u001b[32m[2020-06-22 23:11:06] __main__ INFO: \u001b[0mVal 143\n",
      "\u001b[32m[2020-06-22 23:11:07] __main__ INFO: \u001b[0mEpoch 143 loss 0.4895 acc@1 0.8602 acc@5 0.9926\n",
      "\u001b[32m[2020-06-22 23:11:07] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-22 23:11:07] __main__ INFO: \u001b[0mTrain 144 50193\n",
      "\u001b[32m[2020-06-22 23:11:17] __main__ INFO: \u001b[0mEpoch 144 Step 100/351 lr 0.000010 loss 0.1573 (0.1653) acc@1 0.9453 (0.9452) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-22 23:11:26] __main__ INFO: \u001b[0mEpoch 144 Step 200/351 lr 0.000010 loss 0.1436 (0.1610) acc@1 0.9531 (0.9454) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 23:11:35] __main__ INFO: \u001b[0mEpoch 144 Step 300/351 lr 0.000010 loss 0.1339 (0.1614) acc@1 0.9609 (0.9449) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 23:11:40] __main__ INFO: \u001b[0mEpoch 144 Step 351/351 lr 0.000010 loss 0.1202 (0.1627) acc@1 0.9688 (0.9440) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 23:11:40] __main__ INFO: \u001b[0mElapsed 32.39\n",
      "\u001b[32m[2020-06-22 23:11:40] __main__ INFO: \u001b[0mVal 144\n",
      "\u001b[32m[2020-06-22 23:11:41] __main__ INFO: \u001b[0mEpoch 144 loss 0.4914 acc@1 0.8586 acc@5 0.9926\n",
      "\u001b[32m[2020-06-22 23:11:41] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-06-22 23:11:41] __main__ INFO: \u001b[0mTrain 145 50544\n",
      "\u001b[32m[2020-06-22 23:11:50] __main__ INFO: \u001b[0mEpoch 145 Step 100/351 lr 0.000010 loss 0.1707 (0.1631) acc@1 0.9609 (0.9463) acc@5 0.9844 (0.9991)\n",
      "\u001b[32m[2020-06-22 23:11:59] __main__ INFO: \u001b[0mEpoch 145 Step 200/351 lr 0.000010 loss 0.1203 (0.1630) acc@1 0.9688 (0.9447) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-22 23:12:08] __main__ INFO: \u001b[0mEpoch 145 Step 300/351 lr 0.000010 loss 0.1220 (0.1627) acc@1 0.9531 (0.9442) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 23:12:13] __main__ INFO: \u001b[0mEpoch 145 Step 351/351 lr 0.000010 loss 0.2017 (0.1631) acc@1 0.9375 (0.9444) acc@5 0.9922 (0.9992)\n",
      "\u001b[32m[2020-06-22 23:12:13] __main__ INFO: \u001b[0mElapsed 32.33\n",
      "\u001b[32m[2020-06-22 23:12:13] __main__ INFO: \u001b[0mVal 145\n",
      "\u001b[32m[2020-06-22 23:12:14] __main__ INFO: \u001b[0mEpoch 145 loss 0.4901 acc@1 0.8578 acc@5 0.9930\n",
      "\u001b[32m[2020-06-22 23:12:14] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 23:12:14] __main__ INFO: \u001b[0mTrain 146 50895\n",
      "\u001b[32m[2020-06-22 23:12:23] __main__ INFO: \u001b[0mEpoch 146 Step 100/351 lr 0.000010 loss 0.1741 (0.1632) acc@1 0.9297 (0.9426) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 23:12:33] __main__ INFO: \u001b[0mEpoch 146 Step 200/351 lr 0.000010 loss 0.1445 (0.1656) acc@1 0.9609 (0.9427) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 23:12:42] __main__ INFO: \u001b[0mEpoch 146 Step 300/351 lr 0.000010 loss 0.0893 (0.1636) acc@1 0.9766 (0.9435) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 23:12:47] __main__ INFO: \u001b[0mEpoch 146 Step 351/351 lr 0.000010 loss 0.2271 (0.1624) acc@1 0.9141 (0.9440) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 23:12:47] __main__ INFO: \u001b[0mElapsed 32.45\n",
      "\u001b[32m[2020-06-22 23:12:47] __main__ INFO: \u001b[0mVal 146\n",
      "\u001b[32m[2020-06-22 23:12:48] __main__ INFO: \u001b[0mEpoch 146 loss 0.4878 acc@1 0.8574 acc@5 0.9926\n",
      "\u001b[32m[2020-06-22 23:12:48] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-06-22 23:12:48] __main__ INFO: \u001b[0mTrain 147 51246\n",
      "\u001b[32m[2020-06-22 23:12:57] __main__ INFO: \u001b[0mEpoch 147 Step 100/351 lr 0.000010 loss 0.1384 (0.1597) acc@1 0.9609 (0.9480) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 23:13:06] __main__ INFO: \u001b[0mEpoch 147 Step 200/351 lr 0.000010 loss 0.2859 (0.1605) acc@1 0.8984 (0.9464) acc@5 0.9922 (0.9993)\n",
      "\u001b[32m[2020-06-22 23:13:15] __main__ INFO: \u001b[0mEpoch 147 Step 300/351 lr 0.000010 loss 0.1343 (0.1624) acc@1 0.9609 (0.9449) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 23:13:20] __main__ INFO: \u001b[0mEpoch 147 Step 351/351 lr 0.000010 loss 0.2230 (0.1624) acc@1 0.9062 (0.9447) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 23:13:20] __main__ INFO: \u001b[0mElapsed 32.35\n",
      "\u001b[32m[2020-06-22 23:13:20] __main__ INFO: \u001b[0mVal 147\n",
      "\u001b[32m[2020-06-22 23:13:21] __main__ INFO: \u001b[0mEpoch 147 loss 0.4895 acc@1 0.8582 acc@5 0.9928\n",
      "\u001b[32m[2020-06-22 23:13:21] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-22 23:13:21] __main__ INFO: \u001b[0mTrain 148 51597\n",
      "\u001b[32m[2020-06-22 23:13:30] __main__ INFO: \u001b[0mEpoch 148 Step 100/351 lr 0.000010 loss 0.0967 (0.1634) acc@1 0.9609 (0.9429) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-22 23:13:40] __main__ INFO: \u001b[0mEpoch 148 Step 200/351 lr 0.000010 loss 0.1538 (0.1639) acc@1 0.9531 (0.9440) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 23:13:49] __main__ INFO: \u001b[0mEpoch 148 Step 300/351 lr 0.000010 loss 0.1346 (0.1652) acc@1 0.9609 (0.9431) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 23:13:53] __main__ INFO: \u001b[0mEpoch 148 Step 351/351 lr 0.000010 loss 0.1200 (0.1645) acc@1 0.9688 (0.9434) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 23:13:53] __main__ INFO: \u001b[0mElapsed 32.37\n",
      "\u001b[32m[2020-06-22 23:13:53] __main__ INFO: \u001b[0mVal 148\n",
      "\u001b[32m[2020-06-22 23:13:55] __main__ INFO: \u001b[0mEpoch 148 loss 0.4906 acc@1 0.8600 acc@5 0.9924\n",
      "\u001b[32m[2020-06-22 23:13:55] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 23:13:55] __main__ INFO: \u001b[0mTrain 149 51948\n",
      "\u001b[32m[2020-06-22 23:14:04] __main__ INFO: \u001b[0mEpoch 149 Step 100/351 lr 0.000010 loss 0.1810 (0.1606) acc@1 0.9375 (0.9447) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-22 23:14:13] __main__ INFO: \u001b[0mEpoch 149 Step 200/351 lr 0.000010 loss 0.1637 (0.1620) acc@1 0.9688 (0.9447) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 23:14:22] __main__ INFO: \u001b[0mEpoch 149 Step 300/351 lr 0.000010 loss 0.1687 (0.1614) acc@1 0.9531 (0.9444) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 23:14:27] __main__ INFO: \u001b[0mEpoch 149 Step 351/351 lr 0.000010 loss 0.1550 (0.1593) acc@1 0.9688 (0.9452) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 23:14:27] __main__ INFO: \u001b[0mElapsed 32.40\n",
      "\u001b[32m[2020-06-22 23:14:27] __main__ INFO: \u001b[0mVal 149\n",
      "\u001b[32m[2020-06-22 23:14:28] __main__ INFO: \u001b[0mEpoch 149 loss 0.4898 acc@1 0.8578 acc@5 0.9930\n",
      "\u001b[32m[2020-06-22 23:14:28] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-22 23:14:28] __main__ INFO: \u001b[0mTrain 150 52299\n",
      "\u001b[32m[2020-06-22 23:14:37] __main__ INFO: \u001b[0mEpoch 150 Step 100/351 lr 0.000010 loss 0.1092 (0.1603) acc@1 0.9609 (0.9445) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-22 23:14:47] __main__ INFO: \u001b[0mEpoch 150 Step 200/351 lr 0.000010 loss 0.1545 (0.1588) acc@1 0.9609 (0.9453) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 23:14:56] __main__ INFO: \u001b[0mEpoch 150 Step 300/351 lr 0.000010 loss 0.1447 (0.1604) acc@1 0.9453 (0.9445) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-22 23:15:00] __main__ INFO: \u001b[0mEpoch 150 Step 351/351 lr 0.000010 loss 0.1707 (0.1629) acc@1 0.9453 (0.9436) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-22 23:15:00] __main__ INFO: \u001b[0mElapsed 32.37\n",
      "\u001b[32m[2020-06-22 23:15:00] __main__ INFO: \u001b[0mVal 150\n",
      "\u001b[32m[2020-06-22 23:15:02] __main__ INFO: \u001b[0mEpoch 150 loss 0.4918 acc@1 0.8572 acc@5 0.9930\n",
      "\u001b[32m[2020-06-22 23:15:02] __main__ INFO: \u001b[0mElapsed 1.11\n",
      "\u001b[32m[2020-06-22 23:15:02] fvcore.common.checkpoint INFO: \u001b[0mSaving checkpoint to /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00_resume300_150/checkpoint_00150.pth\n"
     ]
    }
   ],
   "source": [
    "# Resume training with the un-augmented data\n",
    "os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "#!python train.py --config configs/cifar/resnet.yaml \\\n",
    "!python train.py --config /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00/config.yaml \\\n",
    "    train.checkpoint /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00/checkpoint_00300.pth \\\n",
    "    dataset.name CIFAR10 \\\n",
    "    train.base_lr .001 \\\n",
    "    train.output_dir /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00_resume300_150 \\\n",
    "    scheduler.epochs 150\n",
    "\n",
    "#### Set LEARNING RATE based on ending LR\n",
    "#    train.resume True \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-06-22 23:15:50] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00_resume400_50/checkpoint_00050.pth\n",
      "Files already downloaded and verified\n",
      "100%|| 79/79 [00:02<00:00, 26.49it/s]\n",
      "\u001b[32m[2020-06-22 23:15:54] __main__ INFO: \u001b[0mElapsed 2.98\n",
      "\u001b[32m[2020-06-22 23:15:54] __main__ INFO: \u001b[0mLoss 0.4777 Accuracy 0.8546\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10 test dataset \n",
    "# Right the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/resnet.yaml \\\n",
    "   model.resnet.depth 32 \\\n",
    "   test.batch_size 128 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00_resume400_50/checkpoint_00050.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00_resume400_50/test_results_0050_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-06-22 23:16:54] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00_resume300_150/checkpoint_00150.pth\n",
      "Files already downloaded and verified\n",
      "100%|| 79/79 [00:02<00:00, 26.39it/s]\n",
      "\u001b[32m[2020-06-22 23:16:58] __main__ INFO: \u001b[0mElapsed 3.00\n",
      "\u001b[32m[2020-06-22 23:16:58] __main__ INFO: \u001b[0mLoss 0.4869 Accuracy 0.8578\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10 test dataset \n",
    "# Right the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/resnet.yaml \\\n",
    "   model.resnet.depth 32 \\\n",
    "   test.batch_size 128 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00_resume300_150/checkpoint_00150.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00_resume300_150/test_results_0150_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-06-22 23:17:53] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00_resume400_50/checkpoint_00050.pth\n",
      "CIFAR 10.1\n",
      "100%|| 16/16 [00:00<00:00, 17.21it/s]\n",
      "\u001b[32m[2020-06-22 23:17:54] __main__ INFO: \u001b[0mElapsed 0.93\n",
      "\u001b[32m[2020-06-22 23:17:54] __main__ INFO: \u001b[0mLoss 0.8118 Accuracy 0.7410\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10.1 test dataset \n",
    "# Right the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/resnet.yaml \\\n",
    "   model.resnet.depth 32 \\\n",
    "   test.batch_size 128 \\\n",
    "   dataset.name CIFAR101 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00_resume400_50/checkpoint_00050.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00_resume400_50/test_results_0050_cifar101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-06-22 23:18:33] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00_resume300_150/checkpoint_00150.pth\n",
      "CIFAR 10.1\n",
      "100%|| 16/16 [00:00<00:00, 17.22it/s]\n",
      "\u001b[32m[2020-06-22 23:18:35] __main__ INFO: \u001b[0mElapsed 0.93\n",
      "\u001b[32m[2020-06-22 23:18:35] __main__ INFO: \u001b[0mLoss 0.8726 Accuracy 0.7510\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10.1 test dataset \n",
    "# Right the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/resnet.yaml \\\n",
    "   model.resnet.depth 32 \\\n",
    "   test.batch_size 128 \\\n",
    "   dataset.name CIFAR101 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00_resume300_150/checkpoint_00150.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00_resume300_150/test_results_0150_cifar101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-06-22 23:19:47] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00/checkpoint_00400.pth\n",
      "Files already downloaded and verified\n",
      "100%|| 79/79 [00:02<00:00, 26.66it/s]\n",
      "\u001b[32m[2020-06-22 23:19:51] __main__ INFO: \u001b[0mElapsed 2.97\n",
      "\u001b[32m[2020-06-22 23:19:51] __main__ INFO: \u001b[0mLoss 4.3634 Accuracy 0.4587\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10 test dataset \n",
    "# Right the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/resnet.yaml \\\n",
    "   model.resnet.depth 32 \\\n",
    "   test.batch_size 128 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00/checkpoint_00400.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00/test_results_0400_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-06-22 23:22:42] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00/checkpoint_00200.pth\n",
      "Files already downloaded and verified\n",
      "100%|| 79/79 [00:02<00:00, 26.36it/s]\n",
      "\u001b[32m[2020-06-22 23:22:46] __main__ INFO: \u001b[0mElapsed 3.00\n",
      "\u001b[32m[2020-06-22 23:22:46] __main__ INFO: \u001b[0mLoss 2.9290 Accuracy 0.4871\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10 test dataset \n",
    "# Right the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/resnet.yaml \\\n",
    "   model.resnet.depth 32 \\\n",
    "   test.batch_size 128 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00/checkpoint_00200.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00/test_results_0200_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-06-22 23:23:15] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00/checkpoint_00300.pth\n",
      "Files already downloaded and verified\n",
      "100%|| 79/79 [00:02<00:00, 26.51it/s]\n",
      "\u001b[32m[2020-06-22 23:23:19] __main__ INFO: \u001b[0mElapsed 2.98\n",
      "\u001b[32m[2020-06-22 23:23:19] __main__ INFO: \u001b[0mLoss 3.5888 Accuracy 0.4743\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10 test dataset \n",
    "# Right the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/resnet.yaml \\\n",
    "   model.resnet.depth 32 \\\n",
    "   test.batch_size 128 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00/checkpoint_00300.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00/test_results_0300_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-06-22 23:23:46] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00/checkpoint_00400.pth\n",
      "CIFAR 10.1\n",
      "100%|| 16/16 [00:00<00:00, 17.58it/s]\n",
      "\u001b[32m[2020-06-22 23:23:47] __main__ INFO: \u001b[0mElapsed 0.91\n",
      "\u001b[32m[2020-06-22 23:23:47] __main__ INFO: \u001b[0mLoss 5.7641 Accuracy 0.3185\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10.1 test dataset \n",
    "# Right the results to the test output directory specified.\n",
    "os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "!python evaluate.py --config configs/cifar/resnet.yaml \\\n",
    "   model.resnet.depth 32 \\\n",
    "   test.batch_size 128 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00/checkpoint_00400.pth \\\n",
    "   dataset.name CIFAR101 \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00/test_results_0400_cifar101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-06-22 23:24:03] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00/checkpoint_00300.pth\n",
      "CIFAR 10.1\n",
      "100%|| 16/16 [00:00<00:00, 19.34it/s]\n",
      "\u001b[32m[2020-06-22 23:24:04] __main__ INFO: \u001b[0mElapsed 0.83\n",
      "\u001b[32m[2020-06-22 23:24:04] __main__ INFO: \u001b[0mLoss 4.8777 Accuracy 0.3500\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10.1 test dataset \n",
    "# Right the results to the test output directory specified.\n",
    "os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "!python evaluate.py --config configs/cifar/resnet.yaml \\\n",
    "   model.resnet.depth 32 \\\n",
    "   test.batch_size 128 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00/checkpoint_00300.pth \\\n",
    "   dataset.name CIFAR101 \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00/test_results_0300_cifar101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Testset</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Original_Accuracy</th>\n",
       "      <th>Original_CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resnet_basic_32</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3604</td>\n",
       "      <td>0.9170</td>\n",
       "      <td>92.5</td>\n",
       "      <td>(92.0, 93.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>resnet_basic_32</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>160</td>\n",
       "      <td>0.4011</td>\n",
       "      <td>0.9232</td>\n",
       "      <td>92.5</td>\n",
       "      <td>(92.0, 93.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>resnet_basic_32</td>\n",
       "      <td>cifar10.1</td>\n",
       "      <td>160</td>\n",
       "      <td>0.8051</td>\n",
       "      <td>0.8320</td>\n",
       "      <td>84.9</td>\n",
       "      <td>(83.2, 86.4)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model    Testset  Epoch    Loss  Accuracy  Original_Accuracy  \\\n",
       "0  resnet_basic_32    cifar10    100  0.3604    0.9170               92.5   \n",
       "1  resnet_basic_32    cifar10    160  0.4011    0.9232               92.5   \n",
       "2  resnet_basic_32  cifar10.1    160  0.8051    0.8320               84.9   \n",
       "\n",
       "    Original_CI  \n",
       "0  (92.0, 93.0)  \n",
       "1  (92.0, 93.0)  \n",
       "2  (83.2, 86.4)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write the results to a CSV file so that we can analyze later.\n",
    "import pandas as pd\n",
    "\n",
    "results = {'Model': ['resnet_basic_32', 'resnet_basic_32', 'resnet_basic_32']\n",
    "           'Testset': ['cifar10', 'cifar10', 'cifar10.1']\n",
    "           'Loss': [0.3604, 0.4011, 0.8051],\n",
    "           'Epoch': [100, 160, 160],\n",
    "           'Accuracy': [0.9170, 0.9232, 0.8320],\n",
    "           'Original_Accuracy': [92.5, 92.5, 84.9],\n",
    "           'Original_CI': [(92.0, 93.0), (92.0, 93.0), (83.2, 86.4)]\n",
    "           }\n",
    "\n",
    "df = pd.DataFrame(results, columns = ['Model', 'Testset', 'Epoch', 'Loss', 'Accuracy', \n",
    "                                      'Original_Accuracy', 'Original_CI'])\n",
    "\n",
    "\n",
    "df.to_csv('/home/ec2-user/SageMaker/experiments/resnet_basic_32/exp00/results.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Testset</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Original_Accuracy</th>\n",
       "      <th>Original_CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resnet_basic_32_ra_3_20</td>\n",
       "      <td>400</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>4.3634</td>\n",
       "      <td>0.4587</td>\n",
       "      <td>92.5</td>\n",
       "      <td>(92.0, 93.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>resnet_basic_32_ra_3_20</td>\n",
       "      <td>300</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>3.5888</td>\n",
       "      <td>0.4743</td>\n",
       "      <td>92.5</td>\n",
       "      <td>(92.0, 93.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>resnet_basic_32_ra_3_20</td>\n",
       "      <td>400</td>\n",
       "      <td>cifar10.1</td>\n",
       "      <td>5.7641</td>\n",
       "      <td>0.3185</td>\n",
       "      <td>84.9</td>\n",
       "      <td>(83.2, 86.4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>resnet_basic_32_ra_3_20</td>\n",
       "      <td>300</td>\n",
       "      <td>cifar10.1</td>\n",
       "      <td>4.8777</td>\n",
       "      <td>0.35</td>\n",
       "      <td>84.9</td>\n",
       "      <td>(83.2, 86.4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>resnet_basic_32_ra_3_20_refined400</td>\n",
       "      <td>50</td>\n",
       "      <td>cifar10.1</td>\n",
       "      <td>0.8118</td>\n",
       "      <td>0.741</td>\n",
       "      <td>84.9</td>\n",
       "      <td>(83.2, 86.4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>resnet_basic_32_ra_3_20_refined400</td>\n",
       "      <td>50</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>0.4777</td>\n",
       "      <td>0.8546</td>\n",
       "      <td>92.5</td>\n",
       "      <td>(92.0, 93.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>resnet_basic_32_ra_3_20_refined300</td>\n",
       "      <td>150</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>0.4869</td>\n",
       "      <td>0.8578</td>\n",
       "      <td>92.5</td>\n",
       "      <td>(92.0, 93.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>resnet_basic_32_ra_3_20_refined300</td>\n",
       "      <td>150</td>\n",
       "      <td>cifar10.1</td>\n",
       "      <td>0.8726</td>\n",
       "      <td>0.751</td>\n",
       "      <td>84.9</td>\n",
       "      <td>(83.2, 86.4)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Model Epoch    Testset    Loss Accuracy  \\\n",
       "0             resnet_basic_32_ra_3_20   400    cifar10  4.3634   0.4587   \n",
       "1             resnet_basic_32_ra_3_20   300    cifar10  3.5888   0.4743   \n",
       "2             resnet_basic_32_ra_3_20   400  cifar10.1  5.7641   0.3185   \n",
       "3             resnet_basic_32_ra_3_20   300  cifar10.1  4.8777     0.35   \n",
       "4  resnet_basic_32_ra_3_20_refined400    50  cifar10.1  0.8118    0.741   \n",
       "5  resnet_basic_32_ra_3_20_refined400    50    cifar10  0.4777   0.8546   \n",
       "6  resnet_basic_32_ra_3_20_refined300   150    cifar10  0.4869   0.8578   \n",
       "7  resnet_basic_32_ra_3_20_refined300   150  cifar10.1  0.8726    0.751   \n",
       "\n",
       "   Original_Accuracy   Original_CI  \n",
       "0               92.5  (92.0, 93.0)  \n",
       "1               92.5  (92.0, 93.0)  \n",
       "2               84.9  (83.2, 86.4)  \n",
       "3               84.9  (83.2, 86.4)  \n",
       "4               84.9  (83.2, 86.4)  \n",
       "5               92.5  (92.0, 93.0)  \n",
       "6               92.5  (92.0, 93.0)  \n",
       "7               84.9  (83.2, 86.4)  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "a = pd.Series(['resnet_basic_32_ra_3_20', 400, 'cifar10', 4.3634, 0.4587])\n",
    "b = pd.Series(['resnet_basic_32_ra_3_20', 300, 'cifar10', 3.5888, 0.4743])\n",
    "c = pd.Series(['resnet_basic_32_ra_3_20', 400, 'cifar10.1', 5.7641,  0.3185])\n",
    "d = pd.Series(['resnet_basic_32_ra_3_20', 300, 'cifar10.1',  4.8777, 0.3500])\n",
    "\n",
    "    \n",
    "    \n",
    "e = pd.Series(['resnet_basic_32_ra_3_20_refined400', 50, 'cifar10.1', 0.8118, 0.7410])\n",
    "f = pd.Series(['resnet_basic_32_ra_3_20_refined400', 50, 'cifar10', 0.4777, 0.8546])\n",
    "g = pd.Series(['resnet_basic_32_ra_3_20_refined300', 150, 'cifar10',  0.4869, 0.8578])\n",
    "h = pd.Series(['resnet_basic_32_ra_3_20_refined300', 150, 'cifar10.1', 0.8726, 0.7510])\n",
    "               \n",
    "df_results = pd.concat([a,b,c,d,e,f, g, h], axis=1).T\n",
    "df_results.columns = ['Model', 'Epoch', 'Testset', 'Loss', 'Accuracy']\n",
    "\n",
    "df_results['Original_Accuracy'] = df_results.apply((lambda row: 92.5 if row[2] == 'cifar10' else 84.9), axis=1)\n",
    "df_results['Original_CI'] = df_results.apply((lambda row: (92.0, 93.0) if row[2] == 'cifar10' else (83.2, 86.4)), axis=1)\n",
    "\n",
    "df_results.to_csv('/home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/results.csv')\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['preds', 'probs', 'labels', 'loss', 'acc']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ -7.153804  ,  -0.1832159 ,  -0.69570637, ...,  -0.50926757,\n",
       "         -5.526208  , -12.987257  ],\n",
       "       [  2.862379  ,   7.963458  ,  -6.603018  , ...,  -4.740323  ,\n",
       "         25.90399   ,  -0.52988565],\n",
       "       [  4.25749   ,   8.408992  ,  -4.3299227 , ...,  -2.3715498 ,\n",
       "         13.468082  ,   4.5792727 ],\n",
       "       ...,\n",
       "       [ -4.7270765 ,  -1.2400844 ,   1.3852903 , ...,  -0.51062894,\n",
       "         -3.399443  ,  -2.4969094 ],\n",
       "       [ -2.7640457 ,  14.635863  ,   6.7449965 , ...,  -1.3011913 ,\n",
       "         -3.036379  ,  -7.061736  ],\n",
       "       [ -2.6933427 ,   1.8961854 ,  -3.6396854 , ...,  18.63456   ,\n",
       "         -2.7524152 ,  -3.2204888 ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Peak inside the output file for predictions\n",
    "import numpy as np\n",
    "output = '/home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20/exp00/test_results_0160/predictions.npz'\n",
    "npzfile = np.load(output)\n",
    "print(npzfile.files)\n",
    "npzfile['preds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the model checkpoints, configs, and results to S3 \n",
    "bucket='sagemaker-may29'\n",
    "prefix = 'sagemaker/results/original-models/resnet_basic_32_ra_3_20'\n",
    "path = '/home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_3_20'\n",
    "\n",
    "s3_resource = boto3.resource(\"s3\", region_name=\"us-east-2\")\n",
    "\n",
    "def uploadDirectory(local_path,bucket_name,s3_prefix):\n",
    "\n",
    "    my_bucket = s3_resource.Bucket(bucket_name)\n",
    "    \n",
    "    for path, subdirs, files in os.walk(local_path):\n",
    "        path = path.replace(\"\\\\\",\"/\")\n",
    "        directory_name = path.replace(local_path,\"\")\n",
    "        for file in files:\n",
    "            #print(\"Local File:\", os.path.join(path, file))\n",
    "            #print(\"      Dest:\", s3_prefix+directory_name+'/'+file)\n",
    "            my_bucket.upload_file(os.path.join(path, file), s3_prefix+directory_name+'/'+file)\n",
    "    \n",
    "uploadDirectory(path,bucket,prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
