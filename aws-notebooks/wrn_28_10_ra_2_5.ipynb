{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wide Residual Net 29 4x64\n",
    "- Training Dataset: RandAugment, N=2, M=5\n",
    "- Sagemaker Notebook must be of type, conda_pytorch_p36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy \n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 1)) (1.18.1)\n",
      "Requirement already satisfied: torch>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 2)) (1.4.0)\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 3)) (0.5.0)\n",
      "Requirement already satisfied: fvcore in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (0.1.1.post20200619)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 5)) (4.44.1)\n",
      "Requirement already satisfied: yacs in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 6)) (0.1.7)\n",
      "Requirement already satisfied: apex from git+https://github.com/NVIDIA/apex.git#egg=apex in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 7)) (0.1)\n",
      "Requirement already satisfied: termcolor in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 8)) (1.1.0)\n",
      "Requirement already satisfied: thop<0.0.31.post2004070130 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 9)) (0.0.31.post2001170342)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 3)) (1.14.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 3)) (7.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from fvcore->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (5.3.1)\n",
      "Requirement already satisfied: tabulate in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from fvcore->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (0.8.7)\n",
      "Requirement already satisfied: portalocker in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from fvcore->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (1.7.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Sagemaker Notebook must be of type, conda_pytorch_p36\n",
    "\n",
    "!pip install -r '/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (2.2.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.4.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.0.1)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (3.12.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.34.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.14.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.29.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (3.2.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (46.1.3.post20200330)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.18.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (2.23.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.6.0.post3)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.18.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.9.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (1.5.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.1.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard) (3.4.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.4.5.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (1.25.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard) (2.2.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Need to add this to requirements.txt\n",
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model per the settings specified in the original RESNET paper\n",
    "# os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "# !python train.py --config configs/cifar/wrn.yaml \\\n",
    "#     model.wrn.depth 28 \\\n",
    "#     model.wrn.widening_factor 10 \\\n",
    "#     train.batch_size 128 \\\n",
    "#     train.base_lr 0.1 \\\n",
    "#     train.output_dir /home/ec2-user/SageMaker/experiments/wrn_28_10/exp00 \\\n",
    "#     scheduler.epochs 200\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-06-20 17:54:34] __main__ INFO: \u001b[0mdevice: cuda\n",
      "cudnn:\n",
      "  benchmark: True\n",
      "  deterministic: False\n",
      "dataset:\n",
      "  name: CIFAR10_RA_2_5\n",
      "  dataset_dir: ''\n",
      "  image_size: 32\n",
      "  n_channels: 3\n",
      "  n_classes: 10\n",
      "model:\n",
      "  type: cifar\n",
      "  name: wrn\n",
      "  init_mode: kaiming_fan_in\n",
      "  vgg:\n",
      "    n_channels: [64, 128, 256, 512, 512]\n",
      "    n_layers: [2, 2, 3, 3, 3]\n",
      "    use_bn: True\n",
      "  resnet:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "  resnet_preact:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "  wrn:\n",
      "    depth: 28\n",
      "    initial_channels: 16\n",
      "    widening_factor: 10\n",
      "    drop_rate: 0.0\n",
      "  densenet:\n",
      "    depth: 100\n",
      "    n_blocks: [6, 12, 24, 16]\n",
      "    block_type: bottleneck\n",
      "    growth_rate: 12\n",
      "    drop_rate: 0.0\n",
      "    compression_rate: 0.5\n",
      "  pyramidnet:\n",
      "    depth: 272\n",
      "    n_blocks: [3, 24, 36, 3]\n",
      "    initial_channels: 16\n",
      "    block_type: bottleneck\n",
      "    alpha: 200\n",
      "  resnext:\n",
      "    depth: 29\n",
      "    n_blocks: [3, 4, 6, 3]\n",
      "    initial_channels: 64\n",
      "    cardinality: 8\n",
      "    base_channels: 4\n",
      "  shake_shake:\n",
      "    depth: 26\n",
      "    initial_channels: 96\n",
      "    shake_forward: True\n",
      "    shake_backward: True\n",
      "    shake_image: True\n",
      "  se_resnet_preact:\n",
      "    depth: 110\n",
      "    initial_channels: 16\n",
      "    se_reduction: 16\n",
      "    block_type: basic\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "train:\n",
      "  checkpoint: ''\n",
      "  resume: False\n",
      "  precision: O0\n",
      "  batch_size: 128\n",
      "  subdivision: 1\n",
      "  optimizer: sgd\n",
      "  base_lr: 0.1\n",
      "  momentum: 0.9\n",
      "  nesterov: True\n",
      "  weight_decay: 0.0005\n",
      "  no_weight_decay_on_bn: False\n",
      "  gradient_clip: 0\n",
      "  start_epoch: 0\n",
      "  seed: 0\n",
      "  val_first: True\n",
      "  val_period: 1\n",
      "  val_ratio: 0.1\n",
      "  use_test_as_val: False\n",
      "  output_dir: /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_5/exp00\n",
      "  log_period: 100\n",
      "  checkpoint_period: 100\n",
      "  use_tensorboard: True\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: True\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "  distributed: False\n",
      "  dist:\n",
      "    backend: nccl\n",
      "    init_method: env://\n",
      "    world_size: -1\n",
      "    node_rank: -1\n",
      "    local_rank: 0\n",
      "    use_sync_bn: False\n",
      "tensorboard:\n",
      "  train_images: False\n",
      "  val_images: False\n",
      "  model_params: False\n",
      "optim:\n",
      "  adam:\n",
      "    betas: (0.9, 0.999)\n",
      "  lars:\n",
      "    eps: 1e-09\n",
      "    threshold: 0.01\n",
      "  adabound:\n",
      "    betas: (0.9, 0.999)\n",
      "    final_lr: 0.1\n",
      "    gamma: 0.001\n",
      "scheduler:\n",
      "  epochs: 400\n",
      "  warmup:\n",
      "    type: none\n",
      "    epochs: 0\n",
      "    start_factor: 0.001\n",
      "    exponent: 4\n",
      "  type: multistep\n",
      "  milestones: [60, 120, 160]\n",
      "  lr_decay: 0.2\n",
      "  lr_min_factor: 0.001\n",
      "  T0: 10\n",
      "  T_mul: 1.0\n",
      "validation:\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: False\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "augmentation:\n",
      "  use_random_crop: True\n",
      "  use_random_horizontal_flip: True\n",
      "  use_cutout: False\n",
      "  use_random_erasing: False\n",
      "  use_dual_cutout: False\n",
      "  use_mixup: False\n",
      "  use_ricap: False\n",
      "  use_cutmix: False\n",
      "  use_label_smoothing: False\n",
      "  random_crop:\n",
      "    padding: 4\n",
      "    fill: 0\n",
      "    padding_mode: constant\n",
      "  random_horizontal_flip:\n",
      "    prob: 0.5\n",
      "  cutout:\n",
      "    prob: 1.0\n",
      "    mask_size: 16\n",
      "    cut_inside: False\n",
      "    mask_color: 0\n",
      "    dual_cutout_alpha: 0.1\n",
      "  random_erasing:\n",
      "    prob: 0.5\n",
      "    area_ratio_range: [0.02, 0.4]\n",
      "    min_aspect_ratio: 0.3\n",
      "    max_attempt: 20\n",
      "  mixup:\n",
      "    alpha: 1.0\n",
      "  ricap:\n",
      "    beta: 0.3\n",
      "  cutmix:\n",
      "    alpha: 1.0\n",
      "  label_smoothing:\n",
      "    epsilon: 0.1\n",
      "tta:\n",
      "  use_resize: False\n",
      "  use_center_crop: False\n",
      "  resize: 256\n",
      "test:\n",
      "  checkpoint: ''\n",
      "  output_dir: ''\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    pin_memory: False\n",
      "\u001b[32m[2020-06-20 17:54:34] __main__ INFO: \u001b[0menv_info:\n",
      "  pytorch_version: 1.4.0\n",
      "  cuda_version: 10.1\n",
      "  cudnn_version: 7603\n",
      "  num_gpus: 1\n",
      "  gpu_name: Tesla K80\n",
      "  gpu_capability: 3.7\n",
      "(50000, 32, 32, 3)\n",
      "\u001b[32m[2020-06-20 17:54:41] __main__ INFO: \u001b[0mMACs  : 5.25G\n",
      "\u001b[32m[2020-06-20 17:54:41] __main__ INFO: \u001b[0m#params: 36.48M\n",
      "Selected optimization level O0:  Pure FP32 training.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n",
      "\u001b[32m[2020-06-20 17:54:41] __main__ INFO: \u001b[0mVal 0\n",
      "\u001b[32m[2020-06-20 17:55:00] __main__ INFO: \u001b[0mEpoch 0 loss 202.6672 acc@1 0.1016 acc@5 0.4966\n",
      "\u001b[32m[2020-06-20 17:55:00] __main__ INFO: \u001b[0mElapsed 19.73\n",
      "\u001b[32m[2020-06-20 17:55:00] __main__ INFO: \u001b[0mTrain 1 0\n",
      "\u001b[32m[2020-06-20 17:56:58] __main__ INFO: \u001b[0mEpoch 1 Step 100/351 lr 0.100000 loss 2.1510 (2.4081) acc@1 0.1328 (0.1322) acc@5 0.6719 (0.5876)\n",
      "\u001b[32m[2020-06-20 17:58:51] __main__ INFO: \u001b[0mEpoch 1 Step 200/351 lr 0.100000 loss 2.1154 (2.2892) acc@1 0.1953 (0.1557) acc@5 0.7188 (0.6259)\n",
      "\u001b[32m[2020-06-20 18:00:44] __main__ INFO: \u001b[0mEpoch 1 Step 300/351 lr 0.100000 loss 1.9807 (2.2212) acc@1 0.1719 (0.1752) acc@5 0.7656 (0.6501)\n",
      "\u001b[32m[2020-06-20 18:01:41] __main__ INFO: \u001b[0mEpoch 1 Step 351/351 lr 0.100000 loss 1.9717 (2.1956) acc@1 0.2500 (0.1836) acc@5 0.7266 (0.6605)\n",
      "\u001b[32m[2020-06-20 18:01:41] __main__ INFO: \u001b[0mElapsed 400.99\n",
      "\u001b[32m[2020-06-20 18:01:41] __main__ INFO: \u001b[0mVal 1\n",
      "\u001b[32m[2020-06-20 18:01:54] __main__ INFO: \u001b[0mEpoch 1 loss 2.1258 acc@1 0.1988 acc@5 0.7152\n",
      "\u001b[32m[2020-06-20 18:01:54] __main__ INFO: \u001b[0mElapsed 13.24\n",
      "\u001b[32m[2020-06-20 18:01:54] __main__ INFO: \u001b[0mTrain 2 351\n",
      "\u001b[32m[2020-06-20 18:03:47] __main__ INFO: \u001b[0mEpoch 2 Step 100/351 lr 0.100000 loss 2.0602 (1.9899) acc@1 0.2266 (0.2559) acc@5 0.6797 (0.7316)\n",
      "\u001b[32m[2020-06-20 18:05:40] __main__ INFO: \u001b[0mEpoch 2 Step 200/351 lr 0.100000 loss 1.7957 (1.9634) acc@1 0.3047 (0.2657) acc@5 0.8281 (0.7408)\n",
      "\u001b[32m[2020-06-20 18:07:33] __main__ INFO: \u001b[0mEpoch 2 Step 300/351 lr 0.100000 loss 1.6749 (1.9217) acc@1 0.3828 (0.2831) acc@5 0.8125 (0.7513)\n",
      "\u001b[32m[2020-06-20 18:08:31] __main__ INFO: \u001b[0mEpoch 2 Step 351/351 lr 0.100000 loss 1.7919 (1.9058) acc@1 0.2969 (0.2895) acc@5 0.7969 (0.7532)\n",
      "\u001b[32m[2020-06-20 18:08:31] __main__ INFO: \u001b[0mElapsed 396.19\n",
      "\u001b[32m[2020-06-20 18:08:31] __main__ INFO: \u001b[0mVal 2\n",
      "\u001b[32m[2020-06-20 18:08:44] __main__ INFO: \u001b[0mEpoch 2 loss 2.2456 acc@1 0.2312 acc@5 0.6886\n",
      "\u001b[32m[2020-06-20 18:08:44] __main__ INFO: \u001b[0mElapsed 13.27\n",
      "\u001b[32m[2020-06-20 18:08:44] __main__ INFO: \u001b[0mTrain 3 702\n",
      "\u001b[32m[2020-06-20 18:10:37] __main__ INFO: \u001b[0mEpoch 3 Step 100/351 lr 0.100000 loss 1.6985 (1.7743) acc@1 0.4062 (0.3498) acc@5 0.7734 (0.7873)\n",
      "\u001b[32m[2020-06-20 18:12:30] __main__ INFO: \u001b[0mEpoch 3 Step 200/351 lr 0.100000 loss 1.6414 (1.7346) acc@1 0.3828 (0.3616) acc@5 0.8359 (0.7892)\n",
      "\u001b[32m[2020-06-20 18:14:23] __main__ INFO: \u001b[0mEpoch 3 Step 300/351 lr 0.100000 loss 1.7485 (1.7047) acc@1 0.3281 (0.3702) acc@5 0.7734 (0.7944)\n",
      "\u001b[32m[2020-06-20 18:15:20] __main__ INFO: \u001b[0mEpoch 3 Step 351/351 lr 0.100000 loss 1.6114 (1.6947) acc@1 0.3984 (0.3733) acc@5 0.8359 (0.7958)\n",
      "\u001b[32m[2020-06-20 18:15:20] __main__ INFO: \u001b[0mElapsed 396.42\n",
      "\u001b[32m[2020-06-20 18:15:20] __main__ INFO: \u001b[0mVal 3\n",
      "\u001b[32m[2020-06-20 18:15:34] __main__ INFO: \u001b[0mEpoch 3 loss 2.1775 acc@1 0.3030 acc@5 0.7352\n",
      "\u001b[32m[2020-06-20 18:15:34] __main__ INFO: \u001b[0mElapsed 13.30\n",
      "\u001b[32m[2020-06-20 18:15:34] __main__ INFO: \u001b[0mTrain 4 1053\n",
      "\u001b[32m[2020-06-20 18:17:27] __main__ INFO: \u001b[0mEpoch 4 Step 100/351 lr 0.100000 loss 1.6158 (1.5913) acc@1 0.3906 (0.4084) acc@5 0.7891 (0.8135)\n",
      "\u001b[32m[2020-06-20 18:19:20] __main__ INFO: \u001b[0mEpoch 4 Step 200/351 lr 0.100000 loss 1.4835 (1.5763) acc@1 0.5234 (0.4163) acc@5 0.8281 (0.8134)\n",
      "\u001b[32m[2020-06-20 18:21:13] __main__ INFO: \u001b[0mEpoch 4 Step 300/351 lr 0.100000 loss 1.5461 (1.5610) acc@1 0.4453 (0.4220) acc@5 0.8438 (0.8147)\n",
      "\u001b[32m[2020-06-20 18:22:10] __main__ INFO: \u001b[0mEpoch 4 Step 351/351 lr 0.100000 loss 1.3948 (1.5548) acc@1 0.4922 (0.4252) acc@5 0.8516 (0.8149)\n",
      "\u001b[32m[2020-06-20 18:22:10] __main__ INFO: \u001b[0mElapsed 396.51\n",
      "\u001b[32m[2020-06-20 18:22:10] __main__ INFO: \u001b[0mVal 4\n",
      "\u001b[32m[2020-06-20 18:22:23] __main__ INFO: \u001b[0mEpoch 4 loss 1.5966 acc@1 0.4272 acc@5 0.8194\n",
      "\u001b[32m[2020-06-20 18:22:23] __main__ INFO: \u001b[0mElapsed 13.29\n",
      "\u001b[32m[2020-06-20 18:22:23] __main__ INFO: \u001b[0mTrain 5 1404\n",
      "\u001b[32m[2020-06-20 18:24:16] __main__ INFO: \u001b[0mEpoch 5 Step 100/351 lr 0.100000 loss 1.5597 (1.4849) acc@1 0.4219 (0.4522) acc@5 0.8203 (0.8242)\n",
      "\u001b[32m[2020-06-20 18:26:09] __main__ INFO: \u001b[0mEpoch 5 Step 200/351 lr 0.100000 loss 1.5333 (1.4762) acc@1 0.3984 (0.4559) acc@5 0.8672 (0.8230)\n",
      "\u001b[32m[2020-06-20 18:28:02] __main__ INFO: \u001b[0mEpoch 5 Step 300/351 lr 0.100000 loss 1.2125 (1.4659) acc@1 0.5391 (0.4590) acc@5 0.8906 (0.8239)\n",
      "\u001b[32m[2020-06-20 18:29:00] __main__ INFO: \u001b[0mEpoch 5 Step 351/351 lr 0.100000 loss 1.5740 (1.4614) acc@1 0.4375 (0.4611) acc@5 0.8047 (0.8236)\n",
      "\u001b[32m[2020-06-20 18:29:00] __main__ INFO: \u001b[0mElapsed 396.46\n",
      "\u001b[32m[2020-06-20 18:29:00] __main__ INFO: \u001b[0mVal 5\n",
      "\u001b[32m[2020-06-20 18:29:13] __main__ INFO: \u001b[0mEpoch 5 loss 1.5297 acc@1 0.4570 acc@5 0.8234\n",
      "\u001b[32m[2020-06-20 18:29:13] __main__ INFO: \u001b[0mElapsed 13.30\n",
      "\u001b[32m[2020-06-20 18:29:13] __main__ INFO: \u001b[0mTrain 6 1755\n",
      "\u001b[32m[2020-06-20 18:31:06] __main__ INFO: \u001b[0mEpoch 6 Step 100/351 lr 0.100000 loss 1.3618 (1.3922) acc@1 0.5312 (0.4936) acc@5 0.8594 (0.8339)\n",
      "\u001b[32m[2020-06-20 18:32:59] __main__ INFO: \u001b[0mEpoch 6 Step 200/351 lr 0.100000 loss 1.3761 (1.3940) acc@1 0.5078 (0.4917) acc@5 0.8203 (0.8341)\n",
      "\u001b[32m[2020-06-20 18:34:52] __main__ INFO: \u001b[0mEpoch 6 Step 300/351 lr 0.100000 loss 1.3819 (1.3931) acc@1 0.5078 (0.4898) acc@5 0.8516 (0.8337)\n",
      "\u001b[32m[2020-06-20 18:35:50] __main__ INFO: \u001b[0mEpoch 6 Step 351/351 lr 0.100000 loss 1.3744 (1.3937) acc@1 0.5234 (0.4889) acc@5 0.8594 (0.8325)\n",
      "\u001b[32m[2020-06-20 18:35:50] __main__ INFO: \u001b[0mElapsed 396.60\n",
      "\u001b[32m[2020-06-20 18:35:50] __main__ INFO: \u001b[0mVal 6\n",
      "\u001b[32m[2020-06-20 18:36:03] __main__ INFO: \u001b[0mEpoch 6 loss 1.5580 acc@1 0.4416 acc@5 0.8222\n",
      "\u001b[32m[2020-06-20 18:36:03] __main__ INFO: \u001b[0mElapsed 13.27\n",
      "\u001b[32m[2020-06-20 18:36:03] __main__ INFO: \u001b[0mTrain 7 2106\n",
      "\u001b[32m[2020-06-20 18:37:56] __main__ INFO: \u001b[0mEpoch 7 Step 100/351 lr 0.100000 loss 1.3603 (1.3640) acc@1 0.4453 (0.4986) acc@5 0.8281 (0.8306)\n",
      "\u001b[32m[2020-06-20 18:39:49] __main__ INFO: \u001b[0mEpoch 7 Step 200/351 lr 0.100000 loss 1.3983 (1.3594) acc@1 0.4531 (0.5012) acc@5 0.8203 (0.8354)\n",
      "\u001b[32m[2020-06-20 18:41:42] __main__ INFO: \u001b[0mEpoch 7 Step 300/351 lr 0.100000 loss 1.3203 (1.3567) acc@1 0.5078 (0.5001) acc@5 0.8359 (0.8352)\n",
      "\u001b[32m[2020-06-20 18:42:39] __main__ INFO: \u001b[0mEpoch 7 Step 351/351 lr 0.100000 loss 1.3539 (1.3559) acc@1 0.5234 (0.5003) acc@5 0.8203 (0.8354)\n",
      "\u001b[32m[2020-06-20 18:42:40] __main__ INFO: \u001b[0mElapsed 396.39\n",
      "\u001b[32m[2020-06-20 18:42:40] __main__ INFO: \u001b[0mVal 7\n",
      "\u001b[32m[2020-06-20 18:42:53] __main__ INFO: \u001b[0mEpoch 7 loss 1.5256 acc@1 0.4598 acc@5 0.8330\n",
      "\u001b[32m[2020-06-20 18:42:53] __main__ INFO: \u001b[0mElapsed 13.28\n",
      "\u001b[32m[2020-06-20 18:42:53] __main__ INFO: \u001b[0mTrain 8 2457\n",
      "\u001b[32m[2020-06-20 18:44:46] __main__ INFO: \u001b[0mEpoch 8 Step 100/351 lr 0.100000 loss 1.4775 (1.3205) acc@1 0.5078 (0.5110) acc@5 0.8828 (0.8401)\n",
      "\u001b[32m[2020-06-20 18:46:39] __main__ INFO: \u001b[0mEpoch 8 Step 200/351 lr 0.100000 loss 1.5069 (1.3202) acc@1 0.4531 (0.5101) acc@5 0.7500 (0.8389)\n",
      "\u001b[32m[2020-06-20 18:48:32] __main__ INFO: \u001b[0mEpoch 8 Step 300/351 lr 0.100000 loss 1.1514 (1.3220) acc@1 0.5938 (0.5101) acc@5 0.8594 (0.8377)\n",
      "\u001b[32m[2020-06-20 18:49:29] __main__ INFO: \u001b[0mEpoch 8 Step 351/351 lr 0.100000 loss 1.2705 (1.3220) acc@1 0.5938 (0.5110) acc@5 0.9297 (0.8383)\n",
      "\u001b[32m[2020-06-20 18:49:29] __main__ INFO: \u001b[0mElapsed 396.30\n",
      "\u001b[32m[2020-06-20 18:49:29] __main__ INFO: \u001b[0mVal 8\n",
      "\u001b[32m[2020-06-20 18:49:42] __main__ INFO: \u001b[0mEpoch 8 loss 1.3679 acc@1 0.5062 acc@5 0.8362\n",
      "\u001b[32m[2020-06-20 18:49:42] __main__ INFO: \u001b[0mElapsed 13.28\n",
      "\u001b[32m[2020-06-20 18:49:42] __main__ INFO: \u001b[0mTrain 9 2808\n",
      "\u001b[32m[2020-06-20 18:51:35] __main__ INFO: \u001b[0mEpoch 9 Step 100/351 lr 0.100000 loss 1.3587 (1.2833) acc@1 0.5391 (0.5316) acc@5 0.8594 (0.8426)\n",
      "\u001b[32m[2020-06-20 18:53:28] __main__ INFO: \u001b[0mEpoch 9 Step 200/351 lr 0.100000 loss 1.2617 (1.2884) acc@1 0.5391 (0.5278) acc@5 0.8359 (0.8412)\n",
      "\u001b[32m[2020-06-20 18:55:21] __main__ INFO: \u001b[0mEpoch 9 Step 300/351 lr 0.100000 loss 1.2359 (1.2909) acc@1 0.5391 (0.5252) acc@5 0.8516 (0.8405)\n",
      "\u001b[32m[2020-06-20 18:56:19] __main__ INFO: \u001b[0mEpoch 9 Step 351/351 lr 0.100000 loss 1.5393 (1.2934) acc@1 0.4375 (0.5246) acc@5 0.8047 (0.8397)\n",
      "\u001b[32m[2020-06-20 18:56:19] __main__ INFO: \u001b[0mElapsed 396.27\n",
      "\u001b[32m[2020-06-20 18:56:19] __main__ INFO: \u001b[0mVal 9\n",
      "\u001b[32m[2020-06-20 18:56:32] __main__ INFO: \u001b[0mEpoch 9 loss 1.5423 acc@1 0.4504 acc@5 0.8206\n",
      "\u001b[32m[2020-06-20 18:56:32] __main__ INFO: \u001b[0mElapsed 13.29\n",
      "\u001b[32m[2020-06-20 18:56:32] __main__ INFO: \u001b[0mTrain 10 3159\n",
      "\u001b[32m[2020-06-20 18:58:25] __main__ INFO: \u001b[0mEpoch 10 Step 100/351 lr 0.100000 loss 1.2935 (1.2639) acc@1 0.5000 (0.5362) acc@5 0.8438 (0.8390)\n",
      "\u001b[32m[2020-06-20 19:00:18] __main__ INFO: \u001b[0mEpoch 10 Step 200/351 lr 0.100000 loss 1.1824 (1.2644) acc@1 0.5547 (0.5367) acc@5 0.9219 (0.8410)\n",
      "\u001b[32m[2020-06-20 19:02:10] __main__ INFO: \u001b[0mEpoch 10 Step 300/351 lr 0.100000 loss 1.2700 (1.2765) acc@1 0.5625 (0.5315) acc@5 0.8594 (0.8401)\n",
      "\u001b[32m[2020-06-20 19:03:08] __main__ INFO: \u001b[0mEpoch 10 Step 351/351 lr 0.100000 loss 1.1592 (1.2749) acc@1 0.5703 (0.5332) acc@5 0.8828 (0.8405)\n",
      "\u001b[32m[2020-06-20 19:03:08] __main__ INFO: \u001b[0mElapsed 396.00\n",
      "\u001b[32m[2020-06-20 19:03:08] __main__ INFO: \u001b[0mVal 10\n",
      "\u001b[32m[2020-06-20 19:03:21] __main__ INFO: \u001b[0mEpoch 10 loss 1.4817 acc@1 0.4772 acc@5 0.8370\n",
      "\u001b[32m[2020-06-20 19:03:21] __main__ INFO: \u001b[0mElapsed 13.27\n",
      "\u001b[32m[2020-06-20 19:03:21] __main__ INFO: \u001b[0mTrain 11 3510\n",
      "\u001b[32m[2020-06-20 19:05:14] __main__ INFO: \u001b[0mEpoch 11 Step 100/351 lr 0.100000 loss 1.2564 (1.2419) acc@1 0.5312 (0.5418) acc@5 0.8359 (0.8478)\n",
      "\u001b[32m[2020-06-20 19:07:07] __main__ INFO: \u001b[0mEpoch 11 Step 200/351 lr 0.100000 loss 1.2833 (1.2528) acc@1 0.5391 (0.5379) acc@5 0.8359 (0.8424)\n",
      "\u001b[32m[2020-06-20 19:09:00] __main__ INFO: \u001b[0mEpoch 11 Step 300/351 lr 0.100000 loss 1.3352 (1.2566) acc@1 0.4766 (0.5369) acc@5 0.8438 (0.8432)\n",
      "\u001b[32m[2020-06-20 19:09:57] __main__ INFO: \u001b[0mEpoch 11 Step 351/351 lr 0.100000 loss 1.2228 (1.2567) acc@1 0.5312 (0.5366) acc@5 0.7969 (0.8419)\n",
      "\u001b[32m[2020-06-20 19:09:57] __main__ INFO: \u001b[0mElapsed 395.88\n",
      "\u001b[32m[2020-06-20 19:09:57] __main__ INFO: \u001b[0mVal 11\n",
      "\u001b[32m[2020-06-20 19:10:10] __main__ INFO: \u001b[0mEpoch 11 loss 1.3631 acc@1 0.5094 acc@5 0.8358\n",
      "\u001b[32m[2020-06-20 19:10:10] __main__ INFO: \u001b[0mElapsed 13.29\n",
      "\u001b[32m[2020-06-20 19:10:10] __main__ INFO: \u001b[0mTrain 12 3861\n",
      "\u001b[32m[2020-06-20 19:12:03] __main__ INFO: \u001b[0mEpoch 12 Step 100/351 lr 0.100000 loss 1.2069 (1.2355) acc@1 0.5312 (0.5441) acc@5 0.8594 (0.8436)\n",
      "\u001b[32m[2020-06-20 19:13:56] __main__ INFO: \u001b[0mEpoch 12 Step 200/351 lr 0.100000 loss 1.3058 (1.2413) acc@1 0.5469 (0.5412) acc@5 0.8281 (0.8432)\n",
      "\u001b[32m[2020-06-20 19:15:49] __main__ INFO: \u001b[0mEpoch 12 Step 300/351 lr 0.100000 loss 1.3420 (1.2420) acc@1 0.5469 (0.5414) acc@5 0.8516 (0.8441)\n",
      "\u001b[32m[2020-06-20 19:16:46] __main__ INFO: \u001b[0mEpoch 12 Step 351/351 lr 0.100000 loss 1.2101 (1.2428) acc@1 0.5781 (0.5407) acc@5 0.8516 (0.8441)\n",
      "\u001b[32m[2020-06-20 19:16:46] __main__ INFO: \u001b[0mElapsed 395.79\n",
      "\u001b[32m[2020-06-20 19:16:46] __main__ INFO: \u001b[0mVal 12\n",
      "\u001b[32m[2020-06-20 19:16:59] __main__ INFO: \u001b[0mEpoch 12 loss 1.4694 acc@1 0.4722 acc@5 0.8350\n",
      "\u001b[32m[2020-06-20 19:16:59] __main__ INFO: \u001b[0mElapsed 13.28\n",
      "\u001b[32m[2020-06-20 19:16:59] __main__ INFO: \u001b[0mTrain 13 4212\n",
      "\u001b[32m[2020-06-20 19:18:52] __main__ INFO: \u001b[0mEpoch 13 Step 100/351 lr 0.100000 loss 1.2798 (1.2387) acc@1 0.5234 (0.5442) acc@5 0.9062 (0.8462)\n",
      "\u001b[32m[2020-06-20 19:20:45] __main__ INFO: \u001b[0mEpoch 13 Step 200/351 lr 0.100000 loss 1.1402 (1.2347) acc@1 0.6016 (0.5428) acc@5 0.8750 (0.8438)\n",
      "\u001b[32m[2020-06-20 19:22:38] __main__ INFO: \u001b[0mEpoch 13 Step 300/351 lr 0.100000 loss 1.2646 (1.2324) acc@1 0.5312 (0.5449) acc@5 0.8672 (0.8444)\n",
      "\u001b[32m[2020-06-20 19:23:35] __main__ INFO: \u001b[0mEpoch 13 Step 351/351 lr 0.100000 loss 1.1619 (1.2326) acc@1 0.5781 (0.5442) acc@5 0.8438 (0.8446)\n",
      "\u001b[32m[2020-06-20 19:23:35] __main__ INFO: \u001b[0mElapsed 395.90\n",
      "\u001b[32m[2020-06-20 19:23:35] __main__ INFO: \u001b[0mVal 13\n",
      "\u001b[32m[2020-06-20 19:23:49] __main__ INFO: \u001b[0mEpoch 13 loss 1.3604 acc@1 0.5116 acc@5 0.8380\n",
      "\u001b[32m[2020-06-20 19:23:49] __main__ INFO: \u001b[0mElapsed 13.26\n",
      "\u001b[32m[2020-06-20 19:23:49] __main__ INFO: \u001b[0mTrain 14 4563\n",
      "\u001b[32m[2020-06-20 19:25:42] __main__ INFO: \u001b[0mEpoch 14 Step 100/351 lr 0.100000 loss 1.1264 (1.2026) acc@1 0.5703 (0.5529) acc@5 0.8594 (0.8456)\n",
      "\u001b[32m[2020-06-20 19:27:34] __main__ INFO: \u001b[0mEpoch 14 Step 200/351 lr 0.100000 loss 1.2628 (1.2112) acc@1 0.5156 (0.5537) acc@5 0.8828 (0.8452)\n",
      "\u001b[32m[2020-06-20 19:29:27] __main__ INFO: \u001b[0mEpoch 14 Step 300/351 lr 0.100000 loss 1.1375 (1.2145) acc@1 0.5859 (0.5532) acc@5 0.8750 (0.8464)\n",
      "\u001b[32m[2020-06-20 19:30:24] __main__ INFO: \u001b[0mEpoch 14 Step 351/351 lr 0.100000 loss 1.2886 (1.2162) acc@1 0.4922 (0.5530) acc@5 0.8594 (0.8460)\n",
      "\u001b[32m[2020-06-20 19:30:25] __main__ INFO: \u001b[0mElapsed 395.87\n",
      "\u001b[32m[2020-06-20 19:30:25] __main__ INFO: \u001b[0mVal 14\n",
      "\u001b[32m[2020-06-20 19:30:38] __main__ INFO: \u001b[0mEpoch 14 loss 1.3652 acc@1 0.5036 acc@5 0.8380\n",
      "\u001b[32m[2020-06-20 19:30:38] __main__ INFO: \u001b[0mElapsed 13.31\n",
      "\u001b[32m[2020-06-20 19:30:38] __main__ INFO: \u001b[0mTrain 15 4914\n",
      "\u001b[32m[2020-06-20 19:32:31] __main__ INFO: \u001b[0mEpoch 15 Step 100/351 lr 0.100000 loss 1.2145 (1.2086) acc@1 0.5391 (0.5544) acc@5 0.8438 (0.8480)\n",
      "\u001b[32m[2020-06-20 19:34:23] __main__ INFO: \u001b[0mEpoch 15 Step 200/351 lr 0.100000 loss 1.3226 (1.2069) acc@1 0.5469 (0.5548) acc@5 0.8203 (0.8482)\n",
      "\u001b[32m[2020-06-20 19:36:16] __main__ INFO: \u001b[0mEpoch 15 Step 300/351 lr 0.100000 loss 1.0787 (1.2046) acc@1 0.5938 (0.5567) acc@5 0.8672 (0.8462)\n",
      "\u001b[32m[2020-06-20 19:37:13] __main__ INFO: \u001b[0mEpoch 15 Step 351/351 lr 0.100000 loss 1.2942 (1.2055) acc@1 0.5312 (0.5566) acc@5 0.7812 (0.8456)\n",
      "\u001b[32m[2020-06-20 19:37:14] __main__ INFO: \u001b[0mElapsed 395.69\n",
      "\u001b[32m[2020-06-20 19:37:14] __main__ INFO: \u001b[0mVal 15\n",
      "\u001b[32m[2020-06-20 19:37:27] __main__ INFO: \u001b[0mEpoch 15 loss 1.4849 acc@1 0.4894 acc@5 0.8372\n",
      "\u001b[32m[2020-06-20 19:37:27] __main__ INFO: \u001b[0mElapsed 13.27\n",
      "\u001b[32m[2020-06-20 19:37:27] __main__ INFO: \u001b[0mTrain 16 5265\n",
      "\u001b[32m[2020-06-20 19:39:20] __main__ INFO: \u001b[0mEpoch 16 Step 100/351 lr 0.100000 loss 1.2056 (1.1882) acc@1 0.5391 (0.5638) acc@5 0.8594 (0.8475)\n",
      "\u001b[32m[2020-06-20 19:41:12] __main__ INFO: \u001b[0mEpoch 16 Step 200/351 lr 0.100000 loss 1.1709 (1.1905) acc@1 0.5391 (0.5635) acc@5 0.7969 (0.8464)\n",
      "\u001b[32m[2020-06-20 19:43:05] __main__ INFO: \u001b[0mEpoch 16 Step 300/351 lr 0.100000 loss 1.1769 (1.1973) acc@1 0.5625 (0.5593) acc@5 0.8438 (0.8440)\n",
      "\u001b[32m[2020-06-20 19:44:02] __main__ INFO: \u001b[0mEpoch 16 Step 351/351 lr 0.100000 loss 1.2718 (1.1970) acc@1 0.5469 (0.5602) acc@5 0.7969 (0.8448)\n",
      "\u001b[32m[2020-06-20 19:44:02] __main__ INFO: \u001b[0mElapsed 395.57\n",
      "\u001b[32m[2020-06-20 19:44:02] __main__ INFO: \u001b[0mVal 16\n",
      "\u001b[32m[2020-06-20 19:44:16] __main__ INFO: \u001b[0mEpoch 16 loss 1.3060 acc@1 0.5250 acc@5 0.8416\n",
      "\u001b[32m[2020-06-20 19:44:16] __main__ INFO: \u001b[0mElapsed 13.24\n",
      "\u001b[32m[2020-06-20 19:44:16] __main__ INFO: \u001b[0mTrain 17 5616\n",
      "\u001b[32m[2020-06-20 19:46:08] __main__ INFO: \u001b[0mEpoch 17 Step 100/351 lr 0.100000 loss 1.2176 (1.1804) acc@1 0.5625 (0.5634) acc@5 0.8281 (0.8528)\n",
      "\u001b[32m[2020-06-20 19:48:01] __main__ INFO: \u001b[0mEpoch 17 Step 200/351 lr 0.100000 loss 1.2516 (1.1862) acc@1 0.5156 (0.5603) acc@5 0.8047 (0.8503)\n",
      "\u001b[32m[2020-06-20 19:49:54] __main__ INFO: \u001b[0mEpoch 17 Step 300/351 lr 0.100000 loss 1.1549 (1.1873) acc@1 0.5469 (0.5612) acc@5 0.8203 (0.8493)\n",
      "\u001b[32m[2020-06-20 19:50:51] __main__ INFO: \u001b[0mEpoch 17 Step 351/351 lr 0.100000 loss 1.3062 (1.1889) acc@1 0.4844 (0.5611) acc@5 0.8047 (0.8482)\n",
      "\u001b[32m[2020-06-20 19:50:51] __main__ INFO: \u001b[0mElapsed 395.55\n",
      "\u001b[32m[2020-06-20 19:50:51] __main__ INFO: \u001b[0mVal 17\n",
      "\u001b[32m[2020-06-20 19:51:04] __main__ INFO: \u001b[0mEpoch 17 loss 1.3526 acc@1 0.5168 acc@5 0.8376\n",
      "\u001b[32m[2020-06-20 19:51:04] __main__ INFO: \u001b[0mElapsed 13.25\n",
      "\u001b[32m[2020-06-20 19:51:04] __main__ INFO: \u001b[0mTrain 18 5967\n",
      "\u001b[32m[2020-06-20 19:52:57] __main__ INFO: \u001b[0mEpoch 18 Step 100/351 lr 0.100000 loss 1.2870 (1.1587) acc@1 0.5234 (0.5754) acc@5 0.8125 (0.8489)\n",
      "\u001b[32m[2020-06-20 19:54:50] __main__ INFO: \u001b[0mEpoch 18 Step 200/351 lr 0.100000 loss 1.1787 (1.1781) acc@1 0.5391 (0.5648) acc@5 0.8672 (0.8471)\n",
      "\u001b[32m[2020-06-20 19:56:42] __main__ INFO: \u001b[0mEpoch 18 Step 300/351 lr 0.100000 loss 1.1560 (1.1841) acc@1 0.5781 (0.5629) acc@5 0.8516 (0.8468)\n",
      "\u001b[32m[2020-06-20 19:57:40] __main__ INFO: \u001b[0mEpoch 18 Step 351/351 lr 0.100000 loss 1.1391 (1.1835) acc@1 0.6094 (0.5627) acc@5 0.8359 (0.8466)\n",
      "\u001b[32m[2020-06-20 19:57:40] __main__ INFO: \u001b[0mElapsed 395.47\n",
      "\u001b[32m[2020-06-20 19:57:40] __main__ INFO: \u001b[0mVal 18\n",
      "\u001b[32m[2020-06-20 19:57:53] __main__ INFO: \u001b[0mEpoch 18 loss 1.3638 acc@1 0.5166 acc@5 0.8394\n",
      "\u001b[32m[2020-06-20 19:57:53] __main__ INFO: \u001b[0mElapsed 13.25\n",
      "\u001b[32m[2020-06-20 19:57:53] __main__ INFO: \u001b[0mTrain 19 6318\n",
      "\u001b[32m[2020-06-20 19:59:46] __main__ INFO: \u001b[0mEpoch 19 Step 100/351 lr 0.100000 loss 1.0020 (1.1640) acc@1 0.6797 (0.5713) acc@5 0.9453 (0.8528)\n",
      "\u001b[32m[2020-06-20 20:01:39] __main__ INFO: \u001b[0mEpoch 19 Step 200/351 lr 0.100000 loss 1.3384 (1.1692) acc@1 0.5000 (0.5690) acc@5 0.8047 (0.8510)\n",
      "\u001b[32m[2020-06-20 20:03:31] __main__ INFO: \u001b[0mEpoch 19 Step 300/351 lr 0.100000 loss 1.1525 (1.1747) acc@1 0.5391 (0.5668) acc@5 0.8672 (0.8506)\n",
      "\u001b[32m[2020-06-20 20:04:29] __main__ INFO: \u001b[0mEpoch 19 Step 351/351 lr 0.100000 loss 1.0825 (1.1760) acc@1 0.6094 (0.5654) acc@5 0.8594 (0.8510)\n",
      "\u001b[32m[2020-06-20 20:04:29] __main__ INFO: \u001b[0mElapsed 395.56\n",
      "\u001b[32m[2020-06-20 20:04:29] __main__ INFO: \u001b[0mVal 19\n",
      "\u001b[32m[2020-06-20 20:04:42] __main__ INFO: \u001b[0mEpoch 19 loss 1.3997 acc@1 0.4928 acc@5 0.8354\n",
      "\u001b[32m[2020-06-20 20:04:42] __main__ INFO: \u001b[0mElapsed 13.26\n",
      "\u001b[32m[2020-06-20 20:04:42] __main__ INFO: \u001b[0mTrain 20 6669\n",
      "\u001b[32m[2020-06-20 20:06:35] __main__ INFO: \u001b[0mEpoch 20 Step 100/351 lr 0.100000 loss 1.0934 (1.1521) acc@1 0.6172 (0.5730) acc@5 0.8047 (0.8492)\n",
      "\u001b[32m[2020-06-20 20:08:27] __main__ INFO: \u001b[0mEpoch 20 Step 200/351 lr 0.100000 loss 1.0693 (1.1566) acc@1 0.5859 (0.5710) acc@5 0.8516 (0.8500)\n",
      "\u001b[32m[2020-06-20 20:10:20] __main__ INFO: \u001b[0mEpoch 20 Step 300/351 lr 0.100000 loss 1.2746 (1.1637) acc@1 0.5391 (0.5687) acc@5 0.8438 (0.8485)\n",
      "\u001b[32m[2020-06-20 20:11:17] __main__ INFO: \u001b[0mEpoch 20 Step 351/351 lr 0.100000 loss 1.2841 (1.1647) acc@1 0.5156 (0.5691) acc@5 0.8203 (0.8490)\n",
      "\u001b[32m[2020-06-20 20:11:17] __main__ INFO: \u001b[0mElapsed 395.44\n",
      "\u001b[32m[2020-06-20 20:11:17] __main__ INFO: \u001b[0mVal 20\n",
      "\u001b[32m[2020-06-20 20:11:31] __main__ INFO: \u001b[0mEpoch 20 loss 1.4071 acc@1 0.5022 acc@5 0.8350\n",
      "\u001b[32m[2020-06-20 20:11:31] __main__ INFO: \u001b[0mElapsed 13.26\n",
      "\u001b[32m[2020-06-20 20:11:31] __main__ INFO: \u001b[0mTrain 21 7020\n",
      "\u001b[32m[2020-06-20 20:13:23] __main__ INFO: \u001b[0mEpoch 21 Step 100/351 lr 0.100000 loss 1.2171 (1.1241) acc@1 0.5547 (0.5802) acc@5 0.8359 (0.8545)\n",
      "\u001b[32m[2020-06-20 20:15:16] __main__ INFO: \u001b[0mEpoch 21 Step 200/351 lr 0.100000 loss 1.1636 (1.1439) acc@1 0.5234 (0.5756) acc@5 0.8594 (0.8517)\n",
      "\u001b[32m[2020-06-20 20:17:09] __main__ INFO: \u001b[0mEpoch 21 Step 300/351 lr 0.100000 loss 1.0403 (1.1526) acc@1 0.6562 (0.5736) acc@5 0.8438 (0.8496)\n",
      "\u001b[32m[2020-06-20 20:18:06] __main__ INFO: \u001b[0mEpoch 21 Step 351/351 lr 0.100000 loss 1.2410 (1.1568) acc@1 0.5234 (0.5713) acc@5 0.7812 (0.8481)\n",
      "\u001b[32m[2020-06-20 20:18:06] __main__ INFO: \u001b[0mElapsed 395.45\n",
      "\u001b[32m[2020-06-20 20:18:06] __main__ INFO: \u001b[0mVal 21\n",
      "\u001b[32m[2020-06-20 20:18:19] __main__ INFO: \u001b[0mEpoch 21 loss 1.3237 acc@1 0.5180 acc@5 0.8368\n",
      "\u001b[32m[2020-06-20 20:18:19] __main__ INFO: \u001b[0mElapsed 13.22\n",
      "\u001b[32m[2020-06-20 20:18:19] __main__ INFO: \u001b[0mTrain 22 7371\n",
      "\u001b[32m[2020-06-20 20:20:12] __main__ INFO: \u001b[0mEpoch 22 Step 100/351 lr 0.100000 loss 1.1768 (1.1477) acc@1 0.5312 (0.5755) acc@5 0.8281 (0.8474)\n",
      "\u001b[32m[2020-06-20 20:22:05] __main__ INFO: \u001b[0mEpoch 22 Step 200/351 lr 0.100000 loss 1.1320 (1.1423) acc@1 0.5859 (0.5788) acc@5 0.8984 (0.8487)\n",
      "\u001b[32m[2020-06-20 20:23:57] __main__ INFO: \u001b[0mEpoch 22 Step 300/351 lr 0.100000 loss 1.4635 (1.1516) acc@1 0.4766 (0.5745) acc@5 0.8359 (0.8479)\n",
      "\u001b[32m[2020-06-20 20:24:55] __main__ INFO: \u001b[0mEpoch 22 Step 351/351 lr 0.100000 loss 1.1297 (1.1555) acc@1 0.6016 (0.5734) acc@5 0.8906 (0.8473)\n",
      "\u001b[32m[2020-06-20 20:24:55] __main__ INFO: \u001b[0mElapsed 395.31\n",
      "\u001b[32m[2020-06-20 20:24:55] __main__ INFO: \u001b[0mVal 22\n",
      "\u001b[32m[2020-06-20 20:25:08] __main__ INFO: \u001b[0mEpoch 22 loss 1.2979 acc@1 0.5318 acc@5 0.8418\n",
      "\u001b[32m[2020-06-20 20:25:08] __main__ INFO: \u001b[0mElapsed 13.26\n",
      "\u001b[32m[2020-06-20 20:25:08] __main__ INFO: \u001b[0mTrain 23 7722\n",
      "\u001b[32m[2020-06-20 20:27:01] __main__ INFO: \u001b[0mEpoch 23 Step 100/351 lr 0.100000 loss 1.1794 (1.1303) acc@1 0.5469 (0.5816) acc@5 0.8594 (0.8541)\n",
      "\u001b[32m[2020-06-20 20:28:53] __main__ INFO: \u001b[0mEpoch 23 Step 200/351 lr 0.100000 loss 1.1665 (1.1499) acc@1 0.6094 (0.5749) acc@5 0.8359 (0.8491)\n",
      "\u001b[32m[2020-06-20 20:30:46] __main__ INFO: \u001b[0mEpoch 23 Step 300/351 lr 0.100000 loss 1.0641 (1.1526) acc@1 0.6016 (0.5736) acc@5 0.8203 (0.8491)\n",
      "\u001b[32m[2020-06-20 20:31:43] __main__ INFO: \u001b[0mEpoch 23 Step 351/351 lr 0.100000 loss 1.2020 (1.1515) acc@1 0.5703 (0.5746) acc@5 0.8047 (0.8495)\n",
      "\u001b[32m[2020-06-20 20:31:43] __main__ INFO: \u001b[0mElapsed 395.36\n",
      "\u001b[32m[2020-06-20 20:31:43] __main__ INFO: \u001b[0mVal 23\n",
      "\u001b[32m[2020-06-20 20:31:56] __main__ INFO: \u001b[0mEpoch 23 loss 1.3518 acc@1 0.5170 acc@5 0.8382\n",
      "\u001b[32m[2020-06-20 20:31:56] __main__ INFO: \u001b[0mElapsed 13.25\n",
      "\u001b[32m[2020-06-20 20:31:56] __main__ INFO: \u001b[0mTrain 24 8073\n",
      "\u001b[32m[2020-06-20 20:33:49] __main__ INFO: \u001b[0mEpoch 24 Step 100/351 lr 0.100000 loss 1.2176 (1.1289) acc@1 0.5312 (0.5830) acc@5 0.8125 (0.8539)\n",
      "\u001b[32m[2020-06-20 20:35:42] __main__ INFO: \u001b[0mEpoch 24 Step 200/351 lr 0.100000 loss 1.1272 (1.1332) acc@1 0.6016 (0.5793) acc@5 0.8047 (0.8532)\n",
      "\u001b[32m[2020-06-20 20:37:34] __main__ INFO: \u001b[0mEpoch 24 Step 300/351 lr 0.100000 loss 1.1745 (1.1399) acc@1 0.5625 (0.5771) acc@5 0.8438 (0.8519)\n",
      "\u001b[32m[2020-06-20 20:38:32] __main__ INFO: \u001b[0mEpoch 24 Step 351/351 lr 0.100000 loss 1.1530 (1.1413) acc@1 0.5938 (0.5775) acc@5 0.8828 (0.8521)\n",
      "\u001b[32m[2020-06-20 20:38:32] __main__ INFO: \u001b[0mElapsed 395.32\n",
      "\u001b[32m[2020-06-20 20:38:32] __main__ INFO: \u001b[0mVal 24\n",
      "\u001b[32m[2020-06-20 20:38:45] __main__ INFO: \u001b[0mEpoch 24 loss 1.4101 acc@1 0.4982 acc@5 0.8444\n",
      "\u001b[32m[2020-06-20 20:38:45] __main__ INFO: \u001b[0mElapsed 13.23\n",
      "\u001b[32m[2020-06-20 20:38:45] __main__ INFO: \u001b[0mTrain 25 8424\n",
      "\u001b[32m[2020-06-20 20:40:38] __main__ INFO: \u001b[0mEpoch 25 Step 100/351 lr 0.100000 loss 1.1947 (1.1185) acc@1 0.5781 (0.5829) acc@5 0.8516 (0.8538)\n",
      "\u001b[32m[2020-06-20 20:42:30] __main__ INFO: \u001b[0mEpoch 25 Step 200/351 lr 0.100000 loss 0.9719 (1.1320) acc@1 0.6406 (0.5806) acc@5 0.8359 (0.8520)\n",
      "\u001b[32m[2020-06-20 20:44:23] __main__ INFO: \u001b[0mEpoch 25 Step 300/351 lr 0.100000 loss 1.0659 (1.1339) acc@1 0.6094 (0.5816) acc@5 0.8828 (0.8509)\n",
      "\u001b[32m[2020-06-20 20:45:20] __main__ INFO: \u001b[0mEpoch 25 Step 351/351 lr 0.100000 loss 1.0783 (1.1347) acc@1 0.5938 (0.5813) acc@5 0.8438 (0.8517)\n",
      "\u001b[32m[2020-06-20 20:45:20] __main__ INFO: \u001b[0mElapsed 395.31\n",
      "\u001b[32m[2020-06-20 20:45:20] __main__ INFO: \u001b[0mVal 25\n",
      "\u001b[32m[2020-06-20 20:45:34] __main__ INFO: \u001b[0mEpoch 25 loss 1.4147 acc@1 0.5070 acc@5 0.8380\n",
      "\u001b[32m[2020-06-20 20:45:34] __main__ INFO: \u001b[0mElapsed 13.23\n",
      "\u001b[32m[2020-06-20 20:45:34] __main__ INFO: \u001b[0mTrain 26 8775\n",
      "\u001b[32m[2020-06-20 20:47:26] __main__ INFO: \u001b[0mEpoch 26 Step 100/351 lr 0.100000 loss 0.9389 (1.1263) acc@1 0.6719 (0.5831) acc@5 0.8828 (0.8528)\n",
      "\u001b[32m[2020-06-20 20:49:19] __main__ INFO: \u001b[0mEpoch 26 Step 200/351 lr 0.100000 loss 1.2421 (1.1312) acc@1 0.5547 (0.5814) acc@5 0.8516 (0.8508)\n",
      "\u001b[32m[2020-06-20 20:51:12] __main__ INFO: \u001b[0mEpoch 26 Step 300/351 lr 0.100000 loss 1.2299 (1.1321) acc@1 0.5234 (0.5815) acc@5 0.8750 (0.8519)\n",
      "\u001b[32m[2020-06-20 20:52:09] __main__ INFO: \u001b[0mEpoch 26 Step 351/351 lr 0.100000 loss 1.0757 (1.1344) acc@1 0.5859 (0.5805) acc@5 0.8203 (0.8513)\n",
      "\u001b[32m[2020-06-20 20:52:09] __main__ INFO: \u001b[0mElapsed 395.33\n",
      "\u001b[32m[2020-06-20 20:52:09] __main__ INFO: \u001b[0mVal 26\n",
      "\u001b[32m[2020-06-20 20:52:22] __main__ INFO: \u001b[0mEpoch 26 loss 1.3194 acc@1 0.5204 acc@5 0.8414\n",
      "\u001b[32m[2020-06-20 20:52:22] __main__ INFO: \u001b[0mElapsed 13.25\n",
      "\u001b[32m[2020-06-20 20:52:22] __main__ INFO: \u001b[0mTrain 27 9126\n",
      "\u001b[32m[2020-06-20 20:54:15] __main__ INFO: \u001b[0mEpoch 27 Step 100/351 lr 0.100000 loss 1.1251 (1.1125) acc@1 0.5703 (0.5870) acc@5 0.8750 (0.8523)\n",
      "\u001b[32m[2020-06-20 20:56:07] __main__ INFO: \u001b[0mEpoch 27 Step 200/351 lr 0.100000 loss 1.0777 (1.1213) acc@1 0.6172 (0.5830) acc@5 0.7969 (0.8508)\n",
      "\u001b[32m[2020-06-20 20:58:00] __main__ INFO: \u001b[0mEpoch 27 Step 300/351 lr 0.100000 loss 1.2118 (1.1247) acc@1 0.5312 (0.5823) acc@5 0.8516 (0.8496)\n",
      "\u001b[32m[2020-06-20 20:58:57] __main__ INFO: \u001b[0mEpoch 27 Step 351/351 lr 0.100000 loss 1.0621 (1.1231) acc@1 0.6172 (0.5837) acc@5 0.8750 (0.8496)\n",
      "\u001b[32m[2020-06-20 20:58:57] __main__ INFO: \u001b[0mElapsed 395.28\n",
      "\u001b[32m[2020-06-20 20:58:57] __main__ INFO: \u001b[0mVal 27\n",
      "\u001b[32m[2020-06-20 20:59:11] __main__ INFO: \u001b[0mEpoch 27 loss 1.2353 acc@1 0.5602 acc@5 0.8444\n",
      "\u001b[32m[2020-06-20 20:59:11] __main__ INFO: \u001b[0mElapsed 13.24\n",
      "\u001b[32m[2020-06-20 20:59:11] __main__ INFO: \u001b[0mTrain 28 9477\n",
      "\u001b[32m[2020-06-20 21:01:03] __main__ INFO: \u001b[0mEpoch 28 Step 100/351 lr 0.100000 loss 1.1265 (1.1196) acc@1 0.5859 (0.5884) acc@5 0.8750 (0.8521)\n",
      "\u001b[32m[2020-06-20 21:02:56] __main__ INFO: \u001b[0mEpoch 28 Step 200/351 lr 0.100000 loss 0.9808 (1.1250) acc@1 0.6406 (0.5870) acc@5 0.8828 (0.8525)\n",
      "\u001b[32m[2020-06-20 21:04:49] __main__ INFO: \u001b[0mEpoch 28 Step 300/351 lr 0.100000 loss 1.1667 (1.1220) acc@1 0.5547 (0.5863) acc@5 0.8359 (0.8513)\n",
      "\u001b[32m[2020-06-20 21:05:46] __main__ INFO: \u001b[0mEpoch 28 Step 351/351 lr 0.100000 loss 1.2594 (1.1244) acc@1 0.5469 (0.5853) acc@5 0.8047 (0.8507)\n",
      "\u001b[32m[2020-06-20 21:05:46] __main__ INFO: \u001b[0mElapsed 395.37\n",
      "\u001b[32m[2020-06-20 21:05:46] __main__ INFO: \u001b[0mVal 28\n",
      "\u001b[32m[2020-06-20 21:05:59] __main__ INFO: \u001b[0mEpoch 28 loss 1.3208 acc@1 0.5288 acc@5 0.8436\n",
      "\u001b[32m[2020-06-20 21:05:59] __main__ INFO: \u001b[0mElapsed 13.27\n",
      "\u001b[32m[2020-06-20 21:05:59] __main__ INFO: \u001b[0mTrain 29 9828\n",
      "\u001b[32m[2020-06-20 21:07:52] __main__ INFO: \u001b[0mEpoch 29 Step 100/351 lr 0.100000 loss 1.2156 (1.0983) acc@1 0.5703 (0.5921) acc@5 0.8516 (0.8547)\n",
      "\u001b[32m[2020-06-20 21:09:45] __main__ INFO: \u001b[0mEpoch 29 Step 200/351 lr 0.100000 loss 1.0695 (1.1090) acc@1 0.5625 (0.5877) acc@5 0.8828 (0.8527)\n",
      "\u001b[32m[2020-06-20 21:11:37] __main__ INFO: \u001b[0mEpoch 29 Step 300/351 lr 0.100000 loss 1.1271 (1.1147) acc@1 0.5625 (0.5860) acc@5 0.8594 (0.8533)\n",
      "\u001b[32m[2020-06-20 21:12:35] __main__ INFO: \u001b[0mEpoch 29 Step 351/351 lr 0.100000 loss 1.1016 (1.1155) acc@1 0.6250 (0.5853) acc@5 0.8438 (0.8526)\n",
      "\u001b[32m[2020-06-20 21:12:35] __main__ INFO: \u001b[0mElapsed 395.44\n",
      "\u001b[32m[2020-06-20 21:12:35] __main__ INFO: \u001b[0mVal 29\n",
      "\u001b[32m[2020-06-20 21:12:48] __main__ INFO: \u001b[0mEpoch 29 loss 1.4495 acc@1 0.4908 acc@5 0.8338\n",
      "\u001b[32m[2020-06-20 21:12:48] __main__ INFO: \u001b[0mElapsed 13.26\n",
      "\u001b[32m[2020-06-20 21:12:48] __main__ INFO: \u001b[0mTrain 30 10179\n",
      "\u001b[32m[2020-06-20 21:14:41] __main__ INFO: \u001b[0mEpoch 30 Step 100/351 lr 0.100000 loss 1.1785 (1.1066) acc@1 0.5781 (0.5935) acc@5 0.8281 (0.8538)\n",
      "\u001b[32m[2020-06-20 21:16:33] __main__ INFO: \u001b[0mEpoch 30 Step 200/351 lr 0.100000 loss 1.0453 (1.1078) acc@1 0.5625 (0.5908) acc@5 0.8672 (0.8543)\n",
      "\u001b[32m[2020-06-20 21:18:26] __main__ INFO: \u001b[0mEpoch 30 Step 300/351 lr 0.100000 loss 1.0304 (1.1120) acc@1 0.6406 (0.5902) acc@5 0.8359 (0.8526)\n",
      "\u001b[32m[2020-06-20 21:19:23] __main__ INFO: \u001b[0mEpoch 30 Step 351/351 lr 0.100000 loss 1.1333 (1.1142) acc@1 0.5547 (0.5888) acc@5 0.8359 (0.8523)\n",
      "\u001b[32m[2020-06-20 21:19:23] __main__ INFO: \u001b[0mElapsed 395.34\n",
      "\u001b[32m[2020-06-20 21:19:23] __main__ INFO: \u001b[0mVal 30\n",
      "\u001b[32m[2020-06-20 21:19:37] __main__ INFO: \u001b[0mEpoch 30 loss 1.2590 acc@1 0.5502 acc@5 0.8550\n",
      "\u001b[32m[2020-06-20 21:19:37] __main__ INFO: \u001b[0mElapsed 13.24\n",
      "\u001b[32m[2020-06-20 21:19:37] __main__ INFO: \u001b[0mTrain 31 10530\n",
      "\u001b[32m[2020-06-20 21:21:29] __main__ INFO: \u001b[0mEpoch 31 Step 100/351 lr 0.100000 loss 1.0662 (1.0993) acc@1 0.5938 (0.5910) acc@5 0.8906 (0.8523)\n",
      "\u001b[32m[2020-06-20 21:23:22] __main__ INFO: \u001b[0mEpoch 31 Step 200/351 lr 0.100000 loss 1.2158 (1.1049) acc@1 0.5391 (0.5908) acc@5 0.8047 (0.8530)\n",
      "\u001b[32m[2020-06-20 21:25:14] __main__ INFO: \u001b[0mEpoch 31 Step 300/351 lr 0.100000 loss 1.1916 (1.1109) acc@1 0.5859 (0.5896) acc@5 0.8359 (0.8522)\n",
      "\u001b[32m[2020-06-20 21:26:12] __main__ INFO: \u001b[0mEpoch 31 Step 351/351 lr 0.100000 loss 1.0960 (1.1140) acc@1 0.5703 (0.5888) acc@5 0.8750 (0.8525)\n",
      "\u001b[32m[2020-06-20 21:26:12] __main__ INFO: \u001b[0mElapsed 395.31\n",
      "\u001b[32m[2020-06-20 21:26:12] __main__ INFO: \u001b[0mVal 31\n",
      "\u001b[32m[2020-06-20 21:26:25] __main__ INFO: \u001b[0mEpoch 31 loss 1.3541 acc@1 0.5032 acc@5 0.8424\n",
      "\u001b[32m[2020-06-20 21:26:25] __main__ INFO: \u001b[0mElapsed 13.20\n",
      "\u001b[32m[2020-06-20 21:26:25] __main__ INFO: \u001b[0mTrain 32 10881\n",
      "\u001b[32m[2020-06-20 21:28:18] __main__ INFO: \u001b[0mEpoch 32 Step 100/351 lr 0.100000 loss 1.1081 (1.0936) acc@1 0.5938 (0.5900) acc@5 0.8438 (0.8522)\n",
      "\u001b[32m[2020-06-20 21:30:10] __main__ INFO: \u001b[0mEpoch 32 Step 200/351 lr 0.100000 loss 1.1845 (1.0968) acc@1 0.5312 (0.5918) acc@5 0.8359 (0.8556)\n",
      "\u001b[32m[2020-06-20 21:32:03] __main__ INFO: \u001b[0mEpoch 32 Step 300/351 lr 0.100000 loss 1.2494 (1.1078) acc@1 0.5234 (0.5890) acc@5 0.8438 (0.8536)\n",
      "\u001b[32m[2020-06-20 21:33:00] __main__ INFO: \u001b[0mEpoch 32 Step 351/351 lr 0.100000 loss 1.1548 (1.1085) acc@1 0.5547 (0.5889) acc@5 0.8359 (0.8529)\n",
      "\u001b[32m[2020-06-20 21:33:00] __main__ INFO: \u001b[0mElapsed 395.26\n",
      "\u001b[32m[2020-06-20 21:33:00] __main__ INFO: \u001b[0mVal 32\n",
      "\u001b[32m[2020-06-20 21:33:14] __main__ INFO: \u001b[0mEpoch 32 loss 1.3414 acc@1 0.5204 acc@5 0.8338\n",
      "\u001b[32m[2020-06-20 21:33:14] __main__ INFO: \u001b[0mElapsed 13.23\n",
      "\u001b[32m[2020-06-20 21:33:14] __main__ INFO: \u001b[0mTrain 33 11232\n",
      "\u001b[32m[2020-06-20 21:35:06] __main__ INFO: \u001b[0mEpoch 33 Step 100/351 lr 0.100000 loss 1.2668 (1.0897) acc@1 0.5078 (0.5979) acc@5 0.8750 (0.8528)\n",
      "\u001b[32m[2020-06-20 21:36:59] __main__ INFO: \u001b[0mEpoch 33 Step 200/351 lr 0.100000 loss 1.2584 (1.1051) acc@1 0.5391 (0.5907) acc@5 0.8203 (0.8507)\n",
      "\u001b[32m[2020-06-20 21:38:51] __main__ INFO: \u001b[0mEpoch 33 Step 300/351 lr 0.100000 loss 1.1955 (1.1063) acc@1 0.5781 (0.5903) acc@5 0.8125 (0.8502)\n",
      "\u001b[32m[2020-06-20 21:39:49] __main__ INFO: \u001b[0mEpoch 33 Step 351/351 lr 0.100000 loss 1.1662 (1.1054) acc@1 0.5703 (0.5899) acc@5 0.8281 (0.8501)\n",
      "\u001b[32m[2020-06-20 21:39:49] __main__ INFO: \u001b[0mElapsed 395.23\n",
      "\u001b[32m[2020-06-20 21:39:49] __main__ INFO: \u001b[0mVal 33\n",
      "\u001b[32m[2020-06-20 21:40:02] __main__ INFO: \u001b[0mEpoch 33 loss 1.4846 acc@1 0.4904 acc@5 0.8120\n",
      "\u001b[32m[2020-06-20 21:40:02] __main__ INFO: \u001b[0mElapsed 13.27\n",
      "\u001b[32m[2020-06-20 21:40:02] __main__ INFO: \u001b[0mTrain 34 11583\n",
      "\u001b[32m[2020-06-20 21:41:55] __main__ INFO: \u001b[0mEpoch 34 Step 100/351 lr 0.100000 loss 1.2522 (1.0832) acc@1 0.5469 (0.6003) acc@5 0.8203 (0.8552)\n",
      "\u001b[32m[2020-06-20 21:43:47] __main__ INFO: \u001b[0mEpoch 34 Step 200/351 lr 0.100000 loss 0.9389 (1.1016) acc@1 0.6406 (0.5910) acc@5 0.8594 (0.8521)\n",
      "\u001b[32m[2020-06-20 21:45:40] __main__ INFO: \u001b[0mEpoch 34 Step 300/351 lr 0.100000 loss 0.9655 (1.1024) acc@1 0.6094 (0.5908) acc@5 0.9219 (0.8522)\n",
      "\u001b[32m[2020-06-20 21:46:37] __main__ INFO: \u001b[0mEpoch 34 Step 351/351 lr 0.100000 loss 0.9647 (1.1039) acc@1 0.6250 (0.5904) acc@5 0.8281 (0.8527)\n",
      "\u001b[32m[2020-06-20 21:46:37] __main__ INFO: \u001b[0mElapsed 395.32\n",
      "\u001b[32m[2020-06-20 21:46:37] __main__ INFO: \u001b[0mVal 34\n",
      "\u001b[32m[2020-06-20 21:46:51] __main__ INFO: \u001b[0mEpoch 34 loss 1.2358 acc@1 0.5510 acc@5 0.8504\n",
      "\u001b[32m[2020-06-20 21:46:51] __main__ INFO: \u001b[0mElapsed 13.23\n",
      "\u001b[32m[2020-06-20 21:46:51] __main__ INFO: \u001b[0mTrain 35 11934\n",
      "\u001b[32m[2020-06-20 21:48:43] __main__ INFO: \u001b[0mEpoch 35 Step 100/351 lr 0.100000 loss 1.0745 (1.0790) acc@1 0.6328 (0.6020) acc@5 0.8672 (0.8586)\n",
      "\u001b[32m[2020-06-20 21:50:36] __main__ INFO: \u001b[0mEpoch 35 Step 200/351 lr 0.100000 loss 0.9372 (1.0954) acc@1 0.6641 (0.5961) acc@5 0.8906 (0.8532)\n",
      "\u001b[32m[2020-06-20 21:52:28] __main__ INFO: \u001b[0mEpoch 35 Step 300/351 lr 0.100000 loss 1.0578 (1.0982) acc@1 0.6250 (0.5950) acc@5 0.8750 (0.8530)\n",
      "\u001b[32m[2020-06-20 21:53:26] __main__ INFO: \u001b[0mEpoch 35 Step 351/351 lr 0.100000 loss 1.1298 (1.0992) acc@1 0.5859 (0.5939) acc@5 0.9062 (0.8530)\n",
      "\u001b[32m[2020-06-20 21:53:26] __main__ INFO: \u001b[0mElapsed 395.10\n",
      "\u001b[32m[2020-06-20 21:53:26] __main__ INFO: \u001b[0mVal 35\n",
      "\u001b[32m[2020-06-20 21:53:39] __main__ INFO: \u001b[0mEpoch 35 loss 1.4325 acc@1 0.5014 acc@5 0.8422\n",
      "\u001b[32m[2020-06-20 21:53:39] __main__ INFO: \u001b[0mElapsed 13.25\n",
      "\u001b[32m[2020-06-20 21:53:39] __main__ INFO: \u001b[0mTrain 36 12285\n",
      "\u001b[32m[2020-06-20 21:55:32] __main__ INFO: \u001b[0mEpoch 36 Step 100/351 lr 0.100000 loss 1.1111 (1.0792) acc@1 0.5312 (0.5991) acc@5 0.8438 (0.8591)\n",
      "\u001b[32m[2020-06-20 21:57:24] __main__ INFO: \u001b[0mEpoch 36 Step 200/351 lr 0.100000 loss 1.1166 (1.0850) acc@1 0.5859 (0.5981) acc@5 0.8594 (0.8571)\n",
      "\u001b[32m[2020-06-20 21:59:17] __main__ INFO: \u001b[0mEpoch 36 Step 300/351 lr 0.100000 loss 1.1063 (1.0941) acc@1 0.5938 (0.5941) acc@5 0.8984 (0.8548)\n",
      "\u001b[32m[2020-06-20 22:00:14] __main__ INFO: \u001b[0mEpoch 36 Step 351/351 lr 0.100000 loss 1.1908 (1.0981) acc@1 0.5469 (0.5931) acc@5 0.7734 (0.8536)\n",
      "\u001b[32m[2020-06-20 22:00:14] __main__ INFO: \u001b[0mElapsed 395.35\n",
      "\u001b[32m[2020-06-20 22:00:14] __main__ INFO: \u001b[0mVal 36\n",
      "\u001b[32m[2020-06-20 22:00:28] __main__ INFO: \u001b[0mEpoch 36 loss 1.3095 acc@1 0.5328 acc@5 0.8416\n",
      "\u001b[32m[2020-06-20 22:00:28] __main__ INFO: \u001b[0mElapsed 13.25\n",
      "\u001b[32m[2020-06-20 22:00:28] __main__ INFO: \u001b[0mTrain 37 12636\n",
      "\u001b[32m[2020-06-20 22:02:20] __main__ INFO: \u001b[0mEpoch 37 Step 100/351 lr 0.100000 loss 1.0337 (1.0891) acc@1 0.5781 (0.6003) acc@5 0.8750 (0.8538)\n",
      "\u001b[32m[2020-06-20 22:04:13] __main__ INFO: \u001b[0mEpoch 37 Step 200/351 lr 0.100000 loss 1.2083 (1.0919) acc@1 0.5312 (0.5979) acc@5 0.8047 (0.8529)\n",
      "\u001b[32m[2020-06-20 22:06:05] __main__ INFO: \u001b[0mEpoch 37 Step 300/351 lr 0.100000 loss 1.0880 (1.0936) acc@1 0.6172 (0.5943) acc@5 0.8672 (0.8535)\n",
      "\u001b[32m[2020-06-20 22:07:03] __main__ INFO: \u001b[0mEpoch 37 Step 351/351 lr 0.100000 loss 1.0935 (1.0936) acc@1 0.6406 (0.5944) acc@5 0.8438 (0.8525)\n",
      "\u001b[32m[2020-06-20 22:07:03] __main__ INFO: \u001b[0mElapsed 395.17\n",
      "\u001b[32m[2020-06-20 22:07:03] __main__ INFO: \u001b[0mVal 37\n",
      "\u001b[32m[2020-06-20 22:07:16] __main__ INFO: \u001b[0mEpoch 37 loss 1.2956 acc@1 0.5372 acc@5 0.8476\n",
      "\u001b[32m[2020-06-20 22:07:16] __main__ INFO: \u001b[0mElapsed 13.24\n",
      "\u001b[32m[2020-06-20 22:07:16] __main__ INFO: \u001b[0mTrain 38 12987\n",
      "\u001b[32m[2020-06-20 22:09:09] __main__ INFO: \u001b[0mEpoch 38 Step 100/351 lr 0.100000 loss 1.1562 (1.0737) acc@1 0.5859 (0.6000) acc@5 0.8672 (0.8574)\n",
      "\u001b[32m[2020-06-20 22:11:01] __main__ INFO: \u001b[0mEpoch 38 Step 200/351 lr 0.100000 loss 1.0776 (1.0812) acc@1 0.6094 (0.5990) acc@5 0.8984 (0.8575)\n",
      "\u001b[32m[2020-06-20 22:12:54] __main__ INFO: \u001b[0mEpoch 38 Step 300/351 lr 0.100000 loss 1.0497 (1.0893) acc@1 0.6094 (0.5958) acc@5 0.8438 (0.8555)\n",
      "\u001b[32m[2020-06-20 22:13:51] __main__ INFO: \u001b[0mEpoch 38 Step 351/351 lr 0.100000 loss 1.2194 (1.0917) acc@1 0.5547 (0.5949) acc@5 0.7969 (0.8540)\n",
      "\u001b[32m[2020-06-20 22:13:51] __main__ INFO: \u001b[0mElapsed 395.25\n",
      "\u001b[32m[2020-06-20 22:13:51] __main__ INFO: \u001b[0mVal 38\n",
      "\u001b[32m[2020-06-20 22:14:05] __main__ INFO: \u001b[0mEpoch 38 loss 1.2240 acc@1 0.5606 acc@5 0.8506\n",
      "\u001b[32m[2020-06-20 22:14:05] __main__ INFO: \u001b[0mElapsed 13.23\n",
      "\u001b[32m[2020-06-20 22:14:05] __main__ INFO: \u001b[0mTrain 39 13338\n",
      "\u001b[32m[2020-06-20 22:15:57] __main__ INFO: \u001b[0mEpoch 39 Step 100/351 lr 0.100000 loss 1.1392 (1.0641) acc@1 0.5781 (0.6062) acc@5 0.9062 (0.8554)\n",
      "\u001b[32m[2020-06-20 22:17:50] __main__ INFO: \u001b[0mEpoch 39 Step 200/351 lr 0.100000 loss 1.1231 (1.0842) acc@1 0.5312 (0.5994) acc@5 0.8359 (0.8511)\n",
      "\u001b[32m[2020-06-20 22:19:42] __main__ INFO: \u001b[0mEpoch 39 Step 300/351 lr 0.100000 loss 1.1253 (1.0875) acc@1 0.6016 (0.5988) acc@5 0.8906 (0.8521)\n",
      "\u001b[32m[2020-06-20 22:20:40] __main__ INFO: \u001b[0mEpoch 39 Step 351/351 lr 0.100000 loss 1.2286 (1.0926) acc@1 0.5625 (0.5964) acc@5 0.8672 (0.8522)\n",
      "\u001b[32m[2020-06-20 22:20:40] __main__ INFO: \u001b[0mElapsed 395.34\n",
      "\u001b[32m[2020-06-20 22:20:40] __main__ INFO: \u001b[0mVal 39\n",
      "\u001b[32m[2020-06-20 22:20:53] __main__ INFO: \u001b[0mEpoch 39 loss 1.3764 acc@1 0.5206 acc@5 0.8426\n",
      "\u001b[32m[2020-06-20 22:20:53] __main__ INFO: \u001b[0mElapsed 13.24\n",
      "\u001b[32m[2020-06-20 22:20:53] __main__ INFO: \u001b[0mTrain 40 13689\n",
      "\u001b[32m[2020-06-20 22:22:46] __main__ INFO: \u001b[0mEpoch 40 Step 100/351 lr 0.100000 loss 1.0324 (1.0647) acc@1 0.6094 (0.6054) acc@5 0.8672 (0.8631)\n",
      "\u001b[32m[2020-06-20 22:24:38] __main__ INFO: \u001b[0mEpoch 40 Step 200/351 lr 0.100000 loss 1.0722 (1.0778) acc@1 0.6094 (0.5996) acc@5 0.8281 (0.8571)\n",
      "\u001b[32m[2020-06-20 22:26:31] __main__ INFO: \u001b[0mEpoch 40 Step 300/351 lr 0.100000 loss 1.0256 (1.0916) acc@1 0.6328 (0.5946) acc@5 0.8281 (0.8541)\n",
      "\u001b[32m[2020-06-20 22:27:28] __main__ INFO: \u001b[0mEpoch 40 Step 351/351 lr 0.100000 loss 0.9585 (1.0910) acc@1 0.6641 (0.5953) acc@5 0.8906 (0.8540)\n",
      "\u001b[32m[2020-06-20 22:27:28] __main__ INFO: \u001b[0mElapsed 395.30\n",
      "\u001b[32m[2020-06-20 22:27:28] __main__ INFO: \u001b[0mVal 40\n",
      "\u001b[32m[2020-06-20 22:27:42] __main__ INFO: \u001b[0mEpoch 40 loss 1.4031 acc@1 0.5108 acc@5 0.8386\n",
      "\u001b[32m[2020-06-20 22:27:42] __main__ INFO: \u001b[0mElapsed 13.27\n",
      "\u001b[32m[2020-06-20 22:27:42] __main__ INFO: \u001b[0mTrain 41 14040\n",
      "\u001b[32m[2020-06-20 22:29:35] __main__ INFO: \u001b[0mEpoch 41 Step 100/351 lr 0.100000 loss 1.2317 (1.0835) acc@1 0.5781 (0.5955) acc@5 0.8281 (0.8534)\n",
      "\u001b[32m[2020-06-20 22:31:27] __main__ INFO: \u001b[0mEpoch 41 Step 200/351 lr 0.100000 loss 1.1621 (1.0878) acc@1 0.5547 (0.5947) acc@5 0.8203 (0.8535)\n",
      "\u001b[32m[2020-06-20 22:33:20] __main__ INFO: \u001b[0mEpoch 41 Step 300/351 lr 0.100000 loss 0.9615 (1.0839) acc@1 0.6406 (0.5964) acc@5 0.8438 (0.8544)\n",
      "\u001b[32m[2020-06-20 22:34:17] __main__ INFO: \u001b[0mEpoch 41 Step 351/351 lr 0.100000 loss 1.2335 (1.0869) acc@1 0.5547 (0.5954) acc@5 0.7891 (0.8533)\n",
      "\u001b[32m[2020-06-20 22:34:17] __main__ INFO: \u001b[0mElapsed 395.41\n",
      "\u001b[32m[2020-06-20 22:34:17] __main__ INFO: \u001b[0mVal 41\n",
      "\u001b[32m[2020-06-20 22:34:30] __main__ INFO: \u001b[0mEpoch 41 loss 1.3989 acc@1 0.5214 acc@5 0.8372\n",
      "\u001b[32m[2020-06-20 22:34:30] __main__ INFO: \u001b[0mElapsed 13.25\n",
      "\u001b[32m[2020-06-20 22:34:30] __main__ INFO: \u001b[0mTrain 42 14391\n",
      "\u001b[32m[2020-06-20 22:36:23] __main__ INFO: \u001b[0mEpoch 42 Step 100/351 lr 0.100000 loss 1.1474 (1.0502) acc@1 0.5938 (0.6118) acc@5 0.8359 (0.8566)\n",
      "\u001b[32m[2020-06-20 22:38:16] __main__ INFO: \u001b[0mEpoch 42 Step 200/351 lr 0.100000 loss 1.1431 (1.0635) acc@1 0.5703 (0.6056) acc@5 0.8125 (0.8538)\n",
      "\u001b[32m[2020-06-20 22:40:08] __main__ INFO: \u001b[0mEpoch 42 Step 300/351 lr 0.100000 loss 1.0992 (1.0800) acc@1 0.6016 (0.5990) acc@5 0.8438 (0.8519)\n",
      "\u001b[32m[2020-06-20 22:41:06] __main__ INFO: \u001b[0mEpoch 42 Step 351/351 lr 0.100000 loss 1.1471 (1.0852) acc@1 0.5781 (0.5972) acc@5 0.8594 (0.8511)\n",
      "\u001b[32m[2020-06-20 22:41:06] __main__ INFO: \u001b[0mElapsed 395.27\n",
      "\u001b[32m[2020-06-20 22:41:06] __main__ INFO: \u001b[0mVal 42\n",
      "\u001b[32m[2020-06-20 22:41:19] __main__ INFO: \u001b[0mEpoch 42 loss 1.2189 acc@1 0.5556 acc@5 0.8464\n",
      "\u001b[32m[2020-06-20 22:41:19] __main__ INFO: \u001b[0mElapsed 13.23\n",
      "\u001b[32m[2020-06-20 22:41:19] __main__ INFO: \u001b[0mTrain 43 14742\n",
      "\u001b[32m[2020-06-20 22:43:12] __main__ INFO: \u001b[0mEpoch 43 Step 100/351 lr 0.100000 loss 1.0424 (1.0693) acc@1 0.6328 (0.6059) acc@5 0.8438 (0.8564)\n",
      "\u001b[32m[2020-06-20 22:45:04] __main__ INFO: \u001b[0mEpoch 43 Step 200/351 lr 0.100000 loss 0.9509 (1.0809) acc@1 0.6641 (0.6005) acc@5 0.8984 (0.8538)\n",
      "\u001b[32m[2020-06-20 22:46:57] __main__ INFO: \u001b[0mEpoch 43 Step 300/351 lr 0.100000 loss 1.1406 (1.0790) acc@1 0.5859 (0.6008) acc@5 0.8594 (0.8554)\n",
      "\u001b[32m[2020-06-20 22:47:54] __main__ INFO: \u001b[0mEpoch 43 Step 351/351 lr 0.100000 loss 1.0994 (1.0817) acc@1 0.5547 (0.5996) acc@5 0.8906 (0.8553)\n",
      "\u001b[32m[2020-06-20 22:47:54] __main__ INFO: \u001b[0mElapsed 395.18\n",
      "\u001b[32m[2020-06-20 22:47:54] __main__ INFO: \u001b[0mVal 43\n",
      "\u001b[32m[2020-06-20 22:48:07] __main__ INFO: \u001b[0mEpoch 43 loss 1.3560 acc@1 0.5120 acc@5 0.8372\n",
      "\u001b[32m[2020-06-20 22:48:07] __main__ INFO: \u001b[0mElapsed 13.20\n",
      "\u001b[32m[2020-06-20 22:48:07] __main__ INFO: \u001b[0mTrain 44 15093\n",
      "\u001b[32m[2020-06-20 22:50:00] __main__ INFO: \u001b[0mEpoch 44 Step 100/351 lr 0.100000 loss 1.0883 (1.0518) acc@1 0.5859 (0.6089) acc@5 0.8359 (0.8569)\n",
      "\u001b[32m[2020-06-20 22:51:52] __main__ INFO: \u001b[0mEpoch 44 Step 200/351 lr 0.100000 loss 1.0325 (1.0700) acc@1 0.6250 (0.6027) acc@5 0.8750 (0.8534)\n",
      "\u001b[32m[2020-06-20 22:53:45] __main__ INFO: \u001b[0mEpoch 44 Step 300/351 lr 0.100000 loss 1.0083 (1.0778) acc@1 0.6328 (0.6013) acc@5 0.8828 (0.8536)\n",
      "\u001b[32m[2020-06-20 22:54:42] __main__ INFO: \u001b[0mEpoch 44 Step 351/351 lr 0.100000 loss 1.0281 (1.0798) acc@1 0.6172 (0.6004) acc@5 0.9141 (0.8537)\n",
      "\u001b[32m[2020-06-20 22:54:42] __main__ INFO: \u001b[0mElapsed 394.99\n",
      "\u001b[32m[2020-06-20 22:54:42] __main__ INFO: \u001b[0mVal 44\n",
      "\u001b[32m[2020-06-20 22:54:56] __main__ INFO: \u001b[0mEpoch 44 loss 1.2951 acc@1 0.5406 acc@5 0.8476\n",
      "\u001b[32m[2020-06-20 22:54:56] __main__ INFO: \u001b[0mElapsed 13.24\n",
      "\u001b[32m[2020-06-20 22:54:56] __main__ INFO: \u001b[0mTrain 45 15444\n",
      "\u001b[32m[2020-06-20 22:56:48] __main__ INFO: \u001b[0mEpoch 45 Step 100/351 lr 0.100000 loss 1.0177 (1.0574) acc@1 0.6562 (0.6096) acc@5 0.8281 (0.8573)\n",
      "\u001b[32m[2020-06-20 22:58:41] __main__ INFO: \u001b[0mEpoch 45 Step 200/351 lr 0.100000 loss 1.2564 (1.0607) acc@1 0.5781 (0.6079) acc@5 0.8203 (0.8561)\n",
      "\u001b[32m[2020-06-20 23:00:33] __main__ INFO: \u001b[0mEpoch 45 Step 300/351 lr 0.100000 loss 0.9184 (1.0734) acc@1 0.6484 (0.6029) acc@5 0.8750 (0.8554)\n",
      "\u001b[32m[2020-06-20 23:01:30] __main__ INFO: \u001b[0mEpoch 45 Step 351/351 lr 0.100000 loss 1.0201 (1.0784) acc@1 0.6094 (0.6015) acc@5 0.8594 (0.8555)\n",
      "\u001b[32m[2020-06-20 23:01:31] __main__ INFO: \u001b[0mElapsed 395.00\n",
      "\u001b[32m[2020-06-20 23:01:31] __main__ INFO: \u001b[0mVal 45\n",
      "\u001b[32m[2020-06-20 23:01:44] __main__ INFO: \u001b[0mEpoch 45 loss 1.4405 acc@1 0.4958 acc@5 0.8544\n",
      "\u001b[32m[2020-06-20 23:01:44] __main__ INFO: \u001b[0mElapsed 13.21\n",
      "\u001b[32m[2020-06-20 23:01:44] __main__ INFO: \u001b[0mTrain 46 15795\n",
      "\u001b[32m[2020-06-20 23:03:36] __main__ INFO: \u001b[0mEpoch 46 Step 100/351 lr 0.100000 loss 1.0211 (1.0632) acc@1 0.6250 (0.6077) acc@5 0.8516 (0.8554)\n",
      "\u001b[32m[2020-06-20 23:05:29] __main__ INFO: \u001b[0mEpoch 46 Step 200/351 lr 0.100000 loss 1.0392 (1.0760) acc@1 0.6016 (0.6024) acc@5 0.8359 (0.8528)\n",
      "\u001b[32m[2020-06-20 23:07:21] __main__ INFO: \u001b[0mEpoch 46 Step 300/351 lr 0.100000 loss 1.0920 (1.0774) acc@1 0.6094 (0.6014) acc@5 0.8594 (0.8540)\n",
      "\u001b[32m[2020-06-20 23:08:19] __main__ INFO: \u001b[0mEpoch 46 Step 351/351 lr 0.100000 loss 1.3690 (1.0768) acc@1 0.5156 (0.6019) acc@5 0.8594 (0.8551)\n",
      "\u001b[32m[2020-06-20 23:08:19] __main__ INFO: \u001b[0mElapsed 395.08\n",
      "\u001b[32m[2020-06-20 23:08:19] __main__ INFO: \u001b[0mVal 46\n",
      "\u001b[32m[2020-06-20 23:08:32] __main__ INFO: \u001b[0mEpoch 46 loss 1.3498 acc@1 0.5310 acc@5 0.8418\n",
      "\u001b[32m[2020-06-20 23:08:32] __main__ INFO: \u001b[0mElapsed 13.25\n",
      "\u001b[32m[2020-06-20 23:08:32] __main__ INFO: \u001b[0mTrain 47 16146\n",
      "\u001b[32m[2020-06-20 23:10:25] __main__ INFO: \u001b[0mEpoch 47 Step 100/351 lr 0.100000 loss 0.9174 (1.0580) acc@1 0.6562 (0.6060) acc@5 0.9141 (0.8514)\n",
      "\u001b[32m[2020-06-20 23:12:17] __main__ INFO: \u001b[0mEpoch 47 Step 200/351 lr 0.100000 loss 1.1594 (1.0617) acc@1 0.6016 (0.6062) acc@5 0.8828 (0.8538)\n",
      "\u001b[32m[2020-06-20 23:14:10] __main__ INFO: \u001b[0mEpoch 47 Step 300/351 lr 0.100000 loss 1.0377 (1.0688) acc@1 0.6250 (0.6035) acc@5 0.8594 (0.8540)\n",
      "\u001b[32m[2020-06-20 23:15:07] __main__ INFO: \u001b[0mEpoch 47 Step 351/351 lr 0.100000 loss 1.0334 (1.0728) acc@1 0.6250 (0.6023) acc@5 0.8281 (0.8544)\n",
      "\u001b[32m[2020-06-20 23:15:07] __main__ INFO: \u001b[0mElapsed 394.94\n",
      "\u001b[32m[2020-06-20 23:15:07] __main__ INFO: \u001b[0mVal 47\n",
      "\u001b[32m[2020-06-20 23:15:20] __main__ INFO: \u001b[0mEpoch 47 loss 1.2620 acc@1 0.5390 acc@5 0.8484\n",
      "\u001b[32m[2020-06-20 23:15:20] __main__ INFO: \u001b[0mElapsed 13.21\n",
      "\u001b[32m[2020-06-20 23:15:20] __main__ INFO: \u001b[0mTrain 48 16497\n",
      "\u001b[32m[2020-06-20 23:17:13] __main__ INFO: \u001b[0mEpoch 48 Step 100/351 lr 0.100000 loss 1.0388 (1.0501) acc@1 0.5859 (0.6083) acc@5 0.8281 (0.8577)\n",
      "\u001b[32m[2020-06-20 23:19:05] __main__ INFO: \u001b[0mEpoch 48 Step 200/351 lr 0.100000 loss 1.1410 (1.0673) acc@1 0.5391 (0.6044) acc@5 0.8516 (0.8534)\n",
      "\u001b[32m[2020-06-20 23:20:58] __main__ INFO: \u001b[0mEpoch 48 Step 300/351 lr 0.100000 loss 1.1415 (1.0743) acc@1 0.5938 (0.6033) acc@5 0.8594 (0.8529)\n",
      "\u001b[32m[2020-06-20 23:21:55] __main__ INFO: \u001b[0mEpoch 48 Step 351/351 lr 0.100000 loss 1.1042 (1.0751) acc@1 0.5938 (0.6026) acc@5 0.8750 (0.8533)\n",
      "\u001b[32m[2020-06-20 23:21:55] __main__ INFO: \u001b[0mElapsed 394.97\n",
      "\u001b[32m[2020-06-20 23:21:55] __main__ INFO: \u001b[0mVal 48\n",
      "\u001b[32m[2020-06-20 23:22:08] __main__ INFO: \u001b[0mEpoch 48 loss 1.2797 acc@1 0.5398 acc@5 0.8432\n",
      "\u001b[32m[2020-06-20 23:22:08] __main__ INFO: \u001b[0mElapsed 13.24\n",
      "\u001b[32m[2020-06-20 23:22:08] __main__ INFO: \u001b[0mTrain 49 16848\n",
      "\u001b[32m[2020-06-20 23:24:01] __main__ INFO: \u001b[0mEpoch 49 Step 100/351 lr 0.100000 loss 0.9048 (1.0712) acc@1 0.7031 (0.6021) acc@5 0.9062 (0.8493)\n",
      "\u001b[32m[2020-06-20 23:25:53] __main__ INFO: \u001b[0mEpoch 49 Step 200/351 lr 0.100000 loss 1.1522 (1.0644) acc@1 0.5469 (0.6037) acc@5 0.8125 (0.8532)\n",
      "\u001b[32m[2020-06-20 23:27:46] __main__ INFO: \u001b[0mEpoch 49 Step 300/351 lr 0.100000 loss 1.3274 (1.0733) acc@1 0.4766 (0.6014) acc@5 0.8594 (0.8547)\n",
      "\u001b[32m[2020-06-20 23:28:43] __main__ INFO: \u001b[0mEpoch 49 Step 351/351 lr 0.100000 loss 1.0527 (1.0735) acc@1 0.6016 (0.6011) acc@5 0.8516 (0.8542)\n",
      "\u001b[32m[2020-06-20 23:28:43] __main__ INFO: \u001b[0mElapsed 394.79\n",
      "\u001b[32m[2020-06-20 23:28:43] __main__ INFO: \u001b[0mVal 49\n",
      "\u001b[32m[2020-06-20 23:28:56] __main__ INFO: \u001b[0mEpoch 49 loss 1.4011 acc@1 0.5246 acc@5 0.8378\n",
      "\u001b[32m[2020-06-20 23:28:56] __main__ INFO: \u001b[0mElapsed 13.23\n",
      "\u001b[32m[2020-06-20 23:28:56] __main__ INFO: \u001b[0mTrain 50 17199\n",
      "\u001b[32m[2020-06-20 23:30:49] __main__ INFO: \u001b[0mEpoch 50 Step 100/351 lr 0.100000 loss 1.1450 (1.0565) acc@1 0.6016 (0.6068) acc@5 0.8281 (0.8592)\n",
      "\u001b[32m[2020-06-20 23:32:42] __main__ INFO: \u001b[0mEpoch 50 Step 200/351 lr 0.100000 loss 1.0860 (1.0731) acc@1 0.5938 (0.6022) acc@5 0.8516 (0.8538)\n",
      "\u001b[32m[2020-06-20 23:34:34] __main__ INFO: \u001b[0mEpoch 50 Step 300/351 lr 0.100000 loss 1.1956 (1.0806) acc@1 0.5781 (0.5986) acc@5 0.8516 (0.8515)\n",
      "\u001b[32m[2020-06-20 23:35:31] __main__ INFO: \u001b[0mEpoch 50 Step 351/351 lr 0.100000 loss 0.9858 (1.0751) acc@1 0.6250 (0.6012) acc@5 0.8906 (0.8533)\n",
      "\u001b[32m[2020-06-20 23:35:31] __main__ INFO: \u001b[0mElapsed 394.93\n",
      "\u001b[32m[2020-06-20 23:35:31] __main__ INFO: \u001b[0mVal 50\n",
      "\u001b[32m[2020-06-20 23:35:45] __main__ INFO: \u001b[0mEpoch 50 loss 1.4811 acc@1 0.4914 acc@5 0.8418\n",
      "\u001b[32m[2020-06-20 23:35:45] __main__ INFO: \u001b[0mElapsed 13.22\n",
      "\u001b[32m[2020-06-20 23:35:45] __main__ INFO: \u001b[0mTrain 51 17550\n",
      "\u001b[32m[2020-06-20 23:37:37] __main__ INFO: \u001b[0mEpoch 51 Step 100/351 lr 0.100000 loss 1.0283 (1.0460) acc@1 0.6641 (0.6121) acc@5 0.8750 (0.8536)\n",
      "\u001b[32m[2020-06-20 23:39:30] __main__ INFO: \u001b[0mEpoch 51 Step 200/351 lr 0.100000 loss 1.2288 (1.0558) acc@1 0.5234 (0.6111) acc@5 0.7812 (0.8558)\n",
      "\u001b[32m[2020-06-20 23:41:22] __main__ INFO: \u001b[0mEpoch 51 Step 300/351 lr 0.100000 loss 1.1537 (1.0650) acc@1 0.5703 (0.6072) acc@5 0.7812 (0.8551)\n",
      "\u001b[32m[2020-06-20 23:42:19] __main__ INFO: \u001b[0mEpoch 51 Step 351/351 lr 0.100000 loss 1.1534 (1.0715) acc@1 0.5234 (0.6036) acc@5 0.8516 (0.8539)\n",
      "\u001b[32m[2020-06-20 23:42:19] __main__ INFO: \u001b[0mElapsed 394.85\n",
      "\u001b[32m[2020-06-20 23:42:19] __main__ INFO: \u001b[0mVal 51\n",
      "\u001b[32m[2020-06-20 23:42:33] __main__ INFO: \u001b[0mEpoch 51 loss 1.3189 acc@1 0.5332 acc@5 0.8382\n",
      "\u001b[32m[2020-06-20 23:42:33] __main__ INFO: \u001b[0mElapsed 13.23\n",
      "\u001b[32m[2020-06-20 23:42:33] __main__ INFO: \u001b[0mTrain 52 17901\n",
      "\u001b[32m[2020-06-20 23:44:25] __main__ INFO: \u001b[0mEpoch 52 Step 100/351 lr 0.100000 loss 1.1187 (1.0390) acc@1 0.5781 (0.6113) acc@5 0.8516 (0.8605)\n",
      "\u001b[32m[2020-06-20 23:46:18] __main__ INFO: \u001b[0mEpoch 52 Step 200/351 lr 0.100000 loss 1.1256 (1.0499) acc@1 0.5625 (0.6086) acc@5 0.8672 (0.8585)\n",
      "\u001b[32m[2020-06-20 23:48:10] __main__ INFO: \u001b[0mEpoch 52 Step 300/351 lr 0.100000 loss 0.9521 (1.0621) acc@1 0.6484 (0.6052) acc@5 0.8672 (0.8564)\n",
      "\u001b[32m[2020-06-20 23:49:08] __main__ INFO: \u001b[0mEpoch 52 Step 351/351 lr 0.100000 loss 1.3349 (1.0664) acc@1 0.4844 (0.6036) acc@5 0.7969 (0.8553)\n",
      "\u001b[32m[2020-06-20 23:49:08] __main__ INFO: \u001b[0mElapsed 394.91\n",
      "\u001b[32m[2020-06-20 23:49:08] __main__ INFO: \u001b[0mVal 52\n",
      "\u001b[32m[2020-06-20 23:49:21] __main__ INFO: \u001b[0mEpoch 52 loss 1.4157 acc@1 0.5154 acc@5 0.8344\n",
      "\u001b[32m[2020-06-20 23:49:21] __main__ INFO: \u001b[0mElapsed 13.24\n",
      "\u001b[32m[2020-06-20 23:49:21] __main__ INFO: \u001b[0mTrain 53 18252\n",
      "\u001b[32m[2020-06-20 23:51:13] __main__ INFO: \u001b[0mEpoch 53 Step 100/351 lr 0.100000 loss 0.9917 (1.0515) acc@1 0.6406 (0.6079) acc@5 0.8594 (0.8600)\n",
      "\u001b[32m[2020-06-20 23:53:06] __main__ INFO: \u001b[0mEpoch 53 Step 200/351 lr 0.100000 loss 1.1919 (1.0580) acc@1 0.5781 (0.6073) acc@5 0.8516 (0.8573)\n",
      "\u001b[32m[2020-06-20 23:54:58] __main__ INFO: \u001b[0mEpoch 53 Step 300/351 lr 0.100000 loss 1.2294 (1.0665) acc@1 0.5312 (0.6043) acc@5 0.8281 (0.8565)\n",
      "\u001b[32m[2020-06-20 23:55:56] __main__ INFO: \u001b[0mEpoch 53 Step 351/351 lr 0.100000 loss 1.2340 (1.0679) acc@1 0.5547 (0.6033) acc@5 0.8047 (0.8559)\n",
      "\u001b[32m[2020-06-20 23:55:56] __main__ INFO: \u001b[0mElapsed 394.90\n",
      "\u001b[32m[2020-06-20 23:55:56] __main__ INFO: \u001b[0mVal 53\n",
      "\u001b[32m[2020-06-20 23:56:09] __main__ INFO: \u001b[0mEpoch 53 loss 1.3242 acc@1 0.5288 acc@5 0.8450\n",
      "\u001b[32m[2020-06-20 23:56:09] __main__ INFO: \u001b[0mElapsed 13.24\n",
      "\u001b[32m[2020-06-20 23:56:09] __main__ INFO: \u001b[0mTrain 54 18603\n",
      "\u001b[32m[2020-06-20 23:58:02] __main__ INFO: \u001b[0mEpoch 54 Step 100/351 lr 0.100000 loss 1.3026 (1.0610) acc@1 0.5391 (0.6008) acc@5 0.8203 (0.8539)\n",
      "\u001b[32m[2020-06-20 23:59:54] __main__ INFO: \u001b[0mEpoch 54 Step 200/351 lr 0.100000 loss 0.9792 (1.0646) acc@1 0.6797 (0.6041) acc@5 0.8516 (0.8530)\n",
      "\u001b[32m[2020-06-21 00:01:46] __main__ INFO: \u001b[0mEpoch 54 Step 300/351 lr 0.100000 loss 1.1193 (1.0661) acc@1 0.5859 (0.6029) acc@5 0.8125 (0.8552)\n",
      "\u001b[32m[2020-06-21 00:02:44] __main__ INFO: \u001b[0mEpoch 54 Step 351/351 lr 0.100000 loss 1.0275 (1.0716) acc@1 0.6250 (0.6015) acc@5 0.8828 (0.8552)\n",
      "\u001b[32m[2020-06-21 00:02:44] __main__ INFO: \u001b[0mElapsed 394.84\n",
      "\u001b[32m[2020-06-21 00:02:44] __main__ INFO: \u001b[0mVal 54\n",
      "\u001b[32m[2020-06-21 00:02:57] __main__ INFO: \u001b[0mEpoch 54 loss 1.2450 acc@1 0.5442 acc@5 0.8498\n",
      "\u001b[32m[2020-06-21 00:02:57] __main__ INFO: \u001b[0mElapsed 13.23\n",
      "\u001b[32m[2020-06-21 00:02:57] __main__ INFO: \u001b[0mTrain 55 18954\n",
      "\u001b[32m[2020-06-21 00:04:50] __main__ INFO: \u001b[0mEpoch 55 Step 100/351 lr 0.100000 loss 1.0957 (1.0562) acc@1 0.5859 (0.6060) acc@5 0.8750 (0.8503)\n",
      "\u001b[32m[2020-06-21 00:06:42] __main__ INFO: \u001b[0mEpoch 55 Step 200/351 lr 0.100000 loss 1.1509 (1.0584) acc@1 0.5625 (0.6063) acc@5 0.8203 (0.8523)\n",
      "\u001b[32m[2020-06-21 00:08:35] __main__ INFO: \u001b[0mEpoch 55 Step 300/351 lr 0.100000 loss 1.0094 (1.0608) acc@1 0.6094 (0.6065) acc@5 0.8672 (0.8535)\n",
      "\u001b[32m[2020-06-21 00:09:32] __main__ INFO: \u001b[0mEpoch 55 Step 351/351 lr 0.100000 loss 1.0941 (1.0639) acc@1 0.5859 (0.6047) acc@5 0.7969 (0.8547)\n",
      "\u001b[32m[2020-06-21 00:09:32] __main__ INFO: \u001b[0mElapsed 394.97\n",
      "\u001b[32m[2020-06-21 00:09:32] __main__ INFO: \u001b[0mVal 55\n",
      "\u001b[32m[2020-06-21 00:09:45] __main__ INFO: \u001b[0mEpoch 55 loss 1.3210 acc@1 0.5278 acc@5 0.8354\n",
      "\u001b[32m[2020-06-21 00:09:45] __main__ INFO: \u001b[0mElapsed 13.24\n",
      "\u001b[32m[2020-06-21 00:09:45] __main__ INFO: \u001b[0mTrain 56 19305\n",
      "\u001b[32m[2020-06-21 00:11:38] __main__ INFO: \u001b[0mEpoch 56 Step 100/351 lr 0.100000 loss 1.0756 (1.0546) acc@1 0.5938 (0.6106) acc@5 0.8438 (0.8541)\n",
      "\u001b[32m[2020-06-21 00:13:30] __main__ INFO: \u001b[0mEpoch 56 Step 200/351 lr 0.100000 loss 0.9721 (1.0617) acc@1 0.6562 (0.6052) acc@5 0.9375 (0.8519)\n",
      "\u001b[32m[2020-06-21 00:15:23] __main__ INFO: \u001b[0mEpoch 56 Step 300/351 lr 0.100000 loss 1.1018 (1.0638) acc@1 0.6172 (0.6049) acc@5 0.8984 (0.8520)\n",
      "\u001b[32m[2020-06-21 00:16:20] __main__ INFO: \u001b[0mEpoch 56 Step 351/351 lr 0.100000 loss 0.8760 (1.0646) acc@1 0.6797 (0.6048) acc@5 0.8984 (0.8522)\n",
      "\u001b[32m[2020-06-21 00:16:20] __main__ INFO: \u001b[0mElapsed 394.92\n",
      "\u001b[32m[2020-06-21 00:16:20] __main__ INFO: \u001b[0mVal 56\n",
      "\u001b[32m[2020-06-21 00:16:33] __main__ INFO: \u001b[0mEpoch 56 loss 1.2257 acc@1 0.5600 acc@5 0.8480\n",
      "\u001b[32m[2020-06-21 00:16:33] __main__ INFO: \u001b[0mElapsed 13.23\n",
      "\u001b[32m[2020-06-21 00:16:33] __main__ INFO: \u001b[0mTrain 57 19656\n",
      "\u001b[32m[2020-06-21 00:18:26] __main__ INFO: \u001b[0mEpoch 57 Step 100/351 lr 0.100000 loss 1.0046 (1.0561) acc@1 0.5703 (0.6077) acc@5 0.8516 (0.8580)\n",
      "\u001b[32m[2020-06-21 00:20:18] __main__ INFO: \u001b[0mEpoch 57 Step 200/351 lr 0.100000 loss 1.2589 (1.0612) acc@1 0.5156 (0.6068) acc@5 0.8281 (0.8561)\n",
      "\u001b[32m[2020-06-21 00:22:11] __main__ INFO: \u001b[0mEpoch 57 Step 300/351 lr 0.100000 loss 1.1441 (1.0654) acc@1 0.5547 (0.6057) acc@5 0.8438 (0.8548)\n",
      "\u001b[32m[2020-06-21 00:23:08] __main__ INFO: \u001b[0mEpoch 57 Step 351/351 lr 0.100000 loss 1.0794 (1.0700) acc@1 0.6172 (0.6046) acc@5 0.8594 (0.8541)\n",
      "\u001b[32m[2020-06-21 00:23:08] __main__ INFO: \u001b[0mElapsed 394.87\n",
      "\u001b[32m[2020-06-21 00:23:08] __main__ INFO: \u001b[0mVal 57\n",
      "\u001b[32m[2020-06-21 00:23:22] __main__ INFO: \u001b[0mEpoch 57 loss 1.2737 acc@1 0.5528 acc@5 0.8486\n",
      "\u001b[32m[2020-06-21 00:23:22] __main__ INFO: \u001b[0mElapsed 13.26\n",
      "\u001b[32m[2020-06-21 00:23:22] __main__ INFO: \u001b[0mTrain 58 20007\n",
      "\u001b[32m[2020-06-21 00:25:14] __main__ INFO: \u001b[0mEpoch 58 Step 100/351 lr 0.100000 loss 1.0732 (1.0306) acc@1 0.5781 (0.6157) acc@5 0.9141 (0.8568)\n",
      "\u001b[32m[2020-06-21 00:27:07] __main__ INFO: \u001b[0mEpoch 58 Step 200/351 lr 0.100000 loss 1.0304 (1.0522) acc@1 0.6328 (0.6106) acc@5 0.8594 (0.8566)\n",
      "\u001b[32m[2020-06-21 00:28:59] __main__ INFO: \u001b[0mEpoch 58 Step 300/351 lr 0.100000 loss 1.1205 (1.0560) acc@1 0.6016 (0.6086) acc@5 0.8281 (0.8566)\n",
      "\u001b[32m[2020-06-21 00:29:56] __main__ INFO: \u001b[0mEpoch 58 Step 351/351 lr 0.100000 loss 1.1068 (1.0601) acc@1 0.5938 (0.6069) acc@5 0.8281 (0.8560)\n",
      "\u001b[32m[2020-06-21 00:29:56] __main__ INFO: \u001b[0mElapsed 394.77\n",
      "\u001b[32m[2020-06-21 00:29:56] __main__ INFO: \u001b[0mVal 58\n",
      "\u001b[32m[2020-06-21 00:30:10] __main__ INFO: \u001b[0mEpoch 58 loss 1.3440 acc@1 0.5342 acc@5 0.8506\n",
      "\u001b[32m[2020-06-21 00:30:10] __main__ INFO: \u001b[0mElapsed 13.24\n",
      "\u001b[32m[2020-06-21 00:30:10] __main__ INFO: \u001b[0mTrain 59 20358\n",
      "\u001b[32m[2020-06-21 00:32:02] __main__ INFO: \u001b[0mEpoch 59 Step 100/351 lr 0.100000 loss 1.0506 (1.0360) acc@1 0.6406 (0.6130) acc@5 0.8828 (0.8540)\n",
      "\u001b[32m[2020-06-21 00:33:54] __main__ INFO: \u001b[0mEpoch 59 Step 200/351 lr 0.100000 loss 0.9773 (1.0524) acc@1 0.6172 (0.6086) acc@5 0.8750 (0.8544)\n",
      "\u001b[32m[2020-06-21 00:35:47] __main__ INFO: \u001b[0mEpoch 59 Step 300/351 lr 0.100000 loss 1.0380 (1.0642) acc@1 0.6016 (0.6036) acc@5 0.8594 (0.8531)\n",
      "\u001b[32m[2020-06-21 00:36:44] __main__ INFO: \u001b[0mEpoch 59 Step 351/351 lr 0.100000 loss 1.0366 (1.0657) acc@1 0.6172 (0.6038) acc@5 0.8594 (0.8525)\n",
      "\u001b[32m[2020-06-21 00:36:44] __main__ INFO: \u001b[0mElapsed 394.65\n",
      "\u001b[32m[2020-06-21 00:36:44] __main__ INFO: \u001b[0mVal 59\n",
      "\u001b[32m[2020-06-21 00:36:57] __main__ INFO: \u001b[0mEpoch 59 loss 1.2762 acc@1 0.5544 acc@5 0.8506\n",
      "\u001b[32m[2020-06-21 00:36:57] __main__ INFO: \u001b[0mElapsed 13.23\n",
      "\u001b[32m[2020-06-21 00:36:57] __main__ INFO: \u001b[0mTrain 60 20709\n",
      "\u001b[32m[2020-06-21 00:38:50] __main__ INFO: \u001b[0mEpoch 60 Step 100/351 lr 0.100000 loss 1.0686 (1.0362) acc@1 0.6172 (0.6155) acc@5 0.8359 (0.8581)\n",
      "\u001b[32m[2020-06-21 00:40:42] __main__ INFO: \u001b[0mEpoch 60 Step 200/351 lr 0.100000 loss 1.1015 (1.0465) acc@1 0.5625 (0.6106) acc@5 0.8359 (0.8550)\n",
      "\u001b[32m[2020-06-21 00:42:35] __main__ INFO: \u001b[0mEpoch 60 Step 300/351 lr 0.100000 loss 0.9650 (1.0592) acc@1 0.6406 (0.6059) acc@5 0.8672 (0.8543)\n",
      "\u001b[32m[2020-06-21 00:43:32] __main__ INFO: \u001b[0mEpoch 60 Step 351/351 lr 0.100000 loss 1.0719 (1.0634) acc@1 0.6250 (0.6045) acc@5 0.8906 (0.8539)\n",
      "\u001b[32m[2020-06-21 00:43:32] __main__ INFO: \u001b[0mElapsed 394.62\n",
      "\u001b[32m[2020-06-21 00:43:32] __main__ INFO: \u001b[0mVal 60\n",
      "\u001b[32m[2020-06-21 00:43:45] __main__ INFO: \u001b[0mEpoch 60 loss 1.2921 acc@1 0.5300 acc@5 0.8368\n",
      "\u001b[32m[2020-06-21 00:43:45] __main__ INFO: \u001b[0mElapsed 13.22\n",
      "\u001b[32m[2020-06-21 00:43:45] __main__ INFO: \u001b[0mTrain 61 21060\n",
      "\u001b[32m[2020-06-21 00:45:38] __main__ INFO: \u001b[0mEpoch 61 Step 100/351 lr 0.020000 loss 0.9385 (0.9377) acc@1 0.6328 (0.6541) acc@5 0.8438 (0.8605)\n",
      "\u001b[32m[2020-06-21 00:47:30] __main__ INFO: \u001b[0mEpoch 61 Step 200/351 lr 0.020000 loss 0.8312 (0.9133) acc@1 0.7109 (0.6608) acc@5 0.8359 (0.8595)\n",
      "\u001b[32m[2020-06-21 00:49:23] __main__ INFO: \u001b[0mEpoch 61 Step 300/351 lr 0.020000 loss 0.7774 (0.8964) acc@1 0.7266 (0.6657) acc@5 0.9141 (0.8603)\n",
      "\u001b[32m[2020-06-21 00:50:20] __main__ INFO: \u001b[0mEpoch 61 Step 351/351 lr 0.020000 loss 0.7975 (0.8922) acc@1 0.6719 (0.6663) acc@5 0.9062 (0.8604)\n",
      "\u001b[32m[2020-06-21 00:50:20] __main__ INFO: \u001b[0mElapsed 394.69\n",
      "\u001b[32m[2020-06-21 00:50:20] __main__ INFO: \u001b[0mVal 61\n",
      "\u001b[32m[2020-06-21 00:50:33] __main__ INFO: \u001b[0mEpoch 61 loss 1.0343 acc@1 0.6244 acc@5 0.8616\n",
      "\u001b[32m[2020-06-21 00:50:33] __main__ INFO: \u001b[0mElapsed 13.22\n",
      "\u001b[32m[2020-06-21 00:50:33] __main__ INFO: \u001b[0mTrain 62 21411\n",
      "\u001b[32m[2020-06-21 00:52:26] __main__ INFO: \u001b[0mEpoch 62 Step 100/351 lr 0.020000 loss 0.8973 (0.8242) acc@1 0.6562 (0.6879) acc@5 0.8359 (0.8634)\n",
      "\u001b[32m[2020-06-21 00:54:18] __main__ INFO: \u001b[0mEpoch 62 Step 200/351 lr 0.020000 loss 0.9313 (0.8245) acc@1 0.6406 (0.6898) acc@5 0.8203 (0.8631)\n",
      "\u001b[32m[2020-06-21 00:56:11] __main__ INFO: \u001b[0mEpoch 62 Step 300/351 lr 0.020000 loss 0.9315 (0.8282) acc@1 0.6406 (0.6878) acc@5 0.8203 (0.8631)\n",
      "\u001b[32m[2020-06-21 00:57:08] __main__ INFO: \u001b[0mEpoch 62 Step 351/351 lr 0.020000 loss 0.9525 (0.8315) acc@1 0.6250 (0.6861) acc@5 0.8438 (0.8627)\n",
      "\u001b[32m[2020-06-21 00:57:08] __main__ INFO: \u001b[0mElapsed 394.66\n",
      "\u001b[32m[2020-06-21 00:57:08] __main__ INFO: \u001b[0mVal 62\n",
      "\u001b[32m[2020-06-21 00:57:21] __main__ INFO: \u001b[0mEpoch 62 loss 1.0577 acc@1 0.6234 acc@5 0.8614\n",
      "\u001b[32m[2020-06-21 00:57:21] __main__ INFO: \u001b[0mElapsed 13.24\n",
      "\u001b[32m[2020-06-21 00:57:21] __main__ INFO: \u001b[0mTrain 63 21762\n",
      "\u001b[32m[2020-06-21 00:59:14] __main__ INFO: \u001b[0mEpoch 63 Step 100/351 lr 0.020000 loss 0.7292 (0.7923) acc@1 0.7422 (0.7034) acc@5 0.8828 (0.8694)\n",
      "\u001b[32m[2020-06-21 01:01:06] __main__ INFO: \u001b[0mEpoch 63 Step 200/351 lr 0.020000 loss 0.8802 (0.8033) acc@1 0.6484 (0.6982) acc@5 0.8516 (0.8662)\n",
      "\u001b[32m[2020-06-21 01:02:58] __main__ INFO: \u001b[0mEpoch 63 Step 300/351 lr 0.020000 loss 0.7149 (0.8066) acc@1 0.7344 (0.6965) acc@5 0.8906 (0.8647)\n",
      "\u001b[32m[2020-06-21 01:03:56] __main__ INFO: \u001b[0mEpoch 63 Step 351/351 lr 0.020000 loss 0.9300 (0.8087) acc@1 0.6328 (0.6956) acc@5 0.8125 (0.8643)\n",
      "\u001b[32m[2020-06-21 01:03:56] __main__ INFO: \u001b[0mElapsed 394.66\n",
      "\u001b[32m[2020-06-21 01:03:56] __main__ INFO: \u001b[0mVal 63\n",
      "\u001b[32m[2020-06-21 01:04:09] __main__ INFO: \u001b[0mEpoch 63 loss 1.0621 acc@1 0.6220 acc@5 0.8618\n",
      "\u001b[32m[2020-06-21 01:04:09] __main__ INFO: \u001b[0mElapsed 13.22\n",
      "\u001b[32m[2020-06-21 01:04:09] __main__ INFO: \u001b[0mTrain 64 22113\n",
      "\u001b[32m[2020-06-21 01:06:02] __main__ INFO: \u001b[0mEpoch 64 Step 100/351 lr 0.020000 loss 0.8395 (0.7806) acc@1 0.6562 (0.7084) acc@5 0.8516 (0.8691)\n",
      "\u001b[32m[2020-06-21 01:07:54] __main__ INFO: \u001b[0mEpoch 64 Step 200/351 lr 0.020000 loss 0.7860 (0.7897) acc@1 0.7578 (0.7023) acc@5 0.8984 (0.8655)\n",
      "\u001b[32m[2020-06-21 01:09:46] __main__ INFO: \u001b[0mEpoch 64 Step 300/351 lr 0.020000 loss 0.8111 (0.7910) acc@1 0.7188 (0.7011) acc@5 0.8516 (0.8664)\n",
      "\u001b[32m[2020-06-21 01:10:44] __main__ INFO: \u001b[0mEpoch 64 Step 351/351 lr 0.020000 loss 1.0393 (0.7917) acc@1 0.6094 (0.7005) acc@5 0.8438 (0.8660)\n",
      "\u001b[32m[2020-06-21 01:10:44] __main__ INFO: \u001b[0mElapsed 394.64\n",
      "\u001b[32m[2020-06-21 01:10:44] __main__ INFO: \u001b[0mVal 64\n",
      "\u001b[32m[2020-06-21 01:10:57] __main__ INFO: \u001b[0mEpoch 64 loss 1.1048 acc@1 0.6180 acc@5 0.8608\n",
      "\u001b[32m[2020-06-21 01:10:57] __main__ INFO: \u001b[0mElapsed 13.25\n",
      "\u001b[32m[2020-06-21 01:10:57] __main__ INFO: \u001b[0mTrain 65 22464\n",
      "\u001b[32m[2020-06-21 01:12:49] __main__ INFO: \u001b[0mEpoch 65 Step 100/351 lr 0.020000 loss 0.8076 (0.7692) acc@1 0.6953 (0.7105) acc@5 0.8750 (0.8706)\n",
      "\u001b[32m[2020-06-21 01:14:42] __main__ INFO: \u001b[0mEpoch 65 Step 200/351 lr 0.020000 loss 0.8915 (0.7724) acc@1 0.6797 (0.7090) acc@5 0.8438 (0.8689)\n",
      "\u001b[32m[2020-06-21 01:16:34] __main__ INFO: \u001b[0mEpoch 65 Step 300/351 lr 0.020000 loss 0.7072 (0.7782) acc@1 0.7266 (0.7065) acc@5 0.8984 (0.8681)\n",
      "\u001b[32m[2020-06-21 01:17:31] __main__ INFO: \u001b[0mEpoch 65 Step 351/351 lr 0.020000 loss 0.8322 (0.7827) acc@1 0.6719 (0.7043) acc@5 0.8125 (0.8665)\n",
      "\u001b[32m[2020-06-21 01:17:31] __main__ INFO: \u001b[0mElapsed 394.41\n",
      "\u001b[32m[2020-06-21 01:17:31] __main__ INFO: \u001b[0mVal 65\n",
      "\u001b[32m[2020-06-21 01:17:45] __main__ INFO: \u001b[0mEpoch 65 loss 1.0775 acc@1 0.6168 acc@5 0.8612\n",
      "\u001b[32m[2020-06-21 01:17:45] __main__ INFO: \u001b[0mElapsed 13.26\n",
      "\u001b[32m[2020-06-21 01:17:45] __main__ INFO: \u001b[0mTrain 66 22815\n",
      "\u001b[32m[2020-06-21 01:19:37] __main__ INFO: \u001b[0mEpoch 66 Step 100/351 lr 0.020000 loss 0.7367 (0.7726) acc@1 0.7109 (0.7070) acc@5 0.8828 (0.8649)\n",
      "\u001b[32m[2020-06-21 01:21:29] __main__ INFO: \u001b[0mEpoch 66 Step 200/351 lr 0.020000 loss 0.7364 (0.7738) acc@1 0.7109 (0.7064) acc@5 0.8359 (0.8647)\n",
      "\u001b[32m[2020-06-21 01:23:22] __main__ INFO: \u001b[0mEpoch 66 Step 300/351 lr 0.020000 loss 0.7606 (0.7772) acc@1 0.7109 (0.7042) acc@5 0.8438 (0.8662)\n",
      "\u001b[32m[2020-06-21 01:24:19] __main__ INFO: \u001b[0mEpoch 66 Step 351/351 lr 0.020000 loss 0.8650 (0.7796) acc@1 0.6562 (0.7033) acc@5 0.8359 (0.8659)\n",
      "\u001b[32m[2020-06-21 01:24:19] __main__ INFO: \u001b[0mElapsed 394.45\n",
      "\u001b[32m[2020-06-21 01:24:19] __main__ INFO: \u001b[0mVal 66\n",
      "\u001b[32m[2020-06-21 01:24:32] __main__ INFO: \u001b[0mEpoch 66 loss 1.0917 acc@1 0.6188 acc@5 0.8546\n",
      "\u001b[32m[2020-06-21 01:24:32] __main__ INFO: \u001b[0mElapsed 13.22\n",
      "\u001b[32m[2020-06-21 01:24:32] __main__ INFO: \u001b[0mTrain 67 23166\n",
      "\u001b[32m[2020-06-21 01:26:25] __main__ INFO: \u001b[0mEpoch 67 Step 100/351 lr 0.020000 loss 0.6782 (0.7583) acc@1 0.7344 (0.7108) acc@5 0.8672 (0.8712)\n",
      "\u001b[32m[2020-06-21 01:28:17] __main__ INFO: \u001b[0mEpoch 67 Step 200/351 lr 0.020000 loss 0.6644 (0.7710) acc@1 0.7734 (0.7080) acc@5 0.8828 (0.8682)\n",
      "\u001b[32m[2020-06-21 01:30:09] __main__ INFO: \u001b[0mEpoch 67 Step 300/351 lr 0.020000 loss 0.8398 (0.7717) acc@1 0.7031 (0.7067) acc@5 0.8750 (0.8674)\n",
      "\u001b[32m[2020-06-21 01:31:07] __main__ INFO: \u001b[0mEpoch 67 Step 351/351 lr 0.020000 loss 0.6719 (0.7701) acc@1 0.7578 (0.7074) acc@5 0.9062 (0.8675)\n",
      "\u001b[32m[2020-06-21 01:31:07] __main__ INFO: \u001b[0mElapsed 394.44\n",
      "\u001b[32m[2020-06-21 01:31:07] __main__ INFO: \u001b[0mVal 67\n",
      "\u001b[32m[2020-06-21 01:31:20] __main__ INFO: \u001b[0mEpoch 67 loss 1.1034 acc@1 0.6256 acc@5 0.8552\n",
      "\u001b[32m[2020-06-21 01:31:20] __main__ INFO: \u001b[0mElapsed 13.23\n",
      "\u001b[32m[2020-06-21 01:31:20] __main__ INFO: \u001b[0mTrain 68 23517\n",
      "\u001b[32m[2020-06-21 01:33:12] __main__ INFO: \u001b[0mEpoch 68 Step 100/351 lr 0.020000 loss 0.8444 (0.7546) acc@1 0.6797 (0.7135) acc@5 0.8516 (0.8695)\n",
      "\u001b[32m[2020-06-21 01:35:05] __main__ INFO: \u001b[0mEpoch 68 Step 200/351 lr 0.020000 loss 0.8813 (0.7608) acc@1 0.6406 (0.7100) acc@5 0.8438 (0.8680)\n",
      "\u001b[32m[2020-06-21 01:36:57] __main__ INFO: \u001b[0mEpoch 68 Step 300/351 lr 0.020000 loss 0.7257 (0.7725) acc@1 0.7266 (0.7066) acc@5 0.8672 (0.8659)\n",
      "\u001b[32m[2020-06-21 01:37:54] __main__ INFO: \u001b[0mEpoch 68 Step 351/351 lr 0.020000 loss 0.7684 (0.7719) acc@1 0.7188 (0.7068) acc@5 0.8516 (0.8663)\n",
      "\u001b[32m[2020-06-21 01:37:54] __main__ INFO: \u001b[0mElapsed 394.49\n",
      "\u001b[32m[2020-06-21 01:37:54] __main__ INFO: \u001b[0mVal 68\n",
      "\u001b[32m[2020-06-21 01:38:08] __main__ INFO: \u001b[0mEpoch 68 loss 1.1215 acc@1 0.6124 acc@5 0.8586\n",
      "\u001b[32m[2020-06-21 01:38:08] __main__ INFO: \u001b[0mElapsed 13.25\n",
      "\u001b[32m[2020-06-21 01:38:08] __main__ INFO: \u001b[0mTrain 69 23868\n",
      "\u001b[32m[2020-06-21 01:40:00] __main__ INFO: \u001b[0mEpoch 69 Step 100/351 lr 0.020000 loss 0.6615 (0.7432) acc@1 0.7422 (0.7180) acc@5 0.8672 (0.8709)\n",
      "\u001b[32m[2020-06-21 01:41:52] __main__ INFO: \u001b[0mEpoch 69 Step 200/351 lr 0.020000 loss 0.7571 (0.7599) acc@1 0.7031 (0.7108) acc@5 0.8594 (0.8669)\n",
      "\u001b[32m[2020-06-21 01:43:45] __main__ INFO: \u001b[0mEpoch 69 Step 300/351 lr 0.020000 loss 0.7356 (0.7625) acc@1 0.7344 (0.7092) acc@5 0.8750 (0.8684)\n",
      "\u001b[32m[2020-06-21 01:44:42] __main__ INFO: \u001b[0mEpoch 69 Step 351/351 lr 0.020000 loss 0.9508 (0.7676) acc@1 0.6250 (0.7065) acc@5 0.8203 (0.8671)\n",
      "\u001b[32m[2020-06-21 01:44:42] __main__ INFO: \u001b[0mElapsed 394.37\n",
      "\u001b[32m[2020-06-21 01:44:42] __main__ INFO: \u001b[0mVal 69\n",
      "\u001b[32m[2020-06-21 01:44:55] __main__ INFO: \u001b[0mEpoch 69 loss 1.2126 acc@1 0.6000 acc@5 0.8618\n",
      "\u001b[32m[2020-06-21 01:44:55] __main__ INFO: \u001b[0mElapsed 13.24\n",
      "\u001b[32m[2020-06-21 01:44:55] __main__ INFO: \u001b[0mTrain 70 24219\n",
      "\u001b[32m[2020-06-21 01:46:48] __main__ INFO: \u001b[0mEpoch 70 Step 100/351 lr 0.020000 loss 0.7976 (0.7601) acc@1 0.7188 (0.7102) acc@5 0.8516 (0.8689)\n",
      "\u001b[32m[2020-06-21 01:48:40] __main__ INFO: \u001b[0mEpoch 70 Step 200/351 lr 0.020000 loss 0.8113 (0.7722) acc@1 0.6641 (0.7061) acc@5 0.8047 (0.8665)\n",
      "\u001b[32m[2020-06-21 01:50:33] __main__ INFO: \u001b[0mEpoch 70 Step 300/351 lr 0.020000 loss 0.9762 (0.7716) acc@1 0.6484 (0.7060) acc@5 0.8594 (0.8673)\n",
      "\u001b[32m[2020-06-21 01:51:30] __main__ INFO: \u001b[0mEpoch 70 Step 351/351 lr 0.020000 loss 0.8278 (0.7743) acc@1 0.6875 (0.7053) acc@5 0.8594 (0.8664)\n",
      "\u001b[32m[2020-06-21 01:51:30] __main__ INFO: \u001b[0mElapsed 394.63\n",
      "\u001b[32m[2020-06-21 01:51:30] __main__ INFO: \u001b[0mVal 70\n",
      "\u001b[32m[2020-06-21 01:51:43] __main__ INFO: \u001b[0mEpoch 70 loss 1.1837 acc@1 0.6046 acc@5 0.8606\n",
      "\u001b[32m[2020-06-21 01:51:43] __main__ INFO: \u001b[0mElapsed 13.23\n",
      "\u001b[32m[2020-06-21 01:51:43] __main__ INFO: \u001b[0mTrain 71 24570\n",
      "\u001b[32m[2020-06-21 01:53:36] __main__ INFO: \u001b[0mEpoch 71 Step 100/351 lr 0.020000 loss 0.7450 (0.7412) acc@1 0.7344 (0.7170) acc@5 0.8750 (0.8673)\n",
      "\u001b[32m[2020-06-21 01:55:28] __main__ INFO: \u001b[0mEpoch 71 Step 200/351 lr 0.020000 loss 0.8455 (0.7589) acc@1 0.6797 (0.7117) acc@5 0.8359 (0.8661)\n",
      "\u001b[32m[2020-06-21 01:57:20] __main__ INFO: \u001b[0mEpoch 71 Step 300/351 lr 0.020000 loss 0.6556 (0.7632) acc@1 0.7266 (0.7095) acc@5 0.8828 (0.8663)\n",
      "\u001b[32m[2020-06-21 01:58:18] __main__ INFO: \u001b[0mEpoch 71 Step 351/351 lr 0.020000 loss 0.9429 (0.7658) acc@1 0.6484 (0.7083) acc@5 0.8672 (0.8664)\n",
      "\u001b[32m[2020-06-21 01:58:18] __main__ INFO: \u001b[0mElapsed 394.39\n",
      "\u001b[32m[2020-06-21 01:58:18] __main__ INFO: \u001b[0mVal 71\n",
      "\u001b[32m[2020-06-21 01:58:31] __main__ INFO: \u001b[0mEpoch 71 loss 1.1386 acc@1 0.6054 acc@5 0.8574\n",
      "\u001b[32m[2020-06-21 01:58:31] __main__ INFO: \u001b[0mElapsed 13.20\n",
      "\u001b[32m[2020-06-21 01:58:31] __main__ INFO: \u001b[0mTrain 72 24921\n",
      "\u001b[32m[2020-06-21 02:00:23] __main__ INFO: \u001b[0mEpoch 72 Step 100/351 lr 0.020000 loss 0.6699 (0.7451) acc@1 0.7266 (0.7141) acc@5 0.8750 (0.8675)\n",
      "\u001b[32m[2020-06-21 02:02:16] __main__ INFO: \u001b[0mEpoch 72 Step 200/351 lr 0.020000 loss 0.8364 (0.7510) acc@1 0.6562 (0.7137) acc@5 0.8438 (0.8678)\n",
      "\u001b[32m[2020-06-21 02:04:08] __main__ INFO: \u001b[0mEpoch 72 Step 300/351 lr 0.020000 loss 0.8676 (0.7563) acc@1 0.6406 (0.7120) acc@5 0.8203 (0.8686)\n",
      "\u001b[32m[2020-06-21 02:05:05] __main__ INFO: \u001b[0mEpoch 72 Step 351/351 lr 0.020000 loss 0.6563 (0.7616) acc@1 0.7578 (0.7098) acc@5 0.8984 (0.8674)\n",
      "\u001b[32m[2020-06-21 02:05:05] __main__ INFO: \u001b[0mElapsed 394.45\n",
      "\u001b[32m[2020-06-21 02:05:05] __main__ INFO: \u001b[0mVal 72\n",
      "\u001b[32m[2020-06-21 02:05:18] __main__ INFO: \u001b[0mEpoch 72 loss 1.1835 acc@1 0.6040 acc@5 0.8548\n",
      "\u001b[32m[2020-06-21 02:05:18] __main__ INFO: \u001b[0mElapsed 13.21\n",
      "\u001b[32m[2020-06-21 02:05:18] __main__ INFO: \u001b[0mTrain 73 25272\n"
     ]
    }
   ],
   "source": [
    "# Train the model per the settings specified in the original paper\n",
    "os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "!python train.py --config configs/cifar/wrn.yaml \\\n",
    "    model.wrn.depth 28 \\\n",
    "    model.wrn.widening_factor 10 \\\n",
    "    train.batch_size 128 \\\n",
    "    train.base_lr 0.1 \\\n",
    "    dataset.name CIFAR10_RA_2_5 \\\n",
    "    train.output_dir /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_5/exp00 \\\n",
    "    scheduler.epochs 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-06-22 23:40:28] __main__ INFO: \u001b[0mdevice: cuda\n",
      "cudnn:\n",
      "  benchmark: True\n",
      "  deterministic: False\n",
      "dataset:\n",
      "  name: CIFAR10\n",
      "  dataset_dir: ~/.torch/datasets/CIFAR10\n",
      "  image_size: 32\n",
      "  n_channels: 3\n",
      "  n_classes: 10\n",
      "model:\n",
      "  type: cifar\n",
      "  name: wrn\n",
      "  init_mode: kaiming_fan_in\n",
      "  vgg:\n",
      "    n_channels: [64, 128, 256, 512, 512]\n",
      "    n_layers: [2, 2, 3, 3, 3]\n",
      "    use_bn: True\n",
      "  resnet:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "  resnet_preact:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "  wrn:\n",
      "    depth: 28\n",
      "    initial_channels: 16\n",
      "    widening_factor: 10\n",
      "    drop_rate: 0.0\n",
      "  densenet:\n",
      "    depth: 100\n",
      "    n_blocks: [6, 12, 24, 16]\n",
      "    block_type: bottleneck\n",
      "    growth_rate: 12\n",
      "    drop_rate: 0.0\n",
      "    compression_rate: 0.5\n",
      "  pyramidnet:\n",
      "    depth: 272\n",
      "    n_blocks: [3, 24, 36, 3]\n",
      "    initial_channels: 16\n",
      "    block_type: bottleneck\n",
      "    alpha: 200\n",
      "  resnext:\n",
      "    depth: 29\n",
      "    n_blocks: [3, 4, 6, 3]\n",
      "    initial_channels: 64\n",
      "    cardinality: 8\n",
      "    base_channels: 4\n",
      "  shake_shake:\n",
      "    depth: 26\n",
      "    initial_channels: 96\n",
      "    shake_forward: True\n",
      "    shake_backward: True\n",
      "    shake_image: True\n",
      "  se_resnet_preact:\n",
      "    depth: 110\n",
      "    initial_channels: 16\n",
      "    se_reduction: 16\n",
      "    block_type: basic\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "train:\n",
      "  checkpoint: /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_5/exp00/checkpoint_00400.pth\n",
      "  resume: False\n",
      "  precision: O0\n",
      "  batch_size: 128\n",
      "  subdivision: 1\n",
      "  optimizer: sgd\n",
      "  base_lr: 0.0008\n",
      "  momentum: 0.9\n",
      "  nesterov: True\n",
      "  weight_decay: 0.0005\n",
      "  no_weight_decay_on_bn: False\n",
      "  gradient_clip: 0\n",
      "  start_epoch: 0\n",
      "  seed: 0\n",
      "  val_first: True\n",
      "  val_period: 1\n",
      "  val_ratio: 0.1\n",
      "  use_test_as_val: False\n",
      "  output_dir: /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_5/exp00_resume400_50\n",
      "  log_period: 100\n",
      "  checkpoint_period: 100\n",
      "  use_tensorboard: True\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: True\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "  distributed: False\n",
      "  dist:\n",
      "    backend: nccl\n",
      "    init_method: env://\n",
      "    world_size: -1\n",
      "    node_rank: -1\n",
      "    local_rank: 0\n",
      "    use_sync_bn: False\n",
      "tensorboard:\n",
      "  train_images: False\n",
      "  val_images: False\n",
      "  model_params: False\n",
      "optim:\n",
      "  adam:\n",
      "    betas: (0.9, 0.999)\n",
      "  lars:\n",
      "    eps: 1e-09\n",
      "    threshold: 0.01\n",
      "  adabound:\n",
      "    betas: (0.9, 0.999)\n",
      "    final_lr: 0.1\n",
      "    gamma: 0.001\n",
      "scheduler:\n",
      "  epochs: 50\n",
      "  warmup:\n",
      "    type: none\n",
      "    epochs: 0\n",
      "    start_factor: 0.001\n",
      "    exponent: 4\n",
      "  type: multistep\n",
      "  milestones: [60, 120, 160]\n",
      "  lr_decay: 0.2\n",
      "  lr_min_factor: 0.001\n",
      "  T0: 10\n",
      "  T_mul: 1.0\n",
      "validation:\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: False\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "augmentation:\n",
      "  use_random_crop: True\n",
      "  use_random_horizontal_flip: True\n",
      "  use_cutout: False\n",
      "  use_random_erasing: False\n",
      "  use_dual_cutout: False\n",
      "  use_mixup: False\n",
      "  use_ricap: False\n",
      "  use_cutmix: False\n",
      "  use_label_smoothing: False\n",
      "  random_crop:\n",
      "    padding: 4\n",
      "    fill: 0\n",
      "    padding_mode: constant\n",
      "  random_horizontal_flip:\n",
      "    prob: 0.5\n",
      "  cutout:\n",
      "    prob: 1.0\n",
      "    mask_size: 16\n",
      "    cut_inside: False\n",
      "    mask_color: 0\n",
      "    dual_cutout_alpha: 0.1\n",
      "  random_erasing:\n",
      "    prob: 0.5\n",
      "    area_ratio_range: [0.02, 0.4]\n",
      "    min_aspect_ratio: 0.3\n",
      "    max_attempt: 20\n",
      "  mixup:\n",
      "    alpha: 1.0\n",
      "  ricap:\n",
      "    beta: 0.3\n",
      "  cutmix:\n",
      "    alpha: 1.0\n",
      "  label_smoothing:\n",
      "    epsilon: 0.1\n",
      "tta:\n",
      "  use_resize: False\n",
      "  use_center_crop: False\n",
      "  resize: 256\n",
      "test:\n",
      "  checkpoint: ''\n",
      "  output_dir: ''\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    pin_memory: False\n",
      "\u001b[32m[2020-06-22 23:40:28] __main__ INFO: \u001b[0menv_info:\n",
      "  pytorch_version: 1.4.0\n",
      "  cuda_version: 10.1\n",
      "  cudnn_version: 7603\n",
      "  num_gpus: 1\n",
      "  gpu_name: Tesla K80\n",
      "  gpu_capability: 3.7\n",
      "Files already downloaded and verified\n",
      "\u001b[32m[2020-06-22 23:40:32] __main__ INFO: \u001b[0mMACs  : 5.25G\n",
      "\u001b[32m[2020-06-22 23:40:32] __main__ INFO: \u001b[0m#params: 36.48M\n",
      "Selected optimization level O0:  Pure FP32 training.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n",
      "\u001b[32m[2020-06-22 23:40:32] __main__ INFO: \u001b[0mVal 0\n",
      "\u001b[32m[2020-06-22 23:40:52] __main__ INFO: \u001b[0mEpoch 0 loss 0.4080 acc@1 0.9106 acc@5 0.9952\n",
      "\u001b[32m[2020-06-22 23:40:52] __main__ INFO: \u001b[0mElapsed 19.64\n",
      "\u001b[32m[2020-06-22 23:40:52] __main__ INFO: \u001b[0mTrain 1 0\n",
      "\u001b[32m[2020-06-22 23:42:49] __main__ INFO: \u001b[0mEpoch 1 Step 100/351 lr 0.000800 loss 0.0707 (0.1548) acc@1 0.9844 (0.9580) acc@5 1.0000 (0.9983)\n",
      "\u001b[32m[2020-06-22 23:44:42] __main__ INFO: \u001b[0mEpoch 1 Step 200/351 lr 0.000800 loss 0.1556 (0.1427) acc@1 0.9375 (0.9600) acc@5 1.0000 (0.9985)\n",
      "\u001b[32m[2020-06-22 23:46:34] __main__ INFO: \u001b[0mEpoch 1 Step 300/351 lr 0.000800 loss 0.1018 (0.1392) acc@1 0.9609 (0.9603) acc@5 1.0000 (0.9986)\n",
      "\u001b[32m[2020-06-22 23:47:32] __main__ INFO: \u001b[0mEpoch 1 Step 351/351 lr 0.000800 loss 0.0745 (0.1380) acc@1 0.9844 (0.9601) acc@5 1.0000 (0.9987)\n",
      "\u001b[32m[2020-06-22 23:47:32] __main__ INFO: \u001b[0mElapsed 400.01\n",
      "\u001b[32m[2020-06-22 23:47:32] __main__ INFO: \u001b[0mVal 1\n",
      "\u001b[32m[2020-06-22 23:47:45] __main__ INFO: \u001b[0mEpoch 1 loss 0.2307 acc@1 0.9276 acc@5 0.9976\n",
      "\u001b[32m[2020-06-22 23:47:45] __main__ INFO: \u001b[0mElapsed 13.27\n",
      "\u001b[32m[2020-06-22 23:47:45] __main__ INFO: \u001b[0mTrain 2 351\n",
      "\u001b[32m[2020-06-22 23:49:38] __main__ INFO: \u001b[0mEpoch 2 Step 100/351 lr 0.000800 loss 0.0668 (0.0929) acc@1 0.9766 (0.9714) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-22 23:51:30] __main__ INFO: \u001b[0mEpoch 2 Step 200/351 lr 0.000800 loss 0.0463 (0.0913) acc@1 0.9922 (0.9720) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-22 23:53:23] __main__ INFO: \u001b[0mEpoch 2 Step 300/351 lr 0.000800 loss 0.1212 (0.0912) acc@1 0.9531 (0.9723) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 23:54:20] __main__ INFO: \u001b[0mEpoch 2 Step 351/351 lr 0.000800 loss 0.1477 (0.0921) acc@1 0.9609 (0.9720) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-22 23:54:20] __main__ INFO: \u001b[0mElapsed 395.00\n",
      "\u001b[32m[2020-06-22 23:54:20] __main__ INFO: \u001b[0mVal 2\n",
      "\u001b[32m[2020-06-22 23:54:33] __main__ INFO: \u001b[0mEpoch 2 loss 0.2349 acc@1 0.9314 acc@5 0.9972\n",
      "\u001b[32m[2020-06-22 23:54:33] __main__ INFO: \u001b[0mElapsed 13.29\n",
      "\u001b[32m[2020-06-22 23:54:33] __main__ INFO: \u001b[0mTrain 3 702\n",
      "\u001b[32m[2020-06-22 23:56:26] __main__ INFO: \u001b[0mEpoch 3 Step 100/351 lr 0.000800 loss 0.0497 (0.0655) acc@1 0.9844 (0.9827) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-22 23:58:19] __main__ INFO: \u001b[0mEpoch 3 Step 200/351 lr 0.000800 loss 0.0441 (0.0694) acc@1 0.9844 (0.9804) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-23 00:00:11] __main__ INFO: \u001b[0mEpoch 3 Step 300/351 lr 0.000800 loss 0.1163 (0.0692) acc@1 0.9531 (0.9801) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-23 00:01:08] __main__ INFO: \u001b[0mEpoch 3 Step 351/351 lr 0.000800 loss 0.0802 (0.0698) acc@1 0.9688 (0.9796) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-23 00:01:08] __main__ INFO: \u001b[0mElapsed 394.97\n",
      "\u001b[32m[2020-06-23 00:01:08] __main__ INFO: \u001b[0mVal 3\n",
      "\u001b[32m[2020-06-23 00:01:22] __main__ INFO: \u001b[0mEpoch 3 loss 0.2338 acc@1 0.9308 acc@5 0.9976\n",
      "\u001b[32m[2020-06-23 00:01:22] __main__ INFO: \u001b[0mElapsed 13.26\n",
      "\u001b[32m[2020-06-23 00:01:22] __main__ INFO: \u001b[0mTrain 4 1053\n",
      "\u001b[32m[2020-06-23 00:03:14] __main__ INFO: \u001b[0mEpoch 4 Step 100/351 lr 0.000800 loss 0.0187 (0.0469) acc@1 1.0000 (0.9865) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-23 00:05:07] __main__ INFO: \u001b[0mEpoch 4 Step 200/351 lr 0.000800 loss 0.0728 (0.0504) acc@1 0.9766 (0.9854) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-23 00:06:59] __main__ INFO: \u001b[0mEpoch 4 Step 300/351 lr 0.000800 loss 0.0420 (0.0526) acc@1 0.9844 (0.9850) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-23 00:07:57] __main__ INFO: \u001b[0mEpoch 4 Step 351/351 lr 0.000800 loss 0.1311 (0.0534) acc@1 0.9609 (0.9850) acc@5 0.9922 (0.9997)\n",
      "\u001b[32m[2020-06-23 00:07:57] __main__ INFO: \u001b[0mElapsed 394.94\n",
      "\u001b[32m[2020-06-23 00:07:57] __main__ INFO: \u001b[0mVal 4\n",
      "\u001b[32m[2020-06-23 00:08:10] __main__ INFO: \u001b[0mEpoch 4 loss 0.2389 acc@1 0.9344 acc@5 0.9978\n",
      "\u001b[32m[2020-06-23 00:08:10] __main__ INFO: \u001b[0mElapsed 13.28\n",
      "\u001b[32m[2020-06-23 00:08:10] __main__ INFO: \u001b[0mTrain 5 1404\n",
      "\u001b[32m[2020-06-23 00:10:03] __main__ INFO: \u001b[0mEpoch 5 Step 100/351 lr 0.000800 loss 0.0341 (0.0409) acc@1 0.9844 (0.9898) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-06-23 00:11:55] __main__ INFO: \u001b[0mEpoch 5 Step 200/351 lr 0.000800 loss 0.0618 (0.0411) acc@1 0.9844 (0.9897) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-23 00:13:48] __main__ INFO: \u001b[0mEpoch 5 Step 300/351 lr 0.000800 loss 0.0716 (0.0429) acc@1 0.9766 (0.9889) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-23 00:14:45] __main__ INFO: \u001b[0mEpoch 5 Step 351/351 lr 0.000800 loss 0.0225 (0.0434) acc@1 1.0000 (0.9887) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-23 00:14:45] __main__ INFO: \u001b[0mElapsed 395.02\n",
      "\u001b[32m[2020-06-23 00:14:45] __main__ INFO: \u001b[0mVal 5\n",
      "\u001b[32m[2020-06-23 00:14:58] __main__ INFO: \u001b[0mEpoch 5 loss 0.2437 acc@1 0.9332 acc@5 0.9974\n",
      "\u001b[32m[2020-06-23 00:14:58] __main__ INFO: \u001b[0mElapsed 13.27\n",
      "\u001b[32m[2020-06-23 00:14:58] __main__ INFO: \u001b[0mTrain 6 1755\n",
      "\u001b[32m[2020-06-23 00:16:51] __main__ INFO: \u001b[0mEpoch 6 Step 100/351 lr 0.000800 loss 0.0165 (0.0344) acc@1 1.0000 (0.9911) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-06-23 00:18:43] __main__ INFO: \u001b[0mEpoch 6 Step 200/351 lr 0.000800 loss 0.0526 (0.0348) acc@1 0.9766 (0.9908) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 00:20:36] __main__ INFO: \u001b[0mEpoch 6 Step 300/351 lr 0.000800 loss 0.0195 (0.0360) acc@1 1.0000 (0.9904) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 00:21:33] __main__ INFO: \u001b[0mEpoch 6 Step 351/351 lr 0.000800 loss 0.0072 (0.0360) acc@1 1.0000 (0.9904) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-06-23 00:21:33] __main__ INFO: \u001b[0mElapsed 394.97\n",
      "\u001b[32m[2020-06-23 00:21:33] __main__ INFO: \u001b[0mVal 6\n",
      "\u001b[32m[2020-06-23 00:21:46] __main__ INFO: \u001b[0mEpoch 6 loss 0.2455 acc@1 0.9364 acc@5 0.9972\n",
      "\u001b[32m[2020-06-23 00:21:46] __main__ INFO: \u001b[0mElapsed 13.26\n",
      "\u001b[32m[2020-06-23 00:21:46] __main__ INFO: \u001b[0mTrain 7 2106\n",
      "\u001b[32m[2020-06-23 00:23:39] __main__ INFO: \u001b[0mEpoch 7 Step 100/351 lr 0.000800 loss 0.0240 (0.0290) acc@1 0.9922 (0.9930) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 00:25:32] __main__ INFO: \u001b[0mEpoch 7 Step 200/351 lr 0.000800 loss 0.0258 (0.0296) acc@1 0.9922 (0.9928) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-06-23 00:27:24] __main__ INFO: \u001b[0mEpoch 7 Step 300/351 lr 0.000800 loss 0.0229 (0.0284) acc@1 0.9922 (0.9928) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-06-23 00:28:21] __main__ INFO: \u001b[0mEpoch 7 Step 351/351 lr 0.000800 loss 0.0343 (0.0296) acc@1 0.9844 (0.9924) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-06-23 00:28:21] __main__ INFO: \u001b[0mElapsed 395.00\n",
      "\u001b[32m[2020-06-23 00:28:21] __main__ INFO: \u001b[0mVal 7\n",
      "\u001b[32m[2020-06-23 00:28:35] __main__ INFO: \u001b[0mEpoch 7 loss 0.2450 acc@1 0.9348 acc@5 0.9976\n",
      "\u001b[32m[2020-06-23 00:28:35] __main__ INFO: \u001b[0mElapsed 13.26\n",
      "\u001b[32m[2020-06-23 00:28:35] __main__ INFO: \u001b[0mTrain 8 2457\n",
      "\u001b[32m[2020-06-23 00:30:27] __main__ INFO: \u001b[0mEpoch 8 Step 100/351 lr 0.000800 loss 0.0071 (0.0257) acc@1 1.0000 (0.9934) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-06-23 00:32:20] __main__ INFO: \u001b[0mEpoch 8 Step 200/351 lr 0.000800 loss 0.0513 (0.0260) acc@1 0.9922 (0.9934) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 00:34:12] __main__ INFO: \u001b[0mEpoch 8 Step 300/351 lr 0.000800 loss 0.0403 (0.0266) acc@1 0.9922 (0.9930) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-06-23 00:35:10] __main__ INFO: \u001b[0mEpoch 8 Step 351/351 lr 0.000800 loss 0.0255 (0.0269) acc@1 0.9922 (0.9931) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-06-23 00:35:10] __main__ INFO: \u001b[0mElapsed 394.89\n",
      "\u001b[32m[2020-06-23 00:35:10] __main__ INFO: \u001b[0mVal 8\n",
      "\u001b[32m[2020-06-23 00:35:23] __main__ INFO: \u001b[0mEpoch 8 loss 0.2517 acc@1 0.9370 acc@5 0.9974\n",
      "\u001b[32m[2020-06-23 00:35:23] __main__ INFO: \u001b[0mElapsed 13.27\n",
      "\u001b[32m[2020-06-23 00:35:23] __main__ INFO: \u001b[0mTrain 9 2808\n",
      "\u001b[32m[2020-06-23 00:37:15] __main__ INFO: \u001b[0mEpoch 9 Step 100/351 lr 0.000800 loss 0.0326 (0.0230) acc@1 0.9922 (0.9946) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-06-23 00:39:08] __main__ INFO: \u001b[0mEpoch 9 Step 200/351 lr 0.000800 loss 0.0083 (0.0224) acc@1 1.0000 (0.9948) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 00:41:00] __main__ INFO: \u001b[0mEpoch 9 Step 300/351 lr 0.000800 loss 0.0370 (0.0218) acc@1 0.9922 (0.9948) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 00:41:58] __main__ INFO: \u001b[0mEpoch 9 Step 351/351 lr 0.000800 loss 0.0094 (0.0215) acc@1 1.0000 (0.9950) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 00:41:58] __main__ INFO: \u001b[0mElapsed 394.86\n",
      "\u001b[32m[2020-06-23 00:41:58] __main__ INFO: \u001b[0mVal 9\n",
      "\u001b[32m[2020-06-23 00:42:11] __main__ INFO: \u001b[0mEpoch 9 loss 0.2518 acc@1 0.9366 acc@5 0.9968\n",
      "\u001b[32m[2020-06-23 00:42:11] __main__ INFO: \u001b[0mElapsed 13.26\n",
      "\u001b[32m[2020-06-23 00:42:11] __main__ INFO: \u001b[0mTrain 10 3159\n",
      "\u001b[32m[2020-06-23 00:44:03] __main__ INFO: \u001b[0mEpoch 10 Step 100/351 lr 0.000800 loss 0.0229 (0.0184) acc@1 0.9922 (0.9958) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 00:45:56] __main__ INFO: \u001b[0mEpoch 10 Step 200/351 lr 0.000800 loss 0.0081 (0.0187) acc@1 1.0000 (0.9957) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 00:47:48] __main__ INFO: \u001b[0mEpoch 10 Step 300/351 lr 0.000800 loss 0.0168 (0.0190) acc@1 0.9922 (0.9957) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-06-23 00:48:46] __main__ INFO: \u001b[0mEpoch 10 Step 351/351 lr 0.000800 loss 0.0086 (0.0190) acc@1 1.0000 (0.9956) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 00:48:46] __main__ INFO: \u001b[0mElapsed 394.80\n",
      "\u001b[32m[2020-06-23 00:48:46] __main__ INFO: \u001b[0mVal 10\n",
      "\u001b[32m[2020-06-23 00:48:59] __main__ INFO: \u001b[0mEpoch 10 loss 0.2546 acc@1 0.9344 acc@5 0.9978\n",
      "\u001b[32m[2020-06-23 00:48:59] __main__ INFO: \u001b[0mElapsed 13.26\n",
      "\u001b[32m[2020-06-23 00:48:59] __main__ INFO: \u001b[0mTrain 11 3510\n",
      "\u001b[32m[2020-06-23 00:50:52] __main__ INFO: \u001b[0mEpoch 11 Step 100/351 lr 0.000800 loss 0.0470 (0.0144) acc@1 0.9844 (0.9970) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 00:52:44] __main__ INFO: \u001b[0mEpoch 11 Step 200/351 lr 0.000800 loss 0.0150 (0.0157) acc@1 0.9922 (0.9964) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 00:54:36] __main__ INFO: \u001b[0mEpoch 11 Step 300/351 lr 0.000800 loss 0.0157 (0.0157) acc@1 1.0000 (0.9962) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 00:55:34] __main__ INFO: \u001b[0mEpoch 11 Step 351/351 lr 0.000800 loss 0.0126 (0.0158) acc@1 0.9922 (0.9963) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 00:55:34] __main__ INFO: \u001b[0mElapsed 394.83\n",
      "\u001b[32m[2020-06-23 00:55:34] __main__ INFO: \u001b[0mVal 11\n",
      "\u001b[32m[2020-06-23 00:55:47] __main__ INFO: \u001b[0mEpoch 11 loss 0.2664 acc@1 0.9334 acc@5 0.9980\n",
      "\u001b[32m[2020-06-23 00:55:47] __main__ INFO: \u001b[0mElapsed 13.27\n",
      "\u001b[32m[2020-06-23 00:55:47] __main__ INFO: \u001b[0mTrain 12 3861\n",
      "\u001b[32m[2020-06-23 00:57:40] __main__ INFO: \u001b[0mEpoch 12 Step 100/351 lr 0.000800 loss 0.0114 (0.0130) acc@1 1.0000 (0.9976) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 00:59:32] __main__ INFO: \u001b[0mEpoch 12 Step 200/351 lr 0.000800 loss 0.0224 (0.0149) acc@1 0.9922 (0.9968) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 01:01:24] __main__ INFO: \u001b[0mEpoch 12 Step 300/351 lr 0.000800 loss 0.0114 (0.0153) acc@1 1.0000 (0.9965) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 01:02:22] __main__ INFO: \u001b[0mEpoch 12 Step 351/351 lr 0.000800 loss 0.0148 (0.0154) acc@1 1.0000 (0.9966) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 01:02:22] __main__ INFO: \u001b[0mElapsed 394.61\n",
      "\u001b[32m[2020-06-23 01:02:22] __main__ INFO: \u001b[0mVal 12\n",
      "\u001b[32m[2020-06-23 01:02:35] __main__ INFO: \u001b[0mEpoch 12 loss 0.2633 acc@1 0.9358 acc@5 0.9974\n",
      "\u001b[32m[2020-06-23 01:02:35] __main__ INFO: \u001b[0mElapsed 13.25\n",
      "\u001b[32m[2020-06-23 01:02:35] __main__ INFO: \u001b[0mTrain 13 4212\n",
      "\u001b[32m[2020-06-23 01:04:28] __main__ INFO: \u001b[0mEpoch 13 Step 100/351 lr 0.000800 loss 0.0538 (0.0137) acc@1 0.9766 (0.9970) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 01:06:20] __main__ INFO: \u001b[0mEpoch 13 Step 200/351 lr 0.000800 loss 0.0167 (0.0134) acc@1 0.9922 (0.9969) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 01:08:12] __main__ INFO: \u001b[0mEpoch 13 Step 300/351 lr 0.000800 loss 0.0048 (0.0130) acc@1 1.0000 (0.9972) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 01:09:10] __main__ INFO: \u001b[0mEpoch 13 Step 351/351 lr 0.000800 loss 0.0167 (0.0129) acc@1 0.9922 (0.9972) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 01:09:10] __main__ INFO: \u001b[0mElapsed 394.78\n",
      "\u001b[32m[2020-06-23 01:09:10] __main__ INFO: \u001b[0mVal 13\n",
      "\u001b[32m[2020-06-23 01:09:23] __main__ INFO: \u001b[0mEpoch 13 loss 0.2644 acc@1 0.9364 acc@5 0.9986\n",
      "\u001b[32m[2020-06-23 01:09:23] __main__ INFO: \u001b[0mElapsed 13.23\n",
      "\u001b[32m[2020-06-23 01:09:23] __main__ INFO: \u001b[0mTrain 14 4563\n",
      "\u001b[32m[2020-06-23 01:11:15] __main__ INFO: \u001b[0mEpoch 14 Step 100/351 lr 0.000800 loss 0.0047 (0.0126) acc@1 1.0000 (0.9975) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 01:13:08] __main__ INFO: \u001b[0mEpoch 14 Step 200/351 lr 0.000800 loss 0.0059 (0.0127) acc@1 1.0000 (0.9973) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 01:15:00] __main__ INFO: \u001b[0mEpoch 14 Step 300/351 lr 0.000800 loss 0.0122 (0.0124) acc@1 0.9922 (0.9974) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 01:15:58] __main__ INFO: \u001b[0mEpoch 14 Step 351/351 lr 0.000800 loss 0.0047 (0.0125) acc@1 1.0000 (0.9973) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 01:15:58] __main__ INFO: \u001b[0mElapsed 394.63\n",
      "\u001b[32m[2020-06-23 01:15:58] __main__ INFO: \u001b[0mVal 14\n",
      "\u001b[32m[2020-06-23 01:16:11] __main__ INFO: \u001b[0mEpoch 14 loss 0.2694 acc@1 0.9330 acc@5 0.9976\n",
      "\u001b[32m[2020-06-23 01:16:11] __main__ INFO: \u001b[0mElapsed 13.27\n",
      "\u001b[32m[2020-06-23 01:16:11] __main__ INFO: \u001b[0mTrain 15 4914\n",
      "\u001b[32m[2020-06-23 01:18:03] __main__ INFO: \u001b[0mEpoch 15 Step 100/351 lr 0.000800 loss 0.0103 (0.0136) acc@1 1.0000 (0.9971) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 01:19:56] __main__ INFO: \u001b[0mEpoch 15 Step 200/351 lr 0.000800 loss 0.0082 (0.0126) acc@1 1.0000 (0.9975) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 01:21:48] __main__ INFO: \u001b[0mEpoch 15 Step 300/351 lr 0.000800 loss 0.0043 (0.0120) acc@1 1.0000 (0.9976) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 01:22:46] __main__ INFO: \u001b[0mEpoch 15 Step 351/351 lr 0.000800 loss 0.0126 (0.0122) acc@1 1.0000 (0.9974) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 01:22:46] __main__ INFO: \u001b[0mElapsed 394.69\n",
      "\u001b[32m[2020-06-23 01:22:46] __main__ INFO: \u001b[0mVal 15\n",
      "\u001b[32m[2020-06-23 01:22:59] __main__ INFO: \u001b[0mEpoch 15 loss 0.2611 acc@1 0.9362 acc@5 0.9980\n",
      "\u001b[32m[2020-06-23 01:22:59] __main__ INFO: \u001b[0mElapsed 13.26\n",
      "\u001b[32m[2020-06-23 01:22:59] __main__ INFO: \u001b[0mTrain 16 5265\n",
      "\u001b[32m[2020-06-23 01:24:51] __main__ INFO: \u001b[0mEpoch 16 Step 100/351 lr 0.000800 loss 0.0079 (0.0111) acc@1 1.0000 (0.9981) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 01:26:44] __main__ INFO: \u001b[0mEpoch 16 Step 200/351 lr 0.000800 loss 0.0105 (0.0102) acc@1 1.0000 (0.9982) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 01:28:36] __main__ INFO: \u001b[0mEpoch 16 Step 300/351 lr 0.000800 loss 0.0033 (0.0108) acc@1 1.0000 (0.9978) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 01:29:33] __main__ INFO: \u001b[0mEpoch 16 Step 351/351 lr 0.000800 loss 0.0053 (0.0106) acc@1 1.0000 (0.9978) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 01:29:34] __main__ INFO: \u001b[0mElapsed 394.65\n",
      "\u001b[32m[2020-06-23 01:29:34] __main__ INFO: \u001b[0mVal 16\n",
      "\u001b[32m[2020-06-23 01:29:47] __main__ INFO: \u001b[0mEpoch 16 loss 0.2565 acc@1 0.9366 acc@5 0.9982\n",
      "\u001b[32m[2020-06-23 01:29:47] __main__ INFO: \u001b[0mElapsed 13.31\n",
      "\u001b[32m[2020-06-23 01:29:47] __main__ INFO: \u001b[0mTrain 17 5616\n",
      "\u001b[32m[2020-06-23 01:31:39] __main__ INFO: \u001b[0mEpoch 17 Step 100/351 lr 0.000800 loss 0.0067 (0.0080) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 01:33:32] __main__ INFO: \u001b[0mEpoch 17 Step 200/351 lr 0.000800 loss 0.0048 (0.0090) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 01:35:24] __main__ INFO: \u001b[0mEpoch 17 Step 300/351 lr 0.000800 loss 0.0107 (0.0087) acc@1 0.9922 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 01:36:21] __main__ INFO: \u001b[0mEpoch 17 Step 351/351 lr 0.000800 loss 0.0038 (0.0088) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 01:36:21] __main__ INFO: \u001b[0mElapsed 394.60\n",
      "\u001b[32m[2020-06-23 01:36:21] __main__ INFO: \u001b[0mVal 17\n",
      "\u001b[32m[2020-06-23 01:36:35] __main__ INFO: \u001b[0mEpoch 17 loss 0.2742 acc@1 0.9340 acc@5 0.9978\n",
      "\u001b[32m[2020-06-23 01:36:35] __main__ INFO: \u001b[0mElapsed 13.25\n",
      "\u001b[32m[2020-06-23 01:36:35] __main__ INFO: \u001b[0mTrain 18 5967\n",
      "\u001b[32m[2020-06-23 01:38:27] __main__ INFO: \u001b[0mEpoch 18 Step 100/351 lr 0.000800 loss 0.0041 (0.0097) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 01:40:20] __main__ INFO: \u001b[0mEpoch 18 Step 200/351 lr 0.000800 loss 0.0044 (0.0094) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 01:42:12] __main__ INFO: \u001b[0mEpoch 18 Step 300/351 lr 0.000800 loss 0.0186 (0.0092) acc@1 0.9922 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 01:43:09] __main__ INFO: \u001b[0mEpoch 18 Step 351/351 lr 0.000800 loss 0.0169 (0.0095) acc@1 0.9922 (0.9983) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 01:43:09] __main__ INFO: \u001b[0mElapsed 394.69\n",
      "\u001b[32m[2020-06-23 01:43:09] __main__ INFO: \u001b[0mVal 18\n",
      "\u001b[32m[2020-06-23 01:43:23] __main__ INFO: \u001b[0mEpoch 18 loss 0.2801 acc@1 0.9344 acc@5 0.9976\n",
      "\u001b[32m[2020-06-23 01:43:23] __main__ INFO: \u001b[0mElapsed 13.27\n",
      "\u001b[32m[2020-06-23 01:43:23] __main__ INFO: \u001b[0mTrain 19 6318\n",
      "\u001b[32m[2020-06-23 01:45:15] __main__ INFO: \u001b[0mEpoch 19 Step 100/351 lr 0.000800 loss 0.0080 (0.0081) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 01:47:08] __main__ INFO: \u001b[0mEpoch 19 Step 200/351 lr 0.000800 loss 0.0085 (0.0090) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 01:49:00] __main__ INFO: \u001b[0mEpoch 19 Step 300/351 lr 0.000800 loss 0.0175 (0.0090) acc@1 0.9922 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 01:49:57] __main__ INFO: \u001b[0mEpoch 19 Step 351/351 lr 0.000800 loss 0.0246 (0.0091) acc@1 0.9844 (0.9983) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 01:49:57] __main__ INFO: \u001b[0mElapsed 394.65\n",
      "\u001b[32m[2020-06-23 01:49:57] __main__ INFO: \u001b[0mVal 19\n",
      "\u001b[32m[2020-06-23 01:50:11] __main__ INFO: \u001b[0mEpoch 19 loss 0.2750 acc@1 0.9364 acc@5 0.9972\n",
      "\u001b[32m[2020-06-23 01:50:11] __main__ INFO: \u001b[0mElapsed 13.24\n",
      "\u001b[32m[2020-06-23 01:50:11] __main__ INFO: \u001b[0mTrain 20 6669\n",
      "\u001b[32m[2020-06-23 01:52:03] __main__ INFO: \u001b[0mEpoch 20 Step 100/351 lr 0.000800 loss 0.0034 (0.0077) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 01:53:55] __main__ INFO: \u001b[0mEpoch 20 Step 200/351 lr 0.000800 loss 0.0034 (0.0078) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 01:55:48] __main__ INFO: \u001b[0mEpoch 20 Step 300/351 lr 0.000800 loss 0.0048 (0.0083) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 01:56:45] __main__ INFO: \u001b[0mEpoch 20 Step 351/351 lr 0.000800 loss 0.0045 (0.0082) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 01:56:45] __main__ INFO: \u001b[0mElapsed 394.59\n",
      "\u001b[32m[2020-06-23 01:56:45] __main__ INFO: \u001b[0mVal 20\n",
      "\u001b[32m[2020-06-23 01:56:58] __main__ INFO: \u001b[0mEpoch 20 loss 0.2608 acc@1 0.9400 acc@5 0.9972\n",
      "\u001b[32m[2020-06-23 01:56:58] __main__ INFO: \u001b[0mElapsed 13.26\n",
      "\u001b[32m[2020-06-23 01:56:58] __main__ INFO: \u001b[0mTrain 21 7020\n",
      "\u001b[32m[2020-06-23 01:58:51] __main__ INFO: \u001b[0mEpoch 21 Step 100/351 lr 0.000800 loss 0.0188 (0.0080) acc@1 0.9922 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 02:00:43] __main__ INFO: \u001b[0mEpoch 21 Step 200/351 lr 0.000800 loss 0.0055 (0.0087) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 02:02:36] __main__ INFO: \u001b[0mEpoch 21 Step 300/351 lr 0.000800 loss 0.0035 (0.0082) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 02:03:33] __main__ INFO: \u001b[0mEpoch 21 Step 351/351 lr 0.000800 loss 0.0087 (0.0084) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 02:03:33] __main__ INFO: \u001b[0mElapsed 394.67\n",
      "\u001b[32m[2020-06-23 02:03:33] __main__ INFO: \u001b[0mVal 21\n",
      "\u001b[32m[2020-06-23 02:03:46] __main__ INFO: \u001b[0mEpoch 21 loss 0.2776 acc@1 0.9372 acc@5 0.9970\n",
      "\u001b[32m[2020-06-23 02:03:46] __main__ INFO: \u001b[0mElapsed 13.25\n",
      "\u001b[32m[2020-06-23 02:03:46] __main__ INFO: \u001b[0mTrain 22 7371\n",
      "\u001b[32m[2020-06-23 02:05:39] __main__ INFO: \u001b[0mEpoch 22 Step 100/351 lr 0.000800 loss 0.0036 (0.0069) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 02:07:31] __main__ INFO: \u001b[0mEpoch 22 Step 200/351 lr 0.000800 loss 0.0035 (0.0068) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 02:09:24] __main__ INFO: \u001b[0mEpoch 22 Step 300/351 lr 0.000800 loss 0.0052 (0.0068) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 02:10:21] __main__ INFO: \u001b[0mEpoch 22 Step 351/351 lr 0.000800 loss 0.0030 (0.0067) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 02:10:21] __main__ INFO: \u001b[0mElapsed 394.58\n",
      "\u001b[32m[2020-06-23 02:10:21] __main__ INFO: \u001b[0mVal 22\n",
      "\u001b[32m[2020-06-23 02:10:34] __main__ INFO: \u001b[0mEpoch 22 loss 0.2758 acc@1 0.9374 acc@5 0.9976\n",
      "\u001b[32m[2020-06-23 02:10:34] __main__ INFO: \u001b[0mElapsed 13.24\n",
      "\u001b[32m[2020-06-23 02:10:34] __main__ INFO: \u001b[0mTrain 23 7722\n",
      "\u001b[32m[2020-06-23 02:12:27] __main__ INFO: \u001b[0mEpoch 23 Step 100/351 lr 0.000800 loss 0.0048 (0.0072) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 02:14:19] __main__ INFO: \u001b[0mEpoch 23 Step 200/351 lr 0.000800 loss 0.0131 (0.0075) acc@1 0.9922 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 02:16:11] __main__ INFO: \u001b[0mEpoch 23 Step 300/351 lr 0.000800 loss 0.0047 (0.0074) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 02:17:09] __main__ INFO: \u001b[0mEpoch 23 Step 351/351 lr 0.000800 loss 0.0033 (0.0073) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 02:17:09] __main__ INFO: \u001b[0mElapsed 394.62\n",
      "\u001b[32m[2020-06-23 02:17:09] __main__ INFO: \u001b[0mVal 23\n",
      "\u001b[32m[2020-06-23 02:17:22] __main__ INFO: \u001b[0mEpoch 23 loss 0.2638 acc@1 0.9400 acc@5 0.9970\n",
      "\u001b[32m[2020-06-23 02:17:22] __main__ INFO: \u001b[0mElapsed 13.25\n",
      "\u001b[32m[2020-06-23 02:17:22] __main__ INFO: \u001b[0mTrain 24 8073\n",
      "\u001b[32m[2020-06-23 02:19:15] __main__ INFO: \u001b[0mEpoch 24 Step 100/351 lr 0.000800 loss 0.0051 (0.0054) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 02:21:07] __main__ INFO: \u001b[0mEpoch 24 Step 200/351 lr 0.000800 loss 0.0046 (0.0057) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 02:22:59] __main__ INFO: \u001b[0mEpoch 24 Step 300/351 lr 0.000800 loss 0.0065 (0.0063) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 02:23:57] __main__ INFO: \u001b[0mEpoch 24 Step 351/351 lr 0.000800 loss 0.0029 (0.0065) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 02:23:57] __main__ INFO: \u001b[0mElapsed 394.67\n",
      "\u001b[32m[2020-06-23 02:23:57] __main__ INFO: \u001b[0mVal 24\n",
      "\u001b[32m[2020-06-23 02:24:10] __main__ INFO: \u001b[0mEpoch 24 loss 0.2821 acc@1 0.9352 acc@5 0.9972\n",
      "\u001b[32m[2020-06-23 02:24:10] __main__ INFO: \u001b[0mElapsed 13.28\n",
      "\u001b[32m[2020-06-23 02:24:10] __main__ INFO: \u001b[0mTrain 25 8424\n",
      "\u001b[32m[2020-06-23 02:26:02] __main__ INFO: \u001b[0mEpoch 25 Step 100/351 lr 0.000800 loss 0.0028 (0.0066) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 02:27:55] __main__ INFO: \u001b[0mEpoch 25 Step 200/351 lr 0.000800 loss 0.0032 (0.0067) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 02:29:47] __main__ INFO: \u001b[0mEpoch 25 Step 300/351 lr 0.000800 loss 0.0049 (0.0070) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 02:30:45] __main__ INFO: \u001b[0mEpoch 25 Step 351/351 lr 0.000800 loss 0.0068 (0.0068) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 02:30:45] __main__ INFO: \u001b[0mElapsed 394.59\n",
      "\u001b[32m[2020-06-23 02:30:45] __main__ INFO: \u001b[0mVal 25\n",
      "\u001b[32m[2020-06-23 02:30:58] __main__ INFO: \u001b[0mEpoch 25 loss 0.2909 acc@1 0.9352 acc@5 0.9966\n",
      "\u001b[32m[2020-06-23 02:30:58] __main__ INFO: \u001b[0mElapsed 13.27\n",
      "\u001b[32m[2020-06-23 02:30:58] __main__ INFO: \u001b[0mTrain 26 8775\n",
      "\u001b[32m[2020-06-23 02:32:50] __main__ INFO: \u001b[0mEpoch 26 Step 100/351 lr 0.000800 loss 0.0116 (0.0064) acc@1 0.9922 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 02:34:43] __main__ INFO: \u001b[0mEpoch 26 Step 200/351 lr 0.000800 loss 0.0291 (0.0063) acc@1 0.9922 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 02:36:35] __main__ INFO: \u001b[0mEpoch 26 Step 300/351 lr 0.000800 loss 0.0054 (0.0066) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 02:37:32] __main__ INFO: \u001b[0mEpoch 26 Step 351/351 lr 0.000800 loss 0.0026 (0.0067) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 02:37:32] __main__ INFO: \u001b[0mElapsed 394.64\n",
      "\u001b[32m[2020-06-23 02:37:32] __main__ INFO: \u001b[0mVal 26\n",
      "\u001b[32m[2020-06-23 02:37:46] __main__ INFO: \u001b[0mEpoch 26 loss 0.2757 acc@1 0.9364 acc@5 0.9970\n",
      "\u001b[32m[2020-06-23 02:37:46] __main__ INFO: \u001b[0mElapsed 13.28\n",
      "\u001b[32m[2020-06-23 02:37:46] __main__ INFO: \u001b[0mTrain 27 9126\n",
      "\u001b[32m[2020-06-23 02:39:38] __main__ INFO: \u001b[0mEpoch 27 Step 100/351 lr 0.000800 loss 0.0148 (0.0078) acc@1 0.9922 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 02:41:31] __main__ INFO: \u001b[0mEpoch 27 Step 200/351 lr 0.000800 loss 0.0062 (0.0068) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 02:43:23] __main__ INFO: \u001b[0mEpoch 27 Step 300/351 lr 0.000800 loss 0.0072 (0.0064) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 02:44:20] __main__ INFO: \u001b[0mEpoch 27 Step 351/351 lr 0.000800 loss 0.0119 (0.0064) acc@1 0.9922 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 02:44:20] __main__ INFO: \u001b[0mElapsed 394.63\n",
      "\u001b[32m[2020-06-23 02:44:20] __main__ INFO: \u001b[0mVal 27\n",
      "\u001b[32m[2020-06-23 02:44:34] __main__ INFO: \u001b[0mEpoch 27 loss 0.2828 acc@1 0.9356 acc@5 0.9964\n",
      "\u001b[32m[2020-06-23 02:44:34] __main__ INFO: \u001b[0mElapsed 13.27\n",
      "\u001b[32m[2020-06-23 02:44:34] __main__ INFO: \u001b[0mTrain 28 9477\n",
      "\u001b[32m[2020-06-23 02:46:26] __main__ INFO: \u001b[0mEpoch 28 Step 100/351 lr 0.000800 loss 0.0030 (0.0049) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 02:48:18] __main__ INFO: \u001b[0mEpoch 28 Step 200/351 lr 0.000800 loss 0.0058 (0.0054) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 02:50:11] __main__ INFO: \u001b[0mEpoch 28 Step 300/351 lr 0.000800 loss 0.0042 (0.0053) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 02:51:08] __main__ INFO: \u001b[0mEpoch 28 Step 351/351 lr 0.000800 loss 0.0038 (0.0054) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 02:51:08] __main__ INFO: \u001b[0mElapsed 394.55\n",
      "\u001b[32m[2020-06-23 02:51:08] __main__ INFO: \u001b[0mVal 28\n",
      "\u001b[32m[2020-06-23 02:51:21] __main__ INFO: \u001b[0mEpoch 28 loss 0.2894 acc@1 0.9344 acc@5 0.9962\n",
      "\u001b[32m[2020-06-23 02:51:21] __main__ INFO: \u001b[0mElapsed 13.25\n",
      "\u001b[32m[2020-06-23 02:51:21] __main__ INFO: \u001b[0mTrain 29 9828\n",
      "\u001b[32m[2020-06-23 02:53:14] __main__ INFO: \u001b[0mEpoch 29 Step 100/351 lr 0.000800 loss 0.0056 (0.0051) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 02:55:06] __main__ INFO: \u001b[0mEpoch 29 Step 200/351 lr 0.000800 loss 0.0035 (0.0057) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 02:56:59] __main__ INFO: \u001b[0mEpoch 29 Step 300/351 lr 0.000800 loss 0.0024 (0.0054) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 02:57:56] __main__ INFO: \u001b[0mEpoch 29 Step 351/351 lr 0.000800 loss 0.0027 (0.0053) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 02:57:56] __main__ INFO: \u001b[0mElapsed 394.51\n",
      "\u001b[32m[2020-06-23 02:57:56] __main__ INFO: \u001b[0mVal 29\n",
      "\u001b[32m[2020-06-23 02:58:09] __main__ INFO: \u001b[0mEpoch 29 loss 0.2908 acc@1 0.9376 acc@5 0.9968\n",
      "\u001b[32m[2020-06-23 02:58:09] __main__ INFO: \u001b[0mElapsed 13.26\n",
      "\u001b[32m[2020-06-23 02:58:09] __main__ INFO: \u001b[0mTrain 30 10179\n",
      "\u001b[32m[2020-06-23 03:00:02] __main__ INFO: \u001b[0mEpoch 30 Step 100/351 lr 0.000800 loss 0.0030 (0.0046) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 03:01:54] __main__ INFO: \u001b[0mEpoch 30 Step 200/351 lr 0.000800 loss 0.0039 (0.0042) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 03:03:46] __main__ INFO: \u001b[0mEpoch 30 Step 300/351 lr 0.000800 loss 0.0039 (0.0045) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 03:04:44] __main__ INFO: \u001b[0mEpoch 30 Step 351/351 lr 0.000800 loss 0.0048 (0.0045) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 03:04:44] __main__ INFO: \u001b[0mElapsed 394.58\n",
      "\u001b[32m[2020-06-23 03:04:44] __main__ INFO: \u001b[0mVal 30\n",
      "\u001b[32m[2020-06-23 03:04:57] __main__ INFO: \u001b[0mEpoch 30 loss 0.2878 acc@1 0.9352 acc@5 0.9964\n",
      "\u001b[32m[2020-06-23 03:04:57] __main__ INFO: \u001b[0mElapsed 13.24\n",
      "\u001b[32m[2020-06-23 03:04:57] __main__ INFO: \u001b[0mTrain 31 10530\n",
      "\u001b[32m[2020-06-23 03:06:50] __main__ INFO: \u001b[0mEpoch 31 Step 100/351 lr 0.000800 loss 0.0022 (0.0046) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 03:08:42] __main__ INFO: \u001b[0mEpoch 31 Step 200/351 lr 0.000800 loss 0.0041 (0.0048) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 03:10:34] __main__ INFO: \u001b[0mEpoch 31 Step 300/351 lr 0.000800 loss 0.0048 (0.0050) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 03:11:32] __main__ INFO: \u001b[0mEpoch 31 Step 351/351 lr 0.000800 loss 0.0027 (0.0050) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 03:11:32] __main__ INFO: \u001b[0mElapsed 394.65\n",
      "\u001b[32m[2020-06-23 03:11:32] __main__ INFO: \u001b[0mVal 31\n",
      "\u001b[32m[2020-06-23 03:11:45] __main__ INFO: \u001b[0mEpoch 31 loss 0.2786 acc@1 0.9382 acc@5 0.9964\n",
      "\u001b[32m[2020-06-23 03:11:45] __main__ INFO: \u001b[0mElapsed 13.25\n",
      "\u001b[32m[2020-06-23 03:11:45] __main__ INFO: \u001b[0mTrain 32 10881\n",
      "\u001b[32m[2020-06-23 03:13:37] __main__ INFO: \u001b[0mEpoch 32 Step 100/351 lr 0.000800 loss 0.0059 (0.0048) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 03:15:30] __main__ INFO: \u001b[0mEpoch 32 Step 200/351 lr 0.000800 loss 0.0030 (0.0047) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 03:17:22] __main__ INFO: \u001b[0mEpoch 32 Step 300/351 lr 0.000800 loss 0.0031 (0.0045) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 03:18:19] __main__ INFO: \u001b[0mEpoch 32 Step 351/351 lr 0.000800 loss 0.0077 (0.0045) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 03:18:20] __main__ INFO: \u001b[0mElapsed 394.54\n",
      "\u001b[32m[2020-06-23 03:18:20] __main__ INFO: \u001b[0mVal 32\n",
      "\u001b[32m[2020-06-23 03:18:33] __main__ INFO: \u001b[0mEpoch 32 loss 0.2802 acc@1 0.9366 acc@5 0.9970\n",
      "\u001b[32m[2020-06-23 03:18:33] __main__ INFO: \u001b[0mElapsed 13.29\n",
      "\u001b[32m[2020-06-23 03:18:33] __main__ INFO: \u001b[0mTrain 33 11232\n",
      "\u001b[32m[2020-06-23 03:20:25] __main__ INFO: \u001b[0mEpoch 33 Step 100/351 lr 0.000800 loss 0.0023 (0.0042) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 03:22:18] __main__ INFO: \u001b[0mEpoch 33 Step 200/351 lr 0.000800 loss 0.0044 (0.0046) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 03:24:10] __main__ INFO: \u001b[0mEpoch 33 Step 300/351 lr 0.000800 loss 0.0031 (0.0044) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 03:25:07] __main__ INFO: \u001b[0mEpoch 33 Step 351/351 lr 0.000800 loss 0.0019 (0.0047) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 03:25:07] __main__ INFO: \u001b[0mElapsed 394.65\n",
      "\u001b[32m[2020-06-23 03:25:07] __main__ INFO: \u001b[0mVal 33\n",
      "\u001b[32m[2020-06-23 03:25:21] __main__ INFO: \u001b[0mEpoch 33 loss 0.2763 acc@1 0.9380 acc@5 0.9976\n",
      "\u001b[32m[2020-06-23 03:25:21] __main__ INFO: \u001b[0mElapsed 13.26\n",
      "\u001b[32m[2020-06-23 03:25:21] __main__ INFO: \u001b[0mTrain 34 11583\n",
      "\u001b[32m[2020-06-23 03:27:13] __main__ INFO: \u001b[0mEpoch 34 Step 100/351 lr 0.000800 loss 0.0052 (0.0045) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 03:29:06] __main__ INFO: \u001b[0mEpoch 34 Step 200/351 lr 0.000800 loss 0.0054 (0.0046) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 03:30:58] __main__ INFO: \u001b[0mEpoch 34 Step 300/351 lr 0.000800 loss 0.0022 (0.0045) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 03:31:55] __main__ INFO: \u001b[0mEpoch 34 Step 351/351 lr 0.000800 loss 0.0061 (0.0044) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 03:31:55] __main__ INFO: \u001b[0mElapsed 394.73\n",
      "\u001b[32m[2020-06-23 03:31:55] __main__ INFO: \u001b[0mVal 34\n",
      "\u001b[32m[2020-06-23 03:32:09] __main__ INFO: \u001b[0mEpoch 34 loss 0.2865 acc@1 0.9352 acc@5 0.9974\n",
      "\u001b[32m[2020-06-23 03:32:09] __main__ INFO: \u001b[0mElapsed 13.29\n",
      "\u001b[32m[2020-06-23 03:32:09] __main__ INFO: \u001b[0mTrain 35 11934\n",
      "\u001b[32m[2020-06-23 03:34:01] __main__ INFO: \u001b[0mEpoch 35 Step 100/351 lr 0.000800 loss 0.0024 (0.0041) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 03:35:54] __main__ INFO: \u001b[0mEpoch 35 Step 200/351 lr 0.000800 loss 0.0021 (0.0043) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 03:37:46] __main__ INFO: \u001b[0mEpoch 35 Step 300/351 lr 0.000800 loss 0.0021 (0.0045) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 03:38:43] __main__ INFO: \u001b[0mEpoch 35 Step 351/351 lr 0.000800 loss 0.0024 (0.0048) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 03:38:43] __main__ INFO: \u001b[0mElapsed 394.65\n",
      "\u001b[32m[2020-06-23 03:38:43] __main__ INFO: \u001b[0mVal 35\n",
      "\u001b[32m[2020-06-23 03:38:57] __main__ INFO: \u001b[0mEpoch 35 loss 0.2875 acc@1 0.9348 acc@5 0.9968\n",
      "\u001b[32m[2020-06-23 03:38:57] __main__ INFO: \u001b[0mElapsed 13.27\n",
      "\u001b[32m[2020-06-23 03:38:57] __main__ INFO: \u001b[0mTrain 36 12285\n",
      "\u001b[32m[2020-06-23 03:40:49] __main__ INFO: \u001b[0mEpoch 36 Step 100/351 lr 0.000800 loss 0.0027 (0.0041) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 03:42:42] __main__ INFO: \u001b[0mEpoch 36 Step 200/351 lr 0.000800 loss 0.0026 (0.0045) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 03:44:34] __main__ INFO: \u001b[0mEpoch 36 Step 300/351 lr 0.000800 loss 0.0031 (0.0047) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 03:45:31] __main__ INFO: \u001b[0mEpoch 36 Step 351/351 lr 0.000800 loss 0.0022 (0.0051) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 03:45:31] __main__ INFO: \u001b[0mElapsed 394.73\n",
      "\u001b[32m[2020-06-23 03:45:31] __main__ INFO: \u001b[0mVal 36\n",
      "\u001b[32m[2020-06-23 03:45:45] __main__ INFO: \u001b[0mEpoch 36 loss 0.2923 acc@1 0.9376 acc@5 0.9976\n",
      "\u001b[32m[2020-06-23 03:45:45] __main__ INFO: \u001b[0mElapsed 13.28\n",
      "\u001b[32m[2020-06-23 03:45:45] __main__ INFO: \u001b[0mTrain 37 12636\n",
      "\u001b[32m[2020-06-23 03:47:37] __main__ INFO: \u001b[0mEpoch 37 Step 100/351 lr 0.000800 loss 0.0023 (0.0042) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 03:49:30] __main__ INFO: \u001b[0mEpoch 37 Step 200/351 lr 0.000800 loss 0.0027 (0.0040) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 03:51:22] __main__ INFO: \u001b[0mEpoch 37 Step 300/351 lr 0.000800 loss 0.0024 (0.0041) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 03:52:19] __main__ INFO: \u001b[0mEpoch 37 Step 351/351 lr 0.000800 loss 0.0056 (0.0042) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 03:52:19] __main__ INFO: \u001b[0mElapsed 394.61\n",
      "\u001b[32m[2020-06-23 03:52:19] __main__ INFO: \u001b[0mVal 37\n",
      "\u001b[32m[2020-06-23 03:52:33] __main__ INFO: \u001b[0mEpoch 37 loss 0.2971 acc@1 0.9350 acc@5 0.9972\n",
      "\u001b[32m[2020-06-23 03:52:33] __main__ INFO: \u001b[0mElapsed 13.29\n",
      "\u001b[32m[2020-06-23 03:52:33] __main__ INFO: \u001b[0mTrain 38 12987\n",
      "\u001b[32m[2020-06-23 03:54:25] __main__ INFO: \u001b[0mEpoch 38 Step 100/351 lr 0.000800 loss 0.0022 (0.0040) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 03:56:18] __main__ INFO: \u001b[0mEpoch 38 Step 200/351 lr 0.000800 loss 0.0026 (0.0040) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 03:58:10] __main__ INFO: \u001b[0mEpoch 38 Step 300/351 lr 0.000800 loss 0.0063 (0.0041) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 03:59:07] __main__ INFO: \u001b[0mEpoch 38 Step 351/351 lr 0.000800 loss 0.0036 (0.0040) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 03:59:07] __main__ INFO: \u001b[0mElapsed 394.72\n",
      "\u001b[32m[2020-06-23 03:59:07] __main__ INFO: \u001b[0mVal 38\n",
      "\u001b[32m[2020-06-23 03:59:21] __main__ INFO: \u001b[0mEpoch 38 loss 0.2922 acc@1 0.9380 acc@5 0.9976\n",
      "\u001b[32m[2020-06-23 03:59:21] __main__ INFO: \u001b[0mElapsed 13.29\n",
      "\u001b[32m[2020-06-23 03:59:21] __main__ INFO: \u001b[0mTrain 39 13338\n",
      "\u001b[32m[2020-06-23 04:01:13] __main__ INFO: \u001b[0mEpoch 39 Step 100/351 lr 0.000800 loss 0.0028 (0.0044) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 04:03:06] __main__ INFO: \u001b[0mEpoch 39 Step 200/351 lr 0.000800 loss 0.0191 (0.0042) acc@1 0.9922 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 04:04:58] __main__ INFO: \u001b[0mEpoch 39 Step 300/351 lr 0.000800 loss 0.0027 (0.0039) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 04:05:55] __main__ INFO: \u001b[0mEpoch 39 Step 351/351 lr 0.000800 loss 0.0023 (0.0039) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 04:05:55] __main__ INFO: \u001b[0mElapsed 394.69\n",
      "\u001b[32m[2020-06-23 04:05:55] __main__ INFO: \u001b[0mVal 39\n",
      "\u001b[32m[2020-06-23 04:06:09] __main__ INFO: \u001b[0mEpoch 39 loss 0.2889 acc@1 0.9386 acc@5 0.9974\n",
      "\u001b[32m[2020-06-23 04:06:09] __main__ INFO: \u001b[0mElapsed 13.27\n",
      "\u001b[32m[2020-06-23 04:06:09] __main__ INFO: \u001b[0mTrain 40 13689\n",
      "\u001b[32m[2020-06-23 04:08:01] __main__ INFO: \u001b[0mEpoch 40 Step 100/351 lr 0.000800 loss 0.0086 (0.0041) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 04:09:54] __main__ INFO: \u001b[0mEpoch 40 Step 200/351 lr 0.000800 loss 0.0019 (0.0042) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 04:11:46] __main__ INFO: \u001b[0mEpoch 40 Step 300/351 lr 0.000800 loss 0.0106 (0.0041) acc@1 0.9922 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 04:12:43] __main__ INFO: \u001b[0mEpoch 40 Step 351/351 lr 0.000800 loss 0.0127 (0.0041) acc@1 0.9922 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 04:12:43] __main__ INFO: \u001b[0mElapsed 394.84\n",
      "\u001b[32m[2020-06-23 04:12:43] __main__ INFO: \u001b[0mVal 40\n",
      "\u001b[32m[2020-06-23 04:12:57] __main__ INFO: \u001b[0mEpoch 40 loss 0.2954 acc@1 0.9358 acc@5 0.9966\n",
      "\u001b[32m[2020-06-23 04:12:57] __main__ INFO: \u001b[0mElapsed 13.32\n",
      "\u001b[32m[2020-06-23 04:12:57] __main__ INFO: \u001b[0mTrain 41 14040\n",
      "\u001b[32m[2020-06-23 04:14:49] __main__ INFO: \u001b[0mEpoch 41 Step 100/351 lr 0.000800 loss 0.0021 (0.0046) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 04:16:42] __main__ INFO: \u001b[0mEpoch 41 Step 200/351 lr 0.000800 loss 0.0050 (0.0041) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 04:18:34] __main__ INFO: \u001b[0mEpoch 41 Step 300/351 lr 0.000800 loss 0.0020 (0.0041) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 04:19:32] __main__ INFO: \u001b[0mEpoch 41 Step 351/351 lr 0.000800 loss 0.0024 (0.0043) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 04:19:32] __main__ INFO: \u001b[0mElapsed 394.84\n",
      "\u001b[32m[2020-06-23 04:19:32] __main__ INFO: \u001b[0mVal 41\n",
      "\u001b[32m[2020-06-23 04:19:45] __main__ INFO: \u001b[0mEpoch 41 loss 0.2925 acc@1 0.9352 acc@5 0.9968\n",
      "\u001b[32m[2020-06-23 04:19:45] __main__ INFO: \u001b[0mElapsed 13.25\n",
      "\u001b[32m[2020-06-23 04:19:45] __main__ INFO: \u001b[0mTrain 42 14391\n",
      "\u001b[32m[2020-06-23 04:21:37] __main__ INFO: \u001b[0mEpoch 42 Step 100/351 lr 0.000800 loss 0.0033 (0.0041) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 04:23:30] __main__ INFO: \u001b[0mEpoch 42 Step 200/351 lr 0.000800 loss 0.0020 (0.0038) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 04:25:22] __main__ INFO: \u001b[0mEpoch 42 Step 300/351 lr 0.000800 loss 0.0044 (0.0038) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 04:26:20] __main__ INFO: \u001b[0mEpoch 42 Step 351/351 lr 0.000800 loss 0.0044 (0.0039) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 04:26:20] __main__ INFO: \u001b[0mElapsed 394.94\n",
      "\u001b[32m[2020-06-23 04:26:20] __main__ INFO: \u001b[0mVal 42\n",
      "\u001b[32m[2020-06-23 04:26:33] __main__ INFO: \u001b[0mEpoch 42 loss 0.2860 acc@1 0.9350 acc@5 0.9968\n",
      "\u001b[32m[2020-06-23 04:26:33] __main__ INFO: \u001b[0mElapsed 13.27\n",
      "\u001b[32m[2020-06-23 04:26:33] __main__ INFO: \u001b[0mTrain 43 14742\n",
      "\u001b[32m[2020-06-23 04:28:26] __main__ INFO: \u001b[0mEpoch 43 Step 100/351 lr 0.000800 loss 0.0035 (0.0032) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 04:30:18] __main__ INFO: \u001b[0mEpoch 43 Step 200/351 lr 0.000800 loss 0.0017 (0.0034) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 04:32:11] __main__ INFO: \u001b[0mEpoch 43 Step 300/351 lr 0.000800 loss 0.0029 (0.0034) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 04:33:08] __main__ INFO: \u001b[0mEpoch 43 Step 351/351 lr 0.000800 loss 0.0018 (0.0034) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 04:33:08] __main__ INFO: \u001b[0mElapsed 394.93\n",
      "\u001b[32m[2020-06-23 04:33:08] __main__ INFO: \u001b[0mVal 43\n",
      "\u001b[32m[2020-06-23 04:33:21] __main__ INFO: \u001b[0mEpoch 43 loss 0.2944 acc@1 0.9366 acc@5 0.9964\n",
      "\u001b[32m[2020-06-23 04:33:21] __main__ INFO: \u001b[0mElapsed 13.29\n",
      "\u001b[32m[2020-06-23 04:33:21] __main__ INFO: \u001b[0mTrain 44 15093\n",
      "\u001b[32m[2020-06-23 04:35:14] __main__ INFO: \u001b[0mEpoch 44 Step 100/351 lr 0.000800 loss 0.0029 (0.0034) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 04:37:06] __main__ INFO: \u001b[0mEpoch 44 Step 200/351 lr 0.000800 loss 0.0023 (0.0036) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 04:38:59] __main__ INFO: \u001b[0mEpoch 44 Step 300/351 lr 0.000800 loss 0.0026 (0.0038) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 04:39:56] __main__ INFO: \u001b[0mEpoch 44 Step 351/351 lr 0.000800 loss 0.0032 (0.0038) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 04:39:56] __main__ INFO: \u001b[0mElapsed 394.92\n",
      "\u001b[32m[2020-06-23 04:39:56] __main__ INFO: \u001b[0mVal 44\n",
      "\u001b[32m[2020-06-23 04:40:09] __main__ INFO: \u001b[0mEpoch 44 loss 0.2935 acc@1 0.9350 acc@5 0.9954\n",
      "\u001b[32m[2020-06-23 04:40:09] __main__ INFO: \u001b[0mElapsed 13.30\n",
      "\u001b[32m[2020-06-23 04:40:09] __main__ INFO: \u001b[0mTrain 45 15444\n",
      "\u001b[32m[2020-06-23 04:42:02] __main__ INFO: \u001b[0mEpoch 45 Step 100/351 lr 0.000800 loss 0.0017 (0.0040) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 04:43:55] __main__ INFO: \u001b[0mEpoch 45 Step 200/351 lr 0.000800 loss 0.0051 (0.0041) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 04:45:47] __main__ INFO: \u001b[0mEpoch 45 Step 300/351 lr 0.000800 loss 0.0021 (0.0041) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 04:46:45] __main__ INFO: \u001b[0mEpoch 45 Step 351/351 lr 0.000800 loss 0.0023 (0.0040) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 04:46:45] __main__ INFO: \u001b[0mElapsed 395.08\n",
      "\u001b[32m[2020-06-23 04:46:45] __main__ INFO: \u001b[0mVal 45\n",
      "\u001b[32m[2020-06-23 04:46:58] __main__ INFO: \u001b[0mEpoch 45 loss 0.2826 acc@1 0.9366 acc@5 0.9966\n",
      "\u001b[32m[2020-06-23 04:46:58] __main__ INFO: \u001b[0mElapsed 13.29\n",
      "\u001b[32m[2020-06-23 04:46:58] __main__ INFO: \u001b[0mTrain 46 15795\n",
      "\u001b[32m[2020-06-23 04:48:50] __main__ INFO: \u001b[0mEpoch 46 Step 100/351 lr 0.000800 loss 0.0025 (0.0032) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 04:50:43] __main__ INFO: \u001b[0mEpoch 46 Step 200/351 lr 0.000800 loss 0.0022 (0.0039) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 04:52:36] __main__ INFO: \u001b[0mEpoch 46 Step 300/351 lr 0.000800 loss 0.0021 (0.0042) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 04:53:33] __main__ INFO: \u001b[0mEpoch 46 Step 351/351 lr 0.000800 loss 0.0043 (0.0042) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 04:53:33] __main__ INFO: \u001b[0mElapsed 395.08\n",
      "\u001b[32m[2020-06-23 04:53:33] __main__ INFO: \u001b[0mVal 46\n",
      "\u001b[32m[2020-06-23 04:53:46] __main__ INFO: \u001b[0mEpoch 46 loss 0.3060 acc@1 0.9334 acc@5 0.9968\n",
      "\u001b[32m[2020-06-23 04:53:46] __main__ INFO: \u001b[0mElapsed 13.29\n",
      "\u001b[32m[2020-06-23 04:53:46] __main__ INFO: \u001b[0mTrain 47 16146\n",
      "\u001b[32m[2020-06-23 04:55:39] __main__ INFO: \u001b[0mEpoch 47 Step 100/351 lr 0.000800 loss 0.0043 (0.0042) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 04:57:31] __main__ INFO: \u001b[0mEpoch 47 Step 200/351 lr 0.000800 loss 0.0022 (0.0041) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 04:59:24] __main__ INFO: \u001b[0mEpoch 47 Step 300/351 lr 0.000800 loss 0.0041 (0.0043) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 05:00:21] __main__ INFO: \u001b[0mEpoch 47 Step 351/351 lr 0.000800 loss 0.0020 (0.0041) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 05:00:21] __main__ INFO: \u001b[0mElapsed 395.02\n",
      "\u001b[32m[2020-06-23 05:00:21] __main__ INFO: \u001b[0mVal 47\n",
      "\u001b[32m[2020-06-23 05:00:35] __main__ INFO: \u001b[0mEpoch 47 loss 0.2955 acc@1 0.9374 acc@5 0.9966\n",
      "\u001b[32m[2020-06-23 05:00:35] __main__ INFO: \u001b[0mElapsed 13.28\n",
      "\u001b[32m[2020-06-23 05:00:35] __main__ INFO: \u001b[0mTrain 48 16497\n",
      "\u001b[32m[2020-06-23 05:02:27] __main__ INFO: \u001b[0mEpoch 48 Step 100/351 lr 0.000800 loss 0.0018 (0.0038) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 05:04:20] __main__ INFO: \u001b[0mEpoch 48 Step 200/351 lr 0.000800 loss 0.0024 (0.0042) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 05:06:12] __main__ INFO: \u001b[0mEpoch 48 Step 300/351 lr 0.000800 loss 0.0210 (0.0044) acc@1 0.9844 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 05:07:10] __main__ INFO: \u001b[0mEpoch 48 Step 351/351 lr 0.000800 loss 0.0054 (0.0044) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 05:07:10] __main__ INFO: \u001b[0mElapsed 395.10\n",
      "\u001b[32m[2020-06-23 05:07:10] __main__ INFO: \u001b[0mVal 48\n",
      "\u001b[32m[2020-06-23 05:07:23] __main__ INFO: \u001b[0mEpoch 48 loss 0.3007 acc@1 0.9364 acc@5 0.9960\n",
      "\u001b[32m[2020-06-23 05:07:23] __main__ INFO: \u001b[0mElapsed 13.29\n",
      "\u001b[32m[2020-06-23 05:07:23] __main__ INFO: \u001b[0mTrain 49 16848\n",
      "\u001b[32m[2020-06-23 05:09:16] __main__ INFO: \u001b[0mEpoch 49 Step 100/351 lr 0.000800 loss 0.0020 (0.0037) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 05:11:08] __main__ INFO: \u001b[0mEpoch 49 Step 200/351 lr 0.000800 loss 0.0055 (0.0047) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 05:13:01] __main__ INFO: \u001b[0mEpoch 49 Step 300/351 lr 0.000800 loss 0.0023 (0.0046) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 05:13:58] __main__ INFO: \u001b[0mEpoch 49 Step 351/351 lr 0.000800 loss 0.0025 (0.0046) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 05:13:58] __main__ INFO: \u001b[0mElapsed 395.03\n",
      "\u001b[32m[2020-06-23 05:13:58] __main__ INFO: \u001b[0mVal 49\n",
      "\u001b[32m[2020-06-23 05:14:11] __main__ INFO: \u001b[0mEpoch 49 loss 0.2973 acc@1 0.9372 acc@5 0.9966\n",
      "\u001b[32m[2020-06-23 05:14:11] __main__ INFO: \u001b[0mElapsed 13.30\n",
      "\u001b[32m[2020-06-23 05:14:11] __main__ INFO: \u001b[0mTrain 50 17199\n",
      "\u001b[32m[2020-06-23 05:16:04] __main__ INFO: \u001b[0mEpoch 50 Step 100/351 lr 0.000800 loss 0.0024 (0.0047) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 05:17:56] __main__ INFO: \u001b[0mEpoch 50 Step 200/351 lr 0.000800 loss 0.0043 (0.0043) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 05:19:49] __main__ INFO: \u001b[0mEpoch 50 Step 300/351 lr 0.000800 loss 0.0111 (0.0043) acc@1 0.9922 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 05:20:46] __main__ INFO: \u001b[0mEpoch 50 Step 351/351 lr 0.000800 loss 0.0024 (0.0042) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-06-23 05:20:46] __main__ INFO: \u001b[0mElapsed 395.08\n",
      "\u001b[32m[2020-06-23 05:20:46] __main__ INFO: \u001b[0mVal 50\n",
      "\u001b[32m[2020-06-23 05:21:00] __main__ INFO: \u001b[0mEpoch 50 loss 0.2960 acc@1 0.9376 acc@5 0.9966\n",
      "\u001b[32m[2020-06-23 05:21:00] __main__ INFO: \u001b[0mElapsed 13.27\n",
      "\u001b[32m[2020-06-23 05:21:00] fvcore.common.checkpoint INFO: \u001b[0mSaving checkpoint to /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_5/exp00_resume400_50/checkpoint_00050.pth\n"
     ]
    }
   ],
   "source": [
    "# Resume training with the un-augmented data\n",
    "os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "!python train.py --config /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_5/exp00/config.yaml \\\n",
    "    train.checkpoint /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_5/exp00/checkpoint_00400.pth \\\n",
    "    model.wrn.depth 28 \\\n",
    "    model.wrn.widening_factor 10 \\\n",
    "    train.batch_size 128 \\\n",
    "    train.base_lr .0008 \\\n",
    "    dataset.name CIFAR10 \\\n",
    "    train.output_dir /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_5/exp00_resume400_50 \\\n",
    "    scheduler.epochs 50\n",
    "\n",
    "#### Set LEARNING RATE based on ending LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-06-23 12:42:38] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_5/exp00_resume400_50/checkpoint_00050.pth\n",
      "Files already downloaded and verified\n",
      "100%|| 40/40 [00:51<00:00,  1.28s/it]\n",
      "\u001b[32m[2020-06-23 12:43:30] __main__ INFO: \u001b[0mElapsed 51.36\n",
      "\u001b[32m[2020-06-23 12:43:30] __main__ INFO: \u001b[0mLoss 0.2627 Accuracy 0.9403\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10 test dataset \n",
    "# write the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/wrn.yaml \\\n",
    "    model.wrn.depth 28 \\\n",
    "    model.wrn.widening_factor 10 \\\n",
    "    test.checkpoint /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_5/exp00_resume400_50/checkpoint_00050.pth \\\n",
    "    test.output_dir /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_5/exp00_resume400_50/test_results_0050_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-06-23 12:47:22] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_5//exp00_resume400_50/checkpoint_00050.pth\n",
      "CIFAR 10.1\n",
      "100%|| 8/8 [00:10<00:00,  1.34s/it]\n",
      "\u001b[32m[2020-06-23 12:47:33] __main__ INFO: \u001b[0mElapsed 10.69\n",
      "\u001b[32m[2020-06-23 12:47:33] __main__ INFO: \u001b[0mLoss 0.6479 Accuracy 0.8520\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10.1 test dataset \n",
    "# write the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/wrn.yaml \\\n",
    "    model.wrn.depth 28 \\\n",
    "    model.wrn.widening_factor 10 \\\n",
    "    dataset.name CIFAR101 \\\n",
    "    test.checkpoint /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_5//exp00_resume400_50/checkpoint_00050.pth \\\n",
    "    test.output_dir /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_5/exp00_resume400_50/test_results_0050_cifar101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-06-23 13:04:05] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_5/exp00/checkpoint_00400.pth\n",
      "CIFAR 10.1\n",
      "100%|| 8/8 [00:10<00:00,  1.33s/it]\n",
      "\u001b[32m[2020-06-23 13:04:16] __main__ INFO: \u001b[0mElapsed 10.63\n",
      "\u001b[32m[2020-06-23 13:04:16] __main__ INFO: \u001b[0mLoss 0.8676 Accuracy 0.8145\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10 test dataset \n",
    "# write the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/wrn.yaml \\\n",
    "    model.wrn.depth 28 \\\n",
    "    model.wrn.widening_factor 10 \\\n",
    "    dataset.name CIFAR101 \\\n",
    "    test.checkpoint /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_5/exp00/checkpoint_00400.pth \\\n",
    "    test.output_dir /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_5/exp00/test_results_0400_cifar101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-06-23 13:09:51] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_5/exp00/checkpoint_00400.pth\n",
      "Files already downloaded and verified\n",
      "100%|| 40/40 [00:51<00:00,  1.29s/it]\n",
      "\u001b[32m[2020-06-23 13:10:44] __main__ INFO: \u001b[0mElapsed 51.42\n",
      "\u001b[32m[2020-06-23 13:10:44] __main__ INFO: \u001b[0mLoss 0.3942 Accuracy 0.9119\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10.1 test dataset \n",
    "# write the results to the test output directory specified.\n",
    "os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "!python evaluate.py --config configs/cifar/wrn.yaml \\\n",
    "    model.wrn.depth 28 \\\n",
    "    model.wrn.widening_factor 10 \\\n",
    "    test.checkpoint /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_5/exp00/checkpoint_00400.pth \\\n",
    "    test.output_dir /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_5/exp00/test_results_0400_cifar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Testset</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Original_Accuracy</th>\n",
       "      <th>Original_CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wrn_28_10</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2299</td>\n",
       "      <td>0.9311</td>\n",
       "      <td>95.9</td>\n",
       "      <td>(95.5, 96.3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wrn_28_10</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>200</td>\n",
       "      <td>0.1760</td>\n",
       "      <td>0.9578</td>\n",
       "      <td>95.9</td>\n",
       "      <td>(95.5, 96.3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wrn_28_10</td>\n",
       "      <td>cifar10.1</td>\n",
       "      <td>200</td>\n",
       "      <td>0.3896</td>\n",
       "      <td>0.8975</td>\n",
       "      <td>89.7</td>\n",
       "      <td>(88.3, 91.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model    Testset  Epoch    Loss  Accuracy  Original_Accuracy  \\\n",
       "0  wrn_28_10    cifar10    100  0.2299    0.9311               95.9   \n",
       "1  wrn_28_10    cifar10    200  0.1760    0.9578               95.9   \n",
       "2  wrn_28_10  cifar10.1    200  0.3896    0.8975               89.7   \n",
       "\n",
       "    Original_CI  \n",
       "0  (95.5, 96.3)  \n",
       "1  (95.5, 96.3)  \n",
       "2  (88.3, 91.0)  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write the results to a CSV file so that we can analyze later.\n",
    "import pandas as pd\n",
    "\n",
    "results = {'Model': ['wrn_28_10', 'wrn_28_10', 'wrn_28_10'],\n",
    "           'Testset': ['cifar10', 'cifar10', 'cifar10.1'],\n",
    "           'Epoch': [100, 200, 200],\n",
    "           'Loss': [0.2299, 0.1760, 0.3896],\n",
    "           'Accuracy': [0.9311, 0.9578, 0.8975],\n",
    "           'Original_Accuracy': [95.9, 95.9, 89.7],\n",
    "           'Original_CI': [(95.5, 96.3), (95.5, 96.3), (88.3, 91.0)]\n",
    "           }\n",
    "\n",
    "df = pd.DataFrame(results, columns = ['Model', 'Testset', 'Epoch', 'Loss', 'Accuracy', \n",
    "                                      'Original_Accuracy', 'Original_CI'])\n",
    "\n",
    "df.to_csv('/home/ec2-user/SageMaker/experiments/wrn_28_10/exp00/results.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Testset</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Original_Accuracy</th>\n",
       "      <th>Original_CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wrn_28_10_ra_2_5</td>\n",
       "      <td>400</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>0.3942</td>\n",
       "      <td>0.9119</td>\n",
       "      <td>95.9</td>\n",
       "      <td>(95.5, 96.3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wrn_28_10_ra_2_5</td>\n",
       "      <td>300</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.9128</td>\n",
       "      <td>95.9</td>\n",
       "      <td>(95.5, 96.3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wrn_28_10_ra_2_5</td>\n",
       "      <td>400</td>\n",
       "      <td>cifar10.1</td>\n",
       "      <td>0.8676</td>\n",
       "      <td>0.8145</td>\n",
       "      <td>89.7</td>\n",
       "      <td>(88.3, 91.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wrn_28_10_ra_2_5</td>\n",
       "      <td>300</td>\n",
       "      <td>cifar10.1</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.807</td>\n",
       "      <td>89.7</td>\n",
       "      <td>(88.3, 91.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wrn_28_10_ra_2_5_refined400</td>\n",
       "      <td>50</td>\n",
       "      <td>cifar10.1</td>\n",
       "      <td>0.6479</td>\n",
       "      <td>0.852</td>\n",
       "      <td>89.7</td>\n",
       "      <td>(88.3, 91.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wrn_28_10_ra_2_5_refined400</td>\n",
       "      <td>50</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>0.2627</td>\n",
       "      <td>0.9403</td>\n",
       "      <td>95.9</td>\n",
       "      <td>(95.5, 96.3)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model Epoch    Testset    Loss Accuracy  \\\n",
       "0             wrn_28_10_ra_2_5   400    cifar10  0.3942   0.9119   \n",
       "1             wrn_28_10_ra_2_5   300    cifar10    0.38   0.9128   \n",
       "2             wrn_28_10_ra_2_5   400  cifar10.1  0.8676   0.8145   \n",
       "3             wrn_28_10_ra_2_5   300  cifar10.1   0.815    0.807   \n",
       "4  wrn_28_10_ra_2_5_refined400    50  cifar10.1  0.6479    0.852   \n",
       "5  wrn_28_10_ra_2_5_refined400    50    cifar10  0.2627   0.9403   \n",
       "\n",
       "   Original_Accuracy   Original_CI  \n",
       "0               95.9  (95.5, 96.3)  \n",
       "1               95.9  (95.5, 96.3)  \n",
       "2               89.7  (88.3, 91.0)  \n",
       "3               89.7  (88.3, 91.0)  \n",
       "4               89.7  (88.3, 91.0)  \n",
       "5               95.9  (95.5, 96.3)  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "a = pd.Series(['wrn_28_10_ra_2_5', 400, 'cifar10', 0.3942, 0.9119])\n",
    "b = pd.Series(['wrn_28_10_ra_2_5', 300, 'cifar10', 0.3800, 0.9128])\n",
    "c = pd.Series(['wrn_28_10_ra_2_5', 400, 'cifar10.1', 0.8676, 0.8145])\n",
    "d = pd.Series(['wrn_28_10_ra_2_5', 300, 'cifar10.1', 0.8150, 0.8070])\n",
    "    \n",
    "e = pd.Series(['wrn_28_10_ra_2_5_refined400', 50, 'cifar10.1', 0.6479, 0.8520])\n",
    "f = pd.Series(['wrn_28_10_ra_2_5_refined400', 50, 'cifar10', 0.2627, 0.9403])\n",
    "#g = pd.Series(['resnet_basic_32_ra_2_5_refined300', 150, 'cifar10', 0.4499, 0.8795])\n",
    "#h = pd.Series(['resnet_basic_32_ra_2_5_refined300', 150, 'cifar10.1', 0.8206, 0.7710])\n",
    "               \n",
    "df_results = pd.concat([a,b,c,d,e,f], axis=1).T\n",
    "df_results.columns = ['Model', 'Epoch', 'Testset', 'Loss', 'Accuracy']\n",
    "\n",
    "df_results['Original_Accuracy'] = df_results.apply((lambda row: 95.9 if row[2] == 'cifar10' else 89.7), axis=1)\n",
    "df_results['Original_CI'] = df_results.apply((lambda row: (95.5, 96.3) if row[2] == 'cifar10' else (88.3, 91.0)), axis=1)\n",
    "\n",
    "df_results.to_csv('/home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_5/results.csv')\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['preds', 'probs', 'labels', 'loss', 'acc']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ -7.153804  ,  -0.1832159 ,  -0.69570637, ...,  -0.50926757,\n",
       "         -5.526208  , -12.987257  ],\n",
       "       [  2.862379  ,   7.963458  ,  -6.603018  , ...,  -4.740323  ,\n",
       "         25.90399   ,  -0.52988565],\n",
       "       [  4.25749   ,   8.408992  ,  -4.3299227 , ...,  -2.3715498 ,\n",
       "         13.468082  ,   4.5792727 ],\n",
       "       ...,\n",
       "       [ -4.7270765 ,  -1.2400844 ,   1.3852903 , ...,  -0.51062894,\n",
       "         -3.399443  ,  -2.4969094 ],\n",
       "       [ -2.7640457 ,  14.635863  ,   6.7449965 , ...,  -1.3011913 ,\n",
       "         -3.036379  ,  -7.061736  ],\n",
       "       [ -2.6933427 ,   1.8961854 ,  -3.6396854 , ...,  18.63456   ,\n",
       "         -2.7524152 ,  -3.2204888 ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Peak inside the output file for predictions\n",
    "import numpy as np\n",
    "output = '/home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_5/exp00/test_results_0400/predictions.npz'\n",
    "npzfile = np.load(output)\n",
    "print(npzfile.files)\n",
    "npzfile['preds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the model checkpoints, configs, and results to S3 \n",
    "bucket='sagemaker-may29'\n",
    "prefix = 'sagemaker/results/original-models/wrn_28_10_ra_2_5'\n",
    "path = '/home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_5'\n",
    "\n",
    "s3_resource = boto3.resource(\"s3\", region_name=\"us-east-2\")\n",
    "\n",
    "def uploadDirectory(local_path,bucket_name,s3_prefix):\n",
    "\n",
    "    my_bucket = s3_resource.Bucket(bucket_name)\n",
    "    \n",
    "    for path, subdirs, files in os.walk(local_path):\n",
    "        path = path.replace(\"\\\\\",\"/\")\n",
    "        directory_name = path.replace(local_path,\"\")\n",
    "        for file in files:\n",
    "            #print(\"Local File:\", os.path.join(path, file))\n",
    "            #print(\"      Dest:\", s3_prefix+directory_name+'/'+file)\n",
    "            my_bucket.upload_file(os.path.join(path, file), s3_prefix+directory_name+'/'+file)\n",
    "    \n",
    "uploadDirectory(path,bucket,prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
