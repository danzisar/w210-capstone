{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy \n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wide Residual Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 1)) (1.18.1)\n",
      "Requirement already satisfied: torch>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 2)) (1.4.0)\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 3)) (0.5.0)\n",
      "Requirement already satisfied: fvcore in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (0.1.1.post20200619)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 5)) (4.44.1)\n",
      "Requirement already satisfied: yacs in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 6)) (0.1.7)\n",
      "Requirement already satisfied: apex from git+https://github.com/NVIDIA/apex.git#egg=apex in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 7)) (0.1)\n",
      "Requirement already satisfied: termcolor in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 8)) (1.1.0)\n",
      "Requirement already satisfied: thop<0.0.31.post2004070130 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 9)) (0.0.31.post2001170342)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 3)) (1.14.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 3)) (7.0.0)\n",
      "Requirement already satisfied: tabulate in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from fvcore->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (0.8.7)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from fvcore->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (5.3.1)\n",
      "Requirement already satisfied: portalocker in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from fvcore->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (1.7.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Sagemaker Notebook must be of type, conda_pytorch_p36\n",
    "\n",
    "!pip install -r '/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (2.2.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.18.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.29.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.14.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.9.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (3.2.2)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.34.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (46.1.3.post20200330)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.6.0.post3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (2.23.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (3.12.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.18.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.1.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard) (3.4.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (1.5.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (1.25.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.4.5.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard) (2.2.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Need to add this to requirements.txt\n",
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model per the settings specified in the original RESNET paper\n",
    "# os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "# !python train.py --config configs/cifar/wrn.yaml \\\n",
    "#     model.wrn.depth 28 \\\n",
    "#     model.wrn.widening_factor 10 \\\n",
    "#     train.batch_size 128 \\\n",
    "#     train.base_lr 0.1 \\\n",
    "#     train.output_dir /home/ec2-user/SageMaker/experiments/wrn_28_10/exp00 \\\n",
    "#     scheduler.epochs 200\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-06-20 17:54:34] __main__ INFO: \u001b[0mdevice: cuda\n",
      "cudnn:\n",
      "  benchmark: True\n",
      "  deterministic: False\n",
      "dataset:\n",
      "  name: CIFAR10_RA_2_5\n",
      "  dataset_dir: ''\n",
      "  image_size: 32\n",
      "  n_channels: 3\n",
      "  n_classes: 10\n",
      "model:\n",
      "  type: cifar\n",
      "  name: wrn\n",
      "  init_mode: kaiming_fan_in\n",
      "  vgg:\n",
      "    n_channels: [64, 128, 256, 512, 512]\n",
      "    n_layers: [2, 2, 3, 3, 3]\n",
      "    use_bn: True\n",
      "  resnet:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "  resnet_preact:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "  wrn:\n",
      "    depth: 28\n",
      "    initial_channels: 16\n",
      "    widening_factor: 10\n",
      "    drop_rate: 0.0\n",
      "  densenet:\n",
      "    depth: 100\n",
      "    n_blocks: [6, 12, 24, 16]\n",
      "    block_type: bottleneck\n",
      "    growth_rate: 12\n",
      "    drop_rate: 0.0\n",
      "    compression_rate: 0.5\n",
      "  pyramidnet:\n",
      "    depth: 272\n",
      "    n_blocks: [3, 24, 36, 3]\n",
      "    initial_channels: 16\n",
      "    block_type: bottleneck\n",
      "    alpha: 200\n",
      "  resnext:\n",
      "    depth: 29\n",
      "    n_blocks: [3, 4, 6, 3]\n",
      "    initial_channels: 64\n",
      "    cardinality: 8\n",
      "    base_channels: 4\n",
      "  shake_shake:\n",
      "    depth: 26\n",
      "    initial_channels: 96\n",
      "    shake_forward: True\n",
      "    shake_backward: True\n",
      "    shake_image: True\n",
      "  se_resnet_preact:\n",
      "    depth: 110\n",
      "    initial_channels: 16\n",
      "    se_reduction: 16\n",
      "    block_type: basic\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "train:\n",
      "  checkpoint: ''\n",
      "  resume: False\n",
      "  precision: O0\n",
      "  batch_size: 128\n",
      "  subdivision: 1\n",
      "  optimizer: sgd\n",
      "  base_lr: 0.1\n",
      "  momentum: 0.9\n",
      "  nesterov: True\n",
      "  weight_decay: 0.0005\n",
      "  no_weight_decay_on_bn: False\n",
      "  gradient_clip: 0\n",
      "  start_epoch: 0\n",
      "  seed: 0\n",
      "  val_first: True\n",
      "  val_period: 1\n",
      "  val_ratio: 0.1\n",
      "  use_test_as_val: False\n",
      "  output_dir: /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_5/exp00\n",
      "  log_period: 100\n",
      "  checkpoint_period: 100\n",
      "  use_tensorboard: True\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: True\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "  distributed: False\n",
      "  dist:\n",
      "    backend: nccl\n",
      "    init_method: env://\n",
      "    world_size: -1\n",
      "    node_rank: -1\n",
      "    local_rank: 0\n",
      "    use_sync_bn: False\n",
      "tensorboard:\n",
      "  train_images: False\n",
      "  val_images: False\n",
      "  model_params: False\n",
      "optim:\n",
      "  adam:\n",
      "    betas: (0.9, 0.999)\n",
      "  lars:\n",
      "    eps: 1e-09\n",
      "    threshold: 0.01\n",
      "  adabound:\n",
      "    betas: (0.9, 0.999)\n",
      "    final_lr: 0.1\n",
      "    gamma: 0.001\n",
      "scheduler:\n",
      "  epochs: 400\n",
      "  warmup:\n",
      "    type: none\n",
      "    epochs: 0\n",
      "    start_factor: 0.001\n",
      "    exponent: 4\n",
      "  type: multistep\n",
      "  milestones: [60, 120, 160]\n",
      "  lr_decay: 0.2\n",
      "  lr_min_factor: 0.001\n",
      "  T0: 10\n",
      "  T_mul: 1.0\n",
      "validation:\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: False\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "augmentation:\n",
      "  use_random_crop: True\n",
      "  use_random_horizontal_flip: True\n",
      "  use_cutout: False\n",
      "  use_random_erasing: False\n",
      "  use_dual_cutout: False\n",
      "  use_mixup: False\n",
      "  use_ricap: False\n",
      "  use_cutmix: False\n",
      "  use_label_smoothing: False\n",
      "  random_crop:\n",
      "    padding: 4\n",
      "    fill: 0\n",
      "    padding_mode: constant\n",
      "  random_horizontal_flip:\n",
      "    prob: 0.5\n",
      "  cutout:\n",
      "    prob: 1.0\n",
      "    mask_size: 16\n",
      "    cut_inside: False\n",
      "    mask_color: 0\n",
      "    dual_cutout_alpha: 0.1\n",
      "  random_erasing:\n",
      "    prob: 0.5\n",
      "    area_ratio_range: [0.02, 0.4]\n",
      "    min_aspect_ratio: 0.3\n",
      "    max_attempt: 20\n",
      "  mixup:\n",
      "    alpha: 1.0\n",
      "  ricap:\n",
      "    beta: 0.3\n",
      "  cutmix:\n",
      "    alpha: 1.0\n",
      "  label_smoothing:\n",
      "    epsilon: 0.1\n",
      "tta:\n",
      "  use_resize: False\n",
      "  use_center_crop: False\n",
      "  resize: 256\n",
      "test:\n",
      "  checkpoint: ''\n",
      "  output_dir: ''\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    pin_memory: False\n",
      "\u001b[32m[2020-06-20 17:54:34] __main__ INFO: \u001b[0menv_info:\n",
      "  pytorch_version: 1.4.0\n",
      "  cuda_version: 10.1\n",
      "  cudnn_version: 7603\n",
      "  num_gpus: 1\n",
      "  gpu_name: Tesla K80\n",
      "  gpu_capability: 3.7\n",
      "(50000, 32, 32, 3)\n",
      "\u001b[32m[2020-06-20 17:54:41] __main__ INFO: \u001b[0mMACs  : 5.25G\n",
      "\u001b[32m[2020-06-20 17:54:41] __main__ INFO: \u001b[0m#params: 36.48M\n",
      "Selected optimization level O0:  Pure FP32 training.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n",
      "\u001b[32m[2020-06-20 17:54:41] __main__ INFO: \u001b[0mVal 0\n",
      "\u001b[32m[2020-06-20 17:55:00] __main__ INFO: \u001b[0mEpoch 0 loss 202.6672 acc@1 0.1016 acc@5 0.4966\n",
      "\u001b[32m[2020-06-20 17:55:00] __main__ INFO: \u001b[0mElapsed 19.73\n",
      "\u001b[32m[2020-06-20 17:55:00] __main__ INFO: \u001b[0mTrain 1 0\n",
      "\u001b[32m[2020-06-20 17:56:58] __main__ INFO: \u001b[0mEpoch 1 Step 100/351 lr 0.100000 loss 2.1510 (2.4081) acc@1 0.1328 (0.1322) acc@5 0.6719 (0.5876)\n",
      "\u001b[32m[2020-06-20 17:58:51] __main__ INFO: \u001b[0mEpoch 1 Step 200/351 lr 0.100000 loss 2.1154 (2.2892) acc@1 0.1953 (0.1557) acc@5 0.7188 (0.6259)\n",
      "\u001b[32m[2020-06-20 18:00:44] __main__ INFO: \u001b[0mEpoch 1 Step 300/351 lr 0.100000 loss 1.9807 (2.2212) acc@1 0.1719 (0.1752) acc@5 0.7656 (0.6501)\n",
      "\u001b[32m[2020-06-20 18:01:41] __main__ INFO: \u001b[0mEpoch 1 Step 351/351 lr 0.100000 loss 1.9717 (2.1956) acc@1 0.2500 (0.1836) acc@5 0.7266 (0.6605)\n",
      "\u001b[32m[2020-06-20 18:01:41] __main__ INFO: \u001b[0mElapsed 400.99\n",
      "\u001b[32m[2020-06-20 18:01:41] __main__ INFO: \u001b[0mVal 1\n",
      "\u001b[32m[2020-06-20 18:01:54] __main__ INFO: \u001b[0mEpoch 1 loss 2.1258 acc@1 0.1988 acc@5 0.7152\n",
      "\u001b[32m[2020-06-20 18:01:54] __main__ INFO: \u001b[0mElapsed 13.24\n",
      "\u001b[32m[2020-06-20 18:01:54] __main__ INFO: \u001b[0mTrain 2 351\n",
      "\u001b[32m[2020-06-20 18:03:47] __main__ INFO: \u001b[0mEpoch 2 Step 100/351 lr 0.100000 loss 2.0602 (1.9899) acc@1 0.2266 (0.2559) acc@5 0.6797 (0.7316)\n",
      "\u001b[32m[2020-06-20 18:05:40] __main__ INFO: \u001b[0mEpoch 2 Step 200/351 lr 0.100000 loss 1.7957 (1.9634) acc@1 0.3047 (0.2657) acc@5 0.8281 (0.7408)\n",
      "\u001b[32m[2020-06-20 18:07:33] __main__ INFO: \u001b[0mEpoch 2 Step 300/351 lr 0.100000 loss 1.6749 (1.9217) acc@1 0.3828 (0.2831) acc@5 0.8125 (0.7513)\n",
      "\u001b[32m[2020-06-20 18:08:31] __main__ INFO: \u001b[0mEpoch 2 Step 351/351 lr 0.100000 loss 1.7919 (1.9058) acc@1 0.2969 (0.2895) acc@5 0.7969 (0.7532)\n",
      "\u001b[32m[2020-06-20 18:08:31] __main__ INFO: \u001b[0mElapsed 396.19\n",
      "\u001b[32m[2020-06-20 18:08:31] __main__ INFO: \u001b[0mVal 2\n",
      "\u001b[32m[2020-06-20 18:08:44] __main__ INFO: \u001b[0mEpoch 2 loss 2.2456 acc@1 0.2312 acc@5 0.6886\n",
      "\u001b[32m[2020-06-20 18:08:44] __main__ INFO: \u001b[0mElapsed 13.27\n",
      "\u001b[32m[2020-06-20 18:08:44] __main__ INFO: \u001b[0mTrain 3 702\n",
      "\u001b[32m[2020-06-20 18:10:37] __main__ INFO: \u001b[0mEpoch 3 Step 100/351 lr 0.100000 loss 1.6985 (1.7743) acc@1 0.4062 (0.3498) acc@5 0.7734 (0.7873)\n",
      "\u001b[32m[2020-06-20 18:12:30] __main__ INFO: \u001b[0mEpoch 3 Step 200/351 lr 0.100000 loss 1.6414 (1.7346) acc@1 0.3828 (0.3616) acc@5 0.8359 (0.7892)\n",
      "\u001b[32m[2020-06-20 18:14:23] __main__ INFO: \u001b[0mEpoch 3 Step 300/351 lr 0.100000 loss 1.7485 (1.7047) acc@1 0.3281 (0.3702) acc@5 0.7734 (0.7944)\n",
      "\u001b[32m[2020-06-20 18:15:20] __main__ INFO: \u001b[0mEpoch 3 Step 351/351 lr 0.100000 loss 1.6114 (1.6947) acc@1 0.3984 (0.3733) acc@5 0.8359 (0.7958)\n",
      "\u001b[32m[2020-06-20 18:15:20] __main__ INFO: \u001b[0mElapsed 396.42\n",
      "\u001b[32m[2020-06-20 18:15:20] __main__ INFO: \u001b[0mVal 3\n",
      "\u001b[32m[2020-06-20 18:15:34] __main__ INFO: \u001b[0mEpoch 3 loss 2.1775 acc@1 0.3030 acc@5 0.7352\n",
      "\u001b[32m[2020-06-20 18:15:34] __main__ INFO: \u001b[0mElapsed 13.30\n",
      "\u001b[32m[2020-06-20 18:15:34] __main__ INFO: \u001b[0mTrain 4 1053\n",
      "\u001b[32m[2020-06-20 18:17:27] __main__ INFO: \u001b[0mEpoch 4 Step 100/351 lr 0.100000 loss 1.6158 (1.5913) acc@1 0.3906 (0.4084) acc@5 0.7891 (0.8135)\n",
      "\u001b[32m[2020-06-20 18:19:20] __main__ INFO: \u001b[0mEpoch 4 Step 200/351 lr 0.100000 loss 1.4835 (1.5763) acc@1 0.5234 (0.4163) acc@5 0.8281 (0.8134)\n",
      "\u001b[32m[2020-06-20 18:21:13] __main__ INFO: \u001b[0mEpoch 4 Step 300/351 lr 0.100000 loss 1.5461 (1.5610) acc@1 0.4453 (0.4220) acc@5 0.8438 (0.8147)\n",
      "\u001b[32m[2020-06-20 18:22:10] __main__ INFO: \u001b[0mEpoch 4 Step 351/351 lr 0.100000 loss 1.3948 (1.5548) acc@1 0.4922 (0.4252) acc@5 0.8516 (0.8149)\n",
      "\u001b[32m[2020-06-20 18:22:10] __main__ INFO: \u001b[0mElapsed 396.51\n",
      "\u001b[32m[2020-06-20 18:22:10] __main__ INFO: \u001b[0mVal 4\n",
      "\u001b[32m[2020-06-20 18:22:23] __main__ INFO: \u001b[0mEpoch 4 loss 1.5966 acc@1 0.4272 acc@5 0.8194\n",
      "\u001b[32m[2020-06-20 18:22:23] __main__ INFO: \u001b[0mElapsed 13.29\n",
      "\u001b[32m[2020-06-20 18:22:23] __main__ INFO: \u001b[0mTrain 5 1404\n",
      "\u001b[32m[2020-06-20 18:24:16] __main__ INFO: \u001b[0mEpoch 5 Step 100/351 lr 0.100000 loss 1.5597 (1.4849) acc@1 0.4219 (0.4522) acc@5 0.8203 (0.8242)\n",
      "\u001b[32m[2020-06-20 18:26:09] __main__ INFO: \u001b[0mEpoch 5 Step 200/351 lr 0.100000 loss 1.5333 (1.4762) acc@1 0.3984 (0.4559) acc@5 0.8672 (0.8230)\n",
      "\u001b[32m[2020-06-20 18:28:02] __main__ INFO: \u001b[0mEpoch 5 Step 300/351 lr 0.100000 loss 1.2125 (1.4659) acc@1 0.5391 (0.4590) acc@5 0.8906 (0.8239)\n",
      "\u001b[32m[2020-06-20 18:29:00] __main__ INFO: \u001b[0mEpoch 5 Step 351/351 lr 0.100000 loss 1.5740 (1.4614) acc@1 0.4375 (0.4611) acc@5 0.8047 (0.8236)\n",
      "\u001b[32m[2020-06-20 18:29:00] __main__ INFO: \u001b[0mElapsed 396.46\n",
      "\u001b[32m[2020-06-20 18:29:00] __main__ INFO: \u001b[0mVal 5\n",
      "\u001b[32m[2020-06-20 18:29:13] __main__ INFO: \u001b[0mEpoch 5 loss 1.5297 acc@1 0.4570 acc@5 0.8234\n",
      "\u001b[32m[2020-06-20 18:29:13] __main__ INFO: \u001b[0mElapsed 13.30\n",
      "\u001b[32m[2020-06-20 18:29:13] __main__ INFO: \u001b[0mTrain 6 1755\n",
      "\u001b[32m[2020-06-20 18:31:06] __main__ INFO: \u001b[0mEpoch 6 Step 100/351 lr 0.100000 loss 1.3618 (1.3922) acc@1 0.5312 (0.4936) acc@5 0.8594 (0.8339)\n",
      "\u001b[32m[2020-06-20 18:32:59] __main__ INFO: \u001b[0mEpoch 6 Step 200/351 lr 0.100000 loss 1.3761 (1.3940) acc@1 0.5078 (0.4917) acc@5 0.8203 (0.8341)\n",
      "\u001b[32m[2020-06-20 18:34:52] __main__ INFO: \u001b[0mEpoch 6 Step 300/351 lr 0.100000 loss 1.3819 (1.3931) acc@1 0.5078 (0.4898) acc@5 0.8516 (0.8337)\n",
      "\u001b[32m[2020-06-20 18:35:50] __main__ INFO: \u001b[0mEpoch 6 Step 351/351 lr 0.100000 loss 1.3744 (1.3937) acc@1 0.5234 (0.4889) acc@5 0.8594 (0.8325)\n",
      "\u001b[32m[2020-06-20 18:35:50] __main__ INFO: \u001b[0mElapsed 396.60\n",
      "\u001b[32m[2020-06-20 18:35:50] __main__ INFO: \u001b[0mVal 6\n",
      "\u001b[32m[2020-06-20 18:36:03] __main__ INFO: \u001b[0mEpoch 6 loss 1.5580 acc@1 0.4416 acc@5 0.8222\n",
      "\u001b[32m[2020-06-20 18:36:03] __main__ INFO: \u001b[0mElapsed 13.27\n",
      "\u001b[32m[2020-06-20 18:36:03] __main__ INFO: \u001b[0mTrain 7 2106\n",
      "\u001b[32m[2020-06-20 18:37:56] __main__ INFO: \u001b[0mEpoch 7 Step 100/351 lr 0.100000 loss 1.3603 (1.3640) acc@1 0.4453 (0.4986) acc@5 0.8281 (0.8306)\n",
      "\u001b[32m[2020-06-20 18:39:49] __main__ INFO: \u001b[0mEpoch 7 Step 200/351 lr 0.100000 loss 1.3983 (1.3594) acc@1 0.4531 (0.5012) acc@5 0.8203 (0.8354)\n",
      "\u001b[32m[2020-06-20 18:41:42] __main__ INFO: \u001b[0mEpoch 7 Step 300/351 lr 0.100000 loss 1.3203 (1.3567) acc@1 0.5078 (0.5001) acc@5 0.8359 (0.8352)\n",
      "\u001b[32m[2020-06-20 18:42:39] __main__ INFO: \u001b[0mEpoch 7 Step 351/351 lr 0.100000 loss 1.3539 (1.3559) acc@1 0.5234 (0.5003) acc@5 0.8203 (0.8354)\n",
      "\u001b[32m[2020-06-20 18:42:40] __main__ INFO: \u001b[0mElapsed 396.39\n",
      "\u001b[32m[2020-06-20 18:42:40] __main__ INFO: \u001b[0mVal 7\n",
      "\u001b[32m[2020-06-20 18:42:53] __main__ INFO: \u001b[0mEpoch 7 loss 1.5256 acc@1 0.4598 acc@5 0.8330\n",
      "\u001b[32m[2020-06-20 18:42:53] __main__ INFO: \u001b[0mElapsed 13.28\n",
      "\u001b[32m[2020-06-20 18:42:53] __main__ INFO: \u001b[0mTrain 8 2457\n",
      "\u001b[32m[2020-06-20 18:44:46] __main__ INFO: \u001b[0mEpoch 8 Step 100/351 lr 0.100000 loss 1.4775 (1.3205) acc@1 0.5078 (0.5110) acc@5 0.8828 (0.8401)\n",
      "\u001b[32m[2020-06-20 18:46:39] __main__ INFO: \u001b[0mEpoch 8 Step 200/351 lr 0.100000 loss 1.5069 (1.3202) acc@1 0.4531 (0.5101) acc@5 0.7500 (0.8389)\n",
      "\u001b[32m[2020-06-20 18:48:32] __main__ INFO: \u001b[0mEpoch 8 Step 300/351 lr 0.100000 loss 1.1514 (1.3220) acc@1 0.5938 (0.5101) acc@5 0.8594 (0.8377)\n",
      "\u001b[32m[2020-06-20 18:49:29] __main__ INFO: \u001b[0mEpoch 8 Step 351/351 lr 0.100000 loss 1.2705 (1.3220) acc@1 0.5938 (0.5110) acc@5 0.9297 (0.8383)\n",
      "\u001b[32m[2020-06-20 18:49:29] __main__ INFO: \u001b[0mElapsed 396.30\n",
      "\u001b[32m[2020-06-20 18:49:29] __main__ INFO: \u001b[0mVal 8\n",
      "\u001b[32m[2020-06-20 18:49:42] __main__ INFO: \u001b[0mEpoch 8 loss 1.3679 acc@1 0.5062 acc@5 0.8362\n",
      "\u001b[32m[2020-06-20 18:49:42] __main__ INFO: \u001b[0mElapsed 13.28\n",
      "\u001b[32m[2020-06-20 18:49:42] __main__ INFO: \u001b[0mTrain 9 2808\n",
      "\u001b[32m[2020-06-20 18:51:35] __main__ INFO: \u001b[0mEpoch 9 Step 100/351 lr 0.100000 loss 1.3587 (1.2833) acc@1 0.5391 (0.5316) acc@5 0.8594 (0.8426)\n",
      "\u001b[32m[2020-06-20 18:53:28] __main__ INFO: \u001b[0mEpoch 9 Step 200/351 lr 0.100000 loss 1.2617 (1.2884) acc@1 0.5391 (0.5278) acc@5 0.8359 (0.8412)\n",
      "\u001b[32m[2020-06-20 18:55:21] __main__ INFO: \u001b[0mEpoch 9 Step 300/351 lr 0.100000 loss 1.2359 (1.2909) acc@1 0.5391 (0.5252) acc@5 0.8516 (0.8405)\n",
      "\u001b[32m[2020-06-20 18:56:19] __main__ INFO: \u001b[0mEpoch 9 Step 351/351 lr 0.100000 loss 1.5393 (1.2934) acc@1 0.4375 (0.5246) acc@5 0.8047 (0.8397)\n",
      "\u001b[32m[2020-06-20 18:56:19] __main__ INFO: \u001b[0mElapsed 396.27\n",
      "\u001b[32m[2020-06-20 18:56:19] __main__ INFO: \u001b[0mVal 9\n",
      "\u001b[32m[2020-06-20 18:56:32] __main__ INFO: \u001b[0mEpoch 9 loss 1.5423 acc@1 0.4504 acc@5 0.8206\n",
      "\u001b[32m[2020-06-20 18:56:32] __main__ INFO: \u001b[0mElapsed 13.29\n",
      "\u001b[32m[2020-06-20 18:56:32] __main__ INFO: \u001b[0mTrain 10 3159\n",
      "\u001b[32m[2020-06-20 18:58:25] __main__ INFO: \u001b[0mEpoch 10 Step 100/351 lr 0.100000 loss 1.2935 (1.2639) acc@1 0.5000 (0.5362) acc@5 0.8438 (0.8390)\n",
      "\u001b[32m[2020-06-20 19:00:18] __main__ INFO: \u001b[0mEpoch 10 Step 200/351 lr 0.100000 loss 1.1824 (1.2644) acc@1 0.5547 (0.5367) acc@5 0.9219 (0.8410)\n",
      "\u001b[32m[2020-06-20 19:02:10] __main__ INFO: \u001b[0mEpoch 10 Step 300/351 lr 0.100000 loss 1.2700 (1.2765) acc@1 0.5625 (0.5315) acc@5 0.8594 (0.8401)\n",
      "\u001b[32m[2020-06-20 19:03:08] __main__ INFO: \u001b[0mEpoch 10 Step 351/351 lr 0.100000 loss 1.1592 (1.2749) acc@1 0.5703 (0.5332) acc@5 0.8828 (0.8405)\n",
      "\u001b[32m[2020-06-20 19:03:08] __main__ INFO: \u001b[0mElapsed 396.00\n",
      "\u001b[32m[2020-06-20 19:03:08] __main__ INFO: \u001b[0mVal 10\n",
      "\u001b[32m[2020-06-20 19:03:21] __main__ INFO: \u001b[0mEpoch 10 loss 1.4817 acc@1 0.4772 acc@5 0.8370\n",
      "\u001b[32m[2020-06-20 19:03:21] __main__ INFO: \u001b[0mElapsed 13.27\n",
      "\u001b[32m[2020-06-20 19:03:21] __main__ INFO: \u001b[0mTrain 11 3510\n",
      "\u001b[32m[2020-06-20 19:05:14] __main__ INFO: \u001b[0mEpoch 11 Step 100/351 lr 0.100000 loss 1.2564 (1.2419) acc@1 0.5312 (0.5418) acc@5 0.8359 (0.8478)\n",
      "\u001b[32m[2020-06-20 19:07:07] __main__ INFO: \u001b[0mEpoch 11 Step 200/351 lr 0.100000 loss 1.2833 (1.2528) acc@1 0.5391 (0.5379) acc@5 0.8359 (0.8424)\n",
      "\u001b[32m[2020-06-20 19:09:00] __main__ INFO: \u001b[0mEpoch 11 Step 300/351 lr 0.100000 loss 1.3352 (1.2566) acc@1 0.4766 (0.5369) acc@5 0.8438 (0.8432)\n",
      "\u001b[32m[2020-06-20 19:09:57] __main__ INFO: \u001b[0mEpoch 11 Step 351/351 lr 0.100000 loss 1.2228 (1.2567) acc@1 0.5312 (0.5366) acc@5 0.7969 (0.8419)\n",
      "\u001b[32m[2020-06-20 19:09:57] __main__ INFO: \u001b[0mElapsed 395.88\n",
      "\u001b[32m[2020-06-20 19:09:57] __main__ INFO: \u001b[0mVal 11\n",
      "\u001b[32m[2020-06-20 19:10:10] __main__ INFO: \u001b[0mEpoch 11 loss 1.3631 acc@1 0.5094 acc@5 0.8358\n",
      "\u001b[32m[2020-06-20 19:10:10] __main__ INFO: \u001b[0mElapsed 13.29\n",
      "\u001b[32m[2020-06-20 19:10:10] __main__ INFO: \u001b[0mTrain 12 3861\n",
      "\u001b[32m[2020-06-20 19:12:03] __main__ INFO: \u001b[0mEpoch 12 Step 100/351 lr 0.100000 loss 1.2069 (1.2355) acc@1 0.5312 (0.5441) acc@5 0.8594 (0.8436)\n",
      "\u001b[32m[2020-06-20 19:13:56] __main__ INFO: \u001b[0mEpoch 12 Step 200/351 lr 0.100000 loss 1.3058 (1.2413) acc@1 0.5469 (0.5412) acc@5 0.8281 (0.8432)\n",
      "\u001b[32m[2020-06-20 19:15:49] __main__ INFO: \u001b[0mEpoch 12 Step 300/351 lr 0.100000 loss 1.3420 (1.2420) acc@1 0.5469 (0.5414) acc@5 0.8516 (0.8441)\n",
      "\u001b[32m[2020-06-20 19:16:46] __main__ INFO: \u001b[0mEpoch 12 Step 351/351 lr 0.100000 loss 1.2101 (1.2428) acc@1 0.5781 (0.5407) acc@5 0.8516 (0.8441)\n",
      "\u001b[32m[2020-06-20 19:16:46] __main__ INFO: \u001b[0mElapsed 395.79\n",
      "\u001b[32m[2020-06-20 19:16:46] __main__ INFO: \u001b[0mVal 12\n",
      "\u001b[32m[2020-06-20 19:16:59] __main__ INFO: \u001b[0mEpoch 12 loss 1.4694 acc@1 0.4722 acc@5 0.8350\n",
      "\u001b[32m[2020-06-20 19:16:59] __main__ INFO: \u001b[0mElapsed 13.28\n",
      "\u001b[32m[2020-06-20 19:16:59] __main__ INFO: \u001b[0mTrain 13 4212\n",
      "\u001b[32m[2020-06-20 19:18:52] __main__ INFO: \u001b[0mEpoch 13 Step 100/351 lr 0.100000 loss 1.2798 (1.2387) acc@1 0.5234 (0.5442) acc@5 0.9062 (0.8462)\n",
      "\u001b[32m[2020-06-20 19:20:45] __main__ INFO: \u001b[0mEpoch 13 Step 200/351 lr 0.100000 loss 1.1402 (1.2347) acc@1 0.6016 (0.5428) acc@5 0.8750 (0.8438)\n",
      "\u001b[32m[2020-06-20 19:22:38] __main__ INFO: \u001b[0mEpoch 13 Step 300/351 lr 0.100000 loss 1.2646 (1.2324) acc@1 0.5312 (0.5449) acc@5 0.8672 (0.8444)\n",
      "\u001b[32m[2020-06-20 19:23:35] __main__ INFO: \u001b[0mEpoch 13 Step 351/351 lr 0.100000 loss 1.1619 (1.2326) acc@1 0.5781 (0.5442) acc@5 0.8438 (0.8446)\n",
      "\u001b[32m[2020-06-20 19:23:35] __main__ INFO: \u001b[0mElapsed 395.90\n",
      "\u001b[32m[2020-06-20 19:23:35] __main__ INFO: \u001b[0mVal 13\n",
      "\u001b[32m[2020-06-20 19:23:49] __main__ INFO: \u001b[0mEpoch 13 loss 1.3604 acc@1 0.5116 acc@5 0.8380\n",
      "\u001b[32m[2020-06-20 19:23:49] __main__ INFO: \u001b[0mElapsed 13.26\n",
      "\u001b[32m[2020-06-20 19:23:49] __main__ INFO: \u001b[0mTrain 14 4563\n",
      "\u001b[32m[2020-06-20 19:25:42] __main__ INFO: \u001b[0mEpoch 14 Step 100/351 lr 0.100000 loss 1.1264 (1.2026) acc@1 0.5703 (0.5529) acc@5 0.8594 (0.8456)\n",
      "\u001b[32m[2020-06-20 19:27:34] __main__ INFO: \u001b[0mEpoch 14 Step 200/351 lr 0.100000 loss 1.2628 (1.2112) acc@1 0.5156 (0.5537) acc@5 0.8828 (0.8452)\n",
      "\u001b[32m[2020-06-20 19:29:27] __main__ INFO: \u001b[0mEpoch 14 Step 300/351 lr 0.100000 loss 1.1375 (1.2145) acc@1 0.5859 (0.5532) acc@5 0.8750 (0.8464)\n",
      "\u001b[32m[2020-06-20 19:30:24] __main__ INFO: \u001b[0mEpoch 14 Step 351/351 lr 0.100000 loss 1.2886 (1.2162) acc@1 0.4922 (0.5530) acc@5 0.8594 (0.8460)\n",
      "\u001b[32m[2020-06-20 19:30:25] __main__ INFO: \u001b[0mElapsed 395.87\n",
      "\u001b[32m[2020-06-20 19:30:25] __main__ INFO: \u001b[0mVal 14\n",
      "\u001b[32m[2020-06-20 19:30:38] __main__ INFO: \u001b[0mEpoch 14 loss 1.3652 acc@1 0.5036 acc@5 0.8380\n",
      "\u001b[32m[2020-06-20 19:30:38] __main__ INFO: \u001b[0mElapsed 13.31\n",
      "\u001b[32m[2020-06-20 19:30:38] __main__ INFO: \u001b[0mTrain 15 4914\n",
      "\u001b[32m[2020-06-20 19:32:31] __main__ INFO: \u001b[0mEpoch 15 Step 100/351 lr 0.100000 loss 1.2145 (1.2086) acc@1 0.5391 (0.5544) acc@5 0.8438 (0.8480)\n",
      "\u001b[32m[2020-06-20 19:34:23] __main__ INFO: \u001b[0mEpoch 15 Step 200/351 lr 0.100000 loss 1.3226 (1.2069) acc@1 0.5469 (0.5548) acc@5 0.8203 (0.8482)\n",
      "\u001b[32m[2020-06-20 19:36:16] __main__ INFO: \u001b[0mEpoch 15 Step 300/351 lr 0.100000 loss 1.0787 (1.2046) acc@1 0.5938 (0.5567) acc@5 0.8672 (0.8462)\n",
      "\u001b[32m[2020-06-20 19:37:13] __main__ INFO: \u001b[0mEpoch 15 Step 351/351 lr 0.100000 loss 1.2942 (1.2055) acc@1 0.5312 (0.5566) acc@5 0.7812 (0.8456)\n",
      "\u001b[32m[2020-06-20 19:37:14] __main__ INFO: \u001b[0mElapsed 395.69\n",
      "\u001b[32m[2020-06-20 19:37:14] __main__ INFO: \u001b[0mVal 15\n",
      "\u001b[32m[2020-06-20 19:37:27] __main__ INFO: \u001b[0mEpoch 15 loss 1.4849 acc@1 0.4894 acc@5 0.8372\n",
      "\u001b[32m[2020-06-20 19:37:27] __main__ INFO: \u001b[0mElapsed 13.27\n",
      "\u001b[32m[2020-06-20 19:37:27] __main__ INFO: \u001b[0mTrain 16 5265\n",
      "\u001b[32m[2020-06-20 19:39:20] __main__ INFO: \u001b[0mEpoch 16 Step 100/351 lr 0.100000 loss 1.2056 (1.1882) acc@1 0.5391 (0.5638) acc@5 0.8594 (0.8475)\n",
      "\u001b[32m[2020-06-20 19:41:12] __main__ INFO: \u001b[0mEpoch 16 Step 200/351 lr 0.100000 loss 1.1709 (1.1905) acc@1 0.5391 (0.5635) acc@5 0.7969 (0.8464)\n",
      "\u001b[32m[2020-06-20 19:43:05] __main__ INFO: \u001b[0mEpoch 16 Step 300/351 lr 0.100000 loss 1.1769 (1.1973) acc@1 0.5625 (0.5593) acc@5 0.8438 (0.8440)\n",
      "\u001b[32m[2020-06-20 19:44:02] __main__ INFO: \u001b[0mEpoch 16 Step 351/351 lr 0.100000 loss 1.2718 (1.1970) acc@1 0.5469 (0.5602) acc@5 0.7969 (0.8448)\n",
      "\u001b[32m[2020-06-20 19:44:02] __main__ INFO: \u001b[0mElapsed 395.57\n",
      "\u001b[32m[2020-06-20 19:44:02] __main__ INFO: \u001b[0mVal 16\n",
      "\u001b[32m[2020-06-20 19:44:16] __main__ INFO: \u001b[0mEpoch 16 loss 1.3060 acc@1 0.5250 acc@5 0.8416\n",
      "\u001b[32m[2020-06-20 19:44:16] __main__ INFO: \u001b[0mElapsed 13.24\n",
      "\u001b[32m[2020-06-20 19:44:16] __main__ INFO: \u001b[0mTrain 17 5616\n",
      "\u001b[32m[2020-06-20 19:46:08] __main__ INFO: \u001b[0mEpoch 17 Step 100/351 lr 0.100000 loss 1.2176 (1.1804) acc@1 0.5625 (0.5634) acc@5 0.8281 (0.8528)\n",
      "\u001b[32m[2020-06-20 19:48:01] __main__ INFO: \u001b[0mEpoch 17 Step 200/351 lr 0.100000 loss 1.2516 (1.1862) acc@1 0.5156 (0.5603) acc@5 0.8047 (0.8503)\n",
      "\u001b[32m[2020-06-20 19:49:54] __main__ INFO: \u001b[0mEpoch 17 Step 300/351 lr 0.100000 loss 1.1549 (1.1873) acc@1 0.5469 (0.5612) acc@5 0.8203 (0.8493)\n",
      "\u001b[32m[2020-06-20 19:50:51] __main__ INFO: \u001b[0mEpoch 17 Step 351/351 lr 0.100000 loss 1.3062 (1.1889) acc@1 0.4844 (0.5611) acc@5 0.8047 (0.8482)\n",
      "\u001b[32m[2020-06-20 19:50:51] __main__ INFO: \u001b[0mElapsed 395.55\n",
      "\u001b[32m[2020-06-20 19:50:51] __main__ INFO: \u001b[0mVal 17\n",
      "\u001b[32m[2020-06-20 19:51:04] __main__ INFO: \u001b[0mEpoch 17 loss 1.3526 acc@1 0.5168 acc@5 0.8376\n",
      "\u001b[32m[2020-06-20 19:51:04] __main__ INFO: \u001b[0mElapsed 13.25\n",
      "\u001b[32m[2020-06-20 19:51:04] __main__ INFO: \u001b[0mTrain 18 5967\n",
      "\u001b[32m[2020-06-20 19:52:57] __main__ INFO: \u001b[0mEpoch 18 Step 100/351 lr 0.100000 loss 1.2870 (1.1587) acc@1 0.5234 (0.5754) acc@5 0.8125 (0.8489)\n",
      "\u001b[32m[2020-06-20 19:54:50] __main__ INFO: \u001b[0mEpoch 18 Step 200/351 lr 0.100000 loss 1.1787 (1.1781) acc@1 0.5391 (0.5648) acc@5 0.8672 (0.8471)\n",
      "\u001b[32m[2020-06-20 19:56:42] __main__ INFO: \u001b[0mEpoch 18 Step 300/351 lr 0.100000 loss 1.1560 (1.1841) acc@1 0.5781 (0.5629) acc@5 0.8516 (0.8468)\n",
      "\u001b[32m[2020-06-20 19:57:40] __main__ INFO: \u001b[0mEpoch 18 Step 351/351 lr 0.100000 loss 1.1391 (1.1835) acc@1 0.6094 (0.5627) acc@5 0.8359 (0.8466)\n",
      "\u001b[32m[2020-06-20 19:57:40] __main__ INFO: \u001b[0mElapsed 395.47\n",
      "\u001b[32m[2020-06-20 19:57:40] __main__ INFO: \u001b[0mVal 18\n",
      "\u001b[32m[2020-06-20 19:57:53] __main__ INFO: \u001b[0mEpoch 18 loss 1.3638 acc@1 0.5166 acc@5 0.8394\n",
      "\u001b[32m[2020-06-20 19:57:53] __main__ INFO: \u001b[0mElapsed 13.25\n",
      "\u001b[32m[2020-06-20 19:57:53] __main__ INFO: \u001b[0mTrain 19 6318\n",
      "\u001b[32m[2020-06-20 19:59:46] __main__ INFO: \u001b[0mEpoch 19 Step 100/351 lr 0.100000 loss 1.0020 (1.1640) acc@1 0.6797 (0.5713) acc@5 0.9453 (0.8528)\n",
      "\u001b[32m[2020-06-20 20:01:39] __main__ INFO: \u001b[0mEpoch 19 Step 200/351 lr 0.100000 loss 1.3384 (1.1692) acc@1 0.5000 (0.5690) acc@5 0.8047 (0.8510)\n",
      "\u001b[32m[2020-06-20 20:03:31] __main__ INFO: \u001b[0mEpoch 19 Step 300/351 lr 0.100000 loss 1.1525 (1.1747) acc@1 0.5391 (0.5668) acc@5 0.8672 (0.8506)\n",
      "\u001b[32m[2020-06-20 20:04:29] __main__ INFO: \u001b[0mEpoch 19 Step 351/351 lr 0.100000 loss 1.0825 (1.1760) acc@1 0.6094 (0.5654) acc@5 0.8594 (0.8510)\n",
      "\u001b[32m[2020-06-20 20:04:29] __main__ INFO: \u001b[0mElapsed 395.56\n",
      "\u001b[32m[2020-06-20 20:04:29] __main__ INFO: \u001b[0mVal 19\n",
      "\u001b[32m[2020-06-20 20:04:42] __main__ INFO: \u001b[0mEpoch 19 loss 1.3997 acc@1 0.4928 acc@5 0.8354\n",
      "\u001b[32m[2020-06-20 20:04:42] __main__ INFO: \u001b[0mElapsed 13.26\n",
      "\u001b[32m[2020-06-20 20:04:42] __main__ INFO: \u001b[0mTrain 20 6669\n",
      "\u001b[32m[2020-06-20 20:06:35] __main__ INFO: \u001b[0mEpoch 20 Step 100/351 lr 0.100000 loss 1.0934 (1.1521) acc@1 0.6172 (0.5730) acc@5 0.8047 (0.8492)\n",
      "\u001b[32m[2020-06-20 20:08:27] __main__ INFO: \u001b[0mEpoch 20 Step 200/351 lr 0.100000 loss 1.0693 (1.1566) acc@1 0.5859 (0.5710) acc@5 0.8516 (0.8500)\n",
      "\u001b[32m[2020-06-20 20:10:20] __main__ INFO: \u001b[0mEpoch 20 Step 300/351 lr 0.100000 loss 1.2746 (1.1637) acc@1 0.5391 (0.5687) acc@5 0.8438 (0.8485)\n",
      "\u001b[32m[2020-06-20 20:11:17] __main__ INFO: \u001b[0mEpoch 20 Step 351/351 lr 0.100000 loss 1.2841 (1.1647) acc@1 0.5156 (0.5691) acc@5 0.8203 (0.8490)\n",
      "\u001b[32m[2020-06-20 20:11:17] __main__ INFO: \u001b[0mElapsed 395.44\n",
      "\u001b[32m[2020-06-20 20:11:17] __main__ INFO: \u001b[0mVal 20\n",
      "\u001b[32m[2020-06-20 20:11:31] __main__ INFO: \u001b[0mEpoch 20 loss 1.4071 acc@1 0.5022 acc@5 0.8350\n",
      "\u001b[32m[2020-06-20 20:11:31] __main__ INFO: \u001b[0mElapsed 13.26\n",
      "\u001b[32m[2020-06-20 20:11:31] __main__ INFO: \u001b[0mTrain 21 7020\n",
      "\u001b[32m[2020-06-20 20:13:23] __main__ INFO: \u001b[0mEpoch 21 Step 100/351 lr 0.100000 loss 1.2171 (1.1241) acc@1 0.5547 (0.5802) acc@5 0.8359 (0.8545)\n",
      "\u001b[32m[2020-06-20 20:15:16] __main__ INFO: \u001b[0mEpoch 21 Step 200/351 lr 0.100000 loss 1.1636 (1.1439) acc@1 0.5234 (0.5756) acc@5 0.8594 (0.8517)\n",
      "\u001b[32m[2020-06-20 20:17:09] __main__ INFO: \u001b[0mEpoch 21 Step 300/351 lr 0.100000 loss 1.0403 (1.1526) acc@1 0.6562 (0.5736) acc@5 0.8438 (0.8496)\n",
      "\u001b[32m[2020-06-20 20:18:06] __main__ INFO: \u001b[0mEpoch 21 Step 351/351 lr 0.100000 loss 1.2410 (1.1568) acc@1 0.5234 (0.5713) acc@5 0.7812 (0.8481)\n",
      "\u001b[32m[2020-06-20 20:18:06] __main__ INFO: \u001b[0mElapsed 395.45\n",
      "\u001b[32m[2020-06-20 20:18:06] __main__ INFO: \u001b[0mVal 21\n",
      "\u001b[32m[2020-06-20 20:18:19] __main__ INFO: \u001b[0mEpoch 21 loss 1.3237 acc@1 0.5180 acc@5 0.8368\n",
      "\u001b[32m[2020-06-20 20:18:19] __main__ INFO: \u001b[0mElapsed 13.22\n",
      "\u001b[32m[2020-06-20 20:18:19] __main__ INFO: \u001b[0mTrain 22 7371\n",
      "\u001b[32m[2020-06-20 20:20:12] __main__ INFO: \u001b[0mEpoch 22 Step 100/351 lr 0.100000 loss 1.1768 (1.1477) acc@1 0.5312 (0.5755) acc@5 0.8281 (0.8474)\n",
      "\u001b[32m[2020-06-20 20:22:05] __main__ INFO: \u001b[0mEpoch 22 Step 200/351 lr 0.100000 loss 1.1320 (1.1423) acc@1 0.5859 (0.5788) acc@5 0.8984 (0.8487)\n",
      "\u001b[32m[2020-06-20 20:23:57] __main__ INFO: \u001b[0mEpoch 22 Step 300/351 lr 0.100000 loss 1.4635 (1.1516) acc@1 0.4766 (0.5745) acc@5 0.8359 (0.8479)\n",
      "\u001b[32m[2020-06-20 20:24:55] __main__ INFO: \u001b[0mEpoch 22 Step 351/351 lr 0.100000 loss 1.1297 (1.1555) acc@1 0.6016 (0.5734) acc@5 0.8906 (0.8473)\n",
      "\u001b[32m[2020-06-20 20:24:55] __main__ INFO: \u001b[0mElapsed 395.31\n",
      "\u001b[32m[2020-06-20 20:24:55] __main__ INFO: \u001b[0mVal 22\n",
      "\u001b[32m[2020-06-20 20:25:08] __main__ INFO: \u001b[0mEpoch 22 loss 1.2979 acc@1 0.5318 acc@5 0.8418\n",
      "\u001b[32m[2020-06-20 20:25:08] __main__ INFO: \u001b[0mElapsed 13.26\n",
      "\u001b[32m[2020-06-20 20:25:08] __main__ INFO: \u001b[0mTrain 23 7722\n",
      "\u001b[32m[2020-06-20 20:27:01] __main__ INFO: \u001b[0mEpoch 23 Step 100/351 lr 0.100000 loss 1.1794 (1.1303) acc@1 0.5469 (0.5816) acc@5 0.8594 (0.8541)\n",
      "\u001b[32m[2020-06-20 20:28:53] __main__ INFO: \u001b[0mEpoch 23 Step 200/351 lr 0.100000 loss 1.1665 (1.1499) acc@1 0.6094 (0.5749) acc@5 0.8359 (0.8491)\n",
      "\u001b[32m[2020-06-20 20:30:46] __main__ INFO: \u001b[0mEpoch 23 Step 300/351 lr 0.100000 loss 1.0641 (1.1526) acc@1 0.6016 (0.5736) acc@5 0.8203 (0.8491)\n",
      "\u001b[32m[2020-06-20 20:31:43] __main__ INFO: \u001b[0mEpoch 23 Step 351/351 lr 0.100000 loss 1.2020 (1.1515) acc@1 0.5703 (0.5746) acc@5 0.8047 (0.8495)\n",
      "\u001b[32m[2020-06-20 20:31:43] __main__ INFO: \u001b[0mElapsed 395.36\n",
      "\u001b[32m[2020-06-20 20:31:43] __main__ INFO: \u001b[0mVal 23\n",
      "\u001b[32m[2020-06-20 20:31:56] __main__ INFO: \u001b[0mEpoch 23 loss 1.3518 acc@1 0.5170 acc@5 0.8382\n",
      "\u001b[32m[2020-06-20 20:31:56] __main__ INFO: \u001b[0mElapsed 13.25\n",
      "\u001b[32m[2020-06-20 20:31:56] __main__ INFO: \u001b[0mTrain 24 8073\n",
      "\u001b[32m[2020-06-20 20:33:49] __main__ INFO: \u001b[0mEpoch 24 Step 100/351 lr 0.100000 loss 1.2176 (1.1289) acc@1 0.5312 (0.5830) acc@5 0.8125 (0.8539)\n",
      "\u001b[32m[2020-06-20 20:35:42] __main__ INFO: \u001b[0mEpoch 24 Step 200/351 lr 0.100000 loss 1.1272 (1.1332) acc@1 0.6016 (0.5793) acc@5 0.8047 (0.8532)\n",
      "\u001b[32m[2020-06-20 20:37:34] __main__ INFO: \u001b[0mEpoch 24 Step 300/351 lr 0.100000 loss 1.1745 (1.1399) acc@1 0.5625 (0.5771) acc@5 0.8438 (0.8519)\n",
      "\u001b[32m[2020-06-20 20:38:32] __main__ INFO: \u001b[0mEpoch 24 Step 351/351 lr 0.100000 loss 1.1530 (1.1413) acc@1 0.5938 (0.5775) acc@5 0.8828 (0.8521)\n",
      "\u001b[32m[2020-06-20 20:38:32] __main__ INFO: \u001b[0mElapsed 395.32\n",
      "\u001b[32m[2020-06-20 20:38:32] __main__ INFO: \u001b[0mVal 24\n",
      "\u001b[32m[2020-06-20 20:38:45] __main__ INFO: \u001b[0mEpoch 24 loss 1.4101 acc@1 0.4982 acc@5 0.8444\n",
      "\u001b[32m[2020-06-20 20:38:45] __main__ INFO: \u001b[0mElapsed 13.23\n",
      "\u001b[32m[2020-06-20 20:38:45] __main__ INFO: \u001b[0mTrain 25 8424\n",
      "\u001b[32m[2020-06-20 20:40:38] __main__ INFO: \u001b[0mEpoch 25 Step 100/351 lr 0.100000 loss 1.1947 (1.1185) acc@1 0.5781 (0.5829) acc@5 0.8516 (0.8538)\n",
      "\u001b[32m[2020-06-20 20:42:30] __main__ INFO: \u001b[0mEpoch 25 Step 200/351 lr 0.100000 loss 0.9719 (1.1320) acc@1 0.6406 (0.5806) acc@5 0.8359 (0.8520)\n",
      "\u001b[32m[2020-06-20 20:44:23] __main__ INFO: \u001b[0mEpoch 25 Step 300/351 lr 0.100000 loss 1.0659 (1.1339) acc@1 0.6094 (0.5816) acc@5 0.8828 (0.8509)\n",
      "\u001b[32m[2020-06-20 20:45:20] __main__ INFO: \u001b[0mEpoch 25 Step 351/351 lr 0.100000 loss 1.0783 (1.1347) acc@1 0.5938 (0.5813) acc@5 0.8438 (0.8517)\n",
      "\u001b[32m[2020-06-20 20:45:20] __main__ INFO: \u001b[0mElapsed 395.31\n",
      "\u001b[32m[2020-06-20 20:45:20] __main__ INFO: \u001b[0mVal 25\n",
      "\u001b[32m[2020-06-20 20:45:34] __main__ INFO: \u001b[0mEpoch 25 loss 1.4147 acc@1 0.5070 acc@5 0.8380\n",
      "\u001b[32m[2020-06-20 20:45:34] __main__ INFO: \u001b[0mElapsed 13.23\n",
      "\u001b[32m[2020-06-20 20:45:34] __main__ INFO: \u001b[0mTrain 26 8775\n",
      "\u001b[32m[2020-06-20 20:47:26] __main__ INFO: \u001b[0mEpoch 26 Step 100/351 lr 0.100000 loss 0.9389 (1.1263) acc@1 0.6719 (0.5831) acc@5 0.8828 (0.8528)\n",
      "\u001b[32m[2020-06-20 20:49:19] __main__ INFO: \u001b[0mEpoch 26 Step 200/351 lr 0.100000 loss 1.2421 (1.1312) acc@1 0.5547 (0.5814) acc@5 0.8516 (0.8508)\n",
      "\u001b[32m[2020-06-20 20:51:12] __main__ INFO: \u001b[0mEpoch 26 Step 300/351 lr 0.100000 loss 1.2299 (1.1321) acc@1 0.5234 (0.5815) acc@5 0.8750 (0.8519)\n",
      "\u001b[32m[2020-06-20 20:52:09] __main__ INFO: \u001b[0mEpoch 26 Step 351/351 lr 0.100000 loss 1.0757 (1.1344) acc@1 0.5859 (0.5805) acc@5 0.8203 (0.8513)\n",
      "\u001b[32m[2020-06-20 20:52:09] __main__ INFO: \u001b[0mElapsed 395.33\n",
      "\u001b[32m[2020-06-20 20:52:09] __main__ INFO: \u001b[0mVal 26\n",
      "\u001b[32m[2020-06-20 20:52:22] __main__ INFO: \u001b[0mEpoch 26 loss 1.3194 acc@1 0.5204 acc@5 0.8414\n",
      "\u001b[32m[2020-06-20 20:52:22] __main__ INFO: \u001b[0mElapsed 13.25\n",
      "\u001b[32m[2020-06-20 20:52:22] __main__ INFO: \u001b[0mTrain 27 9126\n",
      "\u001b[32m[2020-06-20 20:54:15] __main__ INFO: \u001b[0mEpoch 27 Step 100/351 lr 0.100000 loss 1.1251 (1.1125) acc@1 0.5703 (0.5870) acc@5 0.8750 (0.8523)\n",
      "\u001b[32m[2020-06-20 20:56:07] __main__ INFO: \u001b[0mEpoch 27 Step 200/351 lr 0.100000 loss 1.0777 (1.1213) acc@1 0.6172 (0.5830) acc@5 0.7969 (0.8508)\n",
      "\u001b[32m[2020-06-20 20:58:00] __main__ INFO: \u001b[0mEpoch 27 Step 300/351 lr 0.100000 loss 1.2118 (1.1247) acc@1 0.5312 (0.5823) acc@5 0.8516 (0.8496)\n",
      "\u001b[32m[2020-06-20 20:58:57] __main__ INFO: \u001b[0mEpoch 27 Step 351/351 lr 0.100000 loss 1.0621 (1.1231) acc@1 0.6172 (0.5837) acc@5 0.8750 (0.8496)\n",
      "\u001b[32m[2020-06-20 20:58:57] __main__ INFO: \u001b[0mElapsed 395.28\n",
      "\u001b[32m[2020-06-20 20:58:57] __main__ INFO: \u001b[0mVal 27\n",
      "\u001b[32m[2020-06-20 20:59:11] __main__ INFO: \u001b[0mEpoch 27 loss 1.2353 acc@1 0.5602 acc@5 0.8444\n",
      "\u001b[32m[2020-06-20 20:59:11] __main__ INFO: \u001b[0mElapsed 13.24\n",
      "\u001b[32m[2020-06-20 20:59:11] __main__ INFO: \u001b[0mTrain 28 9477\n",
      "\u001b[32m[2020-06-20 21:01:03] __main__ INFO: \u001b[0mEpoch 28 Step 100/351 lr 0.100000 loss 1.1265 (1.1196) acc@1 0.5859 (0.5884) acc@5 0.8750 (0.8521)\n",
      "\u001b[32m[2020-06-20 21:02:56] __main__ INFO: \u001b[0mEpoch 28 Step 200/351 lr 0.100000 loss 0.9808 (1.1250) acc@1 0.6406 (0.5870) acc@5 0.8828 (0.8525)\n",
      "\u001b[32m[2020-06-20 21:04:49] __main__ INFO: \u001b[0mEpoch 28 Step 300/351 lr 0.100000 loss 1.1667 (1.1220) acc@1 0.5547 (0.5863) acc@5 0.8359 (0.8513)\n",
      "\u001b[32m[2020-06-20 21:05:46] __main__ INFO: \u001b[0mEpoch 28 Step 351/351 lr 0.100000 loss 1.2594 (1.1244) acc@1 0.5469 (0.5853) acc@5 0.8047 (0.8507)\n",
      "\u001b[32m[2020-06-20 21:05:46] __main__ INFO: \u001b[0mElapsed 395.37\n",
      "\u001b[32m[2020-06-20 21:05:46] __main__ INFO: \u001b[0mVal 28\n",
      "\u001b[32m[2020-06-20 21:05:59] __main__ INFO: \u001b[0mEpoch 28 loss 1.3208 acc@1 0.5288 acc@5 0.8436\n",
      "\u001b[32m[2020-06-20 21:05:59] __main__ INFO: \u001b[0mElapsed 13.27\n",
      "\u001b[32m[2020-06-20 21:05:59] __main__ INFO: \u001b[0mTrain 29 9828\n",
      "\u001b[32m[2020-06-20 21:07:52] __main__ INFO: \u001b[0mEpoch 29 Step 100/351 lr 0.100000 loss 1.2156 (1.0983) acc@1 0.5703 (0.5921) acc@5 0.8516 (0.8547)\n",
      "\u001b[32m[2020-06-20 21:09:45] __main__ INFO: \u001b[0mEpoch 29 Step 200/351 lr 0.100000 loss 1.0695 (1.1090) acc@1 0.5625 (0.5877) acc@5 0.8828 (0.8527)\n",
      "\u001b[32m[2020-06-20 21:11:37] __main__ INFO: \u001b[0mEpoch 29 Step 300/351 lr 0.100000 loss 1.1271 (1.1147) acc@1 0.5625 (0.5860) acc@5 0.8594 (0.8533)\n",
      "\u001b[32m[2020-06-20 21:12:35] __main__ INFO: \u001b[0mEpoch 29 Step 351/351 lr 0.100000 loss 1.1016 (1.1155) acc@1 0.6250 (0.5853) acc@5 0.8438 (0.8526)\n",
      "\u001b[32m[2020-06-20 21:12:35] __main__ INFO: \u001b[0mElapsed 395.44\n",
      "\u001b[32m[2020-06-20 21:12:35] __main__ INFO: \u001b[0mVal 29\n",
      "\u001b[32m[2020-06-20 21:12:48] __main__ INFO: \u001b[0mEpoch 29 loss 1.4495 acc@1 0.4908 acc@5 0.8338\n",
      "\u001b[32m[2020-06-20 21:12:48] __main__ INFO: \u001b[0mElapsed 13.26\n",
      "\u001b[32m[2020-06-20 21:12:48] __main__ INFO: \u001b[0mTrain 30 10179\n",
      "\u001b[32m[2020-06-20 21:14:41] __main__ INFO: \u001b[0mEpoch 30 Step 100/351 lr 0.100000 loss 1.1785 (1.1066) acc@1 0.5781 (0.5935) acc@5 0.8281 (0.8538)\n",
      "\u001b[32m[2020-06-20 21:16:33] __main__ INFO: \u001b[0mEpoch 30 Step 200/351 lr 0.100000 loss 1.0453 (1.1078) acc@1 0.5625 (0.5908) acc@5 0.8672 (0.8543)\n",
      "\u001b[32m[2020-06-20 21:18:26] __main__ INFO: \u001b[0mEpoch 30 Step 300/351 lr 0.100000 loss 1.0304 (1.1120) acc@1 0.6406 (0.5902) acc@5 0.8359 (0.8526)\n",
      "\u001b[32m[2020-06-20 21:19:23] __main__ INFO: \u001b[0mEpoch 30 Step 351/351 lr 0.100000 loss 1.1333 (1.1142) acc@1 0.5547 (0.5888) acc@5 0.8359 (0.8523)\n",
      "\u001b[32m[2020-06-20 21:19:23] __main__ INFO: \u001b[0mElapsed 395.34\n",
      "\u001b[32m[2020-06-20 21:19:23] __main__ INFO: \u001b[0mVal 30\n",
      "\u001b[32m[2020-06-20 21:19:37] __main__ INFO: \u001b[0mEpoch 30 loss 1.2590 acc@1 0.5502 acc@5 0.8550\n",
      "\u001b[32m[2020-06-20 21:19:37] __main__ INFO: \u001b[0mElapsed 13.24\n",
      "\u001b[32m[2020-06-20 21:19:37] __main__ INFO: \u001b[0mTrain 31 10530\n",
      "\u001b[32m[2020-06-20 21:21:29] __main__ INFO: \u001b[0mEpoch 31 Step 100/351 lr 0.100000 loss 1.0662 (1.0993) acc@1 0.5938 (0.5910) acc@5 0.8906 (0.8523)\n",
      "\u001b[32m[2020-06-20 21:23:22] __main__ INFO: \u001b[0mEpoch 31 Step 200/351 lr 0.100000 loss 1.2158 (1.1049) acc@1 0.5391 (0.5908) acc@5 0.8047 (0.8530)\n",
      "\u001b[32m[2020-06-20 21:25:14] __main__ INFO: \u001b[0mEpoch 31 Step 300/351 lr 0.100000 loss 1.1916 (1.1109) acc@1 0.5859 (0.5896) acc@5 0.8359 (0.8522)\n",
      "\u001b[32m[2020-06-20 21:26:12] __main__ INFO: \u001b[0mEpoch 31 Step 351/351 lr 0.100000 loss 1.0960 (1.1140) acc@1 0.5703 (0.5888) acc@5 0.8750 (0.8525)\n",
      "\u001b[32m[2020-06-20 21:26:12] __main__ INFO: \u001b[0mElapsed 395.31\n",
      "\u001b[32m[2020-06-20 21:26:12] __main__ INFO: \u001b[0mVal 31\n",
      "\u001b[32m[2020-06-20 21:26:25] __main__ INFO: \u001b[0mEpoch 31 loss 1.3541 acc@1 0.5032 acc@5 0.8424\n",
      "\u001b[32m[2020-06-20 21:26:25] __main__ INFO: \u001b[0mElapsed 13.20\n",
      "\u001b[32m[2020-06-20 21:26:25] __main__ INFO: \u001b[0mTrain 32 10881\n",
      "\u001b[32m[2020-06-20 21:28:18] __main__ INFO: \u001b[0mEpoch 32 Step 100/351 lr 0.100000 loss 1.1081 (1.0936) acc@1 0.5938 (0.5900) acc@5 0.8438 (0.8522)\n",
      "\u001b[32m[2020-06-20 21:30:10] __main__ INFO: \u001b[0mEpoch 32 Step 200/351 lr 0.100000 loss 1.1845 (1.0968) acc@1 0.5312 (0.5918) acc@5 0.8359 (0.8556)\n",
      "\u001b[32m[2020-06-20 21:32:03] __main__ INFO: \u001b[0mEpoch 32 Step 300/351 lr 0.100000 loss 1.2494 (1.1078) acc@1 0.5234 (0.5890) acc@5 0.8438 (0.8536)\n",
      "\u001b[32m[2020-06-20 21:33:00] __main__ INFO: \u001b[0mEpoch 32 Step 351/351 lr 0.100000 loss 1.1548 (1.1085) acc@1 0.5547 (0.5889) acc@5 0.8359 (0.8529)\n",
      "\u001b[32m[2020-06-20 21:33:00] __main__ INFO: \u001b[0mElapsed 395.26\n",
      "\u001b[32m[2020-06-20 21:33:00] __main__ INFO: \u001b[0mVal 32\n",
      "\u001b[32m[2020-06-20 21:33:14] __main__ INFO: \u001b[0mEpoch 32 loss 1.3414 acc@1 0.5204 acc@5 0.8338\n",
      "\u001b[32m[2020-06-20 21:33:14] __main__ INFO: \u001b[0mElapsed 13.23\n",
      "\u001b[32m[2020-06-20 21:33:14] __main__ INFO: \u001b[0mTrain 33 11232\n",
      "\u001b[32m[2020-06-20 21:35:06] __main__ INFO: \u001b[0mEpoch 33 Step 100/351 lr 0.100000 loss 1.2668 (1.0897) acc@1 0.5078 (0.5979) acc@5 0.8750 (0.8528)\n",
      "\u001b[32m[2020-06-20 21:36:59] __main__ INFO: \u001b[0mEpoch 33 Step 200/351 lr 0.100000 loss 1.2584 (1.1051) acc@1 0.5391 (0.5907) acc@5 0.8203 (0.8507)\n",
      "\u001b[32m[2020-06-20 21:38:51] __main__ INFO: \u001b[0mEpoch 33 Step 300/351 lr 0.100000 loss 1.1955 (1.1063) acc@1 0.5781 (0.5903) acc@5 0.8125 (0.8502)\n",
      "\u001b[32m[2020-06-20 21:39:49] __main__ INFO: \u001b[0mEpoch 33 Step 351/351 lr 0.100000 loss 1.1662 (1.1054) acc@1 0.5703 (0.5899) acc@5 0.8281 (0.8501)\n",
      "\u001b[32m[2020-06-20 21:39:49] __main__ INFO: \u001b[0mElapsed 395.23\n",
      "\u001b[32m[2020-06-20 21:39:49] __main__ INFO: \u001b[0mVal 33\n",
      "\u001b[32m[2020-06-20 21:40:02] __main__ INFO: \u001b[0mEpoch 33 loss 1.4846 acc@1 0.4904 acc@5 0.8120\n",
      "\u001b[32m[2020-06-20 21:40:02] __main__ INFO: \u001b[0mElapsed 13.27\n",
      "\u001b[32m[2020-06-20 21:40:02] __main__ INFO: \u001b[0mTrain 34 11583\n",
      "\u001b[32m[2020-06-20 21:41:55] __main__ INFO: \u001b[0mEpoch 34 Step 100/351 lr 0.100000 loss 1.2522 (1.0832) acc@1 0.5469 (0.6003) acc@5 0.8203 (0.8552)\n",
      "\u001b[32m[2020-06-20 21:43:47] __main__ INFO: \u001b[0mEpoch 34 Step 200/351 lr 0.100000 loss 0.9389 (1.1016) acc@1 0.6406 (0.5910) acc@5 0.8594 (0.8521)\n",
      "\u001b[32m[2020-06-20 21:45:40] __main__ INFO: \u001b[0mEpoch 34 Step 300/351 lr 0.100000 loss 0.9655 (1.1024) acc@1 0.6094 (0.5908) acc@5 0.9219 (0.8522)\n",
      "\u001b[32m[2020-06-20 21:46:37] __main__ INFO: \u001b[0mEpoch 34 Step 351/351 lr 0.100000 loss 0.9647 (1.1039) acc@1 0.6250 (0.5904) acc@5 0.8281 (0.8527)\n",
      "\u001b[32m[2020-06-20 21:46:37] __main__ INFO: \u001b[0mElapsed 395.32\n",
      "\u001b[32m[2020-06-20 21:46:37] __main__ INFO: \u001b[0mVal 34\n",
      "\u001b[32m[2020-06-20 21:46:51] __main__ INFO: \u001b[0mEpoch 34 loss 1.2358 acc@1 0.5510 acc@5 0.8504\n",
      "\u001b[32m[2020-06-20 21:46:51] __main__ INFO: \u001b[0mElapsed 13.23\n",
      "\u001b[32m[2020-06-20 21:46:51] __main__ INFO: \u001b[0mTrain 35 11934\n",
      "\u001b[32m[2020-06-20 21:48:43] __main__ INFO: \u001b[0mEpoch 35 Step 100/351 lr 0.100000 loss 1.0745 (1.0790) acc@1 0.6328 (0.6020) acc@5 0.8672 (0.8586)\n",
      "\u001b[32m[2020-06-20 21:50:36] __main__ INFO: \u001b[0mEpoch 35 Step 200/351 lr 0.100000 loss 0.9372 (1.0954) acc@1 0.6641 (0.5961) acc@5 0.8906 (0.8532)\n",
      "\u001b[32m[2020-06-20 21:52:28] __main__ INFO: \u001b[0mEpoch 35 Step 300/351 lr 0.100000 loss 1.0578 (1.0982) acc@1 0.6250 (0.5950) acc@5 0.8750 (0.8530)\n",
      "\u001b[32m[2020-06-20 21:53:26] __main__ INFO: \u001b[0mEpoch 35 Step 351/351 lr 0.100000 loss 1.1298 (1.0992) acc@1 0.5859 (0.5939) acc@5 0.9062 (0.8530)\n",
      "\u001b[32m[2020-06-20 21:53:26] __main__ INFO: \u001b[0mElapsed 395.10\n",
      "\u001b[32m[2020-06-20 21:53:26] __main__ INFO: \u001b[0mVal 35\n",
      "\u001b[32m[2020-06-20 21:53:39] __main__ INFO: \u001b[0mEpoch 35 loss 1.4325 acc@1 0.5014 acc@5 0.8422\n",
      "\u001b[32m[2020-06-20 21:53:39] __main__ INFO: \u001b[0mElapsed 13.25\n",
      "\u001b[32m[2020-06-20 21:53:39] __main__ INFO: \u001b[0mTrain 36 12285\n",
      "\u001b[32m[2020-06-20 21:55:32] __main__ INFO: \u001b[0mEpoch 36 Step 100/351 lr 0.100000 loss 1.1111 (1.0792) acc@1 0.5312 (0.5991) acc@5 0.8438 (0.8591)\n",
      "\u001b[32m[2020-06-20 21:57:24] __main__ INFO: \u001b[0mEpoch 36 Step 200/351 lr 0.100000 loss 1.1166 (1.0850) acc@1 0.5859 (0.5981) acc@5 0.8594 (0.8571)\n",
      "\u001b[32m[2020-06-20 21:59:17] __main__ INFO: \u001b[0mEpoch 36 Step 300/351 lr 0.100000 loss 1.1063 (1.0941) acc@1 0.5938 (0.5941) acc@5 0.8984 (0.8548)\n",
      "\u001b[32m[2020-06-20 22:00:14] __main__ INFO: \u001b[0mEpoch 36 Step 351/351 lr 0.100000 loss 1.1908 (1.0981) acc@1 0.5469 (0.5931) acc@5 0.7734 (0.8536)\n",
      "\u001b[32m[2020-06-20 22:00:14] __main__ INFO: \u001b[0mElapsed 395.35\n",
      "\u001b[32m[2020-06-20 22:00:14] __main__ INFO: \u001b[0mVal 36\n",
      "\u001b[32m[2020-06-20 22:00:28] __main__ INFO: \u001b[0mEpoch 36 loss 1.3095 acc@1 0.5328 acc@5 0.8416\n",
      "\u001b[32m[2020-06-20 22:00:28] __main__ INFO: \u001b[0mElapsed 13.25\n",
      "\u001b[32m[2020-06-20 22:00:28] __main__ INFO: \u001b[0mTrain 37 12636\n",
      "\u001b[32m[2020-06-20 22:02:20] __main__ INFO: \u001b[0mEpoch 37 Step 100/351 lr 0.100000 loss 1.0337 (1.0891) acc@1 0.5781 (0.6003) acc@5 0.8750 (0.8538)\n",
      "\u001b[32m[2020-06-20 22:04:13] __main__ INFO: \u001b[0mEpoch 37 Step 200/351 lr 0.100000 loss 1.2083 (1.0919) acc@1 0.5312 (0.5979) acc@5 0.8047 (0.8529)\n",
      "\u001b[32m[2020-06-20 22:06:05] __main__ INFO: \u001b[0mEpoch 37 Step 300/351 lr 0.100000 loss 1.0880 (1.0936) acc@1 0.6172 (0.5943) acc@5 0.8672 (0.8535)\n",
      "\u001b[32m[2020-06-20 22:07:03] __main__ INFO: \u001b[0mEpoch 37 Step 351/351 lr 0.100000 loss 1.0935 (1.0936) acc@1 0.6406 (0.5944) acc@5 0.8438 (0.8525)\n",
      "\u001b[32m[2020-06-20 22:07:03] __main__ INFO: \u001b[0mElapsed 395.17\n",
      "\u001b[32m[2020-06-20 22:07:03] __main__ INFO: \u001b[0mVal 37\n",
      "\u001b[32m[2020-06-20 22:07:16] __main__ INFO: \u001b[0mEpoch 37 loss 1.2956 acc@1 0.5372 acc@5 0.8476\n",
      "\u001b[32m[2020-06-20 22:07:16] __main__ INFO: \u001b[0mElapsed 13.24\n",
      "\u001b[32m[2020-06-20 22:07:16] __main__ INFO: \u001b[0mTrain 38 12987\n",
      "\u001b[32m[2020-06-20 22:09:09] __main__ INFO: \u001b[0mEpoch 38 Step 100/351 lr 0.100000 loss 1.1562 (1.0737) acc@1 0.5859 (0.6000) acc@5 0.8672 (0.8574)\n",
      "\u001b[32m[2020-06-20 22:11:01] __main__ INFO: \u001b[0mEpoch 38 Step 200/351 lr 0.100000 loss 1.0776 (1.0812) acc@1 0.6094 (0.5990) acc@5 0.8984 (0.8575)\n",
      "\u001b[32m[2020-06-20 22:12:54] __main__ INFO: \u001b[0mEpoch 38 Step 300/351 lr 0.100000 loss 1.0497 (1.0893) acc@1 0.6094 (0.5958) acc@5 0.8438 (0.8555)\n",
      "\u001b[32m[2020-06-20 22:13:51] __main__ INFO: \u001b[0mEpoch 38 Step 351/351 lr 0.100000 loss 1.2194 (1.0917) acc@1 0.5547 (0.5949) acc@5 0.7969 (0.8540)\n",
      "\u001b[32m[2020-06-20 22:13:51] __main__ INFO: \u001b[0mElapsed 395.25\n",
      "\u001b[32m[2020-06-20 22:13:51] __main__ INFO: \u001b[0mVal 38\n",
      "\u001b[32m[2020-06-20 22:14:05] __main__ INFO: \u001b[0mEpoch 38 loss 1.2240 acc@1 0.5606 acc@5 0.8506\n",
      "\u001b[32m[2020-06-20 22:14:05] __main__ INFO: \u001b[0mElapsed 13.23\n",
      "\u001b[32m[2020-06-20 22:14:05] __main__ INFO: \u001b[0mTrain 39 13338\n",
      "\u001b[32m[2020-06-20 22:15:57] __main__ INFO: \u001b[0mEpoch 39 Step 100/351 lr 0.100000 loss 1.1392 (1.0641) acc@1 0.5781 (0.6062) acc@5 0.9062 (0.8554)\n",
      "\u001b[32m[2020-06-20 22:17:50] __main__ INFO: \u001b[0mEpoch 39 Step 200/351 lr 0.100000 loss 1.1231 (1.0842) acc@1 0.5312 (0.5994) acc@5 0.8359 (0.8511)\n",
      "\u001b[32m[2020-06-20 22:19:42] __main__ INFO: \u001b[0mEpoch 39 Step 300/351 lr 0.100000 loss 1.1253 (1.0875) acc@1 0.6016 (0.5988) acc@5 0.8906 (0.8521)\n",
      "\u001b[32m[2020-06-20 22:20:40] __main__ INFO: \u001b[0mEpoch 39 Step 351/351 lr 0.100000 loss 1.2286 (1.0926) acc@1 0.5625 (0.5964) acc@5 0.8672 (0.8522)\n",
      "\u001b[32m[2020-06-20 22:20:40] __main__ INFO: \u001b[0mElapsed 395.34\n",
      "\u001b[32m[2020-06-20 22:20:40] __main__ INFO: \u001b[0mVal 39\n",
      "\u001b[32m[2020-06-20 22:20:53] __main__ INFO: \u001b[0mEpoch 39 loss 1.3764 acc@1 0.5206 acc@5 0.8426\n",
      "\u001b[32m[2020-06-20 22:20:53] __main__ INFO: \u001b[0mElapsed 13.24\n",
      "\u001b[32m[2020-06-20 22:20:53] __main__ INFO: \u001b[0mTrain 40 13689\n",
      "\u001b[32m[2020-06-20 22:22:46] __main__ INFO: \u001b[0mEpoch 40 Step 100/351 lr 0.100000 loss 1.0324 (1.0647) acc@1 0.6094 (0.6054) acc@5 0.8672 (0.8631)\n",
      "\u001b[32m[2020-06-20 22:24:38] __main__ INFO: \u001b[0mEpoch 40 Step 200/351 lr 0.100000 loss 1.0722 (1.0778) acc@1 0.6094 (0.5996) acc@5 0.8281 (0.8571)\n",
      "\u001b[32m[2020-06-20 22:26:31] __main__ INFO: \u001b[0mEpoch 40 Step 300/351 lr 0.100000 loss 1.0256 (1.0916) acc@1 0.6328 (0.5946) acc@5 0.8281 (0.8541)\n",
      "\u001b[32m[2020-06-20 22:27:28] __main__ INFO: \u001b[0mEpoch 40 Step 351/351 lr 0.100000 loss 0.9585 (1.0910) acc@1 0.6641 (0.5953) acc@5 0.8906 (0.8540)\n",
      "\u001b[32m[2020-06-20 22:27:28] __main__ INFO: \u001b[0mElapsed 395.30\n",
      "\u001b[32m[2020-06-20 22:27:28] __main__ INFO: \u001b[0mVal 40\n",
      "\u001b[32m[2020-06-20 22:27:42] __main__ INFO: \u001b[0mEpoch 40 loss 1.4031 acc@1 0.5108 acc@5 0.8386\n",
      "\u001b[32m[2020-06-20 22:27:42] __main__ INFO: \u001b[0mElapsed 13.27\n",
      "\u001b[32m[2020-06-20 22:27:42] __main__ INFO: \u001b[0mTrain 41 14040\n",
      "\u001b[32m[2020-06-20 22:29:35] __main__ INFO: \u001b[0mEpoch 41 Step 100/351 lr 0.100000 loss 1.2317 (1.0835) acc@1 0.5781 (0.5955) acc@5 0.8281 (0.8534)\n",
      "\u001b[32m[2020-06-20 22:31:27] __main__ INFO: \u001b[0mEpoch 41 Step 200/351 lr 0.100000 loss 1.1621 (1.0878) acc@1 0.5547 (0.5947) acc@5 0.8203 (0.8535)\n",
      "\u001b[32m[2020-06-20 22:33:20] __main__ INFO: \u001b[0mEpoch 41 Step 300/351 lr 0.100000 loss 0.9615 (1.0839) acc@1 0.6406 (0.5964) acc@5 0.8438 (0.8544)\n",
      "\u001b[32m[2020-06-20 22:34:17] __main__ INFO: \u001b[0mEpoch 41 Step 351/351 lr 0.100000 loss 1.2335 (1.0869) acc@1 0.5547 (0.5954) acc@5 0.7891 (0.8533)\n",
      "\u001b[32m[2020-06-20 22:34:17] __main__ INFO: \u001b[0mElapsed 395.41\n",
      "\u001b[32m[2020-06-20 22:34:17] __main__ INFO: \u001b[0mVal 41\n",
      "\u001b[32m[2020-06-20 22:34:30] __main__ INFO: \u001b[0mEpoch 41 loss 1.3989 acc@1 0.5214 acc@5 0.8372\n",
      "\u001b[32m[2020-06-20 22:34:30] __main__ INFO: \u001b[0mElapsed 13.25\n",
      "\u001b[32m[2020-06-20 22:34:30] __main__ INFO: \u001b[0mTrain 42 14391\n",
      "\u001b[32m[2020-06-20 22:36:23] __main__ INFO: \u001b[0mEpoch 42 Step 100/351 lr 0.100000 loss 1.1474 (1.0502) acc@1 0.5938 (0.6118) acc@5 0.8359 (0.8566)\n",
      "\u001b[32m[2020-06-20 22:38:16] __main__ INFO: \u001b[0mEpoch 42 Step 200/351 lr 0.100000 loss 1.1431 (1.0635) acc@1 0.5703 (0.6056) acc@5 0.8125 (0.8538)\n",
      "\u001b[32m[2020-06-20 22:40:08] __main__ INFO: \u001b[0mEpoch 42 Step 300/351 lr 0.100000 loss 1.0992 (1.0800) acc@1 0.6016 (0.5990) acc@5 0.8438 (0.8519)\n",
      "\u001b[32m[2020-06-20 22:41:06] __main__ INFO: \u001b[0mEpoch 42 Step 351/351 lr 0.100000 loss 1.1471 (1.0852) acc@1 0.5781 (0.5972) acc@5 0.8594 (0.8511)\n",
      "\u001b[32m[2020-06-20 22:41:06] __main__ INFO: \u001b[0mElapsed 395.27\n",
      "\u001b[32m[2020-06-20 22:41:06] __main__ INFO: \u001b[0mVal 42\n",
      "\u001b[32m[2020-06-20 22:41:19] __main__ INFO: \u001b[0mEpoch 42 loss 1.2189 acc@1 0.5556 acc@5 0.8464\n",
      "\u001b[32m[2020-06-20 22:41:19] __main__ INFO: \u001b[0mElapsed 13.23\n",
      "\u001b[32m[2020-06-20 22:41:19] __main__ INFO: \u001b[0mTrain 43 14742\n",
      "\u001b[32m[2020-06-20 22:43:12] __main__ INFO: \u001b[0mEpoch 43 Step 100/351 lr 0.100000 loss 1.0424 (1.0693) acc@1 0.6328 (0.6059) acc@5 0.8438 (0.8564)\n",
      "\u001b[32m[2020-06-20 22:45:04] __main__ INFO: \u001b[0mEpoch 43 Step 200/351 lr 0.100000 loss 0.9509 (1.0809) acc@1 0.6641 (0.6005) acc@5 0.8984 (0.8538)\n",
      "\u001b[32m[2020-06-20 22:46:57] __main__ INFO: \u001b[0mEpoch 43 Step 300/351 lr 0.100000 loss 1.1406 (1.0790) acc@1 0.5859 (0.6008) acc@5 0.8594 (0.8554)\n",
      "\u001b[32m[2020-06-20 22:47:54] __main__ INFO: \u001b[0mEpoch 43 Step 351/351 lr 0.100000 loss 1.0994 (1.0817) acc@1 0.5547 (0.5996) acc@5 0.8906 (0.8553)\n",
      "\u001b[32m[2020-06-20 22:47:54] __main__ INFO: \u001b[0mElapsed 395.18\n",
      "\u001b[32m[2020-06-20 22:47:54] __main__ INFO: \u001b[0mVal 43\n",
      "\u001b[32m[2020-06-20 22:48:07] __main__ INFO: \u001b[0mEpoch 43 loss 1.3560 acc@1 0.5120 acc@5 0.8372\n",
      "\u001b[32m[2020-06-20 22:48:07] __main__ INFO: \u001b[0mElapsed 13.20\n",
      "\u001b[32m[2020-06-20 22:48:07] __main__ INFO: \u001b[0mTrain 44 15093\n",
      "\u001b[32m[2020-06-20 22:50:00] __main__ INFO: \u001b[0mEpoch 44 Step 100/351 lr 0.100000 loss 1.0883 (1.0518) acc@1 0.5859 (0.6089) acc@5 0.8359 (0.8569)\n",
      "\u001b[32m[2020-06-20 22:51:52] __main__ INFO: \u001b[0mEpoch 44 Step 200/351 lr 0.100000 loss 1.0325 (1.0700) acc@1 0.6250 (0.6027) acc@5 0.8750 (0.8534)\n",
      "\u001b[32m[2020-06-20 22:53:45] __main__ INFO: \u001b[0mEpoch 44 Step 300/351 lr 0.100000 loss 1.0083 (1.0778) acc@1 0.6328 (0.6013) acc@5 0.8828 (0.8536)\n",
      "\u001b[32m[2020-06-20 22:54:42] __main__ INFO: \u001b[0mEpoch 44 Step 351/351 lr 0.100000 loss 1.0281 (1.0798) acc@1 0.6172 (0.6004) acc@5 0.9141 (0.8537)\n",
      "\u001b[32m[2020-06-20 22:54:42] __main__ INFO: \u001b[0mElapsed 394.99\n",
      "\u001b[32m[2020-06-20 22:54:42] __main__ INFO: \u001b[0mVal 44\n",
      "\u001b[32m[2020-06-20 22:54:56] __main__ INFO: \u001b[0mEpoch 44 loss 1.2951 acc@1 0.5406 acc@5 0.8476\n",
      "\u001b[32m[2020-06-20 22:54:56] __main__ INFO: \u001b[0mElapsed 13.24\n",
      "\u001b[32m[2020-06-20 22:54:56] __main__ INFO: \u001b[0mTrain 45 15444\n",
      "\u001b[32m[2020-06-20 22:56:48] __main__ INFO: \u001b[0mEpoch 45 Step 100/351 lr 0.100000 loss 1.0177 (1.0574) acc@1 0.6562 (0.6096) acc@5 0.8281 (0.8573)\n",
      "\u001b[32m[2020-06-20 22:58:41] __main__ INFO: \u001b[0mEpoch 45 Step 200/351 lr 0.100000 loss 1.2564 (1.0607) acc@1 0.5781 (0.6079) acc@5 0.8203 (0.8561)\n",
      "\u001b[32m[2020-06-20 23:00:33] __main__ INFO: \u001b[0mEpoch 45 Step 300/351 lr 0.100000 loss 0.9184 (1.0734) acc@1 0.6484 (0.6029) acc@5 0.8750 (0.8554)\n",
      "\u001b[32m[2020-06-20 23:01:30] __main__ INFO: \u001b[0mEpoch 45 Step 351/351 lr 0.100000 loss 1.0201 (1.0784) acc@1 0.6094 (0.6015) acc@5 0.8594 (0.8555)\n",
      "\u001b[32m[2020-06-20 23:01:31] __main__ INFO: \u001b[0mElapsed 395.00\n",
      "\u001b[32m[2020-06-20 23:01:31] __main__ INFO: \u001b[0mVal 45\n",
      "\u001b[32m[2020-06-20 23:01:44] __main__ INFO: \u001b[0mEpoch 45 loss 1.4405 acc@1 0.4958 acc@5 0.8544\n",
      "\u001b[32m[2020-06-20 23:01:44] __main__ INFO: \u001b[0mElapsed 13.21\n",
      "\u001b[32m[2020-06-20 23:01:44] __main__ INFO: \u001b[0mTrain 46 15795\n",
      "\u001b[32m[2020-06-20 23:03:36] __main__ INFO: \u001b[0mEpoch 46 Step 100/351 lr 0.100000 loss 1.0211 (1.0632) acc@1 0.6250 (0.6077) acc@5 0.8516 (0.8554)\n",
      "\u001b[32m[2020-06-20 23:05:29] __main__ INFO: \u001b[0mEpoch 46 Step 200/351 lr 0.100000 loss 1.0392 (1.0760) acc@1 0.6016 (0.6024) acc@5 0.8359 (0.8528)\n",
      "\u001b[32m[2020-06-20 23:07:21] __main__ INFO: \u001b[0mEpoch 46 Step 300/351 lr 0.100000 loss 1.0920 (1.0774) acc@1 0.6094 (0.6014) acc@5 0.8594 (0.8540)\n",
      "\u001b[32m[2020-06-20 23:08:19] __main__ INFO: \u001b[0mEpoch 46 Step 351/351 lr 0.100000 loss 1.3690 (1.0768) acc@1 0.5156 (0.6019) acc@5 0.8594 (0.8551)\n",
      "\u001b[32m[2020-06-20 23:08:19] __main__ INFO: \u001b[0mElapsed 395.08\n",
      "\u001b[32m[2020-06-20 23:08:19] __main__ INFO: \u001b[0mVal 46\n",
      "\u001b[32m[2020-06-20 23:08:32] __main__ INFO: \u001b[0mEpoch 46 loss 1.3498 acc@1 0.5310 acc@5 0.8418\n",
      "\u001b[32m[2020-06-20 23:08:32] __main__ INFO: \u001b[0mElapsed 13.25\n",
      "\u001b[32m[2020-06-20 23:08:32] __main__ INFO: \u001b[0mTrain 47 16146\n",
      "\u001b[32m[2020-06-20 23:10:25] __main__ INFO: \u001b[0mEpoch 47 Step 100/351 lr 0.100000 loss 0.9174 (1.0580) acc@1 0.6562 (0.6060) acc@5 0.9141 (0.8514)\n",
      "\u001b[32m[2020-06-20 23:12:17] __main__ INFO: \u001b[0mEpoch 47 Step 200/351 lr 0.100000 loss 1.1594 (1.0617) acc@1 0.6016 (0.6062) acc@5 0.8828 (0.8538)\n",
      "\u001b[32m[2020-06-20 23:14:10] __main__ INFO: \u001b[0mEpoch 47 Step 300/351 lr 0.100000 loss 1.0377 (1.0688) acc@1 0.6250 (0.6035) acc@5 0.8594 (0.8540)\n",
      "\u001b[32m[2020-06-20 23:15:07] __main__ INFO: \u001b[0mEpoch 47 Step 351/351 lr 0.100000 loss 1.0334 (1.0728) acc@1 0.6250 (0.6023) acc@5 0.8281 (0.8544)\n",
      "\u001b[32m[2020-06-20 23:15:07] __main__ INFO: \u001b[0mElapsed 394.94\n",
      "\u001b[32m[2020-06-20 23:15:07] __main__ INFO: \u001b[0mVal 47\n",
      "\u001b[32m[2020-06-20 23:15:20] __main__ INFO: \u001b[0mEpoch 47 loss 1.2620 acc@1 0.5390 acc@5 0.8484\n",
      "\u001b[32m[2020-06-20 23:15:20] __main__ INFO: \u001b[0mElapsed 13.21\n",
      "\u001b[32m[2020-06-20 23:15:20] __main__ INFO: \u001b[0mTrain 48 16497\n",
      "\u001b[32m[2020-06-20 23:17:13] __main__ INFO: \u001b[0mEpoch 48 Step 100/351 lr 0.100000 loss 1.0388 (1.0501) acc@1 0.5859 (0.6083) acc@5 0.8281 (0.8577)\n",
      "\u001b[32m[2020-06-20 23:19:05] __main__ INFO: \u001b[0mEpoch 48 Step 200/351 lr 0.100000 loss 1.1410 (1.0673) acc@1 0.5391 (0.6044) acc@5 0.8516 (0.8534)\n",
      "\u001b[32m[2020-06-20 23:20:58] __main__ INFO: \u001b[0mEpoch 48 Step 300/351 lr 0.100000 loss 1.1415 (1.0743) acc@1 0.5938 (0.6033) acc@5 0.8594 (0.8529)\n",
      "\u001b[32m[2020-06-20 23:21:55] __main__ INFO: \u001b[0mEpoch 48 Step 351/351 lr 0.100000 loss 1.1042 (1.0751) acc@1 0.5938 (0.6026) acc@5 0.8750 (0.8533)\n",
      "\u001b[32m[2020-06-20 23:21:55] __main__ INFO: \u001b[0mElapsed 394.97\n",
      "\u001b[32m[2020-06-20 23:21:55] __main__ INFO: \u001b[0mVal 48\n",
      "\u001b[32m[2020-06-20 23:22:08] __main__ INFO: \u001b[0mEpoch 48 loss 1.2797 acc@1 0.5398 acc@5 0.8432\n",
      "\u001b[32m[2020-06-20 23:22:08] __main__ INFO: \u001b[0mElapsed 13.24\n",
      "\u001b[32m[2020-06-20 23:22:08] __main__ INFO: \u001b[0mTrain 49 16848\n",
      "\u001b[32m[2020-06-20 23:24:01] __main__ INFO: \u001b[0mEpoch 49 Step 100/351 lr 0.100000 loss 0.9048 (1.0712) acc@1 0.7031 (0.6021) acc@5 0.9062 (0.8493)\n",
      "\u001b[32m[2020-06-20 23:25:53] __main__ INFO: \u001b[0mEpoch 49 Step 200/351 lr 0.100000 loss 1.1522 (1.0644) acc@1 0.5469 (0.6037) acc@5 0.8125 (0.8532)\n",
      "\u001b[32m[2020-06-20 23:27:46] __main__ INFO: \u001b[0mEpoch 49 Step 300/351 lr 0.100000 loss 1.3274 (1.0733) acc@1 0.4766 (0.6014) acc@5 0.8594 (0.8547)\n",
      "\u001b[32m[2020-06-20 23:28:43] __main__ INFO: \u001b[0mEpoch 49 Step 351/351 lr 0.100000 loss 1.0527 (1.0735) acc@1 0.6016 (0.6011) acc@5 0.8516 (0.8542)\n",
      "\u001b[32m[2020-06-20 23:28:43] __main__ INFO: \u001b[0mElapsed 394.79\n",
      "\u001b[32m[2020-06-20 23:28:43] __main__ INFO: \u001b[0mVal 49\n",
      "\u001b[32m[2020-06-20 23:28:56] __main__ INFO: \u001b[0mEpoch 49 loss 1.4011 acc@1 0.5246 acc@5 0.8378\n",
      "\u001b[32m[2020-06-20 23:28:56] __main__ INFO: \u001b[0mElapsed 13.23\n",
      "\u001b[32m[2020-06-20 23:28:56] __main__ INFO: \u001b[0mTrain 50 17199\n",
      "\u001b[32m[2020-06-20 23:30:49] __main__ INFO: \u001b[0mEpoch 50 Step 100/351 lr 0.100000 loss 1.1450 (1.0565) acc@1 0.6016 (0.6068) acc@5 0.8281 (0.8592)\n",
      "\u001b[32m[2020-06-20 23:32:42] __main__ INFO: \u001b[0mEpoch 50 Step 200/351 lr 0.100000 loss 1.0860 (1.0731) acc@1 0.5938 (0.6022) acc@5 0.8516 (0.8538)\n",
      "\u001b[32m[2020-06-20 23:34:34] __main__ INFO: \u001b[0mEpoch 50 Step 300/351 lr 0.100000 loss 1.1956 (1.0806) acc@1 0.5781 (0.5986) acc@5 0.8516 (0.8515)\n",
      "\u001b[32m[2020-06-20 23:35:31] __main__ INFO: \u001b[0mEpoch 50 Step 351/351 lr 0.100000 loss 0.9858 (1.0751) acc@1 0.6250 (0.6012) acc@5 0.8906 (0.8533)\n",
      "\u001b[32m[2020-06-20 23:35:31] __main__ INFO: \u001b[0mElapsed 394.93\n",
      "\u001b[32m[2020-06-20 23:35:31] __main__ INFO: \u001b[0mVal 50\n",
      "\u001b[32m[2020-06-20 23:35:45] __main__ INFO: \u001b[0mEpoch 50 loss 1.4811 acc@1 0.4914 acc@5 0.8418\n",
      "\u001b[32m[2020-06-20 23:35:45] __main__ INFO: \u001b[0mElapsed 13.22\n",
      "\u001b[32m[2020-06-20 23:35:45] __main__ INFO: \u001b[0mTrain 51 17550\n",
      "\u001b[32m[2020-06-20 23:37:37] __main__ INFO: \u001b[0mEpoch 51 Step 100/351 lr 0.100000 loss 1.0283 (1.0460) acc@1 0.6641 (0.6121) acc@5 0.8750 (0.8536)\n",
      "\u001b[32m[2020-06-20 23:39:30] __main__ INFO: \u001b[0mEpoch 51 Step 200/351 lr 0.100000 loss 1.2288 (1.0558) acc@1 0.5234 (0.6111) acc@5 0.7812 (0.8558)\n",
      "\u001b[32m[2020-06-20 23:41:22] __main__ INFO: \u001b[0mEpoch 51 Step 300/351 lr 0.100000 loss 1.1537 (1.0650) acc@1 0.5703 (0.6072) acc@5 0.7812 (0.8551)\n",
      "\u001b[32m[2020-06-20 23:42:19] __main__ INFO: \u001b[0mEpoch 51 Step 351/351 lr 0.100000 loss 1.1534 (1.0715) acc@1 0.5234 (0.6036) acc@5 0.8516 (0.8539)\n",
      "\u001b[32m[2020-06-20 23:42:19] __main__ INFO: \u001b[0mElapsed 394.85\n",
      "\u001b[32m[2020-06-20 23:42:19] __main__ INFO: \u001b[0mVal 51\n",
      "\u001b[32m[2020-06-20 23:42:33] __main__ INFO: \u001b[0mEpoch 51 loss 1.3189 acc@1 0.5332 acc@5 0.8382\n",
      "\u001b[32m[2020-06-20 23:42:33] __main__ INFO: \u001b[0mElapsed 13.23\n",
      "\u001b[32m[2020-06-20 23:42:33] __main__ INFO: \u001b[0mTrain 52 17901\n",
      "\u001b[32m[2020-06-20 23:44:25] __main__ INFO: \u001b[0mEpoch 52 Step 100/351 lr 0.100000 loss 1.1187 (1.0390) acc@1 0.5781 (0.6113) acc@5 0.8516 (0.8605)\n",
      "\u001b[32m[2020-06-20 23:46:18] __main__ INFO: \u001b[0mEpoch 52 Step 200/351 lr 0.100000 loss 1.1256 (1.0499) acc@1 0.5625 (0.6086) acc@5 0.8672 (0.8585)\n",
      "\u001b[32m[2020-06-20 23:48:10] __main__ INFO: \u001b[0mEpoch 52 Step 300/351 lr 0.100000 loss 0.9521 (1.0621) acc@1 0.6484 (0.6052) acc@5 0.8672 (0.8564)\n",
      "\u001b[32m[2020-06-20 23:49:08] __main__ INFO: \u001b[0mEpoch 52 Step 351/351 lr 0.100000 loss 1.3349 (1.0664) acc@1 0.4844 (0.6036) acc@5 0.7969 (0.8553)\n",
      "\u001b[32m[2020-06-20 23:49:08] __main__ INFO: \u001b[0mElapsed 394.91\n",
      "\u001b[32m[2020-06-20 23:49:08] __main__ INFO: \u001b[0mVal 52\n",
      "\u001b[32m[2020-06-20 23:49:21] __main__ INFO: \u001b[0mEpoch 52 loss 1.4157 acc@1 0.5154 acc@5 0.8344\n",
      "\u001b[32m[2020-06-20 23:49:21] __main__ INFO: \u001b[0mElapsed 13.24\n",
      "\u001b[32m[2020-06-20 23:49:21] __main__ INFO: \u001b[0mTrain 53 18252\n",
      "\u001b[32m[2020-06-20 23:51:13] __main__ INFO: \u001b[0mEpoch 53 Step 100/351 lr 0.100000 loss 0.9917 (1.0515) acc@1 0.6406 (0.6079) acc@5 0.8594 (0.8600)\n",
      "\u001b[32m[2020-06-20 23:53:06] __main__ INFO: \u001b[0mEpoch 53 Step 200/351 lr 0.100000 loss 1.1919 (1.0580) acc@1 0.5781 (0.6073) acc@5 0.8516 (0.8573)\n",
      "\u001b[32m[2020-06-20 23:54:58] __main__ INFO: \u001b[0mEpoch 53 Step 300/351 lr 0.100000 loss 1.2294 (1.0665) acc@1 0.5312 (0.6043) acc@5 0.8281 (0.8565)\n",
      "\u001b[32m[2020-06-20 23:55:56] __main__ INFO: \u001b[0mEpoch 53 Step 351/351 lr 0.100000 loss 1.2340 (1.0679) acc@1 0.5547 (0.6033) acc@5 0.8047 (0.8559)\n",
      "\u001b[32m[2020-06-20 23:55:56] __main__ INFO: \u001b[0mElapsed 394.90\n",
      "\u001b[32m[2020-06-20 23:55:56] __main__ INFO: \u001b[0mVal 53\n",
      "\u001b[32m[2020-06-20 23:56:09] __main__ INFO: \u001b[0mEpoch 53 loss 1.3242 acc@1 0.5288 acc@5 0.8450\n",
      "\u001b[32m[2020-06-20 23:56:09] __main__ INFO: \u001b[0mElapsed 13.24\n",
      "\u001b[32m[2020-06-20 23:56:09] __main__ INFO: \u001b[0mTrain 54 18603\n",
      "\u001b[32m[2020-06-20 23:58:02] __main__ INFO: \u001b[0mEpoch 54 Step 100/351 lr 0.100000 loss 1.3026 (1.0610) acc@1 0.5391 (0.6008) acc@5 0.8203 (0.8539)\n",
      "\u001b[32m[2020-06-20 23:59:54] __main__ INFO: \u001b[0mEpoch 54 Step 200/351 lr 0.100000 loss 0.9792 (1.0646) acc@1 0.6797 (0.6041) acc@5 0.8516 (0.8530)\n",
      "\u001b[32m[2020-06-21 00:01:46] __main__ INFO: \u001b[0mEpoch 54 Step 300/351 lr 0.100000 loss 1.1193 (1.0661) acc@1 0.5859 (0.6029) acc@5 0.8125 (0.8552)\n",
      "\u001b[32m[2020-06-21 00:02:44] __main__ INFO: \u001b[0mEpoch 54 Step 351/351 lr 0.100000 loss 1.0275 (1.0716) acc@1 0.6250 (0.6015) acc@5 0.8828 (0.8552)\n",
      "\u001b[32m[2020-06-21 00:02:44] __main__ INFO: \u001b[0mElapsed 394.84\n",
      "\u001b[32m[2020-06-21 00:02:44] __main__ INFO: \u001b[0mVal 54\n",
      "\u001b[32m[2020-06-21 00:02:57] __main__ INFO: \u001b[0mEpoch 54 loss 1.2450 acc@1 0.5442 acc@5 0.8498\n",
      "\u001b[32m[2020-06-21 00:02:57] __main__ INFO: \u001b[0mElapsed 13.23\n",
      "\u001b[32m[2020-06-21 00:02:57] __main__ INFO: \u001b[0mTrain 55 18954\n",
      "\u001b[32m[2020-06-21 00:04:50] __main__ INFO: \u001b[0mEpoch 55 Step 100/351 lr 0.100000 loss 1.0957 (1.0562) acc@1 0.5859 (0.6060) acc@5 0.8750 (0.8503)\n",
      "\u001b[32m[2020-06-21 00:06:42] __main__ INFO: \u001b[0mEpoch 55 Step 200/351 lr 0.100000 loss 1.1509 (1.0584) acc@1 0.5625 (0.6063) acc@5 0.8203 (0.8523)\n",
      "\u001b[32m[2020-06-21 00:08:35] __main__ INFO: \u001b[0mEpoch 55 Step 300/351 lr 0.100000 loss 1.0094 (1.0608) acc@1 0.6094 (0.6065) acc@5 0.8672 (0.8535)\n",
      "\u001b[32m[2020-06-21 00:09:32] __main__ INFO: \u001b[0mEpoch 55 Step 351/351 lr 0.100000 loss 1.0941 (1.0639) acc@1 0.5859 (0.6047) acc@5 0.7969 (0.8547)\n",
      "\u001b[32m[2020-06-21 00:09:32] __main__ INFO: \u001b[0mElapsed 394.97\n",
      "\u001b[32m[2020-06-21 00:09:32] __main__ INFO: \u001b[0mVal 55\n",
      "\u001b[32m[2020-06-21 00:09:45] __main__ INFO: \u001b[0mEpoch 55 loss 1.3210 acc@1 0.5278 acc@5 0.8354\n",
      "\u001b[32m[2020-06-21 00:09:45] __main__ INFO: \u001b[0mElapsed 13.24\n",
      "\u001b[32m[2020-06-21 00:09:45] __main__ INFO: \u001b[0mTrain 56 19305\n",
      "\u001b[32m[2020-06-21 00:11:38] __main__ INFO: \u001b[0mEpoch 56 Step 100/351 lr 0.100000 loss 1.0756 (1.0546) acc@1 0.5938 (0.6106) acc@5 0.8438 (0.8541)\n",
      "\u001b[32m[2020-06-21 00:13:30] __main__ INFO: \u001b[0mEpoch 56 Step 200/351 lr 0.100000 loss 0.9721 (1.0617) acc@1 0.6562 (0.6052) acc@5 0.9375 (0.8519)\n",
      "\u001b[32m[2020-06-21 00:15:23] __main__ INFO: \u001b[0mEpoch 56 Step 300/351 lr 0.100000 loss 1.1018 (1.0638) acc@1 0.6172 (0.6049) acc@5 0.8984 (0.8520)\n",
      "\u001b[32m[2020-06-21 00:16:20] __main__ INFO: \u001b[0mEpoch 56 Step 351/351 lr 0.100000 loss 0.8760 (1.0646) acc@1 0.6797 (0.6048) acc@5 0.8984 (0.8522)\n",
      "\u001b[32m[2020-06-21 00:16:20] __main__ INFO: \u001b[0mElapsed 394.92\n",
      "\u001b[32m[2020-06-21 00:16:20] __main__ INFO: \u001b[0mVal 56\n",
      "\u001b[32m[2020-06-21 00:16:33] __main__ INFO: \u001b[0mEpoch 56 loss 1.2257 acc@1 0.5600 acc@5 0.8480\n",
      "\u001b[32m[2020-06-21 00:16:33] __main__ INFO: \u001b[0mElapsed 13.23\n",
      "\u001b[32m[2020-06-21 00:16:33] __main__ INFO: \u001b[0mTrain 57 19656\n",
      "\u001b[32m[2020-06-21 00:18:26] __main__ INFO: \u001b[0mEpoch 57 Step 100/351 lr 0.100000 loss 1.0046 (1.0561) acc@1 0.5703 (0.6077) acc@5 0.8516 (0.8580)\n",
      "\u001b[32m[2020-06-21 00:20:18] __main__ INFO: \u001b[0mEpoch 57 Step 200/351 lr 0.100000 loss 1.2589 (1.0612) acc@1 0.5156 (0.6068) acc@5 0.8281 (0.8561)\n",
      "\u001b[32m[2020-06-21 00:22:11] __main__ INFO: \u001b[0mEpoch 57 Step 300/351 lr 0.100000 loss 1.1441 (1.0654) acc@1 0.5547 (0.6057) acc@5 0.8438 (0.8548)\n",
      "\u001b[32m[2020-06-21 00:23:08] __main__ INFO: \u001b[0mEpoch 57 Step 351/351 lr 0.100000 loss 1.0794 (1.0700) acc@1 0.6172 (0.6046) acc@5 0.8594 (0.8541)\n",
      "\u001b[32m[2020-06-21 00:23:08] __main__ INFO: \u001b[0mElapsed 394.87\n",
      "\u001b[32m[2020-06-21 00:23:08] __main__ INFO: \u001b[0mVal 57\n",
      "\u001b[32m[2020-06-21 00:23:22] __main__ INFO: \u001b[0mEpoch 57 loss 1.2737 acc@1 0.5528 acc@5 0.8486\n",
      "\u001b[32m[2020-06-21 00:23:22] __main__ INFO: \u001b[0mElapsed 13.26\n",
      "\u001b[32m[2020-06-21 00:23:22] __main__ INFO: \u001b[0mTrain 58 20007\n",
      "\u001b[32m[2020-06-21 00:25:14] __main__ INFO: \u001b[0mEpoch 58 Step 100/351 lr 0.100000 loss 1.0732 (1.0306) acc@1 0.5781 (0.6157) acc@5 0.9141 (0.8568)\n",
      "\u001b[32m[2020-06-21 00:27:07] __main__ INFO: \u001b[0mEpoch 58 Step 200/351 lr 0.100000 loss 1.0304 (1.0522) acc@1 0.6328 (0.6106) acc@5 0.8594 (0.8566)\n",
      "\u001b[32m[2020-06-21 00:28:59] __main__ INFO: \u001b[0mEpoch 58 Step 300/351 lr 0.100000 loss 1.1205 (1.0560) acc@1 0.6016 (0.6086) acc@5 0.8281 (0.8566)\n",
      "\u001b[32m[2020-06-21 00:29:56] __main__ INFO: \u001b[0mEpoch 58 Step 351/351 lr 0.100000 loss 1.1068 (1.0601) acc@1 0.5938 (0.6069) acc@5 0.8281 (0.8560)\n",
      "\u001b[32m[2020-06-21 00:29:56] __main__ INFO: \u001b[0mElapsed 394.77\n",
      "\u001b[32m[2020-06-21 00:29:56] __main__ INFO: \u001b[0mVal 58\n",
      "\u001b[32m[2020-06-21 00:30:10] __main__ INFO: \u001b[0mEpoch 58 loss 1.3440 acc@1 0.5342 acc@5 0.8506\n",
      "\u001b[32m[2020-06-21 00:30:10] __main__ INFO: \u001b[0mElapsed 13.24\n",
      "\u001b[32m[2020-06-21 00:30:10] __main__ INFO: \u001b[0mTrain 59 20358\n",
      "\u001b[32m[2020-06-21 00:32:02] __main__ INFO: \u001b[0mEpoch 59 Step 100/351 lr 0.100000 loss 1.0506 (1.0360) acc@1 0.6406 (0.6130) acc@5 0.8828 (0.8540)\n",
      "\u001b[32m[2020-06-21 00:33:54] __main__ INFO: \u001b[0mEpoch 59 Step 200/351 lr 0.100000 loss 0.9773 (1.0524) acc@1 0.6172 (0.6086) acc@5 0.8750 (0.8544)\n",
      "\u001b[32m[2020-06-21 00:35:47] __main__ INFO: \u001b[0mEpoch 59 Step 300/351 lr 0.100000 loss 1.0380 (1.0642) acc@1 0.6016 (0.6036) acc@5 0.8594 (0.8531)\n",
      "\u001b[32m[2020-06-21 00:36:44] __main__ INFO: \u001b[0mEpoch 59 Step 351/351 lr 0.100000 loss 1.0366 (1.0657) acc@1 0.6172 (0.6038) acc@5 0.8594 (0.8525)\n",
      "\u001b[32m[2020-06-21 00:36:44] __main__ INFO: \u001b[0mElapsed 394.65\n",
      "\u001b[32m[2020-06-21 00:36:44] __main__ INFO: \u001b[0mVal 59\n",
      "\u001b[32m[2020-06-21 00:36:57] __main__ INFO: \u001b[0mEpoch 59 loss 1.2762 acc@1 0.5544 acc@5 0.8506\n",
      "\u001b[32m[2020-06-21 00:36:57] __main__ INFO: \u001b[0mElapsed 13.23\n",
      "\u001b[32m[2020-06-21 00:36:57] __main__ INFO: \u001b[0mTrain 60 20709\n",
      "\u001b[32m[2020-06-21 00:38:50] __main__ INFO: \u001b[0mEpoch 60 Step 100/351 lr 0.100000 loss 1.0686 (1.0362) acc@1 0.6172 (0.6155) acc@5 0.8359 (0.8581)\n",
      "\u001b[32m[2020-06-21 00:40:42] __main__ INFO: \u001b[0mEpoch 60 Step 200/351 lr 0.100000 loss 1.1015 (1.0465) acc@1 0.5625 (0.6106) acc@5 0.8359 (0.8550)\n",
      "\u001b[32m[2020-06-21 00:42:35] __main__ INFO: \u001b[0mEpoch 60 Step 300/351 lr 0.100000 loss 0.9650 (1.0592) acc@1 0.6406 (0.6059) acc@5 0.8672 (0.8543)\n",
      "\u001b[32m[2020-06-21 00:43:32] __main__ INFO: \u001b[0mEpoch 60 Step 351/351 lr 0.100000 loss 1.0719 (1.0634) acc@1 0.6250 (0.6045) acc@5 0.8906 (0.8539)\n",
      "\u001b[32m[2020-06-21 00:43:32] __main__ INFO: \u001b[0mElapsed 394.62\n",
      "\u001b[32m[2020-06-21 00:43:32] __main__ INFO: \u001b[0mVal 60\n",
      "\u001b[32m[2020-06-21 00:43:45] __main__ INFO: \u001b[0mEpoch 60 loss 1.2921 acc@1 0.5300 acc@5 0.8368\n",
      "\u001b[32m[2020-06-21 00:43:45] __main__ INFO: \u001b[0mElapsed 13.22\n",
      "\u001b[32m[2020-06-21 00:43:45] __main__ INFO: \u001b[0mTrain 61 21060\n",
      "\u001b[32m[2020-06-21 00:45:38] __main__ INFO: \u001b[0mEpoch 61 Step 100/351 lr 0.020000 loss 0.9385 (0.9377) acc@1 0.6328 (0.6541) acc@5 0.8438 (0.8605)\n",
      "\u001b[32m[2020-06-21 00:47:30] __main__ INFO: \u001b[0mEpoch 61 Step 200/351 lr 0.020000 loss 0.8312 (0.9133) acc@1 0.7109 (0.6608) acc@5 0.8359 (0.8595)\n",
      "\u001b[32m[2020-06-21 00:49:23] __main__ INFO: \u001b[0mEpoch 61 Step 300/351 lr 0.020000 loss 0.7774 (0.8964) acc@1 0.7266 (0.6657) acc@5 0.9141 (0.8603)\n",
      "\u001b[32m[2020-06-21 00:50:20] __main__ INFO: \u001b[0mEpoch 61 Step 351/351 lr 0.020000 loss 0.7975 (0.8922) acc@1 0.6719 (0.6663) acc@5 0.9062 (0.8604)\n",
      "\u001b[32m[2020-06-21 00:50:20] __main__ INFO: \u001b[0mElapsed 394.69\n",
      "\u001b[32m[2020-06-21 00:50:20] __main__ INFO: \u001b[0mVal 61\n",
      "\u001b[32m[2020-06-21 00:50:33] __main__ INFO: \u001b[0mEpoch 61 loss 1.0343 acc@1 0.6244 acc@5 0.8616\n",
      "\u001b[32m[2020-06-21 00:50:33] __main__ INFO: \u001b[0mElapsed 13.22\n",
      "\u001b[32m[2020-06-21 00:50:33] __main__ INFO: \u001b[0mTrain 62 21411\n",
      "\u001b[32m[2020-06-21 00:52:26] __main__ INFO: \u001b[0mEpoch 62 Step 100/351 lr 0.020000 loss 0.8973 (0.8242) acc@1 0.6562 (0.6879) acc@5 0.8359 (0.8634)\n",
      "\u001b[32m[2020-06-21 00:54:18] __main__ INFO: \u001b[0mEpoch 62 Step 200/351 lr 0.020000 loss 0.9313 (0.8245) acc@1 0.6406 (0.6898) acc@5 0.8203 (0.8631)\n",
      "\u001b[32m[2020-06-21 00:56:11] __main__ INFO: \u001b[0mEpoch 62 Step 300/351 lr 0.020000 loss 0.9315 (0.8282) acc@1 0.6406 (0.6878) acc@5 0.8203 (0.8631)\n",
      "\u001b[32m[2020-06-21 00:57:08] __main__ INFO: \u001b[0mEpoch 62 Step 351/351 lr 0.020000 loss 0.9525 (0.8315) acc@1 0.6250 (0.6861) acc@5 0.8438 (0.8627)\n",
      "\u001b[32m[2020-06-21 00:57:08] __main__ INFO: \u001b[0mElapsed 394.66\n",
      "\u001b[32m[2020-06-21 00:57:08] __main__ INFO: \u001b[0mVal 62\n",
      "\u001b[32m[2020-06-21 00:57:21] __main__ INFO: \u001b[0mEpoch 62 loss 1.0577 acc@1 0.6234 acc@5 0.8614\n",
      "\u001b[32m[2020-06-21 00:57:21] __main__ INFO: \u001b[0mElapsed 13.24\n",
      "\u001b[32m[2020-06-21 00:57:21] __main__ INFO: \u001b[0mTrain 63 21762\n",
      "\u001b[32m[2020-06-21 00:59:14] __main__ INFO: \u001b[0mEpoch 63 Step 100/351 lr 0.020000 loss 0.7292 (0.7923) acc@1 0.7422 (0.7034) acc@5 0.8828 (0.8694)\n",
      "\u001b[32m[2020-06-21 01:01:06] __main__ INFO: \u001b[0mEpoch 63 Step 200/351 lr 0.020000 loss 0.8802 (0.8033) acc@1 0.6484 (0.6982) acc@5 0.8516 (0.8662)\n",
      "\u001b[32m[2020-06-21 01:02:58] __main__ INFO: \u001b[0mEpoch 63 Step 300/351 lr 0.020000 loss 0.7149 (0.8066) acc@1 0.7344 (0.6965) acc@5 0.8906 (0.8647)\n",
      "\u001b[32m[2020-06-21 01:03:56] __main__ INFO: \u001b[0mEpoch 63 Step 351/351 lr 0.020000 loss 0.9300 (0.8087) acc@1 0.6328 (0.6956) acc@5 0.8125 (0.8643)\n",
      "\u001b[32m[2020-06-21 01:03:56] __main__ INFO: \u001b[0mElapsed 394.66\n",
      "\u001b[32m[2020-06-21 01:03:56] __main__ INFO: \u001b[0mVal 63\n",
      "\u001b[32m[2020-06-21 01:04:09] __main__ INFO: \u001b[0mEpoch 63 loss 1.0621 acc@1 0.6220 acc@5 0.8618\n",
      "\u001b[32m[2020-06-21 01:04:09] __main__ INFO: \u001b[0mElapsed 13.22\n",
      "\u001b[32m[2020-06-21 01:04:09] __main__ INFO: \u001b[0mTrain 64 22113\n",
      "\u001b[32m[2020-06-21 01:06:02] __main__ INFO: \u001b[0mEpoch 64 Step 100/351 lr 0.020000 loss 0.8395 (0.7806) acc@1 0.6562 (0.7084) acc@5 0.8516 (0.8691)\n",
      "\u001b[32m[2020-06-21 01:07:54] __main__ INFO: \u001b[0mEpoch 64 Step 200/351 lr 0.020000 loss 0.7860 (0.7897) acc@1 0.7578 (0.7023) acc@5 0.8984 (0.8655)\n",
      "\u001b[32m[2020-06-21 01:09:46] __main__ INFO: \u001b[0mEpoch 64 Step 300/351 lr 0.020000 loss 0.8111 (0.7910) acc@1 0.7188 (0.7011) acc@5 0.8516 (0.8664)\n",
      "\u001b[32m[2020-06-21 01:10:44] __main__ INFO: \u001b[0mEpoch 64 Step 351/351 lr 0.020000 loss 1.0393 (0.7917) acc@1 0.6094 (0.7005) acc@5 0.8438 (0.8660)\n",
      "\u001b[32m[2020-06-21 01:10:44] __main__ INFO: \u001b[0mElapsed 394.64\n",
      "\u001b[32m[2020-06-21 01:10:44] __main__ INFO: \u001b[0mVal 64\n",
      "\u001b[32m[2020-06-21 01:10:57] __main__ INFO: \u001b[0mEpoch 64 loss 1.1048 acc@1 0.6180 acc@5 0.8608\n",
      "\u001b[32m[2020-06-21 01:10:57] __main__ INFO: \u001b[0mElapsed 13.25\n",
      "\u001b[32m[2020-06-21 01:10:57] __main__ INFO: \u001b[0mTrain 65 22464\n",
      "\u001b[32m[2020-06-21 01:12:49] __main__ INFO: \u001b[0mEpoch 65 Step 100/351 lr 0.020000 loss 0.8076 (0.7692) acc@1 0.6953 (0.7105) acc@5 0.8750 (0.8706)\n",
      "\u001b[32m[2020-06-21 01:14:42] __main__ INFO: \u001b[0mEpoch 65 Step 200/351 lr 0.020000 loss 0.8915 (0.7724) acc@1 0.6797 (0.7090) acc@5 0.8438 (0.8689)\n",
      "\u001b[32m[2020-06-21 01:16:34] __main__ INFO: \u001b[0mEpoch 65 Step 300/351 lr 0.020000 loss 0.7072 (0.7782) acc@1 0.7266 (0.7065) acc@5 0.8984 (0.8681)\n",
      "\u001b[32m[2020-06-21 01:17:31] __main__ INFO: \u001b[0mEpoch 65 Step 351/351 lr 0.020000 loss 0.8322 (0.7827) acc@1 0.6719 (0.7043) acc@5 0.8125 (0.8665)\n",
      "\u001b[32m[2020-06-21 01:17:31] __main__ INFO: \u001b[0mElapsed 394.41\n",
      "\u001b[32m[2020-06-21 01:17:31] __main__ INFO: \u001b[0mVal 65\n",
      "\u001b[32m[2020-06-21 01:17:45] __main__ INFO: \u001b[0mEpoch 65 loss 1.0775 acc@1 0.6168 acc@5 0.8612\n",
      "\u001b[32m[2020-06-21 01:17:45] __main__ INFO: \u001b[0mElapsed 13.26\n",
      "\u001b[32m[2020-06-21 01:17:45] __main__ INFO: \u001b[0mTrain 66 22815\n",
      "\u001b[32m[2020-06-21 01:19:37] __main__ INFO: \u001b[0mEpoch 66 Step 100/351 lr 0.020000 loss 0.7367 (0.7726) acc@1 0.7109 (0.7070) acc@5 0.8828 (0.8649)\n",
      "\u001b[32m[2020-06-21 01:21:29] __main__ INFO: \u001b[0mEpoch 66 Step 200/351 lr 0.020000 loss 0.7364 (0.7738) acc@1 0.7109 (0.7064) acc@5 0.8359 (0.8647)\n",
      "\u001b[32m[2020-06-21 01:23:22] __main__ INFO: \u001b[0mEpoch 66 Step 300/351 lr 0.020000 loss 0.7606 (0.7772) acc@1 0.7109 (0.7042) acc@5 0.8438 (0.8662)\n",
      "\u001b[32m[2020-06-21 01:24:19] __main__ INFO: \u001b[0mEpoch 66 Step 351/351 lr 0.020000 loss 0.8650 (0.7796) acc@1 0.6562 (0.7033) acc@5 0.8359 (0.8659)\n",
      "\u001b[32m[2020-06-21 01:24:19] __main__ INFO: \u001b[0mElapsed 394.45\n",
      "\u001b[32m[2020-06-21 01:24:19] __main__ INFO: \u001b[0mVal 66\n",
      "\u001b[32m[2020-06-21 01:24:32] __main__ INFO: \u001b[0mEpoch 66 loss 1.0917 acc@1 0.6188 acc@5 0.8546\n",
      "\u001b[32m[2020-06-21 01:24:32] __main__ INFO: \u001b[0mElapsed 13.22\n",
      "\u001b[32m[2020-06-21 01:24:32] __main__ INFO: \u001b[0mTrain 67 23166\n",
      "\u001b[32m[2020-06-21 01:26:25] __main__ INFO: \u001b[0mEpoch 67 Step 100/351 lr 0.020000 loss 0.6782 (0.7583) acc@1 0.7344 (0.7108) acc@5 0.8672 (0.8712)\n",
      "\u001b[32m[2020-06-21 01:28:17] __main__ INFO: \u001b[0mEpoch 67 Step 200/351 lr 0.020000 loss 0.6644 (0.7710) acc@1 0.7734 (0.7080) acc@5 0.8828 (0.8682)\n",
      "\u001b[32m[2020-06-21 01:30:09] __main__ INFO: \u001b[0mEpoch 67 Step 300/351 lr 0.020000 loss 0.8398 (0.7717) acc@1 0.7031 (0.7067) acc@5 0.8750 (0.8674)\n",
      "\u001b[32m[2020-06-21 01:31:07] __main__ INFO: \u001b[0mEpoch 67 Step 351/351 lr 0.020000 loss 0.6719 (0.7701) acc@1 0.7578 (0.7074) acc@5 0.9062 (0.8675)\n",
      "\u001b[32m[2020-06-21 01:31:07] __main__ INFO: \u001b[0mElapsed 394.44\n",
      "\u001b[32m[2020-06-21 01:31:07] __main__ INFO: \u001b[0mVal 67\n",
      "\u001b[32m[2020-06-21 01:31:20] __main__ INFO: \u001b[0mEpoch 67 loss 1.1034 acc@1 0.6256 acc@5 0.8552\n",
      "\u001b[32m[2020-06-21 01:31:20] __main__ INFO: \u001b[0mElapsed 13.23\n",
      "\u001b[32m[2020-06-21 01:31:20] __main__ INFO: \u001b[0mTrain 68 23517\n",
      "\u001b[32m[2020-06-21 01:33:12] __main__ INFO: \u001b[0mEpoch 68 Step 100/351 lr 0.020000 loss 0.8444 (0.7546) acc@1 0.6797 (0.7135) acc@5 0.8516 (0.8695)\n",
      "\u001b[32m[2020-06-21 01:35:05] __main__ INFO: \u001b[0mEpoch 68 Step 200/351 lr 0.020000 loss 0.8813 (0.7608) acc@1 0.6406 (0.7100) acc@5 0.8438 (0.8680)\n",
      "\u001b[32m[2020-06-21 01:36:57] __main__ INFO: \u001b[0mEpoch 68 Step 300/351 lr 0.020000 loss 0.7257 (0.7725) acc@1 0.7266 (0.7066) acc@5 0.8672 (0.8659)\n",
      "\u001b[32m[2020-06-21 01:37:54] __main__ INFO: \u001b[0mEpoch 68 Step 351/351 lr 0.020000 loss 0.7684 (0.7719) acc@1 0.7188 (0.7068) acc@5 0.8516 (0.8663)\n",
      "\u001b[32m[2020-06-21 01:37:54] __main__ INFO: \u001b[0mElapsed 394.49\n",
      "\u001b[32m[2020-06-21 01:37:54] __main__ INFO: \u001b[0mVal 68\n",
      "\u001b[32m[2020-06-21 01:38:08] __main__ INFO: \u001b[0mEpoch 68 loss 1.1215 acc@1 0.6124 acc@5 0.8586\n",
      "\u001b[32m[2020-06-21 01:38:08] __main__ INFO: \u001b[0mElapsed 13.25\n",
      "\u001b[32m[2020-06-21 01:38:08] __main__ INFO: \u001b[0mTrain 69 23868\n",
      "\u001b[32m[2020-06-21 01:40:00] __main__ INFO: \u001b[0mEpoch 69 Step 100/351 lr 0.020000 loss 0.6615 (0.7432) acc@1 0.7422 (0.7180) acc@5 0.8672 (0.8709)\n",
      "\u001b[32m[2020-06-21 01:41:52] __main__ INFO: \u001b[0mEpoch 69 Step 200/351 lr 0.020000 loss 0.7571 (0.7599) acc@1 0.7031 (0.7108) acc@5 0.8594 (0.8669)\n",
      "\u001b[32m[2020-06-21 01:43:45] __main__ INFO: \u001b[0mEpoch 69 Step 300/351 lr 0.020000 loss 0.7356 (0.7625) acc@1 0.7344 (0.7092) acc@5 0.8750 (0.8684)\n",
      "\u001b[32m[2020-06-21 01:44:42] __main__ INFO: \u001b[0mEpoch 69 Step 351/351 lr 0.020000 loss 0.9508 (0.7676) acc@1 0.6250 (0.7065) acc@5 0.8203 (0.8671)\n",
      "\u001b[32m[2020-06-21 01:44:42] __main__ INFO: \u001b[0mElapsed 394.37\n",
      "\u001b[32m[2020-06-21 01:44:42] __main__ INFO: \u001b[0mVal 69\n",
      "\u001b[32m[2020-06-21 01:44:55] __main__ INFO: \u001b[0mEpoch 69 loss 1.2126 acc@1 0.6000 acc@5 0.8618\n",
      "\u001b[32m[2020-06-21 01:44:55] __main__ INFO: \u001b[0mElapsed 13.24\n",
      "\u001b[32m[2020-06-21 01:44:55] __main__ INFO: \u001b[0mTrain 70 24219\n",
      "\u001b[32m[2020-06-21 01:46:48] __main__ INFO: \u001b[0mEpoch 70 Step 100/351 lr 0.020000 loss 0.7976 (0.7601) acc@1 0.7188 (0.7102) acc@5 0.8516 (0.8689)\n",
      "\u001b[32m[2020-06-21 01:48:40] __main__ INFO: \u001b[0mEpoch 70 Step 200/351 lr 0.020000 loss 0.8113 (0.7722) acc@1 0.6641 (0.7061) acc@5 0.8047 (0.8665)\n",
      "\u001b[32m[2020-06-21 01:50:33] __main__ INFO: \u001b[0mEpoch 70 Step 300/351 lr 0.020000 loss 0.9762 (0.7716) acc@1 0.6484 (0.7060) acc@5 0.8594 (0.8673)\n",
      "\u001b[32m[2020-06-21 01:51:30] __main__ INFO: \u001b[0mEpoch 70 Step 351/351 lr 0.020000 loss 0.8278 (0.7743) acc@1 0.6875 (0.7053) acc@5 0.8594 (0.8664)\n",
      "\u001b[32m[2020-06-21 01:51:30] __main__ INFO: \u001b[0mElapsed 394.63\n",
      "\u001b[32m[2020-06-21 01:51:30] __main__ INFO: \u001b[0mVal 70\n",
      "\u001b[32m[2020-06-21 01:51:43] __main__ INFO: \u001b[0mEpoch 70 loss 1.1837 acc@1 0.6046 acc@5 0.8606\n",
      "\u001b[32m[2020-06-21 01:51:43] __main__ INFO: \u001b[0mElapsed 13.23\n",
      "\u001b[32m[2020-06-21 01:51:43] __main__ INFO: \u001b[0mTrain 71 24570\n",
      "\u001b[32m[2020-06-21 01:53:36] __main__ INFO: \u001b[0mEpoch 71 Step 100/351 lr 0.020000 loss 0.7450 (0.7412) acc@1 0.7344 (0.7170) acc@5 0.8750 (0.8673)\n",
      "\u001b[32m[2020-06-21 01:55:28] __main__ INFO: \u001b[0mEpoch 71 Step 200/351 lr 0.020000 loss 0.8455 (0.7589) acc@1 0.6797 (0.7117) acc@5 0.8359 (0.8661)\n",
      "\u001b[32m[2020-06-21 01:57:20] __main__ INFO: \u001b[0mEpoch 71 Step 300/351 lr 0.020000 loss 0.6556 (0.7632) acc@1 0.7266 (0.7095) acc@5 0.8828 (0.8663)\n",
      "\u001b[32m[2020-06-21 01:58:18] __main__ INFO: \u001b[0mEpoch 71 Step 351/351 lr 0.020000 loss 0.9429 (0.7658) acc@1 0.6484 (0.7083) acc@5 0.8672 (0.8664)\n",
      "\u001b[32m[2020-06-21 01:58:18] __main__ INFO: \u001b[0mElapsed 394.39\n",
      "\u001b[32m[2020-06-21 01:58:18] __main__ INFO: \u001b[0mVal 71\n",
      "\u001b[32m[2020-06-21 01:58:31] __main__ INFO: \u001b[0mEpoch 71 loss 1.1386 acc@1 0.6054 acc@5 0.8574\n",
      "\u001b[32m[2020-06-21 01:58:31] __main__ INFO: \u001b[0mElapsed 13.20\n",
      "\u001b[32m[2020-06-21 01:58:31] __main__ INFO: \u001b[0mTrain 72 24921\n",
      "\u001b[32m[2020-06-21 02:00:23] __main__ INFO: \u001b[0mEpoch 72 Step 100/351 lr 0.020000 loss 0.6699 (0.7451) acc@1 0.7266 (0.7141) acc@5 0.8750 (0.8675)\n",
      "\u001b[32m[2020-06-21 02:02:16] __main__ INFO: \u001b[0mEpoch 72 Step 200/351 lr 0.020000 loss 0.8364 (0.7510) acc@1 0.6562 (0.7137) acc@5 0.8438 (0.8678)\n",
      "\u001b[32m[2020-06-21 02:04:08] __main__ INFO: \u001b[0mEpoch 72 Step 300/351 lr 0.020000 loss 0.8676 (0.7563) acc@1 0.6406 (0.7120) acc@5 0.8203 (0.8686)\n",
      "\u001b[32m[2020-06-21 02:05:05] __main__ INFO: \u001b[0mEpoch 72 Step 351/351 lr 0.020000 loss 0.6563 (0.7616) acc@1 0.7578 (0.7098) acc@5 0.8984 (0.8674)\n",
      "\u001b[32m[2020-06-21 02:05:05] __main__ INFO: \u001b[0mElapsed 394.45\n",
      "\u001b[32m[2020-06-21 02:05:05] __main__ INFO: \u001b[0mVal 72\n",
      "\u001b[32m[2020-06-21 02:05:18] __main__ INFO: \u001b[0mEpoch 72 loss 1.1835 acc@1 0.6040 acc@5 0.8548\n",
      "\u001b[32m[2020-06-21 02:05:18] __main__ INFO: \u001b[0mElapsed 13.21\n",
      "\u001b[32m[2020-06-21 02:05:18] __main__ INFO: \u001b[0mTrain 73 25272\n"
     ]
    }
   ],
   "source": [
    "# Train the model per the settings specified in the original paper\n",
    "os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "!python train.py --config configs/cifar/wrn.yaml \\\n",
    "    model.wrn.depth 28 \\\n",
    "    model.wrn.widening_factor 10 \\\n",
    "    train.batch_size 128 \\\n",
    "    train.base_lr 0.1 \\\n",
    "    dataset.name CIFAR10_RA_2_5 \\\n",
    "    train.output_dir /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_5/exp00 \\\n",
    "    scheduler.epochs 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-06-20 14:52:23] __main__ INFO: \u001b[0mdevice: cuda\n",
      "cudnn:\n",
      "  benchmark: True\n",
      "  deterministic: False\n",
      "dataset:\n",
      "  name: CIFAR10\n",
      "  dataset_dir: ~/.torch/datasets/CIFAR10\n",
      "  image_size: 32\n",
      "  n_channels: 3\n",
      "  n_classes: 10\n",
      "model:\n",
      "  type: cifar\n",
      "  name: resnet\n",
      "  init_mode: kaiming_fan_out\n",
      "  vgg:\n",
      "    n_channels: [64, 128, 256, 512, 512]\n",
      "    n_layers: [2, 2, 3, 3, 3]\n",
      "    use_bn: True\n",
      "  resnet:\n",
      "    depth: 32\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "  resnet_preact:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "  wrn:\n",
      "    depth: 28\n",
      "    initial_channels: 16\n",
      "    widening_factor: 10\n",
      "    drop_rate: 0.0\n",
      "  densenet:\n",
      "    depth: 100\n",
      "    n_blocks: [6, 12, 24, 16]\n",
      "    block_type: bottleneck\n",
      "    growth_rate: 12\n",
      "    drop_rate: 0.0\n",
      "    compression_rate: 0.5\n",
      "  pyramidnet:\n",
      "    depth: 272\n",
      "    n_blocks: [3, 24, 36, 3]\n",
      "    initial_channels: 16\n",
      "    block_type: bottleneck\n",
      "    alpha: 200\n",
      "  resnext:\n",
      "    depth: 29\n",
      "    n_blocks: [3, 4, 6, 3]\n",
      "    initial_channels: 64\n",
      "    cardinality: 8\n",
      "    base_channels: 4\n",
      "  shake_shake:\n",
      "    depth: 26\n",
      "    initial_channels: 96\n",
      "    shake_forward: True\n",
      "    shake_backward: True\n",
      "    shake_image: True\n",
      "  se_resnet_preact:\n",
      "    depth: 110\n",
      "    initial_channels: 16\n",
      "    se_reduction: 16\n",
      "    block_type: basic\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "train:\n",
      "  checkpoint: /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_5/exp00/checkpoint_00300.pth\n",
      "  resume: False\n",
      "  precision: O0\n",
      "  batch_size: 128\n",
      "  subdivision: 1\n",
      "  optimizer: sgd\n",
      "  base_lr: 0.001\n",
      "  momentum: 0.9\n",
      "  nesterov: True\n",
      "  weight_decay: 0.0001\n",
      "  no_weight_decay_on_bn: False\n",
      "  gradient_clip: 0\n",
      "  start_epoch: 0\n",
      "  seed: 0\n",
      "  val_first: True\n",
      "  val_period: 1\n",
      "  val_ratio: 0.1\n",
      "  use_test_as_val: False\n",
      "  output_dir: /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_5/exp00_resume300_150\n",
      "  log_period: 100\n",
      "  checkpoint_period: 100\n",
      "  use_tensorboard: True\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: True\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "  distributed: False\n",
      "  dist:\n",
      "    backend: nccl\n",
      "    init_method: env://\n",
      "    world_size: -1\n",
      "    node_rank: -1\n",
      "    local_rank: 0\n",
      "    use_sync_bn: False\n",
      "tensorboard:\n",
      "  train_images: False\n",
      "  val_images: False\n",
      "  model_params: False\n",
      "optim:\n",
      "  adam:\n",
      "    betas: (0.9, 0.999)\n",
      "  lars:\n",
      "    eps: 1e-09\n",
      "    threshold: 0.01\n",
      "  adabound:\n",
      "    betas: (0.9, 0.999)\n",
      "    final_lr: 0.1\n",
      "    gamma: 0.001\n",
      "scheduler:\n",
      "  epochs: 150\n",
      "  warmup:\n",
      "    type: none\n",
      "    epochs: 0\n",
      "    start_factor: 0.001\n",
      "    exponent: 4\n",
      "  type: multistep\n",
      "  milestones: [80, 120]\n",
      "  lr_decay: 0.1\n",
      "  lr_min_factor: 0.001\n",
      "  T0: 10\n",
      "  T_mul: 1.0\n",
      "validation:\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: False\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "augmentation:\n",
      "  use_random_crop: True\n",
      "  use_random_horizontal_flip: True\n",
      "  use_cutout: False\n",
      "  use_random_erasing: False\n",
      "  use_dual_cutout: False\n",
      "  use_mixup: False\n",
      "  use_ricap: False\n",
      "  use_cutmix: False\n",
      "  use_label_smoothing: False\n",
      "  random_crop:\n",
      "    padding: 4\n",
      "    fill: 0\n",
      "    padding_mode: constant\n",
      "  random_horizontal_flip:\n",
      "    prob: 0.5\n",
      "  cutout:\n",
      "    prob: 1.0\n",
      "    mask_size: 16\n",
      "    cut_inside: False\n",
      "    mask_color: 0\n",
      "    dual_cutout_alpha: 0.1\n",
      "  random_erasing:\n",
      "    prob: 0.5\n",
      "    area_ratio_range: [0.02, 0.4]\n",
      "    min_aspect_ratio: 0.3\n",
      "    max_attempt: 20\n",
      "  mixup:\n",
      "    alpha: 1.0\n",
      "  ricap:\n",
      "    beta: 0.3\n",
      "  cutmix:\n",
      "    alpha: 1.0\n",
      "  label_smoothing:\n",
      "    epsilon: 0.1\n",
      "tta:\n",
      "  use_resize: False\n",
      "  use_center_crop: False\n",
      "  resize: 256\n",
      "test:\n",
      "  checkpoint: ''\n",
      "  output_dir: ''\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    pin_memory: False\n",
      "\u001b[32m[2020-06-20 14:52:23] __main__ INFO: \u001b[0menv_info:\n",
      "  pytorch_version: 1.4.0\n",
      "  cuda_version: 10.1\n",
      "  cudnn_version: 7603\n",
      "  num_gpus: 1\n",
      "  gpu_name: Tesla K80\n",
      "  gpu_capability: 3.7\n",
      "Files already downloaded and verified\n",
      "\u001b[32m[2020-06-20 14:52:26] __main__ INFO: \u001b[0mMACs  : 69.76M\n",
      "\u001b[32m[2020-06-20 14:52:26] __main__ INFO: \u001b[0m#params: 466.91K\n",
      "Selected optimization level O0:  Pure FP32 training.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n",
      "\u001b[32m[2020-06-20 14:52:26] __main__ INFO: \u001b[0mVal 0\n",
      "\u001b[32m[2020-06-20 14:52:27] __main__ INFO: \u001b[0mEpoch 0 loss 1.1018 acc@1 0.8172 acc@5 0.9868\n",
      "\u001b[32m[2020-06-20 14:52:27] __main__ INFO: \u001b[0mElapsed 1.45\n",
      "\u001b[32m[2020-06-20 14:52:27] __main__ INFO: \u001b[0mTrain 1 0\n",
      "\u001b[32m[2020-06-20 14:52:37] __main__ INFO: \u001b[0mEpoch 1 Step 100/351 lr 0.001000 loss 0.4650 (0.4174) acc@1 0.8594 (0.8884) acc@5 1.0000 (0.9944)\n",
      "\u001b[32m[2020-06-20 14:52:46] __main__ INFO: \u001b[0mEpoch 1 Step 200/351 lr 0.001000 loss 0.5242 (0.3990) acc@1 0.8438 (0.8923) acc@5 0.9922 (0.9951)\n",
      "\u001b[32m[2020-06-20 14:52:55] __main__ INFO: \u001b[0mEpoch 1 Step 300/351 lr 0.001000 loss 0.3730 (0.3839) acc@1 0.8828 (0.8951) acc@5 1.0000 (0.9954)\n",
      "\u001b[32m[2020-06-20 14:52:59] __main__ INFO: \u001b[0mEpoch 1 Step 351/351 lr 0.001000 loss 0.3224 (0.3775) acc@1 0.8906 (0.8960) acc@5 0.9922 (0.9956)\n",
      "\u001b[32m[2020-06-20 14:52:59] __main__ INFO: \u001b[0mElapsed 32.31\n",
      "\u001b[32m[2020-06-20 14:52:59] __main__ INFO: \u001b[0mVal 1\n",
      "\u001b[32m[2020-06-20 14:53:01] __main__ INFO: \u001b[0mEpoch 1 loss 0.5734 acc@1 0.8576 acc@5 0.9936\n",
      "\u001b[32m[2020-06-20 14:53:01] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-20 14:53:01] __main__ INFO: \u001b[0mTrain 2 351\n",
      "\u001b[32m[2020-06-20 14:53:10] __main__ INFO: \u001b[0mEpoch 2 Step 100/351 lr 0.001000 loss 0.3432 (0.3160) acc@1 0.9219 (0.9059) acc@5 0.9922 (0.9963)\n",
      "\u001b[32m[2020-06-20 14:53:19] __main__ INFO: \u001b[0mEpoch 2 Step 200/351 lr 0.001000 loss 0.3685 (0.3158) acc@1 0.8828 (0.9077) acc@5 0.9922 (0.9962)\n",
      "\u001b[32m[2020-06-20 14:53:28] __main__ INFO: \u001b[0mEpoch 2 Step 300/351 lr 0.001000 loss 0.3135 (0.3182) acc@1 0.9141 (0.9062) acc@5 1.0000 (0.9964)\n",
      "\u001b[32m[2020-06-20 14:53:33] __main__ INFO: \u001b[0mEpoch 2 Step 351/351 lr 0.001000 loss 0.1450 (0.3163) acc@1 0.9297 (0.9060) acc@5 1.0000 (0.9965)\n",
      "\u001b[32m[2020-06-20 14:53:33] __main__ INFO: \u001b[0mElapsed 32.19\n",
      "\u001b[32m[2020-06-20 14:53:33] __main__ INFO: \u001b[0mVal 2\n",
      "\u001b[32m[2020-06-20 14:53:34] __main__ INFO: \u001b[0mEpoch 2 loss 0.5385 acc@1 0.8570 acc@5 0.9944\n",
      "\u001b[32m[2020-06-20 14:53:34] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-20 14:53:34] __main__ INFO: \u001b[0mTrain 3 702\n",
      "\u001b[32m[2020-06-20 14:53:43] __main__ INFO: \u001b[0mEpoch 3 Step 100/351 lr 0.001000 loss 0.2187 (0.3039) acc@1 0.9141 (0.9084) acc@5 1.0000 (0.9964)\n",
      "\u001b[32m[2020-06-20 14:53:52] __main__ INFO: \u001b[0mEpoch 3 Step 200/351 lr 0.001000 loss 0.2373 (0.2981) acc@1 0.9219 (0.9087) acc@5 1.0000 (0.9967)\n",
      "\u001b[32m[2020-06-20 14:54:01] __main__ INFO: \u001b[0mEpoch 3 Step 300/351 lr 0.001000 loss 0.1886 (0.2958) acc@1 0.9297 (0.9091) acc@5 1.0000 (0.9965)\n",
      "\u001b[32m[2020-06-20 14:54:06] __main__ INFO: \u001b[0mEpoch 3 Step 351/351 lr 0.001000 loss 0.2664 (0.2935) acc@1 0.9375 (0.9097) acc@5 1.0000 (0.9966)\n",
      "\u001b[32m[2020-06-20 14:54:06] __main__ INFO: \u001b[0mElapsed 32.35\n",
      "\u001b[32m[2020-06-20 14:54:06] __main__ INFO: \u001b[0mVal 3\n",
      "\u001b[32m[2020-06-20 14:54:07] __main__ INFO: \u001b[0mEpoch 3 loss 0.5001 acc@1 0.8640 acc@5 0.9950\n",
      "\u001b[32m[2020-06-20 14:54:07] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 14:54:07] __main__ INFO: \u001b[0mTrain 4 1053\n",
      "\u001b[32m[2020-06-20 14:54:17] __main__ INFO: \u001b[0mEpoch 4 Step 100/351 lr 0.001000 loss 0.2096 (0.2813) acc@1 0.9297 (0.9105) acc@5 1.0000 (0.9971)\n",
      "\u001b[32m[2020-06-20 14:54:26] __main__ INFO: \u001b[0mEpoch 4 Step 200/351 lr 0.001000 loss 0.2584 (0.2788) acc@1 0.8906 (0.9123) acc@5 1.0000 (0.9969)\n",
      "\u001b[32m[2020-06-20 14:54:35] __main__ INFO: \u001b[0mEpoch 4 Step 300/351 lr 0.001000 loss 0.1223 (0.2727) acc@1 0.9688 (0.9137) acc@5 1.0000 (0.9969)\n",
      "\u001b[32m[2020-06-20 14:54:40] __main__ INFO: \u001b[0mEpoch 4 Step 351/351 lr 0.001000 loss 0.2208 (0.2708) acc@1 0.9375 (0.9142) acc@5 1.0000 (0.9970)\n",
      "\u001b[32m[2020-06-20 14:54:40] __main__ INFO: \u001b[0mElapsed 32.43\n",
      "\u001b[32m[2020-06-20 14:54:40] __main__ INFO: \u001b[0mVal 4\n",
      "\u001b[32m[2020-06-20 14:54:41] __main__ INFO: \u001b[0mEpoch 4 loss 0.4902 acc@1 0.8636 acc@5 0.9948\n",
      "\u001b[32m[2020-06-20 14:54:41] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-20 14:54:41] __main__ INFO: \u001b[0mTrain 5 1404\n",
      "\u001b[32m[2020-06-20 14:54:50] __main__ INFO: \u001b[0mEpoch 5 Step 100/351 lr 0.001000 loss 0.2332 (0.2632) acc@1 0.9453 (0.9167) acc@5 0.9922 (0.9972)\n",
      "\u001b[32m[2020-06-20 14:54:59] __main__ INFO: \u001b[0mEpoch 5 Step 200/351 lr 0.001000 loss 0.3500 (0.2672) acc@1 0.8516 (0.9141) acc@5 1.0000 (0.9974)\n",
      "\u001b[32m[2020-06-20 14:55:08] __main__ INFO: \u001b[0mEpoch 5 Step 300/351 lr 0.001000 loss 0.2257 (0.2625) acc@1 0.9297 (0.9155) acc@5 1.0000 (0.9975)\n",
      "\u001b[32m[2020-06-20 14:55:13] __main__ INFO: \u001b[0mEpoch 5 Step 351/351 lr 0.001000 loss 0.2592 (0.2629) acc@1 0.9062 (0.9155) acc@5 0.9922 (0.9974)\n",
      "\u001b[32m[2020-06-20 14:55:13] __main__ INFO: \u001b[0mElapsed 32.50\n",
      "\u001b[32m[2020-06-20 14:55:13] __main__ INFO: \u001b[0mVal 5\n",
      "\u001b[32m[2020-06-20 14:55:14] __main__ INFO: \u001b[0mEpoch 5 loss 0.4719 acc@1 0.8660 acc@5 0.9950\n",
      "\u001b[32m[2020-06-20 14:55:14] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-06-20 14:55:14] __main__ INFO: \u001b[0mTrain 6 1755\n",
      "\u001b[32m[2020-06-20 14:55:24] __main__ INFO: \u001b[0mEpoch 6 Step 100/351 lr 0.001000 loss 0.3179 (0.2457) acc@1 0.8906 (0.9223) acc@5 1.0000 (0.9973)\n",
      "\u001b[32m[2020-06-20 14:55:33] __main__ INFO: \u001b[0mEpoch 6 Step 200/351 lr 0.001000 loss 0.2254 (0.2457) acc@1 0.9375 (0.9207) acc@5 0.9922 (0.9976)\n",
      "\u001b[32m[2020-06-20 14:55:42] __main__ INFO: \u001b[0mEpoch 6 Step 300/351 lr 0.001000 loss 0.1830 (0.2475) acc@1 0.9297 (0.9194) acc@5 0.9922 (0.9973)\n",
      "\u001b[32m[2020-06-20 14:55:47] __main__ INFO: \u001b[0mEpoch 6 Step 351/351 lr 0.001000 loss 0.2853 (0.2482) acc@1 0.8828 (0.9191) acc@5 1.0000 (0.9974)\n",
      "\u001b[32m[2020-06-20 14:55:47] __main__ INFO: \u001b[0mElapsed 32.60\n",
      "\u001b[32m[2020-06-20 14:55:47] __main__ INFO: \u001b[0mVal 6\n",
      "\u001b[32m[2020-06-20 14:55:48] __main__ INFO: \u001b[0mEpoch 6 loss 0.4632 acc@1 0.8676 acc@5 0.9944\n",
      "\u001b[32m[2020-06-20 14:55:48] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-20 14:55:48] __main__ INFO: \u001b[0mTrain 7 2106\n",
      "\u001b[32m[2020-06-20 14:55:57] __main__ INFO: \u001b[0mEpoch 7 Step 100/351 lr 0.001000 loss 0.1472 (0.2275) acc@1 0.9219 (0.9233) acc@5 1.0000 (0.9974)\n",
      "\u001b[32m[2020-06-20 14:56:07] __main__ INFO: \u001b[0mEpoch 7 Step 200/351 lr 0.001000 loss 0.2552 (0.2362) acc@1 0.9219 (0.9231) acc@5 1.0000 (0.9973)\n",
      "\u001b[32m[2020-06-20 14:56:16] __main__ INFO: \u001b[0mEpoch 7 Step 300/351 lr 0.001000 loss 0.1817 (0.2428) acc@1 0.9531 (0.9203) acc@5 1.0000 (0.9973)\n",
      "\u001b[32m[2020-06-20 14:56:20] __main__ INFO: \u001b[0mEpoch 7 Step 351/351 lr 0.001000 loss 0.1124 (0.2414) acc@1 0.9609 (0.9206) acc@5 1.0000 (0.9974)\n",
      "\u001b[32m[2020-06-20 14:56:21] __main__ INFO: \u001b[0mElapsed 32.50\n",
      "\u001b[32m[2020-06-20 14:56:21] __main__ INFO: \u001b[0mVal 7\n",
      "\u001b[32m[2020-06-20 14:56:22] __main__ INFO: \u001b[0mEpoch 7 loss 0.4505 acc@1 0.8692 acc@5 0.9946\n",
      "\u001b[32m[2020-06-20 14:56:22] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 14:56:22] __main__ INFO: \u001b[0mTrain 8 2457\n",
      "\u001b[32m[2020-06-20 14:56:31] __main__ INFO: \u001b[0mEpoch 8 Step 100/351 lr 0.001000 loss 0.2405 (0.2345) acc@1 0.8906 (0.9196) acc@5 1.0000 (0.9984)\n",
      "\u001b[32m[2020-06-20 14:56:40] __main__ INFO: \u001b[0mEpoch 8 Step 200/351 lr 0.001000 loss 0.1985 (0.2396) acc@1 0.9141 (0.9200) acc@5 1.0000 (0.9980)\n",
      "\u001b[32m[2020-06-20 14:56:49] __main__ INFO: \u001b[0mEpoch 8 Step 300/351 lr 0.001000 loss 0.2384 (0.2373) acc@1 0.9219 (0.9208) acc@5 0.9922 (0.9979)\n",
      "\u001b[32m[2020-06-20 14:56:54] __main__ INFO: \u001b[0mEpoch 8 Step 351/351 lr 0.001000 loss 0.2898 (0.2418) acc@1 0.9297 (0.9199) acc@5 0.9844 (0.9978)\n",
      "\u001b[32m[2020-06-20 14:56:54] __main__ INFO: \u001b[0mElapsed 32.46\n",
      "\u001b[32m[2020-06-20 14:56:54] __main__ INFO: \u001b[0mVal 8\n",
      "\u001b[32m[2020-06-20 14:56:55] __main__ INFO: \u001b[0mEpoch 8 loss 0.4419 acc@1 0.8700 acc@5 0.9946\n",
      "\u001b[32m[2020-06-20 14:56:55] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 14:56:55] __main__ INFO: \u001b[0mTrain 9 2808\n",
      "\u001b[32m[2020-06-20 14:57:04] __main__ INFO: \u001b[0mEpoch 9 Step 100/351 lr 0.001000 loss 0.3259 (0.2277) acc@1 0.8984 (0.9266) acc@5 1.0000 (0.9980)\n",
      "\u001b[32m[2020-06-20 14:57:14] __main__ INFO: \u001b[0mEpoch 9 Step 200/351 lr 0.001000 loss 0.2202 (0.2274) acc@1 0.9219 (0.9256) acc@5 1.0000 (0.9981)\n",
      "\u001b[32m[2020-06-20 14:57:23] __main__ INFO: \u001b[0mEpoch 9 Step 300/351 lr 0.001000 loss 0.3185 (0.2292) acc@1 0.9062 (0.9245) acc@5 1.0000 (0.9981)\n",
      "\u001b[32m[2020-06-20 14:57:28] __main__ INFO: \u001b[0mEpoch 9 Step 351/351 lr 0.001000 loss 0.1789 (0.2316) acc@1 0.9375 (0.9235) acc@5 1.0000 (0.9982)\n",
      "\u001b[32m[2020-06-20 14:57:28] __main__ INFO: \u001b[0mElapsed 32.53\n",
      "\u001b[32m[2020-06-20 14:57:28] __main__ INFO: \u001b[0mVal 9\n",
      "\u001b[32m[2020-06-20 14:57:29] __main__ INFO: \u001b[0mEpoch 9 loss 0.4399 acc@1 0.8700 acc@5 0.9950\n",
      "\u001b[32m[2020-06-20 14:57:29] __main__ INFO: \u001b[0mElapsed 1.11\n",
      "\u001b[32m[2020-06-20 14:57:29] __main__ INFO: \u001b[0mTrain 10 3159\n",
      "\u001b[32m[2020-06-20 14:57:38] __main__ INFO: \u001b[0mEpoch 10 Step 100/351 lr 0.001000 loss 0.1462 (0.2248) acc@1 0.9453 (0.9237) acc@5 1.0000 (0.9982)\n",
      "\u001b[32m[2020-06-20 14:57:47] __main__ INFO: \u001b[0mEpoch 10 Step 200/351 lr 0.001000 loss 0.2165 (0.2241) acc@1 0.9375 (0.9239) acc@5 0.9922 (0.9981)\n",
      "\u001b[32m[2020-06-20 14:57:57] __main__ INFO: \u001b[0mEpoch 10 Step 300/351 lr 0.001000 loss 0.2426 (0.2240) acc@1 0.8750 (0.9249) acc@5 1.0000 (0.9980)\n",
      "\u001b[32m[2020-06-20 14:58:01] __main__ INFO: \u001b[0mEpoch 10 Step 351/351 lr 0.001000 loss 0.1937 (0.2241) acc@1 0.9062 (0.9243) acc@5 1.0000 (0.9980)\n",
      "\u001b[32m[2020-06-20 14:58:01] __main__ INFO: \u001b[0mElapsed 32.56\n",
      "\u001b[32m[2020-06-20 14:58:01] __main__ INFO: \u001b[0mVal 10\n",
      "\u001b[32m[2020-06-20 14:58:02] __main__ INFO: \u001b[0mEpoch 10 loss 0.4317 acc@1 0.8714 acc@5 0.9946\n",
      "\u001b[32m[2020-06-20 14:58:02] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 14:58:02] __main__ INFO: \u001b[0mTrain 11 3510\n",
      "\u001b[32m[2020-06-20 14:58:12] __main__ INFO: \u001b[0mEpoch 11 Step 100/351 lr 0.001000 loss 0.2505 (0.2241) acc@1 0.9375 (0.9266) acc@5 1.0000 (0.9975)\n",
      "\u001b[32m[2020-06-20 14:58:21] __main__ INFO: \u001b[0mEpoch 11 Step 200/351 lr 0.001000 loss 0.2179 (0.2270) acc@1 0.8984 (0.9255) acc@5 1.0000 (0.9975)\n",
      "\u001b[32m[2020-06-20 14:58:30] __main__ INFO: \u001b[0mEpoch 11 Step 300/351 lr 0.001000 loss 0.2110 (0.2251) acc@1 0.9062 (0.9260) acc@5 1.0000 (0.9979)\n",
      "\u001b[32m[2020-06-20 14:58:35] __main__ INFO: \u001b[0mEpoch 11 Step 351/351 lr 0.001000 loss 0.2106 (0.2256) acc@1 0.9453 (0.9257) acc@5 1.0000 (0.9978)\n",
      "\u001b[32m[2020-06-20 14:58:35] __main__ INFO: \u001b[0mElapsed 32.46\n",
      "\u001b[32m[2020-06-20 14:58:35] __main__ INFO: \u001b[0mVal 11\n",
      "\u001b[32m[2020-06-20 14:58:36] __main__ INFO: \u001b[0mEpoch 11 loss 0.4326 acc@1 0.8728 acc@5 0.9950\n",
      "\u001b[32m[2020-06-20 14:58:36] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-20 14:58:36] __main__ INFO: \u001b[0mTrain 12 3861\n",
      "\u001b[32m[2020-06-20 14:58:45] __main__ INFO: \u001b[0mEpoch 12 Step 100/351 lr 0.001000 loss 0.2282 (0.2204) acc@1 0.8984 (0.9244) acc@5 1.0000 (0.9983)\n",
      "\u001b[32m[2020-06-20 14:58:54] __main__ INFO: \u001b[0mEpoch 12 Step 200/351 lr 0.001000 loss 0.2912 (0.2167) acc@1 0.9141 (0.9255) acc@5 0.9844 (0.9985)\n",
      "\u001b[32m[2020-06-20 14:59:04] __main__ INFO: \u001b[0mEpoch 12 Step 300/351 lr 0.001000 loss 0.4480 (0.2198) acc@1 0.9062 (0.9258) acc@5 0.9922 (0.9983)\n",
      "\u001b[32m[2020-06-20 14:59:08] __main__ INFO: \u001b[0mEpoch 12 Step 351/351 lr 0.001000 loss 0.3552 (0.2181) acc@1 0.9375 (0.9269) acc@5 0.9844 (0.9982)\n",
      "\u001b[32m[2020-06-20 14:59:08] __main__ INFO: \u001b[0mElapsed 32.44\n",
      "\u001b[32m[2020-06-20 14:59:08] __main__ INFO: \u001b[0mVal 12\n",
      "\u001b[32m[2020-06-20 14:59:09] __main__ INFO: \u001b[0mEpoch 12 loss 0.4203 acc@1 0.8740 acc@5 0.9950\n",
      "\u001b[32m[2020-06-20 14:59:09] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-20 14:59:09] __main__ INFO: \u001b[0mTrain 13 4212\n",
      "\u001b[32m[2020-06-20 14:59:19] __main__ INFO: \u001b[0mEpoch 13 Step 100/351 lr 0.001000 loss 0.2840 (0.2152) acc@1 0.9297 (0.9282) acc@5 1.0000 (0.9975)\n",
      "\u001b[32m[2020-06-20 14:59:28] __main__ INFO: \u001b[0mEpoch 13 Step 200/351 lr 0.001000 loss 0.1610 (0.2100) acc@1 0.9375 (0.9292) acc@5 1.0000 (0.9981)\n",
      "\u001b[32m[2020-06-20 14:59:37] __main__ INFO: \u001b[0mEpoch 13 Step 300/351 lr 0.001000 loss 0.0895 (0.2099) acc@1 0.9609 (0.9294) acc@5 1.0000 (0.9982)\n",
      "\u001b[32m[2020-06-20 14:59:42] __main__ INFO: \u001b[0mEpoch 13 Step 351/351 lr 0.001000 loss 0.1201 (0.2116) acc@1 0.9609 (0.9286) acc@5 1.0000 (0.9982)\n",
      "\u001b[32m[2020-06-20 14:59:42] __main__ INFO: \u001b[0mElapsed 32.52\n",
      "\u001b[32m[2020-06-20 14:59:42] __main__ INFO: \u001b[0mVal 13\n",
      "\u001b[32m[2020-06-20 14:59:43] __main__ INFO: \u001b[0mEpoch 13 loss 0.4214 acc@1 0.8746 acc@5 0.9954\n",
      "\u001b[32m[2020-06-20 14:59:43] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-20 14:59:43] __main__ INFO: \u001b[0mTrain 14 4563\n",
      "\u001b[32m[2020-06-20 14:59:52] __main__ INFO: \u001b[0mEpoch 14 Step 100/351 lr 0.001000 loss 0.3017 (0.2144) acc@1 0.8984 (0.9282) acc@5 1.0000 (0.9977)\n",
      "\u001b[32m[2020-06-20 15:00:02] __main__ INFO: \u001b[0mEpoch 14 Step 200/351 lr 0.001000 loss 0.1678 (0.2091) acc@1 0.9375 (0.9286) acc@5 1.0000 (0.9979)\n",
      "\u001b[32m[2020-06-20 15:00:11] __main__ INFO: \u001b[0mEpoch 14 Step 300/351 lr 0.001000 loss 0.2469 (0.2087) acc@1 0.8906 (0.9286) acc@5 0.9922 (0.9982)\n",
      "\u001b[32m[2020-06-20 15:00:16] __main__ INFO: \u001b[0mEpoch 14 Step 351/351 lr 0.001000 loss 0.2815 (0.2089) acc@1 0.9141 (0.9287) acc@5 1.0000 (0.9981)\n",
      "\u001b[32m[2020-06-20 15:00:16] __main__ INFO: \u001b[0mElapsed 32.49\n",
      "\u001b[32m[2020-06-20 15:00:16] __main__ INFO: \u001b[0mVal 14\n",
      "\u001b[32m[2020-06-20 15:00:17] __main__ INFO: \u001b[0mEpoch 14 loss 0.4198 acc@1 0.8748 acc@5 0.9948\n",
      "\u001b[32m[2020-06-20 15:00:17] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 15:00:17] __main__ INFO: \u001b[0mTrain 15 4914\n",
      "\u001b[32m[2020-06-20 15:00:26] __main__ INFO: \u001b[0mEpoch 15 Step 100/351 lr 0.001000 loss 0.2260 (0.2089) acc@1 0.8984 (0.9294) acc@5 1.0000 (0.9984)\n",
      "\u001b[32m[2020-06-20 15:00:35] __main__ INFO: \u001b[0mEpoch 15 Step 200/351 lr 0.001000 loss 0.1838 (0.2060) acc@1 0.9297 (0.9310) acc@5 1.0000 (0.9983)\n",
      "\u001b[32m[2020-06-20 15:00:44] __main__ INFO: \u001b[0mEpoch 15 Step 300/351 lr 0.001000 loss 0.1740 (0.2074) acc@1 0.9531 (0.9303) acc@5 1.0000 (0.9983)\n",
      "\u001b[32m[2020-06-20 15:00:49] __main__ INFO: \u001b[0mEpoch 15 Step 351/351 lr 0.001000 loss 0.2208 (0.2078) acc@1 0.9219 (0.9300) acc@5 1.0000 (0.9983)\n",
      "\u001b[32m[2020-06-20 15:00:49] __main__ INFO: \u001b[0mElapsed 32.50\n",
      "\u001b[32m[2020-06-20 15:00:49] __main__ INFO: \u001b[0mVal 15\n",
      "\u001b[32m[2020-06-20 15:00:50] __main__ INFO: \u001b[0mEpoch 15 loss 0.4192 acc@1 0.8758 acc@5 0.9950\n",
      "\u001b[32m[2020-06-20 15:00:50] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-20 15:00:50] __main__ INFO: \u001b[0mTrain 16 5265\n",
      "\u001b[32m[2020-06-20 15:01:00] __main__ INFO: \u001b[0mEpoch 16 Step 100/351 lr 0.001000 loss 0.2349 (0.2067) acc@1 0.9219 (0.9316) acc@5 1.0000 (0.9984)\n",
      "\u001b[32m[2020-06-20 15:01:09] __main__ INFO: \u001b[0mEpoch 16 Step 200/351 lr 0.001000 loss 0.1986 (0.2089) acc@1 0.9375 (0.9310) acc@5 1.0000 (0.9982)\n",
      "\u001b[32m[2020-06-20 15:01:18] __main__ INFO: \u001b[0mEpoch 16 Step 300/351 lr 0.001000 loss 0.1417 (0.2069) acc@1 0.9609 (0.9306) acc@5 1.0000 (0.9982)\n",
      "\u001b[32m[2020-06-20 15:01:23] __main__ INFO: \u001b[0mEpoch 16 Step 351/351 lr 0.001000 loss 0.2252 (0.2081) acc@1 0.9375 (0.9298) acc@5 0.9922 (0.9982)\n",
      "\u001b[32m[2020-06-20 15:01:23] __main__ INFO: \u001b[0mElapsed 32.54\n",
      "\u001b[32m[2020-06-20 15:01:23] __main__ INFO: \u001b[0mVal 16\n",
      "\u001b[32m[2020-06-20 15:01:24] __main__ INFO: \u001b[0mEpoch 16 loss 0.4184 acc@1 0.8778 acc@5 0.9956\n",
      "\u001b[32m[2020-06-20 15:01:24] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-20 15:01:24] __main__ INFO: \u001b[0mTrain 17 5616\n",
      "\u001b[32m[2020-06-20 15:01:33] __main__ INFO: \u001b[0mEpoch 17 Step 100/351 lr 0.001000 loss 0.1446 (0.2065) acc@1 0.9297 (0.9307) acc@5 1.0000 (0.9977)\n",
      "\u001b[32m[2020-06-20 15:01:42] __main__ INFO: \u001b[0mEpoch 17 Step 200/351 lr 0.001000 loss 0.2112 (0.2037) acc@1 0.9297 (0.9316) acc@5 1.0000 (0.9981)\n",
      "\u001b[32m[2020-06-20 15:01:52] __main__ INFO: \u001b[0mEpoch 17 Step 300/351 lr 0.001000 loss 0.1968 (0.2006) acc@1 0.9375 (0.9323) acc@5 1.0000 (0.9982)\n",
      "\u001b[32m[2020-06-20 15:01:56] __main__ INFO: \u001b[0mEpoch 17 Step 351/351 lr 0.001000 loss 0.1182 (0.2002) acc@1 0.9609 (0.9327) acc@5 1.0000 (0.9982)\n",
      "\u001b[32m[2020-06-20 15:01:56] __main__ INFO: \u001b[0mElapsed 32.48\n",
      "\u001b[32m[2020-06-20 15:01:56] __main__ INFO: \u001b[0mVal 17\n",
      "\u001b[32m[2020-06-20 15:01:57] __main__ INFO: \u001b[0mEpoch 17 loss 0.4201 acc@1 0.8776 acc@5 0.9950\n",
      "\u001b[32m[2020-06-20 15:01:57] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 15:01:57] __main__ INFO: \u001b[0mTrain 18 5967\n",
      "\u001b[32m[2020-06-20 15:02:07] __main__ INFO: \u001b[0mEpoch 18 Step 100/351 lr 0.001000 loss 0.4031 (0.2029) acc@1 0.8672 (0.9294) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-06-20 15:02:16] __main__ INFO: \u001b[0mEpoch 18 Step 200/351 lr 0.001000 loss 0.2943 (0.1974) acc@1 0.9141 (0.9316) acc@5 0.9922 (0.9984)\n",
      "\u001b[32m[2020-06-20 15:02:25] __main__ INFO: \u001b[0mEpoch 18 Step 300/351 lr 0.001000 loss 0.2564 (0.1981) acc@1 0.8984 (0.9317) acc@5 0.9922 (0.9984)\n",
      "\u001b[32m[2020-06-20 15:02:30] __main__ INFO: \u001b[0mEpoch 18 Step 351/351 lr 0.001000 loss 0.1153 (0.1972) acc@1 0.9609 (0.9320) acc@5 1.0000 (0.9985)\n",
      "\u001b[32m[2020-06-20 15:02:30] __main__ INFO: \u001b[0mElapsed 32.51\n",
      "\u001b[32m[2020-06-20 15:02:30] __main__ INFO: \u001b[0mVal 18\n",
      "\u001b[32m[2020-06-20 15:02:31] __main__ INFO: \u001b[0mEpoch 18 loss 0.4191 acc@1 0.8770 acc@5 0.9954\n",
      "\u001b[32m[2020-06-20 15:02:31] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 15:02:31] __main__ INFO: \u001b[0mTrain 19 6318\n",
      "\u001b[32m[2020-06-20 15:02:40] __main__ INFO: \u001b[0mEpoch 19 Step 100/351 lr 0.001000 loss 0.2003 (0.2021) acc@1 0.9297 (0.9311) acc@5 1.0000 (0.9982)\n",
      "\u001b[32m[2020-06-20 15:02:49] __main__ INFO: \u001b[0mEpoch 19 Step 200/351 lr 0.001000 loss 0.1519 (0.1974) acc@1 0.9453 (0.9321) acc@5 1.0000 (0.9983)\n",
      "\u001b[32m[2020-06-20 15:02:59] __main__ INFO: \u001b[0mEpoch 19 Step 300/351 lr 0.001000 loss 0.3384 (0.1985) acc@1 0.8984 (0.9321) acc@5 0.9844 (0.9982)\n",
      "\u001b[32m[2020-06-20 15:03:03] __main__ INFO: \u001b[0mEpoch 19 Step 351/351 lr 0.001000 loss 0.2503 (0.1984) acc@1 0.9375 (0.9324) acc@5 0.9922 (0.9982)\n",
      "\u001b[32m[2020-06-20 15:03:03] __main__ INFO: \u001b[0mElapsed 32.45\n",
      "\u001b[32m[2020-06-20 15:03:03] __main__ INFO: \u001b[0mVal 19\n",
      "\u001b[32m[2020-06-20 15:03:04] __main__ INFO: \u001b[0mEpoch 19 loss 0.4123 acc@1 0.8760 acc@5 0.9950\n",
      "\u001b[32m[2020-06-20 15:03:04] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-20 15:03:04] __main__ INFO: \u001b[0mTrain 20 6669\n",
      "\u001b[32m[2020-06-20 15:03:14] __main__ INFO: \u001b[0mEpoch 20 Step 100/351 lr 0.001000 loss 0.1581 (0.1939) acc@1 0.9453 (0.9324) acc@5 1.0000 (0.9986)\n",
      "\u001b[32m[2020-06-20 15:03:23] __main__ INFO: \u001b[0mEpoch 20 Step 200/351 lr 0.001000 loss 0.1350 (0.1892) acc@1 0.9531 (0.9350) acc@5 1.0000 (0.9983)\n",
      "\u001b[32m[2020-06-20 15:03:32] __main__ INFO: \u001b[0mEpoch 20 Step 300/351 lr 0.001000 loss 0.2224 (0.1908) acc@1 0.9375 (0.9342) acc@5 1.0000 (0.9985)\n",
      "\u001b[32m[2020-06-20 15:03:37] __main__ INFO: \u001b[0mEpoch 20 Step 351/351 lr 0.001000 loss 0.1790 (0.1906) acc@1 0.9297 (0.9341) acc@5 1.0000 (0.9984)\n",
      "\u001b[32m[2020-06-20 15:03:37] __main__ INFO: \u001b[0mElapsed 32.55\n",
      "\u001b[32m[2020-06-20 15:03:37] __main__ INFO: \u001b[0mVal 20\n",
      "\u001b[32m[2020-06-20 15:03:38] __main__ INFO: \u001b[0mEpoch 20 loss 0.4127 acc@1 0.8736 acc@5 0.9950\n",
      "\u001b[32m[2020-06-20 15:03:38] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 15:03:38] __main__ INFO: \u001b[0mTrain 21 7020\n",
      "\u001b[32m[2020-06-20 15:03:47] __main__ INFO: \u001b[0mEpoch 21 Step 100/351 lr 0.001000 loss 0.2334 (0.1929) acc@1 0.8906 (0.9349) acc@5 1.0000 (0.9982)\n",
      "\u001b[32m[2020-06-20 15:03:57] __main__ INFO: \u001b[0mEpoch 21 Step 200/351 lr 0.001000 loss 0.1464 (0.1926) acc@1 0.9531 (0.9351) acc@5 1.0000 (0.9982)\n",
      "\u001b[32m[2020-06-20 15:04:06] __main__ INFO: \u001b[0mEpoch 21 Step 300/351 lr 0.001000 loss 0.2432 (0.1895) acc@1 0.9219 (0.9358) acc@5 1.0000 (0.9985)\n",
      "\u001b[32m[2020-06-20 15:04:11] __main__ INFO: \u001b[0mEpoch 21 Step 351/351 lr 0.001000 loss 0.1296 (0.1895) acc@1 0.9609 (0.9356) acc@5 0.9922 (0.9984)\n",
      "\u001b[32m[2020-06-20 15:04:11] __main__ INFO: \u001b[0mElapsed 32.50\n",
      "\u001b[32m[2020-06-20 15:04:11] __main__ INFO: \u001b[0mVal 21\n",
      "\u001b[32m[2020-06-20 15:04:12] __main__ INFO: \u001b[0mEpoch 21 loss 0.4151 acc@1 0.8740 acc@5 0.9954\n",
      "\u001b[32m[2020-06-20 15:04:12] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-20 15:04:12] __main__ INFO: \u001b[0mTrain 22 7371\n",
      "\u001b[32m[2020-06-20 15:04:21] __main__ INFO: \u001b[0mEpoch 22 Step 100/351 lr 0.001000 loss 0.2233 (0.1922) acc@1 0.9609 (0.9351) acc@5 0.9922 (0.9980)\n",
      "\u001b[32m[2020-06-20 15:04:30] __main__ INFO: \u001b[0mEpoch 22 Step 200/351 lr 0.001000 loss 0.1865 (0.1910) acc@1 0.9297 (0.9360) acc@5 1.0000 (0.9980)\n",
      "\u001b[32m[2020-06-20 15:04:39] __main__ INFO: \u001b[0mEpoch 22 Step 300/351 lr 0.001000 loss 0.1262 (0.1909) acc@1 0.9453 (0.9355) acc@5 1.0000 (0.9981)\n",
      "\u001b[32m[2020-06-20 15:04:44] __main__ INFO: \u001b[0mEpoch 22 Step 351/351 lr 0.001000 loss 0.2684 (0.1889) acc@1 0.8984 (0.9360) acc@5 1.0000 (0.9982)\n",
      "\u001b[32m[2020-06-20 15:04:44] __main__ INFO: \u001b[0mElapsed 32.48\n",
      "\u001b[32m[2020-06-20 15:04:44] __main__ INFO: \u001b[0mVal 22\n",
      "\u001b[32m[2020-06-20 15:04:45] __main__ INFO: \u001b[0mEpoch 22 loss 0.4119 acc@1 0.8778 acc@5 0.9956\n",
      "\u001b[32m[2020-06-20 15:04:45] __main__ INFO: \u001b[0mElapsed 1.11\n",
      "\u001b[32m[2020-06-20 15:04:45] __main__ INFO: \u001b[0mTrain 23 7722\n",
      "\u001b[32m[2020-06-20 15:04:55] __main__ INFO: \u001b[0mEpoch 23 Step 100/351 lr 0.001000 loss 0.2007 (0.1881) acc@1 0.9062 (0.9369) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-06-20 15:05:04] __main__ INFO: \u001b[0mEpoch 23 Step 200/351 lr 0.001000 loss 0.1723 (0.1897) acc@1 0.9375 (0.9359) acc@5 1.0000 (0.9986)\n",
      "\u001b[32m[2020-06-20 15:05:13] __main__ INFO: \u001b[0mEpoch 23 Step 300/351 lr 0.001000 loss 0.1953 (0.1849) acc@1 0.9531 (0.9380) acc@5 1.0000 (0.9984)\n",
      "\u001b[32m[2020-06-20 15:05:18] __main__ INFO: \u001b[0mEpoch 23 Step 351/351 lr 0.001000 loss 0.2586 (0.1855) acc@1 0.9297 (0.9377) acc@5 0.9922 (0.9984)\n",
      "\u001b[32m[2020-06-20 15:05:18] __main__ INFO: \u001b[0mElapsed 32.44\n",
      "\u001b[32m[2020-06-20 15:05:18] __main__ INFO: \u001b[0mVal 23\n",
      "\u001b[32m[2020-06-20 15:05:19] __main__ INFO: \u001b[0mEpoch 23 loss 0.4103 acc@1 0.8786 acc@5 0.9956\n",
      "\u001b[32m[2020-06-20 15:05:19] __main__ INFO: \u001b[0mElapsed 1.11\n",
      "\u001b[32m[2020-06-20 15:05:19] __main__ INFO: \u001b[0mTrain 24 8073\n",
      "\u001b[32m[2020-06-20 15:05:28] __main__ INFO: \u001b[0mEpoch 24 Step 100/351 lr 0.001000 loss 0.1518 (0.1867) acc@1 0.9531 (0.9355) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-06-20 15:05:37] __main__ INFO: \u001b[0mEpoch 24 Step 200/351 lr 0.001000 loss 0.1120 (0.1855) acc@1 0.9688 (0.9363) acc@5 1.0000 (0.9984)\n",
      "\u001b[32m[2020-06-20 15:05:47] __main__ INFO: \u001b[0mEpoch 24 Step 300/351 lr 0.001000 loss 0.1656 (0.1843) acc@1 0.9531 (0.9363) acc@5 0.9922 (0.9985)\n",
      "\u001b[32m[2020-06-20 15:05:51] __main__ INFO: \u001b[0mEpoch 24 Step 351/351 lr 0.001000 loss 0.1160 (0.1857) acc@1 0.9531 (0.9360) acc@5 1.0000 (0.9985)\n",
      "\u001b[32m[2020-06-20 15:05:51] __main__ INFO: \u001b[0mElapsed 32.50\n",
      "\u001b[32m[2020-06-20 15:05:51] __main__ INFO: \u001b[0mVal 24\n",
      "\u001b[32m[2020-06-20 15:05:52] __main__ INFO: \u001b[0mEpoch 24 loss 0.4119 acc@1 0.8780 acc@5 0.9954\n",
      "\u001b[32m[2020-06-20 15:05:52] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-20 15:05:52] __main__ INFO: \u001b[0mTrain 25 8424\n",
      "\u001b[32m[2020-06-20 15:06:02] __main__ INFO: \u001b[0mEpoch 25 Step 100/351 lr 0.001000 loss 0.0781 (0.1813) acc@1 0.9766 (0.9365) acc@5 1.0000 (0.9987)\n",
      "\u001b[32m[2020-06-20 15:06:11] __main__ INFO: \u001b[0mEpoch 25 Step 200/351 lr 0.001000 loss 0.2375 (0.1829) acc@1 0.9297 (0.9367) acc@5 0.9922 (0.9985)\n",
      "\u001b[32m[2020-06-20 15:06:20] __main__ INFO: \u001b[0mEpoch 25 Step 300/351 lr 0.001000 loss 0.1699 (0.1842) acc@1 0.9453 (0.9362) acc@5 1.0000 (0.9985)\n",
      "\u001b[32m[2020-06-20 15:06:25] __main__ INFO: \u001b[0mEpoch 25 Step 351/351 lr 0.001000 loss 0.1600 (0.1832) acc@1 0.9609 (0.9365) acc@5 1.0000 (0.9986)\n",
      "\u001b[32m[2020-06-20 15:06:25] __main__ INFO: \u001b[0mElapsed 32.44\n",
      "\u001b[32m[2020-06-20 15:06:25] __main__ INFO: \u001b[0mVal 25\n",
      "\u001b[32m[2020-06-20 15:06:26] __main__ INFO: \u001b[0mEpoch 25 loss 0.4118 acc@1 0.8784 acc@5 0.9956\n",
      "\u001b[32m[2020-06-20 15:06:26] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-20 15:06:26] __main__ INFO: \u001b[0mTrain 26 8775\n",
      "\u001b[32m[2020-06-20 15:06:35] __main__ INFO: \u001b[0mEpoch 26 Step 100/351 lr 0.001000 loss 0.0859 (0.1741) acc@1 0.9766 (0.9373) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-06-20 15:06:44] __main__ INFO: \u001b[0mEpoch 26 Step 200/351 lr 0.001000 loss 0.2207 (0.1791) acc@1 0.9297 (0.9372) acc@5 1.0000 (0.9989)\n",
      "\u001b[32m[2020-06-20 15:06:54] __main__ INFO: \u001b[0mEpoch 26 Step 300/351 lr 0.001000 loss 0.1902 (0.1791) acc@1 0.9297 (0.9374) acc@5 1.0000 (0.9989)\n",
      "\u001b[32m[2020-06-20 15:06:58] __main__ INFO: \u001b[0mEpoch 26 Step 351/351 lr 0.001000 loss 0.1176 (0.1802) acc@1 0.9688 (0.9375) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-06-20 15:06:58] __main__ INFO: \u001b[0mElapsed 32.50\n",
      "\u001b[32m[2020-06-20 15:06:58] __main__ INFO: \u001b[0mVal 26\n",
      "\u001b[32m[2020-06-20 15:06:59] __main__ INFO: \u001b[0mEpoch 26 loss 0.4112 acc@1 0.8802 acc@5 0.9954\n",
      "\u001b[32m[2020-06-20 15:06:59] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 15:06:59] __main__ INFO: \u001b[0mTrain 27 9126\n",
      "\u001b[32m[2020-06-20 15:07:09] __main__ INFO: \u001b[0mEpoch 27 Step 100/351 lr 0.001000 loss 0.1535 (0.1681) acc@1 0.9375 (0.9410) acc@5 1.0000 (0.9986)\n",
      "\u001b[32m[2020-06-20 15:07:18] __main__ INFO: \u001b[0mEpoch 27 Step 200/351 lr 0.001000 loss 0.2049 (0.1751) acc@1 0.9453 (0.9399) acc@5 1.0000 (0.9986)\n",
      "\u001b[32m[2020-06-20 15:07:27] __main__ INFO: \u001b[0mEpoch 27 Step 300/351 lr 0.001000 loss 0.1637 (0.1769) acc@1 0.9531 (0.9390) acc@5 0.9922 (0.9984)\n",
      "\u001b[32m[2020-06-20 15:07:32] __main__ INFO: \u001b[0mEpoch 27 Step 351/351 lr 0.001000 loss 0.1872 (0.1773) acc@1 0.9453 (0.9388) acc@5 0.9922 (0.9985)\n",
      "\u001b[32m[2020-06-20 15:07:32] __main__ INFO: \u001b[0mElapsed 32.45\n",
      "\u001b[32m[2020-06-20 15:07:32] __main__ INFO: \u001b[0mVal 27\n",
      "\u001b[32m[2020-06-20 15:07:33] __main__ INFO: \u001b[0mEpoch 27 loss 0.4095 acc@1 0.8798 acc@5 0.9950\n",
      "\u001b[32m[2020-06-20 15:07:33] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-20 15:07:33] __main__ INFO: \u001b[0mTrain 28 9477\n",
      "\u001b[32m[2020-06-20 15:07:42] __main__ INFO: \u001b[0mEpoch 28 Step 100/351 lr 0.001000 loss 0.0984 (0.1666) acc@1 0.9688 (0.9428) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-20 15:07:52] __main__ INFO: \u001b[0mEpoch 28 Step 200/351 lr 0.001000 loss 0.2230 (0.1688) acc@1 0.9297 (0.9420) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-06-20 15:08:01] __main__ INFO: \u001b[0mEpoch 28 Step 300/351 lr 0.001000 loss 0.1284 (0.1720) acc@1 0.9766 (0.9409) acc@5 0.9922 (0.9988)\n",
      "\u001b[32m[2020-06-20 15:08:05] __main__ INFO: \u001b[0mEpoch 28 Step 351/351 lr 0.001000 loss 0.1679 (0.1730) acc@1 0.9297 (0.9404) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-06-20 15:08:05] __main__ INFO: \u001b[0mElapsed 32.49\n",
      "\u001b[32m[2020-06-20 15:08:05] __main__ INFO: \u001b[0mVal 28\n",
      "\u001b[32m[2020-06-20 15:08:07] __main__ INFO: \u001b[0mEpoch 28 loss 0.4109 acc@1 0.8788 acc@5 0.9960\n",
      "\u001b[32m[2020-06-20 15:08:07] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 15:08:07] __main__ INFO: \u001b[0mTrain 29 9828\n",
      "\u001b[32m[2020-06-20 15:08:16] __main__ INFO: \u001b[0mEpoch 29 Step 100/351 lr 0.001000 loss 0.1736 (0.1637) acc@1 0.9219 (0.9444) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-20 15:08:25] __main__ INFO: \u001b[0mEpoch 29 Step 200/351 lr 0.001000 loss 0.2864 (0.1649) acc@1 0.9062 (0.9439) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-20 15:08:34] __main__ INFO: \u001b[0mEpoch 29 Step 300/351 lr 0.001000 loss 0.1881 (0.1683) acc@1 0.9453 (0.9422) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-06-20 15:08:39] __main__ INFO: \u001b[0mEpoch 29 Step 351/351 lr 0.001000 loss 0.1277 (0.1704) acc@1 0.9609 (0.9421) acc@5 1.0000 (0.9987)\n",
      "\u001b[32m[2020-06-20 15:08:39] __main__ INFO: \u001b[0mElapsed 32.43\n",
      "\u001b[32m[2020-06-20 15:08:39] __main__ INFO: \u001b[0mVal 29\n",
      "\u001b[32m[2020-06-20 15:08:40] __main__ INFO: \u001b[0mEpoch 29 loss 0.4096 acc@1 0.8782 acc@5 0.9954\n",
      "\u001b[32m[2020-06-20 15:08:40] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 15:08:40] __main__ INFO: \u001b[0mTrain 30 10179\n",
      "\u001b[32m[2020-06-20 15:08:49] __main__ INFO: \u001b[0mEpoch 30 Step 100/351 lr 0.001000 loss 0.1915 (0.1683) acc@1 0.9375 (0.9419) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-20 15:08:59] __main__ INFO: \u001b[0mEpoch 30 Step 200/351 lr 0.001000 loss 0.1119 (0.1700) acc@1 0.9688 (0.9409) acc@5 1.0000 (0.9989)\n",
      "\u001b[32m[2020-06-20 15:09:08] __main__ INFO: \u001b[0mEpoch 30 Step 300/351 lr 0.001000 loss 0.2042 (0.1705) acc@1 0.9375 (0.9411) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-20 15:09:12] __main__ INFO: \u001b[0mEpoch 30 Step 351/351 lr 0.001000 loss 0.1979 (0.1701) acc@1 0.9219 (0.9416) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-20 15:09:13] __main__ INFO: \u001b[0mElapsed 32.47\n",
      "\u001b[32m[2020-06-20 15:09:13] __main__ INFO: \u001b[0mVal 30\n",
      "\u001b[32m[2020-06-20 15:09:14] __main__ INFO: \u001b[0mEpoch 30 loss 0.4081 acc@1 0.8816 acc@5 0.9950\n",
      "\u001b[32m[2020-06-20 15:09:14] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-20 15:09:14] __main__ INFO: \u001b[0mTrain 31 10530\n",
      "\u001b[32m[2020-06-20 15:09:23] __main__ INFO: \u001b[0mEpoch 31 Step 100/351 lr 0.001000 loss 0.1265 (0.1811) acc@1 0.9453 (0.9368) acc@5 1.0000 (0.9987)\n",
      "\u001b[32m[2020-06-20 15:09:32] __main__ INFO: \u001b[0mEpoch 31 Step 200/351 lr 0.001000 loss 0.1711 (0.1745) acc@1 0.9453 (0.9394) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-06-20 15:09:41] __main__ INFO: \u001b[0mEpoch 31 Step 300/351 lr 0.001000 loss 0.1286 (0.1693) acc@1 0.9609 (0.9418) acc@5 1.0000 (0.9987)\n",
      "\u001b[32m[2020-06-20 15:09:46] __main__ INFO: \u001b[0mEpoch 31 Step 351/351 lr 0.001000 loss 0.1768 (0.1699) acc@1 0.9375 (0.9415) acc@5 1.0000 (0.9987)\n",
      "\u001b[32m[2020-06-20 15:09:46] __main__ INFO: \u001b[0mElapsed 32.50\n",
      "\u001b[32m[2020-06-20 15:09:46] __main__ INFO: \u001b[0mVal 31\n",
      "\u001b[32m[2020-06-20 15:09:47] __main__ INFO: \u001b[0mEpoch 31 loss 0.4120 acc@1 0.8810 acc@5 0.9954\n",
      "\u001b[32m[2020-06-20 15:09:47] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-20 15:09:47] __main__ INFO: \u001b[0mTrain 32 10881\n",
      "\u001b[32m[2020-06-20 15:09:57] __main__ INFO: \u001b[0mEpoch 32 Step 100/351 lr 0.001000 loss 0.0869 (0.1644) acc@1 0.9688 (0.9429) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-06-20 15:10:06] __main__ INFO: \u001b[0mEpoch 32 Step 200/351 lr 0.001000 loss 0.2019 (0.1632) acc@1 0.9219 (0.9443) acc@5 1.0000 (0.9987)\n",
      "\u001b[32m[2020-06-20 15:10:15] __main__ INFO: \u001b[0mEpoch 32 Step 300/351 lr 0.001000 loss 0.1965 (0.1649) acc@1 0.9531 (0.9435) acc@5 0.9922 (0.9988)\n",
      "\u001b[32m[2020-06-20 15:10:20] __main__ INFO: \u001b[0mEpoch 32 Step 351/351 lr 0.001000 loss 0.1876 (0.1663) acc@1 0.9219 (0.9431) acc@5 1.0000 (0.9987)\n",
      "\u001b[32m[2020-06-20 15:10:20] __main__ INFO: \u001b[0mElapsed 32.47\n",
      "\u001b[32m[2020-06-20 15:10:20] __main__ INFO: \u001b[0mVal 32\n",
      "\u001b[32m[2020-06-20 15:10:21] __main__ INFO: \u001b[0mEpoch 32 loss 0.4071 acc@1 0.8822 acc@5 0.9954\n",
      "\u001b[32m[2020-06-20 15:10:21] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-20 15:10:21] __main__ INFO: \u001b[0mTrain 33 11232\n",
      "\u001b[32m[2020-06-20 15:10:30] __main__ INFO: \u001b[0mEpoch 33 Step 100/351 lr 0.001000 loss 0.1170 (0.1669) acc@1 0.9531 (0.9441) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-06-20 15:10:39] __main__ INFO: \u001b[0mEpoch 33 Step 200/351 lr 0.001000 loss 0.1645 (0.1681) acc@1 0.9609 (0.9427) acc@5 1.0000 (0.9989)\n",
      "\u001b[32m[2020-06-20 15:10:48] __main__ INFO: \u001b[0mEpoch 33 Step 300/351 lr 0.001000 loss 0.2131 (0.1685) acc@1 0.9141 (0.9420) acc@5 1.0000 (0.9989)\n",
      "\u001b[32m[2020-06-20 15:10:53] __main__ INFO: \u001b[0mEpoch 33 Step 351/351 lr 0.001000 loss 0.1284 (0.1677) acc@1 0.9531 (0.9421) acc@5 1.0000 (0.9989)\n",
      "\u001b[32m[2020-06-20 15:10:53] __main__ INFO: \u001b[0mElapsed 32.42\n",
      "\u001b[32m[2020-06-20 15:10:53] __main__ INFO: \u001b[0mVal 33\n",
      "\u001b[32m[2020-06-20 15:10:54] __main__ INFO: \u001b[0mEpoch 33 loss 0.4060 acc@1 0.8812 acc@5 0.9958\n",
      "\u001b[32m[2020-06-20 15:10:54] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-20 15:10:54] __main__ INFO: \u001b[0mTrain 34 11583\n",
      "\u001b[32m[2020-06-20 15:11:04] __main__ INFO: \u001b[0mEpoch 34 Step 100/351 lr 0.001000 loss 0.0688 (0.1663) acc@1 0.9766 (0.9412) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-20 15:11:13] __main__ INFO: \u001b[0mEpoch 34 Step 200/351 lr 0.001000 loss 0.1565 (0.1611) acc@1 0.9453 (0.9437) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-20 15:11:22] __main__ INFO: \u001b[0mEpoch 34 Step 300/351 lr 0.001000 loss 0.1425 (0.1638) acc@1 0.9609 (0.9429) acc@5 0.9922 (0.9990)\n",
      "\u001b[32m[2020-06-20 15:11:27] __main__ INFO: \u001b[0mEpoch 34 Step 351/351 lr 0.001000 loss 0.1621 (0.1635) acc@1 0.9297 (0.9429) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-20 15:11:27] __main__ INFO: \u001b[0mElapsed 32.42\n",
      "\u001b[32m[2020-06-20 15:11:27] __main__ INFO: \u001b[0mVal 34\n",
      "\u001b[32m[2020-06-20 15:11:28] __main__ INFO: \u001b[0mEpoch 34 loss 0.4078 acc@1 0.8822 acc@5 0.9952\n",
      "\u001b[32m[2020-06-20 15:11:28] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-20 15:11:28] __main__ INFO: \u001b[0mTrain 35 11934\n",
      "\u001b[32m[2020-06-20 15:11:37] __main__ INFO: \u001b[0mEpoch 35 Step 100/351 lr 0.001000 loss 0.2071 (0.1524) acc@1 0.9062 (0.9463) acc@5 0.9922 (0.9991)\n",
      "\u001b[32m[2020-06-20 15:11:46] __main__ INFO: \u001b[0mEpoch 35 Step 200/351 lr 0.001000 loss 0.1809 (0.1588) acc@1 0.9062 (0.9437) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-06-20 15:11:55] __main__ INFO: \u001b[0mEpoch 35 Step 300/351 lr 0.001000 loss 0.1448 (0.1608) acc@1 0.9297 (0.9439) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-06-20 15:12:00] __main__ INFO: \u001b[0mEpoch 35 Step 351/351 lr 0.001000 loss 0.2435 (0.1605) acc@1 0.8906 (0.9437) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-06-20 15:12:00] __main__ INFO: \u001b[0mElapsed 32.44\n",
      "\u001b[32m[2020-06-20 15:12:00] __main__ INFO: \u001b[0mVal 35\n",
      "\u001b[32m[2020-06-20 15:12:01] __main__ INFO: \u001b[0mEpoch 35 loss 0.4039 acc@1 0.8822 acc@5 0.9954\n",
      "\u001b[32m[2020-06-20 15:12:01] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-20 15:12:01] __main__ INFO: \u001b[0mTrain 36 12285\n",
      "\u001b[32m[2020-06-20 15:12:11] __main__ INFO: \u001b[0mEpoch 36 Step 100/351 lr 0.001000 loss 0.1170 (0.1597) acc@1 0.9453 (0.9439) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-20 15:12:20] __main__ INFO: \u001b[0mEpoch 36 Step 200/351 lr 0.001000 loss 0.1069 (0.1617) acc@1 0.9688 (0.9434) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-20 15:12:29] __main__ INFO: \u001b[0mEpoch 36 Step 300/351 lr 0.001000 loss 0.1488 (0.1608) acc@1 0.9609 (0.9439) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-20 15:12:34] __main__ INFO: \u001b[0mEpoch 36 Step 351/351 lr 0.001000 loss 0.1567 (0.1599) acc@1 0.9297 (0.9444) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-20 15:12:34] __main__ INFO: \u001b[0mElapsed 32.50\n",
      "\u001b[32m[2020-06-20 15:12:34] __main__ INFO: \u001b[0mVal 36\n",
      "\u001b[32m[2020-06-20 15:12:35] __main__ INFO: \u001b[0mEpoch 36 loss 0.4089 acc@1 0.8840 acc@5 0.9948\n",
      "\u001b[32m[2020-06-20 15:12:35] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-20 15:12:35] __main__ INFO: \u001b[0mTrain 37 12636\n",
      "\u001b[32m[2020-06-20 15:12:44] __main__ INFO: \u001b[0mEpoch 37 Step 100/351 lr 0.001000 loss 0.1544 (0.1524) acc@1 0.9375 (0.9477) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-20 15:12:53] __main__ INFO: \u001b[0mEpoch 37 Step 200/351 lr 0.001000 loss 0.2201 (0.1569) acc@1 0.9062 (0.9457) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-20 15:13:03] __main__ INFO: \u001b[0mEpoch 37 Step 300/351 lr 0.001000 loss 0.1903 (0.1563) acc@1 0.9375 (0.9460) acc@5 1.0000 (0.9989)\n",
      "\u001b[32m[2020-06-20 15:13:07] __main__ INFO: \u001b[0mEpoch 37 Step 351/351 lr 0.001000 loss 0.1264 (0.1580) acc@1 0.9297 (0.9452) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-20 15:13:07] __main__ INFO: \u001b[0mElapsed 32.47\n",
      "\u001b[32m[2020-06-20 15:13:07] __main__ INFO: \u001b[0mVal 37\n",
      "\u001b[32m[2020-06-20 15:13:08] __main__ INFO: \u001b[0mEpoch 37 loss 0.4037 acc@1 0.8822 acc@5 0.9958\n",
      "\u001b[32m[2020-06-20 15:13:08] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-20 15:13:08] __main__ INFO: \u001b[0mTrain 38 12987\n",
      "\u001b[32m[2020-06-20 15:13:18] __main__ INFO: \u001b[0mEpoch 38 Step 100/351 lr 0.001000 loss 0.1519 (0.1596) acc@1 0.9453 (0.9427) acc@5 1.0000 (0.9986)\n",
      "\u001b[32m[2020-06-20 15:13:27] __main__ INFO: \u001b[0mEpoch 38 Step 200/351 lr 0.001000 loss 0.2083 (0.1614) acc@1 0.9219 (0.9446) acc@5 1.0000 (0.9989)\n",
      "\u001b[32m[2020-06-20 15:13:36] __main__ INFO: \u001b[0mEpoch 38 Step 300/351 lr 0.001000 loss 0.2079 (0.1582) acc@1 0.9297 (0.9454) acc@5 0.9922 (0.9989)\n",
      "\u001b[32m[2020-06-20 15:13:41] __main__ INFO: \u001b[0mEpoch 38 Step 351/351 lr 0.001000 loss 0.2345 (0.1573) acc@1 0.8984 (0.9455) acc@5 1.0000 (0.9989)\n",
      "\u001b[32m[2020-06-20 15:13:41] __main__ INFO: \u001b[0mElapsed 32.41\n",
      "\u001b[32m[2020-06-20 15:13:41] __main__ INFO: \u001b[0mVal 38\n",
      "\u001b[32m[2020-06-20 15:13:42] __main__ INFO: \u001b[0mEpoch 38 loss 0.4062 acc@1 0.8830 acc@5 0.9952\n",
      "\u001b[32m[2020-06-20 15:13:42] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-20 15:13:42] __main__ INFO: \u001b[0mTrain 39 13338\n",
      "\u001b[32m[2020-06-20 15:13:51] __main__ INFO: \u001b[0mEpoch 39 Step 100/351 lr 0.001000 loss 0.1370 (0.1506) acc@1 0.9609 (0.9481) acc@5 0.9922 (0.9993)\n",
      "\u001b[32m[2020-06-20 15:14:00] __main__ INFO: \u001b[0mEpoch 39 Step 200/351 lr 0.001000 loss 0.1314 (0.1540) acc@1 0.9453 (0.9473) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-20 15:14:10] __main__ INFO: \u001b[0mEpoch 39 Step 300/351 lr 0.001000 loss 0.1249 (0.1538) acc@1 0.9453 (0.9479) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-20 15:14:14] __main__ INFO: \u001b[0mEpoch 39 Step 351/351 lr 0.001000 loss 0.2673 (0.1568) acc@1 0.9141 (0.9466) acc@5 0.9922 (0.9990)\n",
      "\u001b[32m[2020-06-20 15:14:14] __main__ INFO: \u001b[0mElapsed 32.47\n",
      "\u001b[32m[2020-06-20 15:14:14] __main__ INFO: \u001b[0mVal 39\n",
      "\u001b[32m[2020-06-20 15:14:15] __main__ INFO: \u001b[0mEpoch 39 loss 0.4063 acc@1 0.8830 acc@5 0.9958\n",
      "\u001b[32m[2020-06-20 15:14:15] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-20 15:14:15] __main__ INFO: \u001b[0mTrain 40 13689\n",
      "\u001b[32m[2020-06-20 15:14:25] __main__ INFO: \u001b[0mEpoch 40 Step 100/351 lr 0.001000 loss 0.1208 (0.1562) acc@1 0.9531 (0.9469) acc@5 1.0000 (0.9987)\n",
      "\u001b[32m[2020-06-20 15:14:34] __main__ INFO: \u001b[0mEpoch 40 Step 200/351 lr 0.001000 loss 0.1437 (0.1522) acc@1 0.9453 (0.9470) acc@5 1.0000 (0.9989)\n",
      "\u001b[32m[2020-06-20 15:14:43] __main__ INFO: \u001b[0mEpoch 40 Step 300/351 lr 0.001000 loss 0.1710 (0.1508) acc@1 0.9375 (0.9480) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-20 15:14:48] __main__ INFO: \u001b[0mEpoch 40 Step 351/351 lr 0.001000 loss 0.2182 (0.1526) acc@1 0.9219 (0.9477) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-20 15:14:48] __main__ INFO: \u001b[0mElapsed 32.44\n",
      "\u001b[32m[2020-06-20 15:14:48] __main__ INFO: \u001b[0mVal 40\n",
      "\u001b[32m[2020-06-20 15:14:49] __main__ INFO: \u001b[0mEpoch 40 loss 0.4110 acc@1 0.8800 acc@5 0.9956\n",
      "\u001b[32m[2020-06-20 15:14:49] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-20 15:14:49] __main__ INFO: \u001b[0mTrain 41 14040\n",
      "\u001b[32m[2020-06-20 15:14:58] __main__ INFO: \u001b[0mEpoch 41 Step 100/351 lr 0.001000 loss 0.1153 (0.1519) acc@1 0.9531 (0.9499) acc@5 1.0000 (0.9989)\n",
      "\u001b[32m[2020-06-20 15:15:07] __main__ INFO: \u001b[0mEpoch 41 Step 200/351 lr 0.001000 loss 0.1327 (0.1532) acc@1 0.9609 (0.9484) acc@5 0.9922 (0.9988)\n",
      "\u001b[32m[2020-06-20 15:15:17] __main__ INFO: \u001b[0mEpoch 41 Step 300/351 lr 0.001000 loss 0.1005 (0.1520) acc@1 0.9766 (0.9486) acc@5 0.9922 (0.9988)\n",
      "\u001b[32m[2020-06-20 15:15:21] __main__ INFO: \u001b[0mEpoch 41 Step 351/351 lr 0.001000 loss 0.1283 (0.1526) acc@1 0.9609 (0.9481) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-06-20 15:15:21] __main__ INFO: \u001b[0mElapsed 32.41\n",
      "\u001b[32m[2020-06-20 15:15:21] __main__ INFO: \u001b[0mVal 41\n",
      "\u001b[32m[2020-06-20 15:15:22] __main__ INFO: \u001b[0mEpoch 41 loss 0.4085 acc@1 0.8818 acc@5 0.9956\n",
      "\u001b[32m[2020-06-20 15:15:22] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-20 15:15:22] __main__ INFO: \u001b[0mTrain 42 14391\n",
      "\u001b[32m[2020-06-20 15:15:32] __main__ INFO: \u001b[0mEpoch 42 Step 100/351 lr 0.001000 loss 0.1307 (0.1460) acc@1 0.9609 (0.9489) acc@5 0.9922 (0.9991)\n",
      "\u001b[32m[2020-06-20 15:15:41] __main__ INFO: \u001b[0mEpoch 42 Step 200/351 lr 0.001000 loss 0.1757 (0.1466) acc@1 0.9609 (0.9488) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-20 15:15:50] __main__ INFO: \u001b[0mEpoch 42 Step 300/351 lr 0.001000 loss 0.1519 (0.1478) acc@1 0.9531 (0.9485) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-20 15:15:55] __main__ INFO: \u001b[0mEpoch 42 Step 351/351 lr 0.001000 loss 0.0968 (0.1500) acc@1 0.9609 (0.9478) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-20 15:15:55] __main__ INFO: \u001b[0mElapsed 32.47\n",
      "\u001b[32m[2020-06-20 15:15:55] __main__ INFO: \u001b[0mVal 42\n",
      "\u001b[32m[2020-06-20 15:15:56] __main__ INFO: \u001b[0mEpoch 42 loss 0.4065 acc@1 0.8818 acc@5 0.9954\n",
      "\u001b[32m[2020-06-20 15:15:56] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-20 15:15:56] __main__ INFO: \u001b[0mTrain 43 14742\n",
      "\u001b[32m[2020-06-20 15:16:05] __main__ INFO: \u001b[0mEpoch 43 Step 100/351 lr 0.001000 loss 0.1165 (0.1547) acc@1 0.9688 (0.9484) acc@5 1.0000 (0.9989)\n",
      "\u001b[32m[2020-06-20 15:16:15] __main__ INFO: \u001b[0mEpoch 43 Step 200/351 lr 0.001000 loss 0.1989 (0.1477) acc@1 0.9297 (0.9498) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-20 15:16:24] __main__ INFO: \u001b[0mEpoch 43 Step 300/351 lr 0.001000 loss 0.1722 (0.1470) acc@1 0.9531 (0.9500) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-20 15:16:28] __main__ INFO: \u001b[0mEpoch 43 Step 351/351 lr 0.001000 loss 0.0884 (0.1460) acc@1 0.9609 (0.9500) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-20 15:16:28] __main__ INFO: \u001b[0mElapsed 32.47\n",
      "\u001b[32m[2020-06-20 15:16:28] __main__ INFO: \u001b[0mVal 43\n",
      "\u001b[32m[2020-06-20 15:16:30] __main__ INFO: \u001b[0mEpoch 43 loss 0.4065 acc@1 0.8818 acc@5 0.9958\n",
      "\u001b[32m[2020-06-20 15:16:30] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-20 15:16:30] __main__ INFO: \u001b[0mTrain 44 15093\n",
      "\u001b[32m[2020-06-20 15:16:39] __main__ INFO: \u001b[0mEpoch 44 Step 100/351 lr 0.001000 loss 0.0857 (0.1471) acc@1 0.9766 (0.9481) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-20 15:16:48] __main__ INFO: \u001b[0mEpoch 44 Step 200/351 lr 0.001000 loss 0.1080 (0.1492) acc@1 0.9609 (0.9482) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-20 15:16:57] __main__ INFO: \u001b[0mEpoch 44 Step 300/351 lr 0.001000 loss 0.1228 (0.1471) acc@1 0.9609 (0.9483) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-20 15:17:02] __main__ INFO: \u001b[0mEpoch 44 Step 351/351 lr 0.001000 loss 0.1515 (0.1488) acc@1 0.9609 (0.9477) acc@5 0.9922 (0.9991)\n",
      "\u001b[32m[2020-06-20 15:17:02] __main__ INFO: \u001b[0mElapsed 32.50\n",
      "\u001b[32m[2020-06-20 15:17:02] __main__ INFO: \u001b[0mVal 44\n",
      "\u001b[32m[2020-06-20 15:17:03] __main__ INFO: \u001b[0mEpoch 44 loss 0.4139 acc@1 0.8804 acc@5 0.9958\n",
      "\u001b[32m[2020-06-20 15:17:03] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-20 15:17:03] __main__ INFO: \u001b[0mTrain 45 15444\n",
      "\u001b[32m[2020-06-20 15:17:12] __main__ INFO: \u001b[0mEpoch 45 Step 100/351 lr 0.001000 loss 0.0984 (0.1463) acc@1 0.9766 (0.9492) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-20 15:17:22] __main__ INFO: \u001b[0mEpoch 45 Step 200/351 lr 0.001000 loss 0.0825 (0.1492) acc@1 0.9766 (0.9490) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-20 15:17:31] __main__ INFO: \u001b[0mEpoch 45 Step 300/351 lr 0.001000 loss 0.1223 (0.1478) acc@1 0.9844 (0.9492) acc@5 0.9922 (0.9990)\n",
      "\u001b[32m[2020-06-20 15:17:35] __main__ INFO: \u001b[0mEpoch 45 Step 351/351 lr 0.001000 loss 0.2059 (0.1473) acc@1 0.9453 (0.9499) acc@5 0.9922 (0.9991)\n",
      "\u001b[32m[2020-06-20 15:17:36] __main__ INFO: \u001b[0mElapsed 32.45\n",
      "\u001b[32m[2020-06-20 15:17:36] __main__ INFO: \u001b[0mVal 45\n",
      "\u001b[32m[2020-06-20 15:17:37] __main__ INFO: \u001b[0mEpoch 45 loss 0.4103 acc@1 0.8826 acc@5 0.9956\n",
      "\u001b[32m[2020-06-20 15:17:37] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-20 15:17:37] __main__ INFO: \u001b[0mTrain 46 15795\n",
      "\u001b[32m[2020-06-20 15:17:46] __main__ INFO: \u001b[0mEpoch 46 Step 100/351 lr 0.001000 loss 0.1148 (0.1422) acc@1 0.9609 (0.9523) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-20 15:17:55] __main__ INFO: \u001b[0mEpoch 46 Step 200/351 lr 0.001000 loss 0.1246 (0.1444) acc@1 0.9531 (0.9507) acc@5 1.0000 (0.9989)\n",
      "\u001b[32m[2020-06-20 15:18:04] __main__ INFO: \u001b[0mEpoch 46 Step 300/351 lr 0.001000 loss 0.2075 (0.1450) acc@1 0.9062 (0.9503) acc@5 1.0000 (0.9989)\n",
      "\u001b[32m[2020-06-20 15:18:09] __main__ INFO: \u001b[0mEpoch 46 Step 351/351 lr 0.001000 loss 0.1430 (0.1442) acc@1 0.9688 (0.9507) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-20 15:18:09] __main__ INFO: \u001b[0mElapsed 32.48\n",
      "\u001b[32m[2020-06-20 15:18:09] __main__ INFO: \u001b[0mVal 46\n",
      "\u001b[32m[2020-06-20 15:18:10] __main__ INFO: \u001b[0mEpoch 46 loss 0.4147 acc@1 0.8812 acc@5 0.9954\n",
      "\u001b[32m[2020-06-20 15:18:10] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-20 15:18:10] __main__ INFO: \u001b[0mTrain 47 16146\n",
      "\u001b[32m[2020-06-20 15:18:19] __main__ INFO: \u001b[0mEpoch 47 Step 100/351 lr 0.001000 loss 0.0875 (0.1424) acc@1 0.9766 (0.9492) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:18:29] __main__ INFO: \u001b[0mEpoch 47 Step 200/351 lr 0.001000 loss 0.0628 (0.1401) acc@1 0.9844 (0.9509) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-20 15:18:38] __main__ INFO: \u001b[0mEpoch 47 Step 300/351 lr 0.001000 loss 0.2169 (0.1407) acc@1 0.9453 (0.9512) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-20 15:18:43] __main__ INFO: \u001b[0mEpoch 47 Step 351/351 lr 0.001000 loss 0.1992 (0.1425) acc@1 0.9219 (0.9504) acc@5 0.9922 (0.9992)\n",
      "\u001b[32m[2020-06-20 15:18:43] __main__ INFO: \u001b[0mElapsed 32.48\n",
      "\u001b[32m[2020-06-20 15:18:43] __main__ INFO: \u001b[0mVal 47\n",
      "\u001b[32m[2020-06-20 15:18:44] __main__ INFO: \u001b[0mEpoch 47 loss 0.4082 acc@1 0.8816 acc@5 0.9958\n",
      "\u001b[32m[2020-06-20 15:18:44] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-20 15:18:44] __main__ INFO: \u001b[0mTrain 48 16497\n",
      "\u001b[32m[2020-06-20 15:18:53] __main__ INFO: \u001b[0mEpoch 48 Step 100/351 lr 0.001000 loss 0.1251 (0.1330) acc@1 0.9609 (0.9537) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 15:19:02] __main__ INFO: \u001b[0mEpoch 48 Step 200/351 lr 0.001000 loss 0.1585 (0.1338) acc@1 0.9453 (0.9529) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:19:11] __main__ INFO: \u001b[0mEpoch 48 Step 300/351 lr 0.001000 loss 0.1461 (0.1364) acc@1 0.9375 (0.9522) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:19:16] __main__ INFO: \u001b[0mEpoch 48 Step 351/351 lr 0.001000 loss 0.1049 (0.1373) acc@1 0.9766 (0.9518) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:19:16] __main__ INFO: \u001b[0mElapsed 32.43\n",
      "\u001b[32m[2020-06-20 15:19:16] __main__ INFO: \u001b[0mVal 48\n",
      "\u001b[32m[2020-06-20 15:19:17] __main__ INFO: \u001b[0mEpoch 48 loss 0.4160 acc@1 0.8796 acc@5 0.9956\n",
      "\u001b[32m[2020-06-20 15:19:17] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 15:19:17] __main__ INFO: \u001b[0mTrain 49 16848\n",
      "\u001b[32m[2020-06-20 15:19:26] __main__ INFO: \u001b[0mEpoch 49 Step 100/351 lr 0.001000 loss 0.0715 (0.1419) acc@1 0.9766 (0.9530) acc@5 1.0000 (0.9989)\n",
      "\u001b[32m[2020-06-20 15:19:36] __main__ INFO: \u001b[0mEpoch 49 Step 200/351 lr 0.001000 loss 0.1825 (0.1418) acc@1 0.9375 (0.9523) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-20 15:19:45] __main__ INFO: \u001b[0mEpoch 49 Step 300/351 lr 0.001000 loss 0.1570 (0.1407) acc@1 0.9531 (0.9526) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-20 15:19:50] __main__ INFO: \u001b[0mEpoch 49 Step 351/351 lr 0.001000 loss 0.2337 (0.1400) acc@1 0.9219 (0.9530) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-20 15:19:50] __main__ INFO: \u001b[0mElapsed 32.38\n",
      "\u001b[32m[2020-06-20 15:19:50] __main__ INFO: \u001b[0mVal 49\n",
      "\u001b[32m[2020-06-20 15:19:51] __main__ INFO: \u001b[0mEpoch 49 loss 0.4118 acc@1 0.8810 acc@5 0.9958\n",
      "\u001b[32m[2020-06-20 15:19:51] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-20 15:19:51] __main__ INFO: \u001b[0mTrain 50 17199\n",
      "\u001b[32m[2020-06-20 15:20:00] __main__ INFO: \u001b[0mEpoch 50 Step 100/351 lr 0.001000 loss 0.2071 (0.1366) acc@1 0.9453 (0.9527) acc@5 0.9844 (0.9992)\n",
      "\u001b[32m[2020-06-20 15:20:09] __main__ INFO: \u001b[0mEpoch 50 Step 200/351 lr 0.001000 loss 0.1255 (0.1367) acc@1 0.9688 (0.9531) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-20 15:20:18] __main__ INFO: \u001b[0mEpoch 50 Step 300/351 lr 0.001000 loss 0.1390 (0.1383) acc@1 0.9531 (0.9521) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-20 15:20:23] __main__ INFO: \u001b[0mEpoch 50 Step 351/351 lr 0.001000 loss 0.1222 (0.1384) acc@1 0.9609 (0.9523) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-20 15:20:23] __main__ INFO: \u001b[0mElapsed 32.47\n",
      "\u001b[32m[2020-06-20 15:20:23] __main__ INFO: \u001b[0mVal 50\n",
      "\u001b[32m[2020-06-20 15:20:24] __main__ INFO: \u001b[0mEpoch 50 loss 0.4133 acc@1 0.8826 acc@5 0.9962\n",
      "\u001b[32m[2020-06-20 15:20:24] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 15:20:24] __main__ INFO: \u001b[0mTrain 51 17550\n",
      "\u001b[32m[2020-06-20 15:20:34] __main__ INFO: \u001b[0mEpoch 51 Step 100/351 lr 0.001000 loss 0.2046 (0.1342) acc@1 0.9297 (0.9527) acc@5 0.9922 (0.9994)\n",
      "\u001b[32m[2020-06-20 15:20:43] __main__ INFO: \u001b[0mEpoch 51 Step 200/351 lr 0.001000 loss 0.0992 (0.1316) acc@1 0.9766 (0.9552) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-20 15:20:52] __main__ INFO: \u001b[0mEpoch 51 Step 300/351 lr 0.001000 loss 0.1192 (0.1330) acc@1 0.9531 (0.9541) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-20 15:20:57] __main__ INFO: \u001b[0mEpoch 51 Step 351/351 lr 0.001000 loss 0.1422 (0.1356) acc@1 0.9609 (0.9533) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-20 15:20:57] __main__ INFO: \u001b[0mElapsed 32.45\n",
      "\u001b[32m[2020-06-20 15:20:57] __main__ INFO: \u001b[0mVal 51\n",
      "\u001b[32m[2020-06-20 15:20:58] __main__ INFO: \u001b[0mEpoch 51 loss 0.4111 acc@1 0.8816 acc@5 0.9956\n",
      "\u001b[32m[2020-06-20 15:20:58] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-20 15:20:58] __main__ INFO: \u001b[0mTrain 52 17901\n",
      "\u001b[32m[2020-06-20 15:21:07] __main__ INFO: \u001b[0mEpoch 52 Step 100/351 lr 0.001000 loss 0.2577 (0.1403) acc@1 0.9062 (0.9530) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-20 15:21:16] __main__ INFO: \u001b[0mEpoch 52 Step 200/351 lr 0.001000 loss 0.0891 (0.1375) acc@1 0.9688 (0.9532) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:21:25] __main__ INFO: \u001b[0mEpoch 52 Step 300/351 lr 0.001000 loss 0.1114 (0.1377) acc@1 0.9609 (0.9526) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:21:30] __main__ INFO: \u001b[0mEpoch 52 Step 351/351 lr 0.001000 loss 0.1844 (0.1388) acc@1 0.9453 (0.9519) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-20 15:21:30] __main__ INFO: \u001b[0mElapsed 32.43\n",
      "\u001b[32m[2020-06-20 15:21:30] __main__ INFO: \u001b[0mVal 52\n",
      "\u001b[32m[2020-06-20 15:21:31] __main__ INFO: \u001b[0mEpoch 52 loss 0.4126 acc@1 0.8828 acc@5 0.9952\n",
      "\u001b[32m[2020-06-20 15:21:31] __main__ INFO: \u001b[0mElapsed 1.14\n",
      "\u001b[32m[2020-06-20 15:21:31] __main__ INFO: \u001b[0mTrain 53 18252\n",
      "\u001b[32m[2020-06-20 15:21:41] __main__ INFO: \u001b[0mEpoch 53 Step 100/351 lr 0.001000 loss 0.1053 (0.1330) acc@1 0.9688 (0.9541) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-20 15:21:50] __main__ INFO: \u001b[0mEpoch 53 Step 200/351 lr 0.001000 loss 0.0940 (0.1340) acc@1 0.9609 (0.9539) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-20 15:21:59] __main__ INFO: \u001b[0mEpoch 53 Step 300/351 lr 0.001000 loss 0.0764 (0.1343) acc@1 0.9688 (0.9532) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-20 15:22:04] __main__ INFO: \u001b[0mEpoch 53 Step 351/351 lr 0.001000 loss 0.1870 (0.1339) acc@1 0.9375 (0.9535) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-20 15:22:04] __main__ INFO: \u001b[0mElapsed 32.43\n",
      "\u001b[32m[2020-06-20 15:22:04] __main__ INFO: \u001b[0mVal 53\n",
      "\u001b[32m[2020-06-20 15:22:05] __main__ INFO: \u001b[0mEpoch 53 loss 0.4145 acc@1 0.8810 acc@5 0.9956\n",
      "\u001b[32m[2020-06-20 15:22:05] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-20 15:22:05] __main__ INFO: \u001b[0mTrain 54 18603\n",
      "\u001b[32m[2020-06-20 15:22:14] __main__ INFO: \u001b[0mEpoch 54 Step 100/351 lr 0.001000 loss 0.2310 (0.1315) acc@1 0.9297 (0.9561) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-20 15:22:23] __main__ INFO: \u001b[0mEpoch 54 Step 200/351 lr 0.001000 loss 0.1015 (0.1328) acc@1 0.9609 (0.9550) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-20 15:22:33] __main__ INFO: \u001b[0mEpoch 54 Step 300/351 lr 0.001000 loss 0.1249 (0.1320) acc@1 0.9453 (0.9549) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-20 15:22:37] __main__ INFO: \u001b[0mEpoch 54 Step 351/351 lr 0.001000 loss 0.1777 (0.1325) acc@1 0.9219 (0.9545) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-20 15:22:37] __main__ INFO: \u001b[0mElapsed 32.46\n",
      "\u001b[32m[2020-06-20 15:22:37] __main__ INFO: \u001b[0mVal 54\n",
      "\u001b[32m[2020-06-20 15:22:38] __main__ INFO: \u001b[0mEpoch 54 loss 0.4166 acc@1 0.8802 acc@5 0.9958\n",
      "\u001b[32m[2020-06-20 15:22:38] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-20 15:22:38] __main__ INFO: \u001b[0mTrain 55 18954\n",
      "\u001b[32m[2020-06-20 15:22:48] __main__ INFO: \u001b[0mEpoch 55 Step 100/351 lr 0.001000 loss 0.1011 (0.1239) acc@1 0.9688 (0.9586) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-20 15:22:57] __main__ INFO: \u001b[0mEpoch 55 Step 200/351 lr 0.001000 loss 0.1099 (0.1307) acc@1 0.9609 (0.9555) acc@5 1.0000 (0.9989)\n",
      "\u001b[32m[2020-06-20 15:23:06] __main__ INFO: \u001b[0mEpoch 55 Step 300/351 lr 0.001000 loss 0.1078 (0.1336) acc@1 0.9531 (0.9540) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-06-20 15:23:11] __main__ INFO: \u001b[0mEpoch 55 Step 351/351 lr 0.001000 loss 0.1192 (0.1333) acc@1 0.9531 (0.9537) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-20 15:23:11] __main__ INFO: \u001b[0mElapsed 32.46\n",
      "\u001b[32m[2020-06-20 15:23:11] __main__ INFO: \u001b[0mVal 55\n",
      "\u001b[32m[2020-06-20 15:23:12] __main__ INFO: \u001b[0mEpoch 55 loss 0.4156 acc@1 0.8800 acc@5 0.9956\n",
      "\u001b[32m[2020-06-20 15:23:12] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-20 15:23:12] __main__ INFO: \u001b[0mTrain 56 19305\n",
      "\u001b[32m[2020-06-20 15:23:21] __main__ INFO: \u001b[0mEpoch 56 Step 100/351 lr 0.001000 loss 0.0858 (0.1260) acc@1 0.9844 (0.9572) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-20 15:23:30] __main__ INFO: \u001b[0mEpoch 56 Step 200/351 lr 0.001000 loss 0.1252 (0.1282) acc@1 0.9531 (0.9559) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-20 15:23:40] __main__ INFO: \u001b[0mEpoch 56 Step 300/351 lr 0.001000 loss 0.1412 (0.1280) acc@1 0.9609 (0.9561) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-20 15:23:44] __main__ INFO: \u001b[0mEpoch 56 Step 351/351 lr 0.001000 loss 0.1082 (0.1278) acc@1 0.9609 (0.9560) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-20 15:23:44] __main__ INFO: \u001b[0mElapsed 32.47\n",
      "\u001b[32m[2020-06-20 15:23:44] __main__ INFO: \u001b[0mVal 56\n",
      "\u001b[32m[2020-06-20 15:23:45] __main__ INFO: \u001b[0mEpoch 56 loss 0.4170 acc@1 0.8802 acc@5 0.9954\n",
      "\u001b[32m[2020-06-20 15:23:45] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 15:23:45] __main__ INFO: \u001b[0mTrain 57 19656\n",
      "\u001b[32m[2020-06-20 15:23:55] __main__ INFO: \u001b[0mEpoch 57 Step 100/351 lr 0.001000 loss 0.0507 (0.1227) acc@1 0.9844 (0.9575) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-06-20 15:24:04] __main__ INFO: \u001b[0mEpoch 57 Step 200/351 lr 0.001000 loss 0.1187 (0.1261) acc@1 0.9609 (0.9564) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-20 15:24:13] __main__ INFO: \u001b[0mEpoch 57 Step 300/351 lr 0.001000 loss 0.1403 (0.1280) acc@1 0.9609 (0.9558) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-20 15:24:18] __main__ INFO: \u001b[0mEpoch 57 Step 351/351 lr 0.001000 loss 0.1751 (0.1289) acc@1 0.9375 (0.9554) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-20 15:24:18] __main__ INFO: \u001b[0mElapsed 32.45\n",
      "\u001b[32m[2020-06-20 15:24:18] __main__ INFO: \u001b[0mVal 57\n",
      "\u001b[32m[2020-06-20 15:24:19] __main__ INFO: \u001b[0mEpoch 57 loss 0.4157 acc@1 0.8816 acc@5 0.9956\n",
      "\u001b[32m[2020-06-20 15:24:19] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 15:24:19] __main__ INFO: \u001b[0mTrain 58 20007\n",
      "\u001b[32m[2020-06-20 15:24:28] __main__ INFO: \u001b[0mEpoch 58 Step 100/351 lr 0.001000 loss 0.1403 (0.1286) acc@1 0.9453 (0.9577) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-20 15:24:37] __main__ INFO: \u001b[0mEpoch 58 Step 200/351 lr 0.001000 loss 0.2395 (0.1289) acc@1 0.9219 (0.9563) acc@5 0.9922 (0.9992)\n",
      "\u001b[32m[2020-06-20 15:24:47] __main__ INFO: \u001b[0mEpoch 58 Step 300/351 lr 0.001000 loss 0.1495 (0.1287) acc@1 0.9531 (0.9563) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-20 15:24:51] __main__ INFO: \u001b[0mEpoch 58 Step 351/351 lr 0.001000 loss 0.1918 (0.1277) acc@1 0.9297 (0.9565) acc@5 0.9922 (0.9993)\n",
      "\u001b[32m[2020-06-20 15:24:51] __main__ INFO: \u001b[0mElapsed 32.42\n",
      "\u001b[32m[2020-06-20 15:24:51] __main__ INFO: \u001b[0mVal 58\n",
      "\u001b[32m[2020-06-20 15:24:52] __main__ INFO: \u001b[0mEpoch 58 loss 0.4112 acc@1 0.8830 acc@5 0.9952\n",
      "\u001b[32m[2020-06-20 15:24:52] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 15:24:52] __main__ INFO: \u001b[0mTrain 59 20358\n",
      "\u001b[32m[2020-06-20 15:25:02] __main__ INFO: \u001b[0mEpoch 59 Step 100/351 lr 0.001000 loss 0.0906 (0.1245) acc@1 0.9844 (0.9584) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:25:11] __main__ INFO: \u001b[0mEpoch 59 Step 200/351 lr 0.001000 loss 0.1133 (0.1253) acc@1 0.9688 (0.9573) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-20 15:25:20] __main__ INFO: \u001b[0mEpoch 59 Step 300/351 lr 0.001000 loss 0.1556 (0.1265) acc@1 0.9609 (0.9569) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-20 15:25:25] __main__ INFO: \u001b[0mEpoch 59 Step 351/351 lr 0.001000 loss 0.1106 (0.1268) acc@1 0.9766 (0.9571) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-20 15:25:25] __main__ INFO: \u001b[0mElapsed 32.47\n",
      "\u001b[32m[2020-06-20 15:25:25] __main__ INFO: \u001b[0mVal 59\n",
      "\u001b[32m[2020-06-20 15:25:26] __main__ INFO: \u001b[0mEpoch 59 loss 0.4174 acc@1 0.8822 acc@5 0.9952\n",
      "\u001b[32m[2020-06-20 15:25:26] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-20 15:25:26] __main__ INFO: \u001b[0mTrain 60 20709\n",
      "\u001b[32m[2020-06-20 15:25:35] __main__ INFO: \u001b[0mEpoch 60 Step 100/351 lr 0.001000 loss 0.1296 (0.1267) acc@1 0.9609 (0.9559) acc@5 0.9922 (0.9992)\n",
      "\u001b[32m[2020-06-20 15:25:44] __main__ INFO: \u001b[0mEpoch 60 Step 200/351 lr 0.001000 loss 0.1627 (0.1236) acc@1 0.9531 (0.9583) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-20 15:25:54] __main__ INFO: \u001b[0mEpoch 60 Step 300/351 lr 0.001000 loss 0.1971 (0.1248) acc@1 0.9062 (0.9574) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-20 15:25:58] __main__ INFO: \u001b[0mEpoch 60 Step 351/351 lr 0.001000 loss 0.1368 (0.1246) acc@1 0.9609 (0.9574) acc@5 0.9922 (0.9993)\n",
      "\u001b[32m[2020-06-20 15:25:58] __main__ INFO: \u001b[0mElapsed 32.41\n",
      "\u001b[32m[2020-06-20 15:25:58] __main__ INFO: \u001b[0mVal 60\n",
      "\u001b[32m[2020-06-20 15:25:59] __main__ INFO: \u001b[0mEpoch 60 loss 0.4158 acc@1 0.8792 acc@5 0.9958\n",
      "\u001b[32m[2020-06-20 15:25:59] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-20 15:25:59] __main__ INFO: \u001b[0mTrain 61 21060\n",
      "\u001b[32m[2020-06-20 15:26:09] __main__ INFO: \u001b[0mEpoch 61 Step 100/351 lr 0.001000 loss 0.0545 (0.1154) acc@1 0.9844 (0.9611) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-20 15:26:18] __main__ INFO: \u001b[0mEpoch 61 Step 200/351 lr 0.001000 loss 0.1052 (0.1203) acc@1 0.9453 (0.9600) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-20 15:26:27] __main__ INFO: \u001b[0mEpoch 61 Step 300/351 lr 0.001000 loss 0.1385 (0.1219) acc@1 0.9609 (0.9589) acc@5 0.9922 (0.9994)\n",
      "\u001b[32m[2020-06-20 15:26:32] __main__ INFO: \u001b[0mEpoch 61 Step 351/351 lr 0.001000 loss 0.1059 (0.1221) acc@1 0.9688 (0.9587) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-20 15:26:32] __main__ INFO: \u001b[0mElapsed 32.44\n",
      "\u001b[32m[2020-06-20 15:26:32] __main__ INFO: \u001b[0mVal 61\n",
      "\u001b[32m[2020-06-20 15:26:33] __main__ INFO: \u001b[0mEpoch 61 loss 0.4167 acc@1 0.8810 acc@5 0.9958\n",
      "\u001b[32m[2020-06-20 15:26:33] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-20 15:26:33] __main__ INFO: \u001b[0mTrain 62 21411\n",
      "\u001b[32m[2020-06-20 15:26:42] __main__ INFO: \u001b[0mEpoch 62 Step 100/351 lr 0.001000 loss 0.0778 (0.1259) acc@1 0.9688 (0.9585) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:26:51] __main__ INFO: \u001b[0mEpoch 62 Step 200/351 lr 0.001000 loss 0.0596 (0.1213) acc@1 0.9844 (0.9590) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:27:01] __main__ INFO: \u001b[0mEpoch 62 Step 300/351 lr 0.001000 loss 0.1246 (0.1231) acc@1 0.9688 (0.9576) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:27:05] __main__ INFO: \u001b[0mEpoch 62 Step 351/351 lr 0.001000 loss 0.1062 (0.1225) acc@1 0.9609 (0.9576) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:27:05] __main__ INFO: \u001b[0mElapsed 32.44\n",
      "\u001b[32m[2020-06-20 15:27:05] __main__ INFO: \u001b[0mVal 62\n",
      "\u001b[32m[2020-06-20 15:27:06] __main__ INFO: \u001b[0mEpoch 62 loss 0.4184 acc@1 0.8800 acc@5 0.9954\n",
      "\u001b[32m[2020-06-20 15:27:06] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 15:27:06] __main__ INFO: \u001b[0mTrain 63 21762\n",
      "\u001b[32m[2020-06-20 15:27:16] __main__ INFO: \u001b[0mEpoch 63 Step 100/351 lr 0.001000 loss 0.1196 (0.1237) acc@1 0.9609 (0.9583) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-20 15:27:25] __main__ INFO: \u001b[0mEpoch 63 Step 200/351 lr 0.001000 loss 0.1598 (0.1257) acc@1 0.9453 (0.9565) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-20 15:27:34] __main__ INFO: \u001b[0mEpoch 63 Step 300/351 lr 0.001000 loss 0.0819 (0.1243) acc@1 0.9766 (0.9571) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-20 15:27:39] __main__ INFO: \u001b[0mEpoch 63 Step 351/351 lr 0.001000 loss 0.1457 (0.1235) acc@1 0.9453 (0.9572) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-20 15:27:39] __main__ INFO: \u001b[0mElapsed 32.49\n",
      "\u001b[32m[2020-06-20 15:27:39] __main__ INFO: \u001b[0mVal 63\n",
      "\u001b[32m[2020-06-20 15:27:40] __main__ INFO: \u001b[0mEpoch 63 loss 0.4194 acc@1 0.8816 acc@5 0.9952\n",
      "\u001b[32m[2020-06-20 15:27:40] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 15:27:40] __main__ INFO: \u001b[0mTrain 64 22113\n",
      "\u001b[32m[2020-06-20 15:27:49] __main__ INFO: \u001b[0mEpoch 64 Step 100/351 lr 0.001000 loss 0.0806 (0.1198) acc@1 0.9766 (0.9592) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:27:59] __main__ INFO: \u001b[0mEpoch 64 Step 200/351 lr 0.001000 loss 0.1106 (0.1181) acc@1 0.9531 (0.9592) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:28:08] __main__ INFO: \u001b[0mEpoch 64 Step 300/351 lr 0.001000 loss 0.0933 (0.1194) acc@1 0.9688 (0.9592) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-20 15:28:12] __main__ INFO: \u001b[0mEpoch 64 Step 351/351 lr 0.001000 loss 0.1054 (0.1207) acc@1 0.9609 (0.9584) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-20 15:28:12] __main__ INFO: \u001b[0mElapsed 32.41\n",
      "\u001b[32m[2020-06-20 15:28:12] __main__ INFO: \u001b[0mVal 64\n",
      "\u001b[32m[2020-06-20 15:28:14] __main__ INFO: \u001b[0mEpoch 64 loss 0.4216 acc@1 0.8822 acc@5 0.9952\n",
      "\u001b[32m[2020-06-20 15:28:14] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 15:28:14] __main__ INFO: \u001b[0mTrain 65 22464\n",
      "\u001b[32m[2020-06-20 15:28:23] __main__ INFO: \u001b[0mEpoch 65 Step 100/351 lr 0.001000 loss 0.1986 (0.1258) acc@1 0.9453 (0.9567) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:28:32] __main__ INFO: \u001b[0mEpoch 65 Step 200/351 lr 0.001000 loss 0.0713 (0.1251) acc@1 0.9766 (0.9573) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:28:41] __main__ INFO: \u001b[0mEpoch 65 Step 300/351 lr 0.001000 loss 0.0794 (0.1250) acc@1 0.9766 (0.9573) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:28:46] __main__ INFO: \u001b[0mEpoch 65 Step 351/351 lr 0.001000 loss 0.1652 (0.1243) acc@1 0.9453 (0.9572) acc@5 0.9922 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:28:46] __main__ INFO: \u001b[0mElapsed 32.42\n",
      "\u001b[32m[2020-06-20 15:28:46] __main__ INFO: \u001b[0mVal 65\n",
      "\u001b[32m[2020-06-20 15:28:47] __main__ INFO: \u001b[0mEpoch 65 loss 0.4210 acc@1 0.8812 acc@5 0.9952\n",
      "\u001b[32m[2020-06-20 15:28:47] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-20 15:28:47] __main__ INFO: \u001b[0mTrain 66 22815\n",
      "\u001b[32m[2020-06-20 15:28:56] __main__ INFO: \u001b[0mEpoch 66 Step 100/351 lr 0.001000 loss 0.0717 (0.1182) acc@1 0.9766 (0.9584) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:29:06] __main__ INFO: \u001b[0mEpoch 66 Step 200/351 lr 0.001000 loss 0.0866 (0.1173) acc@1 0.9844 (0.9589) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:29:15] __main__ INFO: \u001b[0mEpoch 66 Step 300/351 lr 0.001000 loss 0.2126 (0.1181) acc@1 0.9453 (0.9592) acc@5 0.9922 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:29:19] __main__ INFO: \u001b[0mEpoch 66 Step 351/351 lr 0.001000 loss 0.0795 (0.1179) acc@1 0.9609 (0.9592) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:29:19] __main__ INFO: \u001b[0mElapsed 32.39\n",
      "\u001b[32m[2020-06-20 15:29:19] __main__ INFO: \u001b[0mVal 66\n",
      "\u001b[32m[2020-06-20 15:29:21] __main__ INFO: \u001b[0mEpoch 66 loss 0.4206 acc@1 0.8816 acc@5 0.9950\n",
      "\u001b[32m[2020-06-20 15:29:21] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-06-20 15:29:21] __main__ INFO: \u001b[0mTrain 67 23166\n",
      "\u001b[32m[2020-06-20 15:29:30] __main__ INFO: \u001b[0mEpoch 67 Step 100/351 lr 0.001000 loss 0.1630 (0.1123) acc@1 0.9453 (0.9611) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-20 15:29:39] __main__ INFO: \u001b[0mEpoch 67 Step 200/351 lr 0.001000 loss 0.1663 (0.1133) acc@1 0.9219 (0.9598) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-20 15:29:48] __main__ INFO: \u001b[0mEpoch 67 Step 300/351 lr 0.001000 loss 0.1774 (0.1175) acc@1 0.9531 (0.9591) acc@5 0.9922 (0.9994)\n",
      "\u001b[32m[2020-06-20 15:29:53] __main__ INFO: \u001b[0mEpoch 67 Step 351/351 lr 0.001000 loss 0.1288 (0.1178) acc@1 0.9219 (0.9592) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-20 15:29:53] __main__ INFO: \u001b[0mElapsed 32.41\n",
      "\u001b[32m[2020-06-20 15:29:53] __main__ INFO: \u001b[0mVal 67\n",
      "\u001b[32m[2020-06-20 15:29:54] __main__ INFO: \u001b[0mEpoch 67 loss 0.4209 acc@1 0.8820 acc@5 0.9956\n",
      "\u001b[32m[2020-06-20 15:29:54] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-20 15:29:54] __main__ INFO: \u001b[0mTrain 68 23517\n",
      "\u001b[32m[2020-06-20 15:30:03] __main__ INFO: \u001b[0mEpoch 68 Step 100/351 lr 0.001000 loss 0.0818 (0.1158) acc@1 0.9766 (0.9600) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:30:13] __main__ INFO: \u001b[0mEpoch 68 Step 200/351 lr 0.001000 loss 0.0938 (0.1125) acc@1 0.9609 (0.9613) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:30:22] __main__ INFO: \u001b[0mEpoch 68 Step 300/351 lr 0.001000 loss 0.1498 (0.1106) acc@1 0.9375 (0.9619) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:30:26] __main__ INFO: \u001b[0mEpoch 68 Step 351/351 lr 0.001000 loss 0.0636 (0.1110) acc@1 0.9766 (0.9619) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:30:26] __main__ INFO: \u001b[0mElapsed 32.44\n",
      "\u001b[32m[2020-06-20 15:30:26] __main__ INFO: \u001b[0mVal 68\n",
      "\u001b[32m[2020-06-20 15:30:28] __main__ INFO: \u001b[0mEpoch 68 loss 0.4199 acc@1 0.8820 acc@5 0.9952\n",
      "\u001b[32m[2020-06-20 15:30:28] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-20 15:30:28] __main__ INFO: \u001b[0mTrain 69 23868\n",
      "\u001b[32m[2020-06-20 15:30:37] __main__ INFO: \u001b[0mEpoch 69 Step 100/351 lr 0.001000 loss 0.0717 (0.1139) acc@1 0.9844 (0.9601) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:30:46] __main__ INFO: \u001b[0mEpoch 69 Step 200/351 lr 0.001000 loss 0.1540 (0.1120) acc@1 0.9688 (0.9611) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:30:55] __main__ INFO: \u001b[0mEpoch 69 Step 300/351 lr 0.001000 loss 0.0628 (0.1142) acc@1 0.9766 (0.9602) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:31:00] __main__ INFO: \u001b[0mEpoch 69 Step 351/351 lr 0.001000 loss 0.1577 (0.1132) acc@1 0.9531 (0.9607) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:31:00] __main__ INFO: \u001b[0mElapsed 32.45\n",
      "\u001b[32m[2020-06-20 15:31:00] __main__ INFO: \u001b[0mVal 69\n",
      "\u001b[32m[2020-06-20 15:31:01] __main__ INFO: \u001b[0mEpoch 69 loss 0.4174 acc@1 0.8836 acc@5 0.9958\n",
      "\u001b[32m[2020-06-20 15:31:01] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-20 15:31:01] __main__ INFO: \u001b[0mTrain 70 24219\n",
      "\u001b[32m[2020-06-20 15:31:10] __main__ INFO: \u001b[0mEpoch 70 Step 100/351 lr 0.001000 loss 0.1429 (0.1100) acc@1 0.9531 (0.9621) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:31:20] __main__ INFO: \u001b[0mEpoch 70 Step 200/351 lr 0.001000 loss 0.1791 (0.1101) acc@1 0.9375 (0.9617) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:31:29] __main__ INFO: \u001b[0mEpoch 70 Step 300/351 lr 0.001000 loss 0.1068 (0.1123) acc@1 0.9688 (0.9611) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:31:33] __main__ INFO: \u001b[0mEpoch 70 Step 351/351 lr 0.001000 loss 0.1119 (0.1136) acc@1 0.9609 (0.9603) acc@5 0.9922 (0.9994)\n",
      "\u001b[32m[2020-06-20 15:31:34] __main__ INFO: \u001b[0mElapsed 32.45\n",
      "\u001b[32m[2020-06-20 15:31:34] __main__ INFO: \u001b[0mVal 70\n",
      "\u001b[32m[2020-06-20 15:31:35] __main__ INFO: \u001b[0mEpoch 70 loss 0.4201 acc@1 0.8838 acc@5 0.9952\n",
      "\u001b[32m[2020-06-20 15:31:35] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-20 15:31:35] __main__ INFO: \u001b[0mTrain 71 24570\n",
      "\u001b[32m[2020-06-20 15:31:44] __main__ INFO: \u001b[0mEpoch 71 Step 100/351 lr 0.001000 loss 0.1254 (0.1159) acc@1 0.9609 (0.9594) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-06-20 15:31:53] __main__ INFO: \u001b[0mEpoch 71 Step 200/351 lr 0.001000 loss 0.1758 (0.1148) acc@1 0.9453 (0.9599) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-20 15:32:02] __main__ INFO: \u001b[0mEpoch 71 Step 300/351 lr 0.001000 loss 0.2505 (0.1149) acc@1 0.9297 (0.9596) acc@5 0.9922 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:32:07] __main__ INFO: \u001b[0mEpoch 71 Step 351/351 lr 0.001000 loss 0.1572 (0.1141) acc@1 0.9453 (0.9603) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-20 15:32:07] __main__ INFO: \u001b[0mElapsed 32.45\n",
      "\u001b[32m[2020-06-20 15:32:07] __main__ INFO: \u001b[0mVal 71\n",
      "\u001b[32m[2020-06-20 15:32:08] __main__ INFO: \u001b[0mEpoch 71 loss 0.4209 acc@1 0.8820 acc@5 0.9956\n",
      "\u001b[32m[2020-06-20 15:32:08] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-20 15:32:08] __main__ INFO: \u001b[0mTrain 72 24921\n",
      "\u001b[32m[2020-06-20 15:32:17] __main__ INFO: \u001b[0mEpoch 72 Step 100/351 lr 0.001000 loss 0.1921 (0.1056) acc@1 0.9297 (0.9634) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:32:27] __main__ INFO: \u001b[0mEpoch 72 Step 200/351 lr 0.001000 loss 0.1143 (0.1087) acc@1 0.9609 (0.9613) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:32:36] __main__ INFO: \u001b[0mEpoch 72 Step 300/351 lr 0.001000 loss 0.1327 (0.1083) acc@1 0.9531 (0.9617) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:32:40] __main__ INFO: \u001b[0mEpoch 72 Step 351/351 lr 0.001000 loss 0.1569 (0.1093) acc@1 0.9688 (0.9611) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:32:40] __main__ INFO: \u001b[0mElapsed 32.39\n",
      "\u001b[32m[2020-06-20 15:32:40] __main__ INFO: \u001b[0mVal 72\n",
      "\u001b[32m[2020-06-20 15:32:42] __main__ INFO: \u001b[0mEpoch 72 loss 0.4215 acc@1 0.8828 acc@5 0.9954\n",
      "\u001b[32m[2020-06-20 15:32:42] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-20 15:32:42] __main__ INFO: \u001b[0mTrain 73 25272\n",
      "\u001b[32m[2020-06-20 15:32:51] __main__ INFO: \u001b[0mEpoch 73 Step 100/351 lr 0.001000 loss 0.1051 (0.1092) acc@1 0.9688 (0.9638) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:33:00] __main__ INFO: \u001b[0mEpoch 73 Step 200/351 lr 0.001000 loss 0.0539 (0.1082) acc@1 0.9766 (0.9634) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:33:09] __main__ INFO: \u001b[0mEpoch 73 Step 300/351 lr 0.001000 loss 0.0414 (0.1098) acc@1 0.9844 (0.9622) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-20 15:33:14] __main__ INFO: \u001b[0mEpoch 73 Step 351/351 lr 0.001000 loss 0.1280 (0.1096) acc@1 0.9453 (0.9620) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:33:14] __main__ INFO: \u001b[0mElapsed 32.38\n",
      "\u001b[32m[2020-06-20 15:33:14] __main__ INFO: \u001b[0mVal 73\n",
      "\u001b[32m[2020-06-20 15:33:15] __main__ INFO: \u001b[0mEpoch 73 loss 0.4222 acc@1 0.8814 acc@5 0.9958\n",
      "\u001b[32m[2020-06-20 15:33:15] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-20 15:33:15] __main__ INFO: \u001b[0mTrain 74 25623\n",
      "\u001b[32m[2020-06-20 15:33:24] __main__ INFO: \u001b[0mEpoch 74 Step 100/351 lr 0.001000 loss 0.0857 (0.1075) acc@1 0.9688 (0.9616) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:33:34] __main__ INFO: \u001b[0mEpoch 74 Step 200/351 lr 0.001000 loss 0.1753 (0.1090) acc@1 0.9141 (0.9619) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:33:43] __main__ INFO: \u001b[0mEpoch 74 Step 300/351 lr 0.001000 loss 0.0965 (0.1099) acc@1 0.9609 (0.9622) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:33:47] __main__ INFO: \u001b[0mEpoch 74 Step 351/351 lr 0.001000 loss 0.1745 (0.1097) acc@1 0.9297 (0.9624) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:33:47] __main__ INFO: \u001b[0mElapsed 32.44\n",
      "\u001b[32m[2020-06-20 15:33:47] __main__ INFO: \u001b[0mVal 74\n",
      "\u001b[32m[2020-06-20 15:33:49] __main__ INFO: \u001b[0mEpoch 74 loss 0.4277 acc@1 0.8812 acc@5 0.9950\n",
      "\u001b[32m[2020-06-20 15:33:49] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 15:33:49] __main__ INFO: \u001b[0mTrain 75 25974\n",
      "\u001b[32m[2020-06-20 15:33:58] __main__ INFO: \u001b[0mEpoch 75 Step 100/351 lr 0.001000 loss 0.1185 (0.1032) acc@1 0.9531 (0.9644) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 15:34:07] __main__ INFO: \u001b[0mEpoch 75 Step 200/351 lr 0.001000 loss 0.1088 (0.1027) acc@1 0.9844 (0.9645) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:34:16] __main__ INFO: \u001b[0mEpoch 75 Step 300/351 lr 0.001000 loss 0.1124 (0.1051) acc@1 0.9688 (0.9637) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:34:21] __main__ INFO: \u001b[0mEpoch 75 Step 351/351 lr 0.001000 loss 0.0684 (0.1053) acc@1 0.9766 (0.9637) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:34:21] __main__ INFO: \u001b[0mElapsed 32.40\n",
      "\u001b[32m[2020-06-20 15:34:21] __main__ INFO: \u001b[0mVal 75\n",
      "\u001b[32m[2020-06-20 15:34:22] __main__ INFO: \u001b[0mEpoch 75 loss 0.4280 acc@1 0.8826 acc@5 0.9952\n",
      "\u001b[32m[2020-06-20 15:34:22] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 15:34:22] __main__ INFO: \u001b[0mTrain 76 26325\n",
      "\u001b[32m[2020-06-20 15:34:31] __main__ INFO: \u001b[0mEpoch 76 Step 100/351 lr 0.001000 loss 0.1200 (0.1062) acc@1 0.9453 (0.9633) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 15:34:40] __main__ INFO: \u001b[0mEpoch 76 Step 200/351 lr 0.001000 loss 0.1515 (0.1057) acc@1 0.9453 (0.9632) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:34:50] __main__ INFO: \u001b[0mEpoch 76 Step 300/351 lr 0.001000 loss 0.1016 (0.1037) acc@1 0.9766 (0.9647) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:34:54] __main__ INFO: \u001b[0mEpoch 76 Step 351/351 lr 0.001000 loss 0.0596 (0.1053) acc@1 0.9844 (0.9640) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:34:54] __main__ INFO: \u001b[0mElapsed 32.40\n",
      "\u001b[32m[2020-06-20 15:34:54] __main__ INFO: \u001b[0mVal 76\n",
      "\u001b[32m[2020-06-20 15:34:55] __main__ INFO: \u001b[0mEpoch 76 loss 0.4282 acc@1 0.8826 acc@5 0.9954\n",
      "\u001b[32m[2020-06-20 15:34:55] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 15:34:55] __main__ INFO: \u001b[0mTrain 77 26676\n",
      "\u001b[32m[2020-06-20 15:35:05] __main__ INFO: \u001b[0mEpoch 77 Step 100/351 lr 0.001000 loss 0.1272 (0.1043) acc@1 0.9609 (0.9649) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-20 15:35:14] __main__ INFO: \u001b[0mEpoch 77 Step 200/351 lr 0.001000 loss 0.1637 (0.1056) acc@1 0.9375 (0.9644) acc@5 0.9922 (0.9993)\n",
      "\u001b[32m[2020-06-20 15:35:23] __main__ INFO: \u001b[0mEpoch 77 Step 300/351 lr 0.001000 loss 0.1791 (0.1063) acc@1 0.9453 (0.9635) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-20 15:35:28] __main__ INFO: \u001b[0mEpoch 77 Step 351/351 lr 0.001000 loss 0.1056 (0.1046) acc@1 0.9844 (0.9640) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:35:28] __main__ INFO: \u001b[0mElapsed 32.38\n",
      "\u001b[32m[2020-06-20 15:35:28] __main__ INFO: \u001b[0mVal 77\n",
      "\u001b[32m[2020-06-20 15:35:29] __main__ INFO: \u001b[0mEpoch 77 loss 0.4256 acc@1 0.8826 acc@5 0.9950\n",
      "\u001b[32m[2020-06-20 15:35:29] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-20 15:35:29] __main__ INFO: \u001b[0mTrain 78 27027\n",
      "\u001b[32m[2020-06-20 15:35:38] __main__ INFO: \u001b[0mEpoch 78 Step 100/351 lr 0.001000 loss 0.0500 (0.1057) acc@1 0.9844 (0.9652) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:35:47] __main__ INFO: \u001b[0mEpoch 78 Step 200/351 lr 0.001000 loss 0.1151 (0.1063) acc@1 0.9766 (0.9640) acc@5 0.9922 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:35:57] __main__ INFO: \u001b[0mEpoch 78 Step 300/351 lr 0.001000 loss 0.0746 (0.1068) acc@1 0.9844 (0.9638) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:36:01] __main__ INFO: \u001b[0mEpoch 78 Step 351/351 lr 0.001000 loss 0.1110 (0.1071) acc@1 0.9688 (0.9638) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:36:01] __main__ INFO: \u001b[0mElapsed 32.38\n",
      "\u001b[32m[2020-06-20 15:36:01] __main__ INFO: \u001b[0mVal 78\n",
      "\u001b[32m[2020-06-20 15:36:02] __main__ INFO: \u001b[0mEpoch 78 loss 0.4234 acc@1 0.8818 acc@5 0.9946\n",
      "\u001b[32m[2020-06-20 15:36:02] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-20 15:36:02] __main__ INFO: \u001b[0mTrain 79 27378\n",
      "\u001b[32m[2020-06-20 15:36:12] __main__ INFO: \u001b[0mEpoch 79 Step 100/351 lr 0.001000 loss 0.0976 (0.1028) acc@1 0.9688 (0.9647) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:36:21] __main__ INFO: \u001b[0mEpoch 79 Step 200/351 lr 0.001000 loss 0.1784 (0.1005) acc@1 0.9297 (0.9654) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 15:36:30] __main__ INFO: \u001b[0mEpoch 79 Step 300/351 lr 0.001000 loss 0.1123 (0.1029) acc@1 0.9609 (0.9645) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:36:35] __main__ INFO: \u001b[0mEpoch 79 Step 351/351 lr 0.001000 loss 0.1096 (0.1039) acc@1 0.9688 (0.9641) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:36:35] __main__ INFO: \u001b[0mElapsed 32.44\n",
      "\u001b[32m[2020-06-20 15:36:35] __main__ INFO: \u001b[0mVal 79\n",
      "\u001b[32m[2020-06-20 15:36:36] __main__ INFO: \u001b[0mEpoch 79 loss 0.4281 acc@1 0.8818 acc@5 0.9952\n",
      "\u001b[32m[2020-06-20 15:36:36] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-20 15:36:36] __main__ INFO: \u001b[0mTrain 80 27729\n",
      "\u001b[32m[2020-06-20 15:36:45] __main__ INFO: \u001b[0mEpoch 80 Step 100/351 lr 0.001000 loss 0.1433 (0.1003) acc@1 0.9531 (0.9659) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 15:36:54] __main__ INFO: \u001b[0mEpoch 80 Step 200/351 lr 0.001000 loss 0.1129 (0.1009) acc@1 0.9766 (0.9655) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 15:37:04] __main__ INFO: \u001b[0mEpoch 80 Step 300/351 lr 0.001000 loss 0.1189 (0.1011) acc@1 0.9609 (0.9654) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:37:08] __main__ INFO: \u001b[0mEpoch 80 Step 351/351 lr 0.001000 loss 0.1426 (0.1026) acc@1 0.9531 (0.9650) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:37:08] __main__ INFO: \u001b[0mElapsed 32.46\n",
      "\u001b[32m[2020-06-20 15:37:08] __main__ INFO: \u001b[0mVal 80\n",
      "\u001b[32m[2020-06-20 15:37:09] __main__ INFO: \u001b[0mEpoch 80 loss 0.4274 acc@1 0.8822 acc@5 0.9950\n",
      "\u001b[32m[2020-06-20 15:37:09] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 15:37:09] __main__ INFO: \u001b[0mTrain 81 28080\n",
      "\u001b[32m[2020-06-20 15:37:19] __main__ INFO: \u001b[0mEpoch 81 Step 100/351 lr 0.000100 loss 0.0866 (0.1056) acc@1 0.9844 (0.9631) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:37:28] __main__ INFO: \u001b[0mEpoch 81 Step 200/351 lr 0.000100 loss 0.1316 (0.1065) acc@1 0.9375 (0.9631) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 15:37:37] __main__ INFO: \u001b[0mEpoch 81 Step 300/351 lr 0.000100 loss 0.1170 (0.1048) acc@1 0.9453 (0.9636) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 15:37:42] __main__ INFO: \u001b[0mEpoch 81 Step 351/351 lr 0.000100 loss 0.1197 (0.1044) acc@1 0.9531 (0.9638) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 15:37:42] __main__ INFO: \u001b[0mElapsed 32.38\n",
      "\u001b[32m[2020-06-20 15:37:42] __main__ INFO: \u001b[0mVal 81\n",
      "\u001b[32m[2020-06-20 15:37:43] __main__ INFO: \u001b[0mEpoch 81 loss 0.4228 acc@1 0.8824 acc@5 0.9956\n",
      "\u001b[32m[2020-06-20 15:37:43] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-20 15:37:43] __main__ INFO: \u001b[0mTrain 82 28431\n",
      "\u001b[32m[2020-06-20 15:37:52] __main__ INFO: \u001b[0mEpoch 82 Step 100/351 lr 0.000100 loss 0.1295 (0.0969) acc@1 0.9453 (0.9668) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-06-20 15:38:01] __main__ INFO: \u001b[0mEpoch 82 Step 200/351 lr 0.000100 loss 0.0662 (0.0979) acc@1 0.9844 (0.9657) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 15:38:11] __main__ INFO: \u001b[0mEpoch 82 Step 300/351 lr 0.000100 loss 0.1544 (0.0989) acc@1 0.9531 (0.9654) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 15:38:15] __main__ INFO: \u001b[0mEpoch 82 Step 351/351 lr 0.000100 loss 0.0612 (0.0983) acc@1 0.9688 (0.9658) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 15:38:15] __main__ INFO: \u001b[0mElapsed 32.42\n",
      "\u001b[32m[2020-06-20 15:38:15] __main__ INFO: \u001b[0mVal 82\n",
      "\u001b[32m[2020-06-20 15:38:16] __main__ INFO: \u001b[0mEpoch 82 loss 0.4231 acc@1 0.8842 acc@5 0.9948\n",
      "\u001b[32m[2020-06-20 15:38:16] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 15:38:16] __main__ INFO: \u001b[0mTrain 83 28782\n",
      "\u001b[32m[2020-06-20 15:38:26] __main__ INFO: \u001b[0mEpoch 83 Step 100/351 lr 0.000100 loss 0.1272 (0.1032) acc@1 0.9375 (0.9639) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:38:35] __main__ INFO: \u001b[0mEpoch 83 Step 200/351 lr 0.000100 loss 0.0602 (0.1008) acc@1 0.9844 (0.9657) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-20 15:38:44] __main__ INFO: \u001b[0mEpoch 83 Step 300/351 lr 0.000100 loss 0.1270 (0.1008) acc@1 0.9531 (0.9656) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:38:49] __main__ INFO: \u001b[0mEpoch 83 Step 351/351 lr 0.000100 loss 0.1116 (0.1007) acc@1 0.9453 (0.9656) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:38:49] __main__ INFO: \u001b[0mElapsed 32.39\n",
      "\u001b[32m[2020-06-20 15:38:49] __main__ INFO: \u001b[0mVal 83\n",
      "\u001b[32m[2020-06-20 15:38:50] __main__ INFO: \u001b[0mEpoch 83 loss 0.4250 acc@1 0.8806 acc@5 0.9954\n",
      "\u001b[32m[2020-06-20 15:38:50] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 15:38:50] __main__ INFO: \u001b[0mTrain 84 29133\n",
      "\u001b[32m[2020-06-20 15:38:59] __main__ INFO: \u001b[0mEpoch 84 Step 100/351 lr 0.000100 loss 0.0673 (0.0974) acc@1 0.9766 (0.9671) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 15:39:08] __main__ INFO: \u001b[0mEpoch 84 Step 200/351 lr 0.000100 loss 0.1319 (0.0974) acc@1 0.9453 (0.9671) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:39:18] __main__ INFO: \u001b[0mEpoch 84 Step 300/351 lr 0.000100 loss 0.1072 (0.0997) acc@1 0.9688 (0.9663) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:39:22] __main__ INFO: \u001b[0mEpoch 84 Step 351/351 lr 0.000100 loss 0.1329 (0.1006) acc@1 0.9531 (0.9662) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:39:22] __main__ INFO: \u001b[0mElapsed 32.39\n",
      "\u001b[32m[2020-06-20 15:39:22] __main__ INFO: \u001b[0mVal 84\n",
      "\u001b[32m[2020-06-20 15:39:23] __main__ INFO: \u001b[0mEpoch 84 loss 0.4248 acc@1 0.8828 acc@5 0.9952\n",
      "\u001b[32m[2020-06-20 15:39:23] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-20 15:39:23] __main__ INFO: \u001b[0mTrain 85 29484\n",
      "\u001b[32m[2020-06-20 15:39:33] __main__ INFO: \u001b[0mEpoch 85 Step 100/351 lr 0.000100 loss 0.0752 (0.1009) acc@1 0.9844 (0.9666) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 15:39:42] __main__ INFO: \u001b[0mEpoch 85 Step 200/351 lr 0.000100 loss 0.1597 (0.0985) acc@1 0.9609 (0.9669) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:39:51] __main__ INFO: \u001b[0mEpoch 85 Step 300/351 lr 0.000100 loss 0.0874 (0.0995) acc@1 0.9766 (0.9666) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 15:39:56] __main__ INFO: \u001b[0mEpoch 85 Step 351/351 lr 0.000100 loss 0.1085 (0.1000) acc@1 0.9688 (0.9666) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 15:39:56] __main__ INFO: \u001b[0mElapsed 32.42\n",
      "\u001b[32m[2020-06-20 15:39:56] __main__ INFO: \u001b[0mVal 85\n",
      "\u001b[32m[2020-06-20 15:39:57] __main__ INFO: \u001b[0mEpoch 85 loss 0.4244 acc@1 0.8832 acc@5 0.9944\n",
      "\u001b[32m[2020-06-20 15:39:57] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 15:39:57] __main__ INFO: \u001b[0mTrain 86 29835\n",
      "\u001b[32m[2020-06-20 15:40:06] __main__ INFO: \u001b[0mEpoch 86 Step 100/351 lr 0.000100 loss 0.1044 (0.0992) acc@1 0.9531 (0.9658) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:40:15] __main__ INFO: \u001b[0mEpoch 86 Step 200/351 lr 0.000100 loss 0.0970 (0.0998) acc@1 0.9609 (0.9652) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:40:25] __main__ INFO: \u001b[0mEpoch 86 Step 300/351 lr 0.000100 loss 0.1441 (0.0995) acc@1 0.9531 (0.9655) acc@5 0.9922 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:40:29] __main__ INFO: \u001b[0mEpoch 86 Step 351/351 lr 0.000100 loss 0.1341 (0.1002) acc@1 0.9609 (0.9651) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:40:29] __main__ INFO: \u001b[0mElapsed 32.41\n",
      "\u001b[32m[2020-06-20 15:40:29] __main__ INFO: \u001b[0mVal 86\n",
      "\u001b[32m[2020-06-20 15:40:30] __main__ INFO: \u001b[0mEpoch 86 loss 0.4241 acc@1 0.8826 acc@5 0.9952\n",
      "\u001b[32m[2020-06-20 15:40:30] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 15:40:30] __main__ INFO: \u001b[0mTrain 87 30186\n",
      "\u001b[32m[2020-06-20 15:40:40] __main__ INFO: \u001b[0mEpoch 87 Step 100/351 lr 0.000100 loss 0.0791 (0.0984) acc@1 0.9844 (0.9654) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:40:49] __main__ INFO: \u001b[0mEpoch 87 Step 200/351 lr 0.000100 loss 0.0722 (0.1034) acc@1 0.9844 (0.9639) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:40:58] __main__ INFO: \u001b[0mEpoch 87 Step 300/351 lr 0.000100 loss 0.0830 (0.1023) acc@1 0.9688 (0.9644) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:41:03] __main__ INFO: \u001b[0mEpoch 87 Step 351/351 lr 0.000100 loss 0.0929 (0.1025) acc@1 0.9531 (0.9645) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:41:03] __main__ INFO: \u001b[0mElapsed 32.48\n",
      "\u001b[32m[2020-06-20 15:41:03] __main__ INFO: \u001b[0mVal 87\n",
      "\u001b[32m[2020-06-20 15:41:04] __main__ INFO: \u001b[0mEpoch 87 loss 0.4268 acc@1 0.8830 acc@5 0.9950\n",
      "\u001b[32m[2020-06-20 15:41:04] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 15:41:04] __main__ INFO: \u001b[0mTrain 88 30537\n",
      "\u001b[32m[2020-06-20 15:41:13] __main__ INFO: \u001b[0mEpoch 88 Step 100/351 lr 0.000100 loss 0.1073 (0.0990) acc@1 0.9609 (0.9670) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:41:22] __main__ INFO: \u001b[0mEpoch 88 Step 200/351 lr 0.000100 loss 0.0889 (0.1005) acc@1 0.9766 (0.9650) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:41:32] __main__ INFO: \u001b[0mEpoch 88 Step 300/351 lr 0.000100 loss 0.0742 (0.0997) acc@1 0.9688 (0.9656) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:41:36] __main__ INFO: \u001b[0mEpoch 88 Step 351/351 lr 0.000100 loss 0.0791 (0.0989) acc@1 0.9766 (0.9657) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:41:36] __main__ INFO: \u001b[0mElapsed 32.45\n",
      "\u001b[32m[2020-06-20 15:41:36] __main__ INFO: \u001b[0mVal 88\n",
      "\u001b[32m[2020-06-20 15:41:37] __main__ INFO: \u001b[0mEpoch 88 loss 0.4252 acc@1 0.8834 acc@5 0.9948\n",
      "\u001b[32m[2020-06-20 15:41:37] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-20 15:41:37] __main__ INFO: \u001b[0mTrain 89 30888\n",
      "\u001b[32m[2020-06-20 15:41:47] __main__ INFO: \u001b[0mEpoch 89 Step 100/351 lr 0.000100 loss 0.0594 (0.1006) acc@1 0.9844 (0.9645) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:41:56] __main__ INFO: \u001b[0mEpoch 89 Step 200/351 lr 0.000100 loss 0.0946 (0.0986) acc@1 0.9609 (0.9660) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:42:05] __main__ INFO: \u001b[0mEpoch 89 Step 300/351 lr 0.000100 loss 0.0818 (0.0984) acc@1 0.9844 (0.9664) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:42:10] __main__ INFO: \u001b[0mEpoch 89 Step 351/351 lr 0.000100 loss 0.1370 (0.0987) acc@1 0.9453 (0.9666) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:42:10] __main__ INFO: \u001b[0mElapsed 32.41\n",
      "\u001b[32m[2020-06-20 15:42:10] __main__ INFO: \u001b[0mVal 89\n",
      "\u001b[32m[2020-06-20 15:42:11] __main__ INFO: \u001b[0mEpoch 89 loss 0.4269 acc@1 0.8830 acc@5 0.9948\n",
      "\u001b[32m[2020-06-20 15:42:11] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-20 15:42:11] __main__ INFO: \u001b[0mTrain 90 31239\n",
      "\u001b[32m[2020-06-20 15:42:20] __main__ INFO: \u001b[0mEpoch 90 Step 100/351 lr 0.000100 loss 0.0731 (0.0939) acc@1 0.9688 (0.9667) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 15:42:29] __main__ INFO: \u001b[0mEpoch 90 Step 200/351 lr 0.000100 loss 0.1145 (0.0954) acc@1 0.9531 (0.9676) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 15:42:39] __main__ INFO: \u001b[0mEpoch 90 Step 300/351 lr 0.000100 loss 0.1291 (0.0958) acc@1 0.9219 (0.9673) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 15:42:43] __main__ INFO: \u001b[0mEpoch 90 Step 351/351 lr 0.000100 loss 0.0688 (0.0973) acc@1 0.9609 (0.9668) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:42:43] __main__ INFO: \u001b[0mElapsed 32.40\n",
      "\u001b[32m[2020-06-20 15:42:43] __main__ INFO: \u001b[0mVal 90\n",
      "\u001b[32m[2020-06-20 15:42:44] __main__ INFO: \u001b[0mEpoch 90 loss 0.4259 acc@1 0.8834 acc@5 0.9942\n",
      "\u001b[32m[2020-06-20 15:42:44] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-20 15:42:44] __main__ INFO: \u001b[0mTrain 91 31590\n",
      "\u001b[32m[2020-06-20 15:42:54] __main__ INFO: \u001b[0mEpoch 91 Step 100/351 lr 0.000100 loss 0.0721 (0.0956) acc@1 0.9688 (0.9677) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:43:03] __main__ INFO: \u001b[0mEpoch 91 Step 200/351 lr 0.000100 loss 0.0519 (0.0980) acc@1 0.9844 (0.9664) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:43:12] __main__ INFO: \u001b[0mEpoch 91 Step 300/351 lr 0.000100 loss 0.0300 (0.0988) acc@1 0.9922 (0.9666) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:43:17] __main__ INFO: \u001b[0mEpoch 91 Step 351/351 lr 0.000100 loss 0.1310 (0.0992) acc@1 0.9453 (0.9666) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:43:17] __main__ INFO: \u001b[0mElapsed 32.44\n",
      "\u001b[32m[2020-06-20 15:43:17] __main__ INFO: \u001b[0mVal 91\n",
      "\u001b[32m[2020-06-20 15:43:18] __main__ INFO: \u001b[0mEpoch 91 loss 0.4270 acc@1 0.8826 acc@5 0.9954\n",
      "\u001b[32m[2020-06-20 15:43:18] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 15:43:18] __main__ INFO: \u001b[0mTrain 92 31941\n",
      "\u001b[32m[2020-06-20 15:43:27] __main__ INFO: \u001b[0mEpoch 92 Step 100/351 lr 0.000100 loss 0.0790 (0.0966) acc@1 0.9688 (0.9673) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:43:36] __main__ INFO: \u001b[0mEpoch 92 Step 200/351 lr 0.000100 loss 0.0808 (0.1019) acc@1 0.9844 (0.9653) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:43:46] __main__ INFO: \u001b[0mEpoch 92 Step 300/351 lr 0.000100 loss 0.1437 (0.0981) acc@1 0.9453 (0.9669) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:43:50] __main__ INFO: \u001b[0mEpoch 92 Step 351/351 lr 0.000100 loss 0.0526 (0.0979) acc@1 0.9766 (0.9671) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:43:50] __main__ INFO: \u001b[0mElapsed 32.44\n",
      "\u001b[32m[2020-06-20 15:43:50] __main__ INFO: \u001b[0mVal 92\n",
      "\u001b[32m[2020-06-20 15:43:51] __main__ INFO: \u001b[0mEpoch 92 loss 0.4226 acc@1 0.8844 acc@5 0.9946\n",
      "\u001b[32m[2020-06-20 15:43:51] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-20 15:43:51] __main__ INFO: \u001b[0mTrain 93 32292\n",
      "\u001b[32m[2020-06-20 15:44:01] __main__ INFO: \u001b[0mEpoch 93 Step 100/351 lr 0.000100 loss 0.1083 (0.1018) acc@1 0.9531 (0.9650) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:44:10] __main__ INFO: \u001b[0mEpoch 93 Step 200/351 lr 0.000100 loss 0.0331 (0.0998) acc@1 0.9922 (0.9661) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:44:19] __main__ INFO: \u001b[0mEpoch 93 Step 300/351 lr 0.000100 loss 0.1095 (0.0967) acc@1 0.9531 (0.9671) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:44:24] __main__ INFO: \u001b[0mEpoch 93 Step 351/351 lr 0.000100 loss 0.0909 (0.0976) acc@1 0.9688 (0.9666) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:44:24] __main__ INFO: \u001b[0mElapsed 32.40\n",
      "\u001b[32m[2020-06-20 15:44:24] __main__ INFO: \u001b[0mVal 93\n",
      "\u001b[32m[2020-06-20 15:44:25] __main__ INFO: \u001b[0mEpoch 93 loss 0.4278 acc@1 0.8818 acc@5 0.9956\n",
      "\u001b[32m[2020-06-20 15:44:25] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 15:44:25] __main__ INFO: \u001b[0mTrain 94 32643\n",
      "\u001b[32m[2020-06-20 15:44:34] __main__ INFO: \u001b[0mEpoch 94 Step 100/351 lr 0.000100 loss 0.1738 (0.1014) acc@1 0.9375 (0.9669) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 15:44:43] __main__ INFO: \u001b[0mEpoch 94 Step 200/351 lr 0.000100 loss 0.0558 (0.1001) acc@1 0.9922 (0.9664) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 15:44:52] __main__ INFO: \u001b[0mEpoch 94 Step 300/351 lr 0.000100 loss 0.0757 (0.0991) acc@1 0.9609 (0.9666) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 15:44:57] __main__ INFO: \u001b[0mEpoch 94 Step 351/351 lr 0.000100 loss 0.0657 (0.0993) acc@1 0.9844 (0.9669) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 15:44:57] __main__ INFO: \u001b[0mElapsed 32.40\n",
      "\u001b[32m[2020-06-20 15:44:57] __main__ INFO: \u001b[0mVal 94\n",
      "\u001b[32m[2020-06-20 15:44:58] __main__ INFO: \u001b[0mEpoch 94 loss 0.4234 acc@1 0.8844 acc@5 0.9952\n",
      "\u001b[32m[2020-06-20 15:44:58] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-20 15:44:58] __main__ INFO: \u001b[0mTrain 95 32994\n",
      "\u001b[32m[2020-06-20 15:45:08] __main__ INFO: \u001b[0mEpoch 95 Step 100/351 lr 0.000100 loss 0.0849 (0.0999) acc@1 0.9766 (0.9656) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 15:45:17] __main__ INFO: \u001b[0mEpoch 95 Step 200/351 lr 0.000100 loss 0.0971 (0.0980) acc@1 0.9609 (0.9666) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 15:45:26] __main__ INFO: \u001b[0mEpoch 95 Step 300/351 lr 0.000100 loss 0.0906 (0.0981) acc@1 0.9844 (0.9668) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 15:45:31] __main__ INFO: \u001b[0mEpoch 95 Step 351/351 lr 0.000100 loss 0.1149 (0.0982) acc@1 0.9453 (0.9672) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:45:31] __main__ INFO: \u001b[0mElapsed 32.41\n",
      "\u001b[32m[2020-06-20 15:45:31] __main__ INFO: \u001b[0mVal 95\n",
      "\u001b[32m[2020-06-20 15:45:32] __main__ INFO: \u001b[0mEpoch 95 loss 0.4235 acc@1 0.8834 acc@5 0.9952\n",
      "\u001b[32m[2020-06-20 15:45:32] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-20 15:45:32] __main__ INFO: \u001b[0mTrain 96 33345\n",
      "\u001b[32m[2020-06-20 15:45:41] __main__ INFO: \u001b[0mEpoch 96 Step 100/351 lr 0.000100 loss 0.0758 (0.0986) acc@1 0.9688 (0.9668) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 15:45:50] __main__ INFO: \u001b[0mEpoch 96 Step 200/351 lr 0.000100 loss 0.1246 (0.0969) acc@1 0.9688 (0.9669) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:45:59] __main__ INFO: \u001b[0mEpoch 96 Step 300/351 lr 0.000100 loss 0.0713 (0.0967) acc@1 0.9688 (0.9668) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:46:04] __main__ INFO: \u001b[0mEpoch 96 Step 351/351 lr 0.000100 loss 0.1616 (0.0972) acc@1 0.9453 (0.9667) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:46:04] __main__ INFO: \u001b[0mElapsed 32.45\n",
      "\u001b[32m[2020-06-20 15:46:04] __main__ INFO: \u001b[0mVal 96\n",
      "\u001b[32m[2020-06-20 15:46:05] __main__ INFO: \u001b[0mEpoch 96 loss 0.4264 acc@1 0.8834 acc@5 0.9944\n",
      "\u001b[32m[2020-06-20 15:46:05] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-20 15:46:05] __main__ INFO: \u001b[0mTrain 97 33696\n",
      "\u001b[32m[2020-06-20 15:46:15] __main__ INFO: \u001b[0mEpoch 97 Step 100/351 lr 0.000100 loss 0.0964 (0.1000) acc@1 0.9688 (0.9656) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 15:46:24] __main__ INFO: \u001b[0mEpoch 97 Step 200/351 lr 0.000100 loss 0.0702 (0.0998) acc@1 0.9609 (0.9652) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 15:46:33] __main__ INFO: \u001b[0mEpoch 97 Step 300/351 lr 0.000100 loss 0.1195 (0.0993) acc@1 0.9531 (0.9659) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:46:38] __main__ INFO: \u001b[0mEpoch 97 Step 351/351 lr 0.000100 loss 0.0559 (0.0988) acc@1 0.9922 (0.9662) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:46:38] __main__ INFO: \u001b[0mElapsed 32.38\n",
      "\u001b[32m[2020-06-20 15:46:38] __main__ INFO: \u001b[0mVal 97\n",
      "\u001b[32m[2020-06-20 15:46:39] __main__ INFO: \u001b[0mEpoch 97 loss 0.4255 acc@1 0.8830 acc@5 0.9942\n",
      "\u001b[32m[2020-06-20 15:46:39] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-06-20 15:46:39] __main__ INFO: \u001b[0mTrain 98 34047\n",
      "\u001b[32m[2020-06-20 15:46:48] __main__ INFO: \u001b[0mEpoch 98 Step 100/351 lr 0.000100 loss 0.0967 (0.1004) acc@1 0.9688 (0.9655) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 15:46:57] __main__ INFO: \u001b[0mEpoch 98 Step 200/351 lr 0.000100 loss 0.0641 (0.0994) acc@1 0.9766 (0.9660) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 15:47:06] __main__ INFO: \u001b[0mEpoch 98 Step 300/351 lr 0.000100 loss 0.1146 (0.1001) acc@1 0.9531 (0.9662) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:47:11] __main__ INFO: \u001b[0mEpoch 98 Step 351/351 lr 0.000100 loss 0.0531 (0.0995) acc@1 0.9922 (0.9666) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:47:11] __main__ INFO: \u001b[0mElapsed 32.42\n",
      "\u001b[32m[2020-06-20 15:47:11] __main__ INFO: \u001b[0mVal 98\n",
      "\u001b[32m[2020-06-20 15:47:12] __main__ INFO: \u001b[0mEpoch 98 loss 0.4267 acc@1 0.8834 acc@5 0.9950\n",
      "\u001b[32m[2020-06-20 15:47:12] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-20 15:47:12] __main__ INFO: \u001b[0mTrain 99 34398\n",
      "\u001b[32m[2020-06-20 15:47:22] __main__ INFO: \u001b[0mEpoch 99 Step 100/351 lr 0.000100 loss 0.0597 (0.0926) acc@1 0.9844 (0.9683) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:47:31] __main__ INFO: \u001b[0mEpoch 99 Step 200/351 lr 0.000100 loss 0.0846 (0.0966) acc@1 0.9531 (0.9661) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:47:40] __main__ INFO: \u001b[0mEpoch 99 Step 300/351 lr 0.000100 loss 0.1423 (0.0959) acc@1 0.9297 (0.9665) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 15:47:45] __main__ INFO: \u001b[0mEpoch 99 Step 351/351 lr 0.000100 loss 0.1062 (0.0961) acc@1 0.9609 (0.9665) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 15:47:45] __main__ INFO: \u001b[0mElapsed 32.47\n",
      "\u001b[32m[2020-06-20 15:47:45] __main__ INFO: \u001b[0mVal 99\n",
      "\u001b[32m[2020-06-20 15:47:46] __main__ INFO: \u001b[0mEpoch 99 loss 0.4284 acc@1 0.8822 acc@5 0.9952\n",
      "\u001b[32m[2020-06-20 15:47:46] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-06-20 15:47:46] __main__ INFO: \u001b[0mTrain 100 34749\n",
      "\u001b[32m[2020-06-20 15:47:55] __main__ INFO: \u001b[0mEpoch 100 Step 100/351 lr 0.000100 loss 0.1571 (0.1014) acc@1 0.9531 (0.9661) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-06-20 15:48:04] __main__ INFO: \u001b[0mEpoch 100 Step 200/351 lr 0.000100 loss 0.0833 (0.0990) acc@1 0.9766 (0.9668) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:48:14] __main__ INFO: \u001b[0mEpoch 100 Step 300/351 lr 0.000100 loss 0.0429 (0.0989) acc@1 0.9766 (0.9666) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:48:18] __main__ INFO: \u001b[0mEpoch 100 Step 351/351 lr 0.000100 loss 0.0684 (0.0980) acc@1 0.9766 (0.9666) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:48:18] __main__ INFO: \u001b[0mElapsed 32.43\n",
      "\u001b[32m[2020-06-20 15:48:18] __main__ INFO: \u001b[0mVal 100\n",
      "\u001b[32m[2020-06-20 15:48:19] __main__ INFO: \u001b[0mEpoch 100 loss 0.4296 acc@1 0.8826 acc@5 0.9948\n",
      "\u001b[32m[2020-06-20 15:48:19] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 15:48:19] fvcore.common.checkpoint INFO: \u001b[0mSaving checkpoint to /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_5/exp00_resume300_150/checkpoint_00100.pth\n",
      "\u001b[32m[2020-06-20 15:48:19] __main__ INFO: \u001b[0mTrain 101 35100\n",
      "\u001b[32m[2020-06-20 15:48:29] __main__ INFO: \u001b[0mEpoch 101 Step 100/351 lr 0.000100 loss 0.1214 (0.0996) acc@1 0.9609 (0.9662) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 15:48:38] __main__ INFO: \u001b[0mEpoch 101 Step 200/351 lr 0.000100 loss 0.0795 (0.0956) acc@1 0.9766 (0.9681) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:48:47] __main__ INFO: \u001b[0mEpoch 101 Step 300/351 lr 0.000100 loss 0.0841 (0.0973) acc@1 0.9688 (0.9662) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:48:52] __main__ INFO: \u001b[0mEpoch 101 Step 351/351 lr 0.000100 loss 0.1557 (0.0984) acc@1 0.9219 (0.9654) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:48:52] __main__ INFO: \u001b[0mElapsed 32.42\n",
      "\u001b[32m[2020-06-20 15:48:52] __main__ INFO: \u001b[0mVal 101\n",
      "\u001b[32m[2020-06-20 15:48:53] __main__ INFO: \u001b[0mEpoch 101 loss 0.4253 acc@1 0.8828 acc@5 0.9940\n",
      "\u001b[32m[2020-06-20 15:48:53] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-20 15:48:53] __main__ INFO: \u001b[0mTrain 102 35451\n",
      "\u001b[32m[2020-06-20 15:49:02] __main__ INFO: \u001b[0mEpoch 102 Step 100/351 lr 0.000100 loss 0.0672 (0.0957) acc@1 0.9844 (0.9670) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 15:49:11] __main__ INFO: \u001b[0mEpoch 102 Step 200/351 lr 0.000100 loss 0.1714 (0.0981) acc@1 0.9375 (0.9668) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 15:49:21] __main__ INFO: \u001b[0mEpoch 102 Step 300/351 lr 0.000100 loss 0.0996 (0.0983) acc@1 0.9688 (0.9664) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 15:49:25] __main__ INFO: \u001b[0mEpoch 102 Step 351/351 lr 0.000100 loss 0.0980 (0.0982) acc@1 0.9766 (0.9665) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 15:49:25] __main__ INFO: \u001b[0mElapsed 32.42\n",
      "\u001b[32m[2020-06-20 15:49:25] __main__ INFO: \u001b[0mVal 102\n",
      "\u001b[32m[2020-06-20 15:49:26] __main__ INFO: \u001b[0mEpoch 102 loss 0.4298 acc@1 0.8822 acc@5 0.9950\n",
      "\u001b[32m[2020-06-20 15:49:26] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 15:49:26] __main__ INFO: \u001b[0mTrain 103 35802\n",
      "\u001b[32m[2020-06-20 15:49:36] __main__ INFO: \u001b[0mEpoch 103 Step 100/351 lr 0.000100 loss 0.1355 (0.0959) acc@1 0.9375 (0.9675) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-06-20 15:49:45] __main__ INFO: \u001b[0mEpoch 103 Step 200/351 lr 0.000100 loss 0.0464 (0.0974) acc@1 0.9844 (0.9676) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:49:54] __main__ INFO: \u001b[0mEpoch 103 Step 300/351 lr 0.000100 loss 0.0742 (0.0976) acc@1 0.9766 (0.9675) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:49:59] __main__ INFO: \u001b[0mEpoch 103 Step 351/351 lr 0.000100 loss 0.1306 (0.0968) acc@1 0.9688 (0.9674) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:49:59] __main__ INFO: \u001b[0mElapsed 32.37\n",
      "\u001b[32m[2020-06-20 15:49:59] __main__ INFO: \u001b[0mVal 103\n",
      "\u001b[32m[2020-06-20 15:50:00] __main__ INFO: \u001b[0mEpoch 103 loss 0.4283 acc@1 0.8826 acc@5 0.9954\n",
      "\u001b[32m[2020-06-20 15:50:00] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-20 15:50:00] __main__ INFO: \u001b[0mTrain 104 36153\n",
      "\u001b[32m[2020-06-20 15:50:09] __main__ INFO: \u001b[0mEpoch 104 Step 100/351 lr 0.000100 loss 0.0692 (0.0994) acc@1 0.9766 (0.9653) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 15:50:18] __main__ INFO: \u001b[0mEpoch 104 Step 200/351 lr 0.000100 loss 0.0882 (0.0972) acc@1 0.9609 (0.9667) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 15:50:28] __main__ INFO: \u001b[0mEpoch 104 Step 300/351 lr 0.000100 loss 0.0561 (0.0953) acc@1 0.9844 (0.9673) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 15:50:32] __main__ INFO: \u001b[0mEpoch 104 Step 351/351 lr 0.000100 loss 0.1487 (0.0950) acc@1 0.9453 (0.9675) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 15:50:32] __main__ INFO: \u001b[0mElapsed 32.46\n",
      "\u001b[32m[2020-06-20 15:50:32] __main__ INFO: \u001b[0mVal 104\n",
      "\u001b[32m[2020-06-20 15:50:33] __main__ INFO: \u001b[0mEpoch 104 loss 0.4287 acc@1 0.8842 acc@5 0.9948\n",
      "\u001b[32m[2020-06-20 15:50:33] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-20 15:50:33] __main__ INFO: \u001b[0mTrain 105 36504\n",
      "\u001b[32m[2020-06-20 15:50:43] __main__ INFO: \u001b[0mEpoch 105 Step 100/351 lr 0.000100 loss 0.1071 (0.0960) acc@1 0.9609 (0.9672) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 15:50:52] __main__ INFO: \u001b[0mEpoch 105 Step 200/351 lr 0.000100 loss 0.0813 (0.0942) acc@1 0.9688 (0.9668) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 15:51:01] __main__ INFO: \u001b[0mEpoch 105 Step 300/351 lr 0.000100 loss 0.1336 (0.0949) acc@1 0.9453 (0.9674) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 15:51:06] __main__ INFO: \u001b[0mEpoch 105 Step 351/351 lr 0.000100 loss 0.0681 (0.0948) acc@1 0.9688 (0.9676) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 15:51:06] __main__ INFO: \u001b[0mElapsed 32.44\n",
      "\u001b[32m[2020-06-20 15:51:06] __main__ INFO: \u001b[0mVal 105\n",
      "\u001b[32m[2020-06-20 15:51:07] __main__ INFO: \u001b[0mEpoch 105 loss 0.4257 acc@1 0.8832 acc@5 0.9954\n",
      "\u001b[32m[2020-06-20 15:51:07] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-20 15:51:07] __main__ INFO: \u001b[0mTrain 106 36855\n",
      "\u001b[32m[2020-06-20 15:51:16] __main__ INFO: \u001b[0mEpoch 106 Step 100/351 lr 0.000100 loss 0.1350 (0.0985) acc@1 0.9609 (0.9655) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:51:25] __main__ INFO: \u001b[0mEpoch 106 Step 200/351 lr 0.000100 loss 0.0985 (0.0974) acc@1 0.9844 (0.9674) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:51:35] __main__ INFO: \u001b[0mEpoch 106 Step 300/351 lr 0.000100 loss 0.0736 (0.0969) acc@1 0.9766 (0.9672) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:51:39] __main__ INFO: \u001b[0mEpoch 106 Step 351/351 lr 0.000100 loss 0.0649 (0.0961) acc@1 0.9844 (0.9675) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:51:39] __main__ INFO: \u001b[0mElapsed 32.48\n",
      "\u001b[32m[2020-06-20 15:51:39] __main__ INFO: \u001b[0mVal 106\n",
      "\u001b[32m[2020-06-20 15:51:40] __main__ INFO: \u001b[0mEpoch 106 loss 0.4244 acc@1 0.8844 acc@5 0.9954\n",
      "\u001b[32m[2020-06-20 15:51:40] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-20 15:51:40] __main__ INFO: \u001b[0mTrain 107 37206\n",
      "\u001b[32m[2020-06-20 15:51:50] __main__ INFO: \u001b[0mEpoch 107 Step 100/351 lr 0.000100 loss 0.0930 (0.0948) acc@1 0.9766 (0.9680) acc@5 0.9922 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:51:59] __main__ INFO: \u001b[0mEpoch 107 Step 200/351 lr 0.000100 loss 0.1162 (0.0935) acc@1 0.9531 (0.9692) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:52:08] __main__ INFO: \u001b[0mEpoch 107 Step 300/351 lr 0.000100 loss 0.0731 (0.0938) acc@1 0.9609 (0.9690) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 15:52:13] __main__ INFO: \u001b[0mEpoch 107 Step 351/351 lr 0.000100 loss 0.1315 (0.0944) acc@1 0.9453 (0.9686) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 15:52:13] __main__ INFO: \u001b[0mElapsed 32.40\n",
      "\u001b[32m[2020-06-20 15:52:13] __main__ INFO: \u001b[0mVal 107\n",
      "\u001b[32m[2020-06-20 15:52:14] __main__ INFO: \u001b[0mEpoch 107 loss 0.4288 acc@1 0.8832 acc@5 0.9940\n",
      "\u001b[32m[2020-06-20 15:52:14] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-20 15:52:14] __main__ INFO: \u001b[0mTrain 108 37557\n",
      "\u001b[32m[2020-06-20 15:52:23] __main__ INFO: \u001b[0mEpoch 108 Step 100/351 lr 0.000100 loss 0.0957 (0.0969) acc@1 0.9531 (0.9688) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 15:52:32] __main__ INFO: \u001b[0mEpoch 108 Step 200/351 lr 0.000100 loss 0.0629 (0.0984) acc@1 0.9766 (0.9674) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 15:52:42] __main__ INFO: \u001b[0mEpoch 108 Step 300/351 lr 0.000100 loss 0.0546 (0.0960) acc@1 0.9844 (0.9682) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 15:52:46] __main__ INFO: \u001b[0mEpoch 108 Step 351/351 lr 0.000100 loss 0.1046 (0.0953) acc@1 0.9688 (0.9684) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 15:52:46] __main__ INFO: \u001b[0mElapsed 32.39\n",
      "\u001b[32m[2020-06-20 15:52:46] __main__ INFO: \u001b[0mVal 108\n",
      "\u001b[32m[2020-06-20 15:52:47] __main__ INFO: \u001b[0mEpoch 108 loss 0.4270 acc@1 0.8842 acc@5 0.9950\n",
      "\u001b[32m[2020-06-20 15:52:47] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 15:52:47] __main__ INFO: \u001b[0mTrain 109 37908\n",
      "\u001b[32m[2020-06-20 15:52:57] __main__ INFO: \u001b[0mEpoch 109 Step 100/351 lr 0.000100 loss 0.0876 (0.0935) acc@1 0.9609 (0.9680) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:53:06] __main__ INFO: \u001b[0mEpoch 109 Step 200/351 lr 0.000100 loss 0.0486 (0.0956) acc@1 0.9844 (0.9667) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:53:15] __main__ INFO: \u001b[0mEpoch 109 Step 300/351 lr 0.000100 loss 0.1576 (0.0959) acc@1 0.9453 (0.9672) acc@5 0.9922 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:53:20] __main__ INFO: \u001b[0mEpoch 109 Step 351/351 lr 0.000100 loss 0.0987 (0.0956) acc@1 0.9844 (0.9673) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:53:20] __main__ INFO: \u001b[0mElapsed 32.40\n",
      "\u001b[32m[2020-06-20 15:53:20] __main__ INFO: \u001b[0mVal 109\n",
      "\u001b[32m[2020-06-20 15:53:21] __main__ INFO: \u001b[0mEpoch 109 loss 0.4284 acc@1 0.8814 acc@5 0.9956\n",
      "\u001b[32m[2020-06-20 15:53:21] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-20 15:53:21] __main__ INFO: \u001b[0mTrain 110 38259\n",
      "\u001b[32m[2020-06-20 15:53:30] __main__ INFO: \u001b[0mEpoch 110 Step 100/351 lr 0.000100 loss 0.0785 (0.0951) acc@1 0.9609 (0.9667) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 15:53:39] __main__ INFO: \u001b[0mEpoch 110 Step 200/351 lr 0.000100 loss 0.1125 (0.0955) acc@1 0.9531 (0.9669) acc@5 0.9922 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:53:49] __main__ INFO: \u001b[0mEpoch 110 Step 300/351 lr 0.000100 loss 0.1223 (0.0945) acc@1 0.9453 (0.9680) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:53:53] __main__ INFO: \u001b[0mEpoch 110 Step 351/351 lr 0.000100 loss 0.0942 (0.0945) acc@1 0.9453 (0.9677) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:53:53] __main__ INFO: \u001b[0mElapsed 32.39\n",
      "\u001b[32m[2020-06-20 15:53:53] __main__ INFO: \u001b[0mVal 110\n",
      "\u001b[32m[2020-06-20 15:53:54] __main__ INFO: \u001b[0mEpoch 110 loss 0.4293 acc@1 0.8834 acc@5 0.9956\n",
      "\u001b[32m[2020-06-20 15:53:54] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 15:53:54] __main__ INFO: \u001b[0mTrain 111 38610\n",
      "\u001b[32m[2020-06-20 15:54:04] __main__ INFO: \u001b[0mEpoch 111 Step 100/351 lr 0.000100 loss 0.1064 (0.1025) acc@1 0.9688 (0.9647) acc@5 0.9922 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:54:13] __main__ INFO: \u001b[0mEpoch 111 Step 200/351 lr 0.000100 loss 0.0675 (0.0991) acc@1 0.9766 (0.9664) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 15:54:22] __main__ INFO: \u001b[0mEpoch 111 Step 300/351 lr 0.000100 loss 0.0563 (0.0966) acc@1 0.9844 (0.9670) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 15:54:27] __main__ INFO: \u001b[0mEpoch 111 Step 351/351 lr 0.000100 loss 0.0838 (0.0967) acc@1 0.9688 (0.9670) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 15:54:27] __main__ INFO: \u001b[0mElapsed 32.39\n",
      "\u001b[32m[2020-06-20 15:54:27] __main__ INFO: \u001b[0mVal 111\n",
      "\u001b[32m[2020-06-20 15:54:28] __main__ INFO: \u001b[0mEpoch 111 loss 0.4271 acc@1 0.8826 acc@5 0.9954\n",
      "\u001b[32m[2020-06-20 15:54:28] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-20 15:54:28] __main__ INFO: \u001b[0mTrain 112 38961\n",
      "\u001b[32m[2020-06-20 15:54:37] __main__ INFO: \u001b[0mEpoch 112 Step 100/351 lr 0.000100 loss 0.1157 (0.0980) acc@1 0.9609 (0.9667) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:54:46] __main__ INFO: \u001b[0mEpoch 112 Step 200/351 lr 0.000100 loss 0.0756 (0.0975) acc@1 0.9844 (0.9666) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:54:55] __main__ INFO: \u001b[0mEpoch 112 Step 300/351 lr 0.000100 loss 0.0729 (0.1000) acc@1 0.9844 (0.9652) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:55:00] __main__ INFO: \u001b[0mEpoch 112 Step 351/351 lr 0.000100 loss 0.0784 (0.0995) acc@1 0.9844 (0.9657) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:55:00] __main__ INFO: \u001b[0mElapsed 32.46\n",
      "\u001b[32m[2020-06-20 15:55:00] __main__ INFO: \u001b[0mVal 112\n",
      "\u001b[32m[2020-06-20 15:55:01] __main__ INFO: \u001b[0mEpoch 112 loss 0.4278 acc@1 0.8858 acc@5 0.9950\n",
      "\u001b[32m[2020-06-20 15:55:01] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-20 15:55:01] __main__ INFO: \u001b[0mTrain 113 39312\n",
      "\u001b[32m[2020-06-20 15:55:11] __main__ INFO: \u001b[0mEpoch 113 Step 100/351 lr 0.000100 loss 0.1005 (0.0992) acc@1 0.9766 (0.9659) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:55:20] __main__ INFO: \u001b[0mEpoch 113 Step 200/351 lr 0.000100 loss 0.1720 (0.0934) acc@1 0.9609 (0.9681) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:55:29] __main__ INFO: \u001b[0mEpoch 113 Step 300/351 lr 0.000100 loss 0.0731 (0.0951) acc@1 0.9844 (0.9676) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:55:34] __main__ INFO: \u001b[0mEpoch 113 Step 351/351 lr 0.000100 loss 0.1566 (0.0961) acc@1 0.9453 (0.9673) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:55:34] __main__ INFO: \u001b[0mElapsed 32.47\n",
      "\u001b[32m[2020-06-20 15:55:34] __main__ INFO: \u001b[0mVal 113\n",
      "\u001b[32m[2020-06-20 15:55:35] __main__ INFO: \u001b[0mEpoch 113 loss 0.4269 acc@1 0.8842 acc@5 0.9952\n",
      "\u001b[32m[2020-06-20 15:55:35] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 15:55:35] __main__ INFO: \u001b[0mTrain 114 39663\n",
      "\u001b[32m[2020-06-20 15:55:44] __main__ INFO: \u001b[0mEpoch 114 Step 100/351 lr 0.000100 loss 0.1486 (0.0988) acc@1 0.9531 (0.9664) acc@5 0.9922 (0.9994)\n",
      "\u001b[32m[2020-06-20 15:55:53] __main__ INFO: \u001b[0mEpoch 114 Step 200/351 lr 0.000100 loss 0.0569 (0.0977) acc@1 0.9766 (0.9669) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:56:03] __main__ INFO: \u001b[0mEpoch 114 Step 300/351 lr 0.000100 loss 0.1580 (0.0976) acc@1 0.9375 (0.9673) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:56:07] __main__ INFO: \u001b[0mEpoch 114 Step 351/351 lr 0.000100 loss 0.0951 (0.0967) acc@1 0.9609 (0.9675) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:56:07] __main__ INFO: \u001b[0mElapsed 32.43\n",
      "\u001b[32m[2020-06-20 15:56:07] __main__ INFO: \u001b[0mVal 114\n",
      "\u001b[32m[2020-06-20 15:56:08] __main__ INFO: \u001b[0mEpoch 114 loss 0.4299 acc@1 0.8832 acc@5 0.9942\n",
      "\u001b[32m[2020-06-20 15:56:08] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-20 15:56:08] __main__ INFO: \u001b[0mTrain 115 40014\n",
      "\u001b[32m[2020-06-20 15:56:18] __main__ INFO: \u001b[0mEpoch 115 Step 100/351 lr 0.000100 loss 0.1023 (0.0938) acc@1 0.9688 (0.9691) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 15:56:27] __main__ INFO: \u001b[0mEpoch 115 Step 200/351 lr 0.000100 loss 0.1225 (0.0945) acc@1 0.9688 (0.9688) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 15:56:36] __main__ INFO: \u001b[0mEpoch 115 Step 300/351 lr 0.000100 loss 0.0635 (0.0962) acc@1 0.9844 (0.9679) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:56:41] __main__ INFO: \u001b[0mEpoch 115 Step 351/351 lr 0.000100 loss 0.1021 (0.0950) acc@1 0.9609 (0.9682) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:56:41] __main__ INFO: \u001b[0mElapsed 32.44\n",
      "\u001b[32m[2020-06-20 15:56:41] __main__ INFO: \u001b[0mVal 115\n",
      "\u001b[32m[2020-06-20 15:56:42] __main__ INFO: \u001b[0mEpoch 115 loss 0.4262 acc@1 0.8846 acc@5 0.9952\n",
      "\u001b[32m[2020-06-20 15:56:42] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 15:56:42] __main__ INFO: \u001b[0mTrain 116 40365\n",
      "\u001b[32m[2020-06-20 15:56:51] __main__ INFO: \u001b[0mEpoch 116 Step 100/351 lr 0.000100 loss 0.0499 (0.0927) acc@1 0.9844 (0.9683) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:57:00] __main__ INFO: \u001b[0mEpoch 116 Step 200/351 lr 0.000100 loss 0.1016 (0.0928) acc@1 0.9844 (0.9687) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:57:10] __main__ INFO: \u001b[0mEpoch 116 Step 300/351 lr 0.000100 loss 0.0644 (0.0947) acc@1 0.9766 (0.9679) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:57:14] __main__ INFO: \u001b[0mEpoch 116 Step 351/351 lr 0.000100 loss 0.1340 (0.0955) acc@1 0.9609 (0.9674) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:57:14] __main__ INFO: \u001b[0mElapsed 32.41\n",
      "\u001b[32m[2020-06-20 15:57:14] __main__ INFO: \u001b[0mVal 116\n",
      "\u001b[32m[2020-06-20 15:57:15] __main__ INFO: \u001b[0mEpoch 116 loss 0.4312 acc@1 0.8832 acc@5 0.9950\n",
      "\u001b[32m[2020-06-20 15:57:15] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-20 15:57:15] __main__ INFO: \u001b[0mTrain 117 40716\n",
      "\u001b[32m[2020-06-20 15:57:25] __main__ INFO: \u001b[0mEpoch 117 Step 100/351 lr 0.000100 loss 0.1149 (0.1023) acc@1 0.9531 (0.9641) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:57:34] __main__ INFO: \u001b[0mEpoch 117 Step 200/351 lr 0.000100 loss 0.0957 (0.0985) acc@1 0.9688 (0.9651) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:57:43] __main__ INFO: \u001b[0mEpoch 117 Step 300/351 lr 0.000100 loss 0.0950 (0.0970) acc@1 0.9688 (0.9659) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 15:57:48] __main__ INFO: \u001b[0mEpoch 117 Step 351/351 lr 0.000100 loss 0.0472 (0.0963) acc@1 0.9844 (0.9667) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 15:57:48] __main__ INFO: \u001b[0mElapsed 32.47\n",
      "\u001b[32m[2020-06-20 15:57:48] __main__ INFO: \u001b[0mVal 117\n",
      "\u001b[32m[2020-06-20 15:57:49] __main__ INFO: \u001b[0mEpoch 117 loss 0.4296 acc@1 0.8838 acc@5 0.9954\n",
      "\u001b[32m[2020-06-20 15:57:49] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 15:57:49] __main__ INFO: \u001b[0mTrain 118 41067\n",
      "\u001b[32m[2020-06-20 15:57:58] __main__ INFO: \u001b[0mEpoch 118 Step 100/351 lr 0.000100 loss 0.1260 (0.0927) acc@1 0.9375 (0.9683) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 15:58:07] __main__ INFO: \u001b[0mEpoch 118 Step 200/351 lr 0.000100 loss 0.0256 (0.0923) acc@1 1.0000 (0.9688) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:58:17] __main__ INFO: \u001b[0mEpoch 118 Step 300/351 lr 0.000100 loss 0.1333 (0.0956) acc@1 0.9531 (0.9669) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:58:21] __main__ INFO: \u001b[0mEpoch 118 Step 351/351 lr 0.000100 loss 0.0330 (0.0959) acc@1 0.9922 (0.9669) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 15:58:21] __main__ INFO: \u001b[0mElapsed 32.42\n",
      "\u001b[32m[2020-06-20 15:58:21] __main__ INFO: \u001b[0mVal 118\n",
      "\u001b[32m[2020-06-20 15:58:22] __main__ INFO: \u001b[0mEpoch 118 loss 0.4286 acc@1 0.8838 acc@5 0.9948\n",
      "\u001b[32m[2020-06-20 15:58:22] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 15:58:22] __main__ INFO: \u001b[0mTrain 119 41418\n",
      "\u001b[32m[2020-06-20 15:58:32] __main__ INFO: \u001b[0mEpoch 119 Step 100/351 lr 0.000100 loss 0.1522 (0.1003) acc@1 0.9375 (0.9647) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 15:58:41] __main__ INFO: \u001b[0mEpoch 119 Step 200/351 lr 0.000100 loss 0.0897 (0.0987) acc@1 0.9844 (0.9654) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:58:50] __main__ INFO: \u001b[0mEpoch 119 Step 300/351 lr 0.000100 loss 0.1032 (0.0962) acc@1 0.9609 (0.9663) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:58:55] __main__ INFO: \u001b[0mEpoch 119 Step 351/351 lr 0.000100 loss 0.0868 (0.0958) acc@1 0.9609 (0.9664) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 15:58:55] __main__ INFO: \u001b[0mElapsed 32.40\n",
      "\u001b[32m[2020-06-20 15:58:55] __main__ INFO: \u001b[0mVal 119\n",
      "\u001b[32m[2020-06-20 15:58:56] __main__ INFO: \u001b[0mEpoch 119 loss 0.4289 acc@1 0.8824 acc@5 0.9950\n",
      "\u001b[32m[2020-06-20 15:58:56] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-20 15:58:56] __main__ INFO: \u001b[0mTrain 120 41769\n",
      "\u001b[32m[2020-06-20 15:59:05] __main__ INFO: \u001b[0mEpoch 120 Step 100/351 lr 0.000100 loss 0.1300 (0.0938) acc@1 0.9688 (0.9693) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 15:59:14] __main__ INFO: \u001b[0mEpoch 120 Step 200/351 lr 0.000100 loss 0.1211 (0.0931) acc@1 0.9609 (0.9686) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 15:59:24] __main__ INFO: \u001b[0mEpoch 120 Step 300/351 lr 0.000100 loss 0.0990 (0.0933) acc@1 0.9609 (0.9685) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 15:59:28] __main__ INFO: \u001b[0mEpoch 120 Step 351/351 lr 0.000100 loss 0.0666 (0.0945) acc@1 0.9688 (0.9679) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 15:59:28] __main__ INFO: \u001b[0mElapsed 32.42\n",
      "\u001b[32m[2020-06-20 15:59:28] __main__ INFO: \u001b[0mVal 120\n",
      "\u001b[32m[2020-06-20 15:59:29] __main__ INFO: \u001b[0mEpoch 120 loss 0.4279 acc@1 0.8844 acc@5 0.9952\n",
      "\u001b[32m[2020-06-20 15:59:29] __main__ INFO: \u001b[0mElapsed 1.17\n",
      "\u001b[32m[2020-06-20 15:59:29] __main__ INFO: \u001b[0mTrain 121 42120\n",
      "\u001b[32m[2020-06-20 15:59:39] __main__ INFO: \u001b[0mEpoch 121 Step 100/351 lr 0.000010 loss 0.0717 (0.0986) acc@1 0.9766 (0.9666) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 15:59:48] __main__ INFO: \u001b[0mEpoch 121 Step 200/351 lr 0.000010 loss 0.0668 (0.0945) acc@1 0.9766 (0.9680) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 15:59:57] __main__ INFO: \u001b[0mEpoch 121 Step 300/351 lr 0.000010 loss 0.0974 (0.0957) acc@1 0.9609 (0.9677) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:00:02] __main__ INFO: \u001b[0mEpoch 121 Step 351/351 lr 0.000010 loss 0.1081 (0.0966) acc@1 0.9609 (0.9673) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:00:02] __main__ INFO: \u001b[0mElapsed 32.54\n",
      "\u001b[32m[2020-06-20 16:00:02] __main__ INFO: \u001b[0mVal 121\n",
      "\u001b[32m[2020-06-20 16:00:03] __main__ INFO: \u001b[0mEpoch 121 loss 0.4310 acc@1 0.8830 acc@5 0.9942\n",
      "\u001b[32m[2020-06-20 16:00:03] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-20 16:00:03] __main__ INFO: \u001b[0mTrain 122 42471\n",
      "\u001b[32m[2020-06-20 16:00:12] __main__ INFO: \u001b[0mEpoch 122 Step 100/351 lr 0.000010 loss 0.0577 (0.0934) acc@1 0.9766 (0.9684) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-20 16:00:22] __main__ INFO: \u001b[0mEpoch 122 Step 200/351 lr 0.000010 loss 0.0449 (0.0910) acc@1 0.9844 (0.9686) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:00:31] __main__ INFO: \u001b[0mEpoch 122 Step 300/351 lr 0.000010 loss 0.0924 (0.0927) acc@1 0.9609 (0.9682) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 16:00:36] __main__ INFO: \u001b[0mEpoch 122 Step 351/351 lr 0.000010 loss 0.1568 (0.0938) acc@1 0.9375 (0.9683) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:00:36] __main__ INFO: \u001b[0mElapsed 32.47\n",
      "\u001b[32m[2020-06-20 16:00:36] __main__ INFO: \u001b[0mVal 122\n",
      "\u001b[32m[2020-06-20 16:00:37] __main__ INFO: \u001b[0mEpoch 122 loss 0.4259 acc@1 0.8844 acc@5 0.9948\n",
      "\u001b[32m[2020-06-20 16:00:37] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-20 16:00:37] __main__ INFO: \u001b[0mTrain 123 42822\n",
      "\u001b[32m[2020-06-20 16:00:46] __main__ INFO: \u001b[0mEpoch 123 Step 100/351 lr 0.000010 loss 0.1167 (0.0983) acc@1 0.9531 (0.9671) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-20 16:00:55] __main__ INFO: \u001b[0mEpoch 123 Step 200/351 lr 0.000010 loss 0.1524 (0.0964) acc@1 0.9531 (0.9675) acc@5 0.9922 (0.9995)\n",
      "\u001b[32m[2020-06-20 16:01:04] __main__ INFO: \u001b[0mEpoch 123 Step 300/351 lr 0.000010 loss 0.0847 (0.0960) acc@1 0.9609 (0.9670) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:01:09] __main__ INFO: \u001b[0mEpoch 123 Step 351/351 lr 0.000010 loss 0.0879 (0.0949) acc@1 0.9844 (0.9675) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:01:09] __main__ INFO: \u001b[0mElapsed 32.41\n",
      "\u001b[32m[2020-06-20 16:01:09] __main__ INFO: \u001b[0mVal 123\n",
      "\u001b[32m[2020-06-20 16:01:10] __main__ INFO: \u001b[0mEpoch 123 loss 0.4285 acc@1 0.8842 acc@5 0.9954\n",
      "\u001b[32m[2020-06-20 16:01:10] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-20 16:01:10] __main__ INFO: \u001b[0mTrain 124 43173\n",
      "\u001b[32m[2020-06-20 16:01:19] __main__ INFO: \u001b[0mEpoch 124 Step 100/351 lr 0.000010 loss 0.1527 (0.0983) acc@1 0.9375 (0.9663) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 16:01:29] __main__ INFO: \u001b[0mEpoch 124 Step 200/351 lr 0.000010 loss 0.0898 (0.0965) acc@1 0.9688 (0.9669) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 16:01:38] __main__ INFO: \u001b[0mEpoch 124 Step 300/351 lr 0.000010 loss 0.0831 (0.0950) acc@1 0.9609 (0.9673) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 16:01:43] __main__ INFO: \u001b[0mEpoch 124 Step 351/351 lr 0.000010 loss 0.0677 (0.0956) acc@1 0.9688 (0.9674) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 16:01:43] __main__ INFO: \u001b[0mElapsed 32.43\n",
      "\u001b[32m[2020-06-20 16:01:43] __main__ INFO: \u001b[0mVal 124\n",
      "\u001b[32m[2020-06-20 16:01:44] __main__ INFO: \u001b[0mEpoch 124 loss 0.4286 acc@1 0.8832 acc@5 0.9948\n",
      "\u001b[32m[2020-06-20 16:01:44] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-20 16:01:44] __main__ INFO: \u001b[0mTrain 125 43524\n",
      "\u001b[32m[2020-06-20 16:01:53] __main__ INFO: \u001b[0mEpoch 125 Step 100/351 lr 0.000010 loss 0.0751 (0.0991) acc@1 0.9844 (0.9655) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 16:02:02] __main__ INFO: \u001b[0mEpoch 125 Step 200/351 lr 0.000010 loss 0.1147 (0.0965) acc@1 0.9531 (0.9666) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:02:11] __main__ INFO: \u001b[0mEpoch 125 Step 300/351 lr 0.000010 loss 0.0867 (0.0978) acc@1 0.9609 (0.9660) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:02:16] __main__ INFO: \u001b[0mEpoch 125 Step 351/351 lr 0.000010 loss 0.1064 (0.0973) acc@1 0.9531 (0.9661) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:02:16] __main__ INFO: \u001b[0mElapsed 32.40\n",
      "\u001b[32m[2020-06-20 16:02:16] __main__ INFO: \u001b[0mVal 125\n",
      "\u001b[32m[2020-06-20 16:02:17] __main__ INFO: \u001b[0mEpoch 125 loss 0.4305 acc@1 0.8818 acc@5 0.9950\n",
      "\u001b[32m[2020-06-20 16:02:17] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-20 16:02:17] __main__ INFO: \u001b[0mTrain 126 43875\n",
      "\u001b[32m[2020-06-20 16:02:26] __main__ INFO: \u001b[0mEpoch 126 Step 100/351 lr 0.000010 loss 0.0460 (0.0999) acc@1 0.9922 (0.9645) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 16:02:36] __main__ INFO: \u001b[0mEpoch 126 Step 200/351 lr 0.000010 loss 0.1300 (0.0981) acc@1 0.9688 (0.9658) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 16:02:45] __main__ INFO: \u001b[0mEpoch 126 Step 300/351 lr 0.000010 loss 0.1330 (0.0995) acc@1 0.9609 (0.9655) acc@5 0.9922 (0.9997)\n",
      "\u001b[32m[2020-06-20 16:02:50] __main__ INFO: \u001b[0mEpoch 126 Step 351/351 lr 0.000010 loss 0.0713 (0.0977) acc@1 0.9844 (0.9665) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 16:02:50] __main__ INFO: \u001b[0mElapsed 32.41\n",
      "\u001b[32m[2020-06-20 16:02:50] __main__ INFO: \u001b[0mVal 126\n",
      "\u001b[32m[2020-06-20 16:02:51] __main__ INFO: \u001b[0mEpoch 126 loss 0.4269 acc@1 0.8828 acc@5 0.9956\n",
      "\u001b[32m[2020-06-20 16:02:51] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-20 16:02:51] __main__ INFO: \u001b[0mTrain 127 44226\n",
      "\u001b[32m[2020-06-20 16:03:00] __main__ INFO: \u001b[0mEpoch 127 Step 100/351 lr 0.000010 loss 0.0704 (0.0989) acc@1 0.9688 (0.9666) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 16:03:09] __main__ INFO: \u001b[0mEpoch 127 Step 200/351 lr 0.000010 loss 0.0695 (0.0963) acc@1 0.9844 (0.9679) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:03:18] __main__ INFO: \u001b[0mEpoch 127 Step 300/351 lr 0.000010 loss 0.1293 (0.0945) acc@1 0.9609 (0.9682) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 16:03:23] __main__ INFO: \u001b[0mEpoch 127 Step 351/351 lr 0.000010 loss 0.1098 (0.0945) acc@1 0.9453 (0.9681) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 16:03:23] __main__ INFO: \u001b[0mElapsed 32.43\n",
      "\u001b[32m[2020-06-20 16:03:23] __main__ INFO: \u001b[0mVal 127\n",
      "\u001b[32m[2020-06-20 16:03:24] __main__ INFO: \u001b[0mEpoch 127 loss 0.4295 acc@1 0.8834 acc@5 0.9944\n",
      "\u001b[32m[2020-06-20 16:03:24] __main__ INFO: \u001b[0mElapsed 1.12\n",
      "\u001b[32m[2020-06-20 16:03:24] __main__ INFO: \u001b[0mTrain 128 44577\n",
      "\u001b[32m[2020-06-20 16:03:34] __main__ INFO: \u001b[0mEpoch 128 Step 100/351 lr 0.000010 loss 0.0536 (0.1001) acc@1 0.9844 (0.9651) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 16:03:43] __main__ INFO: \u001b[0mEpoch 128 Step 200/351 lr 0.000010 loss 0.0593 (0.0964) acc@1 0.9766 (0.9670) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:03:52] __main__ INFO: \u001b[0mEpoch 128 Step 300/351 lr 0.000010 loss 0.1074 (0.0965) acc@1 0.9688 (0.9676) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:03:57] __main__ INFO: \u001b[0mEpoch 128 Step 351/351 lr 0.000010 loss 0.0780 (0.0963) acc@1 0.9688 (0.9676) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 16:03:57] __main__ INFO: \u001b[0mElapsed 32.42\n",
      "\u001b[32m[2020-06-20 16:03:57] __main__ INFO: \u001b[0mVal 128\n",
      "\u001b[32m[2020-06-20 16:03:58] __main__ INFO: \u001b[0mEpoch 128 loss 0.4296 acc@1 0.8834 acc@5 0.9954\n",
      "\u001b[32m[2020-06-20 16:03:58] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-20 16:03:58] __main__ INFO: \u001b[0mTrain 129 44928\n",
      "\u001b[32m[2020-06-20 16:04:07] __main__ INFO: \u001b[0mEpoch 129 Step 100/351 lr 0.000010 loss 0.1837 (0.0953) acc@1 0.9453 (0.9683) acc@5 0.9922 (0.9997)\n",
      "\u001b[32m[2020-06-20 16:04:16] __main__ INFO: \u001b[0mEpoch 129 Step 200/351 lr 0.000010 loss 0.0860 (0.0947) acc@1 0.9688 (0.9681) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:04:25] __main__ INFO: \u001b[0mEpoch 129 Step 300/351 lr 0.000010 loss 0.1327 (0.0943) acc@1 0.9375 (0.9683) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:04:30] __main__ INFO: \u001b[0mEpoch 129 Step 351/351 lr 0.000010 loss 0.1335 (0.0948) acc@1 0.9297 (0.9681) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 16:04:30] __main__ INFO: \u001b[0mElapsed 32.39\n",
      "\u001b[32m[2020-06-20 16:04:30] __main__ INFO: \u001b[0mVal 129\n",
      "\u001b[32m[2020-06-20 16:04:31] __main__ INFO: \u001b[0mEpoch 129 loss 0.4279 acc@1 0.8824 acc@5 0.9956\n",
      "\u001b[32m[2020-06-20 16:04:31] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 16:04:31] __main__ INFO: \u001b[0mTrain 130 45279\n",
      "\u001b[32m[2020-06-20 16:04:40] __main__ INFO: \u001b[0mEpoch 130 Step 100/351 lr 0.000010 loss 0.1091 (0.0959) acc@1 0.9609 (0.9667) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 16:04:50] __main__ INFO: \u001b[0mEpoch 130 Step 200/351 lr 0.000010 loss 0.0639 (0.0965) acc@1 0.9844 (0.9666) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-06-20 16:04:59] __main__ INFO: \u001b[0mEpoch 130 Step 300/351 lr 0.000010 loss 0.0495 (0.0969) acc@1 0.9922 (0.9665) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-06-20 16:05:03] __main__ INFO: \u001b[0mEpoch 130 Step 351/351 lr 0.000010 loss 0.1638 (0.0960) acc@1 0.9453 (0.9671) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 16:05:04] __main__ INFO: \u001b[0mElapsed 32.41\n",
      "\u001b[32m[2020-06-20 16:05:04] __main__ INFO: \u001b[0mVal 130\n",
      "\u001b[32m[2020-06-20 16:05:05] __main__ INFO: \u001b[0mEpoch 130 loss 0.4267 acc@1 0.8844 acc@5 0.9946\n",
      "\u001b[32m[2020-06-20 16:05:05] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-20 16:05:05] __main__ INFO: \u001b[0mTrain 131 45630\n",
      "\u001b[32m[2020-06-20 16:05:14] __main__ INFO: \u001b[0mEpoch 131 Step 100/351 lr 0.000010 loss 0.1124 (0.0942) acc@1 0.9531 (0.9685) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 16:05:23] __main__ INFO: \u001b[0mEpoch 131 Step 200/351 lr 0.000010 loss 0.1222 (0.0968) acc@1 0.9531 (0.9672) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 16:05:32] __main__ INFO: \u001b[0mEpoch 131 Step 300/351 lr 0.000010 loss 0.0993 (0.0988) acc@1 0.9609 (0.9662) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 16:05:37] __main__ INFO: \u001b[0mEpoch 131 Step 351/351 lr 0.000010 loss 0.1525 (0.0977) acc@1 0.9531 (0.9672) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 16:05:37] __main__ INFO: \u001b[0mElapsed 32.40\n",
      "\u001b[32m[2020-06-20 16:05:37] __main__ INFO: \u001b[0mVal 131\n",
      "\u001b[32m[2020-06-20 16:05:38] __main__ INFO: \u001b[0mEpoch 131 loss 0.4298 acc@1 0.8824 acc@5 0.9950\n",
      "\u001b[32m[2020-06-20 16:05:38] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 16:05:38] __main__ INFO: \u001b[0mTrain 132 45981\n",
      "\u001b[32m[2020-06-20 16:05:47] __main__ INFO: \u001b[0mEpoch 132 Step 100/351 lr 0.000010 loss 0.0867 (0.0988) acc@1 0.9766 (0.9660) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 16:05:57] __main__ INFO: \u001b[0mEpoch 132 Step 200/351 lr 0.000010 loss 0.0602 (0.0986) acc@1 0.9766 (0.9660) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:06:06] __main__ INFO: \u001b[0mEpoch 132 Step 300/351 lr 0.000010 loss 0.1098 (0.0974) acc@1 0.9609 (0.9665) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:06:10] __main__ INFO: \u001b[0mEpoch 132 Step 351/351 lr 0.000010 loss 0.0997 (0.0960) acc@1 0.9688 (0.9668) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 16:06:11] __main__ INFO: \u001b[0mElapsed 32.43\n",
      "\u001b[32m[2020-06-20 16:06:11] __main__ INFO: \u001b[0mVal 132\n",
      "\u001b[32m[2020-06-20 16:06:12] __main__ INFO: \u001b[0mEpoch 132 loss 0.4312 acc@1 0.8820 acc@5 0.9950\n",
      "\u001b[32m[2020-06-20 16:06:12] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 16:06:12] __main__ INFO: \u001b[0mTrain 133 46332\n",
      "\u001b[32m[2020-06-20 16:06:21] __main__ INFO: \u001b[0mEpoch 133 Step 100/351 lr 0.000010 loss 0.0771 (0.0920) acc@1 0.9766 (0.9674) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:06:30] __main__ INFO: \u001b[0mEpoch 133 Step 200/351 lr 0.000010 loss 0.0902 (0.0937) acc@1 0.9688 (0.9671) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 16:06:39] __main__ INFO: \u001b[0mEpoch 133 Step 300/351 lr 0.000010 loss 0.0647 (0.0966) acc@1 0.9766 (0.9660) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 16:06:44] __main__ INFO: \u001b[0mEpoch 133 Step 351/351 lr 0.000010 loss 0.1547 (0.0964) acc@1 0.9375 (0.9661) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 16:06:44] __main__ INFO: \u001b[0mElapsed 32.45\n",
      "\u001b[32m[2020-06-20 16:06:44] __main__ INFO: \u001b[0mVal 133\n",
      "\u001b[32m[2020-06-20 16:06:45] __main__ INFO: \u001b[0mEpoch 133 loss 0.4289 acc@1 0.8840 acc@5 0.9950\n",
      "\u001b[32m[2020-06-20 16:06:45] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-20 16:06:45] __main__ INFO: \u001b[0mTrain 134 46683\n",
      "\u001b[32m[2020-06-20 16:06:54] __main__ INFO: \u001b[0mEpoch 134 Step 100/351 lr 0.000010 loss 0.0685 (0.0889) acc@1 0.9922 (0.9704) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 16:07:04] __main__ INFO: \u001b[0mEpoch 134 Step 200/351 lr 0.000010 loss 0.0823 (0.0925) acc@1 0.9688 (0.9693) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:07:13] __main__ INFO: \u001b[0mEpoch 134 Step 300/351 lr 0.000010 loss 0.0600 (0.0935) acc@1 0.9922 (0.9687) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 16:07:17] __main__ INFO: \u001b[0mEpoch 134 Step 351/351 lr 0.000010 loss 0.0443 (0.0936) acc@1 0.9922 (0.9684) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 16:07:17] __main__ INFO: \u001b[0mElapsed 32.35\n",
      "\u001b[32m[2020-06-20 16:07:17] __main__ INFO: \u001b[0mVal 134\n",
      "\u001b[32m[2020-06-20 16:07:19] __main__ INFO: \u001b[0mEpoch 134 loss 0.4294 acc@1 0.8836 acc@5 0.9954\n",
      "\u001b[32m[2020-06-20 16:07:19] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-20 16:07:19] __main__ INFO: \u001b[0mTrain 135 47034\n",
      "\u001b[32m[2020-06-20 16:07:28] __main__ INFO: \u001b[0mEpoch 135 Step 100/351 lr 0.000010 loss 0.1398 (0.1005) acc@1 0.9609 (0.9652) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-06-20 16:07:37] __main__ INFO: \u001b[0mEpoch 135 Step 200/351 lr 0.000010 loss 0.1088 (0.0983) acc@1 0.9688 (0.9664) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 16:07:46] __main__ INFO: \u001b[0mEpoch 135 Step 300/351 lr 0.000010 loss 0.1321 (0.0974) acc@1 0.9531 (0.9664) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 16:07:51] __main__ INFO: \u001b[0mEpoch 135 Step 351/351 lr 0.000010 loss 0.1030 (0.0966) acc@1 0.9766 (0.9667) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-06-20 16:07:51] __main__ INFO: \u001b[0mElapsed 32.44\n",
      "\u001b[32m[2020-06-20 16:07:51] __main__ INFO: \u001b[0mVal 135\n",
      "\u001b[32m[2020-06-20 16:07:52] __main__ INFO: \u001b[0mEpoch 135 loss 0.4302 acc@1 0.8824 acc@5 0.9950\n",
      "\u001b[32m[2020-06-20 16:07:52] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 16:07:52] __main__ INFO: \u001b[0mTrain 136 47385\n",
      "\u001b[32m[2020-06-20 16:08:01] __main__ INFO: \u001b[0mEpoch 136 Step 100/351 lr 0.000010 loss 0.0684 (0.0938) acc@1 0.9766 (0.9684) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 16:08:11] __main__ INFO: \u001b[0mEpoch 136 Step 200/351 lr 0.000010 loss 0.1031 (0.0928) acc@1 0.9688 (0.9684) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 16:08:20] __main__ INFO: \u001b[0mEpoch 136 Step 300/351 lr 0.000010 loss 0.1016 (0.0942) acc@1 0.9844 (0.9677) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:08:24] __main__ INFO: \u001b[0mEpoch 136 Step 351/351 lr 0.000010 loss 0.1388 (0.0933) acc@1 0.9609 (0.9680) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:08:24] __main__ INFO: \u001b[0mElapsed 32.41\n",
      "\u001b[32m[2020-06-20 16:08:24] __main__ INFO: \u001b[0mVal 136\n",
      "\u001b[32m[2020-06-20 16:08:26] __main__ INFO: \u001b[0mEpoch 136 loss 0.4267 acc@1 0.8854 acc@5 0.9954\n",
      "\u001b[32m[2020-06-20 16:08:26] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 16:08:26] __main__ INFO: \u001b[0mTrain 137 47736\n",
      "\u001b[32m[2020-06-20 16:08:35] __main__ INFO: \u001b[0mEpoch 137 Step 100/351 lr 0.000010 loss 0.1044 (0.0985) acc@1 0.9688 (0.9655) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 16:08:44] __main__ INFO: \u001b[0mEpoch 137 Step 200/351 lr 0.000010 loss 0.1191 (0.0979) acc@1 0.9531 (0.9661) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 16:08:53] __main__ INFO: \u001b[0mEpoch 137 Step 300/351 lr 0.000010 loss 0.0733 (0.0957) acc@1 0.9766 (0.9674) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:08:58] __main__ INFO: \u001b[0mEpoch 137 Step 351/351 lr 0.000010 loss 0.1002 (0.0961) acc@1 0.9531 (0.9669) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:08:58] __main__ INFO: \u001b[0mElapsed 32.43\n",
      "\u001b[32m[2020-06-20 16:08:58] __main__ INFO: \u001b[0mVal 137\n",
      "\u001b[32m[2020-06-20 16:08:59] __main__ INFO: \u001b[0mEpoch 137 loss 0.4309 acc@1 0.8834 acc@5 0.9952\n",
      "\u001b[32m[2020-06-20 16:08:59] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 16:08:59] __main__ INFO: \u001b[0mTrain 138 48087\n",
      "\u001b[32m[2020-06-20 16:09:08] __main__ INFO: \u001b[0mEpoch 138 Step 100/351 lr 0.000010 loss 0.0877 (0.0886) acc@1 0.9766 (0.9685) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 16:09:18] __main__ INFO: \u001b[0mEpoch 138 Step 200/351 lr 0.000010 loss 0.0398 (0.0917) acc@1 0.9844 (0.9686) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 16:09:27] __main__ INFO: \u001b[0mEpoch 138 Step 300/351 lr 0.000010 loss 0.0986 (0.0927) acc@1 0.9688 (0.9683) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 16:09:31] __main__ INFO: \u001b[0mEpoch 138 Step 351/351 lr 0.000010 loss 0.1071 (0.0930) acc@1 0.9766 (0.9684) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:09:31] __main__ INFO: \u001b[0mElapsed 32.41\n",
      "\u001b[32m[2020-06-20 16:09:31] __main__ INFO: \u001b[0mVal 138\n",
      "\u001b[32m[2020-06-20 16:09:33] __main__ INFO: \u001b[0mEpoch 138 loss 0.4280 acc@1 0.8842 acc@5 0.9952\n",
      "\u001b[32m[2020-06-20 16:09:33] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-20 16:09:33] __main__ INFO: \u001b[0mTrain 139 48438\n",
      "\u001b[32m[2020-06-20 16:09:42] __main__ INFO: \u001b[0mEpoch 139 Step 100/351 lr 0.000010 loss 0.2030 (0.0992) acc@1 0.9609 (0.9655) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 16:09:51] __main__ INFO: \u001b[0mEpoch 139 Step 200/351 lr 0.000010 loss 0.1163 (0.0967) acc@1 0.9531 (0.9673) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-20 16:10:00] __main__ INFO: \u001b[0mEpoch 139 Step 300/351 lr 0.000010 loss 0.0445 (0.0961) acc@1 0.9922 (0.9671) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-06-20 16:10:05] __main__ INFO: \u001b[0mEpoch 139 Step 351/351 lr 0.000010 loss 0.1413 (0.0952) acc@1 0.9375 (0.9677) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 16:10:05] __main__ INFO: \u001b[0mElapsed 32.44\n",
      "\u001b[32m[2020-06-20 16:10:05] __main__ INFO: \u001b[0mVal 139\n",
      "\u001b[32m[2020-06-20 16:10:06] __main__ INFO: \u001b[0mEpoch 139 loss 0.4275 acc@1 0.8844 acc@5 0.9950\n",
      "\u001b[32m[2020-06-20 16:10:06] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 16:10:06] __main__ INFO: \u001b[0mTrain 140 48789\n",
      "\u001b[32m[2020-06-20 16:10:15] __main__ INFO: \u001b[0mEpoch 140 Step 100/351 lr 0.000010 loss 0.0652 (0.0979) acc@1 0.9688 (0.9653) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 16:10:25] __main__ INFO: \u001b[0mEpoch 140 Step 200/351 lr 0.000010 loss 0.1657 (0.0971) acc@1 0.9375 (0.9663) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:10:34] __main__ INFO: \u001b[0mEpoch 140 Step 300/351 lr 0.000010 loss 0.0974 (0.0966) acc@1 0.9766 (0.9671) acc@5 0.9922 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:10:38] __main__ INFO: \u001b[0mEpoch 140 Step 351/351 lr 0.000010 loss 0.0663 (0.0974) acc@1 0.9844 (0.9671) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:10:38] __main__ INFO: \u001b[0mElapsed 32.40\n",
      "\u001b[32m[2020-06-20 16:10:38] __main__ INFO: \u001b[0mVal 140\n",
      "\u001b[32m[2020-06-20 16:10:40] __main__ INFO: \u001b[0mEpoch 140 loss 0.4293 acc@1 0.8834 acc@5 0.9954\n",
      "\u001b[32m[2020-06-20 16:10:40] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 16:10:40] __main__ INFO: \u001b[0mTrain 141 49140\n",
      "\u001b[32m[2020-06-20 16:10:49] __main__ INFO: \u001b[0mEpoch 141 Step 100/351 lr 0.000010 loss 0.0947 (0.0980) acc@1 0.9688 (0.9666) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 16:10:58] __main__ INFO: \u001b[0mEpoch 141 Step 200/351 lr 0.000010 loss 0.1103 (0.0964) acc@1 0.9531 (0.9676) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 16:11:07] __main__ INFO: \u001b[0mEpoch 141 Step 300/351 lr 0.000010 loss 0.1166 (0.0964) acc@1 0.9688 (0.9672) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:11:12] __main__ INFO: \u001b[0mEpoch 141 Step 351/351 lr 0.000010 loss 0.0389 (0.0959) acc@1 0.9844 (0.9674) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:11:12] __main__ INFO: \u001b[0mElapsed 32.40\n",
      "\u001b[32m[2020-06-20 16:11:12] __main__ INFO: \u001b[0mVal 141\n",
      "\u001b[32m[2020-06-20 16:11:13] __main__ INFO: \u001b[0mEpoch 141 loss 0.4321 acc@1 0.8848 acc@5 0.9946\n",
      "\u001b[32m[2020-06-20 16:11:13] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-20 16:11:13] __main__ INFO: \u001b[0mTrain 142 49491\n",
      "\u001b[32m[2020-06-20 16:11:22] __main__ INFO: \u001b[0mEpoch 142 Step 100/351 lr 0.000010 loss 0.1005 (0.0924) acc@1 0.9609 (0.9687) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 16:11:32] __main__ INFO: \u001b[0mEpoch 142 Step 200/351 lr 0.000010 loss 0.1545 (0.0978) acc@1 0.9219 (0.9673) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:11:41] __main__ INFO: \u001b[0mEpoch 142 Step 300/351 lr 0.000010 loss 0.0964 (0.0996) acc@1 0.9688 (0.9668) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:11:45] __main__ INFO: \u001b[0mEpoch 142 Step 351/351 lr 0.000010 loss 0.0613 (0.0975) acc@1 0.9844 (0.9675) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 16:11:45] __main__ INFO: \u001b[0mElapsed 32.44\n",
      "\u001b[32m[2020-06-20 16:11:45] __main__ INFO: \u001b[0mVal 142\n",
      "\u001b[32m[2020-06-20 16:11:47] __main__ INFO: \u001b[0mEpoch 142 loss 0.4276 acc@1 0.8828 acc@5 0.9954\n",
      "\u001b[32m[2020-06-20 16:11:47] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-20 16:11:47] __main__ INFO: \u001b[0mTrain 143 49842\n",
      "\u001b[32m[2020-06-20 16:11:56] __main__ INFO: \u001b[0mEpoch 143 Step 100/351 lr 0.000010 loss 0.0370 (0.0970) acc@1 1.0000 (0.9669) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:12:05] __main__ INFO: \u001b[0mEpoch 143 Step 200/351 lr 0.000010 loss 0.1535 (0.0950) acc@1 0.9609 (0.9677) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:12:14] __main__ INFO: \u001b[0mEpoch 143 Step 300/351 lr 0.000010 loss 0.1332 (0.0936) acc@1 0.9609 (0.9682) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 16:12:19] __main__ INFO: \u001b[0mEpoch 143 Step 351/351 lr 0.000010 loss 0.1083 (0.0941) acc@1 0.9531 (0.9683) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:12:19] __main__ INFO: \u001b[0mElapsed 32.46\n",
      "\u001b[32m[2020-06-20 16:12:19] __main__ INFO: \u001b[0mVal 143\n",
      "\u001b[32m[2020-06-20 16:12:20] __main__ INFO: \u001b[0mEpoch 143 loss 0.4288 acc@1 0.8820 acc@5 0.9948\n",
      "\u001b[32m[2020-06-20 16:12:20] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-20 16:12:20] __main__ INFO: \u001b[0mTrain 144 50193\n",
      "\u001b[32m[2020-06-20 16:12:29] __main__ INFO: \u001b[0mEpoch 144 Step 100/351 lr 0.000010 loss 0.1223 (0.0963) acc@1 0.9609 (0.9682) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 16:12:39] __main__ INFO: \u001b[0mEpoch 144 Step 200/351 lr 0.000010 loss 0.0771 (0.0941) acc@1 0.9766 (0.9692) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 16:12:48] __main__ INFO: \u001b[0mEpoch 144 Step 300/351 lr 0.000010 loss 0.0444 (0.0940) acc@1 0.9922 (0.9690) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 16:12:53] __main__ INFO: \u001b[0mEpoch 144 Step 351/351 lr 0.000010 loss 0.0887 (0.0947) acc@1 0.9688 (0.9689) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 16:12:53] __main__ INFO: \u001b[0mElapsed 32.46\n",
      "\u001b[32m[2020-06-20 16:12:53] __main__ INFO: \u001b[0mVal 144\n",
      "\u001b[32m[2020-06-20 16:12:54] __main__ INFO: \u001b[0mEpoch 144 loss 0.4285 acc@1 0.8834 acc@5 0.9948\n",
      "\u001b[32m[2020-06-20 16:12:54] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-06-20 16:12:54] __main__ INFO: \u001b[0mTrain 145 50544\n",
      "\u001b[32m[2020-06-20 16:13:03] __main__ INFO: \u001b[0mEpoch 145 Step 100/351 lr 0.000010 loss 0.0988 (0.0984) acc@1 0.9688 (0.9653) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 16:13:12] __main__ INFO: \u001b[0mEpoch 145 Step 200/351 lr 0.000010 loss 0.0950 (0.0964) acc@1 0.9531 (0.9663) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 16:13:21] __main__ INFO: \u001b[0mEpoch 145 Step 300/351 lr 0.000010 loss 0.0892 (0.0946) acc@1 0.9688 (0.9677) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-06-20 16:13:26] __main__ INFO: \u001b[0mEpoch 145 Step 351/351 lr 0.000010 loss 0.1244 (0.0950) acc@1 0.9688 (0.9677) acc@5 0.9922 (0.9999)\n",
      "\u001b[32m[2020-06-20 16:13:26] __main__ INFO: \u001b[0mElapsed 32.45\n",
      "\u001b[32m[2020-06-20 16:13:26] __main__ INFO: \u001b[0mVal 145\n",
      "\u001b[32m[2020-06-20 16:13:27] __main__ INFO: \u001b[0mEpoch 145 loss 0.4279 acc@1 0.8844 acc@5 0.9950\n",
      "\u001b[32m[2020-06-20 16:13:27] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-06-20 16:13:27] __main__ INFO: \u001b[0mTrain 146 50895\n",
      "\u001b[32m[2020-06-20 16:13:36] __main__ INFO: \u001b[0mEpoch 146 Step 100/351 lr 0.000010 loss 0.0748 (0.0959) acc@1 0.9844 (0.9670) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 16:13:46] __main__ INFO: \u001b[0mEpoch 146 Step 200/351 lr 0.000010 loss 0.1110 (0.1005) acc@1 0.9609 (0.9653) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:13:55] __main__ INFO: \u001b[0mEpoch 146 Step 300/351 lr 0.000010 loss 0.0607 (0.0968) acc@1 0.9844 (0.9667) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:14:00] __main__ INFO: \u001b[0mEpoch 146 Step 351/351 lr 0.000010 loss 0.1660 (0.0964) acc@1 0.9375 (0.9670) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:14:00] __main__ INFO: \u001b[0mElapsed 32.38\n",
      "\u001b[32m[2020-06-20 16:14:00] __main__ INFO: \u001b[0mVal 146\n",
      "\u001b[32m[2020-06-20 16:14:01] __main__ INFO: \u001b[0mEpoch 146 loss 0.4283 acc@1 0.8848 acc@5 0.9952\n",
      "\u001b[32m[2020-06-20 16:14:01] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-06-20 16:14:01] __main__ INFO: \u001b[0mTrain 147 51246\n",
      "\u001b[32m[2020-06-20 16:14:10] __main__ INFO: \u001b[0mEpoch 147 Step 100/351 lr 0.000010 loss 0.0526 (0.0921) acc@1 0.9922 (0.9684) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 16:14:19] __main__ INFO: \u001b[0mEpoch 147 Step 200/351 lr 0.000010 loss 0.1458 (0.0945) acc@1 0.9453 (0.9675) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-06-20 16:14:28] __main__ INFO: \u001b[0mEpoch 147 Step 300/351 lr 0.000010 loss 0.1314 (0.0945) acc@1 0.9531 (0.9679) acc@5 0.9922 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:14:33] __main__ INFO: \u001b[0mEpoch 147 Step 351/351 lr 0.000010 loss 0.1154 (0.0938) acc@1 0.9609 (0.9681) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:14:33] __main__ INFO: \u001b[0mElapsed 32.45\n",
      "\u001b[32m[2020-06-20 16:14:33] __main__ INFO: \u001b[0mVal 147\n",
      "\u001b[32m[2020-06-20 16:14:34] __main__ INFO: \u001b[0mEpoch 147 loss 0.4276 acc@1 0.8844 acc@5 0.9950\n",
      "\u001b[32m[2020-06-20 16:14:34] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 16:14:34] __main__ INFO: \u001b[0mTrain 148 51597\n",
      "\u001b[32m[2020-06-20 16:14:44] __main__ INFO: \u001b[0mEpoch 148 Step 100/351 lr 0.000010 loss 0.1075 (0.0907) acc@1 0.9688 (0.9691) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 16:14:53] __main__ INFO: \u001b[0mEpoch 148 Step 200/351 lr 0.000010 loss 0.0430 (0.0935) acc@1 0.9922 (0.9673) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 16:15:02] __main__ INFO: \u001b[0mEpoch 148 Step 300/351 lr 0.000010 loss 0.0666 (0.0945) acc@1 0.9844 (0.9671) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 16:15:07] __main__ INFO: \u001b[0mEpoch 148 Step 351/351 lr 0.000010 loss 0.0832 (0.0947) acc@1 0.9609 (0.9669) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 16:15:07] __main__ INFO: \u001b[0mElapsed 32.42\n",
      "\u001b[32m[2020-06-20 16:15:07] __main__ INFO: \u001b[0mVal 148\n",
      "\u001b[32m[2020-06-20 16:15:08] __main__ INFO: \u001b[0mEpoch 148 loss 0.4283 acc@1 0.8840 acc@5 0.9952\n",
      "\u001b[32m[2020-06-20 16:15:08] __main__ INFO: \u001b[0mElapsed 1.11\n",
      "\u001b[32m[2020-06-20 16:15:08] __main__ INFO: \u001b[0mTrain 149 51948\n",
      "\u001b[32m[2020-06-20 16:15:17] __main__ INFO: \u001b[0mEpoch 149 Step 100/351 lr 0.000010 loss 0.0848 (0.0938) acc@1 0.9609 (0.9664) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-06-20 16:15:26] __main__ INFO: \u001b[0mEpoch 149 Step 200/351 lr 0.000010 loss 0.1425 (0.0972) acc@1 0.9531 (0.9660) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:15:35] __main__ INFO: \u001b[0mEpoch 149 Step 300/351 lr 0.000010 loss 0.1097 (0.0951) acc@1 0.9297 (0.9672) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:15:40] __main__ INFO: \u001b[0mEpoch 149 Step 351/351 lr 0.000010 loss 0.1172 (0.0949) acc@1 0.9609 (0.9673) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:15:40] __main__ INFO: \u001b[0mElapsed 32.39\n",
      "\u001b[32m[2020-06-20 16:15:40] __main__ INFO: \u001b[0mVal 149\n",
      "\u001b[32m[2020-06-20 16:15:41] __main__ INFO: \u001b[0mEpoch 149 loss 0.4259 acc@1 0.8846 acc@5 0.9954\n",
      "\u001b[32m[2020-06-20 16:15:41] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-06-20 16:15:41] __main__ INFO: \u001b[0mTrain 150 52299\n",
      "\u001b[32m[2020-06-20 16:15:50] __main__ INFO: \u001b[0mEpoch 150 Step 100/351 lr 0.000010 loss 0.0693 (0.0937) acc@1 0.9922 (0.9675) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-06-20 16:16:00] __main__ INFO: \u001b[0mEpoch 150 Step 200/351 lr 0.000010 loss 0.1721 (0.0960) acc@1 0.9375 (0.9680) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-06-20 16:16:09] __main__ INFO: \u001b[0mEpoch 150 Step 300/351 lr 0.000010 loss 0.0440 (0.0958) acc@1 0.9922 (0.9677) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:16:14] __main__ INFO: \u001b[0mEpoch 150 Step 351/351 lr 0.000010 loss 0.1794 (0.0962) acc@1 0.9062 (0.9673) acc@5 0.9922 (0.9996)\n",
      "\u001b[32m[2020-06-20 16:16:14] __main__ INFO: \u001b[0mElapsed 32.41\n",
      "\u001b[32m[2020-06-20 16:16:14] __main__ INFO: \u001b[0mVal 150\n",
      "\u001b[32m[2020-06-20 16:16:15] __main__ INFO: \u001b[0mEpoch 150 loss 0.4297 acc@1 0.8844 acc@5 0.9950\n",
      "\u001b[32m[2020-06-20 16:16:15] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-06-20 16:16:15] fvcore.common.checkpoint INFO: \u001b[0mSaving checkpoint to /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_5/exp00_resume300_150/checkpoint_00150.pth\n"
     ]
    }
   ],
   "source": [
    "# Resume training with the un-augmented data\n",
    "# os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "# #!python train.py --config configs/cifar/resnet.yaml \\\n",
    "# !python train.py --config /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_5/exp00/config.yaml \\\n",
    "#     train.checkpoint /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_5/exp00/checkpoint_00300.pth \\\n",
    "#     dataset.name CIFAR10 \\\n",
    "#     train.base_lr .001 \\\n",
    "#     train.output_dir /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_5/exp00_resume300_150 \\\n",
    "#     scheduler.epochs 150\n",
    "\n",
    "#### Set LEARNING RATE based on ending LR\n",
    "#    train.resume True \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-06-20 14:12:28] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_5/exp00_resume/checkpoint_00050.pth\n",
      "Files already downloaded and verified\n",
      "100%|| 79/79 [00:03<00:00, 26.06it/s]\n",
      "\u001b[32m[2020-06-20 14:12:32] __main__ INFO: \u001b[0mElapsed 3.03\n",
      "\u001b[32m[2020-06-20 14:12:32] __main__ INFO: \u001b[0mLoss 0.4499 Accuracy 0.8766\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10 test dataset \n",
    "# Right the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/resnet.yaml \\\n",
    "   model.resnet.depth 32 \\\n",
    "   test.batch_size 128 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_5/exp00_resume400_50/checkpoint_00050.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_5/exp00_resume400_50/test_results_0050_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-06-20 16:32:43] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_5/exp00_resume300_150/checkpoint_00150.pth\n",
      "Files already downloaded and verified\n",
      "100%|| 79/79 [00:02<00:00, 26.53it/s]\n",
      "\u001b[32m[2020-06-20 16:32:46] __main__ INFO: \u001b[0mElapsed 2.98\n",
      "\u001b[32m[2020-06-20 16:32:46] __main__ INFO: \u001b[0mLoss 0.4499 Accuracy 0.8795\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10 test dataset \n",
    "# Right the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/resnet.yaml \\\n",
    "   model.resnet.depth 32 \\\n",
    "   test.batch_size 128 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_5/exp00_resume300_150/checkpoint_00150.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_5/exp00_resume300_150/test_results_0150_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-06-20 14:12:40] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_5/exp00_resume/checkpoint_00050.pth\n",
      "CIFAR 10.1\n",
      "100%|| 16/16 [00:00<00:00, 16.79it/s]\n",
      "\u001b[32m[2020-06-20 14:12:42] __main__ INFO: \u001b[0mElapsed 0.96\n",
      "\u001b[32m[2020-06-20 14:12:42] __main__ INFO: \u001b[0mLoss 0.7680 Accuracy 0.7790\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10.1 test dataset \n",
    "# Right the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/resnet.yaml \\\n",
    "   model.resnet.depth 32 \\\n",
    "   test.batch_size 128 \\\n",
    "   dataset.name CIFAR101 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_5/exp00_resume400_50/checkpoint_00050.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_5/exp00_resume400_50/test_results_0050_cifar101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-06-20 16:33:19] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_5/exp00_resume300_150/checkpoint_00150.pth\n",
      "CIFAR 10.1\n",
      "100%|| 16/16 [00:00<00:00, 17.16it/s]\n",
      "\u001b[32m[2020-06-20 16:33:20] __main__ INFO: \u001b[0mElapsed 0.93\n",
      "\u001b[32m[2020-06-20 16:33:20] __main__ INFO: \u001b[0mLoss 0.8206 Accuracy 0.7710\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10.1 test dataset \n",
    "# Right the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/resnet.yaml \\\n",
    "   model.resnet.depth 32 \\\n",
    "   test.batch_size 128 \\\n",
    "   dataset.name CIFAR101 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_5/exp00_resume300_150/checkpoint_00150.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_5/exp00_resume300_150/test_results_0150_cifar101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-06-20 13:07:47] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_5/exp00/checkpoint_00400.pth\n",
      "Files already downloaded and verified\n",
      "100%|| 79/79 [00:02<00:00, 27.61it/s]\n",
      "\u001b[32m[2020-06-20 13:07:51] __main__ INFO: \u001b[0mElapsed 2.86\n",
      "\u001b[32m[2020-06-20 13:07:51] __main__ INFO: \u001b[0mLoss 1.1508 Accuracy 0.8148\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10 test dataset \n",
    "# Right the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/resnet.yaml \\\n",
    "   model.resnet.depth 32 \\\n",
    "   test.batch_size 128 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_5/exp00/checkpoint_00400.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_5/exp00/test_results_0050_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-06-20 13:03:59] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_5/exp00/checkpoint_00200.pth\n",
      "Files already downloaded and verified\n",
      "100%|| 79/79 [00:03<00:00, 26.21it/s]\n",
      "\u001b[32m[2020-06-20 13:04:03] __main__ INFO: \u001b[0mElapsed 3.02\n",
      "\u001b[32m[2020-06-20 13:04:03] __main__ INFO: \u001b[0mLoss 0.9363 Accuracy 0.8193\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10 test dataset \n",
    "# Right the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/resnet.yaml \\\n",
    "   model.resnet.depth 32 \\\n",
    "   test.batch_size 128 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_5/exp00/checkpoint_00200.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_5/exp00/test_results_0200_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-06-20 13:07:35] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_5/exp00/checkpoint_00300.pth\n",
      "Files already downloaded and verified\n",
      "100%|| 79/79 [00:02<00:00, 26.49it/s]\n",
      "\u001b[32m[2020-06-20 13:07:39] __main__ INFO: \u001b[0mElapsed 2.98\n",
      "\u001b[32m[2020-06-20 13:07:39] __main__ INFO: \u001b[0mLoss 1.0633 Accuracy 0.8138\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10 test dataset \n",
    "# Right the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/resnet.yaml \\\n",
    "   model.resnet.depth 32 \\\n",
    "   test.batch_size 128 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_5/exp00/checkpoint_00300.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_5/exp00/test_results_0300_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-06-20 13:07:23] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_5/exp00/checkpoint_00400.pth\n",
      "CIFAR 10.1\n",
      "100%|| 16/16 [00:00<00:00, 19.67it/s]\n",
      "\u001b[32m[2020-06-20 13:07:24] __main__ INFO: \u001b[0mElapsed 0.82\n",
      "\u001b[32m[2020-06-20 13:07:24] __main__ INFO: \u001b[0mLoss 2.0591 Accuracy 0.6780\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10.1 test dataset \n",
    "# Right the results to the test output directory specified.\n",
    "os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "!python evaluate.py --config configs/cifar/resnet.yaml \\\n",
    "   model.resnet.depth 32 \\\n",
    "   test.batch_size 128 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_5/exp00/checkpoint_00400.pth \\\n",
    "   dataset.name CIFAR101 \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_5/exp00/test_results_0400_cifar101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-06-20 13:07:14] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_5/exp00/checkpoint_00300.pth\n",
      "CIFAR 10.1\n",
      "100%|| 16/16 [00:00<00:00, 17.68it/s]\n",
      "\u001b[32m[2020-06-20 13:07:15] __main__ INFO: \u001b[0mElapsed 0.91\n",
      "\u001b[32m[2020-06-20 13:07:15] __main__ INFO: \u001b[0mLoss 1.9379 Accuracy 0.6705\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10.1 test dataset \n",
    "# Right the results to the test output directory specified.\n",
    "os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "!python evaluate.py --config configs/cifar/resnet.yaml \\\n",
    "   model.resnet.depth 32 \\\n",
    "   test.batch_size 128 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_5/exp00/checkpoint_00300.pth \\\n",
    "   dataset.name CIFAR101 \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_5/exp00/test_results_0300_cifar101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Testset</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Original_Accuracy</th>\n",
       "      <th>Original_CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resnet_basic_32</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3604</td>\n",
       "      <td>0.9170</td>\n",
       "      <td>92.5</td>\n",
       "      <td>(92.0, 93.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>resnet_basic_32</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>160</td>\n",
       "      <td>0.4011</td>\n",
       "      <td>0.9232</td>\n",
       "      <td>92.5</td>\n",
       "      <td>(92.0, 93.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>resnet_basic_32</td>\n",
       "      <td>cifar10.1</td>\n",
       "      <td>160</td>\n",
       "      <td>0.8051</td>\n",
       "      <td>0.8320</td>\n",
       "      <td>84.9</td>\n",
       "      <td>(83.2, 86.4)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model    Testset  Epoch    Loss  Accuracy  Original_Accuracy  \\\n",
       "0  resnet_basic_32    cifar10    100  0.3604    0.9170               92.5   \n",
       "1  resnet_basic_32    cifar10    160  0.4011    0.9232               92.5   \n",
       "2  resnet_basic_32  cifar10.1    160  0.8051    0.8320               84.9   \n",
       "\n",
       "    Original_CI  \n",
       "0  (92.0, 93.0)  \n",
       "1  (92.0, 93.0)  \n",
       "2  (83.2, 86.4)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write the results to a CSV file so that we can analyze later.\n",
    "import pandas as pd\n",
    "\n",
    "results = {'Model': ['resnet_basic_32', 'resnet_basic_32', 'resnet_basic_32']\n",
    "           'Testset': ['cifar10', 'cifar10', 'cifar10.1']\n",
    "           'Loss': [0.3604, 0.4011, 0.8051],\n",
    "           'Epoch': [100, 160, 160],\n",
    "           'Accuracy': [0.9170, 0.9232, 0.8320],\n",
    "           'Original_Accuracy': [92.5, 92.5, 84.9],\n",
    "           'Original_CI': [(92.0, 93.0), (92.0, 93.0), (83.2, 86.4)]\n",
    "           }\n",
    "\n",
    "df = pd.DataFrame(results, columns = ['Model', 'Testset', 'Epoch', 'Loss', 'Accuracy', \n",
    "                                      'Original_Accuracy', 'Original_CI'])\n",
    "\n",
    "\n",
    "df.to_csv('/home/ec2-user/SageMaker/experiments/resnet_basic_32/exp00/results.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Testset</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Original_Accuracy</th>\n",
       "      <th>Original_CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resnet_basic_32_ra_2_5</td>\n",
       "      <td>400</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>1.1508</td>\n",
       "      <td>0.8148</td>\n",
       "      <td>92.5</td>\n",
       "      <td>(92.0, 93.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>resnet_basic_32_ra_2_5</td>\n",
       "      <td>300</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>1.0633</td>\n",
       "      <td>0.8138</td>\n",
       "      <td>92.5</td>\n",
       "      <td>(92.0, 93.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>resnet_basic_32_ra_2_5</td>\n",
       "      <td>400</td>\n",
       "      <td>cifar10.1</td>\n",
       "      <td>2.0591</td>\n",
       "      <td>0.678</td>\n",
       "      <td>84.9</td>\n",
       "      <td>(83.2, 86.4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>resnet_basic_32_ra_2_5</td>\n",
       "      <td>300</td>\n",
       "      <td>cifar10.1</td>\n",
       "      <td>1.9379</td>\n",
       "      <td>0.6705</td>\n",
       "      <td>84.9</td>\n",
       "      <td>(83.2, 86.4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>resnet_basic_32_ra_2_5_refined400</td>\n",
       "      <td>50</td>\n",
       "      <td>cifar10.1</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.779</td>\n",
       "      <td>84.9</td>\n",
       "      <td>(83.2, 86.4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>resnet_basic_32_ra_2_5_refined400</td>\n",
       "      <td>50</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>0.4499</td>\n",
       "      <td>0.8766</td>\n",
       "      <td>92.5</td>\n",
       "      <td>(92.0, 93.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>resnet_basic_32_ra_2_5_refined300</td>\n",
       "      <td>150</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>0.4499</td>\n",
       "      <td>0.8795</td>\n",
       "      <td>92.5</td>\n",
       "      <td>(92.0, 93.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>resnet_basic_32_ra_2_5_refined300</td>\n",
       "      <td>150</td>\n",
       "      <td>cifar10.1</td>\n",
       "      <td>0.8206</td>\n",
       "      <td>0.771</td>\n",
       "      <td>84.9</td>\n",
       "      <td>(83.2, 86.4)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Model Epoch    Testset    Loss Accuracy  \\\n",
       "0             resnet_basic_32_ra_2_5   400    cifar10  1.1508   0.8148   \n",
       "1             resnet_basic_32_ra_2_5   300    cifar10  1.0633   0.8138   \n",
       "2             resnet_basic_32_ra_2_5   400  cifar10.1  2.0591    0.678   \n",
       "3             resnet_basic_32_ra_2_5   300  cifar10.1  1.9379   0.6705   \n",
       "4  resnet_basic_32_ra_2_5_refined400    50  cifar10.1   0.768    0.779   \n",
       "5  resnet_basic_32_ra_2_5_refined400    50    cifar10  0.4499   0.8766   \n",
       "6  resnet_basic_32_ra_2_5_refined300   150    cifar10  0.4499   0.8795   \n",
       "7  resnet_basic_32_ra_2_5_refined300   150  cifar10.1  0.8206    0.771   \n",
       "\n",
       "   Original_Accuracy   Original_CI  \n",
       "0               92.5  (92.0, 93.0)  \n",
       "1               92.5  (92.0, 93.0)  \n",
       "2               84.9  (83.2, 86.4)  \n",
       "3               84.9  (83.2, 86.4)  \n",
       "4               84.9  (83.2, 86.4)  \n",
       "5               92.5  (92.0, 93.0)  \n",
       "6               92.5  (92.0, 93.0)  \n",
       "7               84.9  (83.2, 86.4)  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "a = pd.Series(['resnet_basic_32_ra_2_5', 400, 'cifar10', 1.1508, 0.8148])\n",
    "b = pd.Series(['resnet_basic_32_ra_2_5', 300, 'cifar10', 1.0633, 0.8138])\n",
    "c = pd.Series(['resnet_basic_32_ra_2_5', 400, 'cifar10.1', 2.0591, 0.6780])\n",
    "d = pd.Series(['resnet_basic_32_ra_2_5', 300, 'cifar10.1',  1.9379, 0.6705])\n",
    "\n",
    "\n",
    "e = pd.Series(['resnet_basic_32_ra_2_5_refined400', 50, 'cifar10.1', 0.7680, 0.7790])\n",
    "f = pd.Series(['resnet_basic_32_ra_2_5_refined400', 50, 'cifar10', 0.4499,0.8766])\n",
    "g = pd.Series(['resnet_basic_32_ra_2_5_refined300', 150, 'cifar10', 0.4499, 0.8795])\n",
    "h = pd.Series(['resnet_basic_32_ra_2_5_refined300', 150, 'cifar10.1', 0.8206, 0.7710])\n",
    "               \n",
    "df_results = pd.concat([a,b,c,d,e,f, g, h], axis=1).T\n",
    "df_results.columns = ['Model', 'Epoch', 'Testset', 'Loss', 'Accuracy']\n",
    "\n",
    "df_results['Original_Accuracy'] = df_results.apply((lambda row: 92.5 if row[2] == 'cifar10' else 84.9), axis=1)\n",
    "df_results['Original_CI'] = df_results.apply((lambda row: (92.0, 93.0) if row[2] == 'cifar10' else (83.2, 86.4)), axis=1)\n",
    "\n",
    "df_results.to_csv('/home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_5/results.csv')\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['preds', 'probs', 'labels', 'loss', 'acc']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ -7.153804  ,  -0.1832159 ,  -0.69570637, ...,  -0.50926757,\n",
       "         -5.526208  , -12.987257  ],\n",
       "       [  2.862379  ,   7.963458  ,  -6.603018  , ...,  -4.740323  ,\n",
       "         25.90399   ,  -0.52988565],\n",
       "       [  4.25749   ,   8.408992  ,  -4.3299227 , ...,  -2.3715498 ,\n",
       "         13.468082  ,   4.5792727 ],\n",
       "       ...,\n",
       "       [ -4.7270765 ,  -1.2400844 ,   1.3852903 , ...,  -0.51062894,\n",
       "         -3.399443  ,  -2.4969094 ],\n",
       "       [ -2.7640457 ,  14.635863  ,   6.7449965 , ...,  -1.3011913 ,\n",
       "         -3.036379  ,  -7.061736  ],\n",
       "       [ -2.6933427 ,   1.8961854 ,  -3.6396854 , ...,  18.63456   ,\n",
       "         -2.7524152 ,  -3.2204888 ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Peak inside the output file for predictions\n",
    "import numpy as np\n",
    "output = '/home/ec2-user/SageMaker/experiments/resnet_basic_32/exp00/test_results_0160/predictions.npz'\n",
    "npzfile = np.load(output)\n",
    "print(npzfile.files)\n",
    "npzfile['preds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the model checkpoints, configs, and results to S3 \n",
    "bucket='sagemaker-may29'\n",
    "prefix = 'sagemaker/results/original-models/resnet_basic_32_ra_2_5'\n",
    "path = '/home/ec2-user/SageMaker/experiments/resnet_basic_32_ra_2_5'\n",
    "\n",
    "s3_resource = boto3.resource(\"s3\", region_name=\"us-east-2\")\n",
    "\n",
    "def uploadDirectory(local_path,bucket_name,s3_prefix):\n",
    "\n",
    "    my_bucket = s3_resource.Bucket(bucket_name)\n",
    "    \n",
    "    for path, subdirs, files in os.walk(local_path):\n",
    "        path = path.replace(\"\\\\\",\"/\")\n",
    "        directory_name = path.replace(local_path,\"\")\n",
    "        for file in files:\n",
    "            #print(\"Local File:\", os.path.join(path, file))\n",
    "            #print(\"      Dest:\", s3_prefix+directory_name+'/'+file)\n",
    "            my_bucket.upload_file(os.path.join(path, file), s3_prefix+directory_name+'/'+file)\n",
    "    \n",
    "uploadDirectory(path,bucket,prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
