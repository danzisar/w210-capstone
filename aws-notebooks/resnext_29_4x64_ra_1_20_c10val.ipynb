{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNext 29 4x64\n",
    "\n",
    " - Training Dataset:  RandAugment, N=1, M=20\n",
    "   Validation with Unaugmented Data\n",
    " - Sagemaker Notebook must be of type, conda_pytorch_p36\n",
    " \n",
    "#### Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy \n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 1)) (1.18.1)\n",
      "Requirement already satisfied: torch>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 2)) (1.4.0)\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 3)) (0.5.0)\n",
      "Collecting fvcore\n",
      "  Downloading fvcore-0.1.1.post20200716.tar.gz (33 kB)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 5)) (4.44.1)\n",
      "Collecting yacs\n",
      "  Downloading yacs-0.1.7-py3-none-any.whl (14 kB)\n",
      "Collecting apex\n",
      "  Cloning https://github.com/NVIDIA/apex.git to /tmp/pip-install-9gc5arql/apex\n",
      "  Running command git clone -q https://github.com/NVIDIA/apex.git /tmp/pip-install-9gc5arql/apex\n",
      "  Running command git submodule update --init --recursive -q\n",
      "Collecting termcolor\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting thop<0.0.31.post2004070130\n",
      "  Downloading thop-0.0.31.post2001170342-py3-none-any.whl (7.5 kB)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 3)) (1.14.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 3)) (7.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from fvcore->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (5.3.1)\n",
      "Collecting portalocker\n",
      "  Downloading portalocker-1.7.1-py2.py3-none-any.whl (10 kB)\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.8.7-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: fvcore, apex, termcolor\n",
      "  Building wheel for fvcore (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fvcore: filename=fvcore-0.1.1.post20200716-py3-none-any.whl size=42323 sha256=dd3d2696500bcb63ab2ef8f87ff3f2380d43c6f4752c71caa57bb0d87df5a254\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/2a/b5/06/dbfaa61feab8112b9ab038603ca06f375c975e3ef464e3e063\n",
      "  Building wheel for apex (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for apex: filename=apex-0.1-py3-none-any.whl size=192505 sha256=036b323ed580443c252a8db18b1b5b82ae92a0f67f9e3b73790b189308b6ded1\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-7fiwhmed/wheels/2a/45/23/6b4f2d6323a65ee0022d22a96d7bf580138e689f17cc48235c\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=b33d64d04a0fd125d31551ab073871b63114be5c44d62db941a6eac998f6dec5\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n",
      "Successfully built fvcore apex termcolor\n",
      "Installing collected packages: yacs, portalocker, termcolor, tabulate, fvcore, apex, thop\n",
      "Successfully installed apex-0.1 fvcore-0.1.1.post20200716 portalocker-1.7.1 tabulate-0.8.7 termcolor-1.1.0 thop-0.0.31.post2001170342 yacs-0.1.7\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting tensorboard\n",
      "  Downloading tensorboard-2.2.2-py3-none-any.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 11.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.2.2-py3-none-any.whl (88 kB)\n",
      "\u001b[K     |████████████████████████████████| 88 kB 2.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.19.1-py2.py3-none-any.whl (91 kB)\n",
      "\u001b[K     |████████████████████████████████| 91 kB 18.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting absl-py>=0.4\n",
      "  Downloading absl-py-0.9.0.tar.gz (104 kB)\n",
      "\u001b[K     |████████████████████████████████| 104 kB 62.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (46.1.3.post20200330)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.18.1)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\n",
      "\u001b[K     |████████████████████████████████| 779 kB 59.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.34.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (2.23.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (3.12.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.0.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.14.0)\n",
      "Collecting grpcio>=1.24.3\n",
      "  Downloading grpcio-1.30.0-cp36-cp36m-manylinux2010_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 58.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (1.5.0)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 68.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard) (3.4.2)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.1.1-py3-none-any.whl (10 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.4.5.2)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (1.25.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard) (2.2.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 74.7 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: absl-py\n",
      "  Building wheel for absl-py (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for absl-py: filename=absl_py-0.9.0-py3-none-any.whl size=121931 sha256=376394cced23917f4f15fe5e222d87807343a7e294ec53970f0debfdd743388b\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/c3/af/84/3962a6af7b4ab336e951b7877dcfb758cf94548bb1771e0679\n",
      "Successfully built absl-py\n",
      "Installing collected packages: markdown, pyasn1-modules, cachetools, google-auth, absl-py, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard-plugin-wit, grpcio, tensorboard\n",
      "Successfully installed absl-py-0.9.0 cachetools-4.1.1 google-auth-1.19.1 google-auth-oauthlib-0.4.1 grpcio-1.30.0 markdown-3.2.2 oauthlib-3.1.0 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 tensorboard-2.2.2 tensorboard-plugin-wit-1.7.0\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r '/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt'\n",
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model per the settings specified in the original paper\n",
    "os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "!python train.py --config configs/cifar/resnext.yaml \\\n",
    "    model.resnext.cardinality 4 \\\n",
    "    train.batch_size 128 \\\n",
    "    train.base_lr 0.1 \\\n",
    "    dataset.name CIFAR10_RA_1_20 \\\n",
    "    train.base_lr 0.1 \\\n",
    "    train.output_dir /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_ra_1_20/exp00 \\\n",
    "    scheduler.epochs 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refine the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-13 12:21:03] __main__ INFO: \u001b[0mdevice: cuda\n",
      "cudnn:\n",
      "  benchmark: True\n",
      "  deterministic: False\n",
      "dataset:\n",
      "  name: CIFAR10\n",
      "  dataset_dir: ~/.torch/datasets/CIFAR10\n",
      "  image_size: 32\n",
      "  n_channels: 3\n",
      "  n_classes: 10\n",
      "model:\n",
      "  type: cifar\n",
      "  name: resnext\n",
      "  init_mode: kaiming_fan_out\n",
      "  vgg:\n",
      "    n_channels: [64, 128, 256, 512, 512]\n",
      "    n_layers: [2, 2, 3, 3, 3]\n",
      "    use_bn: True\n",
      "  resnet:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "  resnet_preact:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "  wrn:\n",
      "    depth: 28\n",
      "    initial_channels: 16\n",
      "    widening_factor: 10\n",
      "    drop_rate: 0.0\n",
      "  densenet:\n",
      "    depth: 100\n",
      "    n_blocks: [6, 12, 24, 16]\n",
      "    block_type: bottleneck\n",
      "    growth_rate: 12\n",
      "    drop_rate: 0.0\n",
      "    compression_rate: 0.5\n",
      "  pyramidnet:\n",
      "    depth: 272\n",
      "    n_blocks: [3, 24, 36, 3]\n",
      "    initial_channels: 16\n",
      "    block_type: bottleneck\n",
      "    alpha: 200\n",
      "  resnext:\n",
      "    depth: 29\n",
      "    n_blocks: [3, 4, 6, 3]\n",
      "    initial_channels: 64\n",
      "    cardinality: 4\n",
      "    base_channels: 64\n",
      "  shake_shake:\n",
      "    depth: 26\n",
      "    initial_channels: 96\n",
      "    shake_forward: True\n",
      "    shake_backward: True\n",
      "    shake_image: True\n",
      "  se_resnet_preact:\n",
      "    depth: 110\n",
      "    initial_channels: 16\n",
      "    se_reduction: 16\n",
      "    block_type: basic\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "train:\n",
      "  checkpoint: /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_cm_1_1/exp00/checkpoint_00400.pth\n",
      "  resume: False\n",
      "  precision: O0\n",
      "  batch_size: 128\n",
      "  subdivision: 1\n",
      "  optimizer: sgd\n",
      "  base_lr: 0.001\n",
      "  momentum: 0.9\n",
      "  nesterov: True\n",
      "  weight_decay: 0.0005\n",
      "  no_weight_decay_on_bn: False\n",
      "  gradient_clip: 0\n",
      "  start_epoch: 0\n",
      "  seed: 0\n",
      "  val_first: True\n",
      "  val_period: 1\n",
      "  val_ratio: 0.1\n",
      "  use_test_as_val: False\n",
      "  output_dir: /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_cm_1_1/exp00_resume400_50\n",
      "  log_period: 100\n",
      "  checkpoint_period: 100\n",
      "  use_tensorboard: True\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: True\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "  distributed: False\n",
      "  dist:\n",
      "    backend: nccl\n",
      "    init_method: env://\n",
      "    world_size: -1\n",
      "    node_rank: -1\n",
      "    local_rank: 0\n",
      "    use_sync_bn: False\n",
      "tensorboard:\n",
      "  train_images: False\n",
      "  val_images: False\n",
      "  model_params: False\n",
      "optim:\n",
      "  adam:\n",
      "    betas: (0.9, 0.999)\n",
      "  lars:\n",
      "    eps: 1e-09\n",
      "    threshold: 0.01\n",
      "  adabound:\n",
      "    betas: (0.9, 0.999)\n",
      "    final_lr: 0.1\n",
      "    gamma: 0.001\n",
      "scheduler:\n",
      "  epochs: 50\n",
      "  warmup:\n",
      "    type: none\n",
      "    epochs: 0\n",
      "    start_factor: 0.001\n",
      "    exponent: 4\n",
      "  type: multistep\n",
      "  milestones: [150, 225]\n",
      "  lr_decay: 0.1\n",
      "  lr_min_factor: 0.001\n",
      "  T0: 10\n",
      "  T_mul: 1.0\n",
      "validation:\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: False\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "augmentation:\n",
      "  use_random_crop: True\n",
      "  use_random_horizontal_flip: True\n",
      "  use_cutout: False\n",
      "  use_random_erasing: False\n",
      "  use_dual_cutout: False\n",
      "  use_mixup: False\n",
      "  use_ricap: False\n",
      "  use_cutmix: False\n",
      "  use_label_smoothing: False\n",
      "  random_crop:\n",
      "    padding: 4\n",
      "    fill: 0\n",
      "    padding_mode: constant\n",
      "  random_horizontal_flip:\n",
      "    prob: 0.5\n",
      "  cutout:\n",
      "    prob: 1.0\n",
      "    mask_size: 16\n",
      "    cut_inside: False\n",
      "    mask_color: 0\n",
      "    dual_cutout_alpha: 0.1\n",
      "  random_erasing:\n",
      "    prob: 0.5\n",
      "    area_ratio_range: [0.02, 0.4]\n",
      "    min_aspect_ratio: 0.3\n",
      "    max_attempt: 20\n",
      "  mixup:\n",
      "    alpha: 1.0\n",
      "  ricap:\n",
      "    beta: 0.3\n",
      "  cutmix:\n",
      "    alpha: 1.0\n",
      "  label_smoothing:\n",
      "    epsilon: 0.1\n",
      "tta:\n",
      "  use_resize: False\n",
      "  use_center_crop: False\n",
      "  resize: 256\n",
      "test:\n",
      "  checkpoint: ''\n",
      "  output_dir: ''\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    pin_memory: False\n",
      "\u001b[32m[2020-07-13 12:21:03] __main__ INFO: \u001b[0menv_info:\n",
      "  pytorch_version: 1.4.0\n",
      "  cuda_version: 10.1\n",
      "  cudnn_version: 7603\n",
      "  num_gpus: 1\n",
      "  gpu_name: Tesla K80\n",
      "  gpu_capability: 3.7\n",
      "Files already downloaded and verified\n",
      "\u001b[32m[2020-07-13 12:21:07] __main__ INFO: \u001b[0mMACs  : 2.75G\n",
      "\u001b[32m[2020-07-13 12:21:07] __main__ INFO: \u001b[0m#params: 17.56M\n",
      "Selected optimization level O0:  Pure FP32 training.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n",
      "\u001b[32m[2020-07-13 12:21:07] __main__ INFO: \u001b[0mVal 0\n",
      "\u001b[32m[2020-07-13 12:21:33] __main__ INFO: \u001b[0mEpoch 0 loss 0.2277 acc@1 0.9380 acc@5 0.9940\n",
      "\u001b[32m[2020-07-13 12:21:33] __main__ INFO: \u001b[0mElapsed 26.02\n",
      "\u001b[32m[2020-07-13 12:21:33] __main__ INFO: \u001b[0mTrain 1 0\n",
      "\u001b[32m[2020-07-13 12:24:04] __main__ INFO: \u001b[0mEpoch 1 Step 100/351 lr 0.001000 loss 0.0113 (0.0393) acc@1 1.0000 (0.9895) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-13 12:26:29] __main__ INFO: \u001b[0mEpoch 1 Step 200/351 lr 0.001000 loss 0.0171 (0.0377) acc@1 1.0000 (0.9889) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-13 12:28:53] __main__ INFO: \u001b[0mEpoch 1 Step 300/351 lr 0.001000 loss 0.0068 (0.0361) acc@1 1.0000 (0.9891) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-13 12:30:07] __main__ INFO: \u001b[0mEpoch 1 Step 351/351 lr 0.001000 loss 0.0421 (0.0350) acc@1 0.9844 (0.9893) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-13 12:30:07] __main__ INFO: \u001b[0mElapsed 513.83\n",
      "\u001b[32m[2020-07-13 12:30:07] __main__ INFO: \u001b[0mVal 1\n",
      "\u001b[32m[2020-07-13 12:30:25] __main__ INFO: \u001b[0mEpoch 1 loss 0.1429 acc@1 0.9580 acc@5 0.9986\n",
      "\u001b[32m[2020-07-13 12:30:25] __main__ INFO: \u001b[0mElapsed 18.04\n",
      "\u001b[32m[2020-07-13 12:30:25] __main__ INFO: \u001b[0mTrain 2 351\n",
      "\u001b[32m[2020-07-13 12:32:49] __main__ INFO: \u001b[0mEpoch 2 Step 100/351 lr 0.001000 loss 0.0169 (0.0163) acc@1 0.9922 (0.9949) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:35:13] __main__ INFO: \u001b[0mEpoch 2 Step 200/351 lr 0.001000 loss 0.0065 (0.0163) acc@1 1.0000 (0.9950) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:37:37] __main__ INFO: \u001b[0mEpoch 2 Step 300/351 lr 0.001000 loss 0.0167 (0.0172) acc@1 0.9922 (0.9946) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:38:50] __main__ INFO: \u001b[0mEpoch 2 Step 351/351 lr 0.001000 loss 0.0460 (0.0175) acc@1 0.9922 (0.9944) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:38:50] __main__ INFO: \u001b[0mElapsed 505.47\n",
      "\u001b[32m[2020-07-13 12:38:50] __main__ INFO: \u001b[0mVal 2\n",
      "\u001b[32m[2020-07-13 12:39:08] __main__ INFO: \u001b[0mEpoch 2 loss 0.1646 acc@1 0.9568 acc@5 0.9988\n",
      "\u001b[32m[2020-07-13 12:39:08] __main__ INFO: \u001b[0mElapsed 18.00\n",
      "\u001b[32m[2020-07-13 12:39:08] __main__ INFO: \u001b[0mTrain 3 702\n",
      "\u001b[32m[2020-07-13 12:41:32] __main__ INFO: \u001b[0mEpoch 3 Step 100/351 lr 0.001000 loss 0.0060 (0.0157) acc@1 1.0000 (0.9949) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-13 12:43:56] __main__ INFO: \u001b[0mEpoch 3 Step 200/351 lr 0.001000 loss 0.0050 (0.0148) acc@1 1.0000 (0.9956) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:46:20] __main__ INFO: \u001b[0mEpoch 3 Step 300/351 lr 0.001000 loss 0.0287 (0.0139) acc@1 0.9844 (0.9959) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:47:34] __main__ INFO: \u001b[0mEpoch 3 Step 351/351 lr 0.001000 loss 0.0109 (0.0143) acc@1 1.0000 (0.9958) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:47:34] __main__ INFO: \u001b[0mElapsed 505.65\n",
      "\u001b[32m[2020-07-13 12:47:34] __main__ INFO: \u001b[0mVal 3\n",
      "\u001b[32m[2020-07-13 12:47:52] __main__ INFO: \u001b[0mEpoch 3 loss 0.2038 acc@1 0.9484 acc@5 0.9984\n",
      "\u001b[32m[2020-07-13 12:47:52] __main__ INFO: \u001b[0mElapsed 18.01\n",
      "\u001b[32m[2020-07-13 12:47:52] __main__ INFO: \u001b[0mTrain 4 1053\n",
      "\u001b[32m[2020-07-13 12:50:16] __main__ INFO: \u001b[0mEpoch 4 Step 100/351 lr 0.001000 loss 0.0068 (0.0114) acc@1 1.0000 (0.9966) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:52:40] __main__ INFO: \u001b[0mEpoch 4 Step 200/351 lr 0.001000 loss 0.0049 (0.0118) acc@1 1.0000 (0.9964) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:55:04] __main__ INFO: \u001b[0mEpoch 4 Step 300/351 lr 0.001000 loss 0.0036 (0.0107) acc@1 1.0000 (0.9968) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:56:18] __main__ INFO: \u001b[0mEpoch 4 Step 351/351 lr 0.001000 loss 0.0229 (0.0107) acc@1 0.9922 (0.9968) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 12:56:18] __main__ INFO: \u001b[0mElapsed 506.03\n",
      "\u001b[32m[2020-07-13 12:56:18] __main__ INFO: \u001b[0mVal 4\n",
      "\u001b[32m[2020-07-13 12:56:36] __main__ INFO: \u001b[0mEpoch 4 loss 0.1714 acc@1 0.9592 acc@5 0.9984\n",
      "\u001b[32m[2020-07-13 12:56:36] __main__ INFO: \u001b[0mElapsed 18.09\n",
      "\u001b[32m[2020-07-13 12:56:36] __main__ INFO: \u001b[0mTrain 5 1404\n",
      "\u001b[32m[2020-07-13 12:59:01] __main__ INFO: \u001b[0mEpoch 5 Step 100/351 lr 0.001000 loss 0.0022 (0.0097) acc@1 1.0000 (0.9970) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:01:25] __main__ INFO: \u001b[0mEpoch 5 Step 200/351 lr 0.001000 loss 0.0021 (0.0091) acc@1 1.0000 (0.9972) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:03:50] __main__ INFO: \u001b[0mEpoch 5 Step 300/351 lr 0.001000 loss 0.0012 (0.0085) acc@1 1.0000 (0.9974) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:05:04] __main__ INFO: \u001b[0mEpoch 5 Step 351/351 lr 0.001000 loss 0.0016 (0.0085) acc@1 1.0000 (0.9975) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:05:04] __main__ INFO: \u001b[0mElapsed 508.49\n",
      "\u001b[32m[2020-07-13 13:05:04] __main__ INFO: \u001b[0mVal 5\n",
      "\u001b[32m[2020-07-13 13:05:22] __main__ INFO: \u001b[0mEpoch 5 loss 0.1683 acc@1 0.9576 acc@5 0.9986\n",
      "\u001b[32m[2020-07-13 13:05:22] __main__ INFO: \u001b[0mElapsed 18.05\n",
      "\u001b[32m[2020-07-13 13:05:22] __main__ INFO: \u001b[0mTrain 6 1755\n",
      "\u001b[32m[2020-07-13 13:07:47] __main__ INFO: \u001b[0mEpoch 6 Step 100/351 lr 0.001000 loss 0.0103 (0.0055) acc@1 0.9922 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:10:12] __main__ INFO: \u001b[0mEpoch 6 Step 200/351 lr 0.001000 loss 0.0057 (0.0059) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:12:36] __main__ INFO: \u001b[0mEpoch 6 Step 300/351 lr 0.001000 loss 0.0050 (0.0061) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:13:50] __main__ INFO: \u001b[0mEpoch 6 Step 351/351 lr 0.001000 loss 0.0028 (0.0062) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:13:50] __main__ INFO: \u001b[0mElapsed 507.93\n",
      "\u001b[32m[2020-07-13 13:13:50] __main__ INFO: \u001b[0mVal 6\n",
      "\u001b[32m[2020-07-13 13:14:09] __main__ INFO: \u001b[0mEpoch 6 loss 0.1717 acc@1 0.9596 acc@5 0.9982\n",
      "\u001b[32m[2020-07-13 13:14:09] __main__ INFO: \u001b[0mElapsed 18.14\n",
      "\u001b[32m[2020-07-13 13:14:09] __main__ INFO: \u001b[0mTrain 7 2106\n",
      "\u001b[32m[2020-07-13 13:16:33] __main__ INFO: \u001b[0mEpoch 7 Step 100/351 lr 0.001000 loss 0.0019 (0.0060) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:18:58] __main__ INFO: \u001b[0mEpoch 7 Step 200/351 lr 0.001000 loss 0.0013 (0.0051) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:21:23] __main__ INFO: \u001b[0mEpoch 7 Step 300/351 lr 0.001000 loss 0.0029 (0.0054) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:22:37] __main__ INFO: \u001b[0mEpoch 7 Step 351/351 lr 0.001000 loss 0.0013 (0.0055) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:22:37] __main__ INFO: \u001b[0mElapsed 508.74\n",
      "\u001b[32m[2020-07-13 13:22:37] __main__ INFO: \u001b[0mVal 7\n",
      "\u001b[32m[2020-07-13 13:22:55] __main__ INFO: \u001b[0mEpoch 7 loss 0.1690 acc@1 0.9604 acc@5 0.9984\n",
      "\u001b[32m[2020-07-13 13:22:55] __main__ INFO: \u001b[0mElapsed 18.14\n",
      "\u001b[32m[2020-07-13 13:22:55] __main__ INFO: \u001b[0mTrain 8 2457\n",
      "\u001b[32m[2020-07-13 13:25:20] __main__ INFO: \u001b[0mEpoch 8 Step 100/351 lr 0.001000 loss 0.0027 (0.0070) acc@1 1.0000 (0.9983) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:27:45] __main__ INFO: \u001b[0mEpoch 8 Step 200/351 lr 0.001000 loss 0.0026 (0.0066) acc@1 1.0000 (0.9982) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:30:10] __main__ INFO: \u001b[0mEpoch 8 Step 300/351 lr 0.001000 loss 0.0034 (0.0061) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:31:24] __main__ INFO: \u001b[0mEpoch 8 Step 351/351 lr 0.001000 loss 0.0008 (0.0059) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:31:24] __main__ INFO: \u001b[0mElapsed 508.73\n",
      "\u001b[32m[2020-07-13 13:31:24] __main__ INFO: \u001b[0mVal 8\n",
      "\u001b[32m[2020-07-13 13:31:42] __main__ INFO: \u001b[0mEpoch 8 loss 0.1703 acc@1 0.9614 acc@5 0.9984\n",
      "\u001b[32m[2020-07-13 13:31:42] __main__ INFO: \u001b[0mElapsed 18.10\n",
      "\u001b[32m[2020-07-13 13:31:42] __main__ INFO: \u001b[0mTrain 9 2808\n",
      "\u001b[32m[2020-07-13 13:34:08] __main__ INFO: \u001b[0mEpoch 9 Step 100/351 lr 0.001000 loss 0.0017 (0.0040) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:36:33] __main__ INFO: \u001b[0mEpoch 9 Step 200/351 lr 0.001000 loss 0.0017 (0.0043) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:38:58] __main__ INFO: \u001b[0mEpoch 9 Step 300/351 lr 0.001000 loss 0.0030 (0.0045) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:40:11] __main__ INFO: \u001b[0mEpoch 9 Step 351/351 lr 0.001000 loss 0.0025 (0.0045) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:40:11] __main__ INFO: \u001b[0mElapsed 508.88\n",
      "\u001b[32m[2020-07-13 13:40:11] __main__ INFO: \u001b[0mVal 9\n",
      "\u001b[32m[2020-07-13 13:40:29] __main__ INFO: \u001b[0mEpoch 9 loss 0.1876 acc@1 0.9582 acc@5 0.9982\n",
      "\u001b[32m[2020-07-13 13:40:29] __main__ INFO: \u001b[0mElapsed 18.01\n",
      "\u001b[32m[2020-07-13 13:40:29] __main__ INFO: \u001b[0mTrain 10 3159\n",
      "\u001b[32m[2020-07-13 13:42:54] __main__ INFO: \u001b[0mEpoch 10 Step 100/351 lr 0.001000 loss 0.0020 (0.0030) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:45:19] __main__ INFO: \u001b[0mEpoch 10 Step 200/351 lr 0.001000 loss 0.0008 (0.0030) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:47:44] __main__ INFO: \u001b[0mEpoch 10 Step 300/351 lr 0.001000 loss 0.0028 (0.0034) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:48:58] __main__ INFO: \u001b[0mEpoch 10 Step 351/351 lr 0.001000 loss 0.0007 (0.0033) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:48:58] __main__ INFO: \u001b[0mElapsed 508.59\n",
      "\u001b[32m[2020-07-13 13:48:58] __main__ INFO: \u001b[0mVal 10\n",
      "\u001b[32m[2020-07-13 13:49:16] __main__ INFO: \u001b[0mEpoch 10 loss 0.1699 acc@1 0.9622 acc@5 0.9986\n",
      "\u001b[32m[2020-07-13 13:49:16] __main__ INFO: \u001b[0mElapsed 18.07\n",
      "\u001b[32m[2020-07-13 13:49:16] __main__ INFO: \u001b[0mTrain 11 3510\n",
      "\u001b[32m[2020-07-13 13:51:41] __main__ INFO: \u001b[0mEpoch 11 Step 100/351 lr 0.001000 loss 0.0017 (0.0030) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:54:05] __main__ INFO: \u001b[0mEpoch 11 Step 200/351 lr 0.001000 loss 0.0011 (0.0034) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:56:30] __main__ INFO: \u001b[0mEpoch 11 Step 300/351 lr 0.001000 loss 0.0015 (0.0034) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:57:45] __main__ INFO: \u001b[0mEpoch 11 Step 351/351 lr 0.001000 loss 0.0061 (0.0036) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 13:57:45] __main__ INFO: \u001b[0mElapsed 508.75\n",
      "\u001b[32m[2020-07-13 13:57:45] __main__ INFO: \u001b[0mVal 11\n",
      "\u001b[32m[2020-07-13 13:58:03] __main__ INFO: \u001b[0mEpoch 11 loss 0.1879 acc@1 0.9564 acc@5 0.9984\n",
      "\u001b[32m[2020-07-13 13:58:03] __main__ INFO: \u001b[0mElapsed 18.15\n",
      "\u001b[32m[2020-07-13 13:58:03] __main__ INFO: \u001b[0mTrain 12 3861\n",
      "\u001b[32m[2020-07-13 14:00:28] __main__ INFO: \u001b[0mEpoch 12 Step 100/351 lr 0.001000 loss 0.0017 (0.0031) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:02:53] __main__ INFO: \u001b[0mEpoch 12 Step 200/351 lr 0.001000 loss 0.0013 (0.0029) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:05:17] __main__ INFO: \u001b[0mEpoch 12 Step 300/351 lr 0.001000 loss 0.0011 (0.0030) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:06:31] __main__ INFO: \u001b[0mEpoch 12 Step 351/351 lr 0.001000 loss 0.0013 (0.0031) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:06:31] __main__ INFO: \u001b[0mElapsed 508.55\n",
      "\u001b[32m[2020-07-13 14:06:31] __main__ INFO: \u001b[0mVal 12\n",
      "\u001b[32m[2020-07-13 14:06:49] __main__ INFO: \u001b[0mEpoch 12 loss 0.1771 acc@1 0.9602 acc@5 0.9986\n",
      "\u001b[32m[2020-07-13 14:06:49] __main__ INFO: \u001b[0mElapsed 18.03\n",
      "\u001b[32m[2020-07-13 14:06:49] __main__ INFO: \u001b[0mTrain 13 4212\n",
      "\u001b[32m[2020-07-13 14:09:14] __main__ INFO: \u001b[0mEpoch 13 Step 100/351 lr 0.001000 loss 0.0023 (0.0019) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:11:38] __main__ INFO: \u001b[0mEpoch 13 Step 200/351 lr 0.001000 loss 0.0011 (0.0019) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:14:04] __main__ INFO: \u001b[0mEpoch 13 Step 300/351 lr 0.001000 loss 0.0007 (0.0020) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:15:17] __main__ INFO: \u001b[0mEpoch 13 Step 351/351 lr 0.001000 loss 0.0237 (0.0021) acc@1 0.9922 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:15:17] __main__ INFO: \u001b[0mElapsed 508.17\n",
      "\u001b[32m[2020-07-13 14:15:17] __main__ INFO: \u001b[0mVal 13\n",
      "\u001b[32m[2020-07-13 14:15:36] __main__ INFO: \u001b[0mEpoch 13 loss 0.1704 acc@1 0.9622 acc@5 0.9990\n",
      "\u001b[32m[2020-07-13 14:15:36] __main__ INFO: \u001b[0mElapsed 18.09\n",
      "\u001b[32m[2020-07-13 14:15:36] __main__ INFO: \u001b[0mTrain 14 4563\n",
      "\u001b[32m[2020-07-13 14:18:00] __main__ INFO: \u001b[0mEpoch 14 Step 100/351 lr 0.001000 loss 0.0020 (0.0027) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:20:25] __main__ INFO: \u001b[0mEpoch 14 Step 200/351 lr 0.001000 loss 0.0011 (0.0025) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:22:50] __main__ INFO: \u001b[0mEpoch 14 Step 300/351 lr 0.001000 loss 0.0025 (0.0025) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:24:04] __main__ INFO: \u001b[0mEpoch 14 Step 351/351 lr 0.001000 loss 0.0006 (0.0027) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:24:04] __main__ INFO: \u001b[0mElapsed 508.77\n",
      "\u001b[32m[2020-07-13 14:24:04] __main__ INFO: \u001b[0mVal 14\n",
      "\u001b[32m[2020-07-13 14:24:22] __main__ INFO: \u001b[0mEpoch 14 loss 0.1847 acc@1 0.9578 acc@5 0.9988\n",
      "\u001b[32m[2020-07-13 14:24:22] __main__ INFO: \u001b[0mElapsed 18.10\n",
      "\u001b[32m[2020-07-13 14:24:22] __main__ INFO: \u001b[0mTrain 15 4914\n",
      "\u001b[32m[2020-07-13 14:26:47] __main__ INFO: \u001b[0mEpoch 15 Step 100/351 lr 0.001000 loss 0.0035 (0.0024) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:29:13] __main__ INFO: \u001b[0mEpoch 15 Step 200/351 lr 0.001000 loss 0.0013 (0.0026) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:31:37] __main__ INFO: \u001b[0mEpoch 15 Step 300/351 lr 0.001000 loss 0.0027 (0.0027) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:32:51] __main__ INFO: \u001b[0mEpoch 15 Step 351/351 lr 0.001000 loss 0.0019 (0.0030) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:32:51] __main__ INFO: \u001b[0mElapsed 508.69\n",
      "\u001b[32m[2020-07-13 14:32:51] __main__ INFO: \u001b[0mVal 15\n",
      "\u001b[32m[2020-07-13 14:33:09] __main__ INFO: \u001b[0mEpoch 15 loss 0.1837 acc@1 0.9560 acc@5 0.9988\n",
      "\u001b[32m[2020-07-13 14:33:09] __main__ INFO: \u001b[0mElapsed 18.10\n",
      "\u001b[32m[2020-07-13 14:33:09] __main__ INFO: \u001b[0mTrain 16 5265\n",
      "\u001b[32m[2020-07-13 14:35:34] __main__ INFO: \u001b[0mEpoch 16 Step 100/351 lr 0.001000 loss 0.0032 (0.0028) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:37:59] __main__ INFO: \u001b[0mEpoch 16 Step 200/351 lr 0.001000 loss 0.0011 (0.0030) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:40:24] __main__ INFO: \u001b[0mEpoch 16 Step 300/351 lr 0.001000 loss 0.0014 (0.0028) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:41:37] __main__ INFO: \u001b[0mEpoch 16 Step 351/351 lr 0.001000 loss 0.0018 (0.0027) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:41:37] __main__ INFO: \u001b[0mElapsed 507.97\n",
      "\u001b[32m[2020-07-13 14:41:37] __main__ INFO: \u001b[0mVal 16\n",
      "\u001b[32m[2020-07-13 14:41:55] __main__ INFO: \u001b[0mEpoch 16 loss 0.1704 acc@1 0.9632 acc@5 0.9986\n",
      "\u001b[32m[2020-07-13 14:41:55] __main__ INFO: \u001b[0mElapsed 18.06\n",
      "\u001b[32m[2020-07-13 14:41:55] __main__ INFO: \u001b[0mTrain 17 5616\n",
      "\u001b[32m[2020-07-13 14:44:20] __main__ INFO: \u001b[0mEpoch 17 Step 100/351 lr 0.001000 loss 0.0010 (0.0029) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:46:44] __main__ INFO: \u001b[0mEpoch 17 Step 200/351 lr 0.001000 loss 0.0009 (0.0026) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:49:09] __main__ INFO: \u001b[0mEpoch 17 Step 300/351 lr 0.001000 loss 0.0009 (0.0025) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:50:23] __main__ INFO: \u001b[0mEpoch 17 Step 351/351 lr 0.001000 loss 0.0032 (0.0027) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:50:23] __main__ INFO: \u001b[0mElapsed 507.95\n",
      "\u001b[32m[2020-07-13 14:50:23] __main__ INFO: \u001b[0mVal 17\n",
      "\u001b[32m[2020-07-13 14:50:41] __main__ INFO: \u001b[0mEpoch 17 loss 0.1697 acc@1 0.9614 acc@5 0.9990\n",
      "\u001b[32m[2020-07-13 14:50:41] __main__ INFO: \u001b[0mElapsed 18.10\n",
      "\u001b[32m[2020-07-13 14:50:41] __main__ INFO: \u001b[0mTrain 18 5967\n",
      "\u001b[32m[2020-07-13 14:53:06] __main__ INFO: \u001b[0mEpoch 18 Step 100/351 lr 0.001000 loss 0.0197 (0.0038) acc@1 0.9844 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:55:31] __main__ INFO: \u001b[0mEpoch 18 Step 200/351 lr 0.001000 loss 0.0007 (0.0029) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:57:55] __main__ INFO: \u001b[0mEpoch 18 Step 300/351 lr 0.001000 loss 0.0008 (0.0026) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:59:09] __main__ INFO: \u001b[0mEpoch 18 Step 351/351 lr 0.001000 loss 0.0011 (0.0027) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 14:59:09] __main__ INFO: \u001b[0mElapsed 507.24\n",
      "\u001b[32m[2020-07-13 14:59:09] __main__ INFO: \u001b[0mVal 18\n",
      "\u001b[32m[2020-07-13 14:59:27] __main__ INFO: \u001b[0mEpoch 18 loss 0.1843 acc@1 0.9580 acc@5 0.9986\n",
      "\u001b[32m[2020-07-13 14:59:27] __main__ INFO: \u001b[0mElapsed 18.06\n",
      "\u001b[32m[2020-07-13 14:59:27] __main__ INFO: \u001b[0mTrain 19 6318\n",
      "\u001b[32m[2020-07-13 15:01:51] __main__ INFO: \u001b[0mEpoch 19 Step 100/351 lr 0.001000 loss 0.0012 (0.0035) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 15:04:16] __main__ INFO: \u001b[0mEpoch 19 Step 200/351 lr 0.001000 loss 0.0007 (0.0029) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 15:06:40] __main__ INFO: \u001b[0mEpoch 19 Step 300/351 lr 0.001000 loss 0.0042 (0.0026) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 15:07:54] __main__ INFO: \u001b[0mEpoch 19 Step 351/351 lr 0.001000 loss 0.0008 (0.0027) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 15:07:54] __main__ INFO: \u001b[0mElapsed 506.93\n",
      "\u001b[32m[2020-07-13 15:07:54] __main__ INFO: \u001b[0mVal 19\n",
      "\u001b[32m[2020-07-13 15:08:12] __main__ INFO: \u001b[0mEpoch 19 loss 0.1709 acc@1 0.9622 acc@5 0.9986\n",
      "\u001b[32m[2020-07-13 15:08:12] __main__ INFO: \u001b[0mElapsed 18.08\n",
      "\u001b[32m[2020-07-13 15:08:12] __main__ INFO: \u001b[0mTrain 20 6669\n",
      "\u001b[32m[2020-07-13 15:10:36] __main__ INFO: \u001b[0mEpoch 20 Step 100/351 lr 0.001000 loss 0.0021 (0.0028) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 15:13:00] __main__ INFO: \u001b[0mEpoch 20 Step 200/351 lr 0.001000 loss 0.0022 (0.0025) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 15:15:24] __main__ INFO: \u001b[0mEpoch 20 Step 300/351 lr 0.001000 loss 0.0012 (0.0024) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 15:16:38] __main__ INFO: \u001b[0mEpoch 20 Step 351/351 lr 0.001000 loss 0.0020 (0.0023) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 15:16:38] __main__ INFO: \u001b[0mElapsed 506.15\n",
      "\u001b[32m[2020-07-13 15:16:38] __main__ INFO: \u001b[0mVal 20\n",
      "\u001b[32m[2020-07-13 15:16:56] __main__ INFO: \u001b[0mEpoch 20 loss 0.1748 acc@1 0.9604 acc@5 0.9984\n",
      "\u001b[32m[2020-07-13 15:16:56] __main__ INFO: \u001b[0mElapsed 18.05\n",
      "\u001b[32m[2020-07-13 15:16:56] __main__ INFO: \u001b[0mTrain 21 7020\n",
      "\u001b[32m[2020-07-13 15:19:20] __main__ INFO: \u001b[0mEpoch 21 Step 100/351 lr 0.001000 loss 0.0009 (0.0014) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 15:21:44] __main__ INFO: \u001b[0mEpoch 21 Step 200/351 lr 0.001000 loss 0.0009 (0.0014) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 15:24:09] __main__ INFO: \u001b[0mEpoch 21 Step 300/351 lr 0.001000 loss 0.0007 (0.0014) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 15:25:22] __main__ INFO: \u001b[0mEpoch 21 Step 351/351 lr 0.001000 loss 0.0005 (0.0015) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 15:25:22] __main__ INFO: \u001b[0mElapsed 506.55\n",
      "\u001b[32m[2020-07-13 15:25:22] __main__ INFO: \u001b[0mVal 21\n",
      "\u001b[32m[2020-07-13 15:25:40] __main__ INFO: \u001b[0mEpoch 21 loss 0.1721 acc@1 0.9608 acc@5 0.9984\n",
      "\u001b[32m[2020-07-13 15:25:40] __main__ INFO: \u001b[0mElapsed 18.09\n",
      "\u001b[32m[2020-07-13 15:25:40] __main__ INFO: \u001b[0mTrain 22 7371\n",
      "\u001b[32m[2020-07-13 15:28:05] __main__ INFO: \u001b[0mEpoch 22 Step 100/351 lr 0.001000 loss 0.0017 (0.0012) acc@1 1.0000 (1.0000) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 15:30:30] __main__ INFO: \u001b[0mEpoch 22 Step 200/351 lr 0.001000 loss 0.0011 (0.0016) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 15:32:54] __main__ INFO: \u001b[0mEpoch 22 Step 300/351 lr 0.001000 loss 0.0035 (0.0016) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 15:34:08] __main__ INFO: \u001b[0mEpoch 22 Step 351/351 lr 0.001000 loss 0.0008 (0.0017) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 15:34:08] __main__ INFO: \u001b[0mElapsed 507.33\n",
      "\u001b[32m[2020-07-13 15:34:08] __main__ INFO: \u001b[0mVal 22\n",
      "\u001b[32m[2020-07-13 15:34:26] __main__ INFO: \u001b[0mEpoch 22 loss 0.1692 acc@1 0.9634 acc@5 0.9978\n",
      "\u001b[32m[2020-07-13 15:34:26] __main__ INFO: \u001b[0mElapsed 18.03\n",
      "\u001b[32m[2020-07-13 15:34:26] __main__ INFO: \u001b[0mTrain 23 7722\n",
      "\u001b[32m[2020-07-13 15:36:50] __main__ INFO: \u001b[0mEpoch 23 Step 100/351 lr 0.001000 loss 0.0005 (0.0018) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 15:39:15] __main__ INFO: \u001b[0mEpoch 23 Step 200/351 lr 0.001000 loss 0.0038 (0.0017) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 15:41:40] __main__ INFO: \u001b[0mEpoch 23 Step 300/351 lr 0.001000 loss 0.0006 (0.0017) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 15:42:53] __main__ INFO: \u001b[0mEpoch 23 Step 351/351 lr 0.001000 loss 0.0006 (0.0016) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 15:42:53] __main__ INFO: \u001b[0mElapsed 507.55\n",
      "\u001b[32m[2020-07-13 15:42:53] __main__ INFO: \u001b[0mVal 23\n",
      "\u001b[32m[2020-07-13 15:43:11] __main__ INFO: \u001b[0mEpoch 23 loss 0.1734 acc@1 0.9610 acc@5 0.9982\n",
      "\u001b[32m[2020-07-13 15:43:11] __main__ INFO: \u001b[0mElapsed 18.04\n",
      "\u001b[32m[2020-07-13 15:43:11] __main__ INFO: \u001b[0mTrain 24 8073\n",
      "\u001b[32m[2020-07-13 15:45:36] __main__ INFO: \u001b[0mEpoch 24 Step 100/351 lr 0.001000 loss 0.0029 (0.0011) acc@1 1.0000 (1.0000) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 15:48:00] __main__ INFO: \u001b[0mEpoch 24 Step 200/351 lr 0.001000 loss 0.0013 (0.0012) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 15:50:24] __main__ INFO: \u001b[0mEpoch 24 Step 300/351 lr 0.001000 loss 0.0007 (0.0017) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 15:51:38] __main__ INFO: \u001b[0mEpoch 24 Step 351/351 lr 0.001000 loss 0.0053 (0.0020) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 15:51:38] __main__ INFO: \u001b[0mElapsed 506.41\n",
      "\u001b[32m[2020-07-13 15:51:38] __main__ INFO: \u001b[0mVal 24\n",
      "\u001b[32m[2020-07-13 15:51:56] __main__ INFO: \u001b[0mEpoch 24 loss 0.1885 acc@1 0.9574 acc@5 0.9980\n",
      "\u001b[32m[2020-07-13 15:51:56] __main__ INFO: \u001b[0mElapsed 18.02\n",
      "\u001b[32m[2020-07-13 15:51:56] __main__ INFO: \u001b[0mTrain 25 8424\n",
      "\u001b[32m[2020-07-13 15:54:20] __main__ INFO: \u001b[0mEpoch 25 Step 100/351 lr 0.001000 loss 0.0007 (0.0015) acc@1 1.0000 (1.0000) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 15:56:44] __main__ INFO: \u001b[0mEpoch 25 Step 200/351 lr 0.001000 loss 0.0012 (0.0016) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 15:59:09] __main__ INFO: \u001b[0mEpoch 25 Step 300/351 lr 0.001000 loss 0.0004 (0.0014) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:00:22] __main__ INFO: \u001b[0mEpoch 25 Step 351/351 lr 0.001000 loss 0.0006 (0.0014) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:00:22] __main__ INFO: \u001b[0mElapsed 506.23\n",
      "\u001b[32m[2020-07-13 16:00:22] __main__ INFO: \u001b[0mVal 25\n",
      "\u001b[32m[2020-07-13 16:00:40] __main__ INFO: \u001b[0mEpoch 25 loss 0.1715 acc@1 0.9630 acc@5 0.9984\n",
      "\u001b[32m[2020-07-13 16:00:40] __main__ INFO: \u001b[0mElapsed 18.12\n",
      "\u001b[32m[2020-07-13 16:00:40] __main__ INFO: \u001b[0mTrain 26 8775\n",
      "\u001b[32m[2020-07-13 16:03:05] __main__ INFO: \u001b[0mEpoch 26 Step 100/351 lr 0.001000 loss 0.0006 (0.0011) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:05:30] __main__ INFO: \u001b[0mEpoch 26 Step 200/351 lr 0.001000 loss 0.0012 (0.0010) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:07:54] __main__ INFO: \u001b[0mEpoch 26 Step 300/351 lr 0.001000 loss 0.0029 (0.0012) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:09:08] __main__ INFO: \u001b[0mEpoch 26 Step 351/351 lr 0.001000 loss 0.0007 (0.0011) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:09:08] __main__ INFO: \u001b[0mElapsed 507.51\n",
      "\u001b[32m[2020-07-13 16:09:08] __main__ INFO: \u001b[0mVal 26\n",
      "\u001b[32m[2020-07-13 16:09:26] __main__ INFO: \u001b[0mEpoch 26 loss 0.1745 acc@1 0.9616 acc@5 0.9988\n",
      "\u001b[32m[2020-07-13 16:09:26] __main__ INFO: \u001b[0mElapsed 18.02\n",
      "\u001b[32m[2020-07-13 16:09:26] __main__ INFO: \u001b[0mTrain 27 9126\n",
      "\u001b[32m[2020-07-13 16:11:50] __main__ INFO: \u001b[0mEpoch 27 Step 100/351 lr 0.001000 loss 0.0003 (0.0009) acc@1 1.0000 (1.0000) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:14:14] __main__ INFO: \u001b[0mEpoch 27 Step 200/351 lr 0.001000 loss 0.0005 (0.0011) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:16:39] __main__ INFO: \u001b[0mEpoch 27 Step 300/351 lr 0.001000 loss 0.0005 (0.0011) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:17:52] __main__ INFO: \u001b[0mEpoch 27 Step 351/351 lr 0.001000 loss 0.0010 (0.0011) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:17:52] __main__ INFO: \u001b[0mElapsed 506.42\n",
      "\u001b[32m[2020-07-13 16:17:52] __main__ INFO: \u001b[0mVal 27\n",
      "\u001b[32m[2020-07-13 16:18:10] __main__ INFO: \u001b[0mEpoch 27 loss 0.1750 acc@1 0.9594 acc@5 0.9984\n",
      "\u001b[32m[2020-07-13 16:18:10] __main__ INFO: \u001b[0mElapsed 18.03\n",
      "\u001b[32m[2020-07-13 16:18:10] __main__ INFO: \u001b[0mTrain 28 9477\n",
      "\u001b[32m[2020-07-13 16:20:35] __main__ INFO: \u001b[0mEpoch 28 Step 100/351 lr 0.001000 loss 0.0020 (0.0012) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:22:59] __main__ INFO: \u001b[0mEpoch 28 Step 200/351 lr 0.001000 loss 0.0004 (0.0011) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:25:23] __main__ INFO: \u001b[0mEpoch 28 Step 300/351 lr 0.001000 loss 0.0005 (0.0011) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:26:37] __main__ INFO: \u001b[0mEpoch 28 Step 351/351 lr 0.001000 loss 0.0005 (0.0011) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:26:37] __main__ INFO: \u001b[0mElapsed 506.51\n",
      "\u001b[32m[2020-07-13 16:26:37] __main__ INFO: \u001b[0mVal 28\n",
      "\u001b[32m[2020-07-13 16:26:55] __main__ INFO: \u001b[0mEpoch 28 loss 0.1693 acc@1 0.9600 acc@5 0.9986\n",
      "\u001b[32m[2020-07-13 16:26:55] __main__ INFO: \u001b[0mElapsed 18.02\n",
      "\u001b[32m[2020-07-13 16:26:55] __main__ INFO: \u001b[0mTrain 29 9828\n",
      "\u001b[32m[2020-07-13 16:29:19] __main__ INFO: \u001b[0mEpoch 29 Step 100/351 lr 0.001000 loss 0.0007 (0.0011) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:31:44] __main__ INFO: \u001b[0mEpoch 29 Step 200/351 lr 0.001000 loss 0.0031 (0.0012) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:34:08] __main__ INFO: \u001b[0mEpoch 29 Step 300/351 lr 0.001000 loss 0.0009 (0.0011) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:35:22] __main__ INFO: \u001b[0mEpoch 29 Step 351/351 lr 0.001000 loss 0.0011 (0.0011) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:35:22] __main__ INFO: \u001b[0mElapsed 506.84\n",
      "\u001b[32m[2020-07-13 16:35:22] __main__ INFO: \u001b[0mVal 29\n",
      "\u001b[32m[2020-07-13 16:35:40] __main__ INFO: \u001b[0mEpoch 29 loss 0.1727 acc@1 0.9616 acc@5 0.9992\n",
      "\u001b[32m[2020-07-13 16:35:40] __main__ INFO: \u001b[0mElapsed 18.08\n",
      "\u001b[32m[2020-07-13 16:35:40] __main__ INFO: \u001b[0mTrain 30 10179\n",
      "\u001b[32m[2020-07-13 16:38:05] __main__ INFO: \u001b[0mEpoch 30 Step 100/351 lr 0.001000 loss 0.0041 (0.0019) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:40:29] __main__ INFO: \u001b[0mEpoch 30 Step 200/351 lr 0.001000 loss 0.0036 (0.0019) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:42:54] __main__ INFO: \u001b[0mEpoch 30 Step 300/351 lr 0.001000 loss 0.0011 (0.0019) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:44:07] __main__ INFO: \u001b[0mEpoch 30 Step 351/351 lr 0.001000 loss 0.0007 (0.0018) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:44:07] __main__ INFO: \u001b[0mElapsed 507.68\n",
      "\u001b[32m[2020-07-13 16:44:07] __main__ INFO: \u001b[0mVal 30\n",
      "\u001b[32m[2020-07-13 16:44:25] __main__ INFO: \u001b[0mEpoch 30 loss 0.1772 acc@1 0.9588 acc@5 0.9984\n",
      "\u001b[32m[2020-07-13 16:44:25] __main__ INFO: \u001b[0mElapsed 18.08\n",
      "\u001b[32m[2020-07-13 16:44:25] __main__ INFO: \u001b[0mTrain 31 10530\n",
      "\u001b[32m[2020-07-13 16:46:50] __main__ INFO: \u001b[0mEpoch 31 Step 100/351 lr 0.001000 loss 0.0020 (0.0017) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:49:15] __main__ INFO: \u001b[0mEpoch 31 Step 200/351 lr 0.001000 loss 0.0006 (0.0013) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:51:39] __main__ INFO: \u001b[0mEpoch 31 Step 300/351 lr 0.001000 loss 0.0005 (0.0015) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:52:52] __main__ INFO: \u001b[0mEpoch 31 Step 351/351 lr 0.001000 loss 0.0010 (0.0015) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:52:52] __main__ INFO: \u001b[0mElapsed 506.86\n",
      "\u001b[32m[2020-07-13 16:52:52] __main__ INFO: \u001b[0mVal 31\n",
      "\u001b[32m[2020-07-13 16:53:10] __main__ INFO: \u001b[0mEpoch 31 loss 0.1709 acc@1 0.9628 acc@5 0.9986\n",
      "\u001b[32m[2020-07-13 16:53:10] __main__ INFO: \u001b[0mElapsed 18.08\n",
      "\u001b[32m[2020-07-13 16:53:10] __main__ INFO: \u001b[0mTrain 32 10881\n",
      "\u001b[32m[2020-07-13 16:55:35] __main__ INFO: \u001b[0mEpoch 32 Step 100/351 lr 0.001000 loss 0.0078 (0.0012) acc@1 0.9922 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:57:59] __main__ INFO: \u001b[0mEpoch 32 Step 200/351 lr 0.001000 loss 0.0011 (0.0015) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:00:23] __main__ INFO: \u001b[0mEpoch 32 Step 300/351 lr 0.001000 loss 0.0018 (0.0018) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:01:37] __main__ INFO: \u001b[0mEpoch 32 Step 351/351 lr 0.001000 loss 0.0006 (0.0018) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:01:37] __main__ INFO: \u001b[0mElapsed 506.57\n",
      "\u001b[32m[2020-07-13 17:01:37] __main__ INFO: \u001b[0mVal 32\n",
      "\u001b[32m[2020-07-13 17:01:55] __main__ INFO: \u001b[0mEpoch 32 loss 0.1724 acc@1 0.9610 acc@5 0.9982\n",
      "\u001b[32m[2020-07-13 17:01:55] __main__ INFO: \u001b[0mElapsed 18.05\n",
      "\u001b[32m[2020-07-13 17:01:55] __main__ INFO: \u001b[0mTrain 33 11232\n",
      "\u001b[32m[2020-07-13 17:04:20] __main__ INFO: \u001b[0mEpoch 33 Step 100/351 lr 0.001000 loss 0.0006 (0.0015) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:06:44] __main__ INFO: \u001b[0mEpoch 33 Step 200/351 lr 0.001000 loss 0.0020 (0.0015) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:09:08] __main__ INFO: \u001b[0mEpoch 33 Step 300/351 lr 0.001000 loss 0.0004 (0.0016) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:10:22] __main__ INFO: \u001b[0mEpoch 33 Step 351/351 lr 0.001000 loss 0.0011 (0.0016) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:10:22] __main__ INFO: \u001b[0mElapsed 507.09\n",
      "\u001b[32m[2020-07-13 17:10:22] __main__ INFO: \u001b[0mVal 33\n",
      "\u001b[32m[2020-07-13 17:10:40] __main__ INFO: \u001b[0mEpoch 33 loss 0.1803 acc@1 0.9604 acc@5 0.9982\n",
      "\u001b[32m[2020-07-13 17:10:40] __main__ INFO: \u001b[0mElapsed 18.04\n",
      "\u001b[32m[2020-07-13 17:10:40] __main__ INFO: \u001b[0mTrain 34 11583\n",
      "\u001b[32m[2020-07-13 17:13:05] __main__ INFO: \u001b[0mEpoch 34 Step 100/351 lr 0.001000 loss 0.0007 (0.0017) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:15:29] __main__ INFO: \u001b[0mEpoch 34 Step 200/351 lr 0.001000 loss 0.0045 (0.0015) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:17:54] __main__ INFO: \u001b[0mEpoch 34 Step 300/351 lr 0.001000 loss 0.0005 (0.0014) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:19:07] __main__ INFO: \u001b[0mEpoch 34 Step 351/351 lr 0.001000 loss 0.0013 (0.0014) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:19:07] __main__ INFO: \u001b[0mElapsed 507.08\n",
      "\u001b[32m[2020-07-13 17:19:07] __main__ INFO: \u001b[0mVal 34\n",
      "\u001b[32m[2020-07-13 17:19:25] __main__ INFO: \u001b[0mEpoch 34 loss 0.1680 acc@1 0.9638 acc@5 0.9982\n",
      "\u001b[32m[2020-07-13 17:19:25] __main__ INFO: \u001b[0mElapsed 18.06\n",
      "\u001b[32m[2020-07-13 17:19:25] __main__ INFO: \u001b[0mTrain 35 11934\n",
      "\u001b[32m[2020-07-13 17:21:50] __main__ INFO: \u001b[0mEpoch 35 Step 100/351 lr 0.001000 loss 0.0007 (0.0011) acc@1 1.0000 (1.0000) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:24:14] __main__ INFO: \u001b[0mEpoch 35 Step 200/351 lr 0.001000 loss 0.0005 (0.0011) acc@1 1.0000 (1.0000) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:26:39] __main__ INFO: \u001b[0mEpoch 35 Step 300/351 lr 0.001000 loss 0.0008 (0.0013) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:27:52] __main__ INFO: \u001b[0mEpoch 35 Step 351/351 lr 0.001000 loss 0.0011 (0.0013) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:27:52] __main__ INFO: \u001b[0mElapsed 506.89\n",
      "\u001b[32m[2020-07-13 17:27:52] __main__ INFO: \u001b[0mVal 35\n",
      "\u001b[32m[2020-07-13 17:28:10] __main__ INFO: \u001b[0mEpoch 35 loss 0.1671 acc@1 0.9632 acc@5 0.9984\n",
      "\u001b[32m[2020-07-13 17:28:10] __main__ INFO: \u001b[0mElapsed 18.04\n",
      "\u001b[32m[2020-07-13 17:28:10] __main__ INFO: \u001b[0mTrain 36 12285\n",
      "\u001b[32m[2020-07-13 17:30:35] __main__ INFO: \u001b[0mEpoch 36 Step 100/351 lr 0.001000 loss 0.0016 (0.0016) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:32:59] __main__ INFO: \u001b[0mEpoch 36 Step 200/351 lr 0.001000 loss 0.0004 (0.0015) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:35:24] __main__ INFO: \u001b[0mEpoch 36 Step 300/351 lr 0.001000 loss 0.0007 (0.0015) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:36:37] __main__ INFO: \u001b[0mEpoch 36 Step 351/351 lr 0.001000 loss 0.0021 (0.0014) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:36:37] __main__ INFO: \u001b[0mElapsed 507.06\n",
      "\u001b[32m[2020-07-13 17:36:37] __main__ INFO: \u001b[0mVal 36\n",
      "\u001b[32m[2020-07-13 17:36:55] __main__ INFO: \u001b[0mEpoch 36 loss 0.1634 acc@1 0.9636 acc@5 0.9986\n",
      "\u001b[32m[2020-07-13 17:36:55] __main__ INFO: \u001b[0mElapsed 18.08\n",
      "\u001b[32m[2020-07-13 17:36:55] __main__ INFO: \u001b[0mTrain 37 12636\n",
      "\u001b[32m[2020-07-13 17:39:20] __main__ INFO: \u001b[0mEpoch 37 Step 100/351 lr 0.001000 loss 0.0005 (0.0012) acc@1 1.0000 (1.0000) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:41:44] __main__ INFO: \u001b[0mEpoch 37 Step 200/351 lr 0.001000 loss 0.0009 (0.0010) acc@1 1.0000 (1.0000) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:44:09] __main__ INFO: \u001b[0mEpoch 37 Step 300/351 lr 0.001000 loss 0.0044 (0.0010) acc@1 1.0000 (1.0000) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:45:23] __main__ INFO: \u001b[0mEpoch 37 Step 351/351 lr 0.001000 loss 0.0015 (0.0009) acc@1 1.0000 (1.0000) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:45:23] __main__ INFO: \u001b[0mElapsed 507.20\n",
      "\u001b[32m[2020-07-13 17:45:23] __main__ INFO: \u001b[0mVal 37\n",
      "\u001b[32m[2020-07-13 17:45:41] __main__ INFO: \u001b[0mEpoch 37 loss 0.1610 acc@1 0.9628 acc@5 0.9984\n",
      "\u001b[32m[2020-07-13 17:45:41] __main__ INFO: \u001b[0mElapsed 18.09\n",
      "\u001b[32m[2020-07-13 17:45:41] __main__ INFO: \u001b[0mTrain 38 12987\n",
      "\u001b[32m[2020-07-13 17:48:05] __main__ INFO: \u001b[0mEpoch 38 Step 100/351 lr 0.001000 loss 0.0010 (0.0010) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:50:30] __main__ INFO: \u001b[0mEpoch 38 Step 200/351 lr 0.001000 loss 0.0007 (0.0010) acc@1 1.0000 (1.0000) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:52:54] __main__ INFO: \u001b[0mEpoch 38 Step 300/351 lr 0.001000 loss 0.0012 (0.0010) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:54:07] __main__ INFO: \u001b[0mEpoch 38 Step 351/351 lr 0.001000 loss 0.0008 (0.0009) acc@1 1.0000 (1.0000) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:54:07] __main__ INFO: \u001b[0mElapsed 506.72\n",
      "\u001b[32m[2020-07-13 17:54:07] __main__ INFO: \u001b[0mVal 38\n",
      "\u001b[32m[2020-07-13 17:54:25] __main__ INFO: \u001b[0mEpoch 38 loss 0.1676 acc@1 0.9612 acc@5 0.9984\n",
      "\u001b[32m[2020-07-13 17:54:25] __main__ INFO: \u001b[0mElapsed 18.02\n",
      "\u001b[32m[2020-07-13 17:54:25] __main__ INFO: \u001b[0mTrain 39 13338\n",
      "\u001b[32m[2020-07-13 17:56:50] __main__ INFO: \u001b[0mEpoch 39 Step 100/351 lr 0.001000 loss 0.0009 (0.0012) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:59:14] __main__ INFO: \u001b[0mEpoch 39 Step 200/351 lr 0.001000 loss 0.0005 (0.0011) acc@1 1.0000 (1.0000) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:01:38] __main__ INFO: \u001b[0mEpoch 39 Step 300/351 lr 0.001000 loss 0.0008 (0.0012) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:02:52] __main__ INFO: \u001b[0mEpoch 39 Step 351/351 lr 0.001000 loss 0.0007 (0.0012) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:02:52] __main__ INFO: \u001b[0mElapsed 506.64\n",
      "\u001b[32m[2020-07-13 18:02:52] __main__ INFO: \u001b[0mVal 39\n",
      "\u001b[32m[2020-07-13 18:03:10] __main__ INFO: \u001b[0mEpoch 39 loss 0.1671 acc@1 0.9614 acc@5 0.9986\n",
      "\u001b[32m[2020-07-13 18:03:10] __main__ INFO: \u001b[0mElapsed 18.06\n",
      "\u001b[32m[2020-07-13 18:03:10] __main__ INFO: \u001b[0mTrain 40 13689\n",
      "\u001b[32m[2020-07-13 18:05:34] __main__ INFO: \u001b[0mEpoch 40 Step 100/351 lr 0.001000 loss 0.0015 (0.0011) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:07:58] __main__ INFO: \u001b[0mEpoch 40 Step 200/351 lr 0.001000 loss 0.0010 (0.0010) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:10:22] __main__ INFO: \u001b[0mEpoch 40 Step 300/351 lr 0.001000 loss 0.0007 (0.0010) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:11:35] __main__ INFO: \u001b[0mEpoch 40 Step 351/351 lr 0.001000 loss 0.0023 (0.0010) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:11:35] __main__ INFO: \u001b[0mElapsed 505.35\n",
      "\u001b[32m[2020-07-13 18:11:35] __main__ INFO: \u001b[0mVal 40\n",
      "\u001b[32m[2020-07-13 18:11:53] __main__ INFO: \u001b[0mEpoch 40 loss 0.1641 acc@1 0.9630 acc@5 0.9982\n",
      "\u001b[32m[2020-07-13 18:11:53] __main__ INFO: \u001b[0mElapsed 18.02\n",
      "\u001b[32m[2020-07-13 18:11:53] __main__ INFO: \u001b[0mTrain 41 14040\n",
      "\u001b[32m[2020-07-13 18:14:18] __main__ INFO: \u001b[0mEpoch 41 Step 100/351 lr 0.001000 loss 0.0005 (0.0008) acc@1 1.0000 (1.0000) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:16:42] __main__ INFO: \u001b[0mEpoch 41 Step 200/351 lr 0.001000 loss 0.0008 (0.0008) acc@1 1.0000 (1.0000) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:19:05] __main__ INFO: \u001b[0mEpoch 41 Step 300/351 lr 0.001000 loss 0.0014 (0.0008) acc@1 1.0000 (1.0000) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:20:19] __main__ INFO: \u001b[0mEpoch 41 Step 351/351 lr 0.001000 loss 0.0006 (0.0008) acc@1 1.0000 (1.0000) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:20:19] __main__ INFO: \u001b[0mElapsed 505.54\n",
      "\u001b[32m[2020-07-13 18:20:19] __main__ INFO: \u001b[0mVal 41\n",
      "\u001b[32m[2020-07-13 18:20:37] __main__ INFO: \u001b[0mEpoch 41 loss 0.1788 acc@1 0.9620 acc@5 0.9988\n",
      "\u001b[32m[2020-07-13 18:20:37] __main__ INFO: \u001b[0mElapsed 18.06\n",
      "\u001b[32m[2020-07-13 18:20:37] __main__ INFO: \u001b[0mTrain 42 14391\n",
      "\u001b[32m[2020-07-13 18:23:02] __main__ INFO: \u001b[0mEpoch 42 Step 100/351 lr 0.001000 loss 0.0007 (0.0010) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:25:26] __main__ INFO: \u001b[0mEpoch 42 Step 200/351 lr 0.001000 loss 0.0005 (0.0009) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:27:50] __main__ INFO: \u001b[0mEpoch 42 Step 300/351 lr 0.001000 loss 0.0015 (0.0009) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:29:04] __main__ INFO: \u001b[0mEpoch 42 Step 351/351 lr 0.001000 loss 0.0009 (0.0009) acc@1 1.0000 (1.0000) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:29:04] __main__ INFO: \u001b[0mElapsed 506.99\n",
      "\u001b[32m[2020-07-13 18:29:04] __main__ INFO: \u001b[0mVal 42\n",
      "\u001b[32m[2020-07-13 18:29:22] __main__ INFO: \u001b[0mEpoch 42 loss 0.1689 acc@1 0.9624 acc@5 0.9982\n",
      "\u001b[32m[2020-07-13 18:29:22] __main__ INFO: \u001b[0mElapsed 18.06\n",
      "\u001b[32m[2020-07-13 18:29:22] __main__ INFO: \u001b[0mTrain 43 14742\n",
      "\u001b[32m[2020-07-13 18:31:47] __main__ INFO: \u001b[0mEpoch 43 Step 100/351 lr 0.001000 loss 0.0016 (0.0007) acc@1 1.0000 (1.0000) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:34:11] __main__ INFO: \u001b[0mEpoch 43 Step 200/351 lr 0.001000 loss 0.0005 (0.0008) acc@1 1.0000 (1.0000) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:36:35] __main__ INFO: \u001b[0mEpoch 43 Step 300/351 lr 0.001000 loss 0.0007 (0.0008) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:37:48] __main__ INFO: \u001b[0mEpoch 43 Step 351/351 lr 0.001000 loss 0.0004 (0.0008) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:37:48] __main__ INFO: \u001b[0mElapsed 506.15\n",
      "\u001b[32m[2020-07-13 18:37:48] __main__ INFO: \u001b[0mVal 43\n",
      "\u001b[32m[2020-07-13 18:38:06] __main__ INFO: \u001b[0mEpoch 43 loss 0.1679 acc@1 0.9620 acc@5 0.9986\n",
      "\u001b[32m[2020-07-13 18:38:06] __main__ INFO: \u001b[0mElapsed 18.09\n",
      "\u001b[32m[2020-07-13 18:38:06] __main__ INFO: \u001b[0mTrain 44 15093\n",
      "\u001b[32m[2020-07-13 18:40:31] __main__ INFO: \u001b[0mEpoch 44 Step 100/351 lr 0.001000 loss 0.0012 (0.0008) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:42:55] __main__ INFO: \u001b[0mEpoch 44 Step 200/351 lr 0.001000 loss 0.0004 (0.0008) acc@1 1.0000 (1.0000) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:45:20] __main__ INFO: \u001b[0mEpoch 44 Step 300/351 lr 0.001000 loss 0.0020 (0.0008) acc@1 1.0000 (1.0000) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:46:33] __main__ INFO: \u001b[0mEpoch 44 Step 351/351 lr 0.001000 loss 0.0005 (0.0008) acc@1 1.0000 (1.0000) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:46:33] __main__ INFO: \u001b[0mElapsed 507.11\n",
      "\u001b[32m[2020-07-13 18:46:33] __main__ INFO: \u001b[0mVal 44\n",
      "\u001b[32m[2020-07-13 18:46:52] __main__ INFO: \u001b[0mEpoch 44 loss 0.1660 acc@1 0.9622 acc@5 0.9984\n",
      "\u001b[32m[2020-07-13 18:46:52] __main__ INFO: \u001b[0mElapsed 18.12\n",
      "\u001b[32m[2020-07-13 18:46:52] __main__ INFO: \u001b[0mTrain 45 15444\n",
      "\u001b[32m[2020-07-13 18:49:16] __main__ INFO: \u001b[0mEpoch 45 Step 100/351 lr 0.001000 loss 0.0015 (0.0012) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:51:40] __main__ INFO: \u001b[0mEpoch 45 Step 200/351 lr 0.001000 loss 0.0012 (0.0011) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:54:05] __main__ INFO: \u001b[0mEpoch 45 Step 300/351 lr 0.001000 loss 0.0005 (0.0011) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:55:18] __main__ INFO: \u001b[0mEpoch 45 Step 351/351 lr 0.001000 loss 0.0015 (0.0010) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:55:18] __main__ INFO: \u001b[0mElapsed 506.38\n",
      "\u001b[32m[2020-07-13 18:55:18] __main__ INFO: \u001b[0mVal 45\n",
      "\u001b[32m[2020-07-13 18:55:36] __main__ INFO: \u001b[0mEpoch 45 loss 0.1612 acc@1 0.9636 acc@5 0.9984\n",
      "\u001b[32m[2020-07-13 18:55:36] __main__ INFO: \u001b[0mElapsed 18.01\n",
      "\u001b[32m[2020-07-13 18:55:36] __main__ INFO: \u001b[0mTrain 46 15795\n",
      "\u001b[32m[2020-07-13 18:58:00] __main__ INFO: \u001b[0mEpoch 46 Step 100/351 lr 0.001000 loss 0.0005 (0.0010) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:00:24] __main__ INFO: \u001b[0mEpoch 46 Step 200/351 lr 0.001000 loss 0.0011 (0.0009) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:02:48] __main__ INFO: \u001b[0mEpoch 46 Step 300/351 lr 0.001000 loss 0.0005 (0.0009) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:04:02] __main__ INFO: \u001b[0mEpoch 46 Step 351/351 lr 0.001000 loss 0.0013 (0.0009) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:04:02] __main__ INFO: \u001b[0mElapsed 505.80\n",
      "\u001b[32m[2020-07-13 19:04:02] __main__ INFO: \u001b[0mVal 46\n",
      "\u001b[32m[2020-07-13 19:04:20] __main__ INFO: \u001b[0mEpoch 46 loss 0.1509 acc@1 0.9638 acc@5 0.9984\n",
      "\u001b[32m[2020-07-13 19:04:20] __main__ INFO: \u001b[0mElapsed 18.02\n",
      "\u001b[32m[2020-07-13 19:04:20] __main__ INFO: \u001b[0mTrain 47 16146\n",
      "\u001b[32m[2020-07-13 19:06:44] __main__ INFO: \u001b[0mEpoch 47 Step 100/351 lr 0.001000 loss 0.0005 (0.0013) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:09:08] __main__ INFO: \u001b[0mEpoch 47 Step 200/351 lr 0.001000 loss 0.0007 (0.0012) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:11:32] __main__ INFO: \u001b[0mEpoch 47 Step 300/351 lr 0.001000 loss 0.0015 (0.0012) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:12:46] __main__ INFO: \u001b[0mEpoch 47 Step 351/351 lr 0.001000 loss 0.0007 (0.0013) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:12:46] __main__ INFO: \u001b[0mElapsed 505.74\n",
      "\u001b[32m[2020-07-13 19:12:46] __main__ INFO: \u001b[0mVal 47\n",
      "\u001b[32m[2020-07-13 19:13:04] __main__ INFO: \u001b[0mEpoch 47 loss 0.1681 acc@1 0.9614 acc@5 0.9982\n",
      "\u001b[32m[2020-07-13 19:13:04] __main__ INFO: \u001b[0mElapsed 18.00\n",
      "\u001b[32m[2020-07-13 19:13:04] __main__ INFO: \u001b[0mTrain 48 16497\n",
      "\u001b[32m[2020-07-13 19:15:28] __main__ INFO: \u001b[0mEpoch 48 Step 100/351 lr 0.001000 loss 0.0018 (0.0017) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:17:51] __main__ INFO: \u001b[0mEpoch 48 Step 200/351 lr 0.001000 loss 0.0009 (0.0017) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:20:15] __main__ INFO: \u001b[0mEpoch 48 Step 300/351 lr 0.001000 loss 0.0008 (0.0015) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:21:29] __main__ INFO: \u001b[0mEpoch 48 Step 351/351 lr 0.001000 loss 0.0010 (0.0016) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:21:29] __main__ INFO: \u001b[0mElapsed 505.18\n",
      "\u001b[32m[2020-07-13 19:21:29] __main__ INFO: \u001b[0mVal 48\n",
      "\u001b[32m[2020-07-13 19:21:47] __main__ INFO: \u001b[0mEpoch 48 loss 0.1802 acc@1 0.9592 acc@5 0.9984\n",
      "\u001b[32m[2020-07-13 19:21:47] __main__ INFO: \u001b[0mElapsed 17.98\n",
      "\u001b[32m[2020-07-13 19:21:47] __main__ INFO: \u001b[0mTrain 49 16848\n",
      "\u001b[32m[2020-07-13 19:24:11] __main__ INFO: \u001b[0mEpoch 49 Step 100/351 lr 0.001000 loss 0.0007 (0.0015) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:26:35] __main__ INFO: \u001b[0mEpoch 49 Step 200/351 lr 0.001000 loss 0.0007 (0.0018) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:28:58] __main__ INFO: \u001b[0mEpoch 49 Step 300/351 lr 0.001000 loss 0.0006 (0.0020) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:30:12] __main__ INFO: \u001b[0mEpoch 49 Step 351/351 lr 0.001000 loss 0.0008 (0.0020) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:30:12] __main__ INFO: \u001b[0mElapsed 505.06\n",
      "\u001b[32m[2020-07-13 19:30:12] __main__ INFO: \u001b[0mVal 49\n",
      "\u001b[32m[2020-07-13 19:30:30] __main__ INFO: \u001b[0mEpoch 49 loss 0.1703 acc@1 0.9624 acc@5 0.9986\n",
      "\u001b[32m[2020-07-13 19:30:30] __main__ INFO: \u001b[0mElapsed 18.04\n",
      "\u001b[32m[2020-07-13 19:30:30] __main__ INFO: \u001b[0mTrain 50 17199\n",
      "\u001b[32m[2020-07-13 19:32:54] __main__ INFO: \u001b[0mEpoch 50 Step 100/351 lr 0.001000 loss 0.0010 (0.0016) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:35:18] __main__ INFO: \u001b[0mEpoch 50 Step 200/351 lr 0.001000 loss 0.0031 (0.0014) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:37:42] __main__ INFO: \u001b[0mEpoch 50 Step 300/351 lr 0.001000 loss 0.0007 (0.0013) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:38:55] __main__ INFO: \u001b[0mEpoch 50 Step 351/351 lr 0.001000 loss 0.0006 (0.0013) acc@1 1.0000 (0.9999) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:38:55] __main__ INFO: \u001b[0mElapsed 505.48\n",
      "\u001b[32m[2020-07-13 19:38:55] __main__ INFO: \u001b[0mVal 50\n",
      "\u001b[32m[2020-07-13 19:39:13] __main__ INFO: \u001b[0mEpoch 50 loss 0.1658 acc@1 0.9618 acc@5 0.9986\n",
      "\u001b[32m[2020-07-13 19:39:13] __main__ INFO: \u001b[0mElapsed 17.99\n",
      "\u001b[32m[2020-07-13 19:39:13] fvcore.common.checkpoint INFO: \u001b[0mSaving checkpoint to /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_cm_1_1/exp00_resume400_50/checkpoint_00050.pth\n"
     ]
    }
   ],
   "source": [
    "# Resume training with the un-augmented data\n",
    "os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "!python train.py --config /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_cm_1_1/exp00/config.yaml \\\n",
    "    train.checkpoint /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_cm_1_1/exp00/checkpoint_00400.pth \\\n",
    "    dataset.name CIFAR10 \\\n",
    "    model.resnext.cardinality 4 \\\n",
    "    train.batch_size 128 \\\n",
    "    train.base_lr 0.001 \\\n",
    "    train.output_dir /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_ra_1_20/exp00_resume400_50 \\\n",
    "    scheduler.epochs 50\n",
    "\n",
    "#### Set LEARNING RATE based on ending LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-13 21:53:35] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_cm_1_1/exp00_resume400_50/checkpoint_00050.pth\n",
      "Files already downloaded and verified\n",
      "100%|███████████████████████████████████████████| 79/79 [00:36<00:00,  2.17it/s]\n",
      "\u001b[32m[2020-07-13 21:54:13] __main__ INFO: \u001b[0mElapsed 36.43\n",
      "\u001b[32m[2020-07-13 21:54:13] __main__ INFO: \u001b[0mLoss 0.2356 Accuracy 0.9468\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10 test dataset \n",
    "# Right the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/resnext.yaml \\\n",
    "   model.resnext.cardinality 4 \\\n",
    "   test.batch_size 128 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_ra_1_20/exp00_resume400_50/checkpoint_00050.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_ra_1_20/exp00_resume400_50/test_results_0050_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-13 21:54:37] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_cm_1_1/exp00_resume400_50/checkpoint_00050.pth\n",
      "CIFAR 10.1\n",
      "100%|███████████████████████████████████████████| 16/16 [00:07<00:00,  2.11it/s]\n",
      "\u001b[32m[2020-07-13 21:54:46] __main__ INFO: \u001b[0mElapsed 7.59\n",
      "\u001b[32m[2020-07-13 21:54:46] __main__ INFO: \u001b[0mLoss 0.5942 Accuracy 0.8775\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10.1 test dataset \n",
    "# Right the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/resnext.yaml \\\n",
    "   model.resnext.cardinality 4 \\\n",
    "   test.batch_size 128 \\\n",
    "   dataset.name CIFAR101 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_ra_1_20/exp00_resume400_50/checkpoint_00050.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_ra_1_20/exp00_resume400_50/test_results_0050_cifar101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-13 21:55:02] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_cm_1_1/exp00/checkpoint_00400.pth\n",
      "Files already downloaded and verified\n",
      "100%|███████████████████████████████████████████| 79/79 [00:36<00:00,  2.16it/s]\n",
      "\u001b[32m[2020-07-13 21:55:40] __main__ INFO: \u001b[0mElapsed 36.60\n",
      "\u001b[32m[2020-07-13 21:55:40] __main__ INFO: \u001b[0mLoss 0.2970 Accuracy 0.9225\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10 test dataset \n",
    "# Right the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/resnext.yaml \\\n",
    "   model.resnext.cardinality 4 \\\n",
    "   test.batch_size 128 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_ra_1_20/exp00/checkpoint_00400.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_ra_1_20/exp00/test_results_0400_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-13 21:55:50] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_cm_1_1/exp00/checkpoint_00400.pth\n",
      "CIFAR 10.1\n",
      "100%|███████████████████████████████████████████| 16/16 [00:07<00:00,  2.10it/s]\n",
      "\u001b[32m[2020-07-13 21:55:58] __main__ INFO: \u001b[0mElapsed 7.62\n",
      "\u001b[32m[2020-07-13 21:55:58] __main__ INFO: \u001b[0mLoss 0.6040 Accuracy 0.8435\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10.1 test dataset \n",
    "# Right the results to the test output directory specified.\n",
    "os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "!python evaluate.py --config configs/cifar/resnext.yaml \\\n",
    "   model.resnext.cardinality 4 \\\n",
    "   test.batch_size 128 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_ra_1_20/exp00/checkpoint_00400.pth \\\n",
    "   dataset.name CIFAR101 \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_ra_1_20/exp00/test_results_0400_cifar101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Record the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Testset</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Original_Accuracy</th>\n",
       "      <th>Original_CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resnext_29_4x64d</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6746</td>\n",
       "      <td>0.8019</td>\n",
       "      <td>96.4</td>\n",
       "      <td>(96.0, 96.7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>resnext_29_4x64d</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>200</td>\n",
       "      <td>0.2311</td>\n",
       "      <td>0.9321</td>\n",
       "      <td>96.4</td>\n",
       "      <td>(96.0, 96.7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>resnext_29_4x64d</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>300</td>\n",
       "      <td>0.1517</td>\n",
       "      <td>0.9535</td>\n",
       "      <td>96.4</td>\n",
       "      <td>(96.0, 96.7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>resnext_29_4x64d</td>\n",
       "      <td>cifar10.1</td>\n",
       "      <td>300</td>\n",
       "      <td>0.3742</td>\n",
       "      <td>0.8905</td>\n",
       "      <td>89.6</td>\n",
       "      <td>(88.2, 90.9)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model    Testset  Epoch    Loss  Accuracy  Original_Accuracy  \\\n",
       "0  resnext_29_4x64d    cifar10    100  0.6746    0.8019               96.4   \n",
       "1  resnext_29_4x64d    cifar10    200  0.2311    0.9321               96.4   \n",
       "2  resnext_29_4x64d    cifar10    300  0.1517    0.9535               96.4   \n",
       "3  resnext_29_4x64d  cifar10.1    300  0.3742    0.8905               89.6   \n",
       "\n",
       "    Original_CI  \n",
       "0  (96.0, 96.7)  \n",
       "1  (96.0, 96.7)  \n",
       "2  (96.0, 96.7)  \n",
       "3  (88.2, 90.9)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write the results to a CSV file so that we can analyze later.\n",
    "import pandas as pd\n",
    "\n",
    "results = {'Model': ['resnext_29_4x64d', 'resnext_29_4x64d', 'resnext_29_4x64d', 'resnext_29_4x64d'],\n",
    "           'Testset': ['cifar10', 'cifar10', 'cifar10', 'cifar10.1'],\n",
    "           'Epoch': [100, 200, 300, 300],\n",
    "           'Loss': [0.6746, 0.2311, 0.1517, 0.3742],\n",
    "           'Accuracy': [0.8019, 0.9321, 0.9535, 0.8905],\n",
    "           'Original_Accuracy': [96.4, 96.4, 96.4, 89.6],\n",
    "           'Original_CI': [(96.0, 96.7), (96.0, 96.7), (96.0, 96.7), (88.2, 90.9)]\n",
    "           }\n",
    "\n",
    "df = pd.DataFrame(results, columns = ['Model', 'Testset', 'Epoch', 'Loss', 'Accuracy', \n",
    "                                      'Original_Accuracy', 'Original_CI'])\n",
    "\n",
    "\n",
    "\n",
    "#df.to_csv('/home/ec2-user/SageMaker/experiments/wrn_28_10/exp00/results.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Testset</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Original_Accuracy</th>\n",
       "      <th>Original_CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resnext_29_4x64d_cm_1_1</td>\n",
       "      <td>400</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.9225</td>\n",
       "      <td>96.4</td>\n",
       "      <td>(96.0, 96.7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>resnext_29_4x64d_cm_1_1</td>\n",
       "      <td>400</td>\n",
       "      <td>cifar10.1</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.8435</td>\n",
       "      <td>89.6</td>\n",
       "      <td>(88.2, 90.9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>resnext_29_4x64d_cm_1_1_refined400</td>\n",
       "      <td>50</td>\n",
       "      <td>cifar10.1</td>\n",
       "      <td>0.5942</td>\n",
       "      <td>0.8775</td>\n",
       "      <td>89.6</td>\n",
       "      <td>(88.2, 90.9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>resnext_29_4x64d_cm_1_1_refined400</td>\n",
       "      <td>50</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>0.2356</td>\n",
       "      <td>0.9468</td>\n",
       "      <td>96.4</td>\n",
       "      <td>(96.0, 96.7)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Model Epoch    Testset    Loss Accuracy  \\\n",
       "0             resnext_29_4x64d_cm_1_1   400    cifar10   0.297   0.9225   \n",
       "1             resnext_29_4x64d_cm_1_1   400  cifar10.1   0.604   0.8435   \n",
       "2  resnext_29_4x64d_cm_1_1_refined400    50  cifar10.1  0.5942   0.8775   \n",
       "3  resnext_29_4x64d_cm_1_1_refined400    50    cifar10  0.2356   0.9468   \n",
       "\n",
       "   Original_Accuracy   Original_CI  \n",
       "0               96.4  (96.0, 96.7)  \n",
       "1               89.6  (88.2, 90.9)  \n",
       "2               89.6  (88.2, 90.9)  \n",
       "3               96.4  (96.0, 96.7)  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "model = 'resnext_29_4x64d_ra_1_20'\n",
    "model_refined = model + '_refined400'\n",
    "\n",
    "a = pd.Series([model, 400, 'cifar10', ])\n",
    "c = pd.Series([model, 400, 'cifar10.1', ])\n",
    "\n",
    "e = pd.Series([model_refined, 50, 'cifar10.1', ])\n",
    "f = pd.Series([model_refined, 50, 'cifar10', ])\n",
    "               \n",
    "df_results = pd.concat([a,c,e,f], axis=1).T\n",
    "df_results.columns = ['Model', 'Epoch', 'Testset', 'Loss', 'Accuracy']\n",
    "\n",
    "df_results['Original_Accuracy'] = df_results.apply((lambda row: 96.4 if row[2] == 'cifar10' else 89.6), axis=1)\n",
    "df_results['Original_CI'] = df_results.apply((lambda row: (96.0, 96.7) if row[2] == 'cifar10' else (88.2, 90.9)), axis=1)\n",
    "\n",
    "df_results.to_csv('/home/ec2-user/SageMaker/experiments/' + model + '/results.csv')\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the model checkpoints, configs, and results to S3 \n",
    "bucket='sagemaker-june29'\n",
    "prefix = 'sagemaker/results/original-models/resnext_29_4x64d_ra_1_20'\n",
    "path = '/home/ec2-user/SageMaker/experiments/resnext_29_4x64d_ra_1_20'\n",
    "\n",
    "s3_resource = boto3.resource(\"s3\", region_name=\"us-east-2\")\n",
    "\n",
    "def uploadDirectory(local_path,bucket_name,s3_prefix):\n",
    "\n",
    "    my_bucket = s3_resource.Bucket(bucket_name)\n",
    "    \n",
    "    for path, subdirs, files in os.walk(local_path):\n",
    "        path = path.replace(\"\\\\\",\"/\")\n",
    "        directory_name = path.replace(local_path,\"\")\n",
    "        for file in files:\n",
    "            #print(\"Local File:\", os.path.join(path, file))\n",
    "            #print(\"      Dest:\", s3_prefix+directory_name+'/'+file)\n",
    "            my_bucket.upload_file(os.path.join(path, file), s3_prefix+directory_name+'/'+file)\n",
    "    \n",
    "uploadDirectory(path,bucket,prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
