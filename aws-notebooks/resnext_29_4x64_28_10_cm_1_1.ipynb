{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNext 29 4x64\n",
    "\n",
    " - Training Dataset:  CutMix, beta=1, cutmix_prob=1\n",
    " - Sagemaker Notebook must be of type, conda_pytorch_p36\n",
    " \n",
    "#### Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy \n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 1)) (1.15.4)\n",
      "Requirement already satisfied: torch>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 2)) (1.4.0)\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 3)) (0.5.0)\n",
      "Requirement already satisfied: fvcore in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (0.1.1.post20200630)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 5)) (4.42.1)\n",
      "Requirement already satisfied: yacs in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 6)) (0.1.7)\n",
      "Requirement already satisfied: apex from git+https://github.com/NVIDIA/apex.git#egg=apex in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 7)) (0.1)\n",
      "Requirement already satisfied: termcolor in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 8)) (1.1.0)\n",
      "Requirement already satisfied: thop<0.0.31.post2004070130 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 9)) (0.0.31.post2001170342)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 3)) (1.11.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 3)) (5.4.1)\n",
      "Requirement already satisfied: portalocker in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from fvcore->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (1.7.0)\n",
      "Requirement already satisfied: tabulate in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from fvcore->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (0.8.7)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from fvcore->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (5.3.1)\n",
      "Requirement already satisfied: tensorboard in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (2.2.2)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.30.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.7.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.4.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.14.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (47.3.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (3.2.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.9.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (3.12.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.18.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.11.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.15.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (2.24.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.31.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (1.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard) (3.4.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.1.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2019.11.28)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (1.23)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard) (3.0.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r '/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt'\n",
    "\n",
    "# Need to add this to requirements.txt\n",
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-10 05:54:02] __main__ INFO: \u001b[0mdevice: cuda\n",
      "cudnn:\n",
      "  benchmark: True\n",
      "  deterministic: False\n",
      "dataset:\n",
      "  name: CIFAR10_CM_1\n",
      "  dataset_dir: ''\n",
      "  image_size: 32\n",
      "  n_channels: 3\n",
      "  n_classes: 10\n",
      "model:\n",
      "  type: cifar\n",
      "  name: resnet\n",
      "  init_mode: kaiming_fan_out\n",
      "  vgg:\n",
      "    n_channels: [64, 128, 256, 512, 512]\n",
      "    n_layers: [2, 2, 3, 3, 3]\n",
      "    use_bn: True\n",
      "  resnet:\n",
      "    depth: 32\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "  resnet_preact:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "  wrn:\n",
      "    depth: 28\n",
      "    initial_channels: 16\n",
      "    widening_factor: 10\n",
      "    drop_rate: 0.0\n",
      "  densenet:\n",
      "    depth: 100\n",
      "    n_blocks: [6, 12, 24, 16]\n",
      "    block_type: bottleneck\n",
      "    growth_rate: 12\n",
      "    drop_rate: 0.0\n",
      "    compression_rate: 0.5\n",
      "  pyramidnet:\n",
      "    depth: 272\n",
      "    n_blocks: [3, 24, 36, 3]\n",
      "    initial_channels: 16\n",
      "    block_type: bottleneck\n",
      "    alpha: 200\n",
      "  resnext:\n",
      "    depth: 29\n",
      "    n_blocks: [3, 4, 6, 3]\n",
      "    initial_channels: 64\n",
      "    cardinality: 8\n",
      "    base_channels: 4\n",
      "  shake_shake:\n",
      "    depth: 26\n",
      "    initial_channels: 96\n",
      "    shake_forward: True\n",
      "    shake_backward: True\n",
      "    shake_image: True\n",
      "  se_resnet_preact:\n",
      "    depth: 110\n",
      "    initial_channels: 16\n",
      "    se_reduction: 16\n",
      "    block_type: basic\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "train:\n",
      "  checkpoint: ''\n",
      "  resume: False\n",
      "  precision: O0\n",
      "  batch_size: 128\n",
      "  subdivision: 1\n",
      "  optimizer: sgd\n",
      "  base_lr: 0.1\n",
      "  momentum: 0.9\n",
      "  nesterov: True\n",
      "  weight_decay: 0.0001\n",
      "  no_weight_decay_on_bn: False\n",
      "  gradient_clip: 0\n",
      "  start_epoch: 0\n",
      "  seed: 0\n",
      "  val_first: True\n",
      "  val_period: 1\n",
      "  val_ratio: 0.1\n",
      "  use_test_as_val: False\n",
      "  output_dir: /home/ec2-user/SageMaker/experiments/resnet_basic_32_cm_1_1/exp00\n",
      "  log_period: 100\n",
      "  checkpoint_period: 100\n",
      "  use_tensorboard: True\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: True\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "  distributed: False\n",
      "  dist:\n",
      "    backend: nccl\n",
      "    init_method: env://\n",
      "    world_size: -1\n",
      "    node_rank: -1\n",
      "    local_rank: 0\n",
      "    use_sync_bn: False\n",
      "tensorboard:\n",
      "  train_images: False\n",
      "  val_images: False\n",
      "  model_params: False\n",
      "optim:\n",
      "  adam:\n",
      "    betas: (0.9, 0.999)\n",
      "  lars:\n",
      "    eps: 1e-09\n",
      "    threshold: 0.01\n",
      "  adabound:\n",
      "    betas: (0.9, 0.999)\n",
      "    final_lr: 0.1\n",
      "    gamma: 0.001\n",
      "scheduler:\n",
      "  epochs: 400\n",
      "  warmup:\n",
      "    type: none\n",
      "    epochs: 0\n",
      "    start_factor: 0.001\n",
      "    exponent: 4\n",
      "  type: multistep\n",
      "  milestones: [80, 120]\n",
      "  lr_decay: 0.1\n",
      "  lr_min_factor: 0.001\n",
      "  T0: 10\n",
      "  T_mul: 1.0\n",
      "validation:\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: False\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "augmentation:\n",
      "  use_random_crop: True\n",
      "  use_random_horizontal_flip: True\n",
      "  use_cutout: False\n",
      "  use_random_erasing: False\n",
      "  use_dual_cutout: False\n",
      "  use_mixup: False\n",
      "  use_ricap: False\n",
      "  use_cutmix: False\n",
      "  use_label_smoothing: False\n",
      "  random_crop:\n",
      "    padding: 4\n",
      "    fill: 0\n",
      "    padding_mode: constant\n",
      "  random_horizontal_flip:\n",
      "    prob: 0.5\n",
      "  cutout:\n",
      "    prob: 1.0\n",
      "    mask_size: 16\n",
      "    cut_inside: False\n",
      "    mask_color: 0\n",
      "    dual_cutout_alpha: 0.1\n",
      "  random_erasing:\n",
      "    prob: 0.5\n",
      "    area_ratio_range: [0.02, 0.4]\n",
      "    min_aspect_ratio: 0.3\n",
      "    max_attempt: 20\n",
      "  mixup:\n",
      "    alpha: 1.0\n",
      "  ricap:\n",
      "    beta: 0.3\n",
      "  cutmix:\n",
      "    alpha: 1.0\n",
      "  label_smoothing:\n",
      "    epsilon: 0.1\n",
      "tta:\n",
      "  use_resize: False\n",
      "  use_center_crop: False\n",
      "  resize: 256\n",
      "test:\n",
      "  checkpoint: ''\n",
      "  output_dir: ''\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    pin_memory: False\n",
      "\u001b[32m[2020-07-10 05:54:02] __main__ INFO: \u001b[0menv_info:\n",
      "  pytorch_version: 1.4.0\n",
      "  cuda_version: 10.1\n",
      "  cudnn_version: 7603\n",
      "  num_gpus: 1\n",
      "  gpu_name: Tesla K80\n",
      "  gpu_capability: 3.7\n",
      "Files already downloaded and verified\n",
      "\u001b[32m[2020-07-10 05:54:19] __main__ INFO: \u001b[0mMACs  : 69.76M\n",
      "\u001b[32m[2020-07-10 05:54:19] __main__ INFO: \u001b[0m#params: 466.91K\n",
      "Selected optimization level O0:  Pure FP32 training.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n",
      "\u001b[32m[2020-07-10 05:54:19] __main__ INFO: \u001b[0mVal 0\n",
      "\u001b[32m[2020-07-10 05:54:20] __main__ INFO: \u001b[0mEpoch 0 loss 1481.8519 acc@1 0.1050 acc@5 0.5012\n",
      "\u001b[32m[2020-07-10 05:54:20] __main__ INFO: \u001b[0mElapsed 1.45\n",
      "\u001b[32m[2020-07-10 05:54:20] __main__ INFO: \u001b[0mTrain 1 0\n",
      "\u001b[32m[2020-07-10 05:54:30] __main__ INFO: \u001b[0mEpoch 1 Step 100/351 lr 0.100000 loss 2.3146 (2.8299) acc@1 0.1139 (0.1092) acc@5 0.5856 (0.5263)\n",
      "\u001b[32m[2020-07-10 05:54:39] __main__ INFO: \u001b[0mEpoch 1 Step 200/351 lr 0.100000 loss 2.2462 (2.5430) acc@1 0.1492 (0.1269) acc@5 0.6137 (0.5740)\n",
      "\u001b[32m[2020-07-10 05:54:49] __main__ INFO: \u001b[0mEpoch 1 Step 300/351 lr 0.100000 loss 2.1481 (2.4270) acc@1 0.1624 (0.1451) acc@5 0.7151 (0.6085)\n",
      "\u001b[32m[2020-07-10 05:54:53] __main__ INFO: \u001b[0mEpoch 1 Step 351/351 lr 0.100000 loss 2.1346 (2.3877) acc@1 0.2584 (0.1534) acc@5 0.6955 (0.6218)\n",
      "\u001b[32m[2020-07-10 05:54:53] __main__ INFO: \u001b[0mElapsed 33.01\n",
      "\u001b[32m[2020-07-10 05:54:54] __main__ INFO: \u001b[0mVal 1\n",
      "\u001b[32m[2020-07-10 05:54:55] __main__ INFO: \u001b[0mEpoch 1 loss 1.9196 acc@1 0.3166 acc@5 0.8304\n",
      "\u001b[32m[2020-07-10 05:54:55] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-07-10 05:54:55] __main__ INFO: \u001b[0mTrain 2 351\n",
      "\u001b[32m[2020-07-10 05:55:04] __main__ INFO: \u001b[0mEpoch 2 Step 100/351 lr 0.100000 loss 2.0590 (2.1290) acc@1 0.2508 (0.2194) acc@5 0.7464 (0.7196)\n",
      "\u001b[32m[2020-07-10 05:55:13] __main__ INFO: \u001b[0mEpoch 2 Step 200/351 lr 0.100000 loss 2.0793 (2.1155) acc@1 0.2469 (0.2241) acc@5 0.7510 (0.7263)\n",
      "\u001b[32m[2020-07-10 05:55:23] __main__ INFO: \u001b[0mEpoch 2 Step 300/351 lr 0.100000 loss 1.9931 (2.1034) acc@1 0.2773 (0.2297) acc@5 0.7875 (0.7319)\n",
      "\u001b[32m[2020-07-10 05:55:28] __main__ INFO: \u001b[0mEpoch 2 Step 351/351 lr 0.100000 loss 2.0081 (2.0967) acc@1 0.2314 (0.2326) acc@5 0.8041 (0.7349)\n",
      "\u001b[32m[2020-07-10 05:55:28] __main__ INFO: \u001b[0mElapsed 33.01\n",
      "\u001b[32m[2020-07-10 05:55:28] __main__ INFO: \u001b[0mVal 2\n",
      "\u001b[32m[2020-07-10 05:55:29] __main__ INFO: \u001b[0mEpoch 2 loss 1.7779 acc@1 0.3544 acc@5 0.8668\n",
      "\u001b[32m[2020-07-10 05:55:29] __main__ INFO: \u001b[0mElapsed 1.15\n",
      "\u001b[32m[2020-07-10 05:55:29] __main__ INFO: \u001b[0mTrain 3 702\n",
      "\u001b[32m[2020-07-10 05:55:38] __main__ INFO: \u001b[0mEpoch 3 Step 100/351 lr 0.100000 loss 2.0950 (2.0515) acc@1 0.2319 (0.2570) acc@5 0.7085 (0.7564)\n",
      "\u001b[32m[2020-07-10 05:55:48] __main__ INFO: \u001b[0mEpoch 3 Step 200/351 lr 0.100000 loss 2.0125 (2.0428) acc@1 0.2987 (0.2625) acc@5 0.7525 (0.7600)\n",
      "\u001b[32m[2020-07-10 05:55:57] __main__ INFO: \u001b[0mEpoch 3 Step 300/351 lr 0.100000 loss 2.0000 (2.0355) acc@1 0.2946 (0.2668) acc@5 0.7851 (0.7633)\n",
      "\u001b[32m[2020-07-10 05:56:02] __main__ INFO: \u001b[0mEpoch 3 Step 351/351 lr 0.100000 loss 2.0601 (2.0315) acc@1 0.2497 (0.2696) acc@5 0.7365 (0.7649)\n",
      "\u001b[32m[2020-07-10 05:56:02] __main__ INFO: \u001b[0mElapsed 33.37\n",
      "\u001b[32m[2020-07-10 05:56:02] __main__ INFO: \u001b[0mVal 3\n",
      "\u001b[32m[2020-07-10 05:56:03] __main__ INFO: \u001b[0mEpoch 3 loss 1.6582 acc@1 0.3998 acc@5 0.8854\n",
      "\u001b[32m[2020-07-10 05:56:03] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 05:56:03] __main__ INFO: \u001b[0mTrain 4 1053\n",
      "\u001b[32m[2020-07-10 05:56:13] __main__ INFO: \u001b[0mEpoch 4 Step 100/351 lr 0.100000 loss 1.9736 (1.9945) acc@1 0.2783 (0.2897) acc@5 0.7646 (0.7756)\n",
      "\u001b[32m[2020-07-10 05:56:22] __main__ INFO: \u001b[0mEpoch 4 Step 200/351 lr 0.100000 loss 2.0497 (1.9900) acc@1 0.2712 (0.2909) acc@5 0.7606 (0.7794)\n",
      "\u001b[32m[2020-07-10 05:56:32] __main__ INFO: \u001b[0mEpoch 4 Step 300/351 lr 0.100000 loss 1.9875 (1.9838) acc@1 0.3024 (0.2937) acc@5 0.7994 (0.7817)\n",
      "\u001b[32m[2020-07-10 05:56:37] __main__ INFO: \u001b[0mEpoch 4 Step 351/351 lr 0.100000 loss 2.0399 (1.9793) acc@1 0.2421 (0.2967) acc@5 0.7441 (0.7835)\n",
      "\u001b[32m[2020-07-10 05:56:37] __main__ INFO: \u001b[0mElapsed 33.35\n",
      "\u001b[32m[2020-07-10 05:56:37] __main__ INFO: \u001b[0mVal 4\n",
      "\u001b[32m[2020-07-10 05:56:38] __main__ INFO: \u001b[0mEpoch 4 loss 1.5095 acc@1 0.4748 acc@5 0.9144\n",
      "\u001b[32m[2020-07-10 05:56:38] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 05:56:38] __main__ INFO: \u001b[0mTrain 5 1404\n",
      "\u001b[32m[2020-07-10 05:56:47] __main__ INFO: \u001b[0mEpoch 5 Step 100/351 lr 0.100000 loss 1.9752 (1.9381) acc@1 0.2869 (0.3175) acc@5 0.7816 (0.7969)\n",
      "\u001b[32m[2020-07-10 05:56:57] __main__ INFO: \u001b[0mEpoch 5 Step 200/351 lr 0.100000 loss 1.9545 (1.9314) acc@1 0.2979 (0.3209) acc@5 0.8027 (0.7994)\n",
      "\u001b[32m[2020-07-10 05:57:06] __main__ INFO: \u001b[0mEpoch 5 Step 300/351 lr 0.100000 loss 1.9693 (1.9267) acc@1 0.3064 (0.3244) acc@5 0.7892 (0.8004)\n",
      "\u001b[32m[2020-07-10 05:57:11] __main__ INFO: \u001b[0mEpoch 5 Step 351/351 lr 0.100000 loss 1.8677 (1.9239) acc@1 0.3164 (0.3270) acc@5 0.7955 (0.8011)\n",
      "\u001b[32m[2020-07-10 05:57:11] __main__ INFO: \u001b[0mElapsed 33.42\n",
      "\u001b[32m[2020-07-10 05:57:11] __main__ INFO: \u001b[0mVal 5\n",
      "\u001b[32m[2020-07-10 05:57:12] __main__ INFO: \u001b[0mEpoch 5 loss 1.3682 acc@1 0.5174 acc@5 0.9374\n",
      "\u001b[32m[2020-07-10 05:57:12] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 05:57:12] __main__ INFO: \u001b[0mTrain 6 1755\n",
      "\u001b[32m[2020-07-10 05:57:22] __main__ INFO: \u001b[0mEpoch 6 Step 100/351 lr 0.100000 loss 1.9257 (1.8836) acc@1 0.3202 (0.3482) acc@5 0.8415 (0.8153)\n",
      "\u001b[32m[2020-07-10 05:57:31] __main__ INFO: \u001b[0mEpoch 6 Step 200/351 lr 0.100000 loss 1.8316 (1.8813) acc@1 0.3779 (0.3510) acc@5 0.7943 (0.8155)\n",
      "\u001b[32m[2020-07-10 05:57:41] __main__ INFO: \u001b[0mEpoch 6 Step 300/351 lr 0.100000 loss 1.8804 (1.8677) acc@1 0.3582 (0.3563) acc@5 0.8149 (0.8209)\n",
      "\u001b[32m[2020-07-10 05:57:46] __main__ INFO: \u001b[0mEpoch 6 Step 351/351 lr 0.100000 loss 1.8089 (1.8645) acc@1 0.4000 (0.3582) acc@5 0.8140 (0.8213)\n",
      "\u001b[32m[2020-07-10 05:57:46] __main__ INFO: \u001b[0mElapsed 33.46\n",
      "\u001b[32m[2020-07-10 05:57:46] __main__ INFO: \u001b[0mVal 6\n",
      "\u001b[32m[2020-07-10 05:57:47] __main__ INFO: \u001b[0mEpoch 6 loss 1.2801 acc@1 0.5596 acc@5 0.9348\n",
      "\u001b[32m[2020-07-10 05:57:47] __main__ INFO: \u001b[0mElapsed 1.11\n",
      "\u001b[32m[2020-07-10 05:57:47] __main__ INFO: \u001b[0mTrain 7 2106\n",
      "\u001b[32m[2020-07-10 05:57:56] __main__ INFO: \u001b[0mEpoch 7 Step 100/351 lr 0.100000 loss 1.7715 (1.8194) acc@1 0.4398 (0.3757) acc@5 0.8432 (0.8347)\n",
      "\u001b[32m[2020-07-10 05:58:06] __main__ INFO: \u001b[0mEpoch 7 Step 200/351 lr 0.100000 loss 1.7410 (1.8114) acc@1 0.3770 (0.3800) acc@5 0.8748 (0.8362)\n",
      "\u001b[32m[2020-07-10 05:58:15] __main__ INFO: \u001b[0mEpoch 7 Step 300/351 lr 0.100000 loss 1.8621 (1.8086) acc@1 0.3418 (0.3815) acc@5 0.8027 (0.8357)\n",
      "\u001b[32m[2020-07-10 05:58:20] __main__ INFO: \u001b[0mEpoch 7 Step 351/351 lr 0.100000 loss 1.8194 (1.8066) acc@1 0.4022 (0.3830) acc@5 0.8344 (0.8364)\n",
      "\u001b[32m[2020-07-10 05:58:20] __main__ INFO: \u001b[0mElapsed 33.51\n",
      "\u001b[32m[2020-07-10 05:58:20] __main__ INFO: \u001b[0mVal 7\n",
      "\u001b[32m[2020-07-10 05:58:21] __main__ INFO: \u001b[0mEpoch 7 loss 1.1703 acc@1 0.6096 acc@5 0.9520\n",
      "\u001b[32m[2020-07-10 05:58:21] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 05:58:21] __main__ INFO: \u001b[0mTrain 8 2457\n",
      "\u001b[32m[2020-07-10 05:58:31] __main__ INFO: \u001b[0mEpoch 8 Step 100/351 lr 0.100000 loss 1.8653 (1.7725) acc@1 0.3257 (0.3961) acc@5 0.7997 (0.8481)\n",
      "\u001b[32m[2020-07-10 05:58:41] __main__ INFO: \u001b[0mEpoch 8 Step 200/351 lr 0.100000 loss 1.7716 (1.7693) acc@1 0.3773 (0.3987) acc@5 0.8419 (0.8482)\n",
      "\u001b[32m[2020-07-10 05:58:50] __main__ INFO: \u001b[0mEpoch 8 Step 300/351 lr 0.100000 loss 1.7596 (1.7674) acc@1 0.3931 (0.4014) acc@5 0.8567 (0.8479)\n",
      "\u001b[32m[2020-07-10 05:58:55] __main__ INFO: \u001b[0mEpoch 8 Step 351/351 lr 0.100000 loss 1.7008 (1.7642) acc@1 0.4184 (0.4023) acc@5 0.8495 (0.8480)\n",
      "\u001b[32m[2020-07-10 05:58:55] __main__ INFO: \u001b[0mElapsed 33.54\n",
      "\u001b[32m[2020-07-10 05:58:55] __main__ INFO: \u001b[0mVal 8\n",
      "\u001b[32m[2020-07-10 05:58:56] __main__ INFO: \u001b[0mEpoch 8 loss 1.0829 acc@1 0.6496 acc@5 0.9636\n",
      "\u001b[32m[2020-07-10 05:58:56] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 05:58:56] __main__ INFO: \u001b[0mTrain 9 2808\n",
      "\u001b[32m[2020-07-10 05:59:06] __main__ INFO: \u001b[0mEpoch 9 Step 100/351 lr 0.100000 loss 1.6843 (1.7365) acc@1 0.4447 (0.4117) acc@5 0.8842 (0.8549)\n",
      "\u001b[32m[2020-07-10 05:59:15] __main__ INFO: \u001b[0mEpoch 9 Step 200/351 lr 0.100000 loss 1.8031 (1.7362) acc@1 0.4124 (0.4141) acc@5 0.8417 (0.8556)\n",
      "\u001b[32m[2020-07-10 05:59:25] __main__ INFO: \u001b[0mEpoch 9 Step 300/351 lr 0.100000 loss 1.6998 (1.7314) acc@1 0.4341 (0.4161) acc@5 0.8669 (0.8566)\n",
      "\u001b[32m[2020-07-10 05:59:29] __main__ INFO: \u001b[0mEpoch 9 Step 351/351 lr 0.100000 loss 1.7328 (1.7293) acc@1 0.4286 (0.4173) acc@5 0.8109 (0.8569)\n",
      "\u001b[32m[2020-07-10 05:59:29] __main__ INFO: \u001b[0mElapsed 33.50\n",
      "\u001b[32m[2020-07-10 05:59:29] __main__ INFO: \u001b[0mVal 9\n",
      "\u001b[32m[2020-07-10 05:59:31] __main__ INFO: \u001b[0mEpoch 9 loss 1.0832 acc@1 0.6474 acc@5 0.9656\n",
      "\u001b[32m[2020-07-10 05:59:31] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 05:59:31] __main__ INFO: \u001b[0mTrain 10 3159\n",
      "\u001b[32m[2020-07-10 05:59:40] __main__ INFO: \u001b[0mEpoch 10 Step 100/351 lr 0.100000 loss 1.6161 (1.6991) acc@1 0.4661 (0.4327) acc@5 0.8666 (0.8635)\n",
      "\u001b[32m[2020-07-10 05:59:50] __main__ INFO: \u001b[0mEpoch 10 Step 200/351 lr 0.100000 loss 1.7391 (1.6995) acc@1 0.4286 (0.4309) acc@5 0.8646 (0.8637)\n",
      "\u001b[32m[2020-07-10 05:59:59] __main__ INFO: \u001b[0mEpoch 10 Step 300/351 lr 0.100000 loss 1.7492 (1.6979) acc@1 0.4011 (0.4310) acc@5 0.8386 (0.8652)\n",
      "\u001b[32m[2020-07-10 06:00:04] __main__ INFO: \u001b[0mEpoch 10 Step 351/351 lr 0.100000 loss 1.6382 (1.6982) acc@1 0.4735 (0.4307) acc@5 0.8943 (0.8653)\n",
      "\u001b[32m[2020-07-10 06:00:04] __main__ INFO: \u001b[0mElapsed 33.49\n",
      "\u001b[32m[2020-07-10 06:00:04] __main__ INFO: \u001b[0mVal 10\n",
      "\u001b[32m[2020-07-10 06:00:05] __main__ INFO: \u001b[0mEpoch 10 loss 0.9814 acc@1 0.6802 acc@5 0.9672\n",
      "\u001b[32m[2020-07-10 06:00:05] __main__ INFO: \u001b[0mElapsed 1.12\n",
      "\u001b[32m[2020-07-10 06:00:05] __main__ INFO: \u001b[0mTrain 11 3510\n",
      "\u001b[32m[2020-07-10 06:00:15] __main__ INFO: \u001b[0mEpoch 11 Step 100/351 lr 0.100000 loss 1.6706 (1.6856) acc@1 0.4400 (0.4389) acc@5 0.8609 (0.8650)\n",
      "\u001b[32m[2020-07-10 06:00:24] __main__ INFO: \u001b[0mEpoch 11 Step 200/351 lr 0.100000 loss 1.6383 (1.6776) acc@1 0.4462 (0.4408) acc@5 0.8814 (0.8664)\n",
      "\u001b[32m[2020-07-10 06:00:34] __main__ INFO: \u001b[0mEpoch 11 Step 300/351 lr 0.100000 loss 1.6264 (1.6740) acc@1 0.4428 (0.4413) acc@5 0.8653 (0.8683)\n",
      "\u001b[32m[2020-07-10 06:00:39] __main__ INFO: \u001b[0mEpoch 11 Step 351/351 lr 0.100000 loss 1.6898 (1.6706) acc@1 0.4282 (0.4424) acc@5 0.8517 (0.8698)\n",
      "\u001b[32m[2020-07-10 06:00:39] __main__ INFO: \u001b[0mElapsed 33.56\n",
      "\u001b[32m[2020-07-10 06:00:39] __main__ INFO: \u001b[0mVal 11\n",
      "\u001b[32m[2020-07-10 06:00:40] __main__ INFO: \u001b[0mEpoch 11 loss 0.9921 acc@1 0.6780 acc@5 0.9696\n",
      "\u001b[32m[2020-07-10 06:00:40] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 06:00:40] __main__ INFO: \u001b[0mTrain 12 3861\n",
      "\u001b[32m[2020-07-10 06:00:49] __main__ INFO: \u001b[0mEpoch 12 Step 100/351 lr 0.100000 loss 1.6181 (1.6503) acc@1 0.4755 (0.4524) acc@5 0.8759 (0.8744)\n",
      "\u001b[32m[2020-07-10 06:00:59] __main__ INFO: \u001b[0mEpoch 12 Step 200/351 lr 0.100000 loss 1.7228 (1.6545) acc@1 0.4017 (0.4492) acc@5 0.8857 (0.8752)\n",
      "\u001b[32m[2020-07-10 06:01:08] __main__ INFO: \u001b[0mEpoch 12 Step 300/351 lr 0.100000 loss 1.6419 (1.6490) acc@1 0.4969 (0.4512) acc@5 0.8522 (0.8761)\n",
      "\u001b[32m[2020-07-10 06:01:13] __main__ INFO: \u001b[0mEpoch 12 Step 351/351 lr 0.100000 loss 1.7281 (1.6467) acc@1 0.4239 (0.4520) acc@5 0.8453 (0.8768)\n",
      "\u001b[32m[2020-07-10 06:01:13] __main__ INFO: \u001b[0mElapsed 33.51\n",
      "\u001b[32m[2020-07-10 06:01:13] __main__ INFO: \u001b[0mVal 12\n",
      "\u001b[32m[2020-07-10 06:01:14] __main__ INFO: \u001b[0mEpoch 12 loss 0.9673 acc@1 0.6916 acc@5 0.9712\n",
      "\u001b[32m[2020-07-10 06:01:14] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 06:01:14] __main__ INFO: \u001b[0mTrain 13 4212\n",
      "\u001b[32m[2020-07-10 06:01:24] __main__ INFO: \u001b[0mEpoch 13 Step 100/351 lr 0.100000 loss 1.6770 (1.6253) acc@1 0.4530 (0.4603) acc@5 0.8669 (0.8813)\n",
      "\u001b[32m[2020-07-10 06:01:34] __main__ INFO: \u001b[0mEpoch 13 Step 200/351 lr 0.100000 loss 1.7029 (1.6235) acc@1 0.4042 (0.4614) acc@5 0.8544 (0.8817)\n",
      "\u001b[32m[2020-07-10 06:01:43] __main__ INFO: \u001b[0mEpoch 13 Step 300/351 lr 0.100000 loss 1.5655 (1.6224) acc@1 0.5091 (0.4596) acc@5 0.8910 (0.8825)\n",
      "\u001b[32m[2020-07-10 06:01:48] __main__ INFO: \u001b[0mEpoch 13 Step 351/351 lr 0.100000 loss 1.7042 (1.6221) acc@1 0.4310 (0.4601) acc@5 0.8730 (0.8825)\n",
      "\u001b[32m[2020-07-10 06:01:48] __main__ INFO: \u001b[0mElapsed 33.44\n",
      "\u001b[32m[2020-07-10 06:01:48] __main__ INFO: \u001b[0mVal 13\n",
      "\u001b[32m[2020-07-10 06:01:49] __main__ INFO: \u001b[0mEpoch 13 loss 0.9156 acc@1 0.7302 acc@5 0.9768\n",
      "\u001b[32m[2020-07-10 06:01:49] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 06:01:49] __main__ INFO: \u001b[0mTrain 14 4563\n",
      "\u001b[32m[2020-07-10 06:01:59] __main__ INFO: \u001b[0mEpoch 14 Step 100/351 lr 0.100000 loss 1.6814 (1.6063) acc@1 0.4405 (0.4693) acc@5 0.8671 (0.8875)\n",
      "\u001b[32m[2020-07-10 06:02:08] __main__ INFO: \u001b[0mEpoch 14 Step 200/351 lr 0.100000 loss 1.6205 (1.6015) acc@1 0.4858 (0.4705) acc@5 0.8814 (0.8874)\n",
      "\u001b[32m[2020-07-10 06:02:18] __main__ INFO: \u001b[0mEpoch 14 Step 300/351 lr 0.100000 loss 1.6047 (1.6022) acc@1 0.4906 (0.4703) acc@5 0.8812 (0.8873)\n",
      "\u001b[32m[2020-07-10 06:02:22] __main__ INFO: \u001b[0mEpoch 14 Step 351/351 lr 0.100000 loss 1.5363 (1.6033) acc@1 0.4982 (0.4696) acc@5 0.8813 (0.8869)\n",
      "\u001b[32m[2020-07-10 06:02:22] __main__ INFO: \u001b[0mElapsed 33.49\n",
      "\u001b[32m[2020-07-10 06:02:22] __main__ INFO: \u001b[0mVal 14\n",
      "\u001b[32m[2020-07-10 06:02:24] __main__ INFO: \u001b[0mEpoch 14 loss 0.9203 acc@1 0.7252 acc@5 0.9804\n",
      "\u001b[32m[2020-07-10 06:02:24] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 06:02:24] __main__ INFO: \u001b[0mTrain 15 4914\n",
      "\u001b[32m[2020-07-10 06:02:33] __main__ INFO: \u001b[0mEpoch 15 Step 100/351 lr 0.100000 loss 1.5691 (1.5866) acc@1 0.4774 (0.4761) acc@5 0.8891 (0.8915)\n",
      "\u001b[32m[2020-07-10 06:02:43] __main__ INFO: \u001b[0mEpoch 15 Step 200/351 lr 0.100000 loss 1.4668 (1.5873) acc@1 0.5446 (0.4737) acc@5 0.9270 (0.8904)\n",
      "\u001b[32m[2020-07-10 06:02:52] __main__ INFO: \u001b[0mEpoch 15 Step 300/351 lr 0.100000 loss 1.4808 (1.5893) acc@1 0.5077 (0.4747) acc@5 0.9274 (0.8896)\n",
      "\u001b[32m[2020-07-10 06:02:57] __main__ INFO: \u001b[0mEpoch 15 Step 351/351 lr 0.100000 loss 1.5646 (1.5883) acc@1 0.4763 (0.4746) acc@5 0.8976 (0.8899)\n",
      "\u001b[32m[2020-07-10 06:02:57] __main__ INFO: \u001b[0mElapsed 33.54\n",
      "\u001b[32m[2020-07-10 06:02:57] __main__ INFO: \u001b[0mVal 15\n",
      "\u001b[32m[2020-07-10 06:02:58] __main__ INFO: \u001b[0mEpoch 15 loss 0.9068 acc@1 0.7286 acc@5 0.9790\n",
      "\u001b[32m[2020-07-10 06:02:58] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 06:02:58] __main__ INFO: \u001b[0mTrain 16 5265\n",
      "\u001b[32m[2020-07-10 06:03:08] __main__ INFO: \u001b[0mEpoch 16 Step 100/351 lr 0.100000 loss 1.6008 (1.5737) acc@1 0.4893 (0.4794) acc@5 0.8865 (0.8940)\n",
      "\u001b[32m[2020-07-10 06:03:17] __main__ INFO: \u001b[0mEpoch 16 Step 200/351 lr 0.100000 loss 1.5512 (1.5727) acc@1 0.4690 (0.4801) acc@5 0.8738 (0.8936)\n",
      "\u001b[32m[2020-07-10 06:03:27] __main__ INFO: \u001b[0mEpoch 16 Step 300/351 lr 0.100000 loss 1.5465 (1.5735) acc@1 0.4691 (0.4802) acc@5 0.8997 (0.8932)\n",
      "\u001b[32m[2020-07-10 06:03:32] __main__ INFO: \u001b[0mEpoch 16 Step 351/351 lr 0.100000 loss 1.5737 (1.5725) acc@1 0.4829 (0.4805) acc@5 0.8972 (0.8931)\n",
      "\u001b[32m[2020-07-10 06:03:32] __main__ INFO: \u001b[0mElapsed 33.59\n",
      "\u001b[32m[2020-07-10 06:03:32] __main__ INFO: \u001b[0mVal 16\n",
      "\u001b[32m[2020-07-10 06:03:33] __main__ INFO: \u001b[0mEpoch 16 loss 0.8522 acc@1 0.7548 acc@5 0.9830\n",
      "\u001b[32m[2020-07-10 06:03:33] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 06:03:33] __main__ INFO: \u001b[0mTrain 17 5616\n",
      "\u001b[32m[2020-07-10 06:03:42] __main__ INFO: \u001b[0mEpoch 17 Step 100/351 lr 0.100000 loss 1.5961 (1.5621) acc@1 0.4887 (0.4791) acc@5 0.8778 (0.8947)\n",
      "\u001b[32m[2020-07-10 06:03:52] __main__ INFO: \u001b[0mEpoch 17 Step 200/351 lr 0.100000 loss 1.6193 (1.5562) acc@1 0.4485 (0.4837) acc@5 0.8861 (0.8956)\n",
      "\u001b[32m[2020-07-10 06:04:01] __main__ INFO: \u001b[0mEpoch 17 Step 300/351 lr 0.100000 loss 1.6607 (1.5565) acc@1 0.4605 (0.4844) acc@5 0.8761 (0.8957)\n",
      "\u001b[32m[2020-07-10 06:04:06] __main__ INFO: \u001b[0mEpoch 17 Step 351/351 lr 0.100000 loss 1.5976 (1.5563) acc@1 0.4316 (0.4848) acc@5 0.9034 (0.8954)\n",
      "\u001b[32m[2020-07-10 06:04:06] __main__ INFO: \u001b[0mElapsed 33.51\n",
      "\u001b[32m[2020-07-10 06:04:06] __main__ INFO: \u001b[0mVal 17\n",
      "\u001b[32m[2020-07-10 06:04:07] __main__ INFO: \u001b[0mEpoch 17 loss 0.8860 acc@1 0.7248 acc@5 0.9764\n",
      "\u001b[32m[2020-07-10 06:04:07] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 06:04:07] __main__ INFO: \u001b[0mTrain 18 5967\n",
      "\u001b[32m[2020-07-10 06:04:17] __main__ INFO: \u001b[0mEpoch 18 Step 100/351 lr 0.100000 loss 1.5696 (1.5406) acc@1 0.4559 (0.4907) acc@5 0.9063 (0.9000)\n",
      "\u001b[32m[2020-07-10 06:04:27] __main__ INFO: \u001b[0mEpoch 18 Step 200/351 lr 0.100000 loss 1.4896 (1.5433) acc@1 0.5129 (0.4910) acc@5 0.9173 (0.8991)\n",
      "\u001b[32m[2020-07-10 06:04:36] __main__ INFO: \u001b[0mEpoch 18 Step 300/351 lr 0.100000 loss 1.5295 (1.5452) acc@1 0.5012 (0.4906) acc@5 0.9060 (0.8985)\n",
      "\u001b[32m[2020-07-10 06:04:41] __main__ INFO: \u001b[0mEpoch 18 Step 351/351 lr 0.100000 loss 1.5796 (1.5434) acc@1 0.4729 (0.4908) acc@5 0.9008 (0.8988)\n",
      "\u001b[32m[2020-07-10 06:04:41] __main__ INFO: \u001b[0mElapsed 33.49\n",
      "\u001b[32m[2020-07-10 06:04:41] __main__ INFO: \u001b[0mVal 18\n",
      "\u001b[32m[2020-07-10 06:04:42] __main__ INFO: \u001b[0mEpoch 18 loss 0.8171 acc@1 0.7680 acc@5 0.9828\n",
      "\u001b[32m[2020-07-10 06:04:42] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 06:04:42] __main__ INFO: \u001b[0mTrain 19 6318\n",
      "\u001b[32m[2020-07-10 06:04:52] __main__ INFO: \u001b[0mEpoch 19 Step 100/351 lr 0.100000 loss 1.4729 (1.5243) acc@1 0.5143 (0.5000) acc@5 0.9062 (0.9021)\n",
      "\u001b[32m[2020-07-10 06:05:01] __main__ INFO: \u001b[0mEpoch 19 Step 200/351 lr 0.100000 loss 1.5505 (1.5324) acc@1 0.4596 (0.4952) acc@5 0.9006 (0.9011)\n",
      "\u001b[32m[2020-07-10 06:05:11] __main__ INFO: \u001b[0mEpoch 19 Step 300/351 lr 0.100000 loss 1.4897 (1.5316) acc@1 0.4705 (0.4956) acc@5 0.8891 (0.9010)\n",
      "\u001b[32m[2020-07-10 06:05:16] __main__ INFO: \u001b[0mEpoch 19 Step 351/351 lr 0.100000 loss 1.5372 (1.5302) acc@1 0.4983 (0.4962) acc@5 0.8809 (0.9013)\n",
      "\u001b[32m[2020-07-10 06:05:16] __main__ INFO: \u001b[0mElapsed 33.57\n",
      "\u001b[32m[2020-07-10 06:05:16] __main__ INFO: \u001b[0mVal 19\n",
      "\u001b[32m[2020-07-10 06:05:17] __main__ INFO: \u001b[0mEpoch 19 loss 0.8365 acc@1 0.7456 acc@5 0.9802\n",
      "\u001b[32m[2020-07-10 06:05:17] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 06:05:17] __main__ INFO: \u001b[0mTrain 20 6669\n",
      "\u001b[32m[2020-07-10 06:05:26] __main__ INFO: \u001b[0mEpoch 20 Step 100/351 lr 0.100000 loss 1.5594 (1.5176) acc@1 0.4858 (0.5010) acc@5 0.8757 (0.9033)\n",
      "\u001b[32m[2020-07-10 06:05:36] __main__ INFO: \u001b[0mEpoch 20 Step 200/351 lr 0.100000 loss 1.5733 (1.5223) acc@1 0.4687 (0.4986) acc@5 0.9074 (0.9024)\n",
      "\u001b[32m[2020-07-10 06:05:45] __main__ INFO: \u001b[0mEpoch 20 Step 300/351 lr 0.100000 loss 1.5865 (1.5193) acc@1 0.4682 (0.4986) acc@5 0.9140 (0.9032)\n",
      "\u001b[32m[2020-07-10 06:05:50] __main__ INFO: \u001b[0mEpoch 20 Step 351/351 lr 0.100000 loss 1.4820 (1.5204) acc@1 0.5000 (0.4982) acc@5 0.8978 (0.9027)\n",
      "\u001b[32m[2020-07-10 06:05:50] __main__ INFO: \u001b[0mElapsed 33.55\n",
      "\u001b[32m[2020-07-10 06:05:50] __main__ INFO: \u001b[0mVal 20\n",
      "\u001b[32m[2020-07-10 06:05:51] __main__ INFO: \u001b[0mEpoch 20 loss 0.7669 acc@1 0.7876 acc@5 0.9838\n",
      "\u001b[32m[2020-07-10 06:05:51] __main__ INFO: \u001b[0mElapsed 1.11\n",
      "\u001b[32m[2020-07-10 06:05:51] __main__ INFO: \u001b[0mTrain 21 7020\n",
      "\u001b[32m[2020-07-10 06:06:01] __main__ INFO: \u001b[0mEpoch 21 Step 100/351 lr 0.100000 loss 1.5278 (1.5072) acc@1 0.4874 (0.5008) acc@5 0.8943 (0.9077)\n",
      "\u001b[32m[2020-07-10 06:06:10] __main__ INFO: \u001b[0mEpoch 21 Step 200/351 lr 0.100000 loss 1.4774 (1.5031) acc@1 0.5535 (0.5050) acc@5 0.9181 (0.9068)\n",
      "\u001b[32m[2020-07-10 06:06:20] __main__ INFO: \u001b[0mEpoch 21 Step 300/351 lr 0.100000 loss 1.5235 (1.5070) acc@1 0.5207 (0.5034) acc@5 0.8692 (0.9050)\n",
      "\u001b[32m[2020-07-10 06:06:25] __main__ INFO: \u001b[0mEpoch 21 Step 351/351 lr 0.100000 loss 1.3928 (1.5081) acc@1 0.5677 (0.5028) acc@5 0.9174 (0.9053)\n",
      "\u001b[32m[2020-07-10 06:06:25] __main__ INFO: \u001b[0mElapsed 33.46\n",
      "\u001b[32m[2020-07-10 06:06:25] __main__ INFO: \u001b[0mVal 21\n",
      "\u001b[32m[2020-07-10 06:06:26] __main__ INFO: \u001b[0mEpoch 21 loss 0.7644 acc@1 0.7854 acc@5 0.9880\n",
      "\u001b[32m[2020-07-10 06:06:26] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 06:06:26] __main__ INFO: \u001b[0mTrain 22 7371\n",
      "\u001b[32m[2020-07-10 06:06:36] __main__ INFO: \u001b[0mEpoch 22 Step 100/351 lr 0.100000 loss 1.4208 (1.4880) acc@1 0.5226 (0.5121) acc@5 0.9391 (0.9085)\n",
      "\u001b[32m[2020-07-10 06:06:45] __main__ INFO: \u001b[0mEpoch 22 Step 200/351 lr 0.100000 loss 1.4026 (1.4914) acc@1 0.5253 (0.5086) acc@5 0.9420 (0.9083)\n",
      "\u001b[32m[2020-07-10 06:06:55] __main__ INFO: \u001b[0mEpoch 22 Step 300/351 lr 0.100000 loss 1.4958 (1.4944) acc@1 0.5314 (0.5066) acc@5 0.9059 (0.9080)\n",
      "\u001b[32m[2020-07-10 06:06:59] __main__ INFO: \u001b[0mEpoch 22 Step 351/351 lr 0.100000 loss 1.5111 (1.4973) acc@1 0.5131 (0.5060) acc@5 0.9172 (0.9070)\n",
      "\u001b[32m[2020-07-10 06:06:59] __main__ INFO: \u001b[0mElapsed 33.54\n",
      "\u001b[32m[2020-07-10 06:06:59] __main__ INFO: \u001b[0mVal 22\n",
      "\u001b[32m[2020-07-10 06:07:01] __main__ INFO: \u001b[0mEpoch 22 loss 0.7893 acc@1 0.7910 acc@5 0.9886\n",
      "\u001b[32m[2020-07-10 06:07:01] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 06:07:01] __main__ INFO: \u001b[0mTrain 23 7722\n",
      "\u001b[32m[2020-07-10 06:07:10] __main__ INFO: \u001b[0mEpoch 23 Step 100/351 lr 0.100000 loss 1.5232 (1.4821) acc@1 0.4779 (0.5114) acc@5 0.8929 (0.9101)\n",
      "\u001b[32m[2020-07-10 06:07:20] __main__ INFO: \u001b[0mEpoch 23 Step 200/351 lr 0.100000 loss 1.4160 (1.4805) acc@1 0.5308 (0.5106) acc@5 0.9321 (0.9110)\n",
      "\u001b[32m[2020-07-10 06:07:29] __main__ INFO: \u001b[0mEpoch 23 Step 300/351 lr 0.100000 loss 1.5343 (1.4860) acc@1 0.5205 (0.5091) acc@5 0.9173 (0.9100)\n",
      "\u001b[32m[2020-07-10 06:07:34] __main__ INFO: \u001b[0mEpoch 23 Step 351/351 lr 0.100000 loss 1.4798 (1.4880) acc@1 0.5059 (0.5088) acc@5 0.9099 (0.9094)\n",
      "\u001b[32m[2020-07-10 06:07:34] __main__ INFO: \u001b[0mElapsed 33.54\n",
      "\u001b[32m[2020-07-10 06:07:34] __main__ INFO: \u001b[0mVal 23\n",
      "\u001b[32m[2020-07-10 06:07:35] __main__ INFO: \u001b[0mEpoch 23 loss 0.7709 acc@1 0.7752 acc@5 0.9860\n",
      "\u001b[32m[2020-07-10 06:07:35] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 06:07:35] __main__ INFO: \u001b[0mTrain 24 8073\n",
      "\u001b[32m[2020-07-10 06:07:45] __main__ INFO: \u001b[0mEpoch 24 Step 100/351 lr 0.100000 loss 1.5276 (1.4722) acc@1 0.4750 (0.5129) acc@5 0.9197 (0.9111)\n",
      "\u001b[32m[2020-07-10 06:07:54] __main__ INFO: \u001b[0mEpoch 24 Step 200/351 lr 0.100000 loss 1.5008 (1.4775) acc@1 0.4955 (0.5114) acc@5 0.8939 (0.9101)\n",
      "\u001b[32m[2020-07-10 06:08:04] __main__ INFO: \u001b[0mEpoch 24 Step 300/351 lr 0.100000 loss 1.4676 (1.4764) acc@1 0.5051 (0.5121) acc@5 0.9055 (0.9105)\n",
      "\u001b[32m[2020-07-10 06:08:09] __main__ INFO: \u001b[0mEpoch 24 Step 351/351 lr 0.100000 loss 1.5202 (1.4772) acc@1 0.5007 (0.5117) acc@5 0.9097 (0.9112)\n",
      "\u001b[32m[2020-07-10 06:08:09] __main__ INFO: \u001b[0mElapsed 33.54\n",
      "\u001b[32m[2020-07-10 06:08:09] __main__ INFO: \u001b[0mVal 24\n",
      "\u001b[32m[2020-07-10 06:08:10] __main__ INFO: \u001b[0mEpoch 24 loss 0.7247 acc@1 0.7856 acc@5 0.9884\n",
      "\u001b[32m[2020-07-10 06:08:10] __main__ INFO: \u001b[0mElapsed 1.11\n",
      "\u001b[32m[2020-07-10 06:08:10] __main__ INFO: \u001b[0mTrain 25 8424\n",
      "\u001b[32m[2020-07-10 06:08:20] __main__ INFO: \u001b[0mEpoch 25 Step 100/351 lr 0.100000 loss 1.4898 (1.4592) acc@1 0.5048 (0.5194) acc@5 0.9365 (0.9148)\n",
      "\u001b[32m[2020-07-10 06:08:29] __main__ INFO: \u001b[0mEpoch 25 Step 200/351 lr 0.100000 loss 1.5008 (1.4608) acc@1 0.5309 (0.5180) acc@5 0.8661 (0.9137)\n",
      "\u001b[32m[2020-07-10 06:08:38] __main__ INFO: \u001b[0mEpoch 25 Step 300/351 lr 0.100000 loss 1.5783 (1.4655) acc@1 0.4796 (0.5169) acc@5 0.8729 (0.9126)\n",
      "\u001b[32m[2020-07-10 06:08:43] __main__ INFO: \u001b[0mEpoch 25 Step 351/351 lr 0.100000 loss 1.5852 (1.4681) acc@1 0.4551 (0.5156) acc@5 0.9079 (0.9120)\n",
      "\u001b[32m[2020-07-10 06:08:43] __main__ INFO: \u001b[0mElapsed 33.52\n",
      "\u001b[32m[2020-07-10 06:08:43] __main__ INFO: \u001b[0mVal 25\n",
      "\u001b[32m[2020-07-10 06:08:44] __main__ INFO: \u001b[0mEpoch 25 loss 0.7232 acc@1 0.8046 acc@5 0.9842\n",
      "\u001b[32m[2020-07-10 06:08:44] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-07-10 06:08:44] __main__ INFO: \u001b[0mTrain 26 8775\n",
      "\u001b[32m[2020-07-10 06:08:54] __main__ INFO: \u001b[0mEpoch 26 Step 100/351 lr 0.100000 loss 1.4108 (1.4504) acc@1 0.5197 (0.5195) acc@5 0.9431 (0.9187)\n",
      "\u001b[32m[2020-07-10 06:09:04] __main__ INFO: \u001b[0mEpoch 26 Step 200/351 lr 0.100000 loss 1.4910 (1.4580) acc@1 0.5263 (0.5188) acc@5 0.8931 (0.9153)\n",
      "\u001b[32m[2020-07-10 06:09:13] __main__ INFO: \u001b[0mEpoch 26 Step 300/351 lr 0.100000 loss 1.4334 (1.4612) acc@1 0.5092 (0.5177) acc@5 0.9279 (0.9142)\n",
      "\u001b[32m[2020-07-10 06:09:18] __main__ INFO: \u001b[0mEpoch 26 Step 351/351 lr 0.100000 loss 1.3790 (1.4600) acc@1 0.5521 (0.5188) acc@5 0.9071 (0.9143)\n",
      "\u001b[32m[2020-07-10 06:09:18] __main__ INFO: \u001b[0mElapsed 33.44\n",
      "\u001b[32m[2020-07-10 06:09:18] __main__ INFO: \u001b[0mVal 26\n",
      "\u001b[32m[2020-07-10 06:09:19] __main__ INFO: \u001b[0mEpoch 26 loss 0.7450 acc@1 0.7900 acc@5 0.9892\n",
      "\u001b[32m[2020-07-10 06:09:19] __main__ INFO: \u001b[0mElapsed 1.11\n",
      "\u001b[32m[2020-07-10 06:09:19] __main__ INFO: \u001b[0mTrain 27 9126\n",
      "\u001b[32m[2020-07-10 06:09:29] __main__ INFO: \u001b[0mEpoch 27 Step 100/351 lr 0.100000 loss 1.3631 (1.4561) acc@1 0.5586 (0.5194) acc@5 0.9277 (0.9130)\n",
      "\u001b[32m[2020-07-10 06:09:38] __main__ INFO: \u001b[0mEpoch 27 Step 200/351 lr 0.100000 loss 1.3549 (1.4551) acc@1 0.5603 (0.5189) acc@5 0.9590 (0.9133)\n",
      "\u001b[32m[2020-07-10 06:09:48] __main__ INFO: \u001b[0mEpoch 27 Step 300/351 lr 0.100000 loss 1.4399 (1.4551) acc@1 0.4831 (0.5196) acc@5 0.9284 (0.9139)\n",
      "\u001b[32m[2020-07-10 06:09:53] __main__ INFO: \u001b[0mEpoch 27 Step 351/351 lr 0.100000 loss 1.3912 (1.4545) acc@1 0.5787 (0.5195) acc@5 0.9178 (0.9144)\n",
      "\u001b[32m[2020-07-10 06:09:53] __main__ INFO: \u001b[0mElapsed 33.63\n",
      "\u001b[32m[2020-07-10 06:09:53] __main__ INFO: \u001b[0mVal 27\n",
      "\u001b[32m[2020-07-10 06:09:54] __main__ INFO: \u001b[0mEpoch 27 loss 0.6994 acc@1 0.8264 acc@5 0.9892\n",
      "\u001b[32m[2020-07-10 06:09:54] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 06:09:54] __main__ INFO: \u001b[0mTrain 28 9477\n",
      "\u001b[32m[2020-07-10 06:10:03] __main__ INFO: \u001b[0mEpoch 28 Step 100/351 lr 0.100000 loss 1.4438 (1.4324) acc@1 0.5101 (0.5283) acc@5 0.9434 (0.9181)\n",
      "\u001b[32m[2020-07-10 06:10:13] __main__ INFO: \u001b[0mEpoch 28 Step 200/351 lr 0.100000 loss 1.4132 (1.4391) acc@1 0.5099 (0.5246) acc@5 0.9062 (0.9187)\n",
      "\u001b[32m[2020-07-10 06:10:22] __main__ INFO: \u001b[0mEpoch 28 Step 300/351 lr 0.100000 loss 1.4967 (1.4442) acc@1 0.5056 (0.5227) acc@5 0.9068 (0.9177)\n",
      "\u001b[32m[2020-07-10 06:10:27] __main__ INFO: \u001b[0mEpoch 28 Step 351/351 lr 0.100000 loss 1.4337 (1.4446) acc@1 0.5330 (0.5234) acc@5 0.9087 (0.9171)\n",
      "\u001b[32m[2020-07-10 06:10:27] __main__ INFO: \u001b[0mElapsed 33.52\n",
      "\u001b[32m[2020-07-10 06:10:27] __main__ INFO: \u001b[0mVal 28\n",
      "\u001b[32m[2020-07-10 06:10:28] __main__ INFO: \u001b[0mEpoch 28 loss 0.7311 acc@1 0.7950 acc@5 0.9886\n",
      "\u001b[32m[2020-07-10 06:10:28] __main__ INFO: \u001b[0mElapsed 1.11\n",
      "\u001b[32m[2020-07-10 06:10:28] __main__ INFO: \u001b[0mTrain 29 9828\n",
      "\u001b[32m[2020-07-10 06:10:38] __main__ INFO: \u001b[0mEpoch 29 Step 100/351 lr 0.100000 loss 1.5262 (1.4257) acc@1 0.4745 (0.5284) acc@5 0.9308 (0.9203)\n",
      "\u001b[32m[2020-07-10 06:10:47] __main__ INFO: \u001b[0mEpoch 29 Step 200/351 lr 0.100000 loss 1.5482 (1.4333) acc@1 0.5077 (0.5254) acc@5 0.9156 (0.9195)\n",
      "\u001b[32m[2020-07-10 06:10:57] __main__ INFO: \u001b[0mEpoch 29 Step 300/351 lr 0.100000 loss 1.5406 (1.4363) acc@1 0.4948 (0.5238) acc@5 0.8777 (0.9187)\n",
      "\u001b[32m[2020-07-10 06:11:02] __main__ INFO: \u001b[0mEpoch 29 Step 351/351 lr 0.100000 loss 1.5090 (1.4359) acc@1 0.4905 (0.5241) acc@5 0.9291 (0.9186)\n",
      "\u001b[32m[2020-07-10 06:11:02] __main__ INFO: \u001b[0mElapsed 33.51\n",
      "\u001b[32m[2020-07-10 06:11:02] __main__ INFO: \u001b[0mVal 29\n",
      "\u001b[32m[2020-07-10 06:11:03] __main__ INFO: \u001b[0mEpoch 29 loss 0.6853 acc@1 0.8008 acc@5 0.9906\n",
      "\u001b[32m[2020-07-10 06:11:03] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 06:11:03] __main__ INFO: \u001b[0mTrain 30 10179\n",
      "\u001b[32m[2020-07-10 06:11:13] __main__ INFO: \u001b[0mEpoch 30 Step 100/351 lr 0.100000 loss 1.5193 (1.4207) acc@1 0.4802 (0.5315) acc@5 0.9069 (0.9214)\n",
      "\u001b[32m[2020-07-10 06:11:22] __main__ INFO: \u001b[0mEpoch 30 Step 200/351 lr 0.100000 loss 1.3388 (1.4254) acc@1 0.5488 (0.5282) acc@5 0.9327 (0.9211)\n",
      "\u001b[32m[2020-07-10 06:11:32] __main__ INFO: \u001b[0mEpoch 30 Step 300/351 lr 0.100000 loss 1.4272 (1.4293) acc@1 0.5372 (0.5271) acc@5 0.9324 (0.9202)\n",
      "\u001b[32m[2020-07-10 06:11:36] __main__ INFO: \u001b[0mEpoch 30 Step 351/351 lr 0.100000 loss 1.4882 (1.4303) acc@1 0.4979 (0.5267) acc@5 0.9154 (0.9200)\n",
      "\u001b[32m[2020-07-10 06:11:36] __main__ INFO: \u001b[0mElapsed 33.50\n",
      "\u001b[32m[2020-07-10 06:11:36] __main__ INFO: \u001b[0mVal 30\n",
      "\u001b[32m[2020-07-10 06:11:38] __main__ INFO: \u001b[0mEpoch 30 loss 0.6936 acc@1 0.8126 acc@5 0.9910\n",
      "\u001b[32m[2020-07-10 06:11:38] __main__ INFO: \u001b[0mElapsed 1.11\n",
      "\u001b[32m[2020-07-10 06:11:38] __main__ INFO: \u001b[0mTrain 31 10530\n",
      "\u001b[32m[2020-07-10 06:11:47] __main__ INFO: \u001b[0mEpoch 31 Step 100/351 lr 0.100000 loss 1.4962 (1.4087) acc@1 0.5363 (0.5341) acc@5 0.8937 (0.9230)\n",
      "\u001b[32m[2020-07-10 06:11:57] __main__ INFO: \u001b[0mEpoch 31 Step 200/351 lr 0.100000 loss 1.3191 (1.4190) acc@1 0.5746 (0.5299) acc@5 0.9370 (0.9203)\n",
      "\u001b[32m[2020-07-10 06:12:06] __main__ INFO: \u001b[0mEpoch 31 Step 300/351 lr 0.100000 loss 1.3550 (1.4223) acc@1 0.5607 (0.5277) acc@5 0.9371 (0.9202)\n",
      "\u001b[32m[2020-07-10 06:12:11] __main__ INFO: \u001b[0mEpoch 31 Step 351/351 lr 0.100000 loss 1.4419 (1.4221) acc@1 0.4938 (0.5283) acc@5 0.9301 (0.9202)\n",
      "\u001b[32m[2020-07-10 06:12:11] __main__ INFO: \u001b[0mElapsed 33.50\n",
      "\u001b[32m[2020-07-10 06:12:11] __main__ INFO: \u001b[0mVal 31\n",
      "\u001b[32m[2020-07-10 06:12:12] __main__ INFO: \u001b[0mEpoch 31 loss 0.7742 acc@1 0.7988 acc@5 0.9866\n",
      "\u001b[32m[2020-07-10 06:12:12] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 06:12:12] __main__ INFO: \u001b[0mTrain 32 10881\n",
      "\u001b[32m[2020-07-10 06:12:22] __main__ INFO: \u001b[0mEpoch 32 Step 100/351 lr 0.100000 loss 1.5783 (1.4095) acc@1 0.4841 (0.5327) acc@5 0.8877 (0.9216)\n",
      "\u001b[32m[2020-07-10 06:12:31] __main__ INFO: \u001b[0mEpoch 32 Step 200/351 lr 0.100000 loss 1.5118 (1.4099) acc@1 0.5113 (0.5310) acc@5 0.9085 (0.9227)\n",
      "\u001b[32m[2020-07-10 06:12:41] __main__ INFO: \u001b[0mEpoch 32 Step 300/351 lr 0.100000 loss 1.4110 (1.4122) acc@1 0.5416 (0.5308) acc@5 0.9327 (0.9222)\n",
      "\u001b[32m[2020-07-10 06:12:46] __main__ INFO: \u001b[0mEpoch 32 Step 351/351 lr 0.100000 loss 1.3545 (1.4147) acc@1 0.5579 (0.5297) acc@5 0.9045 (0.9220)\n",
      "\u001b[32m[2020-07-10 06:12:46] __main__ INFO: \u001b[0mElapsed 33.50\n",
      "\u001b[32m[2020-07-10 06:12:46] __main__ INFO: \u001b[0mVal 32\n",
      "\u001b[32m[2020-07-10 06:12:47] __main__ INFO: \u001b[0mEpoch 32 loss 0.6825 acc@1 0.8178 acc@5 0.9910\n",
      "\u001b[32m[2020-07-10 06:12:47] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 06:12:47] __main__ INFO: \u001b[0mTrain 33 11232\n",
      "\u001b[32m[2020-07-10 06:12:56] __main__ INFO: \u001b[0mEpoch 33 Step 100/351 lr 0.100000 loss 1.3961 (1.4062) acc@1 0.5322 (0.5380) acc@5 0.9420 (0.9221)\n",
      "\u001b[32m[2020-07-10 06:13:06] __main__ INFO: \u001b[0mEpoch 33 Step 200/351 lr 0.100000 loss 1.4356 (1.4095) acc@1 0.5106 (0.5344) acc@5 0.8926 (0.9226)\n",
      "\u001b[32m[2020-07-10 06:13:15] __main__ INFO: \u001b[0mEpoch 33 Step 300/351 lr 0.100000 loss 1.4442 (1.4068) acc@1 0.5481 (0.5351) acc@5 0.9049 (0.9232)\n",
      "\u001b[32m[2020-07-10 06:13:20] __main__ INFO: \u001b[0mEpoch 33 Step 351/351 lr 0.100000 loss 1.3750 (1.4067) acc@1 0.5623 (0.5349) acc@5 0.9185 (0.9233)\n",
      "\u001b[32m[2020-07-10 06:13:20] __main__ INFO: \u001b[0mElapsed 33.47\n",
      "\u001b[32m[2020-07-10 06:13:20] __main__ INFO: \u001b[0mVal 33\n",
      "\u001b[32m[2020-07-10 06:13:21] __main__ INFO: \u001b[0mEpoch 33 loss 0.6753 acc@1 0.8282 acc@5 0.9904\n",
      "\u001b[32m[2020-07-10 06:13:21] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-07-10 06:13:21] __main__ INFO: \u001b[0mTrain 34 11583\n",
      "\u001b[32m[2020-07-10 06:13:31] __main__ INFO: \u001b[0mEpoch 34 Step 100/351 lr 0.100000 loss 1.4201 (1.3923) acc@1 0.5455 (0.5404) acc@5 0.9294 (0.9257)\n",
      "\u001b[32m[2020-07-10 06:13:40] __main__ INFO: \u001b[0mEpoch 34 Step 200/351 lr 0.100000 loss 1.4007 (1.3987) acc@1 0.5404 (0.5365) acc@5 0.9416 (0.9248)\n",
      "\u001b[32m[2020-07-10 06:13:50] __main__ INFO: \u001b[0mEpoch 34 Step 300/351 lr 0.100000 loss 1.3103 (1.3993) acc@1 0.5674 (0.5363) acc@5 0.9524 (0.9253)\n",
      "\u001b[32m[2020-07-10 06:13:55] __main__ INFO: \u001b[0mEpoch 34 Step 351/351 lr 0.100000 loss 1.4430 (1.4015) acc@1 0.5038 (0.5359) acc@5 0.9192 (0.9248)\n",
      "\u001b[32m[2020-07-10 06:13:55] __main__ INFO: \u001b[0mElapsed 33.47\n",
      "\u001b[32m[2020-07-10 06:13:55] __main__ INFO: \u001b[0mVal 34\n",
      "\u001b[32m[2020-07-10 06:13:56] __main__ INFO: \u001b[0mEpoch 34 loss 0.6654 acc@1 0.8350 acc@5 0.9904\n",
      "\u001b[32m[2020-07-10 06:13:56] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 06:13:56] __main__ INFO: \u001b[0mTrain 35 11934\n",
      "\u001b[32m[2020-07-10 06:14:06] __main__ INFO: \u001b[0mEpoch 35 Step 100/351 lr 0.100000 loss 1.4111 (1.3860) acc@1 0.5296 (0.5399) acc@5 0.8985 (0.9271)\n",
      "\u001b[32m[2020-07-10 06:14:15] __main__ INFO: \u001b[0mEpoch 35 Step 200/351 lr 0.100000 loss 1.4523 (1.3924) acc@1 0.5390 (0.5383) acc@5 0.9005 (0.9258)\n",
      "\u001b[32m[2020-07-10 06:14:25] __main__ INFO: \u001b[0mEpoch 35 Step 300/351 lr 0.100000 loss 1.4049 (1.3962) acc@1 0.5249 (0.5364) acc@5 0.9211 (0.9250)\n",
      "\u001b[32m[2020-07-10 06:14:29] __main__ INFO: \u001b[0mEpoch 35 Step 351/351 lr 0.100000 loss 1.4454 (1.3976) acc@1 0.5332 (0.5364) acc@5 0.9251 (0.9247)\n",
      "\u001b[32m[2020-07-10 06:14:29] __main__ INFO: \u001b[0mElapsed 33.54\n",
      "\u001b[32m[2020-07-10 06:14:29] __main__ INFO: \u001b[0mVal 35\n",
      "\u001b[32m[2020-07-10 06:14:31] __main__ INFO: \u001b[0mEpoch 35 loss 0.6994 acc@1 0.8182 acc@5 0.9904\n",
      "\u001b[32m[2020-07-10 06:14:31] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 06:14:31] __main__ INFO: \u001b[0mTrain 36 12285\n",
      "\u001b[32m[2020-07-10 06:14:40] __main__ INFO: \u001b[0mEpoch 36 Step 100/351 lr 0.100000 loss 1.4461 (1.3814) acc@1 0.5732 (0.5426) acc@5 0.9012 (0.9256)\n",
      "\u001b[32m[2020-07-10 06:14:50] __main__ INFO: \u001b[0mEpoch 36 Step 200/351 lr 0.100000 loss 1.3575 (1.3855) acc@1 0.5727 (0.5390) acc@5 0.9381 (0.9263)\n",
      "\u001b[32m[2020-07-10 06:14:59] __main__ INFO: \u001b[0mEpoch 36 Step 300/351 lr 0.100000 loss 1.3321 (1.3865) acc@1 0.5485 (0.5386) acc@5 0.9384 (0.9262)\n",
      "\u001b[32m[2020-07-10 06:15:04] __main__ INFO: \u001b[0mEpoch 36 Step 351/351 lr 0.100000 loss 1.3507 (1.3872) acc@1 0.5593 (0.5388) acc@5 0.9286 (0.9255)\n",
      "\u001b[32m[2020-07-10 06:15:04] __main__ INFO: \u001b[0mElapsed 33.54\n",
      "\u001b[32m[2020-07-10 06:15:04] __main__ INFO: \u001b[0mVal 36\n",
      "\u001b[32m[2020-07-10 06:15:05] __main__ INFO: \u001b[0mEpoch 36 loss 0.6323 acc@1 0.8438 acc@5 0.9900\n",
      "\u001b[32m[2020-07-10 06:15:05] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 06:15:05] __main__ INFO: \u001b[0mTrain 37 12636\n",
      "\u001b[32m[2020-07-10 06:15:15] __main__ INFO: \u001b[0mEpoch 37 Step 100/351 lr 0.100000 loss 1.4517 (1.3736) acc@1 0.5090 (0.5420) acc@5 0.9270 (0.9297)\n",
      "\u001b[32m[2020-07-10 06:15:24] __main__ INFO: \u001b[0mEpoch 37 Step 200/351 lr 0.100000 loss 1.4522 (1.3808) acc@1 0.4812 (0.5390) acc@5 0.9288 (0.9292)\n",
      "\u001b[32m[2020-07-10 06:15:34] __main__ INFO: \u001b[0mEpoch 37 Step 300/351 lr 0.100000 loss 1.4431 (1.3822) acc@1 0.5192 (0.5395) acc@5 0.9137 (0.9282)\n",
      "\u001b[32m[2020-07-10 06:15:39] __main__ INFO: \u001b[0mEpoch 37 Step 351/351 lr 0.100000 loss 1.3724 (1.3847) acc@1 0.5318 (0.5393) acc@5 0.9497 (0.9279)\n",
      "\u001b[32m[2020-07-10 06:15:39] __main__ INFO: \u001b[0mElapsed 33.49\n",
      "\u001b[32m[2020-07-10 06:15:39] __main__ INFO: \u001b[0mVal 37\n",
      "\u001b[32m[2020-07-10 06:15:40] __main__ INFO: \u001b[0mEpoch 37 loss 0.6336 acc@1 0.8294 acc@5 0.9916\n",
      "\u001b[32m[2020-07-10 06:15:40] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 06:15:40] __main__ INFO: \u001b[0mTrain 38 12987\n",
      "\u001b[32m[2020-07-10 06:15:49] __main__ INFO: \u001b[0mEpoch 38 Step 100/351 lr 0.100000 loss 1.4535 (1.3658) acc@1 0.5454 (0.5443) acc@5 0.8909 (0.9303)\n",
      "\u001b[32m[2020-07-10 06:15:59] __main__ INFO: \u001b[0mEpoch 38 Step 200/351 lr 0.100000 loss 1.4383 (1.3730) acc@1 0.5379 (0.5429) acc@5 0.9024 (0.9284)\n",
      "\u001b[32m[2020-07-10 06:16:08] __main__ INFO: \u001b[0mEpoch 38 Step 300/351 lr 0.100000 loss 1.3853 (1.3747) acc@1 0.5294 (0.5426) acc@5 0.9209 (0.9285)\n",
      "\u001b[32m[2020-07-10 06:16:13] __main__ INFO: \u001b[0mEpoch 38 Step 351/351 lr 0.100000 loss 1.4026 (1.3772) acc@1 0.5196 (0.5420) acc@5 0.9392 (0.9281)\n",
      "\u001b[32m[2020-07-10 06:16:13] __main__ INFO: \u001b[0mElapsed 33.57\n",
      "\u001b[32m[2020-07-10 06:16:13] __main__ INFO: \u001b[0mVal 38\n",
      "\u001b[32m[2020-07-10 06:16:14] __main__ INFO: \u001b[0mEpoch 38 loss 0.6631 acc@1 0.8362 acc@5 0.9918\n",
      "\u001b[32m[2020-07-10 06:16:14] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 06:16:14] __main__ INFO: \u001b[0mTrain 39 13338\n",
      "\u001b[32m[2020-07-10 06:16:24] __main__ INFO: \u001b[0mEpoch 39 Step 100/351 lr 0.100000 loss 1.3823 (1.3591) acc@1 0.5515 (0.5471) acc@5 0.9342 (0.9305)\n",
      "\u001b[32m[2020-07-10 06:16:34] __main__ INFO: \u001b[0mEpoch 39 Step 200/351 lr 0.100000 loss 1.4070 (1.3657) acc@1 0.5247 (0.5445) acc@5 0.9537 (0.9309)\n",
      "\u001b[32m[2020-07-10 06:16:43] __main__ INFO: \u001b[0mEpoch 39 Step 300/351 lr 0.100000 loss 1.4471 (1.3711) acc@1 0.5242 (0.5428) acc@5 0.9135 (0.9300)\n",
      "\u001b[32m[2020-07-10 06:16:48] __main__ INFO: \u001b[0mEpoch 39 Step 351/351 lr 0.100000 loss 1.4212 (1.3726) acc@1 0.5482 (0.5423) acc@5 0.9289 (0.9294)\n",
      "\u001b[32m[2020-07-10 06:16:48] __main__ INFO: \u001b[0mElapsed 33.54\n",
      "\u001b[32m[2020-07-10 06:16:48] __main__ INFO: \u001b[0mVal 39\n",
      "\u001b[32m[2020-07-10 06:16:49] __main__ INFO: \u001b[0mEpoch 39 loss 0.6236 acc@1 0.8396 acc@5 0.9912\n",
      "\u001b[32m[2020-07-10 06:16:49] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 06:16:49] __main__ INFO: \u001b[0mTrain 40 13689\n",
      "\u001b[32m[2020-07-10 06:16:59] __main__ INFO: \u001b[0mEpoch 40 Step 100/351 lr 0.100000 loss 1.3261 (1.3585) acc@1 0.5777 (0.5463) acc@5 0.9388 (0.9325)\n",
      "\u001b[32m[2020-07-10 06:17:08] __main__ INFO: \u001b[0mEpoch 40 Step 200/351 lr 0.100000 loss 1.3673 (1.3630) acc@1 0.5321 (0.5444) acc@5 0.9390 (0.9310)\n",
      "\u001b[32m[2020-07-10 06:17:18] __main__ INFO: \u001b[0mEpoch 40 Step 300/351 lr 0.100000 loss 1.3895 (1.3645) acc@1 0.5279 (0.5446) acc@5 0.9212 (0.9305)\n",
      "\u001b[32m[2020-07-10 06:17:23] __main__ INFO: \u001b[0mEpoch 40 Step 351/351 lr 0.100000 loss 1.4383 (1.3663) acc@1 0.5104 (0.5441) acc@5 0.9206 (0.9303)\n",
      "\u001b[32m[2020-07-10 06:17:23] __main__ INFO: \u001b[0mElapsed 33.50\n",
      "\u001b[32m[2020-07-10 06:17:23] __main__ INFO: \u001b[0mVal 40\n",
      "\u001b[32m[2020-07-10 06:17:24] __main__ INFO: \u001b[0mEpoch 40 loss 0.6644 acc@1 0.8230 acc@5 0.9880\n",
      "\u001b[32m[2020-07-10 06:17:24] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-07-10 06:17:24] __main__ INFO: \u001b[0mTrain 41 14040\n",
      "\u001b[32m[2020-07-10 06:17:33] __main__ INFO: \u001b[0mEpoch 41 Step 100/351 lr 0.100000 loss 1.2888 (1.3438) acc@1 0.5737 (0.5544) acc@5 0.9311 (0.9335)\n",
      "\u001b[32m[2020-07-10 06:17:43] __main__ INFO: \u001b[0mEpoch 41 Step 200/351 lr 0.100000 loss 1.3271 (1.3552) acc@1 0.5784 (0.5487) acc@5 0.9272 (0.9320)\n",
      "\u001b[32m[2020-07-10 06:17:52] __main__ INFO: \u001b[0mEpoch 41 Step 300/351 lr 0.100000 loss 1.3687 (1.3589) acc@1 0.5507 (0.5475) acc@5 0.9254 (0.9313)\n",
      "\u001b[32m[2020-07-10 06:17:57] __main__ INFO: \u001b[0mEpoch 41 Step 351/351 lr 0.100000 loss 1.2961 (1.3626) acc@1 0.5917 (0.5458) acc@5 0.9452 (0.9305)\n",
      "\u001b[32m[2020-07-10 06:17:57] __main__ INFO: \u001b[0mElapsed 33.48\n",
      "\u001b[32m[2020-07-10 06:17:57] __main__ INFO: \u001b[0mVal 41\n",
      "\u001b[32m[2020-07-10 06:17:58] __main__ INFO: \u001b[0mEpoch 41 loss 0.6239 acc@1 0.8382 acc@5 0.9910\n",
      "\u001b[32m[2020-07-10 06:17:58] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 06:17:58] __main__ INFO: \u001b[0mTrain 42 14391\n",
      "\u001b[32m[2020-07-10 06:18:08] __main__ INFO: \u001b[0mEpoch 42 Step 100/351 lr 0.100000 loss 1.4116 (1.3395) acc@1 0.5056 (0.5555) acc@5 0.9407 (0.9330)\n",
      "\u001b[32m[2020-07-10 06:18:17] __main__ INFO: \u001b[0mEpoch 42 Step 200/351 lr 0.100000 loss 1.3797 (1.3420) acc@1 0.5456 (0.5540) acc@5 0.9401 (0.9332)\n",
      "\u001b[32m[2020-07-10 06:18:27] __main__ INFO: \u001b[0mEpoch 42 Step 300/351 lr 0.100000 loss 1.3662 (1.3510) acc@1 0.5439 (0.5496) acc@5 0.9447 (0.9320)\n",
      "\u001b[32m[2020-07-10 06:18:32] __main__ INFO: \u001b[0mEpoch 42 Step 351/351 lr 0.100000 loss 1.4468 (1.3540) acc@1 0.5178 (0.5479) acc@5 0.8892 (0.9315)\n",
      "\u001b[32m[2020-07-10 06:18:32] __main__ INFO: \u001b[0mElapsed 33.53\n",
      "\u001b[32m[2020-07-10 06:18:32] __main__ INFO: \u001b[0mVal 42\n",
      "\u001b[32m[2020-07-10 06:18:33] __main__ INFO: \u001b[0mEpoch 42 loss 0.5978 acc@1 0.8586 acc@5 0.9924\n",
      "\u001b[32m[2020-07-10 06:18:33] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 06:18:33] __main__ INFO: \u001b[0mTrain 43 14742\n",
      "\u001b[32m[2020-07-10 06:18:42] __main__ INFO: \u001b[0mEpoch 43 Step 100/351 lr 0.100000 loss 1.3160 (1.3483) acc@1 0.5740 (0.5479) acc@5 0.9410 (0.9359)\n",
      "\u001b[32m[2020-07-10 06:18:52] __main__ INFO: \u001b[0mEpoch 43 Step 200/351 lr 0.100000 loss 1.3032 (1.3492) acc@1 0.5849 (0.5490) acc@5 0.9390 (0.9341)\n",
      "\u001b[32m[2020-07-10 06:19:01] __main__ INFO: \u001b[0mEpoch 43 Step 300/351 lr 0.100000 loss 1.3043 (1.3508) acc@1 0.5592 (0.5483) acc@5 0.9604 (0.9341)\n",
      "\u001b[32m[2020-07-10 06:19:06] __main__ INFO: \u001b[0mEpoch 43 Step 351/351 lr 0.100000 loss 1.4160 (1.3525) acc@1 0.5321 (0.5482) acc@5 0.9313 (0.9338)\n",
      "\u001b[32m[2020-07-10 06:19:06] __main__ INFO: \u001b[0mElapsed 33.52\n",
      "\u001b[32m[2020-07-10 06:19:06] __main__ INFO: \u001b[0mVal 43\n",
      "\u001b[32m[2020-07-10 06:19:07] __main__ INFO: \u001b[0mEpoch 43 loss 0.6796 acc@1 0.8188 acc@5 0.9914\n",
      "\u001b[32m[2020-07-10 06:19:07] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-07-10 06:19:07] __main__ INFO: \u001b[0mTrain 44 15093\n",
      "\u001b[32m[2020-07-10 06:19:17] __main__ INFO: \u001b[0mEpoch 44 Step 100/351 lr 0.100000 loss 1.3621 (1.3304) acc@1 0.5103 (0.5551) acc@5 0.9379 (0.9370)\n",
      "\u001b[32m[2020-07-10 06:19:27] __main__ INFO: \u001b[0mEpoch 44 Step 200/351 lr 0.100000 loss 1.3898 (1.3374) acc@1 0.5140 (0.5529) acc@5 0.9293 (0.9355)\n",
      "\u001b[32m[2020-07-10 06:19:36] __main__ INFO: \u001b[0mEpoch 44 Step 300/351 lr 0.100000 loss 1.4541 (1.3437) acc@1 0.4813 (0.5493) acc@5 0.9490 (0.9341)\n",
      "\u001b[32m[2020-07-10 06:19:41] __main__ INFO: \u001b[0mEpoch 44 Step 351/351 lr 0.100000 loss 1.3677 (1.3474) acc@1 0.5713 (0.5484) acc@5 0.9205 (0.9337)\n",
      "\u001b[32m[2020-07-10 06:19:41] __main__ INFO: \u001b[0mElapsed 33.48\n",
      "\u001b[32m[2020-07-10 06:19:41] __main__ INFO: \u001b[0mVal 44\n",
      "\u001b[32m[2020-07-10 06:19:42] __main__ INFO: \u001b[0mEpoch 44 loss 0.6553 acc@1 0.8336 acc@5 0.9926\n",
      "\u001b[32m[2020-07-10 06:19:42] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 06:19:42] __main__ INFO: \u001b[0mTrain 45 15444\n",
      "\u001b[32m[2020-07-10 06:19:52] __main__ INFO: \u001b[0mEpoch 45 Step 100/351 lr 0.100000 loss 1.4056 (1.3315) acc@1 0.5286 (0.5539) acc@5 0.9313 (0.9370)\n",
      "\u001b[32m[2020-07-10 06:20:01] __main__ INFO: \u001b[0mEpoch 45 Step 200/351 lr 0.100000 loss 1.4029 (1.3358) acc@1 0.5202 (0.5516) acc@5 0.9095 (0.9365)\n",
      "\u001b[32m[2020-07-10 06:20:11] __main__ INFO: \u001b[0mEpoch 45 Step 300/351 lr 0.100000 loss 1.3574 (1.3384) acc@1 0.5262 (0.5508) acc@5 0.9173 (0.9356)\n",
      "\u001b[32m[2020-07-10 06:20:15] __main__ INFO: \u001b[0mEpoch 45 Step 351/351 lr 0.100000 loss 1.3283 (1.3407) acc@1 0.5771 (0.5501) acc@5 0.9458 (0.9353)\n",
      "\u001b[32m[2020-07-10 06:20:16] __main__ INFO: \u001b[0mElapsed 33.53\n",
      "\u001b[32m[2020-07-10 06:20:16] __main__ INFO: \u001b[0mVal 45\n",
      "\u001b[32m[2020-07-10 06:20:17] __main__ INFO: \u001b[0mEpoch 45 loss 0.5918 acc@1 0.8498 acc@5 0.9934\n",
      "\u001b[32m[2020-07-10 06:20:17] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 06:20:17] __main__ INFO: \u001b[0mTrain 46 15795\n",
      "\u001b[32m[2020-07-10 06:20:26] __main__ INFO: \u001b[0mEpoch 46 Step 100/351 lr 0.100000 loss 1.3890 (1.3216) acc@1 0.5097 (0.5618) acc@5 0.9284 (0.9363)\n",
      "\u001b[32m[2020-07-10 06:20:36] __main__ INFO: \u001b[0mEpoch 46 Step 200/351 lr 0.100000 loss 1.2925 (1.3271) acc@1 0.5910 (0.5572) acc@5 0.9214 (0.9369)\n",
      "\u001b[32m[2020-07-10 06:20:45] __main__ INFO: \u001b[0mEpoch 46 Step 300/351 lr 0.100000 loss 1.3070 (1.3335) acc@1 0.5673 (0.5545) acc@5 0.9448 (0.9362)\n",
      "\u001b[32m[2020-07-10 06:20:50] __main__ INFO: \u001b[0mEpoch 46 Step 351/351 lr 0.100000 loss 1.3343 (1.3366) acc@1 0.5540 (0.5531) acc@5 0.9322 (0.9354)\n",
      "\u001b[32m[2020-07-10 06:20:50] __main__ INFO: \u001b[0mElapsed 33.49\n",
      "\u001b[32m[2020-07-10 06:20:50] __main__ INFO: \u001b[0mVal 46\n",
      "\u001b[32m[2020-07-10 06:20:51] __main__ INFO: \u001b[0mEpoch 46 loss 0.6927 acc@1 0.8152 acc@5 0.9882\n",
      "\u001b[32m[2020-07-10 06:20:51] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 06:20:51] __main__ INFO: \u001b[0mTrain 47 16146\n",
      "\u001b[32m[2020-07-10 06:21:01] __main__ INFO: \u001b[0mEpoch 47 Step 100/351 lr 0.100000 loss 1.3875 (1.3276) acc@1 0.5244 (0.5534) acc@5 0.9494 (0.9360)\n",
      "\u001b[32m[2020-07-10 06:21:10] __main__ INFO: \u001b[0mEpoch 47 Step 200/351 lr 0.100000 loss 1.2567 (1.3246) acc@1 0.5976 (0.5557) acc@5 0.9396 (0.9364)\n",
      "\u001b[32m[2020-07-10 06:21:20] __main__ INFO: \u001b[0mEpoch 47 Step 300/351 lr 0.100000 loss 1.2350 (1.3323) acc@1 0.5837 (0.5532) acc@5 0.9360 (0.9346)\n",
      "\u001b[32m[2020-07-10 06:21:25] __main__ INFO: \u001b[0mEpoch 47 Step 351/351 lr 0.100000 loss 1.3605 (1.3326) acc@1 0.5764 (0.5530) acc@5 0.9080 (0.9347)\n",
      "\u001b[32m[2020-07-10 06:21:25] __main__ INFO: \u001b[0mElapsed 33.52\n",
      "\u001b[32m[2020-07-10 06:21:25] __main__ INFO: \u001b[0mVal 47\n",
      "\u001b[32m[2020-07-10 06:21:26] __main__ INFO: \u001b[0mEpoch 47 loss 0.6657 acc@1 0.8332 acc@5 0.9906\n",
      "\u001b[32m[2020-07-10 06:21:26] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 06:21:26] __main__ INFO: \u001b[0mTrain 48 16497\n",
      "\u001b[32m[2020-07-10 06:21:35] __main__ INFO: \u001b[0mEpoch 48 Step 100/351 lr 0.100000 loss 1.3907 (1.3219) acc@1 0.5283 (0.5558) acc@5 0.9250 (0.9381)\n",
      "\u001b[32m[2020-07-10 06:21:45] __main__ INFO: \u001b[0mEpoch 48 Step 200/351 lr 0.100000 loss 1.2080 (1.3248) acc@1 0.5955 (0.5546) acc@5 0.9470 (0.9375)\n",
      "\u001b[32m[2020-07-10 06:21:54] __main__ INFO: \u001b[0mEpoch 48 Step 300/351 lr 0.100000 loss 1.2487 (1.3292) acc@1 0.5798 (0.5540) acc@5 0.9435 (0.9364)\n",
      "\u001b[32m[2020-07-10 06:21:59] __main__ INFO: \u001b[0mEpoch 48 Step 351/351 lr 0.100000 loss 1.3215 (1.3285) acc@1 0.5606 (0.5544) acc@5 0.9250 (0.9363)\n",
      "\u001b[32m[2020-07-10 06:21:59] __main__ INFO: \u001b[0mElapsed 33.48\n",
      "\u001b[32m[2020-07-10 06:21:59] __main__ INFO: \u001b[0mVal 48\n",
      "\u001b[32m[2020-07-10 06:22:00] __main__ INFO: \u001b[0mEpoch 48 loss 0.6194 acc@1 0.8382 acc@5 0.9924\n",
      "\u001b[32m[2020-07-10 06:22:00] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 06:22:00] __main__ INFO: \u001b[0mTrain 49 16848\n",
      "\u001b[32m[2020-07-10 06:22:10] __main__ INFO: \u001b[0mEpoch 49 Step 100/351 lr 0.100000 loss 1.3509 (1.3087) acc@1 0.5567 (0.5636) acc@5 0.9144 (0.9382)\n",
      "\u001b[32m[2020-07-10 06:22:19] __main__ INFO: \u001b[0mEpoch 49 Step 200/351 lr 0.100000 loss 1.3393 (1.3184) acc@1 0.5245 (0.5592) acc@5 0.9592 (0.9374)\n",
      "\u001b[32m[2020-07-10 06:22:29] __main__ INFO: \u001b[0mEpoch 49 Step 300/351 lr 0.100000 loss 1.3522 (1.3205) acc@1 0.5331 (0.5569) acc@5 0.9421 (0.9377)\n",
      "\u001b[32m[2020-07-10 06:22:34] __main__ INFO: \u001b[0mEpoch 49 Step 351/351 lr 0.100000 loss 1.3756 (1.3211) acc@1 0.5486 (0.5562) acc@5 0.9298 (0.9376)\n",
      "\u001b[32m[2020-07-10 06:22:34] __main__ INFO: \u001b[0mElapsed 33.43\n",
      "\u001b[32m[2020-07-10 06:22:34] __main__ INFO: \u001b[0mVal 49\n",
      "\u001b[32m[2020-07-10 06:22:35] __main__ INFO: \u001b[0mEpoch 49 loss 0.6455 acc@1 0.8432 acc@5 0.9906\n",
      "\u001b[32m[2020-07-10 06:22:35] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 06:22:35] __main__ INFO: \u001b[0mTrain 50 17199\n",
      "\u001b[32m[2020-07-10 06:22:45] __main__ INFO: \u001b[0mEpoch 50 Step 100/351 lr 0.100000 loss 1.2419 (1.2994) acc@1 0.5925 (0.5604) acc@5 0.9489 (0.9412)\n",
      "\u001b[32m[2020-07-10 06:22:54] __main__ INFO: \u001b[0mEpoch 50 Step 200/351 lr 0.100000 loss 1.3006 (1.3138) acc@1 0.5850 (0.5586) acc@5 0.9128 (0.9396)\n",
      "\u001b[32m[2020-07-10 06:23:04] __main__ INFO: \u001b[0mEpoch 50 Step 300/351 lr 0.100000 loss 1.3555 (1.3185) acc@1 0.5731 (0.5571) acc@5 0.9335 (0.9384)\n",
      "\u001b[32m[2020-07-10 06:23:08] __main__ INFO: \u001b[0mEpoch 50 Step 351/351 lr 0.100000 loss 1.3996 (1.3215) acc@1 0.5386 (0.5562) acc@5 0.9245 (0.9377)\n",
      "\u001b[32m[2020-07-10 06:23:08] __main__ INFO: \u001b[0mElapsed 33.49\n",
      "\u001b[32m[2020-07-10 06:23:08] __main__ INFO: \u001b[0mVal 50\n",
      "\u001b[32m[2020-07-10 06:23:09] __main__ INFO: \u001b[0mEpoch 50 loss 0.6724 acc@1 0.8270 acc@5 0.9920\n",
      "\u001b[32m[2020-07-10 06:23:09] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 06:23:09] __main__ INFO: \u001b[0mTrain 51 17550\n",
      "\u001b[32m[2020-07-10 06:23:19] __main__ INFO: \u001b[0mEpoch 51 Step 100/351 lr 0.100000 loss 1.2206 (1.3035) acc@1 0.5792 (0.5625) acc@5 0.9591 (0.9397)\n",
      "\u001b[32m[2020-07-10 06:23:29] __main__ INFO: \u001b[0mEpoch 51 Step 200/351 lr 0.100000 loss 1.2644 (1.3132) acc@1 0.5722 (0.5592) acc@5 0.9412 (0.9389)\n",
      "\u001b[32m[2020-07-10 06:23:38] __main__ INFO: \u001b[0mEpoch 51 Step 300/351 lr 0.100000 loss 1.2915 (1.3148) acc@1 0.5665 (0.5583) acc@5 0.9286 (0.9383)\n",
      "\u001b[32m[2020-07-10 06:23:43] __main__ INFO: \u001b[0mEpoch 51 Step 351/351 lr 0.100000 loss 1.3732 (1.3161) acc@1 0.5532 (0.5574) acc@5 0.9424 (0.9377)\n",
      "\u001b[32m[2020-07-10 06:23:43] __main__ INFO: \u001b[0mElapsed 33.51\n",
      "\u001b[32m[2020-07-10 06:23:43] __main__ INFO: \u001b[0mVal 51\n",
      "\u001b[32m[2020-07-10 06:23:44] __main__ INFO: \u001b[0mEpoch 51 loss 0.7377 acc@1 0.7960 acc@5 0.9872\n",
      "\u001b[32m[2020-07-10 06:23:44] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 06:23:44] __main__ INFO: \u001b[0mTrain 52 17901\n",
      "\u001b[32m[2020-07-10 06:23:54] __main__ INFO: \u001b[0mEpoch 52 Step 100/351 lr 0.100000 loss 1.2739 (1.3061) acc@1 0.5695 (0.5625) acc@5 0.9351 (0.9401)\n",
      "\u001b[32m[2020-07-10 06:24:03] __main__ INFO: \u001b[0mEpoch 52 Step 200/351 lr 0.100000 loss 1.2938 (1.3109) acc@1 0.5801 (0.5585) acc@5 0.9414 (0.9403)\n",
      "\u001b[32m[2020-07-10 06:24:13] __main__ INFO: \u001b[0mEpoch 52 Step 300/351 lr 0.100000 loss 1.4088 (1.3123) acc@1 0.5401 (0.5592) acc@5 0.9014 (0.9392)\n",
      "\u001b[32m[2020-07-10 06:24:18] __main__ INFO: \u001b[0mEpoch 52 Step 351/351 lr 0.100000 loss 1.2543 (1.3128) acc@1 0.6237 (0.5590) acc@5 0.9377 (0.9394)\n",
      "\u001b[32m[2020-07-10 06:24:18] __main__ INFO: \u001b[0mElapsed 33.52\n",
      "\u001b[32m[2020-07-10 06:24:18] __main__ INFO: \u001b[0mVal 52\n",
      "\u001b[32m[2020-07-10 06:24:19] __main__ INFO: \u001b[0mEpoch 52 loss 0.6536 acc@1 0.8536 acc@5 0.9908\n",
      "\u001b[32m[2020-07-10 06:24:19] __main__ INFO: \u001b[0mElapsed 1.11\n",
      "\u001b[32m[2020-07-10 06:24:19] __main__ INFO: \u001b[0mTrain 53 18252\n",
      "\u001b[32m[2020-07-10 06:24:28] __main__ INFO: \u001b[0mEpoch 53 Step 100/351 lr 0.100000 loss 1.2835 (1.2960) acc@1 0.5729 (0.5627) acc@5 0.9469 (0.9424)\n",
      "\u001b[32m[2020-07-10 06:24:38] __main__ INFO: \u001b[0mEpoch 53 Step 200/351 lr 0.100000 loss 1.3029 (1.3045) acc@1 0.5475 (0.5601) acc@5 0.9410 (0.9406)\n",
      "\u001b[32m[2020-07-10 06:24:47] __main__ INFO: \u001b[0mEpoch 53 Step 300/351 lr 0.100000 loss 1.3206 (1.3066) acc@1 0.5633 (0.5595) acc@5 0.9359 (0.9404)\n",
      "\u001b[32m[2020-07-10 06:24:52] __main__ INFO: \u001b[0mEpoch 53 Step 351/351 lr 0.100000 loss 1.2373 (1.3096) acc@1 0.5762 (0.5589) acc@5 0.9378 (0.9400)\n",
      "\u001b[32m[2020-07-10 06:24:52] __main__ INFO: \u001b[0mElapsed 33.58\n",
      "\u001b[32m[2020-07-10 06:24:52] __main__ INFO: \u001b[0mVal 53\n",
      "\u001b[32m[2020-07-10 06:24:53] __main__ INFO: \u001b[0mEpoch 53 loss 0.6213 acc@1 0.8436 acc@5 0.9916\n",
      "\u001b[32m[2020-07-10 06:24:53] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 06:24:53] __main__ INFO: \u001b[0mTrain 54 18603\n",
      "\u001b[32m[2020-07-10 06:25:03] __main__ INFO: \u001b[0mEpoch 54 Step 100/351 lr 0.100000 loss 1.3408 (1.2956) acc@1 0.5515 (0.5638) acc@5 0.9191 (0.9411)\n",
      "\u001b[32m[2020-07-10 06:25:13] __main__ INFO: \u001b[0mEpoch 54 Step 200/351 lr 0.100000 loss 1.3281 (1.3023) acc@1 0.5619 (0.5605) acc@5 0.9121 (0.9406)\n",
      "\u001b[32m[2020-07-10 06:25:22] __main__ INFO: \u001b[0mEpoch 54 Step 300/351 lr 0.100000 loss 1.3682 (1.3033) acc@1 0.5287 (0.5613) acc@5 0.9332 (0.9402)\n",
      "\u001b[32m[2020-07-10 06:25:27] __main__ INFO: \u001b[0mEpoch 54 Step 351/351 lr 0.100000 loss 1.3364 (1.3042) acc@1 0.5746 (0.5611) acc@5 0.9368 (0.9400)\n",
      "\u001b[32m[2020-07-10 06:25:27] __main__ INFO: \u001b[0mElapsed 33.49\n",
      "\u001b[32m[2020-07-10 06:25:27] __main__ INFO: \u001b[0mVal 54\n",
      "\u001b[32m[2020-07-10 06:25:28] __main__ INFO: \u001b[0mEpoch 54 loss 0.6999 acc@1 0.8154 acc@5 0.9896\n",
      "\u001b[32m[2020-07-10 06:25:28] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 06:25:28] __main__ INFO: \u001b[0mTrain 55 18954\n",
      "\u001b[32m[2020-07-10 06:25:38] __main__ INFO: \u001b[0mEpoch 55 Step 100/351 lr 0.100000 loss 1.2481 (1.2979) acc@1 0.5496 (0.5637) acc@5 0.9606 (0.9412)\n",
      "\u001b[32m[2020-07-10 06:25:47] __main__ INFO: \u001b[0mEpoch 55 Step 200/351 lr 0.100000 loss 1.2938 (1.2998) acc@1 0.5668 (0.5615) acc@5 0.9567 (0.9420)\n",
      "\u001b[32m[2020-07-10 06:25:57] __main__ INFO: \u001b[0mEpoch 55 Step 300/351 lr 0.100000 loss 1.2643 (1.3009) acc@1 0.5740 (0.5631) acc@5 0.9524 (0.9413)\n",
      "\u001b[32m[2020-07-10 06:26:01] __main__ INFO: \u001b[0mEpoch 55 Step 351/351 lr 0.100000 loss 1.3462 (1.3034) acc@1 0.5263 (0.5624) acc@5 0.9502 (0.9405)\n",
      "\u001b[32m[2020-07-10 06:26:01] __main__ INFO: \u001b[0mElapsed 33.49\n",
      "\u001b[32m[2020-07-10 06:26:01] __main__ INFO: \u001b[0mVal 55\n",
      "\u001b[32m[2020-07-10 06:26:03] __main__ INFO: \u001b[0mEpoch 55 loss 0.6047 acc@1 0.8562 acc@5 0.9928\n",
      "\u001b[32m[2020-07-10 06:26:03] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 06:26:03] __main__ INFO: \u001b[0mTrain 56 19305\n",
      "\u001b[32m[2020-07-10 06:26:12] __main__ INFO: \u001b[0mEpoch 56 Step 100/351 lr 0.100000 loss 1.1687 (1.2935) acc@1 0.6277 (0.5600) acc@5 0.9589 (0.9442)\n",
      "\u001b[32m[2020-07-10 06:26:22] __main__ INFO: \u001b[0mEpoch 56 Step 200/351 lr 0.100000 loss 1.2070 (1.2980) acc@1 0.5968 (0.5606) acc@5 0.9687 (0.9426)\n",
      "\u001b[32m[2020-07-10 06:26:31] __main__ INFO: \u001b[0mEpoch 56 Step 300/351 lr 0.100000 loss 1.2721 (1.2969) acc@1 0.5601 (0.5633) acc@5 0.9461 (0.9417)\n",
      "\u001b[32m[2020-07-10 06:26:36] __main__ INFO: \u001b[0mEpoch 56 Step 351/351 lr 0.100000 loss 1.3885 (1.2983) acc@1 0.5331 (0.5633) acc@5 0.9306 (0.9417)\n",
      "\u001b[32m[2020-07-10 06:26:36] __main__ INFO: \u001b[0mElapsed 33.50\n",
      "\u001b[32m[2020-07-10 06:26:36] __main__ INFO: \u001b[0mVal 56\n",
      "\u001b[32m[2020-07-10 06:26:37] __main__ INFO: \u001b[0mEpoch 56 loss 0.6177 acc@1 0.8456 acc@5 0.9908\n",
      "\u001b[32m[2020-07-10 06:26:37] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 06:26:37] __main__ INFO: \u001b[0mTrain 57 19656\n",
      "\u001b[32m[2020-07-10 06:26:47] __main__ INFO: \u001b[0mEpoch 57 Step 100/351 lr 0.100000 loss 1.2257 (1.2790) acc@1 0.5944 (0.5691) acc@5 0.9493 (0.9443)\n",
      "\u001b[32m[2020-07-10 06:26:56] __main__ INFO: \u001b[0mEpoch 57 Step 200/351 lr 0.100000 loss 1.3445 (1.2878) acc@1 0.5308 (0.5648) acc@5 0.9539 (0.9438)\n",
      "\u001b[32m[2020-07-10 06:27:06] __main__ INFO: \u001b[0mEpoch 57 Step 300/351 lr 0.100000 loss 1.3194 (1.2914) acc@1 0.5748 (0.5644) acc@5 0.9573 (0.9432)\n",
      "\u001b[32m[2020-07-10 06:27:11] __main__ INFO: \u001b[0mEpoch 57 Step 351/351 lr 0.100000 loss 1.2354 (1.2949) acc@1 0.6014 (0.5634) acc@5 0.9440 (0.9427)\n",
      "\u001b[32m[2020-07-10 06:27:11] __main__ INFO: \u001b[0mElapsed 33.52\n",
      "\u001b[32m[2020-07-10 06:27:11] __main__ INFO: \u001b[0mVal 57\n",
      "\u001b[32m[2020-07-10 06:27:12] __main__ INFO: \u001b[0mEpoch 57 loss 0.6335 acc@1 0.8396 acc@5 0.9884\n",
      "\u001b[32m[2020-07-10 06:27:12] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 06:27:12] __main__ INFO: \u001b[0mTrain 58 20007\n",
      "\u001b[32m[2020-07-10 06:27:21] __main__ INFO: \u001b[0mEpoch 58 Step 100/351 lr 0.100000 loss 1.3036 (1.2813) acc@1 0.6135 (0.5692) acc@5 0.8995 (0.9429)\n",
      "\u001b[32m[2020-07-10 06:27:31] __main__ INFO: \u001b[0mEpoch 58 Step 200/351 lr 0.100000 loss 1.3753 (1.2861) acc@1 0.5403 (0.5675) acc@5 0.9085 (0.9421)\n",
      "\u001b[32m[2020-07-10 06:27:40] __main__ INFO: \u001b[0mEpoch 58 Step 300/351 lr 0.100000 loss 1.3507 (1.2884) acc@1 0.5720 (0.5663) acc@5 0.9194 (0.9419)\n",
      "\u001b[32m[2020-07-10 06:27:45] __main__ INFO: \u001b[0mEpoch 58 Step 351/351 lr 0.100000 loss 1.3280 (1.2912) acc@1 0.5267 (0.5647) acc@5 0.9590 (0.9414)\n",
      "\u001b[32m[2020-07-10 06:27:45] __main__ INFO: \u001b[0mElapsed 33.54\n",
      "\u001b[32m[2020-07-10 06:27:45] __main__ INFO: \u001b[0mVal 58\n",
      "\u001b[32m[2020-07-10 06:27:46] __main__ INFO: \u001b[0mEpoch 58 loss 0.5563 acc@1 0.8802 acc@5 0.9952\n",
      "\u001b[32m[2020-07-10 06:27:46] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 06:27:46] __main__ INFO: \u001b[0mTrain 59 20358\n",
      "\u001b[32m[2020-07-10 06:27:56] __main__ INFO: \u001b[0mEpoch 59 Step 100/351 lr 0.100000 loss 1.2386 (1.2704) acc@1 0.5687 (0.5727) acc@5 0.9544 (0.9451)\n",
      "\u001b[32m[2020-07-10 06:28:06] __main__ INFO: \u001b[0mEpoch 59 Step 200/351 lr 0.100000 loss 1.3022 (1.2801) acc@1 0.5878 (0.5678) acc@5 0.9326 (0.9444)\n",
      "\u001b[32m[2020-07-10 06:28:15] __main__ INFO: \u001b[0mEpoch 59 Step 300/351 lr 0.100000 loss 1.2833 (1.2869) acc@1 0.5510 (0.5647) acc@5 0.9374 (0.9436)\n",
      "\u001b[32m[2020-07-10 06:28:20] __main__ INFO: \u001b[0mEpoch 59 Step 351/351 lr 0.100000 loss 1.1839 (1.2891) acc@1 0.6253 (0.5652) acc@5 0.9268 (0.9428)\n",
      "\u001b[32m[2020-07-10 06:28:20] __main__ INFO: \u001b[0mElapsed 33.58\n",
      "\u001b[32m[2020-07-10 06:28:20] __main__ INFO: \u001b[0mVal 59\n",
      "\u001b[32m[2020-07-10 06:28:21] __main__ INFO: \u001b[0mEpoch 59 loss 0.6508 acc@1 0.8312 acc@5 0.9926\n",
      "\u001b[32m[2020-07-10 06:28:21] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 06:28:21] __main__ INFO: \u001b[0mTrain 60 20709\n",
      "\u001b[32m[2020-07-10 06:28:31] __main__ INFO: \u001b[0mEpoch 60 Step 100/351 lr 0.100000 loss 1.2676 (1.2765) acc@1 0.5539 (0.5689) acc@5 0.9550 (0.9447)\n",
      "\u001b[32m[2020-07-10 06:28:40] __main__ INFO: \u001b[0mEpoch 60 Step 200/351 lr 0.100000 loss 1.2964 (1.2806) acc@1 0.5372 (0.5683) acc@5 0.9420 (0.9438)\n",
      "\u001b[32m[2020-07-10 06:28:50] __main__ INFO: \u001b[0mEpoch 60 Step 300/351 lr 0.100000 loss 1.3159 (1.2825) acc@1 0.5281 (0.5668) acc@5 0.9344 (0.9432)\n",
      "\u001b[32m[2020-07-10 06:28:55] __main__ INFO: \u001b[0mEpoch 60 Step 351/351 lr 0.100000 loss 1.3017 (1.2860) acc@1 0.5387 (0.5662) acc@5 0.9548 (0.9429)\n",
      "\u001b[32m[2020-07-10 06:28:55] __main__ INFO: \u001b[0mElapsed 33.49\n",
      "\u001b[32m[2020-07-10 06:28:55] __main__ INFO: \u001b[0mVal 60\n",
      "\u001b[32m[2020-07-10 06:28:56] __main__ INFO: \u001b[0mEpoch 60 loss 0.6115 acc@1 0.8322 acc@5 0.9932\n",
      "\u001b[32m[2020-07-10 06:28:56] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 06:28:56] __main__ INFO: \u001b[0mTrain 61 21060\n",
      "\u001b[32m[2020-07-10 06:29:05] __main__ INFO: \u001b[0mEpoch 61 Step 100/351 lr 0.100000 loss 1.2135 (1.2666) acc@1 0.5734 (0.5696) acc@5 0.9540 (0.9465)\n",
      "\u001b[32m[2020-07-10 06:29:15] __main__ INFO: \u001b[0mEpoch 61 Step 200/351 lr 0.100000 loss 1.2118 (1.2800) acc@1 0.6168 (0.5665) acc@5 0.9434 (0.9443)\n",
      "\u001b[32m[2020-07-10 06:29:24] __main__ INFO: \u001b[0mEpoch 61 Step 300/351 lr 0.100000 loss 1.1993 (1.2818) acc@1 0.5939 (0.5658) acc@5 0.9631 (0.9440)\n",
      "\u001b[32m[2020-07-10 06:29:29] __main__ INFO: \u001b[0mEpoch 61 Step 351/351 lr 0.100000 loss 1.3567 (1.2833) acc@1 0.5763 (0.5668) acc@5 0.9205 (0.9435)\n",
      "\u001b[32m[2020-07-10 06:29:29] __main__ INFO: \u001b[0mElapsed 33.49\n",
      "\u001b[32m[2020-07-10 06:29:29] __main__ INFO: \u001b[0mVal 61\n",
      "\u001b[32m[2020-07-10 06:29:30] __main__ INFO: \u001b[0mEpoch 61 loss 0.6784 acc@1 0.8346 acc@5 0.9826\n",
      "\u001b[32m[2020-07-10 06:29:30] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 06:29:30] __main__ INFO: \u001b[0mTrain 62 21411\n",
      "\u001b[32m[2020-07-10 06:29:40] __main__ INFO: \u001b[0mEpoch 62 Step 100/351 lr 0.100000 loss 1.2906 (1.2675) acc@1 0.5352 (0.5693) acc@5 0.9643 (0.9471)\n",
      "\u001b[32m[2020-07-10 06:29:49] __main__ INFO: \u001b[0mEpoch 62 Step 200/351 lr 0.100000 loss 1.3540 (1.2779) acc@1 0.5330 (0.5669) acc@5 0.9400 (0.9453)\n",
      "\u001b[32m[2020-07-10 06:29:59] __main__ INFO: \u001b[0mEpoch 62 Step 300/351 lr 0.100000 loss 1.2953 (1.2814) acc@1 0.5752 (0.5666) acc@5 0.9450 (0.9440)\n",
      "\u001b[32m[2020-07-10 06:30:04] __main__ INFO: \u001b[0mEpoch 62 Step 351/351 lr 0.100000 loss 1.2945 (1.2807) acc@1 0.5859 (0.5675) acc@5 0.9461 (0.9441)\n",
      "\u001b[32m[2020-07-10 06:30:04] __main__ INFO: \u001b[0mElapsed 33.50\n",
      "\u001b[32m[2020-07-10 06:30:04] __main__ INFO: \u001b[0mVal 62\n",
      "\u001b[32m[2020-07-10 06:30:05] __main__ INFO: \u001b[0mEpoch 62 loss 0.5917 acc@1 0.8598 acc@5 0.9924\n",
      "\u001b[32m[2020-07-10 06:30:05] __main__ INFO: \u001b[0mElapsed 1.11\n",
      "\u001b[32m[2020-07-10 06:30:05] __main__ INFO: \u001b[0mTrain 63 21762\n",
      "\u001b[32m[2020-07-10 06:30:14] __main__ INFO: \u001b[0mEpoch 63 Step 100/351 lr 0.100000 loss 1.1954 (1.2675) acc@1 0.6271 (0.5695) acc@5 0.9578 (0.9466)\n",
      "\u001b[32m[2020-07-10 06:30:24] __main__ INFO: \u001b[0mEpoch 63 Step 200/351 lr 0.100000 loss 1.3116 (1.2685) acc@1 0.5539 (0.5696) acc@5 0.9693 (0.9467)\n",
      "\u001b[32m[2020-07-10 06:30:33] __main__ INFO: \u001b[0mEpoch 63 Step 300/351 lr 0.100000 loss 1.2538 (1.2738) acc@1 0.5952 (0.5691) acc@5 0.9472 (0.9454)\n",
      "\u001b[32m[2020-07-10 06:30:38] __main__ INFO: \u001b[0mEpoch 63 Step 351/351 lr 0.100000 loss 1.2918 (1.2754) acc@1 0.5283 (0.5678) acc@5 0.9538 (0.9452)\n",
      "\u001b[32m[2020-07-10 06:30:38] __main__ INFO: \u001b[0mElapsed 33.56\n",
      "\u001b[32m[2020-07-10 06:30:38] __main__ INFO: \u001b[0mVal 63\n",
      "\u001b[32m[2020-07-10 06:30:39] __main__ INFO: \u001b[0mEpoch 63 loss 0.6389 acc@1 0.8360 acc@5 0.9926\n",
      "\u001b[32m[2020-07-10 06:30:39] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-07-10 06:30:39] __main__ INFO: \u001b[0mTrain 64 22113\n",
      "\u001b[32m[2020-07-10 06:30:49] __main__ INFO: \u001b[0mEpoch 64 Step 100/351 lr 0.100000 loss 1.3370 (1.2648) acc@1 0.5769 (0.5705) acc@5 0.9450 (0.9462)\n",
      "\u001b[32m[2020-07-10 06:30:59] __main__ INFO: \u001b[0mEpoch 64 Step 200/351 lr 0.100000 loss 1.2522 (1.2696) acc@1 0.5673 (0.5685) acc@5 0.9321 (0.9455)\n",
      "\u001b[32m[2020-07-10 06:31:08] __main__ INFO: \u001b[0mEpoch 64 Step 300/351 lr 0.100000 loss 1.1939 (1.2729) acc@1 0.6136 (0.5685) acc@5 0.9423 (0.9445)\n",
      "\u001b[32m[2020-07-10 06:31:13] __main__ INFO: \u001b[0mEpoch 64 Step 351/351 lr 0.100000 loss 1.3409 (1.2728) acc@1 0.5489 (0.5689) acc@5 0.9380 (0.9447)\n",
      "\u001b[32m[2020-07-10 06:31:13] __main__ INFO: \u001b[0mElapsed 33.55\n",
      "\u001b[32m[2020-07-10 06:31:13] __main__ INFO: \u001b[0mVal 64\n",
      "\u001b[32m[2020-07-10 06:31:14] __main__ INFO: \u001b[0mEpoch 64 loss 0.5895 acc@1 0.8534 acc@5 0.9932\n",
      "\u001b[32m[2020-07-10 06:31:14] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 06:31:14] __main__ INFO: \u001b[0mTrain 65 22464\n",
      "\u001b[32m[2020-07-10 06:31:24] __main__ INFO: \u001b[0mEpoch 65 Step 100/351 lr 0.100000 loss 1.2466 (1.2638) acc@1 0.5884 (0.5737) acc@5 0.9472 (0.9464)\n",
      "\u001b[32m[2020-07-10 06:31:33] __main__ INFO: \u001b[0mEpoch 65 Step 200/351 lr 0.100000 loss 1.2723 (1.2673) acc@1 0.5709 (0.5723) acc@5 0.9568 (0.9455)\n",
      "\u001b[32m[2020-07-10 06:31:43] __main__ INFO: \u001b[0mEpoch 65 Step 300/351 lr 0.100000 loss 1.2282 (1.2710) acc@1 0.6190 (0.5705) acc@5 0.9475 (0.9451)\n",
      "\u001b[32m[2020-07-10 06:31:48] __main__ INFO: \u001b[0mEpoch 65 Step 351/351 lr 0.100000 loss 1.2919 (1.2708) acc@1 0.5797 (0.5705) acc@5 0.9490 (0.9452)\n",
      "\u001b[32m[2020-07-10 06:31:48] __main__ INFO: \u001b[0mElapsed 33.50\n",
      "\u001b[32m[2020-07-10 06:31:48] __main__ INFO: \u001b[0mVal 65\n",
      "\u001b[32m[2020-07-10 06:31:49] __main__ INFO: \u001b[0mEpoch 65 loss 0.6241 acc@1 0.8402 acc@5 0.9874\n",
      "\u001b[32m[2020-07-10 06:31:49] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 06:31:49] __main__ INFO: \u001b[0mTrain 66 22815\n",
      "\u001b[32m[2020-07-10 06:31:58] __main__ INFO: \u001b[0mEpoch 66 Step 100/351 lr 0.100000 loss 1.2627 (1.2553) acc@1 0.5645 (0.5731) acc@5 0.9470 (0.9483)\n",
      "\u001b[32m[2020-07-10 06:32:08] __main__ INFO: \u001b[0mEpoch 66 Step 200/351 lr 0.100000 loss 1.2249 (1.2642) acc@1 0.5788 (0.5722) acc@5 0.9499 (0.9465)\n",
      "\u001b[32m[2020-07-10 06:32:17] __main__ INFO: \u001b[0mEpoch 66 Step 300/351 lr 0.100000 loss 1.2809 (1.2652) acc@1 0.5632 (0.5727) acc@5 0.9616 (0.9460)\n",
      "\u001b[32m[2020-07-10 06:32:22] __main__ INFO: \u001b[0mEpoch 66 Step 351/351 lr 0.100000 loss 1.3374 (1.2675) acc@1 0.5444 (0.5719) acc@5 0.9359 (0.9456)\n",
      "\u001b[32m[2020-07-10 06:32:22] __main__ INFO: \u001b[0mElapsed 33.52\n",
      "\u001b[32m[2020-07-10 06:32:22] __main__ INFO: \u001b[0mVal 66\n",
      "\u001b[32m[2020-07-10 06:32:23] __main__ INFO: \u001b[0mEpoch 66 loss 0.5540 acc@1 0.8616 acc@5 0.9946\n",
      "\u001b[32m[2020-07-10 06:32:23] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 06:32:23] __main__ INFO: \u001b[0mTrain 67 23166\n",
      "\u001b[32m[2020-07-10 06:32:33] __main__ INFO: \u001b[0mEpoch 67 Step 100/351 lr 0.100000 loss 1.2684 (1.2539) acc@1 0.5621 (0.5719) acc@5 0.9467 (0.9483)\n",
      "\u001b[32m[2020-07-10 06:32:42] __main__ INFO: \u001b[0mEpoch 67 Step 200/351 lr 0.100000 loss 1.2808 (1.2574) acc@1 0.5596 (0.5720) acc@5 0.9540 (0.9471)\n",
      "\u001b[32m[2020-07-10 06:32:52] __main__ INFO: \u001b[0mEpoch 67 Step 300/351 lr 0.100000 loss 1.2668 (1.2643) acc@1 0.5342 (0.5707) acc@5 0.9529 (0.9463)\n",
      "\u001b[32m[2020-07-10 06:32:57] __main__ INFO: \u001b[0mEpoch 67 Step 351/351 lr 0.100000 loss 1.2359 (1.2659) acc@1 0.5584 (0.5702) acc@5 0.9568 (0.9459)\n",
      "\u001b[32m[2020-07-10 06:32:57] __main__ INFO: \u001b[0mElapsed 33.57\n",
      "\u001b[32m[2020-07-10 06:32:57] __main__ INFO: \u001b[0mVal 67\n",
      "\u001b[32m[2020-07-10 06:32:58] __main__ INFO: \u001b[0mEpoch 67 loss 0.6404 acc@1 0.8498 acc@5 0.9850\n",
      "\u001b[32m[2020-07-10 06:32:58] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 06:32:58] __main__ INFO: \u001b[0mTrain 68 23517\n",
      "\u001b[32m[2020-07-10 06:33:08] __main__ INFO: \u001b[0mEpoch 68 Step 100/351 lr 0.100000 loss 1.2809 (1.2552) acc@1 0.5695 (0.5705) acc@5 0.9234 (0.9486)\n",
      "\u001b[32m[2020-07-10 06:33:17] __main__ INFO: \u001b[0mEpoch 68 Step 200/351 lr 0.100000 loss 1.1944 (1.2541) acc@1 0.5861 (0.5727) acc@5 0.9428 (0.9481)\n",
      "\u001b[32m[2020-07-10 06:33:27] __main__ INFO: \u001b[0mEpoch 68 Step 300/351 lr 0.100000 loss 1.2789 (1.2612) acc@1 0.5241 (0.5719) acc@5 0.9546 (0.9470)\n",
      "\u001b[32m[2020-07-10 06:33:31] __main__ INFO: \u001b[0mEpoch 68 Step 351/351 lr 0.100000 loss 1.3404 (1.2628) acc@1 0.5362 (0.5720) acc@5 0.9569 (0.9464)\n",
      "\u001b[32m[2020-07-10 06:33:31] __main__ INFO: \u001b[0mElapsed 33.51\n",
      "\u001b[32m[2020-07-10 06:33:31] __main__ INFO: \u001b[0mVal 68\n",
      "\u001b[32m[2020-07-10 06:33:33] __main__ INFO: \u001b[0mEpoch 68 loss 0.5825 acc@1 0.8646 acc@5 0.9894\n",
      "\u001b[32m[2020-07-10 06:33:33] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 06:33:33] __main__ INFO: \u001b[0mTrain 69 23868\n",
      "\u001b[32m[2020-07-10 06:33:42] __main__ INFO: \u001b[0mEpoch 69 Step 100/351 lr 0.100000 loss 1.2599 (1.2481) acc@1 0.5860 (0.5751) acc@5 0.9515 (0.9495)\n",
      "\u001b[32m[2020-07-10 06:33:52] __main__ INFO: \u001b[0mEpoch 69 Step 200/351 lr 0.100000 loss 1.2816 (1.2540) acc@1 0.5858 (0.5746) acc@5 0.9478 (0.9484)\n",
      "\u001b[32m[2020-07-10 06:34:01] __main__ INFO: \u001b[0mEpoch 69 Step 300/351 lr 0.100000 loss 1.2686 (1.2584) acc@1 0.5655 (0.5725) acc@5 0.9414 (0.9471)\n",
      "\u001b[32m[2020-07-10 06:34:06] __main__ INFO: \u001b[0mEpoch 69 Step 351/351 lr 0.100000 loss 1.2155 (1.2603) acc@1 0.5980 (0.5724) acc@5 0.9470 (0.9466)\n",
      "\u001b[32m[2020-07-10 06:34:06] __main__ INFO: \u001b[0mElapsed 33.51\n",
      "\u001b[32m[2020-07-10 06:34:06] __main__ INFO: \u001b[0mVal 69\n",
      "\u001b[32m[2020-07-10 06:34:07] __main__ INFO: \u001b[0mEpoch 69 loss 0.5877 acc@1 0.8514 acc@5 0.9928\n",
      "\u001b[32m[2020-07-10 06:34:07] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 06:34:07] __main__ INFO: \u001b[0mTrain 70 24219\n",
      "\u001b[32m[2020-07-10 06:34:17] __main__ INFO: \u001b[0mEpoch 70 Step 100/351 lr 0.100000 loss 1.3178 (1.2485) acc@1 0.5517 (0.5769) acc@5 0.9492 (0.9490)\n",
      "\u001b[32m[2020-07-10 06:34:26] __main__ INFO: \u001b[0mEpoch 70 Step 200/351 lr 0.100000 loss 1.2822 (1.2525) acc@1 0.5618 (0.5766) acc@5 0.9498 (0.9478)\n",
      "\u001b[32m[2020-07-10 06:34:36] __main__ INFO: \u001b[0mEpoch 70 Step 300/351 lr 0.100000 loss 1.2393 (1.2564) acc@1 0.6322 (0.5748) acc@5 0.9578 (0.9479)\n",
      "\u001b[32m[2020-07-10 06:34:41] __main__ INFO: \u001b[0mEpoch 70 Step 351/351 lr 0.100000 loss 1.2012 (1.2595) acc@1 0.5750 (0.5733) acc@5 0.9632 (0.9477)\n",
      "\u001b[32m[2020-07-10 06:34:41] __main__ INFO: \u001b[0mElapsed 33.53\n",
      "\u001b[32m[2020-07-10 06:34:41] __main__ INFO: \u001b[0mVal 70\n",
      "\u001b[32m[2020-07-10 06:34:42] __main__ INFO: \u001b[0mEpoch 70 loss 0.5923 acc@1 0.8588 acc@5 0.9898\n",
      "\u001b[32m[2020-07-10 06:34:42] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 06:34:42] __main__ INFO: \u001b[0mTrain 71 24570\n",
      "\u001b[32m[2020-07-10 06:34:51] __main__ INFO: \u001b[0mEpoch 71 Step 100/351 lr 0.100000 loss 1.2282 (1.2319) acc@1 0.5879 (0.5800) acc@5 0.9528 (0.9495)\n",
      "\u001b[32m[2020-07-10 06:35:01] __main__ INFO: \u001b[0mEpoch 71 Step 200/351 lr 0.100000 loss 1.2288 (1.2426) acc@1 0.5643 (0.5774) acc@5 0.9651 (0.9487)\n",
      "\u001b[32m[2020-07-10 06:35:10] __main__ INFO: \u001b[0mEpoch 71 Step 300/351 lr 0.100000 loss 1.3053 (1.2485) acc@1 0.5893 (0.5753) acc@5 0.9454 (0.9479)\n",
      "\u001b[32m[2020-07-10 06:35:15] __main__ INFO: \u001b[0mEpoch 71 Step 351/351 lr 0.100000 loss 1.2598 (1.2508) acc@1 0.5571 (0.5746) acc@5 0.9537 (0.9477)\n",
      "\u001b[32m[2020-07-10 06:35:15] __main__ INFO: \u001b[0mElapsed 33.50\n",
      "\u001b[32m[2020-07-10 06:35:15] __main__ INFO: \u001b[0mVal 71\n",
      "\u001b[32m[2020-07-10 06:35:16] __main__ INFO: \u001b[0mEpoch 71 loss 0.6996 acc@1 0.8270 acc@5 0.9850\n",
      "\u001b[32m[2020-07-10 06:35:16] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-07-10 06:35:16] __main__ INFO: \u001b[0mTrain 72 24921\n",
      "\u001b[32m[2020-07-10 06:35:26] __main__ INFO: \u001b[0mEpoch 72 Step 100/351 lr 0.100000 loss 1.2067 (1.2447) acc@1 0.6062 (0.5751) acc@5 0.9582 (0.9473)\n",
      "\u001b[32m[2020-07-10 06:35:35] __main__ INFO: \u001b[0mEpoch 72 Step 200/351 lr 0.100000 loss 1.3614 (1.2466) acc@1 0.5399 (0.5758) acc@5 0.9244 (0.9487)\n",
      "\u001b[32m[2020-07-10 06:35:45] __main__ INFO: \u001b[0mEpoch 72 Step 300/351 lr 0.100000 loss 1.3251 (1.2512) acc@1 0.5280 (0.5753) acc@5 0.9475 (0.9478)\n",
      "\u001b[32m[2020-07-10 06:35:50] __main__ INFO: \u001b[0mEpoch 72 Step 351/351 lr 0.100000 loss 1.1949 (1.2529) acc@1 0.6090 (0.5749) acc@5 0.9554 (0.9475)\n",
      "\u001b[32m[2020-07-10 06:35:50] __main__ INFO: \u001b[0mElapsed 33.50\n",
      "\u001b[32m[2020-07-10 06:35:50] __main__ INFO: \u001b[0mVal 72\n",
      "\u001b[32m[2020-07-10 06:35:51] __main__ INFO: \u001b[0mEpoch 72 loss 0.6553 acc@1 0.8288 acc@5 0.9876\n",
      "\u001b[32m[2020-07-10 06:35:51] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 06:35:51] __main__ INFO: \u001b[0mTrain 73 25272\n",
      "\u001b[32m[2020-07-10 06:36:01] __main__ INFO: \u001b[0mEpoch 73 Step 100/351 lr 0.100000 loss 1.1858 (1.2353) acc@1 0.6231 (0.5814) acc@5 0.9514 (0.9495)\n",
      "\u001b[32m[2020-07-10 06:36:10] __main__ INFO: \u001b[0mEpoch 73 Step 200/351 lr 0.100000 loss 1.2246 (1.2476) acc@1 0.6033 (0.5760) acc@5 0.9463 (0.9486)\n",
      "\u001b[32m[2020-07-10 06:36:20] __main__ INFO: \u001b[0mEpoch 73 Step 300/351 lr 0.100000 loss 1.2718 (1.2524) acc@1 0.5604 (0.5757) acc@5 0.9481 (0.9478)\n",
      "\u001b[32m[2020-07-10 06:36:24] __main__ INFO: \u001b[0mEpoch 73 Step 351/351 lr 0.100000 loss 1.2689 (1.2543) acc@1 0.5777 (0.5753) acc@5 0.9556 (0.9476)\n",
      "\u001b[32m[2020-07-10 06:36:24] __main__ INFO: \u001b[0mElapsed 33.50\n",
      "\u001b[32m[2020-07-10 06:36:24] __main__ INFO: \u001b[0mVal 73\n",
      "\u001b[32m[2020-07-10 06:36:26] __main__ INFO: \u001b[0mEpoch 73 loss 0.5242 acc@1 0.8762 acc@5 0.9914\n",
      "\u001b[32m[2020-07-10 06:36:26] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 06:36:26] __main__ INFO: \u001b[0mTrain 74 25623\n",
      "\u001b[32m[2020-07-10 06:36:35] __main__ INFO: \u001b[0mEpoch 74 Step 100/351 lr 0.100000 loss 1.1954 (1.2346) acc@1 0.6095 (0.5808) acc@5 0.9605 (0.9505)\n",
      "\u001b[32m[2020-07-10 06:36:45] __main__ INFO: \u001b[0mEpoch 74 Step 200/351 lr 0.100000 loss 1.1136 (1.2412) acc@1 0.6333 (0.5778) acc@5 0.9780 (0.9497)\n",
      "\u001b[32m[2020-07-10 06:36:54] __main__ INFO: \u001b[0mEpoch 74 Step 300/351 lr 0.100000 loss 1.2417 (1.2472) acc@1 0.5382 (0.5754) acc@5 0.9461 (0.9486)\n",
      "\u001b[32m[2020-07-10 06:36:59] __main__ INFO: \u001b[0mEpoch 74 Step 351/351 lr 0.100000 loss 1.2709 (1.2473) acc@1 0.5721 (0.5755) acc@5 0.9359 (0.9486)\n",
      "\u001b[32m[2020-07-10 06:36:59] __main__ INFO: \u001b[0mElapsed 33.48\n",
      "\u001b[32m[2020-07-10 06:36:59] __main__ INFO: \u001b[0mVal 74\n",
      "\u001b[32m[2020-07-10 06:37:00] __main__ INFO: \u001b[0mEpoch 74 loss 0.5522 acc@1 0.8718 acc@5 0.9924\n",
      "\u001b[32m[2020-07-10 06:37:00] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 06:37:00] __main__ INFO: \u001b[0mTrain 75 25974\n",
      "\u001b[32m[2020-07-10 06:37:10] __main__ INFO: \u001b[0mEpoch 75 Step 100/351 lr 0.100000 loss 1.1532 (1.2315) acc@1 0.6296 (0.5803) acc@5 0.9570 (0.9511)\n",
      "\u001b[32m[2020-07-10 06:37:19] __main__ INFO: \u001b[0mEpoch 75 Step 200/351 lr 0.100000 loss 1.3135 (1.2371) acc@1 0.5226 (0.5790) acc@5 0.9419 (0.9505)\n",
      "\u001b[32m[2020-07-10 06:37:29] __main__ INFO: \u001b[0mEpoch 75 Step 300/351 lr 0.100000 loss 1.3367 (1.2443) acc@1 0.5677 (0.5771) acc@5 0.9382 (0.9494)\n",
      "\u001b[32m[2020-07-10 06:37:34] __main__ INFO: \u001b[0mEpoch 75 Step 351/351 lr 0.100000 loss 1.3513 (1.2463) acc@1 0.5270 (0.5763) acc@5 0.9356 (0.9492)\n",
      "\u001b[32m[2020-07-10 06:37:34] __main__ INFO: \u001b[0mElapsed 33.53\n",
      "\u001b[32m[2020-07-10 06:37:34] __main__ INFO: \u001b[0mVal 75\n",
      "\u001b[32m[2020-07-10 06:37:35] __main__ INFO: \u001b[0mEpoch 75 loss 0.5190 acc@1 0.8792 acc@5 0.9948\n",
      "\u001b[32m[2020-07-10 06:37:35] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 06:37:35] __main__ INFO: \u001b[0mTrain 76 26325\n",
      "\u001b[32m[2020-07-10 06:37:44] __main__ INFO: \u001b[0mEpoch 76 Step 100/351 lr 0.100000 loss 1.1555 (1.2319) acc@1 0.6304 (0.5803) acc@5 0.9567 (0.9506)\n",
      "\u001b[32m[2020-07-10 06:37:54] __main__ INFO: \u001b[0mEpoch 76 Step 200/351 lr 0.100000 loss 1.3679 (1.2386) acc@1 0.5388 (0.5786) acc@5 0.9376 (0.9495)\n",
      "\u001b[32m[2020-07-10 06:38:03] __main__ INFO: \u001b[0mEpoch 76 Step 300/351 lr 0.100000 loss 1.2069 (1.2417) acc@1 0.6101 (0.5793) acc@5 0.9663 (0.9495)\n",
      "\u001b[32m[2020-07-10 06:38:08] __main__ INFO: \u001b[0mEpoch 76 Step 351/351 lr 0.100000 loss 1.5021 (1.2445) acc@1 0.5000 (0.5781) acc@5 0.9177 (0.9492)\n",
      "\u001b[32m[2020-07-10 06:38:08] __main__ INFO: \u001b[0mElapsed 33.50\n",
      "\u001b[32m[2020-07-10 06:38:08] __main__ INFO: \u001b[0mVal 76\n",
      "\u001b[32m[2020-07-10 06:38:09] __main__ INFO: \u001b[0mEpoch 76 loss 0.5511 acc@1 0.8654 acc@5 0.9934\n",
      "\u001b[32m[2020-07-10 06:38:09] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 06:38:09] __main__ INFO: \u001b[0mTrain 77 26676\n",
      "\u001b[32m[2020-07-10 06:38:19] __main__ INFO: \u001b[0mEpoch 77 Step 100/351 lr 0.100000 loss 1.2679 (1.2268) acc@1 0.5288 (0.5811) acc@5 0.9648 (0.9516)\n",
      "\u001b[32m[2020-07-10 06:38:28] __main__ INFO: \u001b[0mEpoch 77 Step 200/351 lr 0.100000 loss 1.2027 (1.2333) acc@1 0.5998 (0.5809) acc@5 0.9527 (0.9505)\n",
      "\u001b[32m[2020-07-10 06:38:38] __main__ INFO: \u001b[0mEpoch 77 Step 300/351 lr 0.100000 loss 1.3343 (1.2390) acc@1 0.5022 (0.5795) acc@5 0.9495 (0.9498)\n",
      "\u001b[32m[2020-07-10 06:38:43] __main__ INFO: \u001b[0mEpoch 77 Step 351/351 lr 0.100000 loss 1.2827 (1.2408) acc@1 0.5774 (0.5785) acc@5 0.9354 (0.9497)\n",
      "\u001b[32m[2020-07-10 06:38:43] __main__ INFO: \u001b[0mElapsed 33.44\n",
      "\u001b[32m[2020-07-10 06:38:43] __main__ INFO: \u001b[0mVal 77\n",
      "\u001b[32m[2020-07-10 06:38:44] __main__ INFO: \u001b[0mEpoch 77 loss 0.5653 acc@1 0.8666 acc@5 0.9912\n",
      "\u001b[32m[2020-07-10 06:38:44] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 06:38:44] __main__ INFO: \u001b[0mTrain 78 27027\n",
      "\u001b[32m[2020-07-10 06:38:54] __main__ INFO: \u001b[0mEpoch 78 Step 100/351 lr 0.100000 loss 1.2422 (1.2353) acc@1 0.5799 (0.5792) acc@5 0.9505 (0.9507)\n",
      "\u001b[32m[2020-07-10 06:39:03] __main__ INFO: \u001b[0mEpoch 78 Step 200/351 lr 0.100000 loss 1.2438 (1.2348) acc@1 0.5772 (0.5803) acc@5 0.9530 (0.9505)\n",
      "\u001b[32m[2020-07-10 06:39:12] __main__ INFO: \u001b[0mEpoch 78 Step 300/351 lr 0.100000 loss 1.2933 (1.2404) acc@1 0.5526 (0.5776) acc@5 0.9542 (0.9499)\n",
      "\u001b[32m[2020-07-10 06:39:17] __main__ INFO: \u001b[0mEpoch 78 Step 351/351 lr 0.100000 loss 1.3068 (1.2412) acc@1 0.5497 (0.5773) acc@5 0.9151 (0.9496)\n",
      "\u001b[32m[2020-07-10 06:39:17] __main__ INFO: \u001b[0mElapsed 33.48\n",
      "\u001b[32m[2020-07-10 06:39:17] __main__ INFO: \u001b[0mVal 78\n",
      "\u001b[32m[2020-07-10 06:39:18] __main__ INFO: \u001b[0mEpoch 78 loss 0.5181 acc@1 0.8806 acc@5 0.9926\n",
      "\u001b[32m[2020-07-10 06:39:18] __main__ INFO: \u001b[0mElapsed 1.12\n",
      "\u001b[32m[2020-07-10 06:39:18] __main__ INFO: \u001b[0mTrain 79 27378\n",
      "\u001b[32m[2020-07-10 06:39:28] __main__ INFO: \u001b[0mEpoch 79 Step 100/351 lr 0.100000 loss 1.2635 (1.2217) acc@1 0.5715 (0.5851) acc@5 0.9465 (0.9516)\n",
      "\u001b[32m[2020-07-10 06:39:38] __main__ INFO: \u001b[0mEpoch 79 Step 200/351 lr 0.100000 loss 1.2398 (1.2304) acc@1 0.5975 (0.5817) acc@5 0.9475 (0.9510)\n",
      "\u001b[32m[2020-07-10 06:39:47] __main__ INFO: \u001b[0mEpoch 79 Step 300/351 lr 0.100000 loss 1.2471 (1.2337) acc@1 0.5533 (0.5803) acc@5 0.9488 (0.9501)\n",
      "\u001b[32m[2020-07-10 06:39:52] __main__ INFO: \u001b[0mEpoch 79 Step 351/351 lr 0.100000 loss 1.3079 (1.2366) acc@1 0.5373 (0.5791) acc@5 0.9429 (0.9502)\n",
      "\u001b[32m[2020-07-10 06:39:52] __main__ INFO: \u001b[0mElapsed 33.58\n",
      "\u001b[32m[2020-07-10 06:39:52] __main__ INFO: \u001b[0mVal 79\n",
      "\u001b[32m[2020-07-10 06:39:53] __main__ INFO: \u001b[0mEpoch 79 loss 0.6394 acc@1 0.8312 acc@5 0.9868\n",
      "\u001b[32m[2020-07-10 06:39:53] __main__ INFO: \u001b[0mElapsed 1.11\n",
      "\u001b[32m[2020-07-10 06:39:53] __main__ INFO: \u001b[0mTrain 80 27729\n",
      "\u001b[32m[2020-07-10 06:40:03] __main__ INFO: \u001b[0mEpoch 80 Step 100/351 lr 0.100000 loss 1.2166 (1.2266) acc@1 0.5826 (0.5794) acc@5 0.9515 (0.9520)\n",
      "\u001b[32m[2020-07-10 06:40:12] __main__ INFO: \u001b[0mEpoch 80 Step 200/351 lr 0.100000 loss 1.3011 (1.2342) acc@1 0.5496 (0.5768) acc@5 0.9393 (0.9507)\n",
      "\u001b[32m[2020-07-10 06:40:22] __main__ INFO: \u001b[0mEpoch 80 Step 300/351 lr 0.100000 loss 1.3325 (1.2350) acc@1 0.5818 (0.5771) acc@5 0.9157 (0.9508)\n",
      "\u001b[32m[2020-07-10 06:40:27] __main__ INFO: \u001b[0mEpoch 80 Step 351/351 lr 0.100000 loss 1.1741 (1.2383) acc@1 0.6183 (0.5767) acc@5 0.9484 (0.9502)\n",
      "\u001b[32m[2020-07-10 06:40:27] __main__ INFO: \u001b[0mElapsed 33.47\n",
      "\u001b[32m[2020-07-10 06:40:27] __main__ INFO: \u001b[0mVal 80\n",
      "\u001b[32m[2020-07-10 06:40:28] __main__ INFO: \u001b[0mEpoch 80 loss 0.5599 acc@1 0.8626 acc@5 0.9900\n",
      "\u001b[32m[2020-07-10 06:40:28] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 06:40:28] __main__ INFO: \u001b[0mTrain 81 28080\n",
      "\u001b[32m[2020-07-10 06:40:37] __main__ INFO: \u001b[0mEpoch 81 Step 100/351 lr 0.010000 loss 1.1188 (1.1637) acc@1 0.6135 (0.6022) acc@5 0.9519 (0.9603)\n",
      "\u001b[32m[2020-07-10 06:40:47] __main__ INFO: \u001b[0mEpoch 81 Step 200/351 lr 0.010000 loss 1.0809 (1.1504) acc@1 0.6013 (0.6071) acc@5 0.9734 (0.9603)\n",
      "\u001b[32m[2020-07-10 06:40:56] __main__ INFO: \u001b[0mEpoch 81 Step 300/351 lr 0.010000 loss 1.0722 (1.1413) acc@1 0.6358 (0.6086) acc@5 0.9657 (0.9615)\n",
      "\u001b[32m[2020-07-10 06:41:01] __main__ INFO: \u001b[0mEpoch 81 Step 351/351 lr 0.010000 loss 1.1348 (1.1394) acc@1 0.6308 (0.6093) acc@5 0.9507 (0.9615)\n",
      "\u001b[32m[2020-07-10 06:41:01] __main__ INFO: \u001b[0mElapsed 33.54\n",
      "\u001b[32m[2020-07-10 06:41:01] __main__ INFO: \u001b[0mVal 81\n",
      "\u001b[32m[2020-07-10 06:41:02] __main__ INFO: \u001b[0mEpoch 81 loss 0.4169 acc@1 0.9216 acc@5 0.9954\n",
      "\u001b[32m[2020-07-10 06:41:02] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 06:41:02] __main__ INFO: \u001b[0mTrain 82 28431\n",
      "\u001b[32m[2020-07-10 06:41:12] __main__ INFO: \u001b[0mEpoch 82 Step 100/351 lr 0.010000 loss 1.0533 (1.1058) acc@1 0.6577 (0.6189) acc@5 0.9682 (0.9649)\n",
      "\u001b[32m[2020-07-10 06:41:21] __main__ INFO: \u001b[0mEpoch 82 Step 200/351 lr 0.010000 loss 1.0356 (1.1025) acc@1 0.6733 (0.6199) acc@5 0.9794 (0.9654)\n",
      "\u001b[32m[2020-07-10 06:41:31] __main__ INFO: \u001b[0mEpoch 82 Step 300/351 lr 0.010000 loss 0.9767 (1.0995) acc@1 0.7084 (0.6194) acc@5 0.9672 (0.9660)\n",
      "\u001b[32m[2020-07-10 06:41:36] __main__ INFO: \u001b[0mEpoch 82 Step 351/351 lr 0.010000 loss 1.0407 (1.1001) acc@1 0.6332 (0.6185) acc@5 0.9769 (0.9659)\n",
      "\u001b[32m[2020-07-10 06:41:36] __main__ INFO: \u001b[0mElapsed 33.46\n",
      "\u001b[32m[2020-07-10 06:41:36] __main__ INFO: \u001b[0mVal 82\n",
      "\u001b[32m[2020-07-10 06:41:37] __main__ INFO: \u001b[0mEpoch 82 loss 0.4223 acc@1 0.9228 acc@5 0.9960\n",
      "\u001b[32m[2020-07-10 06:41:37] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 06:41:37] __main__ INFO: \u001b[0mTrain 83 28782\n",
      "\u001b[32m[2020-07-10 06:41:46] __main__ INFO: \u001b[0mEpoch 83 Step 100/351 lr 0.010000 loss 1.0608 (1.0793) acc@1 0.6403 (0.6268) acc@5 0.9683 (0.9681)\n",
      "\u001b[32m[2020-07-10 06:41:56] __main__ INFO: \u001b[0mEpoch 83 Step 200/351 lr 0.010000 loss 1.1443 (1.0822) acc@1 0.5958 (0.6256) acc@5 0.9690 (0.9678)\n",
      "\u001b[32m[2020-07-10 06:42:06] __main__ INFO: \u001b[0mEpoch 83 Step 300/351 lr 0.010000 loss 1.0260 (1.0852) acc@1 0.6238 (0.6240) acc@5 0.9760 (0.9675)\n",
      "\u001b[32m[2020-07-10 06:42:10] __main__ INFO: \u001b[0mEpoch 83 Step 351/351 lr 0.010000 loss 1.0542 (1.0868) acc@1 0.6385 (0.6233) acc@5 0.9671 (0.9673)\n",
      "\u001b[32m[2020-07-10 06:42:10] __main__ INFO: \u001b[0mElapsed 33.47\n",
      "\u001b[32m[2020-07-10 06:42:10] __main__ INFO: \u001b[0mVal 83\n",
      "\u001b[32m[2020-07-10 06:42:11] __main__ INFO: \u001b[0mEpoch 83 loss 0.4260 acc@1 0.9222 acc@5 0.9958\n",
      "\u001b[32m[2020-07-10 06:42:11] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 06:42:11] __main__ INFO: \u001b[0mTrain 84 29133\n",
      "\u001b[32m[2020-07-10 06:42:21] __main__ INFO: \u001b[0mEpoch 84 Step 100/351 lr 0.010000 loss 1.0987 (1.0802) acc@1 0.6065 (0.6234) acc@5 0.9604 (0.9681)\n",
      "\u001b[32m[2020-07-10 06:42:31] __main__ INFO: \u001b[0mEpoch 84 Step 200/351 lr 0.010000 loss 1.0524 (1.0793) acc@1 0.6512 (0.6241) acc@5 0.9801 (0.9677)\n",
      "\u001b[32m[2020-07-10 06:42:40] __main__ INFO: \u001b[0mEpoch 84 Step 300/351 lr 0.010000 loss 1.1568 (1.0789) acc@1 0.6036 (0.6250) acc@5 0.9631 (0.9677)\n",
      "\u001b[32m[2020-07-10 06:42:45] __main__ INFO: \u001b[0mEpoch 84 Step 351/351 lr 0.010000 loss 1.0820 (1.0808) acc@1 0.6290 (0.6242) acc@5 0.9661 (0.9677)\n",
      "\u001b[32m[2020-07-10 06:42:45] __main__ INFO: \u001b[0mElapsed 33.52\n",
      "\u001b[32m[2020-07-10 06:42:45] __main__ INFO: \u001b[0mVal 84\n",
      "\u001b[32m[2020-07-10 06:42:46] __main__ INFO: \u001b[0mEpoch 84 loss 0.4105 acc@1 0.9200 acc@5 0.9972\n",
      "\u001b[32m[2020-07-10 06:42:46] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 06:42:46] __main__ INFO: \u001b[0mTrain 85 29484\n",
      "\u001b[32m[2020-07-10 06:42:56] __main__ INFO: \u001b[0mEpoch 85 Step 100/351 lr 0.010000 loss 1.1467 (1.0818) acc@1 0.6157 (0.6225) acc@5 0.9597 (0.9676)\n",
      "\u001b[32m[2020-07-10 06:43:05] __main__ INFO: \u001b[0mEpoch 85 Step 200/351 lr 0.010000 loss 1.0726 (1.0743) acc@1 0.6345 (0.6256) acc@5 0.9690 (0.9680)\n",
      "\u001b[32m[2020-07-10 06:43:15] __main__ INFO: \u001b[0mEpoch 85 Step 300/351 lr 0.010000 loss 1.0080 (1.0703) acc@1 0.6294 (0.6263) acc@5 0.9711 (0.9687)\n",
      "\u001b[32m[2020-07-10 06:43:19] __main__ INFO: \u001b[0mEpoch 85 Step 351/351 lr 0.010000 loss 1.1448 (1.0718) acc@1 0.5973 (0.6266) acc@5 0.9613 (0.9684)\n",
      "\u001b[32m[2020-07-10 06:43:20] __main__ INFO: \u001b[0mElapsed 33.43\n",
      "\u001b[32m[2020-07-10 06:43:20] __main__ INFO: \u001b[0mVal 85\n",
      "\u001b[32m[2020-07-10 06:43:21] __main__ INFO: \u001b[0mEpoch 85 loss 0.4022 acc@1 0.9248 acc@5 0.9958\n",
      "\u001b[32m[2020-07-10 06:43:21] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 06:43:21] __main__ INFO: \u001b[0mTrain 86 29835\n",
      "\u001b[32m[2020-07-10 06:43:30] __main__ INFO: \u001b[0mEpoch 86 Step 100/351 lr 0.010000 loss 1.0501 (1.0604) acc@1 0.6208 (0.6314) acc@5 0.9726 (0.9703)\n",
      "\u001b[32m[2020-07-10 06:43:40] __main__ INFO: \u001b[0mEpoch 86 Step 200/351 lr 0.010000 loss 1.0425 (1.0637) acc@1 0.6305 (0.6286) acc@5 0.9766 (0.9702)\n",
      "\u001b[32m[2020-07-10 06:43:49] __main__ INFO: \u001b[0mEpoch 86 Step 300/351 lr 0.010000 loss 1.0128 (1.0613) acc@1 0.6832 (0.6295) acc@5 0.9619 (0.9701)\n",
      "\u001b[32m[2020-07-10 06:43:54] __main__ INFO: \u001b[0mEpoch 86 Step 351/351 lr 0.010000 loss 1.1091 (1.0629) acc@1 0.6172 (0.6289) acc@5 0.9480 (0.9696)\n",
      "\u001b[32m[2020-07-10 06:43:54] __main__ INFO: \u001b[0mElapsed 33.51\n",
      "\u001b[32m[2020-07-10 06:43:54] __main__ INFO: \u001b[0mVal 86\n",
      "\u001b[32m[2020-07-10 06:43:55] __main__ INFO: \u001b[0mEpoch 86 loss 0.4060 acc@1 0.9258 acc@5 0.9962\n",
      "\u001b[32m[2020-07-10 06:43:55] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 06:43:55] __main__ INFO: \u001b[0mTrain 87 30186\n",
      "\u001b[32m[2020-07-10 06:44:05] __main__ INFO: \u001b[0mEpoch 87 Step 100/351 lr 0.010000 loss 1.0020 (1.0483) acc@1 0.6531 (0.6306) acc@5 0.9744 (0.9709)\n",
      "\u001b[32m[2020-07-10 06:44:14] __main__ INFO: \u001b[0mEpoch 87 Step 200/351 lr 0.010000 loss 1.1052 (1.0535) acc@1 0.5773 (0.6302) acc@5 0.9817 (0.9702)\n",
      "\u001b[32m[2020-07-10 06:44:24] __main__ INFO: \u001b[0mEpoch 87 Step 300/351 lr 0.010000 loss 0.9916 (1.0557) acc@1 0.6760 (0.6307) acc@5 0.9708 (0.9701)\n",
      "\u001b[32m[2020-07-10 06:44:29] __main__ INFO: \u001b[0mEpoch 87 Step 351/351 lr 0.010000 loss 1.1205 (1.0566) acc@1 0.6142 (0.6308) acc@5 0.9497 (0.9699)\n",
      "\u001b[32m[2020-07-10 06:44:29] __main__ INFO: \u001b[0mElapsed 33.50\n",
      "\u001b[32m[2020-07-10 06:44:29] __main__ INFO: \u001b[0mVal 87\n",
      "\u001b[32m[2020-07-10 06:44:30] __main__ INFO: \u001b[0mEpoch 87 loss 0.4043 acc@1 0.9262 acc@5 0.9960\n",
      "\u001b[32m[2020-07-10 06:44:30] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 06:44:30] __main__ INFO: \u001b[0mTrain 88 30537\n",
      "\u001b[32m[2020-07-10 06:44:39] __main__ INFO: \u001b[0mEpoch 88 Step 100/351 lr 0.010000 loss 1.0725 (1.0501) acc@1 0.6097 (0.6323) acc@5 0.9676 (0.9710)\n",
      "\u001b[32m[2020-07-10 06:44:49] __main__ INFO: \u001b[0mEpoch 88 Step 200/351 lr 0.010000 loss 0.9819 (1.0523) acc@1 0.6540 (0.6321) acc@5 0.9800 (0.9708)\n",
      "\u001b[32m[2020-07-10 06:44:58] __main__ INFO: \u001b[0mEpoch 88 Step 300/351 lr 0.010000 loss 1.0020 (1.0509) acc@1 0.6676 (0.6328) acc@5 0.9797 (0.9706)\n",
      "\u001b[32m[2020-07-10 06:45:03] __main__ INFO: \u001b[0mEpoch 88 Step 351/351 lr 0.010000 loss 1.0020 (1.0523) acc@1 0.6175 (0.6313) acc@5 0.9898 (0.9711)\n",
      "\u001b[32m[2020-07-10 06:45:03] __main__ INFO: \u001b[0mElapsed 33.52\n",
      "\u001b[32m[2020-07-10 06:45:03] __main__ INFO: \u001b[0mVal 88\n",
      "\u001b[32m[2020-07-10 06:45:04] __main__ INFO: \u001b[0mEpoch 88 loss 0.4093 acc@1 0.9266 acc@5 0.9958\n",
      "\u001b[32m[2020-07-10 06:45:04] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 06:45:04] __main__ INFO: \u001b[0mTrain 89 30888\n",
      "\u001b[32m[2020-07-10 06:45:14] __main__ INFO: \u001b[0mEpoch 89 Step 100/351 lr 0.010000 loss 1.0288 (1.0431) acc@1 0.6714 (0.6334) acc@5 0.9760 (0.9717)\n",
      "\u001b[32m[2020-07-10 06:45:24] __main__ INFO: \u001b[0mEpoch 89 Step 200/351 lr 0.010000 loss 1.0010 (1.0467) acc@1 0.6497 (0.6328) acc@5 0.9798 (0.9712)\n",
      "\u001b[32m[2020-07-10 06:45:33] __main__ INFO: \u001b[0mEpoch 89 Step 300/351 lr 0.010000 loss 1.1477 (1.0475) acc@1 0.6055 (0.6313) acc@5 0.9611 (0.9712)\n",
      "\u001b[32m[2020-07-10 06:45:38] __main__ INFO: \u001b[0mEpoch 89 Step 351/351 lr 0.010000 loss 0.9862 (1.0474) acc@1 0.6604 (0.6317) acc@5 0.9842 (0.9712)\n",
      "\u001b[32m[2020-07-10 06:45:38] __main__ INFO: \u001b[0mElapsed 33.55\n",
      "\u001b[32m[2020-07-10 06:45:38] __main__ INFO: \u001b[0mVal 89\n",
      "\u001b[32m[2020-07-10 06:45:39] __main__ INFO: \u001b[0mEpoch 89 loss 0.4121 acc@1 0.9242 acc@5 0.9960\n",
      "\u001b[32m[2020-07-10 06:45:39] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 06:45:39] __main__ INFO: \u001b[0mTrain 90 31239\n",
      "\u001b[32m[2020-07-10 06:45:49] __main__ INFO: \u001b[0mEpoch 90 Step 100/351 lr 0.010000 loss 1.0548 (1.0383) acc@1 0.6203 (0.6350) acc@5 0.9706 (0.9719)\n",
      "\u001b[32m[2020-07-10 06:45:58] __main__ INFO: \u001b[0mEpoch 90 Step 200/351 lr 0.010000 loss 1.0352 (1.0446) acc@1 0.6218 (0.6339) acc@5 0.9785 (0.9716)\n",
      "\u001b[32m[2020-07-10 06:46:08] __main__ INFO: \u001b[0mEpoch 90 Step 300/351 lr 0.010000 loss 0.9985 (1.0425) acc@1 0.6276 (0.6344) acc@5 0.9747 (0.9713)\n",
      "\u001b[32m[2020-07-10 06:46:13] __main__ INFO: \u001b[0mEpoch 90 Step 351/351 lr 0.010000 loss 1.0845 (1.0446) acc@1 0.6223 (0.6333) acc@5 0.9746 (0.9713)\n",
      "\u001b[32m[2020-07-10 06:46:13] __main__ INFO: \u001b[0mElapsed 33.54\n",
      "\u001b[32m[2020-07-10 06:46:13] __main__ INFO: \u001b[0mVal 90\n",
      "\u001b[32m[2020-07-10 06:46:14] __main__ INFO: \u001b[0mEpoch 90 loss 0.4048 acc@1 0.9252 acc@5 0.9956\n",
      "\u001b[32m[2020-07-10 06:46:14] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-07-10 06:46:14] __main__ INFO: \u001b[0mTrain 91 31590\n",
      "\u001b[32m[2020-07-10 06:46:23] __main__ INFO: \u001b[0mEpoch 91 Step 100/351 lr 0.010000 loss 1.0270 (1.0394) acc@1 0.6368 (0.6332) acc@5 0.9900 (0.9723)\n",
      "\u001b[32m[2020-07-10 06:46:33] __main__ INFO: \u001b[0mEpoch 91 Step 200/351 lr 0.010000 loss 1.1437 (1.0388) acc@1 0.5586 (0.6351) acc@5 0.9686 (0.9720)\n",
      "\u001b[32m[2020-07-10 06:46:42] __main__ INFO: \u001b[0mEpoch 91 Step 300/351 lr 0.010000 loss 1.1255 (1.0411) acc@1 0.5679 (0.6341) acc@5 0.9616 (0.9720)\n",
      "\u001b[32m[2020-07-10 06:46:47] __main__ INFO: \u001b[0mEpoch 91 Step 351/351 lr 0.010000 loss 1.0403 (1.0398) acc@1 0.6177 (0.6342) acc@5 0.9776 (0.9720)\n",
      "\u001b[32m[2020-07-10 06:46:47] __main__ INFO: \u001b[0mElapsed 33.55\n",
      "\u001b[32m[2020-07-10 06:46:47] __main__ INFO: \u001b[0mVal 91\n",
      "\u001b[32m[2020-07-10 06:46:48] __main__ INFO: \u001b[0mEpoch 91 loss 0.4030 acc@1 0.9268 acc@5 0.9958\n",
      "\u001b[32m[2020-07-10 06:46:48] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-07-10 06:46:48] __main__ INFO: \u001b[0mTrain 92 31941\n",
      "\u001b[32m[2020-07-10 06:46:58] __main__ INFO: \u001b[0mEpoch 92 Step 100/351 lr 0.010000 loss 1.0683 (1.0356) acc@1 0.6449 (0.6344) acc@5 0.9867 (0.9731)\n",
      "\u001b[32m[2020-07-10 06:47:07] __main__ INFO: \u001b[0mEpoch 92 Step 200/351 lr 0.010000 loss 0.9350 (1.0338) acc@1 0.6533 (0.6354) acc@5 0.9842 (0.9735)\n",
      "\u001b[32m[2020-07-10 06:47:17] __main__ INFO: \u001b[0mEpoch 92 Step 300/351 lr 0.010000 loss 0.9936 (1.0360) acc@1 0.6554 (0.6363) acc@5 0.9751 (0.9727)\n",
      "\u001b[32m[2020-07-10 06:47:22] __main__ INFO: \u001b[0mEpoch 92 Step 351/351 lr 0.010000 loss 1.0957 (1.0354) acc@1 0.6065 (0.6363) acc@5 0.9717 (0.9728)\n",
      "\u001b[32m[2020-07-10 06:47:22] __main__ INFO: \u001b[0mElapsed 33.52\n",
      "\u001b[32m[2020-07-10 06:47:22] __main__ INFO: \u001b[0mVal 92\n",
      "\u001b[32m[2020-07-10 06:47:23] __main__ INFO: \u001b[0mEpoch 92 loss 0.4022 acc@1 0.9250 acc@5 0.9960\n",
      "\u001b[32m[2020-07-10 06:47:23] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-07-10 06:47:23] __main__ INFO: \u001b[0mTrain 93 32292\n",
      "\u001b[32m[2020-07-10 06:47:33] __main__ INFO: \u001b[0mEpoch 93 Step 100/351 lr 0.010000 loss 1.0362 (1.0262) acc@1 0.6305 (0.6364) acc@5 0.9804 (0.9729)\n",
      "\u001b[32m[2020-07-10 06:47:42] __main__ INFO: \u001b[0mEpoch 93 Step 200/351 lr 0.010000 loss 1.0422 (1.0318) acc@1 0.6323 (0.6349) acc@5 0.9677 (0.9726)\n",
      "\u001b[32m[2020-07-10 06:47:52] __main__ INFO: \u001b[0mEpoch 93 Step 300/351 lr 0.010000 loss 1.0079 (1.0333) acc@1 0.6165 (0.6345) acc@5 0.9772 (0.9723)\n",
      "\u001b[32m[2020-07-10 06:47:56] __main__ INFO: \u001b[0mEpoch 93 Step 351/351 lr 0.010000 loss 1.0602 (1.0341) acc@1 0.6051 (0.6343) acc@5 0.9767 (0.9724)\n",
      "\u001b[32m[2020-07-10 06:47:56] __main__ INFO: \u001b[0mElapsed 33.54\n",
      "\u001b[32m[2020-07-10 06:47:56] __main__ INFO: \u001b[0mVal 93\n",
      "\u001b[32m[2020-07-10 06:47:58] __main__ INFO: \u001b[0mEpoch 93 loss 0.4111 acc@1 0.9224 acc@5 0.9952\n",
      "\u001b[32m[2020-07-10 06:47:58] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 06:47:58] __main__ INFO: \u001b[0mTrain 94 32643\n",
      "\u001b[32m[2020-07-10 06:48:07] __main__ INFO: \u001b[0mEpoch 94 Step 100/351 lr 0.010000 loss 1.0654 (1.0271) acc@1 0.6467 (0.6374) acc@5 0.9608 (0.9732)\n",
      "\u001b[32m[2020-07-10 06:48:17] __main__ INFO: \u001b[0mEpoch 94 Step 200/351 lr 0.010000 loss 1.0693 (1.0210) acc@1 0.6334 (0.6407) acc@5 0.9634 (0.9740)\n",
      "\u001b[32m[2020-07-10 06:48:26] __main__ INFO: \u001b[0mEpoch 94 Step 300/351 lr 0.010000 loss 0.9641 (1.0254) acc@1 0.6618 (0.6383) acc@5 0.9751 (0.9737)\n",
      "\u001b[32m[2020-07-10 06:48:31] __main__ INFO: \u001b[0mEpoch 94 Step 351/351 lr 0.010000 loss 1.0513 (1.0281) acc@1 0.6334 (0.6372) acc@5 0.9601 (0.9736)\n",
      "\u001b[32m[2020-07-10 06:48:31] __main__ INFO: \u001b[0mElapsed 33.55\n",
      "\u001b[32m[2020-07-10 06:48:31] __main__ INFO: \u001b[0mVal 94\n",
      "\u001b[32m[2020-07-10 06:48:32] __main__ INFO: \u001b[0mEpoch 94 loss 0.4081 acc@1 0.9222 acc@5 0.9950\n",
      "\u001b[32m[2020-07-10 06:48:32] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 06:48:32] __main__ INFO: \u001b[0mTrain 95 32994\n",
      "\u001b[32m[2020-07-10 06:48:42] __main__ INFO: \u001b[0mEpoch 95 Step 100/351 lr 0.010000 loss 1.1010 (1.0256) acc@1 0.6239 (0.6376) acc@5 0.9678 (0.9746)\n",
      "\u001b[32m[2020-07-10 06:48:51] __main__ INFO: \u001b[0mEpoch 95 Step 200/351 lr 0.010000 loss 1.0541 (1.0277) acc@1 0.6335 (0.6377) acc@5 0.9824 (0.9740)\n",
      "\u001b[32m[2020-07-10 06:49:01] __main__ INFO: \u001b[0mEpoch 95 Step 300/351 lr 0.010000 loss 1.0994 (1.0294) acc@1 0.6551 (0.6376) acc@5 0.9689 (0.9736)\n",
      "\u001b[32m[2020-07-10 06:49:06] __main__ INFO: \u001b[0mEpoch 95 Step 351/351 lr 0.010000 loss 1.0781 (1.0289) acc@1 0.6002 (0.6374) acc@5 0.9746 (0.9738)\n",
      "\u001b[32m[2020-07-10 06:49:06] __main__ INFO: \u001b[0mElapsed 33.49\n",
      "\u001b[32m[2020-07-10 06:49:06] __main__ INFO: \u001b[0mVal 95\n",
      "\u001b[32m[2020-07-10 06:49:07] __main__ INFO: \u001b[0mEpoch 95 loss 0.3961 acc@1 0.9226 acc@5 0.9962\n",
      "\u001b[32m[2020-07-10 06:49:07] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 06:49:07] __main__ INFO: \u001b[0mTrain 96 33345\n",
      "\u001b[32m[2020-07-10 06:49:16] __main__ INFO: \u001b[0mEpoch 96 Step 100/351 lr 0.010000 loss 1.0359 (1.0144) acc@1 0.6273 (0.6422) acc@5 0.9774 (0.9742)\n",
      "\u001b[32m[2020-07-10 06:49:26] __main__ INFO: \u001b[0mEpoch 96 Step 200/351 lr 0.010000 loss 1.1120 (1.0245) acc@1 0.5817 (0.6386) acc@5 0.9596 (0.9728)\n",
      "\u001b[32m[2020-07-10 06:49:35] __main__ INFO: \u001b[0mEpoch 96 Step 300/351 lr 0.010000 loss 1.0174 (1.0249) acc@1 0.6450 (0.6379) acc@5 0.9618 (0.9733)\n",
      "\u001b[32m[2020-07-10 06:49:40] __main__ INFO: \u001b[0mEpoch 96 Step 351/351 lr 0.010000 loss 1.0796 (1.0247) acc@1 0.6247 (0.6379) acc@5 0.9662 (0.9735)\n",
      "\u001b[32m[2020-07-10 06:49:40] __main__ INFO: \u001b[0mElapsed 33.49\n",
      "\u001b[32m[2020-07-10 06:49:40] __main__ INFO: \u001b[0mVal 96\n",
      "\u001b[32m[2020-07-10 06:49:41] __main__ INFO: \u001b[0mEpoch 96 loss 0.3933 acc@1 0.9244 acc@5 0.9950\n",
      "\u001b[32m[2020-07-10 06:49:41] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 06:49:41] __main__ INFO: \u001b[0mTrain 97 33696\n",
      "\u001b[32m[2020-07-10 06:49:51] __main__ INFO: \u001b[0mEpoch 97 Step 100/351 lr 0.010000 loss 0.9659 (1.0075) acc@1 0.6684 (0.6426) acc@5 0.9743 (0.9751)\n",
      "\u001b[32m[2020-07-10 06:50:00] __main__ INFO: \u001b[0mEpoch 97 Step 200/351 lr 0.010000 loss 0.9443 (1.0167) acc@1 0.6770 (0.6396) acc@5 0.9770 (0.9740)\n",
      "\u001b[32m[2020-07-10 06:50:10] __main__ INFO: \u001b[0mEpoch 97 Step 300/351 lr 0.010000 loss 1.0176 (1.0219) acc@1 0.6306 (0.6372) acc@5 0.9742 (0.9740)\n",
      "\u001b[32m[2020-07-10 06:50:15] __main__ INFO: \u001b[0mEpoch 97 Step 351/351 lr 0.010000 loss 1.0158 (1.0224) acc@1 0.6619 (0.6371) acc@5 0.9697 (0.9737)\n",
      "\u001b[32m[2020-07-10 06:50:15] __main__ INFO: \u001b[0mElapsed 33.43\n",
      "\u001b[32m[2020-07-10 06:50:15] __main__ INFO: \u001b[0mVal 97\n",
      "\u001b[32m[2020-07-10 06:50:16] __main__ INFO: \u001b[0mEpoch 97 loss 0.4072 acc@1 0.9226 acc@5 0.9954\n",
      "\u001b[32m[2020-07-10 06:50:16] __main__ INFO: \u001b[0mElapsed 1.12\n",
      "\u001b[32m[2020-07-10 06:50:16] __main__ INFO: \u001b[0mTrain 98 34047\n",
      "\u001b[32m[2020-07-10 06:50:26] __main__ INFO: \u001b[0mEpoch 98 Step 100/351 lr 0.010000 loss 1.0055 (1.0100) acc@1 0.6501 (0.6449) acc@5 0.9749 (0.9757)\n",
      "\u001b[32m[2020-07-10 06:50:35] __main__ INFO: \u001b[0mEpoch 98 Step 200/351 lr 0.010000 loss 0.9951 (1.0191) acc@1 0.6533 (0.6406) acc@5 0.9770 (0.9754)\n",
      "\u001b[32m[2020-07-10 06:50:44] __main__ INFO: \u001b[0mEpoch 98 Step 300/351 lr 0.010000 loss 1.0976 (1.0204) acc@1 0.6106 (0.6393) acc@5 0.9731 (0.9751)\n",
      "\u001b[32m[2020-07-10 06:50:49] __main__ INFO: \u001b[0mEpoch 98 Step 351/351 lr 0.010000 loss 1.0551 (1.0206) acc@1 0.5948 (0.6392) acc@5 0.9697 (0.9748)\n",
      "\u001b[32m[2020-07-10 06:50:49] __main__ INFO: \u001b[0mElapsed 33.44\n",
      "\u001b[32m[2020-07-10 06:50:49] __main__ INFO: \u001b[0mVal 98\n",
      "\u001b[32m[2020-07-10 06:50:50] __main__ INFO: \u001b[0mEpoch 98 loss 0.4026 acc@1 0.9240 acc@5 0.9954\n",
      "\u001b[32m[2020-07-10 06:50:50] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 06:50:50] __main__ INFO: \u001b[0mTrain 99 34398\n",
      "\u001b[32m[2020-07-10 06:51:00] __main__ INFO: \u001b[0mEpoch 99 Step 100/351 lr 0.010000 loss 0.9725 (1.0134) acc@1 0.6426 (0.6418) acc@5 0.9878 (0.9742)\n",
      "\u001b[32m[2020-07-10 06:51:09] __main__ INFO: \u001b[0mEpoch 99 Step 200/351 lr 0.010000 loss 0.9519 (1.0138) acc@1 0.6711 (0.6405) acc@5 0.9773 (0.9748)\n",
      "\u001b[32m[2020-07-10 06:51:19] __main__ INFO: \u001b[0mEpoch 99 Step 300/351 lr 0.010000 loss 0.9780 (1.0161) acc@1 0.6448 (0.6403) acc@5 0.9802 (0.9746)\n",
      "\u001b[32m[2020-07-10 06:51:24] __main__ INFO: \u001b[0mEpoch 99 Step 351/351 lr 0.010000 loss 1.0429 (1.0163) acc@1 0.6344 (0.6400) acc@5 0.9833 (0.9748)\n",
      "\u001b[32m[2020-07-10 06:51:24] __main__ INFO: \u001b[0mElapsed 33.47\n",
      "\u001b[32m[2020-07-10 06:51:24] __main__ INFO: \u001b[0mVal 99\n",
      "\u001b[32m[2020-07-10 06:51:25] __main__ INFO: \u001b[0mEpoch 99 loss 0.4045 acc@1 0.9216 acc@5 0.9948\n",
      "\u001b[32m[2020-07-10 06:51:25] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 06:51:25] __main__ INFO: \u001b[0mTrain 100 34749\n",
      "\u001b[32m[2020-07-10 06:51:35] __main__ INFO: \u001b[0mEpoch 100 Step 100/351 lr 0.010000 loss 1.0462 (0.9982) acc@1 0.6375 (0.6422) acc@5 0.9649 (0.9761)\n",
      "\u001b[32m[2020-07-10 06:51:44] __main__ INFO: \u001b[0mEpoch 100 Step 200/351 lr 0.010000 loss 0.9389 (1.0009) acc@1 0.6814 (0.6436) acc@5 0.9871 (0.9761)\n",
      "\u001b[32m[2020-07-10 06:51:54] __main__ INFO: \u001b[0mEpoch 100 Step 300/351 lr 0.010000 loss 1.0637 (1.0090) acc@1 0.6397 (0.6402) acc@5 0.9626 (0.9759)\n",
      "\u001b[32m[2020-07-10 06:51:58] __main__ INFO: \u001b[0mEpoch 100 Step 351/351 lr 0.010000 loss 1.0085 (1.0113) acc@1 0.6268 (0.6398) acc@5 0.9820 (0.9757)\n",
      "\u001b[32m[2020-07-10 06:51:59] __main__ INFO: \u001b[0mElapsed 33.55\n",
      "\u001b[32m[2020-07-10 06:51:59] __main__ INFO: \u001b[0mVal 100\n",
      "\u001b[32m[2020-07-10 06:52:00] __main__ INFO: \u001b[0mEpoch 100 loss 0.3999 acc@1 0.9256 acc@5 0.9950\n",
      "\u001b[32m[2020-07-10 06:52:00] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 06:52:00] fvcore.common.checkpoint INFO: \u001b[0mSaving checkpoint to /home/ec2-user/SageMaker/experiments/resnet_basic_32_cm_1_1/exp00/checkpoint_00100.pth\n",
      "\u001b[32m[2020-07-10 06:52:00] __main__ INFO: \u001b[0mTrain 101 35100\n",
      "\u001b[32m[2020-07-10 06:52:09] __main__ INFO: \u001b[0mEpoch 101 Step 100/351 lr 0.010000 loss 0.9692 (1.0035) acc@1 0.6734 (0.6424) acc@5 0.9717 (0.9758)\n",
      "\u001b[32m[2020-07-10 06:52:19] __main__ INFO: \u001b[0mEpoch 101 Step 200/351 lr 0.010000 loss 0.9951 (1.0083) acc@1 0.6385 (0.6407) acc@5 0.9691 (0.9753)\n",
      "\u001b[32m[2020-07-10 06:52:28] __main__ INFO: \u001b[0mEpoch 101 Step 300/351 lr 0.010000 loss 0.9810 (1.0092) acc@1 0.6345 (0.6403) acc@5 0.9825 (0.9753)\n",
      "\u001b[32m[2020-07-10 06:52:33] __main__ INFO: \u001b[0mEpoch 101 Step 351/351 lr 0.010000 loss 1.0406 (1.0103) acc@1 0.6172 (0.6403) acc@5 0.9766 (0.9754)\n",
      "\u001b[32m[2020-07-10 06:52:33] __main__ INFO: \u001b[0mElapsed 33.51\n",
      "\u001b[32m[2020-07-10 06:52:33] __main__ INFO: \u001b[0mVal 101\n",
      "\u001b[32m[2020-07-10 06:52:34] __main__ INFO: \u001b[0mEpoch 101 loss 0.3980 acc@1 0.9248 acc@5 0.9954\n",
      "\u001b[32m[2020-07-10 06:52:34] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 06:52:34] __main__ INFO: \u001b[0mTrain 102 35451\n",
      "\u001b[32m[2020-07-10 06:52:44] __main__ INFO: \u001b[0mEpoch 102 Step 100/351 lr 0.010000 loss 0.9644 (0.9996) acc@1 0.6571 (0.6446) acc@5 0.9774 (0.9753)\n",
      "\u001b[32m[2020-07-10 06:52:53] __main__ INFO: \u001b[0mEpoch 102 Step 200/351 lr 0.010000 loss 1.0157 (1.0051) acc@1 0.6659 (0.6431) acc@5 0.9732 (0.9750)\n",
      "\u001b[32m[2020-07-10 06:53:03] __main__ INFO: \u001b[0mEpoch 102 Step 300/351 lr 0.010000 loss 0.9662 (1.0108) acc@1 0.6328 (0.6403) acc@5 0.9817 (0.9751)\n",
      "\u001b[32m[2020-07-10 06:53:08] __main__ INFO: \u001b[0mEpoch 102 Step 351/351 lr 0.010000 loss 0.9972 (1.0092) acc@1 0.6584 (0.6417) acc@5 0.9560 (0.9751)\n",
      "\u001b[32m[2020-07-10 06:53:08] __main__ INFO: \u001b[0mElapsed 33.45\n",
      "\u001b[32m[2020-07-10 06:53:08] __main__ INFO: \u001b[0mVal 102\n",
      "\u001b[32m[2020-07-10 06:53:09] __main__ INFO: \u001b[0mEpoch 102 loss 0.4015 acc@1 0.9232 acc@5 0.9950\n",
      "\u001b[32m[2020-07-10 06:53:09] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 06:53:09] __main__ INFO: \u001b[0mTrain 103 35802\n",
      "\u001b[32m[2020-07-10 06:53:18] __main__ INFO: \u001b[0mEpoch 103 Step 100/351 lr 0.010000 loss 0.8500 (0.9851) acc@1 0.7074 (0.6514) acc@5 0.9741 (0.9771)\n",
      "\u001b[32m[2020-07-10 06:53:28] __main__ INFO: \u001b[0mEpoch 103 Step 200/351 lr 0.010000 loss 0.9326 (0.9928) acc@1 0.6601 (0.6479) acc@5 0.9845 (0.9772)\n",
      "\u001b[32m[2020-07-10 06:53:37] __main__ INFO: \u001b[0mEpoch 103 Step 300/351 lr 0.010000 loss 0.9584 (0.9985) acc@1 0.6576 (0.6452) acc@5 0.9822 (0.9764)\n",
      "\u001b[32m[2020-07-10 06:53:42] __main__ INFO: \u001b[0mEpoch 103 Step 351/351 lr 0.010000 loss 0.9827 (1.0023) acc@1 0.6541 (0.6437) acc@5 0.9810 (0.9763)\n",
      "\u001b[32m[2020-07-10 06:53:42] __main__ INFO: \u001b[0mElapsed 33.49\n",
      "\u001b[32m[2020-07-10 06:53:42] __main__ INFO: \u001b[0mVal 103\n",
      "\u001b[32m[2020-07-10 06:53:43] __main__ INFO: \u001b[0mEpoch 103 loss 0.3955 acc@1 0.9238 acc@5 0.9952\n",
      "\u001b[32m[2020-07-10 06:53:43] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 06:53:43] __main__ INFO: \u001b[0mTrain 104 36153\n",
      "\u001b[32m[2020-07-10 06:53:53] __main__ INFO: \u001b[0mEpoch 104 Step 100/351 lr 0.010000 loss 1.0442 (1.0016) acc@1 0.6375 (0.6423) acc@5 0.9625 (0.9765)\n",
      "\u001b[32m[2020-07-10 06:54:02] __main__ INFO: \u001b[0mEpoch 104 Step 200/351 lr 0.010000 loss 1.0428 (0.9958) acc@1 0.6004 (0.6439) acc@5 0.9819 (0.9770)\n",
      "\u001b[32m[2020-07-10 06:54:12] __main__ INFO: \u001b[0mEpoch 104 Step 300/351 lr 0.010000 loss 0.9938 (0.9998) acc@1 0.6267 (0.6427) acc@5 0.9771 (0.9768)\n",
      "\u001b[32m[2020-07-10 06:54:17] __main__ INFO: \u001b[0mEpoch 104 Step 351/351 lr 0.010000 loss 1.0395 (1.0006) acc@1 0.6194 (0.6426) acc@5 0.9720 (0.9765)\n",
      "\u001b[32m[2020-07-10 06:54:17] __main__ INFO: \u001b[0mElapsed 33.50\n",
      "\u001b[32m[2020-07-10 06:54:17] __main__ INFO: \u001b[0mVal 104\n",
      "\u001b[32m[2020-07-10 06:54:18] __main__ INFO: \u001b[0mEpoch 104 loss 0.4029 acc@1 0.9250 acc@5 0.9950\n",
      "\u001b[32m[2020-07-10 06:54:18] __main__ INFO: \u001b[0mElapsed 1.12\n",
      "\u001b[32m[2020-07-10 06:54:18] __main__ INFO: \u001b[0mTrain 105 36504\n",
      "\u001b[32m[2020-07-10 06:54:28] __main__ INFO: \u001b[0mEpoch 105 Step 100/351 lr 0.010000 loss 0.9449 (0.9939) acc@1 0.6687 (0.6430) acc@5 0.9737 (0.9778)\n",
      "\u001b[32m[2020-07-10 06:54:37] __main__ INFO: \u001b[0mEpoch 105 Step 200/351 lr 0.010000 loss 1.0026 (0.9964) acc@1 0.6346 (0.6434) acc@5 0.9805 (0.9772)\n",
      "\u001b[32m[2020-07-10 06:54:47] __main__ INFO: \u001b[0mEpoch 105 Step 300/351 lr 0.010000 loss 0.9693 (0.9994) acc@1 0.6661 (0.6428) acc@5 0.9764 (0.9763)\n",
      "\u001b[32m[2020-07-10 06:54:52] __main__ INFO: \u001b[0mEpoch 105 Step 351/351 lr 0.010000 loss 1.0546 (1.0013) acc@1 0.5908 (0.6421) acc@5 0.9794 (0.9763)\n",
      "\u001b[32m[2020-07-10 06:54:52] __main__ INFO: \u001b[0mElapsed 33.60\n",
      "\u001b[32m[2020-07-10 06:54:52] __main__ INFO: \u001b[0mVal 105\n",
      "\u001b[32m[2020-07-10 06:54:53] __main__ INFO: \u001b[0mEpoch 105 loss 0.3973 acc@1 0.9264 acc@5 0.9950\n",
      "\u001b[32m[2020-07-10 06:54:53] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 06:54:53] __main__ INFO: \u001b[0mTrain 106 36855\n",
      "\u001b[32m[2020-07-10 06:55:02] __main__ INFO: \u001b[0mEpoch 106 Step 100/351 lr 0.010000 loss 1.0286 (0.9958) acc@1 0.6161 (0.6444) acc@5 0.9758 (0.9770)\n",
      "\u001b[32m[2020-07-10 06:55:12] __main__ INFO: \u001b[0mEpoch 106 Step 200/351 lr 0.010000 loss 1.0178 (0.9960) acc@1 0.6399 (0.6432) acc@5 0.9757 (0.9770)\n",
      "\u001b[32m[2020-07-10 06:55:21] __main__ INFO: \u001b[0mEpoch 106 Step 300/351 lr 0.010000 loss 0.9989 (1.0002) acc@1 0.6668 (0.6415) acc@5 0.9801 (0.9767)\n",
      "\u001b[32m[2020-07-10 06:55:26] __main__ INFO: \u001b[0mEpoch 106 Step 351/351 lr 0.010000 loss 0.9554 (1.0013) acc@1 0.6611 (0.6412) acc@5 0.9789 (0.9767)\n",
      "\u001b[32m[2020-07-10 06:55:26] __main__ INFO: \u001b[0mElapsed 33.55\n",
      "\u001b[32m[2020-07-10 06:55:26] __main__ INFO: \u001b[0mVal 106\n",
      "\u001b[32m[2020-07-10 06:55:27] __main__ INFO: \u001b[0mEpoch 106 loss 0.3862 acc@1 0.9240 acc@5 0.9958\n",
      "\u001b[32m[2020-07-10 06:55:27] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 06:55:27] __main__ INFO: \u001b[0mTrain 107 37206\n",
      "\u001b[32m[2020-07-10 06:55:37] __main__ INFO: \u001b[0mEpoch 107 Step 100/351 lr 0.010000 loss 1.0629 (0.9873) acc@1 0.5980 (0.6482) acc@5 0.9741 (0.9773)\n",
      "\u001b[32m[2020-07-10 06:55:46] __main__ INFO: \u001b[0mEpoch 107 Step 200/351 lr 0.010000 loss 1.0308 (0.9893) acc@1 0.6455 (0.6470) acc@5 0.9523 (0.9775)\n",
      "\u001b[32m[2020-07-10 06:55:56] __main__ INFO: \u001b[0mEpoch 107 Step 300/351 lr 0.010000 loss 0.9958 (0.9958) acc@1 0.6481 (0.6442) acc@5 0.9884 (0.9771)\n",
      "\u001b[32m[2020-07-10 06:56:01] __main__ INFO: \u001b[0mEpoch 107 Step 351/351 lr 0.010000 loss 1.0439 (0.9967) acc@1 0.6252 (0.6435) acc@5 0.9849 (0.9773)\n",
      "\u001b[32m[2020-07-10 06:56:01] __main__ INFO: \u001b[0mElapsed 33.46\n",
      "\u001b[32m[2020-07-10 06:56:01] __main__ INFO: \u001b[0mVal 107\n",
      "\u001b[32m[2020-07-10 06:56:02] __main__ INFO: \u001b[0mEpoch 107 loss 0.3888 acc@1 0.9248 acc@5 0.9960\n",
      "\u001b[32m[2020-07-10 06:56:02] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 06:56:02] __main__ INFO: \u001b[0mTrain 108 37557\n",
      "\u001b[32m[2020-07-10 06:56:12] __main__ INFO: \u001b[0mEpoch 108 Step 100/351 lr 0.010000 loss 0.8985 (0.9836) acc@1 0.6768 (0.6481) acc@5 0.9842 (0.9778)\n",
      "\u001b[32m[2020-07-10 06:56:21] __main__ INFO: \u001b[0mEpoch 108 Step 200/351 lr 0.010000 loss 1.0206 (0.9923) acc@1 0.6221 (0.6460) acc@5 0.9831 (0.9771)\n",
      "\u001b[32m[2020-07-10 06:56:31] __main__ INFO: \u001b[0mEpoch 108 Step 300/351 lr 0.010000 loss 0.9554 (0.9928) acc@1 0.6463 (0.6454) acc@5 0.9781 (0.9772)\n",
      "\u001b[32m[2020-07-10 06:56:35] __main__ INFO: \u001b[0mEpoch 108 Step 351/351 lr 0.010000 loss 0.9907 (0.9936) acc@1 0.6579 (0.6453) acc@5 0.9759 (0.9773)\n",
      "\u001b[32m[2020-07-10 06:56:35] __main__ INFO: \u001b[0mElapsed 33.48\n",
      "\u001b[32m[2020-07-10 06:56:35] __main__ INFO: \u001b[0mVal 108\n",
      "\u001b[32m[2020-07-10 06:56:36] __main__ INFO: \u001b[0mEpoch 108 loss 0.3845 acc@1 0.9302 acc@5 0.9954\n",
      "\u001b[32m[2020-07-10 06:56:36] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 06:56:36] __main__ INFO: \u001b[0mTrain 109 37908\n",
      "\u001b[32m[2020-07-10 06:56:46] __main__ INFO: \u001b[0mEpoch 109 Step 100/351 lr 0.010000 loss 1.0256 (0.9897) acc@1 0.6702 (0.6488) acc@5 0.9730 (0.9766)\n",
      "\u001b[32m[2020-07-10 06:56:56] __main__ INFO: \u001b[0mEpoch 109 Step 200/351 lr 0.010000 loss 1.0164 (0.9932) acc@1 0.6318 (0.6464) acc@5 0.9696 (0.9774)\n",
      "\u001b[32m[2020-07-10 06:57:05] __main__ INFO: \u001b[0mEpoch 109 Step 300/351 lr 0.010000 loss 0.9671 (0.9921) acc@1 0.6481 (0.6457) acc@5 0.9862 (0.9776)\n",
      "\u001b[32m[2020-07-10 06:57:10] __main__ INFO: \u001b[0mEpoch 109 Step 351/351 lr 0.010000 loss 1.0278 (0.9938) acc@1 0.6532 (0.6453) acc@5 0.9710 (0.9773)\n",
      "\u001b[32m[2020-07-10 06:57:10] __main__ INFO: \u001b[0mElapsed 33.50\n",
      "\u001b[32m[2020-07-10 06:57:10] __main__ INFO: \u001b[0mVal 109\n",
      "\u001b[32m[2020-07-10 06:57:11] __main__ INFO: \u001b[0mEpoch 109 loss 0.4042 acc@1 0.9232 acc@5 0.9944\n",
      "\u001b[32m[2020-07-10 06:57:11] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-07-10 06:57:11] __main__ INFO: \u001b[0mTrain 110 38259\n",
      "\u001b[32m[2020-07-10 06:57:21] __main__ INFO: \u001b[0mEpoch 110 Step 100/351 lr 0.010000 loss 1.0183 (0.9771) acc@1 0.6312 (0.6546) acc@5 0.9776 (0.9789)\n",
      "\u001b[32m[2020-07-10 06:57:30] __main__ INFO: \u001b[0mEpoch 110 Step 200/351 lr 0.010000 loss 0.9876 (0.9854) acc@1 0.6684 (0.6483) acc@5 0.9774 (0.9781)\n",
      "\u001b[32m[2020-07-10 06:57:40] __main__ INFO: \u001b[0mEpoch 110 Step 300/351 lr 0.010000 loss 1.0090 (0.9893) acc@1 0.6220 (0.6468) acc@5 0.9884 (0.9779)\n",
      "\u001b[32m[2020-07-10 06:57:45] __main__ INFO: \u001b[0mEpoch 110 Step 351/351 lr 0.010000 loss 1.0912 (0.9910) acc@1 0.5969 (0.6459) acc@5 0.9711 (0.9776)\n",
      "\u001b[32m[2020-07-10 06:57:45] __main__ INFO: \u001b[0mElapsed 33.55\n",
      "\u001b[32m[2020-07-10 06:57:45] __main__ INFO: \u001b[0mVal 110\n",
      "\u001b[32m[2020-07-10 06:57:46] __main__ INFO: \u001b[0mEpoch 110 loss 0.3928 acc@1 0.9236 acc@5 0.9956\n",
      "\u001b[32m[2020-07-10 06:57:46] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-07-10 06:57:46] __main__ INFO: \u001b[0mTrain 111 38610\n",
      "\u001b[32m[2020-07-10 06:57:55] __main__ INFO: \u001b[0mEpoch 111 Step 100/351 lr 0.010000 loss 0.9789 (0.9801) acc@1 0.6626 (0.6474) acc@5 0.9595 (0.9784)\n",
      "\u001b[32m[2020-07-10 06:58:05] __main__ INFO: \u001b[0mEpoch 111 Step 200/351 lr 0.010000 loss 1.0744 (0.9844) acc@1 0.5737 (0.6465) acc@5 0.9738 (0.9780)\n",
      "\u001b[32m[2020-07-10 06:58:14] __main__ INFO: \u001b[0mEpoch 111 Step 300/351 lr 0.010000 loss 0.9442 (0.9901) acc@1 0.6701 (0.6454) acc@5 0.9752 (0.9777)\n",
      "\u001b[32m[2020-07-10 06:58:19] __main__ INFO: \u001b[0mEpoch 111 Step 351/351 lr 0.010000 loss 1.0148 (0.9904) acc@1 0.6405 (0.6454) acc@5 0.9695 (0.9777)\n",
      "\u001b[32m[2020-07-10 06:58:19] __main__ INFO: \u001b[0mElapsed 33.51\n",
      "\u001b[32m[2020-07-10 06:58:19] __main__ INFO: \u001b[0mVal 111\n",
      "\u001b[32m[2020-07-10 06:58:20] __main__ INFO: \u001b[0mEpoch 111 loss 0.4054 acc@1 0.9206 acc@5 0.9954\n",
      "\u001b[32m[2020-07-10 06:58:20] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 06:58:20] __main__ INFO: \u001b[0mTrain 112 38961\n",
      "\u001b[32m[2020-07-10 06:58:30] __main__ INFO: \u001b[0mEpoch 112 Step 100/351 lr 0.010000 loss 0.9962 (0.9855) acc@1 0.5896 (0.6449) acc@5 0.9822 (0.9787)\n",
      "\u001b[32m[2020-07-10 06:58:39] __main__ INFO: \u001b[0mEpoch 112 Step 200/351 lr 0.010000 loss 0.9681 (0.9848) acc@1 0.6175 (0.6464) acc@5 0.9844 (0.9785)\n",
      "\u001b[32m[2020-07-10 06:58:49] __main__ INFO: \u001b[0mEpoch 112 Step 300/351 lr 0.010000 loss 1.0211 (0.9872) acc@1 0.6120 (0.6446) acc@5 0.9846 (0.9784)\n",
      "\u001b[32m[2020-07-10 06:58:54] __main__ INFO: \u001b[0mEpoch 112 Step 351/351 lr 0.010000 loss 1.0133 (0.9880) acc@1 0.6541 (0.6448) acc@5 0.9781 (0.9780)\n",
      "\u001b[32m[2020-07-10 06:58:54] __main__ INFO: \u001b[0mElapsed 33.48\n",
      "\u001b[32m[2020-07-10 06:58:54] __main__ INFO: \u001b[0mVal 112\n",
      "\u001b[32m[2020-07-10 06:58:55] __main__ INFO: \u001b[0mEpoch 112 loss 0.3978 acc@1 0.9262 acc@5 0.9956\n",
      "\u001b[32m[2020-07-10 06:58:55] __main__ INFO: \u001b[0mElapsed 1.11\n",
      "\u001b[32m[2020-07-10 06:58:55] __main__ INFO: \u001b[0mTrain 113 39312\n",
      "\u001b[32m[2020-07-10 06:59:04] __main__ INFO: \u001b[0mEpoch 113 Step 100/351 lr 0.010000 loss 0.9612 (0.9902) acc@1 0.6467 (0.6436) acc@5 0.9774 (0.9783)\n",
      "\u001b[32m[2020-07-10 06:59:14] __main__ INFO: \u001b[0mEpoch 113 Step 200/351 lr 0.010000 loss 0.9997 (0.9874) acc@1 0.6719 (0.6451) acc@5 0.9682 (0.9787)\n",
      "\u001b[32m[2020-07-10 06:59:24] __main__ INFO: \u001b[0mEpoch 113 Step 300/351 lr 0.010000 loss 1.0372 (0.9875) acc@1 0.6257 (0.6454) acc@5 0.9845 (0.9784)\n",
      "\u001b[32m[2020-07-10 06:59:28] __main__ INFO: \u001b[0mEpoch 113 Step 351/351 lr 0.010000 loss 1.0084 (0.9880) acc@1 0.6522 (0.6454) acc@5 0.9781 (0.9782)\n",
      "\u001b[32m[2020-07-10 06:59:28] __main__ INFO: \u001b[0mElapsed 33.55\n",
      "\u001b[32m[2020-07-10 06:59:28] __main__ INFO: \u001b[0mVal 113\n",
      "\u001b[32m[2020-07-10 06:59:29] __main__ INFO: \u001b[0mEpoch 113 loss 0.3961 acc@1 0.9206 acc@5 0.9958\n",
      "\u001b[32m[2020-07-10 06:59:29] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 06:59:29] __main__ INFO: \u001b[0mTrain 114 39663\n",
      "\u001b[32m[2020-07-10 06:59:39] __main__ INFO: \u001b[0mEpoch 114 Step 100/351 lr 0.010000 loss 1.0087 (0.9745) acc@1 0.6101 (0.6499) acc@5 0.9856 (0.9787)\n",
      "\u001b[32m[2020-07-10 06:59:49] __main__ INFO: \u001b[0mEpoch 114 Step 200/351 lr 0.010000 loss 1.0153 (0.9840) acc@1 0.6215 (0.6465) acc@5 0.9728 (0.9778)\n",
      "\u001b[32m[2020-07-10 06:59:58] __main__ INFO: \u001b[0mEpoch 114 Step 300/351 lr 0.010000 loss 0.9755 (0.9846) acc@1 0.6410 (0.6458) acc@5 0.9761 (0.9780)\n",
      "\u001b[32m[2020-07-10 07:00:03] __main__ INFO: \u001b[0mEpoch 114 Step 351/351 lr 0.010000 loss 0.9415 (0.9849) acc@1 0.6682 (0.6463) acc@5 0.9781 (0.9780)\n",
      "\u001b[32m[2020-07-10 07:00:03] __main__ INFO: \u001b[0mElapsed 33.52\n",
      "\u001b[32m[2020-07-10 07:00:03] __main__ INFO: \u001b[0mVal 114\n",
      "\u001b[32m[2020-07-10 07:00:04] __main__ INFO: \u001b[0mEpoch 114 loss 0.3866 acc@1 0.9270 acc@5 0.9950\n",
      "\u001b[32m[2020-07-10 07:00:04] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 07:00:04] __main__ INFO: \u001b[0mTrain 115 40014\n",
      "\u001b[32m[2020-07-10 07:00:14] __main__ INFO: \u001b[0mEpoch 115 Step 100/351 lr 0.010000 loss 1.0184 (0.9757) acc@1 0.5860 (0.6484) acc@5 0.9775 (0.9793)\n",
      "\u001b[32m[2020-07-10 07:00:23] __main__ INFO: \u001b[0mEpoch 115 Step 200/351 lr 0.010000 loss 0.9573 (0.9751) acc@1 0.6639 (0.6477) acc@5 0.9830 (0.9792)\n",
      "\u001b[32m[2020-07-10 07:00:33] __main__ INFO: \u001b[0mEpoch 115 Step 300/351 lr 0.010000 loss 1.0417 (0.9802) acc@1 0.5982 (0.6465) acc@5 0.9877 (0.9788)\n",
      "\u001b[32m[2020-07-10 07:00:38] __main__ INFO: \u001b[0mEpoch 115 Step 351/351 lr 0.010000 loss 1.1110 (0.9828) acc@1 0.6021 (0.6458) acc@5 0.9768 (0.9786)\n",
      "\u001b[32m[2020-07-10 07:00:38] __main__ INFO: \u001b[0mElapsed 33.65\n",
      "\u001b[32m[2020-07-10 07:00:38] __main__ INFO: \u001b[0mVal 115\n",
      "\u001b[32m[2020-07-10 07:00:39] __main__ INFO: \u001b[0mEpoch 115 loss 0.4010 acc@1 0.9258 acc@5 0.9964\n",
      "\u001b[32m[2020-07-10 07:00:39] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 07:00:39] __main__ INFO: \u001b[0mTrain 116 40365\n",
      "\u001b[32m[2020-07-10 07:00:48] __main__ INFO: \u001b[0mEpoch 116 Step 100/351 lr 0.010000 loss 1.0222 (0.9754) acc@1 0.6192 (0.6499) acc@5 0.9906 (0.9797)\n",
      "\u001b[32m[2020-07-10 07:00:58] __main__ INFO: \u001b[0mEpoch 116 Step 200/351 lr 0.010000 loss 0.9653 (0.9799) acc@1 0.6425 (0.6476) acc@5 0.9880 (0.9798)\n",
      "\u001b[32m[2020-07-10 07:01:07] __main__ INFO: \u001b[0mEpoch 116 Step 300/351 lr 0.010000 loss 0.9779 (0.9798) acc@1 0.6636 (0.6474) acc@5 0.9790 (0.9794)\n",
      "\u001b[32m[2020-07-10 07:01:12] __main__ INFO: \u001b[0mEpoch 116 Step 351/351 lr 0.010000 loss 0.9702 (0.9808) acc@1 0.6457 (0.6479) acc@5 0.9797 (0.9793)\n",
      "\u001b[32m[2020-07-10 07:01:12] __main__ INFO: \u001b[0mElapsed 33.52\n",
      "\u001b[32m[2020-07-10 07:01:12] __main__ INFO: \u001b[0mVal 116\n",
      "\u001b[32m[2020-07-10 07:01:13] __main__ INFO: \u001b[0mEpoch 116 loss 0.3906 acc@1 0.9234 acc@5 0.9950\n",
      "\u001b[32m[2020-07-10 07:01:13] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 07:01:13] __main__ INFO: \u001b[0mTrain 117 40716\n",
      "\u001b[32m[2020-07-10 07:01:23] __main__ INFO: \u001b[0mEpoch 117 Step 100/351 lr 0.010000 loss 0.9830 (0.9721) acc@1 0.6124 (0.6475) acc@5 0.9818 (0.9797)\n",
      "\u001b[32m[2020-07-10 07:01:33] __main__ INFO: \u001b[0mEpoch 117 Step 200/351 lr 0.010000 loss 0.9652 (0.9749) acc@1 0.6364 (0.6472) acc@5 0.9818 (0.9792)\n",
      "\u001b[32m[2020-07-10 07:01:42] __main__ INFO: \u001b[0mEpoch 117 Step 300/351 lr 0.010000 loss 0.9826 (0.9810) acc@1 0.6390 (0.6457) acc@5 0.9798 (0.9788)\n",
      "\u001b[32m[2020-07-10 07:01:47] __main__ INFO: \u001b[0mEpoch 117 Step 351/351 lr 0.010000 loss 1.0167 (0.9792) acc@1 0.6316 (0.6468) acc@5 0.9767 (0.9790)\n",
      "\u001b[32m[2020-07-10 07:01:47] __main__ INFO: \u001b[0mElapsed 33.50\n",
      "\u001b[32m[2020-07-10 07:01:47] __main__ INFO: \u001b[0mVal 117\n",
      "\u001b[32m[2020-07-10 07:01:48] __main__ INFO: \u001b[0mEpoch 117 loss 0.4118 acc@1 0.9216 acc@5 0.9936\n",
      "\u001b[32m[2020-07-10 07:01:48] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 07:01:48] __main__ INFO: \u001b[0mTrain 118 41067\n",
      "\u001b[32m[2020-07-10 07:01:58] __main__ INFO: \u001b[0mEpoch 118 Step 100/351 lr 0.010000 loss 0.9687 (0.9676) acc@1 0.6339 (0.6478) acc@5 0.9731 (0.9795)\n",
      "\u001b[32m[2020-07-10 07:02:07] __main__ INFO: \u001b[0mEpoch 118 Step 200/351 lr 0.010000 loss 1.0416 (0.9728) acc@1 0.6524 (0.6473) acc@5 0.9598 (0.9791)\n",
      "\u001b[32m[2020-07-10 07:02:17] __main__ INFO: \u001b[0mEpoch 118 Step 300/351 lr 0.010000 loss 1.0029 (0.9780) acc@1 0.6164 (0.6467) acc@5 0.9848 (0.9791)\n",
      "\u001b[32m[2020-07-10 07:02:22] __main__ INFO: \u001b[0mEpoch 118 Step 351/351 lr 0.010000 loss 0.9321 (0.9792) acc@1 0.6498 (0.6459) acc@5 0.9752 (0.9789)\n",
      "\u001b[32m[2020-07-10 07:02:22] __main__ INFO: \u001b[0mElapsed 33.47\n",
      "\u001b[32m[2020-07-10 07:02:22] __main__ INFO: \u001b[0mVal 118\n",
      "\u001b[32m[2020-07-10 07:02:23] __main__ INFO: \u001b[0mEpoch 118 loss 0.3919 acc@1 0.9266 acc@5 0.9954\n",
      "\u001b[32m[2020-07-10 07:02:23] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 07:02:23] __main__ INFO: \u001b[0mTrain 119 41418\n",
      "\u001b[32m[2020-07-10 07:02:32] __main__ INFO: \u001b[0mEpoch 119 Step 100/351 lr 0.010000 loss 0.9959 (0.9729) acc@1 0.6158 (0.6487) acc@5 0.9799 (0.9799)\n",
      "\u001b[32m[2020-07-10 07:02:42] __main__ INFO: \u001b[0mEpoch 119 Step 200/351 lr 0.010000 loss 1.0125 (0.9766) acc@1 0.6306 (0.6464) acc@5 0.9618 (0.9797)\n",
      "\u001b[32m[2020-07-10 07:02:51] __main__ INFO: \u001b[0mEpoch 119 Step 300/351 lr 0.010000 loss 0.9615 (0.9777) acc@1 0.6573 (0.6468) acc@5 0.9774 (0.9791)\n",
      "\u001b[32m[2020-07-10 07:02:56] __main__ INFO: \u001b[0mEpoch 119 Step 351/351 lr 0.010000 loss 0.9828 (0.9780) acc@1 0.6673 (0.6472) acc@5 0.9781 (0.9789)\n",
      "\u001b[32m[2020-07-10 07:02:56] __main__ INFO: \u001b[0mElapsed 33.49\n",
      "\u001b[32m[2020-07-10 07:02:56] __main__ INFO: \u001b[0mVal 119\n",
      "\u001b[32m[2020-07-10 07:02:57] __main__ INFO: \u001b[0mEpoch 119 loss 0.3847 acc@1 0.9246 acc@5 0.9952\n",
      "\u001b[32m[2020-07-10 07:02:57] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 07:02:57] __main__ INFO: \u001b[0mTrain 120 41769\n",
      "\u001b[32m[2020-07-10 07:03:07] __main__ INFO: \u001b[0mEpoch 120 Step 100/351 lr 0.010000 loss 0.9416 (0.9715) acc@1 0.6436 (0.6464) acc@5 0.9810 (0.9793)\n",
      "\u001b[32m[2020-07-10 07:03:16] __main__ INFO: \u001b[0mEpoch 120 Step 200/351 lr 0.010000 loss 0.9741 (0.9713) acc@1 0.6611 (0.6483) acc@5 0.9813 (0.9796)\n",
      "\u001b[32m[2020-07-10 07:03:26] __main__ INFO: \u001b[0mEpoch 120 Step 300/351 lr 0.010000 loss 0.9848 (0.9747) acc@1 0.6697 (0.6472) acc@5 0.9813 (0.9793)\n",
      "\u001b[32m[2020-07-10 07:03:31] __main__ INFO: \u001b[0mEpoch 120 Step 351/351 lr 0.010000 loss 0.9995 (0.9747) acc@1 0.6153 (0.6474) acc@5 0.9837 (0.9793)\n",
      "\u001b[32m[2020-07-10 07:03:31] __main__ INFO: \u001b[0mElapsed 33.54\n",
      "\u001b[32m[2020-07-10 07:03:31] __main__ INFO: \u001b[0mVal 120\n",
      "\u001b[32m[2020-07-10 07:03:32] __main__ INFO: \u001b[0mEpoch 120 loss 0.4133 acc@1 0.9186 acc@5 0.9954\n",
      "\u001b[32m[2020-07-10 07:03:32] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 07:03:32] __main__ INFO: \u001b[0mTrain 121 42120\n",
      "\u001b[32m[2020-07-10 07:03:41] __main__ INFO: \u001b[0mEpoch 121 Step 100/351 lr 0.001000 loss 0.9739 (0.9547) acc@1 0.6433 (0.6533) acc@5 0.9752 (0.9811)\n",
      "\u001b[32m[2020-07-10 07:03:51] __main__ INFO: \u001b[0mEpoch 121 Step 200/351 lr 0.001000 loss 0.8931 (0.9529) acc@1 0.6730 (0.6540) acc@5 0.9928 (0.9807)\n",
      "\u001b[32m[2020-07-10 07:04:00] __main__ INFO: \u001b[0mEpoch 121 Step 300/351 lr 0.001000 loss 0.9431 (0.9519) acc@1 0.6425 (0.6543) acc@5 0.9856 (0.9810)\n",
      "\u001b[32m[2020-07-10 07:04:05] __main__ INFO: \u001b[0mEpoch 121 Step 351/351 lr 0.001000 loss 0.9021 (0.9499) acc@1 0.6887 (0.6553) acc@5 0.9858 (0.9810)\n",
      "\u001b[32m[2020-07-10 07:04:05] __main__ INFO: \u001b[0mElapsed 33.49\n",
      "\u001b[32m[2020-07-10 07:04:05] __main__ INFO: \u001b[0mVal 121\n",
      "\u001b[32m[2020-07-10 07:04:06] __main__ INFO: \u001b[0mEpoch 121 loss 0.3837 acc@1 0.9280 acc@5 0.9952\n",
      "\u001b[32m[2020-07-10 07:04:06] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 07:04:06] __main__ INFO: \u001b[0mTrain 122 42471\n",
      "\u001b[32m[2020-07-10 07:04:16] __main__ INFO: \u001b[0mEpoch 122 Step 100/351 lr 0.001000 loss 0.9091 (0.9367) acc@1 0.6453 (0.6595) acc@5 0.9977 (0.9821)\n",
      "\u001b[32m[2020-07-10 07:04:26] __main__ INFO: \u001b[0mEpoch 122 Step 200/351 lr 0.001000 loss 0.9309 (0.9367) acc@1 0.6362 (0.6594) acc@5 0.9846 (0.9824)\n",
      "\u001b[32m[2020-07-10 07:04:35] __main__ INFO: \u001b[0mEpoch 122 Step 300/351 lr 0.001000 loss 0.9262 (0.9391) acc@1 0.6481 (0.6585) acc@5 0.9922 (0.9827)\n",
      "\u001b[32m[2020-07-10 07:04:40] __main__ INFO: \u001b[0mEpoch 122 Step 351/351 lr 0.001000 loss 0.9491 (0.9409) acc@1 0.6496 (0.6575) acc@5 0.9799 (0.9825)\n",
      "\u001b[32m[2020-07-10 07:04:40] __main__ INFO: \u001b[0mElapsed 33.52\n",
      "\u001b[32m[2020-07-10 07:04:40] __main__ INFO: \u001b[0mVal 122\n",
      "\u001b[32m[2020-07-10 07:04:41] __main__ INFO: \u001b[0mEpoch 122 loss 0.3834 acc@1 0.9306 acc@5 0.9954\n",
      "\u001b[32m[2020-07-10 07:04:41] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 07:04:41] __main__ INFO: \u001b[0mTrain 123 42822\n",
      "\u001b[32m[2020-07-10 07:04:51] __main__ INFO: \u001b[0mEpoch 123 Step 100/351 lr 0.001000 loss 0.9398 (0.9327) acc@1 0.6643 (0.6631) acc@5 0.9812 (0.9827)\n",
      "\u001b[32m[2020-07-10 07:05:00] __main__ INFO: \u001b[0mEpoch 123 Step 200/351 lr 0.001000 loss 0.9154 (0.9408) acc@1 0.6520 (0.6587) acc@5 0.9906 (0.9819)\n",
      "\u001b[32m[2020-07-10 07:05:10] __main__ INFO: \u001b[0mEpoch 123 Step 300/351 lr 0.001000 loss 0.9330 (0.9408) acc@1 0.6755 (0.6574) acc@5 0.9781 (0.9819)\n",
      "\u001b[32m[2020-07-10 07:05:15] __main__ INFO: \u001b[0mEpoch 123 Step 351/351 lr 0.001000 loss 0.9142 (0.9400) acc@1 0.6945 (0.6585) acc@5 0.9803 (0.9818)\n",
      "\u001b[32m[2020-07-10 07:05:15] __main__ INFO: \u001b[0mElapsed 33.55\n",
      "\u001b[32m[2020-07-10 07:05:15] __main__ INFO: \u001b[0mVal 123\n",
      "\u001b[32m[2020-07-10 07:05:16] __main__ INFO: \u001b[0mEpoch 123 loss 0.3801 acc@1 0.9294 acc@5 0.9960\n",
      "\u001b[32m[2020-07-10 07:05:16] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 07:05:16] __main__ INFO: \u001b[0mTrain 124 43173\n",
      "\u001b[32m[2020-07-10 07:05:25] __main__ INFO: \u001b[0mEpoch 124 Step 100/351 lr 0.001000 loss 0.9577 (0.9305) acc@1 0.6603 (0.6609) acc@5 0.9876 (0.9820)\n",
      "\u001b[32m[2020-07-10 07:05:35] __main__ INFO: \u001b[0mEpoch 124 Step 200/351 lr 0.001000 loss 0.9497 (0.9314) acc@1 0.6617 (0.6620) acc@5 0.9826 (0.9823)\n",
      "\u001b[32m[2020-07-10 07:05:44] __main__ INFO: \u001b[0mEpoch 124 Step 300/351 lr 0.001000 loss 0.8763 (0.9362) acc@1 0.6938 (0.6592) acc@5 0.9863 (0.9821)\n",
      "\u001b[32m[2020-07-10 07:05:49] __main__ INFO: \u001b[0mEpoch 124 Step 351/351 lr 0.001000 loss 0.9305 (0.9371) acc@1 0.6660 (0.6590) acc@5 0.9809 (0.9822)\n",
      "\u001b[32m[2020-07-10 07:05:49] __main__ INFO: \u001b[0mElapsed 33.42\n",
      "\u001b[32m[2020-07-10 07:05:49] __main__ INFO: \u001b[0mVal 124\n",
      "\u001b[32m[2020-07-10 07:05:50] __main__ INFO: \u001b[0mEpoch 124 loss 0.3780 acc@1 0.9314 acc@5 0.9956\n",
      "\u001b[32m[2020-07-10 07:05:50] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 07:05:50] __main__ INFO: \u001b[0mTrain 125 43524\n",
      "\u001b[32m[2020-07-10 07:06:00] __main__ INFO: \u001b[0mEpoch 125 Step 100/351 lr 0.001000 loss 0.9113 (0.9375) acc@1 0.6726 (0.6587) acc@5 0.9835 (0.9818)\n",
      "\u001b[32m[2020-07-10 07:06:09] __main__ INFO: \u001b[0mEpoch 125 Step 200/351 lr 0.001000 loss 0.9566 (0.9363) acc@1 0.6603 (0.6587) acc@5 0.9746 (0.9824)\n",
      "\u001b[32m[2020-07-10 07:06:19] __main__ INFO: \u001b[0mEpoch 125 Step 300/351 lr 0.001000 loss 0.8521 (0.9354) acc@1 0.6850 (0.6587) acc@5 0.9871 (0.9824)\n",
      "\u001b[32m[2020-07-10 07:06:24] __main__ INFO: \u001b[0mEpoch 125 Step 351/351 lr 0.001000 loss 0.9721 (0.9352) acc@1 0.6405 (0.6587) acc@5 0.9788 (0.9826)\n",
      "\u001b[32m[2020-07-10 07:06:24] __main__ INFO: \u001b[0mElapsed 33.55\n",
      "\u001b[32m[2020-07-10 07:06:24] __main__ INFO: \u001b[0mVal 125\n",
      "\u001b[32m[2020-07-10 07:06:25] __main__ INFO: \u001b[0mEpoch 125 loss 0.3807 acc@1 0.9292 acc@5 0.9952\n",
      "\u001b[32m[2020-07-10 07:06:25] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 07:06:25] __main__ INFO: \u001b[0mTrain 126 43875\n",
      "\u001b[32m[2020-07-10 07:06:34] __main__ INFO: \u001b[0mEpoch 126 Step 100/351 lr 0.001000 loss 1.0224 (0.9377) acc@1 0.6111 (0.6566) acc@5 0.9844 (0.9833)\n",
      "\u001b[32m[2020-07-10 07:06:44] __main__ INFO: \u001b[0mEpoch 126 Step 200/351 lr 0.001000 loss 1.0337 (0.9341) acc@1 0.6210 (0.6593) acc@5 0.9768 (0.9829)\n",
      "\u001b[32m[2020-07-10 07:06:53] __main__ INFO: \u001b[0mEpoch 126 Step 300/351 lr 0.001000 loss 0.9037 (0.9344) acc@1 0.6761 (0.6595) acc@5 0.9931 (0.9827)\n",
      "\u001b[32m[2020-07-10 07:06:58] __main__ INFO: \u001b[0mEpoch 126 Step 351/351 lr 0.001000 loss 0.9251 (0.9348) acc@1 0.6487 (0.6594) acc@5 0.9878 (0.9826)\n",
      "\u001b[32m[2020-07-10 07:06:58] __main__ INFO: \u001b[0mElapsed 33.49\n",
      "\u001b[32m[2020-07-10 07:06:58] __main__ INFO: \u001b[0mVal 126\n",
      "\u001b[32m[2020-07-10 07:06:59] __main__ INFO: \u001b[0mEpoch 126 loss 0.3881 acc@1 0.9294 acc@5 0.9966\n",
      "\u001b[32m[2020-07-10 07:06:59] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 07:06:59] __main__ INFO: \u001b[0mTrain 127 44226\n",
      "\u001b[32m[2020-07-10 07:07:09] __main__ INFO: \u001b[0mEpoch 127 Step 100/351 lr 0.001000 loss 0.9777 (0.9356) acc@1 0.6403 (0.6577) acc@5 0.9822 (0.9825)\n",
      "\u001b[32m[2020-07-10 07:07:19] __main__ INFO: \u001b[0mEpoch 127 Step 200/351 lr 0.001000 loss 0.9422 (0.9346) acc@1 0.6545 (0.6588) acc@5 0.9866 (0.9822)\n",
      "\u001b[32m[2020-07-10 07:07:28] __main__ INFO: \u001b[0mEpoch 127 Step 300/351 lr 0.001000 loss 0.9272 (0.9337) acc@1 0.6677 (0.6602) acc@5 0.9890 (0.9822)\n",
      "\u001b[32m[2020-07-10 07:07:33] __main__ INFO: \u001b[0mEpoch 127 Step 351/351 lr 0.001000 loss 0.9388 (0.9344) acc@1 0.6456 (0.6597) acc@5 0.9807 (0.9823)\n",
      "\u001b[32m[2020-07-10 07:07:33] __main__ INFO: \u001b[0mElapsed 33.47\n",
      "\u001b[32m[2020-07-10 07:07:33] __main__ INFO: \u001b[0mVal 127\n",
      "\u001b[32m[2020-07-10 07:07:34] __main__ INFO: \u001b[0mEpoch 127 loss 0.3774 acc@1 0.9302 acc@5 0.9954\n",
      "\u001b[32m[2020-07-10 07:07:34] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 07:07:34] __main__ INFO: \u001b[0mTrain 128 44577\n",
      "\u001b[32m[2020-07-10 07:07:44] __main__ INFO: \u001b[0mEpoch 128 Step 100/351 lr 0.001000 loss 0.9086 (0.9373) acc@1 0.6471 (0.6589) acc@5 0.9821 (0.9825)\n",
      "\u001b[32m[2020-07-10 07:07:53] __main__ INFO: \u001b[0mEpoch 128 Step 200/351 lr 0.001000 loss 0.9980 (0.9338) acc@1 0.6178 (0.6604) acc@5 0.9745 (0.9830)\n",
      "\u001b[32m[2020-07-10 07:08:03] __main__ INFO: \u001b[0mEpoch 128 Step 300/351 lr 0.001000 loss 0.8792 (0.9321) acc@1 0.6940 (0.6605) acc@5 0.9887 (0.9831)\n",
      "\u001b[32m[2020-07-10 07:08:07] __main__ INFO: \u001b[0mEpoch 128 Step 351/351 lr 0.001000 loss 0.8879 (0.9323) acc@1 0.6666 (0.6599) acc@5 0.9886 (0.9831)\n",
      "\u001b[32m[2020-07-10 07:08:07] __main__ INFO: \u001b[0mElapsed 33.50\n",
      "\u001b[32m[2020-07-10 07:08:07] __main__ INFO: \u001b[0mVal 128\n",
      "\u001b[32m[2020-07-10 07:08:09] __main__ INFO: \u001b[0mEpoch 128 loss 0.3824 acc@1 0.9286 acc@5 0.9954\n",
      "\u001b[32m[2020-07-10 07:08:09] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 07:08:09] __main__ INFO: \u001b[0mTrain 129 44928\n",
      "\u001b[32m[2020-07-10 07:08:18] __main__ INFO: \u001b[0mEpoch 129 Step 100/351 lr 0.001000 loss 0.9842 (0.9277) acc@1 0.6211 (0.6591) acc@5 0.9825 (0.9847)\n",
      "\u001b[32m[2020-07-10 07:08:28] __main__ INFO: \u001b[0mEpoch 129 Step 200/351 lr 0.001000 loss 0.9649 (0.9299) acc@1 0.6641 (0.6601) acc@5 0.9804 (0.9833)\n",
      "\u001b[32m[2020-07-10 07:08:37] __main__ INFO: \u001b[0mEpoch 129 Step 300/351 lr 0.001000 loss 1.0256 (0.9308) acc@1 0.6384 (0.6600) acc@5 0.9747 (0.9831)\n",
      "\u001b[32m[2020-07-10 07:08:42] __main__ INFO: \u001b[0mEpoch 129 Step 351/351 lr 0.001000 loss 0.8839 (0.9307) acc@1 0.6854 (0.6602) acc@5 0.9931 (0.9832)\n",
      "\u001b[32m[2020-07-10 07:08:42] __main__ INFO: \u001b[0mElapsed 33.48\n",
      "\u001b[32m[2020-07-10 07:08:42] __main__ INFO: \u001b[0mVal 129\n",
      "\u001b[32m[2020-07-10 07:08:43] __main__ INFO: \u001b[0mEpoch 129 loss 0.3809 acc@1 0.9298 acc@5 0.9956\n",
      "\u001b[32m[2020-07-10 07:08:43] __main__ INFO: \u001b[0mElapsed 1.11\n",
      "\u001b[32m[2020-07-10 07:08:43] __main__ INFO: \u001b[0mTrain 130 45279\n",
      "\u001b[32m[2020-07-10 07:08:53] __main__ INFO: \u001b[0mEpoch 130 Step 100/351 lr 0.001000 loss 0.9032 (0.9264) acc@1 0.7023 (0.6597) acc@5 0.9714 (0.9829)\n",
      "\u001b[32m[2020-07-10 07:09:02] __main__ INFO: \u001b[0mEpoch 130 Step 200/351 lr 0.001000 loss 0.9681 (0.9274) acc@1 0.6447 (0.6601) acc@5 0.9684 (0.9828)\n",
      "\u001b[32m[2020-07-10 07:09:12] __main__ INFO: \u001b[0mEpoch 130 Step 300/351 lr 0.001000 loss 0.9293 (0.9272) acc@1 0.6461 (0.6612) acc@5 0.9832 (0.9828)\n",
      "\u001b[32m[2020-07-10 07:09:17] __main__ INFO: \u001b[0mEpoch 130 Step 351/351 lr 0.001000 loss 0.9701 (0.9285) acc@1 0.6214 (0.6607) acc@5 0.9841 (0.9829)\n",
      "\u001b[32m[2020-07-10 07:09:17] __main__ INFO: \u001b[0mElapsed 33.48\n",
      "\u001b[32m[2020-07-10 07:09:17] __main__ INFO: \u001b[0mVal 130\n",
      "\u001b[32m[2020-07-10 07:09:18] __main__ INFO: \u001b[0mEpoch 130 loss 0.3818 acc@1 0.9306 acc@5 0.9960\n",
      "\u001b[32m[2020-07-10 07:09:18] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 07:09:18] __main__ INFO: \u001b[0mTrain 131 45630\n",
      "\u001b[32m[2020-07-10 07:09:27] __main__ INFO: \u001b[0mEpoch 131 Step 100/351 lr 0.001000 loss 0.9196 (0.9195) acc@1 0.6880 (0.6667) acc@5 0.9770 (0.9835)\n",
      "\u001b[32m[2020-07-10 07:09:37] __main__ INFO: \u001b[0mEpoch 131 Step 200/351 lr 0.001000 loss 0.8961 (0.9265) acc@1 0.6561 (0.6613) acc@5 0.9859 (0.9835)\n",
      "\u001b[32m[2020-07-10 07:09:46] __main__ INFO: \u001b[0mEpoch 131 Step 300/351 lr 0.001000 loss 0.9425 (0.9279) acc@1 0.6608 (0.6612) acc@5 0.9751 (0.9834)\n",
      "\u001b[32m[2020-07-10 07:09:51] __main__ INFO: \u001b[0mEpoch 131 Step 351/351 lr 0.001000 loss 0.9514 (0.9283) acc@1 0.6604 (0.6606) acc@5 0.9801 (0.9833)\n",
      "\u001b[32m[2020-07-10 07:09:51] __main__ INFO: \u001b[0mElapsed 33.52\n",
      "\u001b[32m[2020-07-10 07:09:51] __main__ INFO: \u001b[0mVal 131\n",
      "\u001b[32m[2020-07-10 07:09:52] __main__ INFO: \u001b[0mEpoch 131 loss 0.3786 acc@1 0.9306 acc@5 0.9958\n",
      "\u001b[32m[2020-07-10 07:09:52] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 07:09:52] __main__ INFO: \u001b[0mTrain 132 45981\n",
      "\u001b[32m[2020-07-10 07:10:02] __main__ INFO: \u001b[0mEpoch 132 Step 100/351 lr 0.001000 loss 0.8595 (0.9269) acc@1 0.6725 (0.6628) acc@5 0.9866 (0.9830)\n",
      "\u001b[32m[2020-07-10 07:10:11] __main__ INFO: \u001b[0mEpoch 132 Step 200/351 lr 0.001000 loss 0.8757 (0.9307) acc@1 0.6982 (0.6601) acc@5 0.9823 (0.9827)\n",
      "\u001b[32m[2020-07-10 07:10:21] __main__ INFO: \u001b[0mEpoch 132 Step 300/351 lr 0.001000 loss 0.8774 (0.9286) acc@1 0.6814 (0.6611) acc@5 0.9880 (0.9826)\n",
      "\u001b[32m[2020-07-10 07:10:26] __main__ INFO: \u001b[0mEpoch 132 Step 351/351 lr 0.001000 loss 0.9357 (0.9263) acc@1 0.6779 (0.6624) acc@5 0.9755 (0.9827)\n",
      "\u001b[32m[2020-07-10 07:10:26] __main__ INFO: \u001b[0mElapsed 33.37\n",
      "\u001b[32m[2020-07-10 07:10:26] __main__ INFO: \u001b[0mVal 132\n",
      "\u001b[32m[2020-07-10 07:10:27] __main__ INFO: \u001b[0mEpoch 132 loss 0.3754 acc@1 0.9308 acc@5 0.9958\n",
      "\u001b[32m[2020-07-10 07:10:27] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 07:10:27] __main__ INFO: \u001b[0mTrain 133 46332\n",
      "\u001b[32m[2020-07-10 07:10:36] __main__ INFO: \u001b[0mEpoch 133 Step 100/351 lr 0.001000 loss 0.9217 (0.9247) acc@1 0.6679 (0.6614) acc@5 0.9790 (0.9834)\n",
      "\u001b[32m[2020-07-10 07:10:46] __main__ INFO: \u001b[0mEpoch 133 Step 200/351 lr 0.001000 loss 0.9272 (0.9240) acc@1 0.6540 (0.6631) acc@5 0.9923 (0.9823)\n",
      "\u001b[32m[2020-07-10 07:10:55] __main__ INFO: \u001b[0mEpoch 133 Step 300/351 lr 0.001000 loss 0.9539 (0.9265) acc@1 0.6547 (0.6624) acc@5 0.9931 (0.9824)\n",
      "\u001b[32m[2020-07-10 07:11:00] __main__ INFO: \u001b[0mEpoch 133 Step 351/351 lr 0.001000 loss 0.9169 (0.9276) acc@1 0.6506 (0.6619) acc@5 0.9899 (0.9826)\n",
      "\u001b[32m[2020-07-10 07:11:00] __main__ INFO: \u001b[0mElapsed 33.44\n",
      "\u001b[32m[2020-07-10 07:11:00] __main__ INFO: \u001b[0mVal 133\n",
      "\u001b[32m[2020-07-10 07:11:01] __main__ INFO: \u001b[0mEpoch 133 loss 0.3783 acc@1 0.9330 acc@5 0.9954\n",
      "\u001b[32m[2020-07-10 07:11:01] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 07:11:01] __main__ INFO: \u001b[0mTrain 134 46683\n",
      "\u001b[32m[2020-07-10 07:11:11] __main__ INFO: \u001b[0mEpoch 134 Step 100/351 lr 0.001000 loss 0.9085 (0.9249) acc@1 0.6713 (0.6618) acc@5 0.9820 (0.9846)\n",
      "\u001b[32m[2020-07-10 07:11:20] __main__ INFO: \u001b[0mEpoch 134 Step 200/351 lr 0.001000 loss 0.9224 (0.9255) acc@1 0.6398 (0.6618) acc@5 0.9742 (0.9837)\n",
      "\u001b[32m[2020-07-10 07:11:30] __main__ INFO: \u001b[0mEpoch 134 Step 300/351 lr 0.001000 loss 0.8733 (0.9274) acc@1 0.6765 (0.6612) acc@5 0.9786 (0.9833)\n",
      "\u001b[32m[2020-07-10 07:11:35] __main__ INFO: \u001b[0mEpoch 134 Step 351/351 lr 0.001000 loss 0.9812 (0.9283) acc@1 0.6266 (0.6609) acc@5 0.9765 (0.9831)\n",
      "\u001b[32m[2020-07-10 07:11:35] __main__ INFO: \u001b[0mElapsed 33.48\n",
      "\u001b[32m[2020-07-10 07:11:35] __main__ INFO: \u001b[0mVal 134\n",
      "\u001b[32m[2020-07-10 07:11:36] __main__ INFO: \u001b[0mEpoch 134 loss 0.3820 acc@1 0.9308 acc@5 0.9950\n",
      "\u001b[32m[2020-07-10 07:11:36] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 07:11:36] __main__ INFO: \u001b[0mTrain 135 47034\n",
      "\u001b[32m[2020-07-10 07:11:45] __main__ INFO: \u001b[0mEpoch 135 Step 100/351 lr 0.001000 loss 0.9739 (0.9248) acc@1 0.6334 (0.6648) acc@5 0.9822 (0.9815)\n",
      "\u001b[32m[2020-07-10 07:11:55] __main__ INFO: \u001b[0mEpoch 135 Step 200/351 lr 0.001000 loss 0.9423 (0.9266) acc@1 0.6466 (0.6620) acc@5 0.9885 (0.9828)\n",
      "\u001b[32m[2020-07-10 07:12:04] __main__ INFO: \u001b[0mEpoch 135 Step 300/351 lr 0.001000 loss 0.9739 (0.9289) acc@1 0.6279 (0.6620) acc@5 0.9949 (0.9824)\n",
      "\u001b[32m[2020-07-10 07:12:09] __main__ INFO: \u001b[0mEpoch 135 Step 351/351 lr 0.001000 loss 0.9134 (0.9285) acc@1 0.6730 (0.6617) acc@5 0.9797 (0.9826)\n",
      "\u001b[32m[2020-07-10 07:12:09] __main__ INFO: \u001b[0mElapsed 33.42\n",
      "\u001b[32m[2020-07-10 07:12:09] __main__ INFO: \u001b[0mVal 135\n",
      "\u001b[32m[2020-07-10 07:12:10] __main__ INFO: \u001b[0mEpoch 135 loss 0.3803 acc@1 0.9320 acc@5 0.9952\n",
      "\u001b[32m[2020-07-10 07:12:10] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 07:12:10] __main__ INFO: \u001b[0mTrain 136 47385\n",
      "\u001b[32m[2020-07-10 07:12:20] __main__ INFO: \u001b[0mEpoch 136 Step 100/351 lr 0.001000 loss 0.9331 (0.9304) acc@1 0.6512 (0.6573) acc@5 0.9807 (0.9827)\n",
      "\u001b[32m[2020-07-10 07:12:30] __main__ INFO: \u001b[0mEpoch 136 Step 200/351 lr 0.001000 loss 0.9285 (0.9308) acc@1 0.6754 (0.6587) acc@5 0.9834 (0.9829)\n",
      "\u001b[32m[2020-07-10 07:12:39] __main__ INFO: \u001b[0mEpoch 136 Step 300/351 lr 0.001000 loss 0.8971 (0.9272) acc@1 0.6661 (0.6603) acc@5 0.9777 (0.9831)\n",
      "\u001b[32m[2020-07-10 07:12:44] __main__ INFO: \u001b[0mEpoch 136 Step 351/351 lr 0.001000 loss 0.8296 (0.9257) acc@1 0.6938 (0.6609) acc@5 0.9853 (0.9834)\n",
      "\u001b[32m[2020-07-10 07:12:44] __main__ INFO: \u001b[0mElapsed 33.46\n",
      "\u001b[32m[2020-07-10 07:12:44] __main__ INFO: \u001b[0mVal 136\n",
      "\u001b[32m[2020-07-10 07:12:45] __main__ INFO: \u001b[0mEpoch 136 loss 0.3799 acc@1 0.9316 acc@5 0.9956\n",
      "\u001b[32m[2020-07-10 07:12:45] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 07:12:45] __main__ INFO: \u001b[0mTrain 137 47736\n",
      "\u001b[32m[2020-07-10 07:12:55] __main__ INFO: \u001b[0mEpoch 137 Step 100/351 lr 0.001000 loss 0.9485 (0.9287) acc@1 0.6676 (0.6617) acc@5 0.9850 (0.9822)\n",
      "\u001b[32m[2020-07-10 07:13:04] __main__ INFO: \u001b[0mEpoch 137 Step 200/351 lr 0.001000 loss 0.9905 (0.9250) acc@1 0.6614 (0.6620) acc@5 0.9672 (0.9825)\n",
      "\u001b[32m[2020-07-10 07:13:14] __main__ INFO: \u001b[0mEpoch 137 Step 300/351 lr 0.001000 loss 0.8971 (0.9246) acc@1 0.6812 (0.6610) acc@5 0.9896 (0.9829)\n",
      "\u001b[32m[2020-07-10 07:13:18] __main__ INFO: \u001b[0mEpoch 137 Step 351/351 lr 0.001000 loss 0.9753 (0.9251) acc@1 0.6447 (0.6607) acc@5 0.9764 (0.9828)\n",
      "\u001b[32m[2020-07-10 07:13:18] __main__ INFO: \u001b[0mElapsed 33.43\n",
      "\u001b[32m[2020-07-10 07:13:18] __main__ INFO: \u001b[0mVal 137\n",
      "\u001b[32m[2020-07-10 07:13:19] __main__ INFO: \u001b[0mEpoch 137 loss 0.3833 acc@1 0.9302 acc@5 0.9956\n",
      "\u001b[32m[2020-07-10 07:13:20] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 07:13:20] __main__ INFO: \u001b[0mTrain 138 48087\n",
      "\u001b[32m[2020-07-10 07:13:29] __main__ INFO: \u001b[0mEpoch 138 Step 100/351 lr 0.001000 loss 0.8529 (0.9232) acc@1 0.6694 (0.6611) acc@5 0.9900 (0.9840)\n",
      "\u001b[32m[2020-07-10 07:13:39] __main__ INFO: \u001b[0mEpoch 138 Step 200/351 lr 0.001000 loss 0.9127 (0.9254) acc@1 0.6549 (0.6611) acc@5 0.9796 (0.9836)\n",
      "\u001b[32m[2020-07-10 07:13:48] __main__ INFO: \u001b[0mEpoch 138 Step 300/351 lr 0.001000 loss 0.8826 (0.9245) acc@1 0.6745 (0.6606) acc@5 0.9879 (0.9837)\n",
      "\u001b[32m[2020-07-10 07:13:53] __main__ INFO: \u001b[0mEpoch 138 Step 351/351 lr 0.001000 loss 0.8762 (0.9257) acc@1 0.6924 (0.6609) acc@5 0.9827 (0.9835)\n",
      "\u001b[32m[2020-07-10 07:13:53] __main__ INFO: \u001b[0mElapsed 33.49\n",
      "\u001b[32m[2020-07-10 07:13:53] __main__ INFO: \u001b[0mVal 138\n",
      "\u001b[32m[2020-07-10 07:13:54] __main__ INFO: \u001b[0mEpoch 138 loss 0.3854 acc@1 0.9292 acc@5 0.9952\n",
      "\u001b[32m[2020-07-10 07:13:54] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 07:13:54] __main__ INFO: \u001b[0mTrain 139 48438\n",
      "\u001b[32m[2020-07-10 07:14:04] __main__ INFO: \u001b[0mEpoch 139 Step 100/351 lr 0.001000 loss 0.9753 (0.9210) acc@1 0.6155 (0.6643) acc@5 0.9800 (0.9828)\n",
      "\u001b[32m[2020-07-10 07:14:13] __main__ INFO: \u001b[0mEpoch 139 Step 200/351 lr 0.001000 loss 0.9859 (0.9204) acc@1 0.6412 (0.6640) acc@5 0.9852 (0.9834)\n",
      "\u001b[32m[2020-07-10 07:14:23] __main__ INFO: \u001b[0mEpoch 139 Step 300/351 lr 0.001000 loss 0.9564 (0.9237) acc@1 0.6591 (0.6627) acc@5 0.9805 (0.9834)\n",
      "\u001b[32m[2020-07-10 07:14:27] __main__ INFO: \u001b[0mEpoch 139 Step 351/351 lr 0.001000 loss 1.0012 (0.9244) acc@1 0.6107 (0.6624) acc@5 0.9742 (0.9832)\n",
      "\u001b[32m[2020-07-10 07:14:28] __main__ INFO: \u001b[0mElapsed 33.43\n",
      "\u001b[32m[2020-07-10 07:14:28] __main__ INFO: \u001b[0mVal 139\n",
      "\u001b[32m[2020-07-10 07:14:29] __main__ INFO: \u001b[0mEpoch 139 loss 0.3827 acc@1 0.9296 acc@5 0.9952\n",
      "\u001b[32m[2020-07-10 07:14:29] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 07:14:29] __main__ INFO: \u001b[0mTrain 140 48789\n",
      "\u001b[32m[2020-07-10 07:14:38] __main__ INFO: \u001b[0mEpoch 140 Step 100/351 lr 0.001000 loss 0.9498 (0.9135) acc@1 0.6656 (0.6643) acc@5 0.9883 (0.9845)\n",
      "\u001b[32m[2020-07-10 07:14:48] __main__ INFO: \u001b[0mEpoch 140 Step 200/351 lr 0.001000 loss 0.9373 (0.9181) acc@1 0.6642 (0.6630) acc@5 0.9832 (0.9838)\n",
      "\u001b[32m[2020-07-10 07:14:57] __main__ INFO: \u001b[0mEpoch 140 Step 300/351 lr 0.001000 loss 1.0338 (0.9190) acc@1 0.6171 (0.6631) acc@5 0.9715 (0.9840)\n",
      "\u001b[32m[2020-07-10 07:15:02] __main__ INFO: \u001b[0mEpoch 140 Step 351/351 lr 0.001000 loss 0.8436 (0.9218) acc@1 0.6824 (0.6624) acc@5 0.9908 (0.9837)\n",
      "\u001b[32m[2020-07-10 07:15:02] __main__ INFO: \u001b[0mElapsed 33.38\n",
      "\u001b[32m[2020-07-10 07:15:02] __main__ INFO: \u001b[0mVal 140\n",
      "\u001b[32m[2020-07-10 07:15:03] __main__ INFO: \u001b[0mEpoch 140 loss 0.3875 acc@1 0.9306 acc@5 0.9952\n",
      "\u001b[32m[2020-07-10 07:15:03] __main__ INFO: \u001b[0mElapsed 1.11\n",
      "\u001b[32m[2020-07-10 07:15:03] __main__ INFO: \u001b[0mTrain 141 49140\n",
      "\u001b[32m[2020-07-10 07:15:13] __main__ INFO: \u001b[0mEpoch 141 Step 100/351 lr 0.001000 loss 0.9429 (0.9244) acc@1 0.6770 (0.6614) acc@5 0.9808 (0.9833)\n",
      "\u001b[32m[2020-07-10 07:15:22] __main__ INFO: \u001b[0mEpoch 141 Step 200/351 lr 0.001000 loss 0.9277 (0.9225) acc@1 0.6272 (0.6619) acc@5 0.9814 (0.9836)\n",
      "\u001b[32m[2020-07-10 07:15:32] __main__ INFO: \u001b[0mEpoch 141 Step 300/351 lr 0.001000 loss 0.8797 (0.9228) acc@1 0.6876 (0.6613) acc@5 0.9802 (0.9838)\n",
      "\u001b[32m[2020-07-10 07:15:36] __main__ INFO: \u001b[0mEpoch 141 Step 351/351 lr 0.001000 loss 0.8838 (0.9220) acc@1 0.6357 (0.6618) acc@5 0.9927 (0.9837)\n",
      "\u001b[32m[2020-07-10 07:15:37] __main__ INFO: \u001b[0mElapsed 33.43\n",
      "\u001b[32m[2020-07-10 07:15:37] __main__ INFO: \u001b[0mVal 141\n",
      "\u001b[32m[2020-07-10 07:15:38] __main__ INFO: \u001b[0mEpoch 141 loss 0.3781 acc@1 0.9308 acc@5 0.9960\n",
      "\u001b[32m[2020-07-10 07:15:38] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 07:15:38] __main__ INFO: \u001b[0mTrain 142 49491\n",
      "\u001b[32m[2020-07-10 07:15:47] __main__ INFO: \u001b[0mEpoch 142 Step 100/351 lr 0.001000 loss 0.9143 (0.9190) acc@1 0.6559 (0.6608) acc@5 0.9873 (0.9840)\n",
      "\u001b[32m[2020-07-10 07:15:57] __main__ INFO: \u001b[0mEpoch 142 Step 200/351 lr 0.001000 loss 0.9293 (0.9201) acc@1 0.6514 (0.6618) acc@5 0.9873 (0.9841)\n",
      "\u001b[32m[2020-07-10 07:16:06] __main__ INFO: \u001b[0mEpoch 142 Step 300/351 lr 0.001000 loss 0.8662 (0.9214) acc@1 0.6864 (0.6620) acc@5 0.9812 (0.9837)\n",
      "\u001b[32m[2020-07-10 07:16:11] __main__ INFO: \u001b[0mEpoch 142 Step 351/351 lr 0.001000 loss 0.9141 (0.9228) acc@1 0.6528 (0.6621) acc@5 0.9880 (0.9834)\n",
      "\u001b[32m[2020-07-10 07:16:11] __main__ INFO: \u001b[0mElapsed 33.41\n",
      "\u001b[32m[2020-07-10 07:16:11] __main__ INFO: \u001b[0mVal 142\n",
      "\u001b[32m[2020-07-10 07:16:12] __main__ INFO: \u001b[0mEpoch 142 loss 0.3869 acc@1 0.9308 acc@5 0.9958\n",
      "\u001b[32m[2020-07-10 07:16:12] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-07-10 07:16:12] __main__ INFO: \u001b[0mTrain 143 49842\n",
      "\u001b[32m[2020-07-10 07:16:22] __main__ INFO: \u001b[0mEpoch 143 Step 100/351 lr 0.001000 loss 0.9158 (0.9287) acc@1 0.6585 (0.6558) acc@5 0.9883 (0.9838)\n",
      "\u001b[32m[2020-07-10 07:16:31] __main__ INFO: \u001b[0mEpoch 143 Step 200/351 lr 0.001000 loss 0.9817 (0.9217) acc@1 0.6106 (0.6601) acc@5 0.9866 (0.9840)\n",
      "\u001b[32m[2020-07-10 07:16:41] __main__ INFO: \u001b[0mEpoch 143 Step 300/351 lr 0.001000 loss 0.8798 (0.9222) acc@1 0.7110 (0.6608) acc@5 0.9768 (0.9836)\n",
      "\u001b[32m[2020-07-10 07:16:46] __main__ INFO: \u001b[0mEpoch 143 Step 351/351 lr 0.001000 loss 0.9784 (0.9214) acc@1 0.6457 (0.6617) acc@5 0.9784 (0.9836)\n",
      "\u001b[32m[2020-07-10 07:16:46] __main__ INFO: \u001b[0mElapsed 33.41\n",
      "\u001b[32m[2020-07-10 07:16:46] __main__ INFO: \u001b[0mVal 143\n",
      "\u001b[32m[2020-07-10 07:16:47] __main__ INFO: \u001b[0mEpoch 143 loss 0.3782 acc@1 0.9310 acc@5 0.9950\n",
      "\u001b[32m[2020-07-10 07:16:47] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 07:16:47] __main__ INFO: \u001b[0mTrain 144 50193\n",
      "\u001b[32m[2020-07-10 07:16:56] __main__ INFO: \u001b[0mEpoch 144 Step 100/351 lr 0.001000 loss 0.8876 (0.9184) acc@1 0.6817 (0.6630) acc@5 0.9813 (0.9847)\n",
      "\u001b[32m[2020-07-10 07:17:06] __main__ INFO: \u001b[0mEpoch 144 Step 200/351 lr 0.001000 loss 0.9463 (0.9192) acc@1 0.6461 (0.6626) acc@5 0.9724 (0.9841)\n",
      "\u001b[32m[2020-07-10 07:17:15] __main__ INFO: \u001b[0mEpoch 144 Step 300/351 lr 0.001000 loss 0.8199 (0.9210) acc@1 0.7044 (0.6623) acc@5 0.9953 (0.9838)\n",
      "\u001b[32m[2020-07-10 07:17:20] __main__ INFO: \u001b[0mEpoch 144 Step 351/351 lr 0.001000 loss 0.9089 (0.9219) acc@1 0.6616 (0.6620) acc@5 0.9880 (0.9838)\n",
      "\u001b[32m[2020-07-10 07:17:20] __main__ INFO: \u001b[0mElapsed 33.39\n",
      "\u001b[32m[2020-07-10 07:17:20] __main__ INFO: \u001b[0mVal 144\n",
      "\u001b[32m[2020-07-10 07:17:21] __main__ INFO: \u001b[0mEpoch 144 loss 0.3838 acc@1 0.9296 acc@5 0.9948\n",
      "\u001b[32m[2020-07-10 07:17:21] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 07:17:21] __main__ INFO: \u001b[0mTrain 145 50544\n",
      "\u001b[32m[2020-07-10 07:17:31] __main__ INFO: \u001b[0mEpoch 145 Step 100/351 lr 0.001000 loss 0.8598 (0.9146) acc@1 0.6680 (0.6643) acc@5 0.9816 (0.9845)\n",
      "\u001b[32m[2020-07-10 07:17:40] __main__ INFO: \u001b[0mEpoch 145 Step 200/351 lr 0.001000 loss 1.0055 (0.9217) acc@1 0.6405 (0.6625) acc@5 0.9726 (0.9837)\n",
      "\u001b[32m[2020-07-10 07:17:50] __main__ INFO: \u001b[0mEpoch 145 Step 300/351 lr 0.001000 loss 0.9660 (0.9213) acc@1 0.6419 (0.6621) acc@5 0.9849 (0.9835)\n",
      "\u001b[32m[2020-07-10 07:17:55] __main__ INFO: \u001b[0mEpoch 145 Step 351/351 lr 0.001000 loss 0.9434 (0.9215) acc@1 0.6605 (0.6619) acc@5 0.9877 (0.9834)\n",
      "\u001b[32m[2020-07-10 07:17:55] __main__ INFO: \u001b[0mElapsed 33.45\n",
      "\u001b[32m[2020-07-10 07:17:55] __main__ INFO: \u001b[0mVal 145\n",
      "\u001b[32m[2020-07-10 07:17:56] __main__ INFO: \u001b[0mEpoch 145 loss 0.3861 acc@1 0.9306 acc@5 0.9954\n",
      "\u001b[32m[2020-07-10 07:17:56] __main__ INFO: \u001b[0mElapsed 1.11\n",
      "\u001b[32m[2020-07-10 07:17:56] __main__ INFO: \u001b[0mTrain 146 50895\n",
      "\u001b[32m[2020-07-10 07:18:05] __main__ INFO: \u001b[0mEpoch 146 Step 100/351 lr 0.001000 loss 0.8270 (0.9135) acc@1 0.7050 (0.6649) acc@5 0.9911 (0.9831)\n",
      "\u001b[32m[2020-07-10 07:18:15] __main__ INFO: \u001b[0mEpoch 146 Step 200/351 lr 0.001000 loss 0.8766 (0.9151) acc@1 0.6766 (0.6645) acc@5 0.9927 (0.9833)\n",
      "\u001b[32m[2020-07-10 07:18:24] __main__ INFO: \u001b[0mEpoch 146 Step 300/351 lr 0.001000 loss 0.9144 (0.9175) acc@1 0.6545 (0.6636) acc@5 0.9852 (0.9835)\n",
      "\u001b[32m[2020-07-10 07:18:29] __main__ INFO: \u001b[0mEpoch 146 Step 351/351 lr 0.001000 loss 0.9445 (0.9196) acc@1 0.6279 (0.6630) acc@5 0.9872 (0.9833)\n",
      "\u001b[32m[2020-07-10 07:18:29] __main__ INFO: \u001b[0mElapsed 33.46\n",
      "\u001b[32m[2020-07-10 07:18:29] __main__ INFO: \u001b[0mVal 146\n",
      "\u001b[32m[2020-07-10 07:18:30] __main__ INFO: \u001b[0mEpoch 146 loss 0.3801 acc@1 0.9284 acc@5 0.9954\n",
      "\u001b[32m[2020-07-10 07:18:30] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 07:18:30] __main__ INFO: \u001b[0mTrain 147 51246\n",
      "\u001b[32m[2020-07-10 07:18:40] __main__ INFO: \u001b[0mEpoch 147 Step 100/351 lr 0.001000 loss 0.9395 (0.9182) acc@1 0.6522 (0.6621) acc@5 0.9787 (0.9844)\n",
      "\u001b[32m[2020-07-10 07:18:49] __main__ INFO: \u001b[0mEpoch 147 Step 200/351 lr 0.001000 loss 0.8292 (0.9187) acc@1 0.6994 (0.6626) acc@5 0.9875 (0.9842)\n",
      "\u001b[32m[2020-07-10 07:18:59] __main__ INFO: \u001b[0mEpoch 147 Step 300/351 lr 0.001000 loss 0.8699 (0.9213) acc@1 0.6787 (0.6618) acc@5 0.9928 (0.9839)\n",
      "\u001b[32m[2020-07-10 07:19:04] __main__ INFO: \u001b[0mEpoch 147 Step 351/351 lr 0.001000 loss 0.8778 (0.9198) acc@1 0.6921 (0.6622) acc@5 0.9907 (0.9839)\n",
      "\u001b[32m[2020-07-10 07:19:04] __main__ INFO: \u001b[0mElapsed 33.45\n",
      "\u001b[32m[2020-07-10 07:19:04] __main__ INFO: \u001b[0mVal 147\n",
      "\u001b[32m[2020-07-10 07:19:05] __main__ INFO: \u001b[0mEpoch 147 loss 0.3740 acc@1 0.9300 acc@5 0.9964\n",
      "\u001b[32m[2020-07-10 07:19:05] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 07:19:05] __main__ INFO: \u001b[0mTrain 148 51597\n",
      "\u001b[32m[2020-07-10 07:19:14] __main__ INFO: \u001b[0mEpoch 148 Step 100/351 lr 0.001000 loss 0.9449 (0.9225) acc@1 0.6350 (0.6617) acc@5 0.9876 (0.9830)\n",
      "\u001b[32m[2020-07-10 07:19:24] __main__ INFO: \u001b[0mEpoch 148 Step 200/351 lr 0.001000 loss 0.9544 (0.9220) acc@1 0.6699 (0.6627) acc@5 0.9820 (0.9839)\n",
      "\u001b[32m[2020-07-10 07:19:33] __main__ INFO: \u001b[0mEpoch 148 Step 300/351 lr 0.001000 loss 0.8852 (0.9214) acc@1 0.6821 (0.6625) acc@5 0.9828 (0.9838)\n",
      "\u001b[32m[2020-07-10 07:19:38] __main__ INFO: \u001b[0mEpoch 148 Step 351/351 lr 0.001000 loss 0.9118 (0.9216) acc@1 0.6661 (0.6620) acc@5 0.9904 (0.9839)\n",
      "\u001b[32m[2020-07-10 07:19:38] __main__ INFO: \u001b[0mElapsed 33.40\n",
      "\u001b[32m[2020-07-10 07:19:38] __main__ INFO: \u001b[0mVal 148\n",
      "\u001b[32m[2020-07-10 07:19:39] __main__ INFO: \u001b[0mEpoch 148 loss 0.3796 acc@1 0.9294 acc@5 0.9952\n",
      "\u001b[32m[2020-07-10 07:19:39] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-07-10 07:19:39] __main__ INFO: \u001b[0mTrain 149 51948\n",
      "\u001b[32m[2020-07-10 07:19:49] __main__ INFO: \u001b[0mEpoch 149 Step 100/351 lr 0.001000 loss 0.9239 (0.9239) acc@1 0.6694 (0.6597) acc@5 0.9861 (0.9830)\n",
      "\u001b[32m[2020-07-10 07:19:58] __main__ INFO: \u001b[0mEpoch 149 Step 200/351 lr 0.001000 loss 0.9047 (0.9234) acc@1 0.6625 (0.6595) acc@5 0.9790 (0.9834)\n",
      "\u001b[32m[2020-07-10 07:20:08] __main__ INFO: \u001b[0mEpoch 149 Step 300/351 lr 0.001000 loss 0.9147 (0.9203) acc@1 0.6760 (0.6611) acc@5 0.9780 (0.9836)\n",
      "\u001b[32m[2020-07-10 07:20:13] __main__ INFO: \u001b[0mEpoch 149 Step 351/351 lr 0.001000 loss 0.9172 (0.9200) acc@1 0.6802 (0.6613) acc@5 0.9744 (0.9837)\n",
      "\u001b[32m[2020-07-10 07:20:13] __main__ INFO: \u001b[0mElapsed 33.44\n",
      "\u001b[32m[2020-07-10 07:20:13] __main__ INFO: \u001b[0mVal 149\n",
      "\u001b[32m[2020-07-10 07:20:14] __main__ INFO: \u001b[0mEpoch 149 loss 0.3786 acc@1 0.9328 acc@5 0.9954\n",
      "\u001b[32m[2020-07-10 07:20:14] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-07-10 07:20:14] __main__ INFO: \u001b[0mTrain 150 52299\n",
      "\u001b[32m[2020-07-10 07:20:23] __main__ INFO: \u001b[0mEpoch 150 Step 100/351 lr 0.001000 loss 0.9370 (0.9229) acc@1 0.6660 (0.6603) acc@5 0.9828 (0.9836)\n",
      "\u001b[32m[2020-07-10 07:20:33] __main__ INFO: \u001b[0mEpoch 150 Step 200/351 lr 0.001000 loss 0.9375 (0.9214) acc@1 0.6267 (0.6617) acc@5 0.9851 (0.9840)\n",
      "\u001b[32m[2020-07-10 07:20:42] __main__ INFO: \u001b[0mEpoch 150 Step 300/351 lr 0.001000 loss 0.9187 (0.9209) acc@1 0.6718 (0.6615) acc@5 0.9729 (0.9839)\n",
      "\u001b[32m[2020-07-10 07:20:47] __main__ INFO: \u001b[0mEpoch 150 Step 351/351 lr 0.001000 loss 0.9988 (0.9206) acc@1 0.6279 (0.6620) acc@5 0.9695 (0.9840)\n",
      "\u001b[32m[2020-07-10 07:20:47] __main__ INFO: \u001b[0mElapsed 33.48\n",
      "\u001b[32m[2020-07-10 07:20:47] __main__ INFO: \u001b[0mVal 150\n",
      "\u001b[32m[2020-07-10 07:20:48] __main__ INFO: \u001b[0mEpoch 150 loss 0.3830 acc@1 0.9288 acc@5 0.9954\n",
      "\u001b[32m[2020-07-10 07:20:48] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 07:20:48] __main__ INFO: \u001b[0mTrain 151 52650\n",
      "\u001b[32m[2020-07-10 07:20:58] __main__ INFO: \u001b[0mEpoch 151 Step 100/351 lr 0.001000 loss 0.8848 (0.9141) acc@1 0.7028 (0.6650) acc@5 0.9891 (0.9837)\n",
      "\u001b[32m[2020-07-10 07:21:07] __main__ INFO: \u001b[0mEpoch 151 Step 200/351 lr 0.001000 loss 0.9430 (0.9184) acc@1 0.6668 (0.6625) acc@5 0.9884 (0.9838)\n",
      "\u001b[32m[2020-07-10 07:21:17] __main__ INFO: \u001b[0mEpoch 151 Step 300/351 lr 0.001000 loss 0.9306 (0.9187) acc@1 0.6592 (0.6618) acc@5 0.9947 (0.9839)\n",
      "\u001b[32m[2020-07-10 07:21:22] __main__ INFO: \u001b[0mEpoch 151 Step 351/351 lr 0.001000 loss 0.9015 (0.9199) acc@1 0.6667 (0.6617) acc@5 0.9902 (0.9839)\n",
      "\u001b[32m[2020-07-10 07:21:22] __main__ INFO: \u001b[0mElapsed 33.44\n",
      "\u001b[32m[2020-07-10 07:21:22] __main__ INFO: \u001b[0mVal 151\n",
      "\u001b[32m[2020-07-10 07:21:23] __main__ INFO: \u001b[0mEpoch 151 loss 0.3766 acc@1 0.9304 acc@5 0.9954\n",
      "\u001b[32m[2020-07-10 07:21:23] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 07:21:23] __main__ INFO: \u001b[0mTrain 152 53001\n",
      "\u001b[32m[2020-07-10 07:21:32] __main__ INFO: \u001b[0mEpoch 152 Step 100/351 lr 0.001000 loss 0.9228 (0.9122) acc@1 0.6666 (0.6672) acc@5 0.9834 (0.9843)\n",
      "\u001b[32m[2020-07-10 07:21:42] __main__ INFO: \u001b[0mEpoch 152 Step 200/351 lr 0.001000 loss 0.9382 (0.9160) acc@1 0.6449 (0.6649) acc@5 0.9903 (0.9843)\n",
      "\u001b[32m[2020-07-10 07:21:51] __main__ INFO: \u001b[0mEpoch 152 Step 300/351 lr 0.001000 loss 0.9608 (0.9197) acc@1 0.6358 (0.6628) acc@5 0.9836 (0.9839)\n",
      "\u001b[32m[2020-07-10 07:21:56] __main__ INFO: \u001b[0mEpoch 152 Step 351/351 lr 0.001000 loss 0.8462 (0.9191) acc@1 0.6940 (0.6634) acc@5 0.9811 (0.9837)\n",
      "\u001b[32m[2020-07-10 07:21:56] __main__ INFO: \u001b[0mElapsed 33.30\n",
      "\u001b[32m[2020-07-10 07:21:56] __main__ INFO: \u001b[0mVal 152\n",
      "\u001b[32m[2020-07-10 07:21:57] __main__ INFO: \u001b[0mEpoch 152 loss 0.3791 acc@1 0.9310 acc@5 0.9956\n",
      "\u001b[32m[2020-07-10 07:21:57] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 07:21:57] __main__ INFO: \u001b[0mTrain 153 53352\n",
      "\u001b[32m[2020-07-10 07:22:07] __main__ INFO: \u001b[0mEpoch 153 Step 100/351 lr 0.001000 loss 0.8742 (0.9152) acc@1 0.6671 (0.6629) acc@5 0.9905 (0.9843)\n",
      "\u001b[32m[2020-07-10 07:22:16] __main__ INFO: \u001b[0mEpoch 153 Step 200/351 lr 0.001000 loss 0.8649 (0.9148) acc@1 0.7120 (0.6633) acc@5 0.9909 (0.9846)\n",
      "\u001b[32m[2020-07-10 07:22:26] __main__ INFO: \u001b[0mEpoch 153 Step 300/351 lr 0.001000 loss 0.9562 (0.9148) acc@1 0.6585 (0.6634) acc@5 0.9827 (0.9847)\n",
      "\u001b[32m[2020-07-10 07:22:30] __main__ INFO: \u001b[0mEpoch 153 Step 351/351 lr 0.001000 loss 0.9105 (0.9157) acc@1 0.6580 (0.6625) acc@5 0.9835 (0.9845)\n",
      "\u001b[32m[2020-07-10 07:22:30] __main__ INFO: \u001b[0mElapsed 33.21\n",
      "\u001b[32m[2020-07-10 07:22:30] __main__ INFO: \u001b[0mVal 153\n",
      "\u001b[32m[2020-07-10 07:22:32] __main__ INFO: \u001b[0mEpoch 153 loss 0.3786 acc@1 0.9302 acc@5 0.9950\n",
      "\u001b[32m[2020-07-10 07:22:32] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 07:22:32] __main__ INFO: \u001b[0mTrain 154 53703\n",
      "\u001b[32m[2020-07-10 07:22:41] __main__ INFO: \u001b[0mEpoch 154 Step 100/351 lr 0.001000 loss 0.8828 (0.9108) acc@1 0.6621 (0.6627) acc@5 0.9974 (0.9841)\n",
      "\u001b[32m[2020-07-10 07:22:51] __main__ INFO: \u001b[0mEpoch 154 Step 200/351 lr 0.001000 loss 0.9016 (0.9157) acc@1 0.6821 (0.6616) acc@5 0.9824 (0.9837)\n",
      "\u001b[32m[2020-07-10 07:23:00] __main__ INFO: \u001b[0mEpoch 154 Step 300/351 lr 0.001000 loss 0.9276 (0.9183) acc@1 0.6560 (0.6613) acc@5 0.9817 (0.9834)\n",
      "\u001b[32m[2020-07-10 07:23:05] __main__ INFO: \u001b[0mEpoch 154 Step 351/351 lr 0.001000 loss 0.8666 (0.9175) acc@1 0.6966 (0.6621) acc@5 0.9813 (0.9836)\n",
      "\u001b[32m[2020-07-10 07:23:05] __main__ INFO: \u001b[0mElapsed 33.44\n",
      "\u001b[32m[2020-07-10 07:23:05] __main__ INFO: \u001b[0mVal 154\n",
      "\u001b[32m[2020-07-10 07:23:06] __main__ INFO: \u001b[0mEpoch 154 loss 0.3813 acc@1 0.9292 acc@5 0.9954\n",
      "\u001b[32m[2020-07-10 07:23:06] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 07:23:06] __main__ INFO: \u001b[0mTrain 155 54054\n",
      "\u001b[32m[2020-07-10 07:23:16] __main__ INFO: \u001b[0mEpoch 155 Step 100/351 lr 0.001000 loss 0.9092 (0.9182) acc@1 0.6812 (0.6650) acc@5 0.9764 (0.9834)\n",
      "\u001b[32m[2020-07-10 07:23:25] __main__ INFO: \u001b[0mEpoch 155 Step 200/351 lr 0.001000 loss 0.8894 (0.9168) acc@1 0.6899 (0.6639) acc@5 0.9864 (0.9840)\n",
      "\u001b[32m[2020-07-10 07:23:34] __main__ INFO: \u001b[0mEpoch 155 Step 300/351 lr 0.001000 loss 0.9335 (0.9153) acc@1 0.6733 (0.6641) acc@5 0.9812 (0.9840)\n",
      "\u001b[32m[2020-07-10 07:23:39] __main__ INFO: \u001b[0mEpoch 155 Step 351/351 lr 0.001000 loss 0.8699 (0.9160) acc@1 0.6849 (0.6635) acc@5 0.9739 (0.9837)\n",
      "\u001b[32m[2020-07-10 07:23:39] __main__ INFO: \u001b[0mElapsed 33.22\n",
      "\u001b[32m[2020-07-10 07:23:39] __main__ INFO: \u001b[0mVal 155\n",
      "\u001b[32m[2020-07-10 07:23:40] __main__ INFO: \u001b[0mEpoch 155 loss 0.3784 acc@1 0.9318 acc@5 0.9950\n",
      "\u001b[32m[2020-07-10 07:23:40] __main__ INFO: \u001b[0mElapsed 1.05\n",
      "\u001b[32m[2020-07-10 07:23:40] __main__ INFO: \u001b[0mTrain 156 54405\n",
      "\u001b[32m[2020-07-10 07:23:50] __main__ INFO: \u001b[0mEpoch 156 Step 100/351 lr 0.001000 loss 0.9723 (0.9196) acc@1 0.6518 (0.6612) acc@5 0.9846 (0.9836)\n",
      "\u001b[32m[2020-07-10 07:23:59] __main__ INFO: \u001b[0mEpoch 156 Step 200/351 lr 0.001000 loss 0.8964 (0.9178) acc@1 0.6834 (0.6619) acc@5 0.9929 (0.9834)\n",
      "\u001b[32m[2020-07-10 07:24:09] __main__ INFO: \u001b[0mEpoch 156 Step 300/351 lr 0.001000 loss 0.9580 (0.9174) acc@1 0.6163 (0.6624) acc@5 0.9832 (0.9836)\n",
      "\u001b[32m[2020-07-10 07:24:14] __main__ INFO: \u001b[0mEpoch 156 Step 351/351 lr 0.001000 loss 0.9675 (0.9167) acc@1 0.6425 (0.6625) acc@5 0.9847 (0.9838)\n",
      "\u001b[32m[2020-07-10 07:24:14] __main__ INFO: \u001b[0mElapsed 33.22\n",
      "\u001b[32m[2020-07-10 07:24:14] __main__ INFO: \u001b[0mVal 156\n",
      "\u001b[32m[2020-07-10 07:24:15] __main__ INFO: \u001b[0mEpoch 156 loss 0.3820 acc@1 0.9322 acc@5 0.9950\n",
      "\u001b[32m[2020-07-10 07:24:15] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-07-10 07:24:15] __main__ INFO: \u001b[0mTrain 157 54756\n",
      "\u001b[32m[2020-07-10 07:24:24] __main__ INFO: \u001b[0mEpoch 157 Step 100/351 lr 0.001000 loss 0.9225 (0.9111) acc@1 0.6743 (0.6645) acc@5 0.9863 (0.9843)\n",
      "\u001b[32m[2020-07-10 07:24:34] __main__ INFO: \u001b[0mEpoch 157 Step 200/351 lr 0.001000 loss 0.9452 (0.9149) acc@1 0.6719 (0.6632) acc@5 0.9608 (0.9840)\n",
      "\u001b[32m[2020-07-10 07:24:43] __main__ INFO: \u001b[0mEpoch 157 Step 300/351 lr 0.001000 loss 0.9458 (0.9160) acc@1 0.6384 (0.6632) acc@5 0.9899 (0.9843)\n",
      "\u001b[32m[2020-07-10 07:24:48] __main__ INFO: \u001b[0mEpoch 157 Step 351/351 lr 0.001000 loss 0.9812 (0.9154) acc@1 0.6391 (0.6634) acc@5 0.9853 (0.9846)\n",
      "\u001b[32m[2020-07-10 07:24:48] __main__ INFO: \u001b[0mElapsed 33.26\n",
      "\u001b[32m[2020-07-10 07:24:48] __main__ INFO: \u001b[0mVal 157\n",
      "\u001b[32m[2020-07-10 07:24:49] __main__ INFO: \u001b[0mEpoch 157 loss 0.3826 acc@1 0.9324 acc@5 0.9944\n",
      "\u001b[32m[2020-07-10 07:24:49] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-07-10 07:24:49] __main__ INFO: \u001b[0mTrain 158 55107\n",
      "\u001b[32m[2020-07-10 07:24:59] __main__ INFO: \u001b[0mEpoch 158 Step 100/351 lr 0.001000 loss 0.8778 (0.9148) acc@1 0.6942 (0.6625) acc@5 0.9887 (0.9833)\n",
      "\u001b[32m[2020-07-10 07:25:08] __main__ INFO: \u001b[0mEpoch 158 Step 200/351 lr 0.001000 loss 0.8925 (0.9131) acc@1 0.6552 (0.6616) acc@5 0.9895 (0.9845)\n",
      "\u001b[32m[2020-07-10 07:25:17] __main__ INFO: \u001b[0mEpoch 158 Step 300/351 lr 0.001000 loss 0.9146 (0.9139) acc@1 0.6435 (0.6626) acc@5 0.9955 (0.9841)\n",
      "\u001b[32m[2020-07-10 07:25:22] __main__ INFO: \u001b[0mEpoch 158 Step 351/351 lr 0.001000 loss 0.8549 (0.9133) acc@1 0.6576 (0.6632) acc@5 0.9930 (0.9843)\n",
      "\u001b[32m[2020-07-10 07:25:22] __main__ INFO: \u001b[0mElapsed 33.31\n",
      "\u001b[32m[2020-07-10 07:25:22] __main__ INFO: \u001b[0mVal 158\n",
      "\u001b[32m[2020-07-10 07:25:23] __main__ INFO: \u001b[0mEpoch 158 loss 0.3816 acc@1 0.9318 acc@5 0.9948\n",
      "\u001b[32m[2020-07-10 07:25:23] __main__ INFO: \u001b[0mElapsed 1.11\n",
      "\u001b[32m[2020-07-10 07:25:23] __main__ INFO: \u001b[0mTrain 159 55458\n",
      "\u001b[32m[2020-07-10 07:25:33] __main__ INFO: \u001b[0mEpoch 159 Step 100/351 lr 0.001000 loss 0.9349 (0.9198) acc@1 0.6489 (0.6624) acc@5 0.9953 (0.9841)\n",
      "\u001b[32m[2020-07-10 07:25:42] __main__ INFO: \u001b[0mEpoch 159 Step 200/351 lr 0.001000 loss 0.8464 (0.9164) acc@1 0.6858 (0.6636) acc@5 0.9846 (0.9842)\n",
      "\u001b[32m[2020-07-10 07:25:52] __main__ INFO: \u001b[0mEpoch 159 Step 300/351 lr 0.001000 loss 0.9404 (0.9167) acc@1 0.6436 (0.6633) acc@5 0.9847 (0.9843)\n",
      "\u001b[32m[2020-07-10 07:25:57] __main__ INFO: \u001b[0mEpoch 159 Step 351/351 lr 0.001000 loss 0.8958 (0.9156) acc@1 0.6702 (0.6635) acc@5 0.9854 (0.9843)\n",
      "\u001b[32m[2020-07-10 07:25:57] __main__ INFO: \u001b[0mElapsed 33.29\n",
      "\u001b[32m[2020-07-10 07:25:57] __main__ INFO: \u001b[0mVal 159\n",
      "\u001b[32m[2020-07-10 07:25:58] __main__ INFO: \u001b[0mEpoch 159 loss 0.3822 acc@1 0.9314 acc@5 0.9950\n",
      "\u001b[32m[2020-07-10 07:25:58] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-07-10 07:25:58] __main__ INFO: \u001b[0mTrain 160 55809\n",
      "\u001b[32m[2020-07-10 07:26:07] __main__ INFO: \u001b[0mEpoch 160 Step 100/351 lr 0.001000 loss 0.9425 (0.9154) acc@1 0.6507 (0.6611) acc@5 0.9854 (0.9847)\n",
      "\u001b[32m[2020-07-10 07:26:17] __main__ INFO: \u001b[0mEpoch 160 Step 200/351 lr 0.001000 loss 0.8912 (0.9149) acc@1 0.6752 (0.6627) acc@5 0.9819 (0.9842)\n",
      "\u001b[32m[2020-07-10 07:26:26] __main__ INFO: \u001b[0mEpoch 160 Step 300/351 lr 0.001000 loss 0.9317 (0.9134) acc@1 0.6663 (0.6631) acc@5 0.9766 (0.9845)\n",
      "\u001b[32m[2020-07-10 07:26:31] __main__ INFO: \u001b[0mEpoch 160 Step 351/351 lr 0.001000 loss 0.9641 (0.9140) acc@1 0.6111 (0.6631) acc@5 0.9898 (0.9843)\n",
      "\u001b[32m[2020-07-10 07:26:31] __main__ INFO: \u001b[0mElapsed 33.33\n",
      "\u001b[32m[2020-07-10 07:26:31] __main__ INFO: \u001b[0mVal 160\n",
      "\u001b[32m[2020-07-10 07:26:32] __main__ INFO: \u001b[0mEpoch 160 loss 0.3813 acc@1 0.9292 acc@5 0.9948\n",
      "\u001b[32m[2020-07-10 07:26:32] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-07-10 07:26:32] __main__ INFO: \u001b[0mTrain 161 56160\n",
      "\u001b[32m[2020-07-10 07:26:42] __main__ INFO: \u001b[0mEpoch 161 Step 100/351 lr 0.001000 loss 0.8676 (0.9175) acc@1 0.6903 (0.6623) acc@5 0.9889 (0.9839)\n",
      "\u001b[32m[2020-07-10 07:26:51] __main__ INFO: \u001b[0mEpoch 161 Step 200/351 lr 0.001000 loss 0.8828 (0.9116) acc@1 0.6987 (0.6640) acc@5 0.9869 (0.9847)\n",
      "\u001b[32m[2020-07-10 07:27:01] __main__ INFO: \u001b[0mEpoch 161 Step 300/351 lr 0.001000 loss 0.9056 (0.9144) acc@1 0.6488 (0.6632) acc@5 0.9889 (0.9845)\n",
      "\u001b[32m[2020-07-10 07:27:05] __main__ INFO: \u001b[0mEpoch 161 Step 351/351 lr 0.001000 loss 0.8413 (0.9142) acc@1 0.6930 (0.6631) acc@5 0.9931 (0.9844)\n",
      "\u001b[32m[2020-07-10 07:27:05] __main__ INFO: \u001b[0mElapsed 33.29\n",
      "\u001b[32m[2020-07-10 07:27:05] __main__ INFO: \u001b[0mVal 161\n",
      "\u001b[32m[2020-07-10 07:27:07] __main__ INFO: \u001b[0mEpoch 161 loss 0.3812 acc@1 0.9328 acc@5 0.9946\n",
      "\u001b[32m[2020-07-10 07:27:07] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 07:27:07] __main__ INFO: \u001b[0mTrain 162 56511\n",
      "\u001b[32m[2020-07-10 07:27:16] __main__ INFO: \u001b[0mEpoch 162 Step 100/351 lr 0.001000 loss 0.9060 (0.9151) acc@1 0.6944 (0.6656) acc@5 0.9735 (0.9836)\n",
      "\u001b[32m[2020-07-10 07:27:26] __main__ INFO: \u001b[0mEpoch 162 Step 200/351 lr 0.001000 loss 0.9529 (0.9153) acc@1 0.6461 (0.6629) acc@5 0.9776 (0.9841)\n",
      "\u001b[32m[2020-07-10 07:27:35] __main__ INFO: \u001b[0mEpoch 162 Step 300/351 lr 0.001000 loss 0.7896 (0.9170) acc@1 0.7108 (0.6624) acc@5 0.9927 (0.9842)\n",
      "\u001b[32m[2020-07-10 07:27:40] __main__ INFO: \u001b[0mEpoch 162 Step 351/351 lr 0.001000 loss 0.9527 (0.9161) acc@1 0.6501 (0.6631) acc@5 0.9876 (0.9839)\n",
      "\u001b[32m[2020-07-10 07:27:40] __main__ INFO: \u001b[0mElapsed 33.26\n",
      "\u001b[32m[2020-07-10 07:27:40] __main__ INFO: \u001b[0mVal 162\n",
      "\u001b[32m[2020-07-10 07:27:41] __main__ INFO: \u001b[0mEpoch 162 loss 0.3833 acc@1 0.9286 acc@5 0.9950\n",
      "\u001b[32m[2020-07-10 07:27:41] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 07:27:41] __main__ INFO: \u001b[0mTrain 163 56862\n",
      "\u001b[32m[2020-07-10 07:27:50] __main__ INFO: \u001b[0mEpoch 163 Step 100/351 lr 0.001000 loss 0.9142 (0.9201) acc@1 0.6207 (0.6584) acc@5 0.9831 (0.9842)\n",
      "\u001b[32m[2020-07-10 07:28:00] __main__ INFO: \u001b[0mEpoch 163 Step 200/351 lr 0.001000 loss 0.9233 (0.9169) acc@1 0.6617 (0.6607) acc@5 0.9796 (0.9839)\n",
      "\u001b[32m[2020-07-10 07:28:09] __main__ INFO: \u001b[0mEpoch 163 Step 300/351 lr 0.001000 loss 0.8800 (0.9156) acc@1 0.6596 (0.6616) acc@5 0.9931 (0.9843)\n",
      "\u001b[32m[2020-07-10 07:28:14] __main__ INFO: \u001b[0mEpoch 163 Step 351/351 lr 0.001000 loss 0.9523 (0.9144) acc@1 0.6578 (0.6622) acc@5 0.9745 (0.9844)\n",
      "\u001b[32m[2020-07-10 07:28:14] __main__ INFO: \u001b[0mElapsed 33.28\n",
      "\u001b[32m[2020-07-10 07:28:14] __main__ INFO: \u001b[0mVal 163\n",
      "\u001b[32m[2020-07-10 07:28:15] __main__ INFO: \u001b[0mEpoch 163 loss 0.3797 acc@1 0.9296 acc@5 0.9950\n",
      "\u001b[32m[2020-07-10 07:28:15] __main__ INFO: \u001b[0mElapsed 1.11\n",
      "\u001b[32m[2020-07-10 07:28:15] __main__ INFO: \u001b[0mTrain 164 57213\n",
      "\u001b[32m[2020-07-10 07:28:25] __main__ INFO: \u001b[0mEpoch 164 Step 100/351 lr 0.001000 loss 0.8860 (0.9087) acc@1 0.6560 (0.6641) acc@5 0.9846 (0.9853)\n",
      "\u001b[32m[2020-07-10 07:28:34] __main__ INFO: \u001b[0mEpoch 164 Step 200/351 lr 0.001000 loss 0.8761 (0.9099) acc@1 0.6766 (0.6652) acc@5 0.9777 (0.9848)\n",
      "\u001b[32m[2020-07-10 07:28:44] __main__ INFO: \u001b[0mEpoch 164 Step 300/351 lr 0.001000 loss 0.9707 (0.9125) acc@1 0.6496 (0.6637) acc@5 0.9837 (0.9845)\n",
      "\u001b[32m[2020-07-10 07:28:49] __main__ INFO: \u001b[0mEpoch 164 Step 351/351 lr 0.001000 loss 0.9016 (0.9123) acc@1 0.6451 (0.6639) acc@5 0.9951 (0.9845)\n",
      "\u001b[32m[2020-07-10 07:28:49] __main__ INFO: \u001b[0mElapsed 33.24\n",
      "\u001b[32m[2020-07-10 07:28:49] __main__ INFO: \u001b[0mVal 164\n",
      "\u001b[32m[2020-07-10 07:28:50] __main__ INFO: \u001b[0mEpoch 164 loss 0.3791 acc@1 0.9312 acc@5 0.9944\n",
      "\u001b[32m[2020-07-10 07:28:50] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 07:28:50] __main__ INFO: \u001b[0mTrain 165 57564\n",
      "\u001b[32m[2020-07-10 07:28:59] __main__ INFO: \u001b[0mEpoch 165 Step 100/351 lr 0.001000 loss 0.8847 (0.9187) acc@1 0.6858 (0.6600) acc@5 0.9828 (0.9846)\n",
      "\u001b[32m[2020-07-10 07:29:09] __main__ INFO: \u001b[0mEpoch 165 Step 200/351 lr 0.001000 loss 0.9415 (0.9167) acc@1 0.6671 (0.6610) acc@5 0.9787 (0.9842)\n",
      "\u001b[32m[2020-07-10 07:29:18] __main__ INFO: \u001b[0mEpoch 165 Step 300/351 lr 0.001000 loss 0.9324 (0.9162) acc@1 0.6658 (0.6620) acc@5 0.9904 (0.9842)\n",
      "\u001b[32m[2020-07-10 07:29:23] __main__ INFO: \u001b[0mEpoch 165 Step 351/351 lr 0.001000 loss 0.9147 (0.9144) acc@1 0.6534 (0.6626) acc@5 0.9696 (0.9842)\n",
      "\u001b[32m[2020-07-10 07:29:23] __main__ INFO: \u001b[0mElapsed 33.31\n",
      "\u001b[32m[2020-07-10 07:29:23] __main__ INFO: \u001b[0mVal 165\n",
      "\u001b[32m[2020-07-10 07:29:24] __main__ INFO: \u001b[0mEpoch 165 loss 0.3813 acc@1 0.9304 acc@5 0.9948\n",
      "\u001b[32m[2020-07-10 07:29:24] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 07:29:24] __main__ INFO: \u001b[0mTrain 166 57915\n",
      "\u001b[32m[2020-07-10 07:29:34] __main__ INFO: \u001b[0mEpoch 166 Step 100/351 lr 0.001000 loss 0.8963 (0.9099) acc@1 0.6756 (0.6638) acc@5 0.9902 (0.9851)\n",
      "\u001b[32m[2020-07-10 07:29:43] __main__ INFO: \u001b[0mEpoch 166 Step 200/351 lr 0.001000 loss 0.8893 (0.9095) acc@1 0.6701 (0.6639) acc@5 0.9809 (0.9850)\n",
      "\u001b[32m[2020-07-10 07:29:53] __main__ INFO: \u001b[0mEpoch 166 Step 300/351 lr 0.001000 loss 0.8499 (0.9116) acc@1 0.6808 (0.6640) acc@5 0.9931 (0.9844)\n",
      "\u001b[32m[2020-07-10 07:29:57] __main__ INFO: \u001b[0mEpoch 166 Step 351/351 lr 0.001000 loss 0.8434 (0.9130) acc@1 0.6716 (0.6633) acc@5 0.9878 (0.9843)\n",
      "\u001b[32m[2020-07-10 07:29:57] __main__ INFO: \u001b[0mElapsed 33.36\n",
      "\u001b[32m[2020-07-10 07:29:57] __main__ INFO: \u001b[0mVal 166\n",
      "\u001b[32m[2020-07-10 07:29:58] __main__ INFO: \u001b[0mEpoch 166 loss 0.3823 acc@1 0.9292 acc@5 0.9942\n",
      "\u001b[32m[2020-07-10 07:29:58] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 07:29:58] __main__ INFO: \u001b[0mTrain 167 58266\n",
      "\u001b[32m[2020-07-10 07:30:08] __main__ INFO: \u001b[0mEpoch 167 Step 100/351 lr 0.001000 loss 0.8839 (0.9138) acc@1 0.6985 (0.6634) acc@5 0.9882 (0.9844)\n",
      "\u001b[32m[2020-07-10 07:30:18] __main__ INFO: \u001b[0mEpoch 167 Step 200/351 lr 0.001000 loss 0.9079 (0.9135) acc@1 0.6815 (0.6628) acc@5 0.9910 (0.9845)\n",
      "\u001b[32m[2020-07-10 07:30:27] __main__ INFO: \u001b[0mEpoch 167 Step 300/351 lr 0.001000 loss 0.9237 (0.9126) acc@1 0.6257 (0.6631) acc@5 0.9899 (0.9843)\n",
      "\u001b[32m[2020-07-10 07:30:32] __main__ INFO: \u001b[0mEpoch 167 Step 351/351 lr 0.001000 loss 0.8990 (0.9128) acc@1 0.6721 (0.6631) acc@5 0.9866 (0.9842)\n",
      "\u001b[32m[2020-07-10 07:30:32] __main__ INFO: \u001b[0mElapsed 33.51\n",
      "\u001b[32m[2020-07-10 07:30:32] __main__ INFO: \u001b[0mVal 167\n",
      "\u001b[32m[2020-07-10 07:30:33] __main__ INFO: \u001b[0mEpoch 167 loss 0.3792 acc@1 0.9290 acc@5 0.9946\n",
      "\u001b[32m[2020-07-10 07:30:33] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 07:30:33] __main__ INFO: \u001b[0mTrain 168 58617\n",
      "\u001b[32m[2020-07-10 07:30:43] __main__ INFO: \u001b[0mEpoch 168 Step 100/351 lr 0.001000 loss 0.9473 (0.9064) acc@1 0.6420 (0.6675) acc@5 0.9779 (0.9853)\n",
      "\u001b[32m[2020-07-10 07:30:52] __main__ INFO: \u001b[0mEpoch 168 Step 200/351 lr 0.001000 loss 0.9141 (0.9142) acc@1 0.6748 (0.6621) acc@5 0.9881 (0.9846)\n",
      "\u001b[32m[2020-07-10 07:31:02] __main__ INFO: \u001b[0mEpoch 168 Step 300/351 lr 0.001000 loss 0.8936 (0.9126) acc@1 0.6683 (0.6628) acc@5 0.9850 (0.9846)\n",
      "\u001b[32m[2020-07-10 07:31:06] __main__ INFO: \u001b[0mEpoch 168 Step 351/351 lr 0.001000 loss 0.9388 (0.9122) acc@1 0.6658 (0.6636) acc@5 0.9859 (0.9845)\n",
      "\u001b[32m[2020-07-10 07:31:07] __main__ INFO: \u001b[0mElapsed 33.42\n",
      "\u001b[32m[2020-07-10 07:31:07] __main__ INFO: \u001b[0mVal 168\n",
      "\u001b[32m[2020-07-10 07:31:08] __main__ INFO: \u001b[0mEpoch 168 loss 0.3800 acc@1 0.9308 acc@5 0.9950\n",
      "\u001b[32m[2020-07-10 07:31:08] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-07-10 07:31:08] __main__ INFO: \u001b[0mTrain 169 58968\n",
      "\u001b[32m[2020-07-10 07:31:17] __main__ INFO: \u001b[0mEpoch 169 Step 100/351 lr 0.001000 loss 0.8842 (0.9140) acc@1 0.6810 (0.6641) acc@5 0.9821 (0.9837)\n",
      "\u001b[32m[2020-07-10 07:31:27] __main__ INFO: \u001b[0mEpoch 169 Step 200/351 lr 0.001000 loss 0.9655 (0.9113) acc@1 0.6644 (0.6631) acc@5 0.9730 (0.9845)\n",
      "\u001b[32m[2020-07-10 07:31:36] __main__ INFO: \u001b[0mEpoch 169 Step 300/351 lr 0.001000 loss 0.9078 (0.9116) acc@1 0.6570 (0.6630) acc@5 0.9854 (0.9843)\n",
      "\u001b[32m[2020-07-10 07:31:41] __main__ INFO: \u001b[0mEpoch 169 Step 351/351 lr 0.001000 loss 0.9668 (0.9109) acc@1 0.6277 (0.6631) acc@5 0.9801 (0.9846)\n",
      "\u001b[32m[2020-07-10 07:31:41] __main__ INFO: \u001b[0mElapsed 33.34\n",
      "\u001b[32m[2020-07-10 07:31:41] __main__ INFO: \u001b[0mVal 169\n",
      "\u001b[32m[2020-07-10 07:31:42] __main__ INFO: \u001b[0mEpoch 169 loss 0.3818 acc@1 0.9334 acc@5 0.9944\n",
      "\u001b[32m[2020-07-10 07:31:42] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-07-10 07:31:42] __main__ INFO: \u001b[0mTrain 170 59319\n",
      "\u001b[32m[2020-07-10 07:31:52] __main__ INFO: \u001b[0mEpoch 170 Step 100/351 lr 0.001000 loss 0.9233 (0.9054) acc@1 0.6574 (0.6658) acc@5 0.9848 (0.9848)\n",
      "\u001b[32m[2020-07-10 07:32:01] __main__ INFO: \u001b[0mEpoch 170 Step 200/351 lr 0.001000 loss 0.9397 (0.9075) acc@1 0.6635 (0.6636) acc@5 0.9802 (0.9850)\n",
      "\u001b[32m[2020-07-10 07:32:10] __main__ INFO: \u001b[0mEpoch 170 Step 300/351 lr 0.001000 loss 0.9139 (0.9105) acc@1 0.6780 (0.6633) acc@5 0.9840 (0.9850)\n",
      "\u001b[32m[2020-07-10 07:32:15] __main__ INFO: \u001b[0mEpoch 170 Step 351/351 lr 0.001000 loss 0.8983 (0.9107) acc@1 0.6617 (0.6628) acc@5 0.9754 (0.9851)\n",
      "\u001b[32m[2020-07-10 07:32:15] __main__ INFO: \u001b[0mElapsed 33.28\n",
      "\u001b[32m[2020-07-10 07:32:15] __main__ INFO: \u001b[0mVal 170\n",
      "\u001b[32m[2020-07-10 07:32:16] __main__ INFO: \u001b[0mEpoch 170 loss 0.3809 acc@1 0.9314 acc@5 0.9952\n",
      "\u001b[32m[2020-07-10 07:32:16] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 07:32:16] __main__ INFO: \u001b[0mTrain 171 59670\n",
      "\u001b[32m[2020-07-10 07:32:26] __main__ INFO: \u001b[0mEpoch 171 Step 100/351 lr 0.001000 loss 0.8878 (0.9075) acc@1 0.6867 (0.6642) acc@5 0.9899 (0.9845)\n",
      "\u001b[32m[2020-07-10 07:32:35] __main__ INFO: \u001b[0mEpoch 171 Step 200/351 lr 0.001000 loss 0.9512 (0.9087) acc@1 0.6604 (0.6639) acc@5 0.9673 (0.9840)\n",
      "\u001b[32m[2020-07-10 07:32:45] __main__ INFO: \u001b[0mEpoch 171 Step 300/351 lr 0.001000 loss 0.8583 (0.9089) acc@1 0.6952 (0.6646) acc@5 0.9893 (0.9844)\n",
      "\u001b[32m[2020-07-10 07:32:50] __main__ INFO: \u001b[0mEpoch 171 Step 351/351 lr 0.001000 loss 0.9071 (0.9105) acc@1 0.7015 (0.6641) acc@5 0.9851 (0.9846)\n",
      "\u001b[32m[2020-07-10 07:32:50] __main__ INFO: \u001b[0mElapsed 33.33\n",
      "\u001b[32m[2020-07-10 07:32:50] __main__ INFO: \u001b[0mVal 171\n",
      "\u001b[32m[2020-07-10 07:32:51] __main__ INFO: \u001b[0mEpoch 171 loss 0.3767 acc@1 0.9316 acc@5 0.9950\n",
      "\u001b[32m[2020-07-10 07:32:51] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 07:32:51] __main__ INFO: \u001b[0mTrain 172 60021\n",
      "\u001b[32m[2020-07-10 07:33:00] __main__ INFO: \u001b[0mEpoch 172 Step 100/351 lr 0.001000 loss 0.9832 (0.9091) acc@1 0.6431 (0.6629) acc@5 0.9834 (0.9851)\n",
      "\u001b[32m[2020-07-10 07:33:10] __main__ INFO: \u001b[0mEpoch 172 Step 200/351 lr 0.001000 loss 0.9721 (0.9133) acc@1 0.6399 (0.6624) acc@5 0.9784 (0.9845)\n",
      "\u001b[32m[2020-07-10 07:33:19] __main__ INFO: \u001b[0mEpoch 172 Step 300/351 lr 0.001000 loss 0.9484 (0.9109) acc@1 0.6194 (0.6642) acc@5 0.9875 (0.9844)\n",
      "\u001b[32m[2020-07-10 07:33:24] __main__ INFO: \u001b[0mEpoch 172 Step 351/351 lr 0.001000 loss 0.9945 (0.9095) acc@1 0.6290 (0.6642) acc@5 0.9849 (0.9845)\n",
      "\u001b[32m[2020-07-10 07:33:24] __main__ INFO: \u001b[0mElapsed 33.36\n",
      "\u001b[32m[2020-07-10 07:33:24] __main__ INFO: \u001b[0mVal 172\n",
      "\u001b[32m[2020-07-10 07:33:25] __main__ INFO: \u001b[0mEpoch 172 loss 0.3750 acc@1 0.9312 acc@5 0.9946\n",
      "\u001b[32m[2020-07-10 07:33:25] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 07:33:25] __main__ INFO: \u001b[0mTrain 173 60372\n",
      "\u001b[32m[2020-07-10 07:33:35] __main__ INFO: \u001b[0mEpoch 173 Step 100/351 lr 0.001000 loss 0.9732 (0.9097) acc@1 0.6491 (0.6624) acc@5 0.9806 (0.9852)\n",
      "\u001b[32m[2020-07-10 07:33:44] __main__ INFO: \u001b[0mEpoch 173 Step 200/351 lr 0.001000 loss 0.9337 (0.9096) acc@1 0.6652 (0.6642) acc@5 0.9780 (0.9844)\n",
      "\u001b[32m[2020-07-10 07:33:54] __main__ INFO: \u001b[0mEpoch 173 Step 300/351 lr 0.001000 loss 0.9135 (0.9090) acc@1 0.6571 (0.6642) acc@5 0.9827 (0.9844)\n",
      "\u001b[32m[2020-07-10 07:33:59] __main__ INFO: \u001b[0mEpoch 173 Step 351/351 lr 0.001000 loss 0.9558 (0.9093) acc@1 0.6459 (0.6640) acc@5 0.9977 (0.9845)\n",
      "\u001b[32m[2020-07-10 07:33:59] __main__ INFO: \u001b[0mElapsed 33.44\n",
      "\u001b[32m[2020-07-10 07:33:59] __main__ INFO: \u001b[0mVal 173\n",
      "\u001b[32m[2020-07-10 07:34:00] __main__ INFO: \u001b[0mEpoch 173 loss 0.3846 acc@1 0.9302 acc@5 0.9948\n",
      "\u001b[32m[2020-07-10 07:34:00] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 07:34:00] __main__ INFO: \u001b[0mTrain 174 60723\n",
      "\u001b[32m[2020-07-10 07:34:09] __main__ INFO: \u001b[0mEpoch 174 Step 100/351 lr 0.001000 loss 0.8747 (0.9056) acc@1 0.6858 (0.6661) acc@5 0.9905 (0.9854)\n",
      "\u001b[32m[2020-07-10 07:34:19] __main__ INFO: \u001b[0mEpoch 174 Step 200/351 lr 0.001000 loss 0.8443 (0.9085) acc@1 0.6643 (0.6640) acc@5 0.9922 (0.9850)\n",
      "\u001b[32m[2020-07-10 07:34:28] __main__ INFO: \u001b[0mEpoch 174 Step 300/351 lr 0.001000 loss 0.8487 (0.9063) acc@1 0.6879 (0.6646) acc@5 0.9862 (0.9852)\n"
     ]
    }
   ],
   "source": [
    "# Train the model per the settings specified in the original paper\n",
    "os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "!python train.py --config configs/cifar/resnext.yaml \\\n",
    "    model.resnext.cardinality 4 \\\n",
    "    train.batch_size 128 \\\n",
    "    train.base_lr 0.1 \\\n",
    "    dataset.name CIFAR10_CM_1 \\\n",
    "    train.base_lr 0.1 \\\n",
    "    train.output_dir /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_cm_1_1/exp00 \\\n",
    "    scheduler.epochs 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refine the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-10 13:39:42] __main__ INFO: \u001b[0mdevice: cuda\n",
      "cudnn:\n",
      "  benchmark: True\n",
      "  deterministic: False\n",
      "dataset:\n",
      "  name: CIFAR10\n",
      "  dataset_dir: ~/.torch/datasets/CIFAR10\n",
      "  image_size: 32\n",
      "  n_channels: 3\n",
      "  n_classes: 10\n",
      "model:\n",
      "  type: cifar\n",
      "  name: resnet\n",
      "  init_mode: kaiming_fan_out\n",
      "  vgg:\n",
      "    n_channels: [64, 128, 256, 512, 512]\n",
      "    n_layers: [2, 2, 3, 3, 3]\n",
      "    use_bn: True\n",
      "  resnet:\n",
      "    depth: 32\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "  resnet_preact:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "  wrn:\n",
      "    depth: 28\n",
      "    initial_channels: 16\n",
      "    widening_factor: 10\n",
      "    drop_rate: 0.0\n",
      "  densenet:\n",
      "    depth: 100\n",
      "    n_blocks: [6, 12, 24, 16]\n",
      "    block_type: bottleneck\n",
      "    growth_rate: 12\n",
      "    drop_rate: 0.0\n",
      "    compression_rate: 0.5\n",
      "  pyramidnet:\n",
      "    depth: 272\n",
      "    n_blocks: [3, 24, 36, 3]\n",
      "    initial_channels: 16\n",
      "    block_type: bottleneck\n",
      "    alpha: 200\n",
      "  resnext:\n",
      "    depth: 29\n",
      "    n_blocks: [3, 4, 6, 3]\n",
      "    initial_channels: 64\n",
      "    cardinality: 8\n",
      "    base_channels: 4\n",
      "  shake_shake:\n",
      "    depth: 26\n",
      "    initial_channels: 96\n",
      "    shake_forward: True\n",
      "    shake_backward: True\n",
      "    shake_image: True\n",
      "  se_resnet_preact:\n",
      "    depth: 110\n",
      "    initial_channels: 16\n",
      "    se_reduction: 16\n",
      "    block_type: basic\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "train:\n",
      "  checkpoint: /home/ec2-user/SageMaker/experiments/resnet_basic_32_cm_1_1/exp00/checkpoint_00400.pth\n",
      "  resume: False\n",
      "  precision: O0\n",
      "  batch_size: 128\n",
      "  subdivision: 1\n",
      "  optimizer: sgd\n",
      "  base_lr: 0.001\n",
      "  momentum: 0.9\n",
      "  nesterov: True\n",
      "  weight_decay: 0.0001\n",
      "  no_weight_decay_on_bn: False\n",
      "  gradient_clip: 0\n",
      "  start_epoch: 0\n",
      "  seed: 0\n",
      "  val_first: True\n",
      "  val_period: 1\n",
      "  val_ratio: 0.1\n",
      "  use_test_as_val: False\n",
      "  output_dir: /home/ec2-user/SageMaker/experiments/resnet_basic_32_cm_1_1/exp00_resume400_50\n",
      "  log_period: 100\n",
      "  checkpoint_period: 100\n",
      "  use_tensorboard: True\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: True\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "  distributed: False\n",
      "  dist:\n",
      "    backend: nccl\n",
      "    init_method: env://\n",
      "    world_size: -1\n",
      "    node_rank: -1\n",
      "    local_rank: 0\n",
      "    use_sync_bn: False\n",
      "tensorboard:\n",
      "  train_images: False\n",
      "  val_images: False\n",
      "  model_params: False\n",
      "optim:\n",
      "  adam:\n",
      "    betas: (0.9, 0.999)\n",
      "  lars:\n",
      "    eps: 1e-09\n",
      "    threshold: 0.01\n",
      "  adabound:\n",
      "    betas: (0.9, 0.999)\n",
      "    final_lr: 0.1\n",
      "    gamma: 0.001\n",
      "scheduler:\n",
      "  epochs: 50\n",
      "  warmup:\n",
      "    type: none\n",
      "    epochs: 0\n",
      "    start_factor: 0.001\n",
      "    exponent: 4\n",
      "  type: multistep\n",
      "  milestones: [80, 120]\n",
      "  lr_decay: 0.1\n",
      "  lr_min_factor: 0.001\n",
      "  T0: 10\n",
      "  T_mul: 1.0\n",
      "validation:\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: False\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "augmentation:\n",
      "  use_random_crop: True\n",
      "  use_random_horizontal_flip: True\n",
      "  use_cutout: False\n",
      "  use_random_erasing: False\n",
      "  use_dual_cutout: False\n",
      "  use_mixup: False\n",
      "  use_ricap: False\n",
      "  use_cutmix: False\n",
      "  use_label_smoothing: False\n",
      "  random_crop:\n",
      "    padding: 4\n",
      "    fill: 0\n",
      "    padding_mode: constant\n",
      "  random_horizontal_flip:\n",
      "    prob: 0.5\n",
      "  cutout:\n",
      "    prob: 1.0\n",
      "    mask_size: 16\n",
      "    cut_inside: False\n",
      "    mask_color: 0\n",
      "    dual_cutout_alpha: 0.1\n",
      "  random_erasing:\n",
      "    prob: 0.5\n",
      "    area_ratio_range: [0.02, 0.4]\n",
      "    min_aspect_ratio: 0.3\n",
      "    max_attempt: 20\n",
      "  mixup:\n",
      "    alpha: 1.0\n",
      "  ricap:\n",
      "    beta: 0.3\n",
      "  cutmix:\n",
      "    alpha: 1.0\n",
      "  label_smoothing:\n",
      "    epsilon: 0.1\n",
      "tta:\n",
      "  use_resize: False\n",
      "  use_center_crop: False\n",
      "  resize: 256\n",
      "test:\n",
      "  checkpoint: ''\n",
      "  output_dir: ''\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    pin_memory: False\n",
      "\u001b[32m[2020-07-10 13:39:42] __main__ INFO: \u001b[0menv_info:\n",
      "  pytorch_version: 1.4.0\n",
      "  cuda_version: 10.1\n",
      "  cudnn_version: 7603\n",
      "  num_gpus: 1\n",
      "  gpu_name: Tesla K80\n",
      "  gpu_capability: 3.7\n",
      "Files already downloaded and verified\n",
      "\u001b[32m[2020-07-10 13:39:45] __main__ INFO: \u001b[0mMACs  : 69.76M\n",
      "\u001b[32m[2020-07-10 13:39:45] __main__ INFO: \u001b[0m#params: 466.91K\n",
      "Selected optimization level O0:  Pure FP32 training.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n",
      "\u001b[32m[2020-07-10 13:39:45] __main__ INFO: \u001b[0mVal 0\n",
      "\u001b[32m[2020-07-10 13:39:47] __main__ INFO: \u001b[0mEpoch 0 loss 0.5501 acc@1 0.8698 acc@5 0.9796\n",
      "\u001b[32m[2020-07-10 13:39:47] __main__ INFO: \u001b[0mElapsed 1.42\n",
      "\u001b[32m[2020-07-10 13:39:47] __main__ INFO: \u001b[0mTrain 1 0\n",
      "\u001b[32m[2020-07-10 13:39:56] __main__ INFO: \u001b[0mEpoch 1 Step 100/351 lr 0.001000 loss 0.2423 (0.2862) acc@1 0.9297 (0.9212) acc@5 1.0000 (0.9962)\n",
      "\u001b[32m[2020-07-10 13:40:06] __main__ INFO: \u001b[0mEpoch 1 Step 200/351 lr 0.001000 loss 0.2956 (0.2553) acc@1 0.9219 (0.9270) acc@5 0.9922 (0.9969)\n",
      "\u001b[32m[2020-07-10 13:40:15] __main__ INFO: \u001b[0mEpoch 1 Step 300/351 lr 0.001000 loss 0.2155 (0.2415) acc@1 0.9453 (0.9284) acc@5 1.0000 (0.9972)\n",
      "\u001b[32m[2020-07-10 13:40:20] __main__ INFO: \u001b[0mEpoch 1 Step 351/351 lr 0.001000 loss 0.2429 (0.2372) acc@1 0.9062 (0.9290) acc@5 1.0000 (0.9972)\n",
      "\u001b[32m[2020-07-10 13:40:20] __main__ INFO: \u001b[0mElapsed 33.15\n",
      "\u001b[32m[2020-07-10 13:40:20] __main__ INFO: \u001b[0mVal 1\n",
      "\u001b[32m[2020-07-10 13:40:21] __main__ INFO: \u001b[0mEpoch 1 loss 0.3264 acc@1 0.9016 acc@5 0.9958\n",
      "\u001b[32m[2020-07-10 13:40:21] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-07-10 13:40:21] __main__ INFO: \u001b[0mTrain 2 351\n",
      "\u001b[32m[2020-07-10 13:40:30] __main__ INFO: \u001b[0mEpoch 2 Step 100/351 lr 0.001000 loss 0.2068 (0.2028) acc@1 0.9609 (0.9352) acc@5 0.9922 (0.9980)\n",
      "\u001b[32m[2020-07-10 13:40:40] __main__ INFO: \u001b[0mEpoch 2 Step 200/351 lr 0.001000 loss 0.2627 (0.2009) acc@1 0.9375 (0.9354) acc@5 0.9844 (0.9983)\n",
      "\u001b[32m[2020-07-10 13:40:49] __main__ INFO: \u001b[0mEpoch 2 Step 300/351 lr 0.001000 loss 0.2231 (0.1995) acc@1 0.9297 (0.9351) acc@5 1.0000 (0.9983)\n",
      "\u001b[32m[2020-07-10 13:40:54] __main__ INFO: \u001b[0mEpoch 2 Step 351/351 lr 0.001000 loss 0.1768 (0.1977) acc@1 0.9453 (0.9360) acc@5 1.0000 (0.9983)\n",
      "\u001b[32m[2020-07-10 13:40:54] __main__ INFO: \u001b[0mElapsed 33.22\n",
      "\u001b[32m[2020-07-10 13:40:54] __main__ INFO: \u001b[0mVal 2\n",
      "\u001b[32m[2020-07-10 13:40:55] __main__ INFO: \u001b[0mEpoch 2 loss 0.3108 acc@1 0.9064 acc@5 0.9970\n",
      "\u001b[32m[2020-07-10 13:40:55] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-07-10 13:40:55] __main__ INFO: \u001b[0mTrain 3 702\n",
      "\u001b[32m[2020-07-10 13:41:05] __main__ INFO: \u001b[0mEpoch 3 Step 100/351 lr 0.001000 loss 0.1866 (0.1746) acc@1 0.9297 (0.9418) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-07-10 13:41:14] __main__ INFO: \u001b[0mEpoch 3 Step 200/351 lr 0.001000 loss 0.1195 (0.1799) acc@1 0.9453 (0.9408) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-07-10 13:41:24] __main__ INFO: \u001b[0mEpoch 3 Step 300/351 lr 0.001000 loss 0.1551 (0.1825) acc@1 0.9375 (0.9399) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-07-10 13:41:29] __main__ INFO: \u001b[0mEpoch 3 Step 351/351 lr 0.001000 loss 0.1272 (0.1837) acc@1 0.9609 (0.9395) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-07-10 13:41:29] __main__ INFO: \u001b[0mElapsed 33.47\n",
      "\u001b[32m[2020-07-10 13:41:29] __main__ INFO: \u001b[0mVal 3\n",
      "\u001b[32m[2020-07-10 13:41:30] __main__ INFO: \u001b[0mEpoch 3 loss 0.3057 acc@1 0.9018 acc@5 0.9968\n",
      "\u001b[32m[2020-07-10 13:41:30] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 13:41:30] __main__ INFO: \u001b[0mTrain 4 1053\n",
      "\u001b[32m[2020-07-10 13:41:39] __main__ INFO: \u001b[0mEpoch 4 Step 100/351 lr 0.001000 loss 0.2115 (0.1729) acc@1 0.9219 (0.9431) acc@5 0.9922 (0.9984)\n",
      "\u001b[32m[2020-07-10 13:41:49] __main__ INFO: \u001b[0mEpoch 4 Step 200/351 lr 0.001000 loss 0.1954 (0.1721) acc@1 0.9453 (0.9434) acc@5 1.0000 (0.9985)\n",
      "\u001b[32m[2020-07-10 13:41:58] __main__ INFO: \u001b[0mEpoch 4 Step 300/351 lr 0.001000 loss 0.1433 (0.1773) acc@1 0.9531 (0.9416) acc@5 1.0000 (0.9985)\n",
      "\u001b[32m[2020-07-10 13:42:03] __main__ INFO: \u001b[0mEpoch 4 Step 351/351 lr 0.001000 loss 0.1715 (0.1779) acc@1 0.9531 (0.9413) acc@5 1.0000 (0.9986)\n",
      "\u001b[32m[2020-07-10 13:42:03] __main__ INFO: \u001b[0mElapsed 33.56\n",
      "\u001b[32m[2020-07-10 13:42:03] __main__ INFO: \u001b[0mVal 4\n",
      "\u001b[32m[2020-07-10 13:42:04] __main__ INFO: \u001b[0mEpoch 4 loss 0.3041 acc@1 0.9054 acc@5 0.9970\n",
      "\u001b[32m[2020-07-10 13:42:04] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 13:42:04] __main__ INFO: \u001b[0mTrain 5 1404\n",
      "\u001b[32m[2020-07-10 13:42:14] __main__ INFO: \u001b[0mEpoch 5 Step 100/351 lr 0.001000 loss 0.1997 (0.1723) acc@1 0.9453 (0.9425) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-07-10 13:42:24] __main__ INFO: \u001b[0mEpoch 5 Step 200/351 lr 0.001000 loss 0.2562 (0.1688) acc@1 0.9297 (0.9432) acc@5 1.0000 (0.9989)\n",
      "\u001b[32m[2020-07-10 13:42:33] __main__ INFO: \u001b[0mEpoch 5 Step 300/351 lr 0.001000 loss 0.1895 (0.1700) acc@1 0.9375 (0.9441) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-07-10 13:42:38] __main__ INFO: \u001b[0mEpoch 5 Step 351/351 lr 0.001000 loss 0.2039 (0.1688) acc@1 0.9219 (0.9443) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-07-10 13:42:38] __main__ INFO: \u001b[0mElapsed 33.68\n",
      "\u001b[32m[2020-07-10 13:42:38] __main__ INFO: \u001b[0mVal 5\n",
      "\u001b[32m[2020-07-10 13:42:39] __main__ INFO: \u001b[0mEpoch 5 loss 0.3030 acc@1 0.9084 acc@5 0.9974\n",
      "\u001b[32m[2020-07-10 13:42:39] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 13:42:39] __main__ INFO: \u001b[0mTrain 6 1755\n",
      "\u001b[32m[2020-07-10 13:42:49] __main__ INFO: \u001b[0mEpoch 6 Step 100/351 lr 0.001000 loss 0.1610 (0.1650) acc@1 0.9297 (0.9451) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-07-10 13:42:58] __main__ INFO: \u001b[0mEpoch 6 Step 200/351 lr 0.001000 loss 0.1819 (0.1618) acc@1 0.9453 (0.9459) acc@5 0.9922 (0.9991)\n",
      "\u001b[32m[2020-07-10 13:43:08] __main__ INFO: \u001b[0mEpoch 6 Step 300/351 lr 0.001000 loss 0.1200 (0.1644) acc@1 0.9531 (0.9445) acc@5 0.9922 (0.9990)\n",
      "\u001b[32m[2020-07-10 13:43:13] __main__ INFO: \u001b[0mEpoch 6 Step 351/351 lr 0.001000 loss 0.1370 (0.1650) acc@1 0.9688 (0.9441) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-07-10 13:43:13] __main__ INFO: \u001b[0mElapsed 33.78\n",
      "\u001b[32m[2020-07-10 13:43:13] __main__ INFO: \u001b[0mVal 6\n",
      "\u001b[32m[2020-07-10 13:43:14] __main__ INFO: \u001b[0mEpoch 6 loss 0.3051 acc@1 0.9076 acc@5 0.9970\n",
      "\u001b[32m[2020-07-10 13:43:14] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-07-10 13:43:14] __main__ INFO: \u001b[0mTrain 7 2106\n",
      "\u001b[32m[2020-07-10 13:43:24] __main__ INFO: \u001b[0mEpoch 7 Step 100/351 lr 0.001000 loss 0.0897 (0.1465) acc@1 0.9766 (0.9498) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-10 13:43:33] __main__ INFO: \u001b[0mEpoch 7 Step 200/351 lr 0.001000 loss 0.1600 (0.1512) acc@1 0.9219 (0.9489) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-07-10 13:43:43] __main__ INFO: \u001b[0mEpoch 7 Step 300/351 lr 0.001000 loss 0.1039 (0.1575) acc@1 0.9609 (0.9474) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-07-10 13:43:48] __main__ INFO: \u001b[0mEpoch 7 Step 351/351 lr 0.001000 loss 0.1359 (0.1590) acc@1 0.9531 (0.9469) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-07-10 13:43:48] __main__ INFO: \u001b[0mElapsed 33.71\n",
      "\u001b[32m[2020-07-10 13:43:48] __main__ INFO: \u001b[0mVal 7\n",
      "\u001b[32m[2020-07-10 13:43:49] __main__ INFO: \u001b[0mEpoch 7 loss 0.3023 acc@1 0.9094 acc@5 0.9968\n",
      "\u001b[32m[2020-07-10 13:43:49] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 13:43:49] __main__ INFO: \u001b[0mTrain 8 2457\n",
      "\u001b[32m[2020-07-10 13:43:59] __main__ INFO: \u001b[0mEpoch 8 Step 100/351 lr 0.001000 loss 0.0775 (0.1517) acc@1 0.9766 (0.9482) acc@5 1.0000 (0.9989)\n",
      "\u001b[32m[2020-07-10 13:44:08] __main__ INFO: \u001b[0mEpoch 8 Step 200/351 lr 0.001000 loss 0.1171 (0.1524) acc@1 0.9531 (0.9464) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-07-10 13:44:18] __main__ INFO: \u001b[0mEpoch 8 Step 300/351 lr 0.001000 loss 0.1102 (0.1534) acc@1 0.9609 (0.9471) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-07-10 13:44:23] __main__ INFO: \u001b[0mEpoch 8 Step 351/351 lr 0.001000 loss 0.1200 (0.1563) acc@1 0.9453 (0.9468) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-07-10 13:44:23] __main__ INFO: \u001b[0mElapsed 33.81\n",
      "\u001b[32m[2020-07-10 13:44:23] __main__ INFO: \u001b[0mVal 8\n",
      "\u001b[32m[2020-07-10 13:44:24] __main__ INFO: \u001b[0mEpoch 8 loss 0.2992 acc@1 0.9096 acc@5 0.9972\n",
      "\u001b[32m[2020-07-10 13:44:24] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 13:44:24] __main__ INFO: \u001b[0mTrain 9 2808\n",
      "\u001b[32m[2020-07-10 13:44:33] __main__ INFO: \u001b[0mEpoch 9 Step 100/351 lr 0.001000 loss 0.1764 (0.1442) acc@1 0.9453 (0.9505) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-10 13:44:43] __main__ INFO: \u001b[0mEpoch 9 Step 200/351 lr 0.001000 loss 0.1477 (0.1498) acc@1 0.9453 (0.9481) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-07-10 13:44:53] __main__ INFO: \u001b[0mEpoch 9 Step 300/351 lr 0.001000 loss 0.2224 (0.1519) acc@1 0.9375 (0.9475) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-07-10 13:44:57] __main__ INFO: \u001b[0mEpoch 9 Step 351/351 lr 0.001000 loss 0.1233 (0.1529) acc@1 0.9766 (0.9474) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-07-10 13:44:57] __main__ INFO: \u001b[0mElapsed 33.78\n",
      "\u001b[32m[2020-07-10 13:44:57] __main__ INFO: \u001b[0mVal 9\n",
      "\u001b[32m[2020-07-10 13:44:59] __main__ INFO: \u001b[0mEpoch 9 loss 0.3025 acc@1 0.9070 acc@5 0.9972\n",
      "\u001b[32m[2020-07-10 13:44:59] __main__ INFO: \u001b[0mElapsed 1.11\n",
      "\u001b[32m[2020-07-10 13:44:59] __main__ INFO: \u001b[0mTrain 10 3159\n",
      "\u001b[32m[2020-07-10 13:45:08] __main__ INFO: \u001b[0mEpoch 10 Step 100/351 lr 0.001000 loss 0.0545 (0.1290) acc@1 0.9766 (0.9556) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-07-10 13:45:18] __main__ INFO: \u001b[0mEpoch 10 Step 200/351 lr 0.001000 loss 0.0983 (0.1417) acc@1 0.9844 (0.9521) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-07-10 13:45:28] __main__ INFO: \u001b[0mEpoch 10 Step 300/351 lr 0.001000 loss 0.1208 (0.1453) acc@1 0.9375 (0.9506) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-07-10 13:45:33] __main__ INFO: \u001b[0mEpoch 10 Step 351/351 lr 0.001000 loss 0.1219 (0.1447) acc@1 0.9609 (0.9509) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-07-10 13:45:33] __main__ INFO: \u001b[0mElapsed 33.92\n",
      "\u001b[32m[2020-07-10 13:45:33] __main__ INFO: \u001b[0mVal 10\n",
      "\u001b[32m[2020-07-10 13:45:34] __main__ INFO: \u001b[0mEpoch 10 loss 0.3071 acc@1 0.9060 acc@5 0.9968\n",
      "\u001b[32m[2020-07-10 13:45:34] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 13:45:34] __main__ INFO: \u001b[0mTrain 11 3510\n",
      "\u001b[32m[2020-07-10 13:45:43] __main__ INFO: \u001b[0mEpoch 11 Step 100/351 lr 0.001000 loss 0.1158 (0.1462) acc@1 0.9766 (0.9516) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-07-10 13:45:53] __main__ INFO: \u001b[0mEpoch 11 Step 200/351 lr 0.001000 loss 0.0801 (0.1431) acc@1 0.9609 (0.9506) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-07-10 13:46:03] __main__ INFO: \u001b[0mEpoch 11 Step 300/351 lr 0.001000 loss 0.1018 (0.1432) acc@1 0.9609 (0.9502) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-07-10 13:46:07] __main__ INFO: \u001b[0mEpoch 11 Step 351/351 lr 0.001000 loss 0.2054 (0.1444) acc@1 0.9219 (0.9500) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-07-10 13:46:07] __main__ INFO: \u001b[0mElapsed 33.87\n",
      "\u001b[32m[2020-07-10 13:46:07] __main__ INFO: \u001b[0mVal 11\n",
      "\u001b[32m[2020-07-10 13:46:09] __main__ INFO: \u001b[0mEpoch 11 loss 0.3079 acc@1 0.9064 acc@5 0.9968\n",
      "\u001b[32m[2020-07-10 13:46:09] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 13:46:09] __main__ INFO: \u001b[0mTrain 12 3861\n",
      "\u001b[32m[2020-07-10 13:46:18] __main__ INFO: \u001b[0mEpoch 12 Step 100/351 lr 0.001000 loss 0.1550 (0.1409) acc@1 0.9609 (0.9516) acc@5 0.9922 (0.9993)\n",
      "\u001b[32m[2020-07-10 13:46:28] __main__ INFO: \u001b[0mEpoch 12 Step 200/351 lr 0.001000 loss 0.1537 (0.1393) acc@1 0.9531 (0.9518) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-07-10 13:46:37] __main__ INFO: \u001b[0mEpoch 12 Step 300/351 lr 0.001000 loss 0.0903 (0.1390) acc@1 0.9766 (0.9520) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-10 13:46:42] __main__ INFO: \u001b[0mEpoch 12 Step 351/351 lr 0.001000 loss 0.2631 (0.1393) acc@1 0.9297 (0.9522) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-07-10 13:46:42] __main__ INFO: \u001b[0mElapsed 33.76\n",
      "\u001b[32m[2020-07-10 13:46:42] __main__ INFO: \u001b[0mVal 12\n",
      "\u001b[32m[2020-07-10 13:46:43] __main__ INFO: \u001b[0mEpoch 12 loss 0.3069 acc@1 0.9096 acc@5 0.9964\n",
      "\u001b[32m[2020-07-10 13:46:43] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 13:46:43] __main__ INFO: \u001b[0mTrain 13 4212\n",
      "\u001b[32m[2020-07-10 13:46:53] __main__ INFO: \u001b[0mEpoch 13 Step 100/351 lr 0.001000 loss 0.1697 (0.1282) acc@1 0.9453 (0.9545) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-10 13:47:03] __main__ INFO: \u001b[0mEpoch 13 Step 200/351 lr 0.001000 loss 0.0569 (0.1298) acc@1 0.9844 (0.9541) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-10 13:47:12] __main__ INFO: \u001b[0mEpoch 13 Step 300/351 lr 0.001000 loss 0.0795 (0.1330) acc@1 0.9766 (0.9534) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-10 13:47:17] __main__ INFO: \u001b[0mEpoch 13 Step 351/351 lr 0.001000 loss 0.0968 (0.1347) acc@1 0.9609 (0.9530) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-10 13:47:17] __main__ INFO: \u001b[0mElapsed 33.77\n",
      "\u001b[32m[2020-07-10 13:47:17] __main__ INFO: \u001b[0mVal 13\n",
      "\u001b[32m[2020-07-10 13:47:18] __main__ INFO: \u001b[0mEpoch 13 loss 0.3068 acc@1 0.9088 acc@5 0.9960\n",
      "\u001b[32m[2020-07-10 13:47:18] __main__ INFO: \u001b[0mElapsed 1.12\n",
      "\u001b[32m[2020-07-10 13:47:18] __main__ INFO: \u001b[0mTrain 14 4563\n",
      "\u001b[32m[2020-07-10 13:47:28] __main__ INFO: \u001b[0mEpoch 14 Step 100/351 lr 0.001000 loss 0.1165 (0.1324) acc@1 0.9688 (0.9554) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-10 13:47:38] __main__ INFO: \u001b[0mEpoch 14 Step 200/351 lr 0.001000 loss 0.1093 (0.1328) acc@1 0.9453 (0.9552) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-07-10 13:47:47] __main__ INFO: \u001b[0mEpoch 14 Step 300/351 lr 0.001000 loss 0.1362 (0.1349) acc@1 0.9531 (0.9546) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-07-10 13:47:52] __main__ INFO: \u001b[0mEpoch 14 Step 351/351 lr 0.001000 loss 0.1745 (0.1339) acc@1 0.9453 (0.9547) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-07-10 13:47:52] __main__ INFO: \u001b[0mElapsed 33.69\n",
      "\u001b[32m[2020-07-10 13:47:52] __main__ INFO: \u001b[0mVal 14\n",
      "\u001b[32m[2020-07-10 13:47:53] __main__ INFO: \u001b[0mEpoch 14 loss 0.3121 acc@1 0.9068 acc@5 0.9960\n",
      "\u001b[32m[2020-07-10 13:47:53] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 13:47:53] __main__ INFO: \u001b[0mTrain 15 4914\n",
      "\u001b[32m[2020-07-10 13:48:03] __main__ INFO: \u001b[0mEpoch 15 Step 100/351 lr 0.001000 loss 0.1584 (0.1354) acc@1 0.9219 (0.9544) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-07-10 13:48:12] __main__ INFO: \u001b[0mEpoch 15 Step 200/351 lr 0.001000 loss 0.0724 (0.1297) acc@1 0.9766 (0.9567) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-07-10 13:48:22] __main__ INFO: \u001b[0mEpoch 15 Step 300/351 lr 0.001000 loss 0.0757 (0.1302) acc@1 0.9766 (0.9564) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-07-10 13:48:27] __main__ INFO: \u001b[0mEpoch 15 Step 351/351 lr 0.001000 loss 0.1667 (0.1307) acc@1 0.9297 (0.9561) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-07-10 13:48:27] __main__ INFO: \u001b[0mElapsed 33.73\n",
      "\u001b[32m[2020-07-10 13:48:27] __main__ INFO: \u001b[0mVal 15\n",
      "\u001b[32m[2020-07-10 13:48:28] __main__ INFO: \u001b[0mEpoch 15 loss 0.3228 acc@1 0.9066 acc@5 0.9960\n",
      "\u001b[32m[2020-07-10 13:48:28] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 13:48:28] __main__ INFO: \u001b[0mTrain 16 5265\n",
      "\u001b[32m[2020-07-10 13:48:38] __main__ INFO: \u001b[0mEpoch 16 Step 100/351 lr 0.001000 loss 0.1312 (0.1299) acc@1 0.9688 (0.9546) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-07-10 13:48:47] __main__ INFO: \u001b[0mEpoch 16 Step 200/351 lr 0.001000 loss 0.1181 (0.1286) acc@1 0.9453 (0.9561) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-07-10 13:48:57] __main__ INFO: \u001b[0mEpoch 16 Step 300/351 lr 0.001000 loss 0.1258 (0.1280) acc@1 0.9453 (0.9566) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-10 13:49:02] __main__ INFO: \u001b[0mEpoch 16 Step 351/351 lr 0.001000 loss 0.0812 (0.1299) acc@1 0.9766 (0.9561) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-07-10 13:49:02] __main__ INFO: \u001b[0mElapsed 33.73\n",
      "\u001b[32m[2020-07-10 13:49:02] __main__ INFO: \u001b[0mVal 16\n",
      "\u001b[32m[2020-07-10 13:49:03] __main__ INFO: \u001b[0mEpoch 16 loss 0.3152 acc@1 0.9100 acc@5 0.9960\n",
      "\u001b[32m[2020-07-10 13:49:03] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 13:49:03] __main__ INFO: \u001b[0mTrain 17 5616\n",
      "\u001b[32m[2020-07-10 13:49:12] __main__ INFO: \u001b[0mEpoch 17 Step 100/351 lr 0.001000 loss 0.0759 (0.1213) acc@1 0.9844 (0.9574) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-10 13:49:22] __main__ INFO: \u001b[0mEpoch 17 Step 200/351 lr 0.001000 loss 0.2448 (0.1222) acc@1 0.9453 (0.9578) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-10 13:49:32] __main__ INFO: \u001b[0mEpoch 17 Step 300/351 lr 0.001000 loss 0.1062 (0.1245) acc@1 0.9531 (0.9570) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-07-10 13:49:36] __main__ INFO: \u001b[0mEpoch 17 Step 351/351 lr 0.001000 loss 0.0505 (0.1256) acc@1 0.9766 (0.9566) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-10 13:49:36] __main__ INFO: \u001b[0mElapsed 33.66\n",
      "\u001b[32m[2020-07-10 13:49:36] __main__ INFO: \u001b[0mVal 17\n",
      "\u001b[32m[2020-07-10 13:49:37] __main__ INFO: \u001b[0mEpoch 17 loss 0.3227 acc@1 0.9070 acc@5 0.9960\n",
      "\u001b[32m[2020-07-10 13:49:37] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-07-10 13:49:37] __main__ INFO: \u001b[0mTrain 18 5967\n",
      "\u001b[32m[2020-07-10 13:49:47] __main__ INFO: \u001b[0mEpoch 18 Step 100/351 lr 0.001000 loss 0.2364 (0.1262) acc@1 0.9062 (0.9547) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-10 13:49:57] __main__ INFO: \u001b[0mEpoch 18 Step 200/351 lr 0.001000 loss 0.1001 (0.1231) acc@1 0.9531 (0.9566) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-10 13:50:06] __main__ INFO: \u001b[0mEpoch 18 Step 300/351 lr 0.001000 loss 0.1086 (0.1232) acc@1 0.9766 (0.9569) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-10 13:50:11] __main__ INFO: \u001b[0mEpoch 18 Step 351/351 lr 0.001000 loss 0.0757 (0.1232) acc@1 0.9766 (0.9571) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-10 13:50:11] __main__ INFO: \u001b[0mElapsed 33.70\n",
      "\u001b[32m[2020-07-10 13:50:11] __main__ INFO: \u001b[0mVal 18\n",
      "\u001b[32m[2020-07-10 13:50:12] __main__ INFO: \u001b[0mEpoch 18 loss 0.3152 acc@1 0.9080 acc@5 0.9970\n",
      "\u001b[32m[2020-07-10 13:50:12] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 13:50:12] __main__ INFO: \u001b[0mTrain 19 6318\n",
      "\u001b[32m[2020-07-10 13:50:22] __main__ INFO: \u001b[0mEpoch 19 Step 100/351 lr 0.001000 loss 0.0767 (0.1231) acc@1 0.9766 (0.9587) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-10 13:50:32] __main__ INFO: \u001b[0mEpoch 19 Step 200/351 lr 0.001000 loss 0.1892 (0.1226) acc@1 0.9297 (0.9582) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-10 13:50:41] __main__ INFO: \u001b[0mEpoch 19 Step 300/351 lr 0.001000 loss 0.2645 (0.1239) acc@1 0.9062 (0.9578) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-10 13:50:46] __main__ INFO: \u001b[0mEpoch 19 Step 351/351 lr 0.001000 loss 0.1083 (0.1240) acc@1 0.9609 (0.9576) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-10 13:50:46] __main__ INFO: \u001b[0mElapsed 33.71\n",
      "\u001b[32m[2020-07-10 13:50:46] __main__ INFO: \u001b[0mVal 19\n",
      "\u001b[32m[2020-07-10 13:50:47] __main__ INFO: \u001b[0mEpoch 19 loss 0.3178 acc@1 0.9090 acc@5 0.9970\n",
      "\u001b[32m[2020-07-10 13:50:47] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 13:50:47] __main__ INFO: \u001b[0mTrain 20 6669\n",
      "\u001b[32m[2020-07-10 13:50:57] __main__ INFO: \u001b[0mEpoch 20 Step 100/351 lr 0.001000 loss 0.0922 (0.1134) acc@1 0.9688 (0.9620) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 13:51:06] __main__ INFO: \u001b[0mEpoch 20 Step 200/351 lr 0.001000 loss 0.0961 (0.1127) acc@1 0.9688 (0.9620) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-10 13:51:16] __main__ INFO: \u001b[0mEpoch 20 Step 300/351 lr 0.001000 loss 0.1039 (0.1144) acc@1 0.9531 (0.9612) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-10 13:51:21] __main__ INFO: \u001b[0mEpoch 20 Step 351/351 lr 0.001000 loss 0.0999 (0.1163) acc@1 0.9688 (0.9604) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-10 13:51:21] __main__ INFO: \u001b[0mElapsed 33.73\n",
      "\u001b[32m[2020-07-10 13:51:21] __main__ INFO: \u001b[0mVal 20\n",
      "\u001b[32m[2020-07-10 13:51:22] __main__ INFO: \u001b[0mEpoch 20 loss 0.3189 acc@1 0.9092 acc@5 0.9964\n",
      "\u001b[32m[2020-07-10 13:51:22] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 13:51:22] __main__ INFO: \u001b[0mTrain 21 7020\n",
      "\u001b[32m[2020-07-10 13:51:32] __main__ INFO: \u001b[0mEpoch 21 Step 100/351 lr 0.001000 loss 0.1866 (0.1142) acc@1 0.9375 (0.9613) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-07-10 13:51:41] __main__ INFO: \u001b[0mEpoch 21 Step 200/351 lr 0.001000 loss 0.1598 (0.1106) acc@1 0.9375 (0.9628) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-10 13:51:51] __main__ INFO: \u001b[0mEpoch 21 Step 300/351 lr 0.001000 loss 0.2139 (0.1144) acc@1 0.9219 (0.9619) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-10 13:51:56] __main__ INFO: \u001b[0mEpoch 21 Step 351/351 lr 0.001000 loss 0.1040 (0.1146) acc@1 0.9531 (0.9615) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-10 13:51:56] __main__ INFO: \u001b[0mElapsed 33.68\n",
      "\u001b[32m[2020-07-10 13:51:56] __main__ INFO: \u001b[0mVal 21\n",
      "\u001b[32m[2020-07-10 13:51:57] __main__ INFO: \u001b[0mEpoch 21 loss 0.3177 acc@1 0.9090 acc@5 0.9968\n",
      "\u001b[32m[2020-07-10 13:51:57] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 13:51:57] __main__ INFO: \u001b[0mTrain 22 7371\n",
      "\u001b[32m[2020-07-10 13:52:06] __main__ INFO: \u001b[0mEpoch 22 Step 100/351 lr 0.001000 loss 0.0972 (0.1135) acc@1 0.9531 (0.9614) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-10 13:52:16] __main__ INFO: \u001b[0mEpoch 22 Step 200/351 lr 0.001000 loss 0.1649 (0.1142) acc@1 0.9531 (0.9611) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-10 13:52:26] __main__ INFO: \u001b[0mEpoch 22 Step 300/351 lr 0.001000 loss 0.1456 (0.1140) acc@1 0.9531 (0.9614) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-10 13:52:30] __main__ INFO: \u001b[0mEpoch 22 Step 351/351 lr 0.001000 loss 0.1139 (0.1122) acc@1 0.9844 (0.9624) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-10 13:52:30] __main__ INFO: \u001b[0mElapsed 33.75\n",
      "\u001b[32m[2020-07-10 13:52:30] __main__ INFO: \u001b[0mVal 22\n",
      "\u001b[32m[2020-07-10 13:52:31] __main__ INFO: \u001b[0mEpoch 22 loss 0.3209 acc@1 0.9094 acc@5 0.9966\n",
      "\u001b[32m[2020-07-10 13:52:32] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 13:52:32] __main__ INFO: \u001b[0mTrain 23 7722\n",
      "\u001b[32m[2020-07-10 13:52:41] __main__ INFO: \u001b[0mEpoch 23 Step 100/351 lr 0.001000 loss 0.1000 (0.1091) acc@1 0.9688 (0.9613) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-10 13:52:51] __main__ INFO: \u001b[0mEpoch 23 Step 200/351 lr 0.001000 loss 0.1743 (0.1125) acc@1 0.9219 (0.9615) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-10 13:53:00] __main__ INFO: \u001b[0mEpoch 23 Step 300/351 lr 0.001000 loss 0.1160 (0.1112) acc@1 0.9609 (0.9619) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-10 13:53:05] __main__ INFO: \u001b[0mEpoch 23 Step 351/351 lr 0.001000 loss 0.1803 (0.1120) acc@1 0.9453 (0.9615) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-10 13:53:05] __main__ INFO: \u001b[0mElapsed 33.71\n",
      "\u001b[32m[2020-07-10 13:53:05] __main__ INFO: \u001b[0mVal 23\n",
      "\u001b[32m[2020-07-10 13:53:06] __main__ INFO: \u001b[0mEpoch 23 loss 0.3219 acc@1 0.9052 acc@5 0.9964\n",
      "\u001b[32m[2020-07-10 13:53:06] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 13:53:06] __main__ INFO: \u001b[0mTrain 24 8073\n",
      "\u001b[32m[2020-07-10 13:53:16] __main__ INFO: \u001b[0mEpoch 24 Step 100/351 lr 0.001000 loss 0.0486 (0.1123) acc@1 0.9844 (0.9635) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-10 13:53:25] __main__ INFO: \u001b[0mEpoch 24 Step 200/351 lr 0.001000 loss 0.1045 (0.1088) acc@1 0.9688 (0.9639) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-10 13:53:35] __main__ INFO: \u001b[0mEpoch 24 Step 300/351 lr 0.001000 loss 0.0880 (0.1093) acc@1 0.9609 (0.9633) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-10 13:53:40] __main__ INFO: \u001b[0mEpoch 24 Step 351/351 lr 0.001000 loss 0.0553 (0.1089) acc@1 0.9844 (0.9633) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-10 13:53:40] __main__ INFO: \u001b[0mElapsed 33.63\n",
      "\u001b[32m[2020-07-10 13:53:40] __main__ INFO: \u001b[0mVal 24\n",
      "\u001b[32m[2020-07-10 13:53:41] __main__ INFO: \u001b[0mEpoch 24 loss 0.3259 acc@1 0.9080 acc@5 0.9958\n",
      "\u001b[32m[2020-07-10 13:53:41] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 13:53:41] __main__ INFO: \u001b[0mTrain 25 8424\n",
      "\u001b[32m[2020-07-10 13:53:51] __main__ INFO: \u001b[0mEpoch 25 Step 100/351 lr 0.001000 loss 0.0799 (0.1031) acc@1 0.9688 (0.9652) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-10 13:54:00] __main__ INFO: \u001b[0mEpoch 25 Step 200/351 lr 0.001000 loss 0.1593 (0.1050) acc@1 0.9375 (0.9642) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-10 13:54:10] __main__ INFO: \u001b[0mEpoch 25 Step 300/351 lr 0.001000 loss 0.0812 (0.1065) acc@1 0.9688 (0.9635) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 13:54:15] __main__ INFO: \u001b[0mEpoch 25 Step 351/351 lr 0.001000 loss 0.0642 (0.1067) acc@1 0.9844 (0.9637) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 13:54:15] __main__ INFO: \u001b[0mElapsed 33.74\n",
      "\u001b[32m[2020-07-10 13:54:15] __main__ INFO: \u001b[0mVal 25\n",
      "\u001b[32m[2020-07-10 13:54:16] __main__ INFO: \u001b[0mEpoch 25 loss 0.3380 acc@1 0.9078 acc@5 0.9964\n",
      "\u001b[32m[2020-07-10 13:54:16] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 13:54:16] __main__ INFO: \u001b[0mTrain 26 8775\n",
      "\u001b[32m[2020-07-10 13:54:26] __main__ INFO: \u001b[0mEpoch 26 Step 100/351 lr 0.001000 loss 0.0825 (0.1026) acc@1 0.9766 (0.9635) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-10 13:54:35] __main__ INFO: \u001b[0mEpoch 26 Step 200/351 lr 0.001000 loss 0.1293 (0.1054) acc@1 0.9609 (0.9627) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 13:54:45] __main__ INFO: \u001b[0mEpoch 26 Step 300/351 lr 0.001000 loss 0.1689 (0.1064) acc@1 0.9531 (0.9624) acc@5 0.9922 (0.9998)\n",
      "\u001b[32m[2020-07-10 13:54:50] __main__ INFO: \u001b[0mEpoch 26 Step 351/351 lr 0.001000 loss 0.1295 (0.1068) acc@1 0.9531 (0.9625) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 13:54:50] __main__ INFO: \u001b[0mElapsed 33.75\n",
      "\u001b[32m[2020-07-10 13:54:50] __main__ INFO: \u001b[0mVal 26\n",
      "\u001b[32m[2020-07-10 13:54:51] __main__ INFO: \u001b[0mEpoch 26 loss 0.3396 acc@1 0.9052 acc@5 0.9964\n",
      "\u001b[32m[2020-07-10 13:54:51] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 13:54:51] __main__ INFO: \u001b[0mTrain 27 9126\n",
      "\u001b[32m[2020-07-10 13:55:00] __main__ INFO: \u001b[0mEpoch 27 Step 100/351 lr 0.001000 loss 0.0311 (0.0958) acc@1 1.0000 (0.9680) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 13:55:10] __main__ INFO: \u001b[0mEpoch 27 Step 200/351 lr 0.001000 loss 0.0527 (0.1007) acc@1 0.9766 (0.9661) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-10 13:55:19] __main__ INFO: \u001b[0mEpoch 27 Step 300/351 lr 0.001000 loss 0.1250 (0.1043) acc@1 0.9375 (0.9645) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-10 13:55:24] __main__ INFO: \u001b[0mEpoch 27 Step 351/351 lr 0.001000 loss 0.1527 (0.1050) acc@1 0.9375 (0.9644) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-10 13:55:24] __main__ INFO: \u001b[0mElapsed 33.70\n",
      "\u001b[32m[2020-07-10 13:55:24] __main__ INFO: \u001b[0mVal 27\n",
      "\u001b[32m[2020-07-10 13:55:25] __main__ INFO: \u001b[0mEpoch 27 loss 0.3352 acc@1 0.9050 acc@5 0.9958\n",
      "\u001b[32m[2020-07-10 13:55:25] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 13:55:25] __main__ INFO: \u001b[0mTrain 28 9477\n",
      "\u001b[32m[2020-07-10 13:55:35] __main__ INFO: \u001b[0mEpoch 28 Step 100/351 lr 0.001000 loss 0.0623 (0.0949) acc@1 0.9922 (0.9680) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-10 13:55:45] __main__ INFO: \u001b[0mEpoch 28 Step 200/351 lr 0.001000 loss 0.1333 (0.0943) acc@1 0.9453 (0.9670) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 13:55:54] __main__ INFO: \u001b[0mEpoch 28 Step 300/351 lr 0.001000 loss 0.0341 (0.0980) acc@1 0.9922 (0.9659) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 13:55:59] __main__ INFO: \u001b[0mEpoch 28 Step 351/351 lr 0.001000 loss 0.0621 (0.1000) acc@1 0.9766 (0.9654) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 13:55:59] __main__ INFO: \u001b[0mElapsed 33.69\n",
      "\u001b[32m[2020-07-10 13:55:59] __main__ INFO: \u001b[0mVal 28\n",
      "\u001b[32m[2020-07-10 13:56:00] __main__ INFO: \u001b[0mEpoch 28 loss 0.3376 acc@1 0.9036 acc@5 0.9968\n",
      "\u001b[32m[2020-07-10 13:56:00] __main__ INFO: \u001b[0mElapsed 1.11\n",
      "\u001b[32m[2020-07-10 13:56:00] __main__ INFO: \u001b[0mTrain 29 9828\n",
      "\u001b[32m[2020-07-10 13:56:10] __main__ INFO: \u001b[0mEpoch 29 Step 100/351 lr 0.001000 loss 0.0883 (0.0964) acc@1 0.9766 (0.9681) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-10 13:56:19] __main__ INFO: \u001b[0mEpoch 29 Step 200/351 lr 0.001000 loss 0.1060 (0.0965) acc@1 0.9531 (0.9673) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-10 13:56:29] __main__ INFO: \u001b[0mEpoch 29 Step 300/351 lr 0.001000 loss 0.0788 (0.0960) acc@1 0.9766 (0.9671) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-10 13:56:34] __main__ INFO: \u001b[0mEpoch 29 Step 351/351 lr 0.001000 loss 0.0875 (0.0974) acc@1 0.9609 (0.9666) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-10 13:56:34] __main__ INFO: \u001b[0mElapsed 33.67\n",
      "\u001b[32m[2020-07-10 13:56:34] __main__ INFO: \u001b[0mVal 29\n",
      "\u001b[32m[2020-07-10 13:56:35] __main__ INFO: \u001b[0mEpoch 29 loss 0.3377 acc@1 0.9062 acc@5 0.9960\n",
      "\u001b[32m[2020-07-10 13:56:35] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 13:56:35] __main__ INFO: \u001b[0mTrain 30 10179\n",
      "\u001b[32m[2020-07-10 13:56:45] __main__ INFO: \u001b[0mEpoch 30 Step 100/351 lr 0.001000 loss 0.0948 (0.0969) acc@1 0.9688 (0.9660) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 13:56:54] __main__ INFO: \u001b[0mEpoch 30 Step 200/351 lr 0.001000 loss 0.0548 (0.0988) acc@1 0.9766 (0.9657) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 13:57:04] __main__ INFO: \u001b[0mEpoch 30 Step 300/351 lr 0.001000 loss 0.0757 (0.0990) acc@1 0.9609 (0.9656) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 13:57:09] __main__ INFO: \u001b[0mEpoch 30 Step 351/351 lr 0.001000 loss 0.1422 (0.0980) acc@1 0.9297 (0.9661) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 13:57:09] __main__ INFO: \u001b[0mElapsed 33.68\n",
      "\u001b[32m[2020-07-10 13:57:09] __main__ INFO: \u001b[0mVal 30\n",
      "\u001b[32m[2020-07-10 13:57:10] __main__ INFO: \u001b[0mEpoch 30 loss 0.3408 acc@1 0.9080 acc@5 0.9966\n",
      "\u001b[32m[2020-07-10 13:57:10] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 13:57:10] __main__ INFO: \u001b[0mTrain 31 10530\n",
      "\u001b[32m[2020-07-10 13:57:20] __main__ INFO: \u001b[0mEpoch 31 Step 100/351 lr 0.001000 loss 0.1029 (0.0961) acc@1 0.9609 (0.9663) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 13:57:29] __main__ INFO: \u001b[0mEpoch 31 Step 200/351 lr 0.001000 loss 0.0791 (0.0958) acc@1 0.9688 (0.9665) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-10 13:57:39] __main__ INFO: \u001b[0mEpoch 31 Step 300/351 lr 0.001000 loss 0.0550 (0.0939) acc@1 0.9844 (0.9671) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 13:57:43] __main__ INFO: \u001b[0mEpoch 31 Step 351/351 lr 0.001000 loss 0.0800 (0.0950) acc@1 0.9688 (0.9668) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 13:57:44] __main__ INFO: \u001b[0mElapsed 33.72\n",
      "\u001b[32m[2020-07-10 13:57:44] __main__ INFO: \u001b[0mVal 31\n",
      "\u001b[32m[2020-07-10 13:57:45] __main__ INFO: \u001b[0mEpoch 31 loss 0.3374 acc@1 0.9076 acc@5 0.9964\n",
      "\u001b[32m[2020-07-10 13:57:45] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 13:57:45] __main__ INFO: \u001b[0mTrain 32 10881\n",
      "\u001b[32m[2020-07-10 13:57:54] __main__ INFO: \u001b[0mEpoch 32 Step 100/351 lr 0.001000 loss 0.0879 (0.0928) acc@1 0.9766 (0.9674) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 13:58:04] __main__ INFO: \u001b[0mEpoch 32 Step 200/351 lr 0.001000 loss 0.1093 (0.0936) acc@1 0.9531 (0.9685) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 13:58:13] __main__ INFO: \u001b[0mEpoch 32 Step 300/351 lr 0.001000 loss 0.0604 (0.0932) acc@1 0.9766 (0.9685) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 13:58:18] __main__ INFO: \u001b[0mEpoch 32 Step 351/351 lr 0.001000 loss 0.0447 (0.0931) acc@1 0.9766 (0.9686) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 13:58:18] __main__ INFO: \u001b[0mElapsed 33.63\n",
      "\u001b[32m[2020-07-10 13:58:18] __main__ INFO: \u001b[0mVal 32\n",
      "\u001b[32m[2020-07-10 13:58:19] __main__ INFO: \u001b[0mEpoch 32 loss 0.3371 acc@1 0.9072 acc@5 0.9968\n",
      "\u001b[32m[2020-07-10 13:58:19] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 13:58:19] __main__ INFO: \u001b[0mTrain 33 11232\n",
      "\u001b[32m[2020-07-10 13:58:29] __main__ INFO: \u001b[0mEpoch 33 Step 100/351 lr 0.001000 loss 0.0640 (0.0972) acc@1 0.9766 (0.9665) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 13:58:39] __main__ INFO: \u001b[0mEpoch 33 Step 200/351 lr 0.001000 loss 0.0704 (0.0950) acc@1 0.9766 (0.9680) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-10 13:58:48] __main__ INFO: \u001b[0mEpoch 33 Step 300/351 lr 0.001000 loss 0.1778 (0.0958) acc@1 0.9062 (0.9673) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 13:58:53] __main__ INFO: \u001b[0mEpoch 33 Step 351/351 lr 0.001000 loss 0.0656 (0.0950) acc@1 0.9844 (0.9673) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-10 13:58:53] __main__ INFO: \u001b[0mElapsed 33.79\n",
      "\u001b[32m[2020-07-10 13:58:53] __main__ INFO: \u001b[0mVal 33\n",
      "\u001b[32m[2020-07-10 13:58:54] __main__ INFO: \u001b[0mEpoch 33 loss 0.3410 acc@1 0.9080 acc@5 0.9968\n",
      "\u001b[32m[2020-07-10 13:58:54] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 13:58:54] __main__ INFO: \u001b[0mTrain 34 11583\n",
      "\u001b[32m[2020-07-10 13:59:04] __main__ INFO: \u001b[0mEpoch 34 Step 100/351 lr 0.001000 loss 0.0554 (0.0914) acc@1 0.9766 (0.9688) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-10 13:59:14] __main__ INFO: \u001b[0mEpoch 34 Step 200/351 lr 0.001000 loss 0.1264 (0.0910) acc@1 0.9531 (0.9693) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 13:59:23] __main__ INFO: \u001b[0mEpoch 34 Step 300/351 lr 0.001000 loss 0.0851 (0.0894) acc@1 0.9531 (0.9699) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-10 13:59:28] __main__ INFO: \u001b[0mEpoch 34 Step 351/351 lr 0.001000 loss 0.0623 (0.0889) acc@1 0.9922 (0.9701) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-10 13:59:28] __main__ INFO: \u001b[0mElapsed 33.80\n",
      "\u001b[32m[2020-07-10 13:59:28] __main__ INFO: \u001b[0mVal 34\n",
      "\u001b[32m[2020-07-10 13:59:29] __main__ INFO: \u001b[0mEpoch 34 loss 0.3439 acc@1 0.9096 acc@5 0.9968\n",
      "\u001b[32m[2020-07-10 13:59:29] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 13:59:29] __main__ INFO: \u001b[0mTrain 35 11934\n",
      "\u001b[32m[2020-07-10 13:59:39] __main__ INFO: \u001b[0mEpoch 35 Step 100/351 lr 0.001000 loss 0.0902 (0.0910) acc@1 0.9609 (0.9677) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 13:59:48] __main__ INFO: \u001b[0mEpoch 35 Step 200/351 lr 0.001000 loss 0.0736 (0.0898) acc@1 0.9844 (0.9688) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 13:59:58] __main__ INFO: \u001b[0mEpoch 35 Step 300/351 lr 0.001000 loss 0.0452 (0.0897) acc@1 0.9922 (0.9692) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 14:00:03] __main__ INFO: \u001b[0mEpoch 35 Step 351/351 lr 0.001000 loss 0.0958 (0.0894) acc@1 0.9453 (0.9691) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 14:00:03] __main__ INFO: \u001b[0mElapsed 33.88\n",
      "\u001b[32m[2020-07-10 14:00:03] __main__ INFO: \u001b[0mVal 35\n",
      "\u001b[32m[2020-07-10 14:00:04] __main__ INFO: \u001b[0mEpoch 35 loss 0.3452 acc@1 0.9090 acc@5 0.9960\n",
      "\u001b[32m[2020-07-10 14:00:04] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 14:00:04] __main__ INFO: \u001b[0mTrain 36 12285\n",
      "\u001b[32m[2020-07-10 14:00:14] __main__ INFO: \u001b[0mEpoch 36 Step 100/351 lr 0.001000 loss 0.0762 (0.0842) acc@1 0.9766 (0.9719) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-10 14:00:23] __main__ INFO: \u001b[0mEpoch 36 Step 200/351 lr 0.001000 loss 0.0822 (0.0850) acc@1 0.9766 (0.9715) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-10 14:00:33] __main__ INFO: \u001b[0mEpoch 36 Step 300/351 lr 0.001000 loss 0.0499 (0.0844) acc@1 0.9922 (0.9714) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-10 14:00:38] __main__ INFO: \u001b[0mEpoch 36 Step 351/351 lr 0.001000 loss 0.0766 (0.0846) acc@1 0.9688 (0.9711) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 14:00:38] __main__ INFO: \u001b[0mElapsed 33.77\n",
      "\u001b[32m[2020-07-10 14:00:38] __main__ INFO: \u001b[0mVal 36\n",
      "\u001b[32m[2020-07-10 14:00:39] __main__ INFO: \u001b[0mEpoch 36 loss 0.3504 acc@1 0.9078 acc@5 0.9956\n",
      "\u001b[32m[2020-07-10 14:00:39] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 14:00:39] __main__ INFO: \u001b[0mTrain 37 12636\n",
      "\u001b[32m[2020-07-10 14:00:49] __main__ INFO: \u001b[0mEpoch 37 Step 100/351 lr 0.001000 loss 0.1013 (0.0830) acc@1 0.9531 (0.9710) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 14:00:58] __main__ INFO: \u001b[0mEpoch 37 Step 200/351 lr 0.001000 loss 0.1076 (0.0855) acc@1 0.9609 (0.9704) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 14:01:08] __main__ INFO: \u001b[0mEpoch 37 Step 300/351 lr 0.001000 loss 0.0437 (0.0867) acc@1 0.9766 (0.9700) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 14:01:13] __main__ INFO: \u001b[0mEpoch 37 Step 351/351 lr 0.001000 loss 0.0878 (0.0869) acc@1 0.9766 (0.9699) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 14:01:13] __main__ INFO: \u001b[0mElapsed 33.67\n",
      "\u001b[32m[2020-07-10 14:01:13] __main__ INFO: \u001b[0mVal 37\n",
      "\u001b[32m[2020-07-10 14:01:14] __main__ INFO: \u001b[0mEpoch 37 loss 0.3490 acc@1 0.9080 acc@5 0.9958\n",
      "\u001b[32m[2020-07-10 14:01:14] __main__ INFO: \u001b[0mElapsed 1.10\n",
      "\u001b[32m[2020-07-10 14:01:14] __main__ INFO: \u001b[0mTrain 38 12987\n",
      "\u001b[32m[2020-07-10 14:01:23] __main__ INFO: \u001b[0mEpoch 38 Step 100/351 lr 0.001000 loss 0.0644 (0.0849) acc@1 0.9688 (0.9699) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 14:01:33] __main__ INFO: \u001b[0mEpoch 38 Step 200/351 lr 0.001000 loss 0.0742 (0.0876) acc@1 0.9844 (0.9698) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-10 14:01:43] __main__ INFO: \u001b[0mEpoch 38 Step 300/351 lr 0.001000 loss 0.0984 (0.0855) acc@1 0.9688 (0.9715) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-10 14:01:47] __main__ INFO: \u001b[0mEpoch 38 Step 351/351 lr 0.001000 loss 0.0811 (0.0865) acc@1 0.9688 (0.9710) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-10 14:01:47] __main__ INFO: \u001b[0mElapsed 33.71\n",
      "\u001b[32m[2020-07-10 14:01:47] __main__ INFO: \u001b[0mVal 38\n",
      "\u001b[32m[2020-07-10 14:01:49] __main__ INFO: \u001b[0mEpoch 38 loss 0.3472 acc@1 0.9080 acc@5 0.9968\n",
      "\u001b[32m[2020-07-10 14:01:49] __main__ INFO: \u001b[0mElapsed 1.12\n",
      "\u001b[32m[2020-07-10 14:01:49] __main__ INFO: \u001b[0mTrain 39 13338\n",
      "\u001b[32m[2020-07-10 14:01:58] __main__ INFO: \u001b[0mEpoch 39 Step 100/351 lr 0.001000 loss 0.0629 (0.0850) acc@1 0.9688 (0.9700) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 14:02:08] __main__ INFO: \u001b[0mEpoch 39 Step 200/351 lr 0.001000 loss 0.0309 (0.0839) acc@1 0.9922 (0.9696) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 14:02:17] __main__ INFO: \u001b[0mEpoch 39 Step 300/351 lr 0.001000 loss 0.1341 (0.0844) acc@1 0.9453 (0.9702) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 14:02:22] __main__ INFO: \u001b[0mEpoch 39 Step 351/351 lr 0.001000 loss 0.0952 (0.0853) acc@1 0.9688 (0.9700) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 14:02:22] __main__ INFO: \u001b[0mElapsed 33.68\n",
      "\u001b[32m[2020-07-10 14:02:22] __main__ INFO: \u001b[0mVal 39\n",
      "\u001b[32m[2020-07-10 14:02:23] __main__ INFO: \u001b[0mEpoch 39 loss 0.3553 acc@1 0.9078 acc@5 0.9958\n",
      "\u001b[32m[2020-07-10 14:02:23] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 14:02:23] __main__ INFO: \u001b[0mTrain 40 13689\n",
      "\u001b[32m[2020-07-10 14:02:33] __main__ INFO: \u001b[0mEpoch 40 Step 100/351 lr 0.001000 loss 0.0494 (0.0797) acc@1 0.9922 (0.9732) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 14:02:43] __main__ INFO: \u001b[0mEpoch 40 Step 200/351 lr 0.001000 loss 0.0630 (0.0812) acc@1 0.9844 (0.9721) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-10 14:02:52] __main__ INFO: \u001b[0mEpoch 40 Step 300/351 lr 0.001000 loss 0.1254 (0.0809) acc@1 0.9609 (0.9723) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-10 14:02:57] __main__ INFO: \u001b[0mEpoch 40 Step 351/351 lr 0.001000 loss 0.1779 (0.0817) acc@1 0.9609 (0.9719) acc@5 0.9922 (0.9998)\n",
      "\u001b[32m[2020-07-10 14:02:57] __main__ INFO: \u001b[0mElapsed 33.65\n",
      "\u001b[32m[2020-07-10 14:02:57] __main__ INFO: \u001b[0mVal 40\n",
      "\u001b[32m[2020-07-10 14:02:58] __main__ INFO: \u001b[0mEpoch 40 loss 0.3490 acc@1 0.9090 acc@5 0.9960\n",
      "\u001b[32m[2020-07-10 14:02:58] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-07-10 14:02:58] __main__ INFO: \u001b[0mTrain 41 14040\n",
      "\u001b[32m[2020-07-10 14:03:08] __main__ INFO: \u001b[0mEpoch 41 Step 100/351 lr 0.001000 loss 0.1074 (0.0756) acc@1 0.9688 (0.9739) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 14:03:17] __main__ INFO: \u001b[0mEpoch 41 Step 200/351 lr 0.001000 loss 0.0782 (0.0804) acc@1 0.9766 (0.9722) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-10 14:03:27] __main__ INFO: \u001b[0mEpoch 41 Step 300/351 lr 0.001000 loss 0.1021 (0.0804) acc@1 0.9453 (0.9721) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-10 14:03:32] __main__ INFO: \u001b[0mEpoch 41 Step 351/351 lr 0.001000 loss 0.0314 (0.0809) acc@1 0.9844 (0.9718) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 14:03:32] __main__ INFO: \u001b[0mElapsed 33.65\n",
      "\u001b[32m[2020-07-10 14:03:32] __main__ INFO: \u001b[0mVal 41\n",
      "\u001b[32m[2020-07-10 14:03:33] __main__ INFO: \u001b[0mEpoch 41 loss 0.3635 acc@1 0.9078 acc@5 0.9960\n",
      "\u001b[32m[2020-07-10 14:03:33] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-07-10 14:03:33] __main__ INFO: \u001b[0mTrain 42 14391\n",
      "\u001b[32m[2020-07-10 14:03:42] __main__ INFO: \u001b[0mEpoch 42 Step 100/351 lr 0.001000 loss 0.0611 (0.0814) acc@1 0.9766 (0.9721) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-10 14:03:52] __main__ INFO: \u001b[0mEpoch 42 Step 200/351 lr 0.001000 loss 0.1071 (0.0788) acc@1 0.9531 (0.9721) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-10 14:04:02] __main__ INFO: \u001b[0mEpoch 42 Step 300/351 lr 0.001000 loss 0.1021 (0.0785) acc@1 0.9531 (0.9721) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-10 14:04:06] __main__ INFO: \u001b[0mEpoch 42 Step 351/351 lr 0.001000 loss 0.0538 (0.0791) acc@1 0.9844 (0.9722) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-10 14:04:06] __main__ INFO: \u001b[0mElapsed 33.70\n",
      "\u001b[32m[2020-07-10 14:04:06] __main__ INFO: \u001b[0mVal 42\n",
      "\u001b[32m[2020-07-10 14:04:08] __main__ INFO: \u001b[0mEpoch 42 loss 0.3571 acc@1 0.9090 acc@5 0.9968\n",
      "\u001b[32m[2020-07-10 14:04:08] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 14:04:08] __main__ INFO: \u001b[0mTrain 43 14742\n",
      "\u001b[32m[2020-07-10 14:04:17] __main__ INFO: \u001b[0mEpoch 43 Step 100/351 lr 0.001000 loss 0.1324 (0.0818) acc@1 0.9531 (0.9709) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-10 14:04:27] __main__ INFO: \u001b[0mEpoch 43 Step 200/351 lr 0.001000 loss 0.0599 (0.0771) acc@1 0.9766 (0.9733) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-10 14:04:36] __main__ INFO: \u001b[0mEpoch 43 Step 300/351 lr 0.001000 loss 0.0780 (0.0784) acc@1 0.9766 (0.9729) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 14:04:41] __main__ INFO: \u001b[0mEpoch 43 Step 351/351 lr 0.001000 loss 0.0389 (0.0785) acc@1 0.9844 (0.9730) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 14:04:41] __main__ INFO: \u001b[0mElapsed 33.56\n",
      "\u001b[32m[2020-07-10 14:04:41] __main__ INFO: \u001b[0mVal 43\n",
      "\u001b[32m[2020-07-10 14:04:42] __main__ INFO: \u001b[0mEpoch 43 loss 0.3529 acc@1 0.9088 acc@5 0.9968\n",
      "\u001b[32m[2020-07-10 14:04:42] __main__ INFO: \u001b[0mElapsed 1.08\n",
      "\u001b[32m[2020-07-10 14:04:42] __main__ INFO: \u001b[0mTrain 44 15093\n",
      "\u001b[32m[2020-07-10 14:04:52] __main__ INFO: \u001b[0mEpoch 44 Step 100/351 lr 0.001000 loss 0.0337 (0.0759) acc@1 0.9922 (0.9751) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 14:05:01] __main__ INFO: \u001b[0mEpoch 44 Step 200/351 lr 0.001000 loss 0.0254 (0.0730) acc@1 0.9922 (0.9755) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-10 14:05:11] __main__ INFO: \u001b[0mEpoch 44 Step 300/351 lr 0.001000 loss 0.0818 (0.0735) acc@1 0.9766 (0.9753) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 14:05:16] __main__ INFO: \u001b[0mEpoch 44 Step 351/351 lr 0.001000 loss 0.0766 (0.0749) acc@1 0.9766 (0.9745) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 14:05:16] __main__ INFO: \u001b[0mElapsed 33.64\n",
      "\u001b[32m[2020-07-10 14:05:16] __main__ INFO: \u001b[0mVal 44\n",
      "\u001b[32m[2020-07-10 14:05:17] __main__ INFO: \u001b[0mEpoch 44 loss 0.3657 acc@1 0.9036 acc@5 0.9964\n",
      "\u001b[32m[2020-07-10 14:05:17] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-07-10 14:05:17] __main__ INFO: \u001b[0mTrain 45 15444\n",
      "\u001b[32m[2020-07-10 14:05:27] __main__ INFO: \u001b[0mEpoch 45 Step 100/351 lr 0.001000 loss 0.0658 (0.0727) acc@1 0.9688 (0.9754) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-10 14:05:36] __main__ INFO: \u001b[0mEpoch 45 Step 200/351 lr 0.001000 loss 0.0851 (0.0725) acc@1 0.9688 (0.9750) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-10 14:05:46] __main__ INFO: \u001b[0mEpoch 45 Step 300/351 lr 0.001000 loss 0.0598 (0.0743) acc@1 0.9844 (0.9746) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-10 14:05:51] __main__ INFO: \u001b[0mEpoch 45 Step 351/351 lr 0.001000 loss 0.1059 (0.0757) acc@1 0.9766 (0.9744) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 14:05:51] __main__ INFO: \u001b[0mElapsed 33.65\n",
      "\u001b[32m[2020-07-10 14:05:51] __main__ INFO: \u001b[0mVal 45\n",
      "\u001b[32m[2020-07-10 14:05:52] __main__ INFO: \u001b[0mEpoch 45 loss 0.3691 acc@1 0.9078 acc@5 0.9964\n",
      "\u001b[32m[2020-07-10 14:05:52] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-07-10 14:05:52] __main__ INFO: \u001b[0mTrain 46 15795\n",
      "\u001b[32m[2020-07-10 14:06:01] __main__ INFO: \u001b[0mEpoch 46 Step 100/351 lr 0.001000 loss 0.0457 (0.0703) acc@1 0.9844 (0.9763) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 14:06:11] __main__ INFO: \u001b[0mEpoch 46 Step 200/351 lr 0.001000 loss 0.0281 (0.0694) acc@1 1.0000 (0.9765) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-10 14:06:20] __main__ INFO: \u001b[0mEpoch 46 Step 300/351 lr 0.001000 loss 0.1295 (0.0721) acc@1 0.9609 (0.9758) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-10 14:06:25] __main__ INFO: \u001b[0mEpoch 46 Step 351/351 lr 0.001000 loss 0.0567 (0.0745) acc@1 0.9766 (0.9745) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-10 14:06:25] __main__ INFO: \u001b[0mElapsed 33.68\n",
      "\u001b[32m[2020-07-10 14:06:25] __main__ INFO: \u001b[0mVal 46\n",
      "\u001b[32m[2020-07-10 14:06:26] __main__ INFO: \u001b[0mEpoch 46 loss 0.3662 acc@1 0.9064 acc@5 0.9964\n",
      "\u001b[32m[2020-07-10 14:06:26] __main__ INFO: \u001b[0mElapsed 1.06\n",
      "\u001b[32m[2020-07-10 14:06:26] __main__ INFO: \u001b[0mTrain 47 16146\n",
      "\u001b[32m[2020-07-10 14:06:36] __main__ INFO: \u001b[0mEpoch 47 Step 100/351 lr 0.001000 loss 0.0535 (0.0723) acc@1 0.9844 (0.9763) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-10 14:06:46] __main__ INFO: \u001b[0mEpoch 47 Step 200/351 lr 0.001000 loss 0.0787 (0.0724) acc@1 0.9766 (0.9753) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-10 14:06:55] __main__ INFO: \u001b[0mEpoch 47 Step 300/351 lr 0.001000 loss 0.0977 (0.0709) acc@1 0.9688 (0.9754) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-10 14:07:00] __main__ INFO: \u001b[0mEpoch 47 Step 351/351 lr 0.001000 loss 0.0298 (0.0715) acc@1 1.0000 (0.9750) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-10 14:07:00] __main__ INFO: \u001b[0mElapsed 33.54\n",
      "\u001b[32m[2020-07-10 14:07:00] __main__ INFO: \u001b[0mVal 47\n",
      "\u001b[32m[2020-07-10 14:07:01] __main__ INFO: \u001b[0mEpoch 47 loss 0.3588 acc@1 0.9058 acc@5 0.9970\n",
      "\u001b[32m[2020-07-10 14:07:01] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-07-10 14:07:01] __main__ INFO: \u001b[0mTrain 48 16497\n",
      "\u001b[32m[2020-07-10 14:07:11] __main__ INFO: \u001b[0mEpoch 48 Step 100/351 lr 0.001000 loss 0.0729 (0.0681) acc@1 0.9766 (0.9765) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-10 14:07:20] __main__ INFO: \u001b[0mEpoch 48 Step 200/351 lr 0.001000 loss 0.0691 (0.0695) acc@1 0.9766 (0.9759) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-10 14:07:30] __main__ INFO: \u001b[0mEpoch 48 Step 300/351 lr 0.001000 loss 0.0703 (0.0686) acc@1 0.9766 (0.9763) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-10 14:07:34] __main__ INFO: \u001b[0mEpoch 48 Step 351/351 lr 0.001000 loss 0.1029 (0.0691) acc@1 0.9688 (0.9760) acc@5 0.9922 (0.9999)\n",
      "\u001b[32m[2020-07-10 14:07:34] __main__ INFO: \u001b[0mElapsed 33.50\n",
      "\u001b[32m[2020-07-10 14:07:34] __main__ INFO: \u001b[0mVal 48\n",
      "\u001b[32m[2020-07-10 14:07:36] __main__ INFO: \u001b[0mEpoch 48 loss 0.3703 acc@1 0.9080 acc@5 0.9968\n",
      "\u001b[32m[2020-07-10 14:07:36] __main__ INFO: \u001b[0mElapsed 1.07\n",
      "\u001b[32m[2020-07-10 14:07:36] __main__ INFO: \u001b[0mTrain 49 16848\n",
      "\u001b[32m[2020-07-10 14:07:45] __main__ INFO: \u001b[0mEpoch 49 Step 100/351 lr 0.001000 loss 0.0442 (0.0746) acc@1 0.9844 (0.9749) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-10 14:07:55] __main__ INFO: \u001b[0mEpoch 49 Step 200/351 lr 0.001000 loss 0.0548 (0.0700) acc@1 0.9844 (0.9759) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-10 14:08:04] __main__ INFO: \u001b[0mEpoch 49 Step 300/351 lr 0.001000 loss 0.0543 (0.0715) acc@1 0.9844 (0.9751) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-10 14:08:09] __main__ INFO: \u001b[0mEpoch 49 Step 351/351 lr 0.001000 loss 0.0718 (0.0720) acc@1 0.9688 (0.9750) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-10 14:08:09] __main__ INFO: \u001b[0mElapsed 33.67\n",
      "\u001b[32m[2020-07-10 14:08:09] __main__ INFO: \u001b[0mVal 49\n",
      "\u001b[32m[2020-07-10 14:08:10] __main__ INFO: \u001b[0mEpoch 49 loss 0.3666 acc@1 0.9070 acc@5 0.9968\n",
      "\u001b[32m[2020-07-10 14:08:10] __main__ INFO: \u001b[0mElapsed 1.11\n",
      "\u001b[32m[2020-07-10 14:08:10] __main__ INFO: \u001b[0mTrain 50 17199\n",
      "\u001b[32m[2020-07-10 14:08:20] __main__ INFO: \u001b[0mEpoch 50 Step 100/351 lr 0.001000 loss 0.1253 (0.0639) acc@1 0.9688 (0.9785) acc@5 0.9922 (0.9999)\n",
      "\u001b[32m[2020-07-10 14:08:30] __main__ INFO: \u001b[0mEpoch 50 Step 200/351 lr 0.001000 loss 0.1178 (0.0681) acc@1 0.9609 (0.9763) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-10 14:08:39] __main__ INFO: \u001b[0mEpoch 50 Step 300/351 lr 0.001000 loss 0.0269 (0.0676) acc@1 0.9922 (0.9762) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-10 14:08:44] __main__ INFO: \u001b[0mEpoch 50 Step 351/351 lr 0.001000 loss 0.0858 (0.0674) acc@1 0.9609 (0.9762) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-10 14:08:44] __main__ INFO: \u001b[0mElapsed 33.71\n",
      "\u001b[32m[2020-07-10 14:08:44] __main__ INFO: \u001b[0mVal 50\n",
      "\u001b[32m[2020-07-10 14:08:45] __main__ INFO: \u001b[0mEpoch 50 loss 0.3783 acc@1 0.9078 acc@5 0.9958\n",
      "\u001b[32m[2020-07-10 14:08:45] __main__ INFO: \u001b[0mElapsed 1.09\n",
      "\u001b[32m[2020-07-10 14:08:45] fvcore.common.checkpoint INFO: \u001b[0mSaving checkpoint to /home/ec2-user/SageMaker/experiments/resnet_basic_32_cm_1_1/exp00_resume400_50/checkpoint_00050.pth\n"
     ]
    }
   ],
   "source": [
    "# Resume training with the un-augmented data\n",
    "os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "!python train.py --config /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_cm_1_1/exp00/config.yaml \\\n",
    "    train.checkpoint /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_cm_1_1/exp00/checkpoint_00400.pth \\\n",
    "    dataset.name CIFAR10 \\\n",
    "    model.wrn.depth 28 \\\n",
    "    model.wrn.widening_factor 10 \\\n",
    "    train.batch_size 128 \\\n",
    "    train.base_lr 0.000032 \\\n",
    "    train.output_dir /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_cm_1_1/exp00_resume400_50 \\\n",
    "    scheduler.epochs 50\n",
    "\n",
    "#### Set LEARNING RATE based on ending LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-10 14:10:31] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/resnet_basic_32_cm_1_1/exp00_resume400_50/checkpoint_00050.pth\n",
      "Files already downloaded and verified\n",
      "100%|███████████████████████████████████████████| 79/79 [00:02<00:00, 26.66it/s]\n",
      "\u001b[32m[2020-07-10 14:10:35] __main__ INFO: \u001b[0mElapsed 2.97\n",
      "\u001b[32m[2020-07-10 14:10:35] __main__ INFO: \u001b[0mLoss 0.4049 Accuracy 0.9010\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10 test dataset \n",
    "# Right the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/resnext.yaml \\\n",
    "   model.resnet.depth 32 \\\n",
    "   test.batch_size 128 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_cm_1_1/exp00_resume400_50/checkpoint_00050.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_cm_1_1/exp00_resume400_50/test_results_0050_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-10 16:59:44] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/resnet_basic_32_cm_1_1/exp00_resume400_50/checkpoint_00050.pth\n",
      "CIFAR 10.1\n",
      "100%|███████████████████████████████████████████| 16/16 [00:00<00:00, 18.16it/s]\n",
      "\u001b[32m[2020-07-10 16:59:45] __main__ INFO: \u001b[0mElapsed 0.88\n",
      "\u001b[32m[2020-07-10 16:59:45] __main__ INFO: \u001b[0mLoss 0.8287 Accuracy 0.8260\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10.1 test dataset \n",
    "# Right the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/resnext.yaml \\\n",
    "   model.resnet.depth 32 \\\n",
    "   test.batch_size 128 \\\n",
    "   dataset.name CIFAR101 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_cm_1_1/exp00_resume400_50/checkpoint_00050.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_cm_1_1/exp00_resume400_50/test_results_0050_cifar101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-10 14:11:23] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/resnet_basic_32_cm_1_1/exp00/checkpoint_00400.pth\n",
      "Files already downloaded and verified\n",
      "100%|███████████████████████████████████████████| 79/79 [00:02<00:00, 27.59it/s]\n",
      "\u001b[32m[2020-07-10 14:11:27] __main__ INFO: \u001b[0mElapsed 2.87\n",
      "\u001b[32m[2020-07-10 14:11:27] __main__ INFO: \u001b[0mLoss 0.5840 Accuracy 0.8608\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10 test dataset \n",
    "# Right the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/resnext.yaml \\\n",
    "   model.resnet.depth 32 \\\n",
    "   test.batch_size 128 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_cm_1_1/exp00/checkpoint_00400.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_cm_1_1/exp00/test_results_0400_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-10 17:00:22] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/resnet_basic_32_cm_1_1/exp00/checkpoint_00400.pth\n",
      "CIFAR 10.1\n",
      "100%|███████████████████████████████████████████| 16/16 [00:00<00:00, 18.09it/s]\n",
      "\u001b[32m[2020-07-10 17:00:24] __main__ INFO: \u001b[0mElapsed 0.89\n",
      "\u001b[32m[2020-07-10 17:00:24] __main__ INFO: \u001b[0mLoss 0.8922 Accuracy 0.7515\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10.1 test dataset \n",
    "# Right the results to the test output directory specified.\n",
    "os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "!python evaluate.py --config configs/cifar/resnext.yaml \\\n",
    "   model.resnet.depth 32 \\\n",
    "   test.batch_size 128 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_cm_1_1/exp00/checkpoint_00400.pth \\\n",
    "   dataset.name CIFAR101 \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/resnext_29_4x64d_cm_1_1/exp00/test_results_0400_cifar101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Record the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Testset</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Original_Accuracy</th>\n",
       "      <th>Original_CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resnext_29_4x64d</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6746</td>\n",
       "      <td>0.8019</td>\n",
       "      <td>96.4</td>\n",
       "      <td>(96.0, 96.7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>resnext_29_4x64d</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>200</td>\n",
       "      <td>0.2311</td>\n",
       "      <td>0.9321</td>\n",
       "      <td>96.4</td>\n",
       "      <td>(96.0, 96.7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>resnext_29_4x64d</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>300</td>\n",
       "      <td>0.1517</td>\n",
       "      <td>0.9535</td>\n",
       "      <td>96.4</td>\n",
       "      <td>(96.0, 96.7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>resnext_29_4x64d</td>\n",
       "      <td>cifar10.1</td>\n",
       "      <td>300</td>\n",
       "      <td>0.3742</td>\n",
       "      <td>0.8905</td>\n",
       "      <td>89.6</td>\n",
       "      <td>(88.2, 90.9)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model    Testset  Epoch    Loss  Accuracy  Original_Accuracy  \\\n",
       "0  resnext_29_4x64d    cifar10    100  0.6746    0.8019               96.4   \n",
       "1  resnext_29_4x64d    cifar10    200  0.2311    0.9321               96.4   \n",
       "2  resnext_29_4x64d    cifar10    300  0.1517    0.9535               96.4   \n",
       "3  resnext_29_4x64d  cifar10.1    300  0.3742    0.8905               89.6   \n",
       "\n",
       "    Original_CI  \n",
       "0  (96.0, 96.7)  \n",
       "1  (96.0, 96.7)  \n",
       "2  (96.0, 96.7)  \n",
       "3  (88.2, 90.9)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write the results to a CSV file so that we can analyze later.\n",
    "import pandas as pd\n",
    "\n",
    "results = {'Model': ['resnext_29_4x64d', 'resnext_29_4x64d', 'resnext_29_4x64d', 'resnext_29_4x64d'],\n",
    "           'Testset': ['cifar10', 'cifar10', 'cifar10', 'cifar10.1'],\n",
    "           'Epoch': [100, 200, 300, 300],\n",
    "           'Loss': [0.6746, 0.2311, 0.1517, 0.3742],\n",
    "           'Accuracy': [0.8019, 0.9321, 0.9535, 0.8905],\n",
    "           'Original_Accuracy': [96.4, 96.4, 96.4, 89.6],\n",
    "           'Original_CI': [(96.0, 96.7), (96.0, 96.7), (96.0, 96.7), (88.2, 90.9)]\n",
    "           }\n",
    "\n",
    "df = pd.DataFrame(results, columns = ['Model', 'Testset', 'Epoch', 'Loss', 'Accuracy', \n",
    "                                      'Original_Accuracy', 'Original_CI'])\n",
    "\n",
    "\n",
    "\n",
    "#df.to_csv('/home/ec2-user/SageMaker/experiments/wrn_28_10/exp00/results.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Testset</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Original_Accuracy</th>\n",
       "      <th>Original_CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resnet_basic_32_cm_1_1</td>\n",
       "      <td>400</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.8608</td>\n",
       "      <td>92.5</td>\n",
       "      <td>(92.0, 93.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>resnet_basic_32_cm_1_1</td>\n",
       "      <td>400</td>\n",
       "      <td>cifar10.1</td>\n",
       "      <td>0.8922</td>\n",
       "      <td>0.7515</td>\n",
       "      <td>84.9</td>\n",
       "      <td>(83.2, 86.4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>resnet_basic_32_cm_1_1</td>\n",
       "      <td>50</td>\n",
       "      <td>cifar10.1</td>\n",
       "      <td>0.8287</td>\n",
       "      <td>0.826</td>\n",
       "      <td>84.9</td>\n",
       "      <td>(83.2, 86.4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>resnet_basic_32_cm_1_1</td>\n",
       "      <td>50</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>0.4049</td>\n",
       "      <td>0.901</td>\n",
       "      <td>92.5</td>\n",
       "      <td>(92.0, 93.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model Epoch    Testset    Loss Accuracy  \\\n",
       "0  resnet_basic_32_cm_1_1   400    cifar10   0.584   0.8608   \n",
       "1  resnet_basic_32_cm_1_1   400  cifar10.1  0.8922   0.7515   \n",
       "2  resnet_basic_32_cm_1_1    50  cifar10.1  0.8287    0.826   \n",
       "3  resnet_basic_32_cm_1_1    50    cifar10  0.4049    0.901   \n",
       "\n",
       "   Original_Accuracy   Original_CI  \n",
       "0               92.5  (92.0, 93.0)  \n",
       "1               84.9  (83.2, 86.4)  \n",
       "2               84.9  (83.2, 86.4)  \n",
       "3               92.5  (92.0, 93.0)  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "model = 'resnext_29_4x64d_cm_1_1'\n",
    "\n",
    "a = pd.Series([model, 400, 'cifar10', ])\n",
    "c = pd.Series([model, 400, 'cifar10.1', ])\n",
    "\n",
    "e = pd.Series([model, 50, 'cifar10.1', ])\n",
    "f = pd.Series([model, 50, 'cifar10', ])\n",
    "               \n",
    "df_results = pd.concat([a,c,e,f], axis=1).T\n",
    "df_results.columns = ['Model', 'Epoch', 'Testset', 'Loss', 'Accuracy']\n",
    "\n",
    "df_results['Original_Accuracy'] = df_results.apply((lambda row: 96.4 if row[2] == 'cifar10' else 89.6), axis=1)\n",
    "df_results['Original_CI'] = df_results.apply((lambda row: (96.0, 96.7) if row[2] == 'cifar10' else (88.2, 90.9)), axis=1)\n",
    "\n",
    "df_results.to_csv('/home/ec2-user/SageMaker/experiments/' + model + '/results.csv')\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the model checkpoints, configs, and results to S3 \n",
    "bucket='sagemaker-may29'\n",
    "prefix = 'sagemaker/results/original-models/resnext_29_4x64d_cm_1_1'\n",
    "path = '/home/ec2-user/SageMaker/experiments/resnext_29_4x64d_cm_1_1'\n",
    "\n",
    "s3_resource = boto3.resource(\"s3\", region_name=\"us-east-2\")\n",
    "\n",
    "def uploadDirectory(local_path,bucket_name,s3_prefix):\n",
    "\n",
    "    my_bucket = s3_resource.Bucket(bucket_name)\n",
    "    \n",
    "    for path, subdirs, files in os.walk(local_path):\n",
    "        path = path.replace(\"\\\\\",\"/\")\n",
    "        directory_name = path.replace(local_path,\"\")\n",
    "        for file in files:\n",
    "            #print(\"Local File:\", os.path.join(path, file))\n",
    "            #print(\"      Dest:\", s3_prefix+directory_name+'/'+file)\n",
    "            my_bucket.upload_file(os.path.join(path, file), s3_prefix+directory_name+'/'+file)\n",
    "    \n",
    "uploadDirectory(path,bucket,prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
