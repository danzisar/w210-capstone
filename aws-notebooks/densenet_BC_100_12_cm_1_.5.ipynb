{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense Net\n",
    "\n",
    " - Training Dataset:  CutMix, beta=1, cutmix_prob=1\n",
    " - Sagemaker Notebook must be of type, conda_pytorch_p36\n",
    " \n",
    "#### Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy \n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 1)) (1.18.1)\n",
      "Requirement already satisfied: torch>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 2)) (1.4.0)\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 3)) (0.5.0)\n",
      "Requirement already satisfied: fvcore in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (0.1.1.post20200711)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 5)) (4.44.1)\n",
      "Requirement already satisfied: yacs in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 6)) (0.1.7)\n",
      "Requirement already satisfied: apex from git+https://github.com/NVIDIA/apex.git#egg=apex in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 7)) (0.1)\n",
      "Requirement already satisfied: termcolor in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 8)) (1.1.0)\n",
      "Requirement already satisfied: thop<0.0.31.post2004070130 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 9)) (0.0.31.post2001170342)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 3)) (1.14.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 3)) (7.0.0)\n",
      "Requirement already satisfied: tabulate in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from fvcore->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (0.8.7)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from fvcore->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (5.3.1)\n",
      "Requirement already satisfied: portalocker in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from fvcore->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (1.7.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: tensorboard in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (2.2.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.18.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (46.1.3.post20200330)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.30.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (3.2.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.14.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.34.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.4.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.7.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (3.12.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.18.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (2.23.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.0.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard) (3.4.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (1.5.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.4.5.2)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (1.25.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard) (2.2.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r '/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt'\n",
    "\n",
    "# Need to add this to requirements.txt\n",
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-12 04:40:04] __main__ INFO: \u001b[0mdevice: cuda\n",
      "cudnn:\n",
      "  benchmark: True\n",
      "  deterministic: False\n",
      "dataset:\n",
      "  name: CIFAR10_CM_.5\n",
      "  dataset_dir: ''\n",
      "  image_size: 32\n",
      "  n_channels: 3\n",
      "  n_classes: 10\n",
      "model:\n",
      "  type: cifar\n",
      "  name: densenet\n",
      "  init_mode: kaiming_fan_out\n",
      "  vgg:\n",
      "    n_channels: [64, 128, 256, 512, 512]\n",
      "    n_layers: [2, 2, 3, 3, 3]\n",
      "    use_bn: True\n",
      "  resnet:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "  resnet_preact:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "  wrn:\n",
      "    depth: 28\n",
      "    initial_channels: 16\n",
      "    widening_factor: 10\n",
      "    drop_rate: 0.0\n",
      "  densenet:\n",
      "    depth: 100\n",
      "    n_blocks: [6, 12, 24, 16]\n",
      "    block_type: bottleneck\n",
      "    growth_rate: 12\n",
      "    drop_rate: 0.0\n",
      "    compression_rate: 0.5\n",
      "  pyramidnet:\n",
      "    depth: 272\n",
      "    n_blocks: [3, 24, 36, 3]\n",
      "    initial_channels: 16\n",
      "    block_type: bottleneck\n",
      "    alpha: 200\n",
      "  resnext:\n",
      "    depth: 29\n",
      "    n_blocks: [3, 4, 6, 3]\n",
      "    initial_channels: 64\n",
      "    cardinality: 8\n",
      "    base_channels: 4\n",
      "  shake_shake:\n",
      "    depth: 26\n",
      "    initial_channels: 96\n",
      "    shake_forward: True\n",
      "    shake_backward: True\n",
      "    shake_image: True\n",
      "  se_resnet_preact:\n",
      "    depth: 110\n",
      "    initial_channels: 16\n",
      "    se_reduction: 16\n",
      "    block_type: basic\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "train:\n",
      "  checkpoint: ''\n",
      "  resume: False\n",
      "  precision: O0\n",
      "  batch_size: 64\n",
      "  subdivision: 1\n",
      "  optimizer: sgd\n",
      "  base_lr: 0.1\n",
      "  momentum: 0.9\n",
      "  nesterov: True\n",
      "  weight_decay: 0.0001\n",
      "  no_weight_decay_on_bn: False\n",
      "  gradient_clip: 0\n",
      "  start_epoch: 0\n",
      "  seed: 0\n",
      "  val_first: True\n",
      "  val_period: 1\n",
      "  val_ratio: 0.1\n",
      "  use_test_as_val: False\n",
      "  output_dir: /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_cm_1_.5/exp00\n",
      "  log_period: 100\n",
      "  checkpoint_period: 100\n",
      "  use_tensorboard: True\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: True\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "  distributed: False\n",
      "  dist:\n",
      "    backend: nccl\n",
      "    init_method: env://\n",
      "    world_size: -1\n",
      "    node_rank: -1\n",
      "    local_rank: 0\n",
      "    use_sync_bn: False\n",
      "tensorboard:\n",
      "  train_images: False\n",
      "  val_images: False\n",
      "  model_params: False\n",
      "optim:\n",
      "  adam:\n",
      "    betas: (0.9, 0.999)\n",
      "  lars:\n",
      "    eps: 1e-09\n",
      "    threshold: 0.01\n",
      "  adabound:\n",
      "    betas: (0.9, 0.999)\n",
      "    final_lr: 0.1\n",
      "    gamma: 0.001\n",
      "scheduler:\n",
      "  epochs: 400\n",
      "  warmup:\n",
      "    type: none\n",
      "    epochs: 0\n",
      "    start_factor: 0.001\n",
      "    exponent: 4\n",
      "  type: multistep\n",
      "  milestones: [150, 225]\n",
      "  lr_decay: 0.1\n",
      "  lr_min_factor: 0.001\n",
      "  T0: 10\n",
      "  T_mul: 1.0\n",
      "validation:\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: False\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "augmentation:\n",
      "  use_random_crop: True\n",
      "  use_random_horizontal_flip: True\n",
      "  use_cutout: False\n",
      "  use_random_erasing: False\n",
      "  use_dual_cutout: False\n",
      "  use_mixup: False\n",
      "  use_ricap: False\n",
      "  use_cutmix: False\n",
      "  use_label_smoothing: False\n",
      "  random_crop:\n",
      "    padding: 4\n",
      "    fill: 0\n",
      "    padding_mode: constant\n",
      "  random_horizontal_flip:\n",
      "    prob: 0.5\n",
      "  cutout:\n",
      "    prob: 1.0\n",
      "    mask_size: 16\n",
      "    cut_inside: False\n",
      "    mask_color: 0\n",
      "    dual_cutout_alpha: 0.1\n",
      "  random_erasing:\n",
      "    prob: 0.5\n",
      "    area_ratio_range: [0.02, 0.4]\n",
      "    min_aspect_ratio: 0.3\n",
      "    max_attempt: 20\n",
      "  mixup:\n",
      "    alpha: 1.0\n",
      "  ricap:\n",
      "    beta: 0.3\n",
      "  cutmix:\n",
      "    alpha: 1.0\n",
      "  label_smoothing:\n",
      "    epsilon: 0.1\n",
      "tta:\n",
      "  use_resize: False\n",
      "  use_center_crop: False\n",
      "  resize: 256\n",
      "test:\n",
      "  checkpoint: ''\n",
      "  output_dir: ''\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    pin_memory: False\n",
      "\u001b[32m[2020-07-12 04:40:04] __main__ INFO: \u001b[0menv_info:\n",
      "  pytorch_version: 1.4.0\n",
      "  cuda_version: 10.1\n",
      "  cudnn_version: 7603\n",
      "  num_gpus: 1\n",
      "  gpu_name: Tesla K80\n",
      "  gpu_capability: 3.7\n",
      "Files already downloaded and verified\n",
      "\u001b[32m[2020-07-12 04:40:29] __main__ INFO: \u001b[0mMACs  : 296.49M\n",
      "\u001b[32m[2020-07-12 04:40:29] __main__ INFO: \u001b[0m#params: 769.16K\n",
      "Selected optimization level O0:  Pure FP32 training.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n",
      "\u001b[32m[2020-07-12 04:40:29] __main__ INFO: \u001b[0mVal 0\n",
      "\u001b[32m[2020-07-12 04:40:40] __main__ INFO: \u001b[0mEpoch 0 loss 13259259.9280 acc@1 0.1012 acc@5 0.5040\n",
      "\u001b[32m[2020-07-12 04:40:40] __main__ INFO: \u001b[0mElapsed 11.33\n",
      "\u001b[32m[2020-07-12 04:40:40] __main__ INFO: \u001b[0mTrain 1 0\n",
      "\u001b[32m[2020-07-12 04:41:14] __main__ INFO: \u001b[0mEpoch 1 Step 100/703 lr 0.100000 loss 2.0177 (2.3355) acc@1 0.2428 (0.2191) acc@5 0.7580 (0.7225)\n",
      "\u001b[32m[2020-07-12 04:41:45] __main__ INFO: \u001b[0mEpoch 1 Step 200/703 lr 0.100000 loss 1.8433 (2.1577) acc@1 0.2965 (0.2488) acc@5 0.8748 (0.7562)\n",
      "\u001b[32m[2020-07-12 04:42:17] __main__ INFO: \u001b[0mEpoch 1 Step 300/703 lr 0.100000 loss 1.8855 (2.0751) acc@1 0.3090 (0.2677) acc@5 0.7943 (0.7740)\n",
      "\u001b[32m[2020-07-12 04:42:49] __main__ INFO: \u001b[0mEpoch 1 Step 400/703 lr 0.100000 loss 1.9997 (2.0204) acc@1 0.3190 (0.2840) acc@5 0.8225 (0.7862)\n",
      "\u001b[32m[2020-07-12 04:43:21] __main__ INFO: \u001b[0mEpoch 1 Step 500/703 lr 0.100000 loss 1.7646 (1.9808) acc@1 0.3441 (0.2959) acc@5 0.9039 (0.7958)\n",
      "\u001b[32m[2020-07-12 04:43:53] __main__ INFO: \u001b[0mEpoch 1 Step 600/703 lr 0.100000 loss 1.8087 (1.9493) acc@1 0.3485 (0.3069) acc@5 0.8864 (0.8042)\n",
      "\u001b[32m[2020-07-12 04:44:26] __main__ INFO: \u001b[0mEpoch 1 Step 700/703 lr 0.100000 loss 1.7339 (1.9157) acc@1 0.3336 (0.3189) acc@5 0.8915 (0.8123)\n",
      "\u001b[32m[2020-07-12 04:44:27] __main__ INFO: \u001b[0mEpoch 1 Step 703/703 lr 0.100000 loss 1.7152 (1.9148) acc@1 0.3578 (0.3191) acc@5 0.8830 (0.8125)\n",
      "\u001b[32m[2020-07-12 04:44:27] __main__ INFO: \u001b[0mElapsed 226.61\n",
      "\u001b[32m[2020-07-12 04:44:27] __main__ INFO: \u001b[0mVal 1\n",
      "\u001b[32m[2020-07-12 04:44:34] __main__ INFO: \u001b[0mEpoch 1 loss 1.5413 acc@1 0.4538 acc@5 0.8980\n",
      "\u001b[32m[2020-07-12 04:44:34] __main__ INFO: \u001b[0mElapsed 7.80\n",
      "\u001b[32m[2020-07-12 04:44:34] __main__ INFO: \u001b[0mTrain 2 703\n",
      "\u001b[32m[2020-07-12 04:45:07] __main__ INFO: \u001b[0mEpoch 2 Step 100/703 lr 0.100000 loss 1.8247 (1.6817) acc@1 0.4254 (0.4064) acc@5 0.8125 (0.8714)\n",
      "\u001b[32m[2020-07-12 04:45:39] __main__ INFO: \u001b[0mEpoch 2 Step 200/703 lr 0.100000 loss 1.7370 (1.6657) acc@1 0.4115 (0.4172) acc@5 0.8412 (0.8722)\n",
      "\u001b[32m[2020-07-12 04:46:11] __main__ INFO: \u001b[0mEpoch 2 Step 300/703 lr 0.100000 loss 1.7103 (1.6600) acc@1 0.4165 (0.4206) acc@5 0.8552 (0.8724)\n",
      "\u001b[32m[2020-07-12 04:46:43] __main__ INFO: \u001b[0mEpoch 2 Step 400/703 lr 0.100000 loss 1.5017 (1.6468) acc@1 0.5188 (0.4261) acc@5 0.8971 (0.8751)\n",
      "\u001b[32m[2020-07-12 04:47:16] __main__ INFO: \u001b[0mEpoch 2 Step 500/703 lr 0.100000 loss 1.5274 (1.6351) acc@1 0.4597 (0.4309) acc@5 0.8914 (0.8772)\n",
      "\u001b[32m[2020-07-12 04:47:48] __main__ INFO: \u001b[0mEpoch 2 Step 600/703 lr 0.100000 loss 1.6463 (1.6219) acc@1 0.4420 (0.4354) acc@5 0.8688 (0.8800)\n",
      "\u001b[32m[2020-07-12 04:48:20] __main__ INFO: \u001b[0mEpoch 2 Step 700/703 lr 0.100000 loss 1.6320 (1.6121) acc@1 0.3984 (0.4396) acc@5 0.9193 (0.8814)\n",
      "\u001b[32m[2020-07-12 04:48:21] __main__ INFO: \u001b[0mEpoch 2 Step 703/703 lr 0.100000 loss 1.6145 (1.6119) acc@1 0.4548 (0.4396) acc@5 0.8833 (0.8815)\n",
      "\u001b[32m[2020-07-12 04:48:21] __main__ INFO: \u001b[0mElapsed 226.78\n",
      "\u001b[32m[2020-07-12 04:48:21] __main__ INFO: \u001b[0mVal 2\n",
      "\u001b[32m[2020-07-12 04:48:29] __main__ INFO: \u001b[0mEpoch 2 loss 1.1306 acc@1 0.6120 acc@5 0.9516\n",
      "\u001b[32m[2020-07-12 04:48:29] __main__ INFO: \u001b[0mElapsed 7.80\n",
      "\u001b[32m[2020-07-12 04:48:29] __main__ INFO: \u001b[0mTrain 3 1406\n",
      "\u001b[32m[2020-07-12 04:49:01] __main__ INFO: \u001b[0mEpoch 3 Step 100/703 lr 0.100000 loss 1.4900 (1.4815) acc@1 0.5533 (0.4990) acc@5 0.9158 (0.9006)\n",
      "\u001b[32m[2020-07-12 04:49:34] __main__ INFO: \u001b[0mEpoch 3 Step 200/703 lr 0.100000 loss 1.5626 (1.5033) acc@1 0.4891 (0.4894) acc@5 0.9259 (0.8999)\n"
     ]
    }
   ],
   "source": [
    "# Train the model per the settings specified in the original paper\n",
    "os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "!python train.py --config configs/cifar/densenet.yaml \\\n",
    "    model.densenet.depth 100 \\\n",
    "    model.densenet.growth_rate 12 \\\n",
    "    train.batch_size 64 \\\n",
    "    train.base_lr 0.1 \\\n",
    "    dataset.name CIFAR10_CM_.5 \\\n",
    "    train.output_dir /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_cm_1_.5/exp00 \\\n",
    "    scheduler.epochs 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refine the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-13 16:32:23] __main__ INFO: \u001b[0mdevice: cuda\n",
      "cudnn:\n",
      "  benchmark: True\n",
      "  deterministic: False\n",
      "dataset:\n",
      "  name: CIFAR10\n",
      "  dataset_dir: ~/.torch/datasets/CIFAR10\n",
      "  image_size: 32\n",
      "  n_channels: 3\n",
      "  n_classes: 10\n",
      "model:\n",
      "  type: cifar\n",
      "  name: densenet\n",
      "  init_mode: kaiming_fan_out\n",
      "  vgg:\n",
      "    n_channels: [64, 128, 256, 512, 512]\n",
      "    n_layers: [2, 2, 3, 3, 3]\n",
      "    use_bn: True\n",
      "  resnet:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "  resnet_preact:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "  wrn:\n",
      "    depth: 28\n",
      "    initial_channels: 16\n",
      "    widening_factor: 10\n",
      "    drop_rate: 0.0\n",
      "  densenet:\n",
      "    depth: 100\n",
      "    n_blocks: [6, 12, 24, 16]\n",
      "    block_type: bottleneck\n",
      "    growth_rate: 12\n",
      "    drop_rate: 0.0\n",
      "    compression_rate: 0.5\n",
      "  pyramidnet:\n",
      "    depth: 272\n",
      "    n_blocks: [3, 24, 36, 3]\n",
      "    initial_channels: 16\n",
      "    block_type: bottleneck\n",
      "    alpha: 200\n",
      "  resnext:\n",
      "    depth: 29\n",
      "    n_blocks: [3, 4, 6, 3]\n",
      "    initial_channels: 64\n",
      "    cardinality: 8\n",
      "    base_channels: 4\n",
      "  shake_shake:\n",
      "    depth: 26\n",
      "    initial_channels: 96\n",
      "    shake_forward: True\n",
      "    shake_backward: True\n",
      "    shake_image: True\n",
      "  se_resnet_preact:\n",
      "    depth: 110\n",
      "    initial_channels: 16\n",
      "    se_reduction: 16\n",
      "    block_type: basic\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "train:\n",
      "  checkpoint: /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_cm_1_.5/exp00/checkpoint_00400.pth\n",
      "  resume: False\n",
      "  precision: O0\n",
      "  batch_size: 64\n",
      "  subdivision: 1\n",
      "  optimizer: sgd\n",
      "  base_lr: 0.001\n",
      "  momentum: 0.9\n",
      "  nesterov: True\n",
      "  weight_decay: 0.0001\n",
      "  no_weight_decay_on_bn: False\n",
      "  gradient_clip: 0\n",
      "  start_epoch: 0\n",
      "  seed: 0\n",
      "  val_first: True\n",
      "  val_period: 1\n",
      "  val_ratio: 0.1\n",
      "  use_test_as_val: False\n",
      "  output_dir: /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_cm_1_.5/exp00_resume400_50\n",
      "  log_period: 100\n",
      "  checkpoint_period: 100\n",
      "  use_tensorboard: True\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: True\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "  distributed: False\n",
      "  dist:\n",
      "    backend: nccl\n",
      "    init_method: env://\n",
      "    world_size: -1\n",
      "    node_rank: -1\n",
      "    local_rank: 0\n",
      "    use_sync_bn: False\n",
      "tensorboard:\n",
      "  train_images: False\n",
      "  val_images: False\n",
      "  model_params: False\n",
      "optim:\n",
      "  adam:\n",
      "    betas: (0.9, 0.999)\n",
      "  lars:\n",
      "    eps: 1e-09\n",
      "    threshold: 0.01\n",
      "  adabound:\n",
      "    betas: (0.9, 0.999)\n",
      "    final_lr: 0.1\n",
      "    gamma: 0.001\n",
      "scheduler:\n",
      "  epochs: 50\n",
      "  warmup:\n",
      "    type: none\n",
      "    epochs: 0\n",
      "    start_factor: 0.001\n",
      "    exponent: 4\n",
      "  type: multistep\n",
      "  milestones: [150, 225]\n",
      "  lr_decay: 0.1\n",
      "  lr_min_factor: 0.001\n",
      "  T0: 10\n",
      "  T_mul: 1.0\n",
      "validation:\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: False\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "augmentation:\n",
      "  use_random_crop: True\n",
      "  use_random_horizontal_flip: True\n",
      "  use_cutout: False\n",
      "  use_random_erasing: False\n",
      "  use_dual_cutout: False\n",
      "  use_mixup: False\n",
      "  use_ricap: False\n",
      "  use_cutmix: False\n",
      "  use_label_smoothing: False\n",
      "  random_crop:\n",
      "    padding: 4\n",
      "    fill: 0\n",
      "    padding_mode: constant\n",
      "  random_horizontal_flip:\n",
      "    prob: 0.5\n",
      "  cutout:\n",
      "    prob: 1.0\n",
      "    mask_size: 16\n",
      "    cut_inside: False\n",
      "    mask_color: 0\n",
      "    dual_cutout_alpha: 0.1\n",
      "  random_erasing:\n",
      "    prob: 0.5\n",
      "    area_ratio_range: [0.02, 0.4]\n",
      "    min_aspect_ratio: 0.3\n",
      "    max_attempt: 20\n",
      "  mixup:\n",
      "    alpha: 1.0\n",
      "  ricap:\n",
      "    beta: 0.3\n",
      "  cutmix:\n",
      "    alpha: 1.0\n",
      "  label_smoothing:\n",
      "    epsilon: 0.1\n",
      "tta:\n",
      "  use_resize: False\n",
      "  use_center_crop: False\n",
      "  resize: 256\n",
      "test:\n",
      "  checkpoint: ''\n",
      "  output_dir: ''\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    pin_memory: False\n",
      "\u001b[32m[2020-07-13 16:32:23] __main__ INFO: \u001b[0menv_info:\n",
      "  pytorch_version: 1.4.0\n",
      "  cuda_version: 10.1\n",
      "  cudnn_version: 7603\n",
      "  num_gpus: 1\n",
      "  gpu_name: Tesla K80\n",
      "  gpu_capability: 3.7\n",
      "Files already downloaded and verified\n",
      "\u001b[32m[2020-07-13 16:32:26] __main__ INFO: \u001b[0mMACs  : 296.49M\n",
      "\u001b[32m[2020-07-13 16:32:26] __main__ INFO: \u001b[0m#params: 769.16K\n",
      "Selected optimization level O0:  Pure FP32 training.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n",
      "\u001b[32m[2020-07-13 16:32:26] __main__ INFO: \u001b[0mVal 0\n",
      "\u001b[32m[2020-07-13 16:32:38] __main__ INFO: \u001b[0mEpoch 0 loss 3.0067 acc@1 0.3108 acc@5 0.6938\n",
      "\u001b[32m[2020-07-13 16:32:38] __main__ INFO: \u001b[0mElapsed 11.41\n",
      "\u001b[32m[2020-07-13 16:32:38] __main__ INFO: \u001b[0mTrain 1 0\n",
      "\u001b[32m[2020-07-13 16:33:11] __main__ INFO: \u001b[0mEpoch 1 Step 100/703 lr 0.001000 loss 0.0449 (0.0631) acc@1 0.9844 (0.9877) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-13 16:33:43] __main__ INFO: \u001b[0mEpoch 1 Step 200/703 lr 0.001000 loss 0.0327 (0.0540) acc@1 0.9844 (0.9880) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-13 16:34:15] __main__ INFO: \u001b[0mEpoch 1 Step 300/703 lr 0.001000 loss 0.0145 (0.0521) acc@1 1.0000 (0.9880) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-13 16:34:47] __main__ INFO: \u001b[0mEpoch 1 Step 400/703 lr 0.001000 loss 0.0075 (0.0493) acc@1 1.0000 (0.9883) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-13 16:35:19] __main__ INFO: \u001b[0mEpoch 1 Step 500/703 lr 0.001000 loss 0.0080 (0.0495) acc@1 1.0000 (0.9878) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-13 16:35:51] __main__ INFO: \u001b[0mEpoch 1 Step 600/703 lr 0.001000 loss 0.0268 (0.0473) acc@1 0.9844 (0.9880) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-13 16:36:23] __main__ INFO: \u001b[0mEpoch 1 Step 700/703 lr 0.001000 loss 0.0090 (0.0462) acc@1 1.0000 (0.9881) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-13 16:36:24] __main__ INFO: \u001b[0mEpoch 1 Step 703/703 lr 0.001000 loss 0.0088 (0.0461) acc@1 1.0000 (0.9881) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-13 16:36:24] __main__ INFO: \u001b[0mElapsed 226.86\n",
      "\u001b[32m[2020-07-13 16:36:24] __main__ INFO: \u001b[0mVal 1\n",
      "\u001b[32m[2020-07-13 16:36:32] __main__ INFO: \u001b[0mEpoch 1 loss 0.2301 acc@1 0.9402 acc@5 0.9956\n",
      "\u001b[32m[2020-07-13 16:36:32] __main__ INFO: \u001b[0mElapsed 7.85\n",
      "\u001b[32m[2020-07-13 16:36:32] __main__ INFO: \u001b[0mTrain 2 703\n",
      "\u001b[32m[2020-07-13 16:37:05] __main__ INFO: \u001b[0mEpoch 2 Step 100/703 lr 0.001000 loss 0.0065 (0.0305) acc@1 1.0000 (0.9927) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:37:37] __main__ INFO: \u001b[0mEpoch 2 Step 200/703 lr 0.001000 loss 0.0071 (0.0310) acc@1 1.0000 (0.9920) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:38:09] __main__ INFO: \u001b[0mEpoch 2 Step 300/703 lr 0.001000 loss 0.0066 (0.0299) acc@1 1.0000 (0.9921) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-13 16:38:41] __main__ INFO: \u001b[0mEpoch 2 Step 400/703 lr 0.001000 loss 0.0059 (0.0290) acc@1 1.0000 (0.9921) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-13 16:39:13] __main__ INFO: \u001b[0mEpoch 2 Step 500/703 lr 0.001000 loss 0.0039 (0.0291) acc@1 1.0000 (0.9921) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-13 16:39:45] __main__ INFO: \u001b[0mEpoch 2 Step 600/703 lr 0.001000 loss 0.0258 (0.0287) acc@1 0.9844 (0.9921) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-13 16:40:18] __main__ INFO: \u001b[0mEpoch 2 Step 700/703 lr 0.001000 loss 0.0600 (0.0291) acc@1 0.9844 (0.9918) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:40:19] __main__ INFO: \u001b[0mEpoch 2 Step 703/703 lr 0.001000 loss 0.0889 (0.0291) acc@1 0.9844 (0.9918) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:40:19] __main__ INFO: \u001b[0mElapsed 226.29\n",
      "\u001b[32m[2020-07-13 16:40:19] __main__ INFO: \u001b[0mVal 2\n",
      "\u001b[32m[2020-07-13 16:40:26] __main__ INFO: \u001b[0mEpoch 2 loss 0.2246 acc@1 0.9442 acc@5 0.9964\n",
      "\u001b[32m[2020-07-13 16:40:26] __main__ INFO: \u001b[0mElapsed 7.87\n",
      "\u001b[32m[2020-07-13 16:40:26] __main__ INFO: \u001b[0mTrain 3 1406\n",
      "\u001b[32m[2020-07-13 16:40:59] __main__ INFO: \u001b[0mEpoch 3 Step 100/703 lr 0.001000 loss 0.0250 (0.0188) acc@1 0.9844 (0.9953) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:41:31] __main__ INFO: \u001b[0mEpoch 3 Step 200/703 lr 0.001000 loss 0.0046 (0.0195) acc@1 1.0000 (0.9952) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:42:03] __main__ INFO: \u001b[0mEpoch 3 Step 300/703 lr 0.001000 loss 0.0059 (0.0205) acc@1 1.0000 (0.9946) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:42:35] __main__ INFO: \u001b[0mEpoch 3 Step 400/703 lr 0.001000 loss 0.0030 (0.0210) acc@1 1.0000 (0.9941) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:43:07] __main__ INFO: \u001b[0mEpoch 3 Step 500/703 lr 0.001000 loss 0.0129 (0.0214) acc@1 1.0000 (0.9938) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:43:40] __main__ INFO: \u001b[0mEpoch 3 Step 600/703 lr 0.001000 loss 0.0089 (0.0222) acc@1 1.0000 (0.9936) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:44:12] __main__ INFO: \u001b[0mEpoch 3 Step 700/703 lr 0.001000 loss 0.0215 (0.0225) acc@1 0.9844 (0.9934) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:44:13] __main__ INFO: \u001b[0mEpoch 3 Step 703/703 lr 0.001000 loss 0.0283 (0.0226) acc@1 0.9844 (0.9933) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:44:13] __main__ INFO: \u001b[0mElapsed 226.35\n",
      "\u001b[32m[2020-07-13 16:44:13] __main__ INFO: \u001b[0mVal 3\n",
      "\u001b[32m[2020-07-13 16:44:21] __main__ INFO: \u001b[0mEpoch 3 loss 0.2409 acc@1 0.9402 acc@5 0.9968\n",
      "\u001b[32m[2020-07-13 16:44:21] __main__ INFO: \u001b[0mElapsed 7.81\n",
      "\u001b[32m[2020-07-13 16:44:21] __main__ INFO: \u001b[0mTrain 4 2109\n",
      "\u001b[32m[2020-07-13 16:44:53] __main__ INFO: \u001b[0mEpoch 4 Step 100/703 lr 0.001000 loss 0.0282 (0.0233) acc@1 0.9844 (0.9922) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:45:25] __main__ INFO: \u001b[0mEpoch 4 Step 200/703 lr 0.001000 loss 0.0555 (0.0206) acc@1 0.9844 (0.9935) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:45:57] __main__ INFO: \u001b[0mEpoch 4 Step 300/703 lr 0.001000 loss 0.0242 (0.0216) acc@1 0.9844 (0.9934) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:46:29] __main__ INFO: \u001b[0mEpoch 4 Step 400/703 lr 0.001000 loss 0.0031 (0.0211) acc@1 1.0000 (0.9939) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:47:01] __main__ INFO: \u001b[0mEpoch 4 Step 500/703 lr 0.001000 loss 0.1165 (0.0211) acc@1 0.9844 (0.9939) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:47:33] __main__ INFO: \u001b[0mEpoch 4 Step 600/703 lr 0.001000 loss 0.0063 (0.0207) acc@1 1.0000 (0.9939) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:48:05] __main__ INFO: \u001b[0mEpoch 4 Step 700/703 lr 0.001000 loss 0.0293 (0.0202) acc@1 0.9844 (0.9941) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:48:06] __main__ INFO: \u001b[0mEpoch 4 Step 703/703 lr 0.001000 loss 0.0039 (0.0202) acc@1 1.0000 (0.9941) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:48:06] __main__ INFO: \u001b[0mElapsed 225.63\n",
      "\u001b[32m[2020-07-13 16:48:06] __main__ INFO: \u001b[0mVal 4\n",
      "\u001b[32m[2020-07-13 16:48:14] __main__ INFO: \u001b[0mEpoch 4 loss 0.2424 acc@1 0.9434 acc@5 0.9968\n",
      "\u001b[32m[2020-07-13 16:48:14] __main__ INFO: \u001b[0mElapsed 7.81\n",
      "\u001b[32m[2020-07-13 16:48:14] __main__ INFO: \u001b[0mTrain 5 2812\n",
      "\u001b[32m[2020-07-13 16:48:46] __main__ INFO: \u001b[0mEpoch 5 Step 100/703 lr 0.001000 loss 0.0047 (0.0209) acc@1 1.0000 (0.9941) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:49:18] __main__ INFO: \u001b[0mEpoch 5 Step 200/703 lr 0.001000 loss 0.0349 (0.0200) acc@1 0.9844 (0.9942) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-13 16:49:50] __main__ INFO: \u001b[0mEpoch 5 Step 300/703 lr 0.001000 loss 0.0568 (0.0182) acc@1 0.9844 (0.9948) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-13 16:50:23] __main__ INFO: \u001b[0mEpoch 5 Step 400/703 lr 0.001000 loss 0.0182 (0.0180) acc@1 1.0000 (0.9950) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:50:55] __main__ INFO: \u001b[0mEpoch 5 Step 500/703 lr 0.001000 loss 0.0123 (0.0169) acc@1 1.0000 (0.9954) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:51:27] __main__ INFO: \u001b[0mEpoch 5 Step 600/703 lr 0.001000 loss 0.0490 (0.0172) acc@1 0.9844 (0.9951) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:51:59] __main__ INFO: \u001b[0mEpoch 5 Step 700/703 lr 0.001000 loss 0.0522 (0.0178) acc@1 0.9844 (0.9950) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:52:00] __main__ INFO: \u001b[0mEpoch 5 Step 703/703 lr 0.001000 loss 0.0172 (0.0178) acc@1 1.0000 (0.9950) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:52:00] __main__ INFO: \u001b[0mElapsed 225.59\n",
      "\u001b[32m[2020-07-13 16:52:00] __main__ INFO: \u001b[0mVal 5\n",
      "\u001b[32m[2020-07-13 16:52:07] __main__ INFO: \u001b[0mEpoch 5 loss 0.2458 acc@1 0.9412 acc@5 0.9962\n",
      "\u001b[32m[2020-07-13 16:52:07] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-13 16:52:07] __main__ INFO: \u001b[0mTrain 6 3515\n",
      "\u001b[32m[2020-07-13 16:52:40] __main__ INFO: \u001b[0mEpoch 6 Step 100/703 lr 0.001000 loss 0.0083 (0.0124) acc@1 1.0000 (0.9966) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:53:12] __main__ INFO: \u001b[0mEpoch 6 Step 200/703 lr 0.001000 loss 0.0024 (0.0132) acc@1 1.0000 (0.9964) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:53:44] __main__ INFO: \u001b[0mEpoch 6 Step 300/703 lr 0.001000 loss 0.0987 (0.0146) acc@1 0.9688 (0.9956) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:54:16] __main__ INFO: \u001b[0mEpoch 6 Step 400/703 lr 0.001000 loss 0.0042 (0.0144) acc@1 1.0000 (0.9956) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:54:48] __main__ INFO: \u001b[0mEpoch 6 Step 500/703 lr 0.001000 loss 0.0106 (0.0153) acc@1 1.0000 (0.9954) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:55:20] __main__ INFO: \u001b[0mEpoch 6 Step 600/703 lr 0.001000 loss 0.0116 (0.0154) acc@1 1.0000 (0.9953) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:55:52] __main__ INFO: \u001b[0mEpoch 6 Step 700/703 lr 0.001000 loss 0.0097 (0.0150) acc@1 1.0000 (0.9954) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:55:53] __main__ INFO: \u001b[0mEpoch 6 Step 703/703 lr 0.001000 loss 0.0044 (0.0150) acc@1 1.0000 (0.9954) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:55:53] __main__ INFO: \u001b[0mElapsed 225.72\n",
      "\u001b[32m[2020-07-13 16:55:53] __main__ INFO: \u001b[0mVal 6\n",
      "\u001b[32m[2020-07-13 16:56:01] __main__ INFO: \u001b[0mEpoch 6 loss 0.2507 acc@1 0.9442 acc@5 0.9954\n",
      "\u001b[32m[2020-07-13 16:56:01] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-13 16:56:01] __main__ INFO: \u001b[0mTrain 7 4218\n",
      "\u001b[32m[2020-07-13 16:56:33] __main__ INFO: \u001b[0mEpoch 7 Step 100/703 lr 0.001000 loss 0.0059 (0.0109) acc@1 1.0000 (0.9964) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:57:05] __main__ INFO: \u001b[0mEpoch 7 Step 200/703 lr 0.001000 loss 0.0030 (0.0131) acc@1 1.0000 (0.9959) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:57:37] __main__ INFO: \u001b[0mEpoch 7 Step 300/703 lr 0.001000 loss 0.0037 (0.0130) acc@1 1.0000 (0.9962) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:58:10] __main__ INFO: \u001b[0mEpoch 7 Step 400/703 lr 0.001000 loss 0.0136 (0.0126) acc@1 1.0000 (0.9964) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:58:42] __main__ INFO: \u001b[0mEpoch 7 Step 500/703 lr 0.001000 loss 0.0133 (0.0135) acc@1 1.0000 (0.9962) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:59:14] __main__ INFO: \u001b[0mEpoch 7 Step 600/703 lr 0.001000 loss 0.0019 (0.0135) acc@1 1.0000 (0.9962) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:59:46] __main__ INFO: \u001b[0mEpoch 7 Step 700/703 lr 0.001000 loss 0.0115 (0.0135) acc@1 1.0000 (0.9963) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:59:47] __main__ INFO: \u001b[0mEpoch 7 Step 703/703 lr 0.001000 loss 0.0038 (0.0134) acc@1 1.0000 (0.9963) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 16:59:47] __main__ INFO: \u001b[0mElapsed 225.87\n",
      "\u001b[32m[2020-07-13 16:59:47] __main__ INFO: \u001b[0mVal 7\n",
      "\u001b[32m[2020-07-13 16:59:55] __main__ INFO: \u001b[0mEpoch 7 loss 0.2542 acc@1 0.9434 acc@5 0.9954\n",
      "\u001b[32m[2020-07-13 16:59:55] __main__ INFO: \u001b[0mElapsed 7.86\n",
      "\u001b[32m[2020-07-13 16:59:55] __main__ INFO: \u001b[0mTrain 8 4921\n",
      "\u001b[32m[2020-07-13 17:00:27] __main__ INFO: \u001b[0mEpoch 8 Step 100/703 lr 0.001000 loss 0.0023 (0.0087) acc@1 1.0000 (0.9980) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:00:59] __main__ INFO: \u001b[0mEpoch 8 Step 200/703 lr 0.001000 loss 0.0742 (0.0090) acc@1 0.9844 (0.9979) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:01:31] __main__ INFO: \u001b[0mEpoch 8 Step 300/703 lr 0.001000 loss 0.0054 (0.0109) acc@1 1.0000 (0.9973) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:02:03] __main__ INFO: \u001b[0mEpoch 8 Step 400/703 lr 0.001000 loss 0.0031 (0.0112) acc@1 1.0000 (0.9971) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:02:35] __main__ INFO: \u001b[0mEpoch 8 Step 500/703 lr 0.001000 loss 0.0083 (0.0110) acc@1 1.0000 (0.9972) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:03:08] __main__ INFO: \u001b[0mEpoch 8 Step 600/703 lr 0.001000 loss 0.0041 (0.0112) acc@1 1.0000 (0.9971) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:03:40] __main__ INFO: \u001b[0mEpoch 8 Step 700/703 lr 0.001000 loss 0.0075 (0.0112) acc@1 1.0000 (0.9971) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:03:41] __main__ INFO: \u001b[0mEpoch 8 Step 703/703 lr 0.001000 loss 0.0029 (0.0112) acc@1 1.0000 (0.9971) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:03:41] __main__ INFO: \u001b[0mElapsed 226.00\n",
      "\u001b[32m[2020-07-13 17:03:41] __main__ INFO: \u001b[0mVal 8\n",
      "\u001b[32m[2020-07-13 17:03:48] __main__ INFO: \u001b[0mEpoch 8 loss 0.2591 acc@1 0.9428 acc@5 0.9950\n",
      "\u001b[32m[2020-07-13 17:03:48] __main__ INFO: \u001b[0mElapsed 7.81\n",
      "\u001b[32m[2020-07-13 17:03:48] __main__ INFO: \u001b[0mTrain 9 5624\n",
      "\u001b[32m[2020-07-13 17:04:21] __main__ INFO: \u001b[0mEpoch 9 Step 100/703 lr 0.001000 loss 0.0046 (0.0135) acc@1 1.0000 (0.9961) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:04:53] __main__ INFO: \u001b[0mEpoch 9 Step 200/703 lr 0.001000 loss 0.0063 (0.0117) acc@1 1.0000 (0.9968) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:05:25] __main__ INFO: \u001b[0mEpoch 9 Step 300/703 lr 0.001000 loss 0.0049 (0.0116) acc@1 1.0000 (0.9969) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:05:57] __main__ INFO: \u001b[0mEpoch 9 Step 400/703 lr 0.001000 loss 0.0023 (0.0117) acc@1 1.0000 (0.9968) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:06:29] __main__ INFO: \u001b[0mEpoch 9 Step 500/703 lr 0.001000 loss 0.0032 (0.0123) acc@1 1.0000 (0.9967) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:07:02] __main__ INFO: \u001b[0mEpoch 9 Step 600/703 lr 0.001000 loss 0.0016 (0.0123) acc@1 1.0000 (0.9967) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:07:34] __main__ INFO: \u001b[0mEpoch 9 Step 700/703 lr 0.001000 loss 0.0039 (0.0121) acc@1 1.0000 (0.9968) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:07:35] __main__ INFO: \u001b[0mEpoch 9 Step 703/703 lr 0.001000 loss 0.0025 (0.0121) acc@1 1.0000 (0.9968) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:07:35] __main__ INFO: \u001b[0mElapsed 226.18\n",
      "\u001b[32m[2020-07-13 17:07:35] __main__ INFO: \u001b[0mVal 9\n",
      "\u001b[32m[2020-07-13 17:07:43] __main__ INFO: \u001b[0mEpoch 9 loss 0.2519 acc@1 0.9454 acc@5 0.9952\n",
      "\u001b[32m[2020-07-13 17:07:43] __main__ INFO: \u001b[0mElapsed 7.88\n",
      "\u001b[32m[2020-07-13 17:07:43] __main__ INFO: \u001b[0mTrain 10 6327\n",
      "\u001b[32m[2020-07-13 17:08:15] __main__ INFO: \u001b[0mEpoch 10 Step 100/703 lr 0.001000 loss 0.0055 (0.0100) acc@1 1.0000 (0.9969) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:08:47] __main__ INFO: \u001b[0mEpoch 10 Step 200/703 lr 0.001000 loss 0.0035 (0.0116) acc@1 1.0000 (0.9965) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:09:19] __main__ INFO: \u001b[0mEpoch 10 Step 300/703 lr 0.001000 loss 0.0028 (0.0108) acc@1 1.0000 (0.9968) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:09:51] __main__ INFO: \u001b[0mEpoch 10 Step 400/703 lr 0.001000 loss 0.0124 (0.0109) acc@1 1.0000 (0.9970) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:10:23] __main__ INFO: \u001b[0mEpoch 10 Step 500/703 lr 0.001000 loss 0.0749 (0.0111) acc@1 0.9688 (0.9967) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:10:56] __main__ INFO: \u001b[0mEpoch 10 Step 600/703 lr 0.001000 loss 0.0081 (0.0112) acc@1 1.0000 (0.9967) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:11:28] __main__ INFO: \u001b[0mEpoch 10 Step 700/703 lr 0.001000 loss 0.0026 (0.0108) acc@1 1.0000 (0.9968) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:11:29] __main__ INFO: \u001b[0mEpoch 10 Step 703/703 lr 0.001000 loss 0.0057 (0.0110) acc@1 1.0000 (0.9968) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:11:29] __main__ INFO: \u001b[0mElapsed 226.21\n",
      "\u001b[32m[2020-07-13 17:11:29] __main__ INFO: \u001b[0mVal 10\n",
      "\u001b[32m[2020-07-13 17:11:37] __main__ INFO: \u001b[0mEpoch 10 loss 0.2626 acc@1 0.9430 acc@5 0.9952\n",
      "\u001b[32m[2020-07-13 17:11:37] __main__ INFO: \u001b[0mElapsed 7.80\n",
      "\u001b[32m[2020-07-13 17:11:37] __main__ INFO: \u001b[0mTrain 11 7030\n",
      "\u001b[32m[2020-07-13 17:12:09] __main__ INFO: \u001b[0mEpoch 11 Step 100/703 lr 0.001000 loss 0.0024 (0.0104) acc@1 1.0000 (0.9975) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:12:41] __main__ INFO: \u001b[0mEpoch 11 Step 200/703 lr 0.001000 loss 0.0028 (0.0089) acc@1 1.0000 (0.9980) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:13:13] __main__ INFO: \u001b[0mEpoch 11 Step 300/703 lr 0.001000 loss 0.0121 (0.0088) acc@1 1.0000 (0.9978) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:13:45] __main__ INFO: \u001b[0mEpoch 11 Step 400/703 lr 0.001000 loss 0.0042 (0.0086) acc@1 1.0000 (0.9978) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:14:18] __main__ INFO: \u001b[0mEpoch 11 Step 500/703 lr 0.001000 loss 0.0026 (0.0088) acc@1 1.0000 (0.9978) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:14:50] __main__ INFO: \u001b[0mEpoch 11 Step 600/703 lr 0.001000 loss 0.0031 (0.0090) acc@1 1.0000 (0.9977) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:15:22] __main__ INFO: \u001b[0mEpoch 11 Step 700/703 lr 0.001000 loss 0.0023 (0.0093) acc@1 1.0000 (0.9977) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:15:23] __main__ INFO: \u001b[0mEpoch 11 Step 703/703 lr 0.001000 loss 0.0046 (0.0093) acc@1 1.0000 (0.9977) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:15:23] __main__ INFO: \u001b[0mElapsed 226.32\n",
      "\u001b[32m[2020-07-13 17:15:23] __main__ INFO: \u001b[0mVal 11\n",
      "\u001b[32m[2020-07-13 17:15:31] __main__ INFO: \u001b[0mEpoch 11 loss 0.2702 acc@1 0.9420 acc@5 0.9958\n",
      "\u001b[32m[2020-07-13 17:15:31] __main__ INFO: \u001b[0mElapsed 7.86\n",
      "\u001b[32m[2020-07-13 17:15:31] __main__ INFO: \u001b[0mTrain 12 7733\n",
      "\u001b[32m[2020-07-13 17:16:03] __main__ INFO: \u001b[0mEpoch 12 Step 100/703 lr 0.001000 loss 0.0030 (0.0111) acc@1 1.0000 (0.9970) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:16:35] __main__ INFO: \u001b[0mEpoch 12 Step 200/703 lr 0.001000 loss 0.0206 (0.0090) acc@1 0.9844 (0.9974) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:17:07] __main__ INFO: \u001b[0mEpoch 12 Step 300/703 lr 0.001000 loss 0.0053 (0.0091) acc@1 1.0000 (0.9974) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:17:40] __main__ INFO: \u001b[0mEpoch 12 Step 400/703 lr 0.001000 loss 0.0029 (0.0094) acc@1 1.0000 (0.9974) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:18:12] __main__ INFO: \u001b[0mEpoch 12 Step 500/703 lr 0.001000 loss 0.0020 (0.0093) acc@1 1.0000 (0.9973) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:18:44] __main__ INFO: \u001b[0mEpoch 12 Step 600/703 lr 0.001000 loss 0.0013 (0.0088) acc@1 1.0000 (0.9976) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:19:16] __main__ INFO: \u001b[0mEpoch 12 Step 700/703 lr 0.001000 loss 0.0267 (0.0090) acc@1 0.9844 (0.9975) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:19:17] __main__ INFO: \u001b[0mEpoch 12 Step 703/703 lr 0.001000 loss 0.0177 (0.0090) acc@1 0.9844 (0.9975) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:19:17] __main__ INFO: \u001b[0mElapsed 226.35\n",
      "\u001b[32m[2020-07-13 17:19:17] __main__ INFO: \u001b[0mVal 12\n",
      "\u001b[32m[2020-07-13 17:19:25] __main__ INFO: \u001b[0mEpoch 12 loss 0.2692 acc@1 0.9436 acc@5 0.9952\n",
      "\u001b[32m[2020-07-13 17:19:25] __main__ INFO: \u001b[0mElapsed 7.82\n",
      "\u001b[32m[2020-07-13 17:19:25] __main__ INFO: \u001b[0mTrain 13 8436\n",
      "\u001b[32m[2020-07-13 17:19:57] __main__ INFO: \u001b[0mEpoch 13 Step 100/703 lr 0.001000 loss 0.0018 (0.0068) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:20:29] __main__ INFO: \u001b[0mEpoch 13 Step 200/703 lr 0.001000 loss 0.0025 (0.0090) acc@1 1.0000 (0.9978) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:21:02] __main__ INFO: \u001b[0mEpoch 13 Step 300/703 lr 0.001000 loss 0.0015 (0.0092) acc@1 1.0000 (0.9976) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:21:34] __main__ INFO: \u001b[0mEpoch 13 Step 400/703 lr 0.001000 loss 0.0746 (0.0096) acc@1 0.9844 (0.9975) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:22:06] __main__ INFO: \u001b[0mEpoch 13 Step 500/703 lr 0.001000 loss 0.0053 (0.0101) acc@1 1.0000 (0.9974) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:22:38] __main__ INFO: \u001b[0mEpoch 13 Step 600/703 lr 0.001000 loss 0.0026 (0.0097) acc@1 1.0000 (0.9975) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:23:11] __main__ INFO: \u001b[0mEpoch 13 Step 700/703 lr 0.001000 loss 0.0027 (0.0100) acc@1 1.0000 (0.9974) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:23:12] __main__ INFO: \u001b[0mEpoch 13 Step 703/703 lr 0.001000 loss 0.0358 (0.0100) acc@1 0.9844 (0.9974) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:23:12] __main__ INFO: \u001b[0mElapsed 226.61\n",
      "\u001b[32m[2020-07-13 17:23:12] __main__ INFO: \u001b[0mVal 13\n",
      "\u001b[32m[2020-07-13 17:23:19] __main__ INFO: \u001b[0mEpoch 13 loss 0.2646 acc@1 0.9422 acc@5 0.9964\n",
      "\u001b[32m[2020-07-13 17:23:19] __main__ INFO: \u001b[0mElapsed 7.88\n",
      "\u001b[32m[2020-07-13 17:23:19] __main__ INFO: \u001b[0mTrain 14 9139\n",
      "\u001b[32m[2020-07-13 17:23:52] __main__ INFO: \u001b[0mEpoch 14 Step 100/703 lr 0.001000 loss 0.0087 (0.0100) acc@1 1.0000 (0.9964) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:24:24] __main__ INFO: \u001b[0mEpoch 14 Step 200/703 lr 0.001000 loss 0.0542 (0.0096) acc@1 0.9844 (0.9969) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:24:56] __main__ INFO: \u001b[0mEpoch 14 Step 300/703 lr 0.001000 loss 0.0034 (0.0095) acc@1 1.0000 (0.9971) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:25:28] __main__ INFO: \u001b[0mEpoch 14 Step 400/703 lr 0.001000 loss 0.0107 (0.0090) acc@1 1.0000 (0.9973) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:26:00] __main__ INFO: \u001b[0mEpoch 14 Step 500/703 lr 0.001000 loss 0.0154 (0.0092) acc@1 0.9844 (0.9973) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:26:32] __main__ INFO: \u001b[0mEpoch 14 Step 600/703 lr 0.001000 loss 0.0027 (0.0090) acc@1 1.0000 (0.9974) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:27:04] __main__ INFO: \u001b[0mEpoch 14 Step 700/703 lr 0.001000 loss 0.0029 (0.0089) acc@1 1.0000 (0.9975) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:27:05] __main__ INFO: \u001b[0mEpoch 14 Step 703/703 lr 0.001000 loss 0.0023 (0.0089) acc@1 1.0000 (0.9976) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:27:05] __main__ INFO: \u001b[0mElapsed 225.87\n",
      "\u001b[32m[2020-07-13 17:27:05] __main__ INFO: \u001b[0mVal 14\n",
      "\u001b[32m[2020-07-13 17:27:13] __main__ INFO: \u001b[0mEpoch 14 loss 0.2786 acc@1 0.9410 acc@5 0.9950\n",
      "\u001b[32m[2020-07-13 17:27:13] __main__ INFO: \u001b[0mElapsed 7.86\n",
      "\u001b[32m[2020-07-13 17:27:13] __main__ INFO: \u001b[0mTrain 15 9842\n",
      "\u001b[32m[2020-07-13 17:27:45] __main__ INFO: \u001b[0mEpoch 15 Step 100/703 lr 0.001000 loss 0.0060 (0.0109) acc@1 1.0000 (0.9978) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:28:18] __main__ INFO: \u001b[0mEpoch 15 Step 200/703 lr 0.001000 loss 0.0065 (0.0091) acc@1 1.0000 (0.9980) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:28:50] __main__ INFO: \u001b[0mEpoch 15 Step 300/703 lr 0.001000 loss 0.0018 (0.0088) acc@1 1.0000 (0.9979) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:29:22] __main__ INFO: \u001b[0mEpoch 15 Step 400/703 lr 0.001000 loss 0.0270 (0.0087) acc@1 0.9844 (0.9979) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:29:54] __main__ INFO: \u001b[0mEpoch 15 Step 500/703 lr 0.001000 loss 0.0663 (0.0089) acc@1 0.9844 (0.9976) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:30:26] __main__ INFO: \u001b[0mEpoch 15 Step 600/703 lr 0.001000 loss 0.0016 (0.0087) acc@1 1.0000 (0.9977) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:30:58] __main__ INFO: \u001b[0mEpoch 15 Step 700/703 lr 0.001000 loss 0.0094 (0.0086) acc@1 1.0000 (0.9977) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:30:59] __main__ INFO: \u001b[0mEpoch 15 Step 703/703 lr 0.001000 loss 0.0052 (0.0087) acc@1 1.0000 (0.9977) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:30:59] __main__ INFO: \u001b[0mElapsed 225.91\n",
      "\u001b[32m[2020-07-13 17:30:59] __main__ INFO: \u001b[0mVal 15\n",
      "\u001b[32m[2020-07-13 17:31:07] __main__ INFO: \u001b[0mEpoch 15 loss 0.2815 acc@1 0.9398 acc@5 0.9960\n",
      "\u001b[32m[2020-07-13 17:31:07] __main__ INFO: \u001b[0mElapsed 7.85\n",
      "\u001b[32m[2020-07-13 17:31:07] __main__ INFO: \u001b[0mTrain 16 10545\n",
      "\u001b[32m[2020-07-13 17:31:39] __main__ INFO: \u001b[0mEpoch 16 Step 100/703 lr 0.001000 loss 0.0020 (0.0065) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:32:11] __main__ INFO: \u001b[0mEpoch 16 Step 200/703 lr 0.001000 loss 0.0141 (0.0080) acc@1 1.0000 (0.9978) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:32:43] __main__ INFO: \u001b[0mEpoch 16 Step 300/703 lr 0.001000 loss 0.0020 (0.0075) acc@1 1.0000 (0.9981) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:33:15] __main__ INFO: \u001b[0mEpoch 16 Step 400/703 lr 0.001000 loss 0.0016 (0.0079) acc@1 1.0000 (0.9978) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:33:47] __main__ INFO: \u001b[0mEpoch 16 Step 500/703 lr 0.001000 loss 0.0017 (0.0082) acc@1 1.0000 (0.9978) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:34:19] __main__ INFO: \u001b[0mEpoch 16 Step 600/703 lr 0.001000 loss 0.0018 (0.0086) acc@1 1.0000 (0.9977) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:34:51] __main__ INFO: \u001b[0mEpoch 16 Step 700/703 lr 0.001000 loss 0.0123 (0.0080) acc@1 1.0000 (0.9979) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:34:52] __main__ INFO: \u001b[0mEpoch 16 Step 703/703 lr 0.001000 loss 0.0030 (0.0081) acc@1 1.0000 (0.9979) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:34:52] __main__ INFO: \u001b[0mElapsed 225.52\n",
      "\u001b[32m[2020-07-13 17:34:52] __main__ INFO: \u001b[0mVal 16\n",
      "\u001b[32m[2020-07-13 17:35:00] __main__ INFO: \u001b[0mEpoch 16 loss 0.2727 acc@1 0.9410 acc@5 0.9952\n",
      "\u001b[32m[2020-07-13 17:35:00] __main__ INFO: \u001b[0mElapsed 7.83\n",
      "\u001b[32m[2020-07-13 17:35:00] __main__ INFO: \u001b[0mTrain 17 11248\n",
      "\u001b[32m[2020-07-13 17:35:32] __main__ INFO: \u001b[0mEpoch 17 Step 100/703 lr 0.001000 loss 0.0032 (0.0083) acc@1 1.0000 (0.9981) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:36:04] __main__ INFO: \u001b[0mEpoch 17 Step 200/703 lr 0.001000 loss 0.0021 (0.0088) acc@1 1.0000 (0.9980) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:36:36] __main__ INFO: \u001b[0mEpoch 17 Step 300/703 lr 0.001000 loss 0.0019 (0.0087) acc@1 1.0000 (0.9982) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:37:09] __main__ INFO: \u001b[0mEpoch 17 Step 400/703 lr 0.001000 loss 0.0095 (0.0084) acc@1 1.0000 (0.9981) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:37:41] __main__ INFO: \u001b[0mEpoch 17 Step 500/703 lr 0.001000 loss 0.0039 (0.0085) acc@1 1.0000 (0.9981) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:38:13] __main__ INFO: \u001b[0mEpoch 17 Step 600/703 lr 0.001000 loss 0.0020 (0.0085) acc@1 1.0000 (0.9980) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:38:45] __main__ INFO: \u001b[0mEpoch 17 Step 700/703 lr 0.001000 loss 0.0024 (0.0084) acc@1 1.0000 (0.9979) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:38:46] __main__ INFO: \u001b[0mEpoch 17 Step 703/703 lr 0.001000 loss 0.0020 (0.0083) acc@1 1.0000 (0.9979) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:38:46] __main__ INFO: \u001b[0mElapsed 225.53\n",
      "\u001b[32m[2020-07-13 17:38:46] __main__ INFO: \u001b[0mVal 17\n",
      "\u001b[32m[2020-07-13 17:38:54] __main__ INFO: \u001b[0mEpoch 17 loss 0.2737 acc@1 0.9432 acc@5 0.9956\n",
      "\u001b[32m[2020-07-13 17:38:54] __main__ INFO: \u001b[0mElapsed 7.84\n",
      "\u001b[32m[2020-07-13 17:38:54] __main__ INFO: \u001b[0mTrain 18 11951\n",
      "\u001b[32m[2020-07-13 17:39:26] __main__ INFO: \u001b[0mEpoch 18 Step 100/703 lr 0.001000 loss 0.0319 (0.0072) acc@1 0.9844 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:39:58] __main__ INFO: \u001b[0mEpoch 18 Step 200/703 lr 0.001000 loss 0.0033 (0.0058) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:40:30] __main__ INFO: \u001b[0mEpoch 18 Step 300/703 lr 0.001000 loss 0.0024 (0.0063) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:41:02] __main__ INFO: \u001b[0mEpoch 18 Step 400/703 lr 0.001000 loss 0.0017 (0.0064) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:41:34] __main__ INFO: \u001b[0mEpoch 18 Step 500/703 lr 0.001000 loss 0.0068 (0.0072) acc@1 1.0000 (0.9982) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:42:06] __main__ INFO: \u001b[0mEpoch 18 Step 600/703 lr 0.001000 loss 0.0018 (0.0071) acc@1 1.0000 (0.9983) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:42:38] __main__ INFO: \u001b[0mEpoch 18 Step 700/703 lr 0.001000 loss 0.0015 (0.0071) acc@1 1.0000 (0.9982) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:42:39] __main__ INFO: \u001b[0mEpoch 18 Step 703/703 lr 0.001000 loss 0.0020 (0.0071) acc@1 1.0000 (0.9982) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:42:39] __main__ INFO: \u001b[0mElapsed 225.63\n",
      "\u001b[32m[2020-07-13 17:42:39] __main__ INFO: \u001b[0mVal 18\n",
      "\u001b[32m[2020-07-13 17:42:47] __main__ INFO: \u001b[0mEpoch 18 loss 0.2749 acc@1 0.9446 acc@5 0.9954\n",
      "\u001b[32m[2020-07-13 17:42:47] __main__ INFO: \u001b[0mElapsed 7.83\n",
      "\u001b[32m[2020-07-13 17:42:47] __main__ INFO: \u001b[0mTrain 19 12654\n",
      "\u001b[32m[2020-07-13 17:43:19] __main__ INFO: \u001b[0mEpoch 19 Step 100/703 lr 0.001000 loss 0.0054 (0.0085) acc@1 1.0000 (0.9973) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:43:51] __main__ INFO: \u001b[0mEpoch 19 Step 200/703 lr 0.001000 loss 0.0020 (0.0074) acc@1 1.0000 (0.9979) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:44:24] __main__ INFO: \u001b[0mEpoch 19 Step 300/703 lr 0.001000 loss 0.0024 (0.0071) acc@1 1.0000 (0.9981) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:44:56] __main__ INFO: \u001b[0mEpoch 19 Step 400/703 lr 0.001000 loss 0.0017 (0.0074) acc@1 1.0000 (0.9980) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:45:28] __main__ INFO: \u001b[0mEpoch 19 Step 500/703 lr 0.001000 loss 0.0020 (0.0073) acc@1 1.0000 (0.9981) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:46:00] __main__ INFO: \u001b[0mEpoch 19 Step 600/703 lr 0.001000 loss 0.0021 (0.0068) acc@1 1.0000 (0.9983) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:46:32] __main__ INFO: \u001b[0mEpoch 19 Step 700/703 lr 0.001000 loss 0.0012 (0.0068) acc@1 1.0000 (0.9983) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:46:33] __main__ INFO: \u001b[0mEpoch 19 Step 703/703 lr 0.001000 loss 0.0011 (0.0068) acc@1 1.0000 (0.9983) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:46:33] __main__ INFO: \u001b[0mElapsed 225.61\n",
      "\u001b[32m[2020-07-13 17:46:33] __main__ INFO: \u001b[0mVal 19\n",
      "\u001b[32m[2020-07-13 17:46:41] __main__ INFO: \u001b[0mEpoch 19 loss 0.2747 acc@1 0.9452 acc@5 0.9950\n",
      "\u001b[32m[2020-07-13 17:46:41] __main__ INFO: \u001b[0mElapsed 7.80\n",
      "\u001b[32m[2020-07-13 17:46:41] __main__ INFO: \u001b[0mTrain 20 13357\n",
      "\u001b[32m[2020-07-13 17:47:13] __main__ INFO: \u001b[0mEpoch 20 Step 100/703 lr 0.001000 loss 0.0029 (0.0074) acc@1 1.0000 (0.9983) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:47:45] __main__ INFO: \u001b[0mEpoch 20 Step 200/703 lr 0.001000 loss 0.0017 (0.0057) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:48:16] __main__ INFO: \u001b[0mEpoch 20 Step 300/703 lr 0.001000 loss 0.0012 (0.0057) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:48:48] __main__ INFO: \u001b[0mEpoch 20 Step 400/703 lr 0.001000 loss 0.0242 (0.0062) acc@1 0.9844 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:49:20] __main__ INFO: \u001b[0mEpoch 20 Step 500/703 lr 0.001000 loss 0.0047 (0.0067) acc@1 1.0000 (0.9983) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:49:52] __main__ INFO: \u001b[0mEpoch 20 Step 600/703 lr 0.001000 loss 0.0065 (0.0072) acc@1 1.0000 (0.9981) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:50:24] __main__ INFO: \u001b[0mEpoch 20 Step 700/703 lr 0.001000 loss 0.0682 (0.0075) acc@1 0.9844 (0.9980) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:50:25] __main__ INFO: \u001b[0mEpoch 20 Step 703/703 lr 0.001000 loss 0.0165 (0.0075) acc@1 0.9844 (0.9980) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:50:25] __main__ INFO: \u001b[0mElapsed 224.92\n",
      "\u001b[32m[2020-07-13 17:50:25] __main__ INFO: \u001b[0mVal 20\n",
      "\u001b[32m[2020-07-13 17:50:33] __main__ INFO: \u001b[0mEpoch 20 loss 0.2649 acc@1 0.9460 acc@5 0.9954\n",
      "\u001b[32m[2020-07-13 17:50:33] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-13 17:50:33] __main__ INFO: \u001b[0mTrain 21 14060\n",
      "\u001b[32m[2020-07-13 17:51:05] __main__ INFO: \u001b[0mEpoch 21 Step 100/703 lr 0.001000 loss 0.0344 (0.0088) acc@1 0.9844 (0.9970) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:51:37] __main__ INFO: \u001b[0mEpoch 21 Step 200/703 lr 0.001000 loss 0.0044 (0.0077) acc@1 1.0000 (0.9977) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:52:09] __main__ INFO: \u001b[0mEpoch 21 Step 300/703 lr 0.001000 loss 0.0104 (0.0079) acc@1 1.0000 (0.9976) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:52:41] __main__ INFO: \u001b[0mEpoch 21 Step 400/703 lr 0.001000 loss 0.0012 (0.0079) acc@1 1.0000 (0.9977) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:53:13] __main__ INFO: \u001b[0mEpoch 21 Step 500/703 lr 0.001000 loss 0.0022 (0.0075) acc@1 1.0000 (0.9978) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:53:46] __main__ INFO: \u001b[0mEpoch 21 Step 600/703 lr 0.001000 loss 0.0018 (0.0070) acc@1 1.0000 (0.9980) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:54:18] __main__ INFO: \u001b[0mEpoch 21 Step 700/703 lr 0.001000 loss 0.0013 (0.0067) acc@1 1.0000 (0.9981) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:54:18] __main__ INFO: \u001b[0mEpoch 21 Step 703/703 lr 0.001000 loss 0.0019 (0.0068) acc@1 1.0000 (0.9981) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:54:19] __main__ INFO: \u001b[0mElapsed 225.28\n",
      "\u001b[32m[2020-07-13 17:54:19] __main__ INFO: \u001b[0mVal 21\n",
      "\u001b[32m[2020-07-13 17:54:26] __main__ INFO: \u001b[0mEpoch 21 loss 0.2680 acc@1 0.9458 acc@5 0.9948\n",
      "\u001b[32m[2020-07-13 17:54:26] __main__ INFO: \u001b[0mElapsed 7.79\n",
      "\u001b[32m[2020-07-13 17:54:26] __main__ INFO: \u001b[0mTrain 22 14763\n",
      "\u001b[32m[2020-07-13 17:54:58] __main__ INFO: \u001b[0mEpoch 22 Step 100/703 lr 0.001000 loss 0.0026 (0.0058) acc@1 1.0000 (0.9983) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:55:30] __main__ INFO: \u001b[0mEpoch 22 Step 200/703 lr 0.001000 loss 0.0054 (0.0053) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:56:02] __main__ INFO: \u001b[0mEpoch 22 Step 300/703 lr 0.001000 loss 0.0016 (0.0055) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:56:35] __main__ INFO: \u001b[0mEpoch 22 Step 400/703 lr 0.001000 loss 0.0025 (0.0053) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:57:07] __main__ INFO: \u001b[0mEpoch 22 Step 500/703 lr 0.001000 loss 0.0012 (0.0054) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:57:39] __main__ INFO: \u001b[0mEpoch 22 Step 600/703 lr 0.001000 loss 0.0723 (0.0058) acc@1 0.9844 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:58:11] __main__ INFO: \u001b[0mEpoch 22 Step 700/703 lr 0.001000 loss 0.0017 (0.0062) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:58:12] __main__ INFO: \u001b[0mEpoch 22 Step 703/703 lr 0.001000 loss 0.0010 (0.0062) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:58:12] __main__ INFO: \u001b[0mElapsed 225.46\n",
      "\u001b[32m[2020-07-13 17:58:12] __main__ INFO: \u001b[0mVal 22\n",
      "\u001b[32m[2020-07-13 17:58:20] __main__ INFO: \u001b[0mEpoch 22 loss 0.2693 acc@1 0.9424 acc@5 0.9952\n",
      "\u001b[32m[2020-07-13 17:58:20] __main__ INFO: \u001b[0mElapsed 7.79\n",
      "\u001b[32m[2020-07-13 17:58:20] __main__ INFO: \u001b[0mTrain 23 15466\n",
      "\u001b[32m[2020-07-13 17:58:52] __main__ INFO: \u001b[0mEpoch 23 Step 100/703 lr 0.001000 loss 0.0047 (0.0056) acc@1 1.0000 (0.9980) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:59:24] __main__ INFO: \u001b[0mEpoch 23 Step 200/703 lr 0.001000 loss 0.0014 (0.0054) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 17:59:56] __main__ INFO: \u001b[0mEpoch 23 Step 300/703 lr 0.001000 loss 0.0016 (0.0063) acc@1 1.0000 (0.9981) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:00:28] __main__ INFO: \u001b[0mEpoch 23 Step 400/703 lr 0.001000 loss 0.0014 (0.0066) acc@1 1.0000 (0.9980) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:01:00] __main__ INFO: \u001b[0mEpoch 23 Step 500/703 lr 0.001000 loss 0.0057 (0.0066) acc@1 1.0000 (0.9981) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:01:32] __main__ INFO: \u001b[0mEpoch 23 Step 600/703 lr 0.001000 loss 0.0032 (0.0064) acc@1 1.0000 (0.9981) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:02:04] __main__ INFO: \u001b[0mEpoch 23 Step 700/703 lr 0.001000 loss 0.0063 (0.0068) acc@1 1.0000 (0.9981) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:02:05] __main__ INFO: \u001b[0mEpoch 23 Step 703/703 lr 0.001000 loss 0.0014 (0.0068) acc@1 1.0000 (0.9981) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:02:05] __main__ INFO: \u001b[0mElapsed 225.16\n",
      "\u001b[32m[2020-07-13 18:02:05] __main__ INFO: \u001b[0mVal 23\n",
      "\u001b[32m[2020-07-13 18:02:13] __main__ INFO: \u001b[0mEpoch 23 loss 0.2776 acc@1 0.9440 acc@5 0.9946\n",
      "\u001b[32m[2020-07-13 18:02:13] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-13 18:02:13] __main__ INFO: \u001b[0mTrain 24 16169\n",
      "\u001b[32m[2020-07-13 18:02:45] __main__ INFO: \u001b[0mEpoch 24 Step 100/703 lr 0.001000 loss 0.0020 (0.0057) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:03:17] __main__ INFO: \u001b[0mEpoch 24 Step 200/703 lr 0.001000 loss 0.0017 (0.0053) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:03:49] __main__ INFO: \u001b[0mEpoch 24 Step 300/703 lr 0.001000 loss 0.0047 (0.0056) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:04:21] __main__ INFO: \u001b[0mEpoch 24 Step 400/703 lr 0.001000 loss 0.0019 (0.0055) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:04:53] __main__ INFO: \u001b[0mEpoch 24 Step 500/703 lr 0.001000 loss 0.0145 (0.0059) acc@1 0.9844 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:05:25] __main__ INFO: \u001b[0mEpoch 24 Step 600/703 lr 0.001000 loss 0.0062 (0.0062) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:05:57] __main__ INFO: \u001b[0mEpoch 24 Step 700/703 lr 0.001000 loss 0.0031 (0.0061) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:05:58] __main__ INFO: \u001b[0mEpoch 24 Step 703/703 lr 0.001000 loss 0.0013 (0.0061) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:05:58] __main__ INFO: \u001b[0mElapsed 225.52\n",
      "\u001b[32m[2020-07-13 18:05:58] __main__ INFO: \u001b[0mVal 24\n",
      "\u001b[32m[2020-07-13 18:06:06] __main__ INFO: \u001b[0mEpoch 24 loss 0.2740 acc@1 0.9424 acc@5 0.9950\n",
      "\u001b[32m[2020-07-13 18:06:06] __main__ INFO: \u001b[0mElapsed 7.80\n",
      "\u001b[32m[2020-07-13 18:06:06] __main__ INFO: \u001b[0mTrain 25 16872\n",
      "\u001b[32m[2020-07-13 18:06:38] __main__ INFO: \u001b[0mEpoch 25 Step 100/703 lr 0.001000 loss 0.0074 (0.0053) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:07:10] __main__ INFO: \u001b[0mEpoch 25 Step 200/703 lr 0.001000 loss 0.0191 (0.0054) acc@1 0.9844 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:07:42] __main__ INFO: \u001b[0mEpoch 25 Step 300/703 lr 0.001000 loss 0.0150 (0.0052) acc@1 0.9844 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:08:14] __main__ INFO: \u001b[0mEpoch 25 Step 400/703 lr 0.001000 loss 0.0049 (0.0056) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:08:47] __main__ INFO: \u001b[0mEpoch 25 Step 500/703 lr 0.001000 loss 0.0016 (0.0058) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:09:19] __main__ INFO: \u001b[0mEpoch 25 Step 600/703 lr 0.001000 loss 0.0016 (0.0057) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:09:51] __main__ INFO: \u001b[0mEpoch 25 Step 700/703 lr 0.001000 loss 0.0029 (0.0057) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:09:52] __main__ INFO: \u001b[0mEpoch 25 Step 703/703 lr 0.001000 loss 0.0012 (0.0056) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:09:52] __main__ INFO: \u001b[0mElapsed 225.80\n",
      "\u001b[32m[2020-07-13 18:09:52] __main__ INFO: \u001b[0mVal 25\n",
      "\u001b[32m[2020-07-13 18:09:59] __main__ INFO: \u001b[0mEpoch 25 loss 0.2802 acc@1 0.9440 acc@5 0.9948\n",
      "\u001b[32m[2020-07-13 18:09:59] __main__ INFO: \u001b[0mElapsed 7.82\n",
      "\u001b[32m[2020-07-13 18:09:59] __main__ INFO: \u001b[0mTrain 26 17575\n",
      "\u001b[32m[2020-07-13 18:10:32] __main__ INFO: \u001b[0mEpoch 26 Step 100/703 lr 0.001000 loss 0.0012 (0.0050) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:11:04] __main__ INFO: \u001b[0mEpoch 26 Step 200/703 lr 0.001000 loss 0.0010 (0.0043) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:11:36] __main__ INFO: \u001b[0mEpoch 26 Step 300/703 lr 0.001000 loss 0.0723 (0.0042) acc@1 0.9844 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:12:08] __main__ INFO: \u001b[0mEpoch 26 Step 400/703 lr 0.001000 loss 0.0038 (0.0049) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:12:40] __main__ INFO: \u001b[0mEpoch 26 Step 500/703 lr 0.001000 loss 0.0019 (0.0051) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:13:12] __main__ INFO: \u001b[0mEpoch 26 Step 600/703 lr 0.001000 loss 0.0033 (0.0054) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:13:44] __main__ INFO: \u001b[0mEpoch 26 Step 700/703 lr 0.001000 loss 0.0624 (0.0056) acc@1 0.9844 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:13:45] __main__ INFO: \u001b[0mEpoch 26 Step 703/703 lr 0.001000 loss 0.0054 (0.0056) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:13:45] __main__ INFO: \u001b[0mElapsed 225.69\n",
      "\u001b[32m[2020-07-13 18:13:45] __main__ INFO: \u001b[0mVal 26\n",
      "\u001b[32m[2020-07-13 18:13:53] __main__ INFO: \u001b[0mEpoch 26 loss 0.2808 acc@1 0.9438 acc@5 0.9954\n",
      "\u001b[32m[2020-07-13 18:13:53] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-13 18:13:53] __main__ INFO: \u001b[0mTrain 27 18278\n",
      "\u001b[32m[2020-07-13 18:14:25] __main__ INFO: \u001b[0mEpoch 27 Step 100/703 lr 0.001000 loss 0.0009 (0.0049) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:14:57] __main__ INFO: \u001b[0mEpoch 27 Step 200/703 lr 0.001000 loss 0.0043 (0.0058) acc@1 1.0000 (0.9983) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:15:29] __main__ INFO: \u001b[0mEpoch 27 Step 300/703 lr 0.001000 loss 0.0022 (0.0064) acc@1 1.0000 (0.9981) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:16:01] __main__ INFO: \u001b[0mEpoch 27 Step 400/703 lr 0.001000 loss 0.0013 (0.0060) acc@1 1.0000 (0.9981) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:16:33] __main__ INFO: \u001b[0mEpoch 27 Step 500/703 lr 0.001000 loss 0.0031 (0.0056) acc@1 1.0000 (0.9983) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:17:05] __main__ INFO: \u001b[0mEpoch 27 Step 600/703 lr 0.001000 loss 0.0149 (0.0058) acc@1 0.9844 (0.9983) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:17:37] __main__ INFO: \u001b[0mEpoch 27 Step 700/703 lr 0.001000 loss 0.0027 (0.0058) acc@1 1.0000 (0.9983) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:17:38] __main__ INFO: \u001b[0mEpoch 27 Step 703/703 lr 0.001000 loss 0.0016 (0.0058) acc@1 1.0000 (0.9983) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:17:38] __main__ INFO: \u001b[0mElapsed 225.37\n",
      "\u001b[32m[2020-07-13 18:17:38] __main__ INFO: \u001b[0mVal 27\n",
      "\u001b[32m[2020-07-13 18:17:46] __main__ INFO: \u001b[0mEpoch 27 loss 0.2766 acc@1 0.9428 acc@5 0.9962\n",
      "\u001b[32m[2020-07-13 18:17:46] __main__ INFO: \u001b[0mElapsed 7.81\n",
      "\u001b[32m[2020-07-13 18:17:46] __main__ INFO: \u001b[0mTrain 28 18981\n",
      "\u001b[32m[2020-07-13 18:18:18] __main__ INFO: \u001b[0mEpoch 28 Step 100/703 lr 0.001000 loss 0.0020 (0.0041) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:18:50] __main__ INFO: \u001b[0mEpoch 28 Step 200/703 lr 0.001000 loss 0.0019 (0.0043) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:19:23] __main__ INFO: \u001b[0mEpoch 28 Step 300/703 lr 0.001000 loss 0.0032 (0.0045) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:19:55] __main__ INFO: \u001b[0mEpoch 28 Step 400/703 lr 0.001000 loss 0.0050 (0.0052) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:20:27] __main__ INFO: \u001b[0mEpoch 28 Step 500/703 lr 0.001000 loss 0.0009 (0.0051) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:20:59] __main__ INFO: \u001b[0mEpoch 28 Step 600/703 lr 0.001000 loss 0.0067 (0.0049) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:21:31] __main__ INFO: \u001b[0mEpoch 28 Step 700/703 lr 0.001000 loss 0.0030 (0.0050) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:21:32] __main__ INFO: \u001b[0mEpoch 28 Step 703/703 lr 0.001000 loss 0.0020 (0.0050) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:21:32] __main__ INFO: \u001b[0mElapsed 226.04\n",
      "\u001b[32m[2020-07-13 18:21:32] __main__ INFO: \u001b[0mVal 28\n",
      "\u001b[32m[2020-07-13 18:21:40] __main__ INFO: \u001b[0mEpoch 28 loss 0.2774 acc@1 0.9442 acc@5 0.9956\n",
      "\u001b[32m[2020-07-13 18:21:40] __main__ INFO: \u001b[0mElapsed 7.82\n",
      "\u001b[32m[2020-07-13 18:21:40] __main__ INFO: \u001b[0mTrain 29 19684\n",
      "\u001b[32m[2020-07-13 18:22:12] __main__ INFO: \u001b[0mEpoch 29 Step 100/703 lr 0.001000 loss 0.0028 (0.0035) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:22:44] __main__ INFO: \u001b[0mEpoch 29 Step 200/703 lr 0.001000 loss 0.0022 (0.0050) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:23:16] __main__ INFO: \u001b[0mEpoch 29 Step 300/703 lr 0.001000 loss 0.0013 (0.0054) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:23:48] __main__ INFO: \u001b[0mEpoch 29 Step 400/703 lr 0.001000 loss 0.0020 (0.0051) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:24:20] __main__ INFO: \u001b[0mEpoch 29 Step 500/703 lr 0.001000 loss 0.0008 (0.0049) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:24:53] __main__ INFO: \u001b[0mEpoch 29 Step 600/703 lr 0.001000 loss 0.0026 (0.0048) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:25:25] __main__ INFO: \u001b[0mEpoch 29 Step 700/703 lr 0.001000 loss 0.0010 (0.0047) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:25:25] __main__ INFO: \u001b[0mEpoch 29 Step 703/703 lr 0.001000 loss 0.0010 (0.0046) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:25:25] __main__ INFO: \u001b[0mElapsed 225.51\n",
      "\u001b[32m[2020-07-13 18:25:25] __main__ INFO: \u001b[0mVal 29\n",
      "\u001b[32m[2020-07-13 18:25:33] __main__ INFO: \u001b[0mEpoch 29 loss 0.3057 acc@1 0.9432 acc@5 0.9948\n",
      "\u001b[32m[2020-07-13 18:25:33] __main__ INFO: \u001b[0mElapsed 7.80\n",
      "\u001b[32m[2020-07-13 18:25:33] __main__ INFO: \u001b[0mTrain 30 20387\n",
      "\u001b[32m[2020-07-13 18:26:05] __main__ INFO: \u001b[0mEpoch 30 Step 100/703 lr 0.001000 loss 0.0411 (0.0059) acc@1 0.9844 (0.9978) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:26:38] __main__ INFO: \u001b[0mEpoch 30 Step 200/703 lr 0.001000 loss 0.0015 (0.0065) acc@1 1.0000 (0.9980) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:27:10] __main__ INFO: \u001b[0mEpoch 30 Step 300/703 lr 0.001000 loss 0.0036 (0.0065) acc@1 1.0000 (0.9980) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:27:42] __main__ INFO: \u001b[0mEpoch 30 Step 400/703 lr 0.001000 loss 0.0042 (0.0064) acc@1 1.0000 (0.9982) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:28:14] __main__ INFO: \u001b[0mEpoch 30 Step 500/703 lr 0.001000 loss 0.0102 (0.0063) acc@1 1.0000 (0.9982) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:28:46] __main__ INFO: \u001b[0mEpoch 30 Step 600/703 lr 0.001000 loss 0.0447 (0.0063) acc@1 0.9844 (0.9983) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:29:18] __main__ INFO: \u001b[0mEpoch 30 Step 700/703 lr 0.001000 loss 0.0012 (0.0061) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:29:19] __main__ INFO: \u001b[0mEpoch 30 Step 703/703 lr 0.001000 loss 0.0011 (0.0061) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:29:19] __main__ INFO: \u001b[0mElapsed 225.69\n",
      "\u001b[32m[2020-07-13 18:29:19] __main__ INFO: \u001b[0mVal 30\n",
      "\u001b[32m[2020-07-13 18:29:27] __main__ INFO: \u001b[0mEpoch 30 loss 0.2847 acc@1 0.9438 acc@5 0.9954\n",
      "\u001b[32m[2020-07-13 18:29:27] __main__ INFO: \u001b[0mElapsed 7.82\n",
      "\u001b[32m[2020-07-13 18:29:27] __main__ INFO: \u001b[0mTrain 31 21090\n",
      "\u001b[32m[2020-07-13 18:29:59] __main__ INFO: \u001b[0mEpoch 31 Step 100/703 lr 0.001000 loss 0.0015 (0.0074) acc@1 1.0000 (0.9981) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:30:31] __main__ INFO: \u001b[0mEpoch 31 Step 200/703 lr 0.001000 loss 0.0012 (0.0071) acc@1 1.0000 (0.9980) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:31:03] __main__ INFO: \u001b[0mEpoch 31 Step 300/703 lr 0.001000 loss 0.0019 (0.0068) acc@1 1.0000 (0.9981) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:31:35] __main__ INFO: \u001b[0mEpoch 31 Step 400/703 lr 0.001000 loss 0.0017 (0.0064) acc@1 1.0000 (0.9983) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:32:07] __main__ INFO: \u001b[0mEpoch 31 Step 500/703 lr 0.001000 loss 0.0014 (0.0062) acc@1 1.0000 (0.9983) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:32:39] __main__ INFO: \u001b[0mEpoch 31 Step 600/703 lr 0.001000 loss 0.0032 (0.0058) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:33:12] __main__ INFO: \u001b[0mEpoch 31 Step 700/703 lr 0.001000 loss 0.0016 (0.0058) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:33:13] __main__ INFO: \u001b[0mEpoch 31 Step 703/703 lr 0.001000 loss 0.0008 (0.0058) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:33:13] __main__ INFO: \u001b[0mElapsed 225.70\n",
      "\u001b[32m[2020-07-13 18:33:13] __main__ INFO: \u001b[0mVal 31\n",
      "\u001b[32m[2020-07-13 18:33:20] __main__ INFO: \u001b[0mEpoch 31 loss 0.2864 acc@1 0.9428 acc@5 0.9950\n",
      "\u001b[32m[2020-07-13 18:33:20] __main__ INFO: \u001b[0mElapsed 7.84\n",
      "\u001b[32m[2020-07-13 18:33:20] __main__ INFO: \u001b[0mTrain 32 21793\n",
      "\u001b[32m[2020-07-13 18:33:53] __main__ INFO: \u001b[0mEpoch 32 Step 100/703 lr 0.001000 loss 0.0046 (0.0068) acc@1 1.0000 (0.9981) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:34:25] __main__ INFO: \u001b[0mEpoch 32 Step 200/703 lr 0.001000 loss 0.0276 (0.0061) acc@1 0.9844 (0.9983) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:34:57] __main__ INFO: \u001b[0mEpoch 32 Step 300/703 lr 0.001000 loss 0.0018 (0.0063) acc@1 1.0000 (0.9982) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:35:29] __main__ INFO: \u001b[0mEpoch 32 Step 400/703 lr 0.001000 loss 0.0012 (0.0060) acc@1 1.0000 (0.9982) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:36:01] __main__ INFO: \u001b[0mEpoch 32 Step 500/703 lr 0.001000 loss 0.0024 (0.0059) acc@1 1.0000 (0.9982) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:36:33] __main__ INFO: \u001b[0mEpoch 32 Step 600/703 lr 0.001000 loss 0.0018 (0.0058) acc@1 1.0000 (0.9982) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:37:05] __main__ INFO: \u001b[0mEpoch 32 Step 700/703 lr 0.001000 loss 0.0018 (0.0057) acc@1 1.0000 (0.9982) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:37:06] __main__ INFO: \u001b[0mEpoch 32 Step 703/703 lr 0.001000 loss 0.0008 (0.0057) acc@1 1.0000 (0.9982) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:37:06] __main__ INFO: \u001b[0mElapsed 225.42\n",
      "\u001b[32m[2020-07-13 18:37:06] __main__ INFO: \u001b[0mVal 32\n",
      "\u001b[32m[2020-07-13 18:37:14] __main__ INFO: \u001b[0mEpoch 32 loss 0.2935 acc@1 0.9436 acc@5 0.9940\n",
      "\u001b[32m[2020-07-13 18:37:14] __main__ INFO: \u001b[0mElapsed 7.82\n",
      "\u001b[32m[2020-07-13 18:37:14] __main__ INFO: \u001b[0mTrain 33 22496\n",
      "\u001b[32m[2020-07-13 18:37:46] __main__ INFO: \u001b[0mEpoch 33 Step 100/703 lr 0.001000 loss 0.0021 (0.0044) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:38:18] __main__ INFO: \u001b[0mEpoch 33 Step 200/703 lr 0.001000 loss 0.0012 (0.0054) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:38:50] __main__ INFO: \u001b[0mEpoch 33 Step 300/703 lr 0.001000 loss 0.0061 (0.0059) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:39:22] __main__ INFO: \u001b[0mEpoch 33 Step 400/703 lr 0.001000 loss 0.0010 (0.0058) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:39:54] __main__ INFO: \u001b[0mEpoch 33 Step 500/703 lr 0.001000 loss 0.0024 (0.0055) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:40:26] __main__ INFO: \u001b[0mEpoch 33 Step 600/703 lr 0.001000 loss 0.0077 (0.0054) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:40:59] __main__ INFO: \u001b[0mEpoch 33 Step 700/703 lr 0.001000 loss 0.0008 (0.0053) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:40:59] __main__ INFO: \u001b[0mEpoch 33 Step 703/703 lr 0.001000 loss 0.0014 (0.0053) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:41:00] __main__ INFO: \u001b[0mElapsed 225.90\n",
      "\u001b[32m[2020-07-13 18:41:00] __main__ INFO: \u001b[0mVal 33\n",
      "\u001b[32m[2020-07-13 18:41:07] __main__ INFO: \u001b[0mEpoch 33 loss 0.2925 acc@1 0.9448 acc@5 0.9950\n",
      "\u001b[32m[2020-07-13 18:41:07] __main__ INFO: \u001b[0mElapsed 7.84\n",
      "\u001b[32m[2020-07-13 18:41:07] __main__ INFO: \u001b[0mTrain 34 23199\n",
      "\u001b[32m[2020-07-13 18:41:40] __main__ INFO: \u001b[0mEpoch 34 Step 100/703 lr 0.001000 loss 0.0013 (0.0043) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:42:12] __main__ INFO: \u001b[0mEpoch 34 Step 200/703 lr 0.001000 loss 0.0011 (0.0039) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:42:44] __main__ INFO: \u001b[0mEpoch 34 Step 300/703 lr 0.001000 loss 0.0012 (0.0043) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:43:16] __main__ INFO: \u001b[0mEpoch 34 Step 400/703 lr 0.001000 loss 0.0022 (0.0047) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:43:48] __main__ INFO: \u001b[0mEpoch 34 Step 500/703 lr 0.001000 loss 0.0019 (0.0047) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:44:20] __main__ INFO: \u001b[0mEpoch 34 Step 600/703 lr 0.001000 loss 0.0010 (0.0051) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:44:52] __main__ INFO: \u001b[0mEpoch 34 Step 700/703 lr 0.001000 loss 0.0010 (0.0051) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:44:53] __main__ INFO: \u001b[0mEpoch 34 Step 703/703 lr 0.001000 loss 0.0048 (0.0051) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:44:53] __main__ INFO: \u001b[0mElapsed 225.42\n",
      "\u001b[32m[2020-07-13 18:44:53] __main__ INFO: \u001b[0mVal 34\n",
      "\u001b[32m[2020-07-13 18:45:01] __main__ INFO: \u001b[0mEpoch 34 loss 0.2890 acc@1 0.9444 acc@5 0.9948\n",
      "\u001b[32m[2020-07-13 18:45:01] __main__ INFO: \u001b[0mElapsed 7.80\n",
      "\u001b[32m[2020-07-13 18:45:01] __main__ INFO: \u001b[0mTrain 35 23902\n",
      "\u001b[32m[2020-07-13 18:45:33] __main__ INFO: \u001b[0mEpoch 35 Step 100/703 lr 0.001000 loss 0.0009 (0.0051) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:46:05] __main__ INFO: \u001b[0mEpoch 35 Step 200/703 lr 0.001000 loss 0.0015 (0.0052) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:46:37] __main__ INFO: \u001b[0mEpoch 35 Step 300/703 lr 0.001000 loss 0.0011 (0.0052) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:47:09] __main__ INFO: \u001b[0mEpoch 35 Step 400/703 lr 0.001000 loss 0.0009 (0.0050) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:47:41] __main__ INFO: \u001b[0mEpoch 35 Step 500/703 lr 0.001000 loss 0.0044 (0.0047) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:48:13] __main__ INFO: \u001b[0mEpoch 35 Step 600/703 lr 0.001000 loss 0.0046 (0.0045) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:48:45] __main__ INFO: \u001b[0mEpoch 35 Step 700/703 lr 0.001000 loss 0.0406 (0.0047) acc@1 0.9844 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:48:46] __main__ INFO: \u001b[0mEpoch 35 Step 703/703 lr 0.001000 loss 0.0089 (0.0047) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:48:46] __main__ INFO: \u001b[0mElapsed 225.81\n",
      "\u001b[32m[2020-07-13 18:48:46] __main__ INFO: \u001b[0mVal 35\n",
      "\u001b[32m[2020-07-13 18:48:54] __main__ INFO: \u001b[0mEpoch 35 loss 0.2965 acc@1 0.9428 acc@5 0.9954\n",
      "\u001b[32m[2020-07-13 18:48:54] __main__ INFO: \u001b[0mElapsed 7.83\n",
      "\u001b[32m[2020-07-13 18:48:54] __main__ INFO: \u001b[0mTrain 36 24605\n",
      "\u001b[32m[2020-07-13 18:49:26] __main__ INFO: \u001b[0mEpoch 36 Step 100/703 lr 0.001000 loss 0.0015 (0.0043) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:49:59] __main__ INFO: \u001b[0mEpoch 36 Step 200/703 lr 0.001000 loss 0.0017 (0.0039) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:50:31] __main__ INFO: \u001b[0mEpoch 36 Step 300/703 lr 0.001000 loss 0.0013 (0.0036) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:51:03] __main__ INFO: \u001b[0mEpoch 36 Step 400/703 lr 0.001000 loss 0.0012 (0.0039) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:51:35] __main__ INFO: \u001b[0mEpoch 36 Step 500/703 lr 0.001000 loss 0.0012 (0.0039) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:52:07] __main__ INFO: \u001b[0mEpoch 36 Step 600/703 lr 0.001000 loss 0.0042 (0.0042) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:52:39] __main__ INFO: \u001b[0mEpoch 36 Step 700/703 lr 0.001000 loss 0.0008 (0.0042) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:52:40] __main__ INFO: \u001b[0mEpoch 36 Step 703/703 lr 0.001000 loss 0.0013 (0.0042) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:52:40] __main__ INFO: \u001b[0mElapsed 225.84\n",
      "\u001b[32m[2020-07-13 18:52:40] __main__ INFO: \u001b[0mVal 36\n",
      "\u001b[32m[2020-07-13 18:52:48] __main__ INFO: \u001b[0mEpoch 36 loss 0.2849 acc@1 0.9446 acc@5 0.9960\n",
      "\u001b[32m[2020-07-13 18:52:48] __main__ INFO: \u001b[0mElapsed 7.80\n",
      "\u001b[32m[2020-07-13 18:52:48] __main__ INFO: \u001b[0mTrain 37 25308\n",
      "\u001b[32m[2020-07-13 18:53:20] __main__ INFO: \u001b[0mEpoch 37 Step 100/703 lr 0.001000 loss 0.0027 (0.0061) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:53:52] __main__ INFO: \u001b[0mEpoch 37 Step 200/703 lr 0.001000 loss 0.0017 (0.0055) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:54:24] __main__ INFO: \u001b[0mEpoch 37 Step 300/703 lr 0.001000 loss 0.0012 (0.0056) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:54:57] __main__ INFO: \u001b[0mEpoch 37 Step 400/703 lr 0.001000 loss 0.0012 (0.0052) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:55:29] __main__ INFO: \u001b[0mEpoch 37 Step 500/703 lr 0.001000 loss 0.0010 (0.0054) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:56:01] __main__ INFO: \u001b[0mEpoch 37 Step 600/703 lr 0.001000 loss 0.0023 (0.0051) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:56:33] __main__ INFO: \u001b[0mEpoch 37 Step 700/703 lr 0.001000 loss 0.0015 (0.0052) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:56:34] __main__ INFO: \u001b[0mEpoch 37 Step 703/703 lr 0.001000 loss 0.0013 (0.0052) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:56:34] __main__ INFO: \u001b[0mElapsed 225.92\n",
      "\u001b[32m[2020-07-13 18:56:34] __main__ INFO: \u001b[0mVal 37\n",
      "\u001b[32m[2020-07-13 18:56:42] __main__ INFO: \u001b[0mEpoch 37 loss 0.2865 acc@1 0.9446 acc@5 0.9956\n",
      "\u001b[32m[2020-07-13 18:56:42] __main__ INFO: \u001b[0mElapsed 7.82\n",
      "\u001b[32m[2020-07-13 18:56:42] __main__ INFO: \u001b[0mTrain 38 26011\n",
      "\u001b[32m[2020-07-13 18:57:14] __main__ INFO: \u001b[0mEpoch 38 Step 100/703 lr 0.001000 loss 0.0009 (0.0051) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:57:46] __main__ INFO: \u001b[0mEpoch 38 Step 200/703 lr 0.001000 loss 0.0013 (0.0041) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:58:18] __main__ INFO: \u001b[0mEpoch 38 Step 300/703 lr 0.001000 loss 0.0011 (0.0044) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:58:50] __main__ INFO: \u001b[0mEpoch 38 Step 400/703 lr 0.001000 loss 0.0011 (0.0043) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:59:22] __main__ INFO: \u001b[0mEpoch 38 Step 500/703 lr 0.001000 loss 0.0045 (0.0043) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 18:59:54] __main__ INFO: \u001b[0mEpoch 38 Step 600/703 lr 0.001000 loss 0.0015 (0.0043) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:00:26] __main__ INFO: \u001b[0mEpoch 38 Step 700/703 lr 0.001000 loss 0.0200 (0.0045) acc@1 0.9844 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:00:27] __main__ INFO: \u001b[0mEpoch 38 Step 703/703 lr 0.001000 loss 0.0019 (0.0045) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:00:27] __main__ INFO: \u001b[0mElapsed 225.67\n",
      "\u001b[32m[2020-07-13 19:00:27] __main__ INFO: \u001b[0mVal 38\n",
      "\u001b[32m[2020-07-13 19:00:35] __main__ INFO: \u001b[0mEpoch 38 loss 0.2833 acc@1 0.9428 acc@5 0.9956\n",
      "\u001b[32m[2020-07-13 19:00:35] __main__ INFO: \u001b[0mElapsed 7.80\n",
      "\u001b[32m[2020-07-13 19:00:35] __main__ INFO: \u001b[0mTrain 39 26714\n",
      "\u001b[32m[2020-07-13 19:01:07] __main__ INFO: \u001b[0mEpoch 39 Step 100/703 lr 0.001000 loss 0.0011 (0.0035) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:01:39] __main__ INFO: \u001b[0mEpoch 39 Step 200/703 lr 0.001000 loss 0.0012 (0.0030) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:02:11] __main__ INFO: \u001b[0mEpoch 39 Step 300/703 lr 0.001000 loss 0.0015 (0.0033) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:02:43] __main__ INFO: \u001b[0mEpoch 39 Step 400/703 lr 0.001000 loss 0.0016 (0.0037) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:03:15] __main__ INFO: \u001b[0mEpoch 39 Step 500/703 lr 0.001000 loss 0.0011 (0.0039) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:03:47] __main__ INFO: \u001b[0mEpoch 39 Step 600/703 lr 0.001000 loss 0.0010 (0.0038) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:04:19] __main__ INFO: \u001b[0mEpoch 39 Step 700/703 lr 0.001000 loss 0.0028 (0.0039) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:04:20] __main__ INFO: \u001b[0mEpoch 39 Step 703/703 lr 0.001000 loss 0.0010 (0.0039) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:04:20] __main__ INFO: \u001b[0mElapsed 225.40\n",
      "\u001b[32m[2020-07-13 19:04:20] __main__ INFO: \u001b[0mVal 39\n",
      "\u001b[32m[2020-07-13 19:04:28] __main__ INFO: \u001b[0mEpoch 39 loss 0.2977 acc@1 0.9434 acc@5 0.9948\n",
      "\u001b[32m[2020-07-13 19:04:28] __main__ INFO: \u001b[0mElapsed 7.81\n",
      "\u001b[32m[2020-07-13 19:04:28] __main__ INFO: \u001b[0mTrain 40 27417\n",
      "\u001b[32m[2020-07-13 19:05:00] __main__ INFO: \u001b[0mEpoch 40 Step 100/703 lr 0.001000 loss 0.0010 (0.0042) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:05:33] __main__ INFO: \u001b[0mEpoch 40 Step 200/703 lr 0.001000 loss 0.0035 (0.0049) acc@1 1.0000 (0.9990) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-13 19:06:04] __main__ INFO: \u001b[0mEpoch 40 Step 300/703 lr 0.001000 loss 0.0012 (0.0052) acc@1 1.0000 (0.9988) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-13 19:06:37] __main__ INFO: \u001b[0mEpoch 40 Step 400/703 lr 0.001000 loss 0.0411 (0.0053) acc@1 0.9844 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:07:09] __main__ INFO: \u001b[0mEpoch 40 Step 500/703 lr 0.001000 loss 0.0013 (0.0050) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:07:41] __main__ INFO: \u001b[0mEpoch 40 Step 600/703 lr 0.001000 loss 0.0011 (0.0048) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:08:13] __main__ INFO: \u001b[0mEpoch 40 Step 700/703 lr 0.001000 loss 0.0013 (0.0046) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:08:14] __main__ INFO: \u001b[0mEpoch 40 Step 703/703 lr 0.001000 loss 0.0011 (0.0046) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:08:14] __main__ INFO: \u001b[0mElapsed 225.38\n",
      "\u001b[32m[2020-07-13 19:08:14] __main__ INFO: \u001b[0mVal 40\n",
      "\u001b[32m[2020-07-13 19:08:21] __main__ INFO: \u001b[0mEpoch 40 loss 0.2896 acc@1 0.9412 acc@5 0.9952\n",
      "\u001b[32m[2020-07-13 19:08:21] __main__ INFO: \u001b[0mElapsed 7.80\n",
      "\u001b[32m[2020-07-13 19:08:21] __main__ INFO: \u001b[0mTrain 41 28120\n",
      "\u001b[32m[2020-07-13 19:08:54] __main__ INFO: \u001b[0mEpoch 41 Step 100/703 lr 0.001000 loss 0.0018 (0.0029) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:09:26] __main__ INFO: \u001b[0mEpoch 41 Step 200/703 lr 0.001000 loss 0.0088 (0.0034) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:09:58] __main__ INFO: \u001b[0mEpoch 41 Step 300/703 lr 0.001000 loss 0.0012 (0.0031) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:10:30] __main__ INFO: \u001b[0mEpoch 41 Step 400/703 lr 0.001000 loss 0.0007 (0.0031) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:11:02] __main__ INFO: \u001b[0mEpoch 41 Step 500/703 lr 0.001000 loss 0.0011 (0.0030) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:11:34] __main__ INFO: \u001b[0mEpoch 41 Step 600/703 lr 0.001000 loss 0.0013 (0.0035) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:12:06] __main__ INFO: \u001b[0mEpoch 41 Step 700/703 lr 0.001000 loss 0.0045 (0.0039) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:12:07] __main__ INFO: \u001b[0mEpoch 41 Step 703/703 lr 0.001000 loss 0.0015 (0.0039) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:12:07] __main__ INFO: \u001b[0mElapsed 225.35\n",
      "\u001b[32m[2020-07-13 19:12:07] __main__ INFO: \u001b[0mVal 41\n",
      "\u001b[32m[2020-07-13 19:12:15] __main__ INFO: \u001b[0mEpoch 41 loss 0.2848 acc@1 0.9428 acc@5 0.9964\n",
      "\u001b[32m[2020-07-13 19:12:15] __main__ INFO: \u001b[0mElapsed 7.79\n",
      "\u001b[32m[2020-07-13 19:12:15] __main__ INFO: \u001b[0mTrain 42 28823\n",
      "\u001b[32m[2020-07-13 19:12:47] __main__ INFO: \u001b[0mEpoch 42 Step 100/703 lr 0.001000 loss 0.0008 (0.0036) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:13:19] __main__ INFO: \u001b[0mEpoch 42 Step 200/703 lr 0.001000 loss 0.0010 (0.0050) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:13:51] __main__ INFO: \u001b[0mEpoch 42 Step 300/703 lr 0.001000 loss 0.0010 (0.0054) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:14:23] __main__ INFO: \u001b[0mEpoch 42 Step 400/703 lr 0.001000 loss 0.0018 (0.0047) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:14:55] __main__ INFO: \u001b[0mEpoch 42 Step 500/703 lr 0.001000 loss 0.0025 (0.0045) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:15:27] __main__ INFO: \u001b[0mEpoch 42 Step 600/703 lr 0.001000 loss 0.0007 (0.0044) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:15:59] __main__ INFO: \u001b[0mEpoch 42 Step 700/703 lr 0.001000 loss 0.0046 (0.0044) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:16:00] __main__ INFO: \u001b[0mEpoch 42 Step 703/703 lr 0.001000 loss 0.0025 (0.0044) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:16:00] __main__ INFO: \u001b[0mElapsed 225.74\n",
      "\u001b[32m[2020-07-13 19:16:00] __main__ INFO: \u001b[0mVal 42\n",
      "\u001b[32m[2020-07-13 19:16:08] __main__ INFO: \u001b[0mEpoch 42 loss 0.2940 acc@1 0.9422 acc@5 0.9954\n",
      "\u001b[32m[2020-07-13 19:16:08] __main__ INFO: \u001b[0mElapsed 7.80\n",
      "\u001b[32m[2020-07-13 19:16:08] __main__ INFO: \u001b[0mTrain 43 29526\n",
      "\u001b[32m[2020-07-13 19:16:40] __main__ INFO: \u001b[0mEpoch 43 Step 100/703 lr 0.001000 loss 0.0012 (0.0043) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:17:12] __main__ INFO: \u001b[0mEpoch 43 Step 200/703 lr 0.001000 loss 0.0013 (0.0035) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:17:45] __main__ INFO: \u001b[0mEpoch 43 Step 300/703 lr 0.001000 loss 0.0016 (0.0039) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:18:17] __main__ INFO: \u001b[0mEpoch 43 Step 400/703 lr 0.001000 loss 0.0025 (0.0039) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:18:49] __main__ INFO: \u001b[0mEpoch 43 Step 500/703 lr 0.001000 loss 0.0011 (0.0036) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:19:21] __main__ INFO: \u001b[0mEpoch 43 Step 600/703 lr 0.001000 loss 0.0534 (0.0036) acc@1 0.9688 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:19:53] __main__ INFO: \u001b[0mEpoch 43 Step 700/703 lr 0.001000 loss 0.0178 (0.0036) acc@1 0.9844 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:19:54] __main__ INFO: \u001b[0mEpoch 43 Step 703/703 lr 0.001000 loss 0.0013 (0.0036) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:19:54] __main__ INFO: \u001b[0mElapsed 225.76\n",
      "\u001b[32m[2020-07-13 19:19:54] __main__ INFO: \u001b[0mVal 43\n",
      "\u001b[32m[2020-07-13 19:20:02] __main__ INFO: \u001b[0mEpoch 43 loss 0.2954 acc@1 0.9424 acc@5 0.9956\n",
      "\u001b[32m[2020-07-13 19:20:02] __main__ INFO: \u001b[0mElapsed 7.81\n",
      "\u001b[32m[2020-07-13 19:20:02] __main__ INFO: \u001b[0mTrain 44 30229\n",
      "\u001b[32m[2020-07-13 19:20:34] __main__ INFO: \u001b[0mEpoch 44 Step 100/703 lr 0.001000 loss 0.0051 (0.0066) acc@1 1.0000 (0.9977) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:21:06] __main__ INFO: \u001b[0mEpoch 44 Step 200/703 lr 0.001000 loss 0.0012 (0.0056) acc@1 1.0000 (0.9982) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:21:38] __main__ INFO: \u001b[0mEpoch 44 Step 300/703 lr 0.001000 loss 0.0018 (0.0053) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:22:10] __main__ INFO: \u001b[0mEpoch 44 Step 400/703 lr 0.001000 loss 0.0026 (0.0051) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:22:42] __main__ INFO: \u001b[0mEpoch 44 Step 500/703 lr 0.001000 loss 0.0007 (0.0052) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:23:14] __main__ INFO: \u001b[0mEpoch 44 Step 600/703 lr 0.001000 loss 0.0013 (0.0051) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:23:46] __main__ INFO: \u001b[0mEpoch 44 Step 700/703 lr 0.001000 loss 0.0011 (0.0049) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:23:47] __main__ INFO: \u001b[0mEpoch 44 Step 703/703 lr 0.001000 loss 0.0016 (0.0049) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:23:47] __main__ INFO: \u001b[0mElapsed 225.68\n",
      "\u001b[32m[2020-07-13 19:23:47] __main__ INFO: \u001b[0mVal 44\n",
      "\u001b[32m[2020-07-13 19:23:55] __main__ INFO: \u001b[0mEpoch 44 loss 0.3065 acc@1 0.9392 acc@5 0.9952\n",
      "\u001b[32m[2020-07-13 19:23:55] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-13 19:23:55] __main__ INFO: \u001b[0mTrain 45 30932\n",
      "\u001b[32m[2020-07-13 19:24:27] __main__ INFO: \u001b[0mEpoch 45 Step 100/703 lr 0.001000 loss 0.0380 (0.0037) acc@1 0.9844 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:24:59] __main__ INFO: \u001b[0mEpoch 45 Step 200/703 lr 0.001000 loss 0.0020 (0.0042) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:25:31] __main__ INFO: \u001b[0mEpoch 45 Step 300/703 lr 0.001000 loss 0.0023 (0.0043) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:26:03] __main__ INFO: \u001b[0mEpoch 45 Step 400/703 lr 0.001000 loss 0.0008 (0.0041) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:26:36] __main__ INFO: \u001b[0mEpoch 45 Step 500/703 lr 0.001000 loss 0.0008 (0.0037) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:27:08] __main__ INFO: \u001b[0mEpoch 45 Step 600/703 lr 0.001000 loss 0.0025 (0.0036) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:27:40] __main__ INFO: \u001b[0mEpoch 45 Step 700/703 lr 0.001000 loss 0.0159 (0.0037) acc@1 0.9844 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:27:41] __main__ INFO: \u001b[0mEpoch 45 Step 703/703 lr 0.001000 loss 0.0020 (0.0036) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:27:41] __main__ INFO: \u001b[0mElapsed 225.51\n",
      "\u001b[32m[2020-07-13 19:27:41] __main__ INFO: \u001b[0mVal 45\n",
      "\u001b[32m[2020-07-13 19:27:48] __main__ INFO: \u001b[0mEpoch 45 loss 0.2839 acc@1 0.9424 acc@5 0.9956\n",
      "\u001b[32m[2020-07-13 19:27:48] __main__ INFO: \u001b[0mElapsed 7.80\n",
      "\u001b[32m[2020-07-13 19:27:49] __main__ INFO: \u001b[0mTrain 46 31635\n",
      "\u001b[32m[2020-07-13 19:28:21] __main__ INFO: \u001b[0mEpoch 46 Step 100/703 lr 0.001000 loss 0.0007 (0.0030) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:28:53] __main__ INFO: \u001b[0mEpoch 46 Step 200/703 lr 0.001000 loss 0.0007 (0.0046) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:29:25] __main__ INFO: \u001b[0mEpoch 46 Step 300/703 lr 0.001000 loss 0.0008 (0.0041) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:29:57] __main__ INFO: \u001b[0mEpoch 46 Step 400/703 lr 0.001000 loss 0.0007 (0.0040) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:30:29] __main__ INFO: \u001b[0mEpoch 46 Step 500/703 lr 0.001000 loss 0.0021 (0.0038) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:31:01] __main__ INFO: \u001b[0mEpoch 46 Step 600/703 lr 0.001000 loss 0.0014 (0.0037) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:31:33] __main__ INFO: \u001b[0mEpoch 46 Step 700/703 lr 0.001000 loss 0.0007 (0.0039) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:31:34] __main__ INFO: \u001b[0mEpoch 46 Step 703/703 lr 0.001000 loss 0.0047 (0.0039) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:31:34] __main__ INFO: \u001b[0mElapsed 225.79\n",
      "\u001b[32m[2020-07-13 19:31:34] __main__ INFO: \u001b[0mVal 46\n",
      "\u001b[32m[2020-07-13 19:31:42] __main__ INFO: \u001b[0mEpoch 46 loss 0.2867 acc@1 0.9434 acc@5 0.9954\n",
      "\u001b[32m[2020-07-13 19:31:42] __main__ INFO: \u001b[0mElapsed 7.82\n",
      "\u001b[32m[2020-07-13 19:31:42] __main__ INFO: \u001b[0mTrain 47 32338\n",
      "\u001b[32m[2020-07-13 19:32:14] __main__ INFO: \u001b[0mEpoch 47 Step 100/703 lr 0.001000 loss 0.0021 (0.0022) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:32:46] __main__ INFO: \u001b[0mEpoch 47 Step 200/703 lr 0.001000 loss 0.0047 (0.0043) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:33:19] __main__ INFO: \u001b[0mEpoch 47 Step 300/703 lr 0.001000 loss 0.0008 (0.0048) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:33:51] __main__ INFO: \u001b[0mEpoch 47 Step 400/703 lr 0.001000 loss 0.0019 (0.0042) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:34:23] __main__ INFO: \u001b[0mEpoch 47 Step 500/703 lr 0.001000 loss 0.0010 (0.0044) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:34:55] __main__ INFO: \u001b[0mEpoch 47 Step 600/703 lr 0.001000 loss 0.0492 (0.0046) acc@1 0.9844 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:35:27] __main__ INFO: \u001b[0mEpoch 47 Step 700/703 lr 0.001000 loss 0.0017 (0.0045) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:35:28] __main__ INFO: \u001b[0mEpoch 47 Step 703/703 lr 0.001000 loss 0.0016 (0.0045) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:35:28] __main__ INFO: \u001b[0mElapsed 225.65\n",
      "\u001b[32m[2020-07-13 19:35:28] __main__ INFO: \u001b[0mVal 47\n",
      "\u001b[32m[2020-07-13 19:35:36] __main__ INFO: \u001b[0mEpoch 47 loss 0.2910 acc@1 0.9452 acc@5 0.9946\n",
      "\u001b[32m[2020-07-13 19:35:36] __main__ INFO: \u001b[0mElapsed 7.86\n",
      "\u001b[32m[2020-07-13 19:35:36] __main__ INFO: \u001b[0mTrain 48 33041\n",
      "\u001b[32m[2020-07-13 19:36:08] __main__ INFO: \u001b[0mEpoch 48 Step 100/703 lr 0.001000 loss 0.0013 (0.0033) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:36:40] __main__ INFO: \u001b[0mEpoch 48 Step 200/703 lr 0.001000 loss 0.0060 (0.0036) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:37:12] __main__ INFO: \u001b[0mEpoch 48 Step 300/703 lr 0.001000 loss 0.0011 (0.0034) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:37:44] __main__ INFO: \u001b[0mEpoch 48 Step 400/703 lr 0.001000 loss 0.0017 (0.0034) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:38:16] __main__ INFO: \u001b[0mEpoch 48 Step 500/703 lr 0.001000 loss 0.0008 (0.0034) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:38:48] __main__ INFO: \u001b[0mEpoch 48 Step 600/703 lr 0.001000 loss 0.0010 (0.0033) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:39:20] __main__ INFO: \u001b[0mEpoch 48 Step 700/703 lr 0.001000 loss 0.0014 (0.0034) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:39:21] __main__ INFO: \u001b[0mEpoch 48 Step 703/703 lr 0.001000 loss 0.0007 (0.0034) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:39:21] __main__ INFO: \u001b[0mElapsed 225.74\n",
      "\u001b[32m[2020-07-13 19:39:21] __main__ INFO: \u001b[0mVal 48\n",
      "\u001b[32m[2020-07-13 19:39:29] __main__ INFO: \u001b[0mEpoch 48 loss 0.2954 acc@1 0.9442 acc@5 0.9958\n",
      "\u001b[32m[2020-07-13 19:39:29] __main__ INFO: \u001b[0mElapsed 7.83\n",
      "\u001b[32m[2020-07-13 19:39:29] __main__ INFO: \u001b[0mTrain 49 33744\n",
      "\u001b[32m[2020-07-13 19:40:01] __main__ INFO: \u001b[0mEpoch 49 Step 100/703 lr 0.001000 loss 0.0022 (0.0041) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:40:33] __main__ INFO: \u001b[0mEpoch 49 Step 200/703 lr 0.001000 loss 0.0033 (0.0037) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:41:05] __main__ INFO: \u001b[0mEpoch 49 Step 300/703 lr 0.001000 loss 0.0011 (0.0034) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:41:37] __main__ INFO: \u001b[0mEpoch 49 Step 400/703 lr 0.001000 loss 0.0036 (0.0037) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:42:10] __main__ INFO: \u001b[0mEpoch 49 Step 500/703 lr 0.001000 loss 0.0018 (0.0038) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:42:42] __main__ INFO: \u001b[0mEpoch 49 Step 600/703 lr 0.001000 loss 0.0023 (0.0038) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:43:14] __main__ INFO: \u001b[0mEpoch 49 Step 700/703 lr 0.001000 loss 0.0008 (0.0037) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:43:15] __main__ INFO: \u001b[0mEpoch 49 Step 703/703 lr 0.001000 loss 0.0008 (0.0037) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:43:15] __main__ INFO: \u001b[0mElapsed 225.54\n",
      "\u001b[32m[2020-07-13 19:43:15] __main__ INFO: \u001b[0mVal 49\n",
      "\u001b[32m[2020-07-13 19:43:23] __main__ INFO: \u001b[0mEpoch 49 loss 0.2964 acc@1 0.9436 acc@5 0.9950\n",
      "\u001b[32m[2020-07-13 19:43:23] __main__ INFO: \u001b[0mElapsed 7.79\n",
      "\u001b[32m[2020-07-13 19:43:23] __main__ INFO: \u001b[0mTrain 50 34447\n",
      "\u001b[32m[2020-07-13 19:43:55] __main__ INFO: \u001b[0mEpoch 50 Step 100/703 lr 0.001000 loss 0.0008 (0.0028) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:44:27] __main__ INFO: \u001b[0mEpoch 50 Step 200/703 lr 0.001000 loss 0.0019 (0.0030) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:44:59] __main__ INFO: \u001b[0mEpoch 50 Step 300/703 lr 0.001000 loss 0.0009 (0.0033) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:45:31] __main__ INFO: \u001b[0mEpoch 50 Step 400/703 lr 0.001000 loss 0.0009 (0.0035) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:46:03] __main__ INFO: \u001b[0mEpoch 50 Step 500/703 lr 0.001000 loss 0.0022 (0.0036) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:46:35] __main__ INFO: \u001b[0mEpoch 50 Step 600/703 lr 0.001000 loss 0.0268 (0.0035) acc@1 0.9844 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:47:07] __main__ INFO: \u001b[0mEpoch 50 Step 700/703 lr 0.001000 loss 0.0010 (0.0036) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:47:08] __main__ INFO: \u001b[0mEpoch 50 Step 703/703 lr 0.001000 loss 0.1341 (0.0038) acc@1 0.9844 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 19:47:08] __main__ INFO: \u001b[0mElapsed 225.42\n",
      "\u001b[32m[2020-07-13 19:47:08] __main__ INFO: \u001b[0mVal 50\n",
      "\u001b[32m[2020-07-13 19:47:16] __main__ INFO: \u001b[0mEpoch 50 loss 0.3001 acc@1 0.9422 acc@5 0.9954\n",
      "\u001b[32m[2020-07-13 19:47:16] __main__ INFO: \u001b[0mElapsed 7.81\n",
      "\u001b[32m[2020-07-13 19:47:16] fvcore.common.checkpoint INFO: \u001b[0mSaving checkpoint to /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_cm_1_.5/exp00_resume400_50/checkpoint_00050.pth\n"
     ]
    }
   ],
   "source": [
    "# Resume training with the un-augmented data\n",
    "os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "!python train.py --config /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_cm_1_.5/exp00/config.yaml \\\n",
    "    train.checkpoint /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_cm_1_.5/exp00/checkpoint_00400.pth \\\n",
    "    dataset.name CIFAR10 \\\n",
    "    train.base_lr 0.001 \\\n",
    "    train.output_dir /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_cm_1_.5/exp00_resume400_50 \\\n",
    "    scheduler.epochs 50\n",
    "\n",
    "#### Set LEARNING RATE based on ending LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-13 21:36:01] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_cm_1_.5/exp00_resume400_50/checkpoint_00050.pth\n",
      "Files already downloaded and verified\n",
      "100%|█████████████████████████████████████████| 157/157 [00:19<00:00,  8.04it/s]\n",
      "\u001b[32m[2020-07-13 21:36:22] __main__ INFO: \u001b[0mElapsed 19.52\n",
      "\u001b[32m[2020-07-13 21:36:22] __main__ INFO: \u001b[0mLoss 0.3368 Accuracy 0.9374\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10 test dataset \n",
    "# Right the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/densenet.yaml \\\n",
    "   model.densenet.depth 100 \\\n",
    "   model.densenet.growth_rate 12 \\\n",
    "   test.batch_size 64 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_cm_1_.5/exp00_resume400_50/checkpoint_00050.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_cm_1_.5/exp00_resume400_50/test_results_0050_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-13 21:37:42] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_cm_1_.5/exp00_resume400_50/checkpoint_00050.pth\n",
      "CIFAR 10.1\n",
      "100%|███████████████████████████████████████████| 32/32 [00:04<00:00,  7.63it/s]\n",
      "\u001b[32m[2020-07-13 21:37:47] __main__ INFO: \u001b[0mElapsed 4.20\n",
      "\u001b[32m[2020-07-13 21:37:47] __main__ INFO: \u001b[0mLoss 0.7471 Accuracy 0.8630\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10.1 test dataset \n",
    "# Right the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/densenet.yaml \\\n",
    "   model.densenet.depth 100 \\\n",
    "   model.densenet.growth_rate 12 \\\n",
    "   test.batch_size 64 \\\n",
    "   dataset.name CIFAR101 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_cm_1_.5/exp00_resume400_50/checkpoint_00050.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_cm_1_.5/exp00_resume400_50/test_results_0050_cifar101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-13 21:38:49] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_cm_1_.5/exp00/checkpoint_00400.pth\n",
      "Files already downloaded and verified\n",
      "100%|█████████████████████████████████████████| 157/157 [00:19<00:00,  8.10it/s]\n",
      "\u001b[32m[2020-07-13 21:39:09] __main__ INFO: \u001b[0mElapsed 19.38\n",
      "\u001b[32m[2020-07-13 21:39:09] __main__ INFO: \u001b[0mLoss 3.0530 Accuracy 0.3093\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10 test dataset \n",
    "# Right the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/densenet.yaml \\\n",
    "   model.densenet.depth 100 \\\n",
    "   model.densenet.growth_rate 12 \\\n",
    "   test.batch_size 64 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_cm_1_.5/exp00/checkpoint_00400.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_cm_1_.5/exp00/test_results_0400_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-13 21:39:18] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_cm_1_.5/exp00/checkpoint_00400.pth\n",
      "CIFAR 10.1\n",
      "100%|███████████████████████████████████████████| 32/32 [00:04<00:00,  7.55it/s]\n",
      "\u001b[32m[2020-07-13 21:39:23] __main__ INFO: \u001b[0mElapsed 4.24\n",
      "\u001b[32m[2020-07-13 21:39:23] __main__ INFO: \u001b[0mLoss 3.2110 Accuracy 0.2710\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10.1 test dataset \n",
    "# Right the results to the test output directory specified.\n",
    "os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "!python evaluate.py --config configs/cifar/densenet.yaml \\\n",
    "   model.densenet.depth 100 \\\n",
    "   model.densenet.growth_rate 12 \\\n",
    "   test.batch_size 64 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_cm_1_.5/exp00/checkpoint_00400.pth \\\n",
    "   dataset.name CIFAR101 \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_cm_1_.5/exp00/test_results_0400_cifar101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Record the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Testset</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Original_Accuracy</th>\n",
       "      <th>Original_CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>densenet_BC_100_12</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3681</td>\n",
       "      <td>0.8875</td>\n",
       "      <td>95.5</td>\n",
       "      <td>(95.1, 95.9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>densenet_BC_100_12</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>200</td>\n",
       "      <td>0.2279</td>\n",
       "      <td>0.9456</td>\n",
       "      <td>95.5</td>\n",
       "      <td>(95.1, 95.9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>densenet_BC_100_12</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>300</td>\n",
       "      <td>0.2223</td>\n",
       "      <td>0.9484</td>\n",
       "      <td>95.5</td>\n",
       "      <td>(95.1, 95.9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>densenet_BC_100_12</td>\n",
       "      <td>cifar10.1</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5098</td>\n",
       "      <td>0.8830</td>\n",
       "      <td>87.6</td>\n",
       "      <td>(86.1, 89.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model    Testset  Epoch    Loss  Accuracy  Original_Accuracy  \\\n",
       "0  densenet_BC_100_12    cifar10    100  0.3681    0.8875               95.5   \n",
       "1  densenet_BC_100_12    cifar10    200  0.2279    0.9456               95.5   \n",
       "2  densenet_BC_100_12    cifar10    300  0.2223    0.9484               95.5   \n",
       "3  densenet_BC_100_12  cifar10.1    300  0.5098    0.8830               87.6   \n",
       "\n",
       "    Original_CI  \n",
       "0  (95.1, 95.9)  \n",
       "1  (95.1, 95.9)  \n",
       "2  (95.1, 95.9)  \n",
       "3  (86.1, 89.0)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write the results to a CSV file so that we can analyze later.\n",
    "import pandas as pd\n",
    "\n",
    "results = {'Model': ['densenet_BC_100_12', 'densenet_BC_100_12', 'densenet_BC_100_12', 'densenet_BC_100_12'],\n",
    "           'Testset': ['cifar10', 'cifar10', 'cifar10', 'cifar10.1'],\n",
    "           'Epoch': [100, 200, 300, 300],\n",
    "           'Loss': [0.3681, 0.2279, 0.2223, 0.5098],\n",
    "           'Accuracy': [0.8875, 0.9456, 0.9484, 0.8830],\n",
    "           'Original_Accuracy': [95.5, 95.5, 95.5, 87.6],\n",
    "           'Original_CI': [(95.1, 95.9), (95.1, 95.9), (95.1, 95.9), (86.1, 89.0)]\n",
    "           }\n",
    "\n",
    "df = pd.DataFrame(results, columns = ['Model', 'Testset', 'Epoch', 'Loss', 'Accuracy', \n",
    "                                      'Original_Accuracy', 'Original_CI'])\n",
    "\n",
    "\n",
    "\n",
    "#df.to_csv('/home/ec2-user/SageMaker/experiments/wrn_28_10/exp00/results.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Testset</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Original_Accuracy</th>\n",
       "      <th>Original_CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>densenet_BC_100_12_cm_1_.5</td>\n",
       "      <td>400</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>3.053</td>\n",
       "      <td>0.3093</td>\n",
       "      <td>95.5</td>\n",
       "      <td>(95.1, 95.9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>densenet_BC_100_12_cm_1_.5</td>\n",
       "      <td>400</td>\n",
       "      <td>cifar10.1</td>\n",
       "      <td>3.211</td>\n",
       "      <td>0.271</td>\n",
       "      <td>87.6</td>\n",
       "      <td>(86.1, 89.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>densenet_BC_100_12_cm_1_.5_refined400</td>\n",
       "      <td>50</td>\n",
       "      <td>cifar10.1</td>\n",
       "      <td>0.7471</td>\n",
       "      <td>0.863</td>\n",
       "      <td>87.6</td>\n",
       "      <td>(86.1, 89.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>densenet_BC_100_12_cm_1_.5_refined400</td>\n",
       "      <td>50</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>0.3368</td>\n",
       "      <td>0.9374</td>\n",
       "      <td>95.5</td>\n",
       "      <td>(95.1, 95.9)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Model Epoch    Testset    Loss Accuracy  \\\n",
       "0             densenet_BC_100_12_cm_1_.5   400    cifar10   3.053   0.3093   \n",
       "1             densenet_BC_100_12_cm_1_.5   400  cifar10.1   3.211    0.271   \n",
       "2  densenet_BC_100_12_cm_1_.5_refined400    50  cifar10.1  0.7471    0.863   \n",
       "3  densenet_BC_100_12_cm_1_.5_refined400    50    cifar10  0.3368   0.9374   \n",
       "\n",
       "   Original_Accuracy   Original_CI  \n",
       "0               95.5  (95.1, 95.9)  \n",
       "1               87.6  (86.1, 89.0)  \n",
       "2               87.6  (86.1, 89.0)  \n",
       "3               95.5  (95.1, 95.9)  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "model = 'densenet_BC_100_12_cm_1_.5'\n",
    "model_refined = model + '_refined400'\n",
    "\n",
    "a = pd.Series([model, 400, 'cifar10', 3.0530, 0.3093])\n",
    "c = pd.Series([model, 400, 'cifar10.1', 3.2110, 0.2710])\n",
    "\n",
    "e = pd.Series([model_refined, 50, 'cifar10.1', 0.7471, 0.8630])\n",
    "f = pd.Series([model_refined, 50, 'cifar10', 0.3368, 0.9374])\n",
    "               \n",
    "df_results = pd.concat([a,c,e,f], axis=1).T\n",
    "df_results.columns = ['Model', 'Epoch', 'Testset', 'Loss', 'Accuracy']\n",
    "\n",
    "df_results['Original_Accuracy'] = df_results.apply((lambda row: 95.5 if row[2] == 'cifar10' else 87.6), axis=1)\n",
    "df_results['Original_CI'] = df_results.apply((lambda row: (95.1, 95.9) if row[2] == 'cifar10' else (86.1, 89.0)), axis=1)\n",
    "\n",
    "df_results.to_csv('/home/ec2-user/SageMaker/experiments/' + model + '/results.csv')\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the model checkpoints, configs, and results to S3 \n",
    "bucket='sagemaker-june29'\n",
    "prefix = 'sagemaker/results/original-models/densenet_BC_100_12_cm_1_.5'\n",
    "path = '/home/ec2-user/SageMaker/experiments/densenet_BC_100_12_cm_1_.5'\n",
    "\n",
    "s3_resource = boto3.resource(\"s3\", region_name=\"us-east-2\")\n",
    "\n",
    "def uploadDirectory(local_path,bucket_name,s3_prefix):\n",
    "\n",
    "    my_bucket = s3_resource.Bucket(bucket_name)\n",
    "    \n",
    "    for path, subdirs, files in os.walk(local_path):\n",
    "        path = path.replace(\"\\\\\",\"/\")\n",
    "        directory_name = path.replace(local_path,\"\")\n",
    "        for file in files:\n",
    "            #print(\"Local File:\", os.path.join(path, file))\n",
    "            #print(\"      Dest:\", s3_prefix+directory_name+'/'+file)\n",
    "            my_bucket.upload_file(os.path.join(path, file), s3_prefix+directory_name+'/'+file)\n",
    "    \n",
    "uploadDirectory(path,bucket,prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
