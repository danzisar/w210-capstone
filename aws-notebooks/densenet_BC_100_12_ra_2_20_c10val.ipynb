{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DENSENET 211\n",
    "- Training Dataset: RandAugment, N=2, M=20\n",
    "- Sagemaker Notebook must be of type, conda_pytorch_p36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy \n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 1)) (1.15.4)\n",
      "Requirement already satisfied: torch>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 2)) (1.4.0)\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 3)) (0.5.0)\n",
      "Requirement already satisfied: fvcore in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (0.1.1.post20200630)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 5)) (4.42.1)\n",
      "Requirement already satisfied: yacs in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 6)) (0.1.7)\n",
      "Requirement already satisfied: apex from git+https://github.com/NVIDIA/apex.git#egg=apex in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 7)) (0.1)\n",
      "Requirement already satisfied: termcolor in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 8)) (1.1.0)\n",
      "Requirement already satisfied: thop<0.0.31.post2004070130 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 9)) (0.0.31.post2001170342)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 3)) (1.11.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 3)) (5.4.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from fvcore->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (5.3.1)\n",
      "Requirement already satisfied: tabulate in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from fvcore->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (0.8.7)\n",
      "Requirement already satisfied: portalocker in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from fvcore->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (1.7.0)\n",
      "\u001b[31mfastai 1.0.60 requires nvidia-ml-py3, which is not installed.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.2b1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Sagemaker Notebook must be of type, conda_pytorch_p36\n",
    "\n",
    "!pip install -r '/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (2.2.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.18.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (47.3.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.11.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.15.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.7.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (2.24.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.9.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.30.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (3.12.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.14.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (3.2.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.4.1)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.31.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard) (3.4.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.1.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.6)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (1.23)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (1.5.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard) (3.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.0)\n",
      "\u001b[31mfastai 1.0.60 requires nvidia-ml-py3, which is not installed.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.2b1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Need to add this to requirements.txt\n",
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-01 01:47:45] __main__ INFO: \u001b[0mdevice: cuda\n",
      "cudnn:\n",
      "  benchmark: True\n",
      "  deterministic: False\n",
      "dataset:\n",
      "  name: CIFAR10_RA_2_20\n",
      "  dataset_dir: ''\n",
      "  image_size: 32\n",
      "  n_channels: 3\n",
      "  n_classes: 10\n",
      "model:\n",
      "  type: cifar\n",
      "  name: densenet\n",
      "  init_mode: kaiming_fan_out\n",
      "  vgg:\n",
      "    n_channels: [64, 128, 256, 512, 512]\n",
      "    n_layers: [2, 2, 3, 3, 3]\n",
      "    use_bn: True\n",
      "  resnet:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "  resnet_preact:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "  wrn:\n",
      "    depth: 28\n",
      "    initial_channels: 16\n",
      "    widening_factor: 10\n",
      "    drop_rate: 0.0\n",
      "  densenet:\n",
      "    depth: 100\n",
      "    n_blocks: [6, 12, 24, 16]\n",
      "    block_type: bottleneck\n",
      "    growth_rate: 12\n",
      "    drop_rate: 0.0\n",
      "    compression_rate: 0.5\n",
      "  pyramidnet:\n",
      "    depth: 272\n",
      "    n_blocks: [3, 24, 36, 3]\n",
      "    initial_channels: 16\n",
      "    block_type: bottleneck\n",
      "    alpha: 200\n",
      "  resnext:\n",
      "    depth: 29\n",
      "    n_blocks: [3, 4, 6, 3]\n",
      "    initial_channels: 64\n",
      "    cardinality: 8\n",
      "    base_channels: 4\n",
      "  shake_shake:\n",
      "    depth: 26\n",
      "    initial_channels: 96\n",
      "    shake_forward: True\n",
      "    shake_backward: True\n",
      "    shake_image: True\n",
      "  se_resnet_preact:\n",
      "    depth: 110\n",
      "    initial_channels: 16\n",
      "    se_reduction: 16\n",
      "    block_type: basic\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "train:\n",
      "  checkpoint: ''\n",
      "  resume: False\n",
      "  precision: O0\n",
      "  batch_size: 64\n",
      "  subdivision: 1\n",
      "  optimizer: sgd\n",
      "  base_lr: 0.1\n",
      "  momentum: 0.9\n",
      "  nesterov: True\n",
      "  weight_decay: 0.0001\n",
      "  no_weight_decay_on_bn: False\n",
      "  gradient_clip: 0\n",
      "  start_epoch: 0\n",
      "  seed: 0\n",
      "  val_first: True\n",
      "  val_period: 1\n",
      "  val_ratio: 0.1\n",
      "  use_test_as_val: False\n",
      "  output_dir: /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_2_20_c10val/exp00\n",
      "  log_period: 100\n",
      "  checkpoint_period: 100\n",
      "  use_tensorboard: True\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: True\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "  distributed: False\n",
      "  dist:\n",
      "    backend: nccl\n",
      "    init_method: env://\n",
      "    world_size: -1\n",
      "    node_rank: -1\n",
      "    local_rank: 0\n",
      "    use_sync_bn: False\n",
      "tensorboard:\n",
      "  train_images: False\n",
      "  val_images: False\n",
      "  model_params: False\n",
      "optim:\n",
      "  adam:\n",
      "    betas: (0.9, 0.999)\n",
      "  lars:\n",
      "    eps: 1e-09\n",
      "    threshold: 0.01\n",
      "  adabound:\n",
      "    betas: (0.9, 0.999)\n",
      "    final_lr: 0.1\n",
      "    gamma: 0.001\n",
      "scheduler:\n",
      "  epochs: 400\n",
      "  warmup:\n",
      "    type: none\n",
      "    epochs: 0\n",
      "    start_factor: 0.001\n",
      "    exponent: 4\n",
      "  type: multistep\n",
      "  milestones: [150, 225]\n",
      "  lr_decay: 0.1\n",
      "  lr_min_factor: 0.001\n",
      "  T0: 10\n",
      "  T_mul: 1.0\n",
      "validation:\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: False\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "augmentation:\n",
      "  use_random_crop: True\n",
      "  use_random_horizontal_flip: True\n",
      "  use_cutout: False\n",
      "  use_random_erasing: False\n",
      "  use_dual_cutout: False\n",
      "  use_mixup: False\n",
      "  use_ricap: False\n",
      "  use_cutmix: False\n",
      "  use_label_smoothing: False\n",
      "  random_crop:\n",
      "    padding: 4\n",
      "    fill: 0\n",
      "    padding_mode: constant\n",
      "  random_horizontal_flip:\n",
      "    prob: 0.5\n",
      "  cutout:\n",
      "    prob: 1.0\n",
      "    mask_size: 16\n",
      "    cut_inside: False\n",
      "    mask_color: 0\n",
      "    dual_cutout_alpha: 0.1\n",
      "  random_erasing:\n",
      "    prob: 0.5\n",
      "    area_ratio_range: [0.02, 0.4]\n",
      "    min_aspect_ratio: 0.3\n",
      "    max_attempt: 20\n",
      "  mixup:\n",
      "    alpha: 1.0\n",
      "  ricap:\n",
      "    beta: 0.3\n",
      "  cutmix:\n",
      "    alpha: 1.0\n",
      "  label_smoothing:\n",
      "    epsilon: 0.1\n",
      "tta:\n",
      "  use_resize: False\n",
      "  use_center_crop: False\n",
      "  resize: 256\n",
      "test:\n",
      "  checkpoint: ''\n",
      "  output_dir: ''\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    pin_memory: False\n",
      "\u001b[32m[2020-07-01 01:47:45] __main__ INFO: \u001b[0menv_info:\n",
      "  pytorch_version: 1.4.0\n",
      "  cuda_version: 10.1\n",
      "  cudnn_version: 7603\n",
      "  num_gpus: 1\n",
      "  gpu_name: Tesla K80\n",
      "  gpu_capability: 3.7\n",
      "(50000, 32, 32, 3)\n",
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /home/ec2-user/.torch/datasets/CIFAR10/cifar-10-python.tar.gz\n",
      "170500096it [00:03, 54692919.93it/s]                                            \n",
      "Extracting /home/ec2-user/.torch/datasets/CIFAR10/cifar-10-python.tar.gz to /home/ec2-user/.torch/datasets/CIFAR10\n",
      "\u001b[32m[2020-07-01 01:48:33] __main__ INFO: \u001b[0mMACs  : 296.49M\n",
      "\u001b[32m[2020-07-01 01:48:33] __main__ INFO: \u001b[0m#params: 769.16K\n",
      "Selected optimization level O0:  Pure FP32 training.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n",
      "\u001b[32m[2020-07-01 01:48:33] __main__ INFO: \u001b[0mVal 0\n",
      "\u001b[32m[2020-07-01 01:48:44] __main__ INFO: \u001b[0mEpoch 0 loss 37763838.1120 acc@1 0.1012 acc@5 0.5040\n",
      "\u001b[32m[2020-07-01 01:48:44] __main__ INFO: \u001b[0mElapsed 11.68\n",
      "\u001b[32m[2020-07-01 01:48:44] __main__ INFO: \u001b[0mTrain 1 0\n",
      "\u001b[32m[2020-07-01 01:49:18] __main__ INFO: \u001b[0mEpoch 1 Step 100/703 lr 0.100000 loss 2.3349 (2.9128) acc@1 0.0781 (0.1042) acc@5 0.5625 (0.5138)\n",
      "\u001b[32m[2020-07-01 01:49:50] __main__ INFO: \u001b[0mEpoch 1 Step 200/703 lr 0.100000 loss 2.2737 (2.6388) acc@1 0.0938 (0.1047) acc@5 0.5469 (0.5181)\n",
      "\u001b[32m[2020-07-01 01:50:22] __main__ INFO: \u001b[0mEpoch 1 Step 300/703 lr 0.100000 loss 2.2598 (2.5377) acc@1 0.1094 (0.1078) acc@5 0.6094 (0.5260)\n",
      "\u001b[32m[2020-07-01 01:50:54] __main__ INFO: \u001b[0mEpoch 1 Step 400/703 lr 0.100000 loss 2.3789 (2.4835) acc@1 0.1094 (0.1101) acc@5 0.5312 (0.5304)\n",
      "\u001b[32m[2020-07-01 01:51:26] __main__ INFO: \u001b[0mEpoch 1 Step 500/703 lr 0.100000 loss 2.3317 (2.4473) acc@1 0.0781 (0.1125) acc@5 0.5000 (0.5367)\n",
      "\u001b[32m[2020-07-01 01:51:58] __main__ INFO: \u001b[0mEpoch 1 Step 600/703 lr 0.100000 loss 2.2564 (2.4228) acc@1 0.1562 (0.1146) acc@5 0.5000 (0.5393)\n",
      "\u001b[32m[2020-07-01 01:52:30] __main__ INFO: \u001b[0mEpoch 1 Step 700/703 lr 0.100000 loss 2.2820 (2.4043) acc@1 0.1250 (0.1169) acc@5 0.4844 (0.5425)\n",
      "\u001b[32m[2020-07-01 01:52:31] __main__ INFO: \u001b[0mEpoch 1 Step 703/703 lr 0.100000 loss 2.2600 (2.4037) acc@1 0.1406 (0.1171) acc@5 0.5781 (0.5427)\n",
      "\u001b[32m[2020-07-01 01:52:31] __main__ INFO: \u001b[0mElapsed 226.36\n",
      "\u001b[32m[2020-07-01 01:52:31] __main__ INFO: \u001b[0mVal 1\n",
      "\u001b[32m[2020-07-01 01:52:38] __main__ INFO: \u001b[0mEpoch 1 loss 2.1903 acc@1 0.1770 acc@5 0.7018\n",
      "\u001b[32m[2020-07-01 01:52:38] __main__ INFO: \u001b[0mElapsed 7.80\n",
      "\u001b[32m[2020-07-01 01:52:38] __main__ INFO: \u001b[0mTrain 2 703\n",
      "\u001b[32m[2020-07-01 01:53:10] __main__ INFO: \u001b[0mEpoch 2 Step 100/703 lr 0.100000 loss 2.3450 (2.2745) acc@1 0.1094 (0.1316) acc@5 0.5625 (0.5938)\n",
      "\u001b[32m[2020-07-01 01:53:42] __main__ INFO: \u001b[0mEpoch 2 Step 200/703 lr 0.100000 loss 2.2941 (2.2731) acc@1 0.1875 (0.1310) acc@5 0.5781 (0.5908)\n",
      "\u001b[32m[2020-07-01 01:54:14] __main__ INFO: \u001b[0mEpoch 2 Step 300/703 lr 0.100000 loss 2.3054 (2.2711) acc@1 0.1406 (0.1322) acc@5 0.5625 (0.5887)\n",
      "\u001b[32m[2020-07-01 01:54:46] __main__ INFO: \u001b[0mEpoch 2 Step 400/703 lr 0.100000 loss 2.2340 (2.2668) acc@1 0.1875 (0.1363) acc@5 0.5938 (0.5900)\n",
      "\u001b[32m[2020-07-01 01:55:18] __main__ INFO: \u001b[0mEpoch 2 Step 500/703 lr 0.100000 loss 2.1648 (2.2657) acc@1 0.1875 (0.1364) acc@5 0.6406 (0.5892)\n",
      "\u001b[32m[2020-07-01 01:55:50] __main__ INFO: \u001b[0mEpoch 2 Step 600/703 lr 0.100000 loss 2.2370 (2.2636) acc@1 0.2031 (0.1382) acc@5 0.6562 (0.5895)\n",
      "\u001b[32m[2020-07-01 01:56:22] __main__ INFO: \u001b[0mEpoch 2 Step 700/703 lr 0.100000 loss 2.2091 (2.2612) acc@1 0.1562 (0.1391) acc@5 0.6094 (0.5919)\n",
      "\u001b[32m[2020-07-01 01:56:23] __main__ INFO: \u001b[0mEpoch 2 Step 703/703 lr 0.100000 loss 2.2346 (2.2612) acc@1 0.1562 (0.1392) acc@5 0.5938 (0.5919)\n",
      "\u001b[32m[2020-07-01 01:56:23] __main__ INFO: \u001b[0mElapsed 224.28\n",
      "\u001b[32m[2020-07-01 01:56:23] __main__ INFO: \u001b[0mVal 2\n",
      "\u001b[32m[2020-07-01 01:56:30] __main__ INFO: \u001b[0mEpoch 2 loss 2.0211 acc@1 0.2270 acc@5 0.7872\n",
      "\u001b[32m[2020-07-01 01:56:30] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-01 01:56:30] __main__ INFO: \u001b[0mTrain 3 1406\n",
      "\u001b[32m[2020-07-01 01:57:02] __main__ INFO: \u001b[0mEpoch 3 Step 100/703 lr 0.100000 loss 2.2572 (2.2288) acc@1 0.1562 (0.1528) acc@5 0.5781 (0.6077)\n",
      "\u001b[32m[2020-07-01 01:57:34] __main__ INFO: \u001b[0mEpoch 3 Step 200/703 lr 0.100000 loss 2.2061 (2.2268) acc@1 0.1562 (0.1520) acc@5 0.6719 (0.6152)\n",
      "\u001b[32m[2020-07-01 01:58:06] __main__ INFO: \u001b[0mEpoch 3 Step 300/703 lr 0.100000 loss 2.2488 (2.2254) acc@1 0.1250 (0.1533) acc@5 0.5781 (0.6168)\n",
      "\u001b[32m[2020-07-01 01:58:38] __main__ INFO: \u001b[0mEpoch 3 Step 400/703 lr 0.100000 loss 2.2648 (2.2205) acc@1 0.1875 (0.1560) acc@5 0.5156 (0.6170)\n",
      "\u001b[32m[2020-07-01 01:59:10] __main__ INFO: \u001b[0mEpoch 3 Step 500/703 lr 0.100000 loss 2.2062 (2.2164) acc@1 0.1562 (0.1574) acc@5 0.6406 (0.6210)\n",
      "\u001b[32m[2020-07-01 01:59:42] __main__ INFO: \u001b[0mEpoch 3 Step 600/703 lr 0.100000 loss 2.1469 (2.2131) acc@1 0.1719 (0.1585) acc@5 0.6719 (0.6223)\n",
      "\u001b[32m[2020-07-01 02:00:14] __main__ INFO: \u001b[0mEpoch 3 Step 700/703 lr 0.100000 loss 2.2483 (2.2084) acc@1 0.1250 (0.1606) acc@5 0.4844 (0.6254)\n",
      "\u001b[32m[2020-07-01 02:00:15] __main__ INFO: \u001b[0mEpoch 3 Step 703/703 lr 0.100000 loss 2.0920 (2.2080) acc@1 0.2656 (0.1608) acc@5 0.6875 (0.6257)\n",
      "\u001b[32m[2020-07-01 02:00:15] __main__ INFO: \u001b[0mElapsed 224.42\n",
      "\u001b[32m[2020-07-01 02:00:15] __main__ INFO: \u001b[0mVal 3\n",
      "\u001b[32m[2020-07-01 02:00:23] __main__ INFO: \u001b[0mEpoch 3 loss 1.9330 acc@1 0.3008 acc@5 0.8198\n",
      "\u001b[32m[2020-07-01 02:00:23] __main__ INFO: \u001b[0mElapsed 7.81\n",
      "\u001b[32m[2020-07-01 02:00:23] __main__ INFO: \u001b[0mTrain 4 2109\n",
      "\u001b[32m[2020-07-01 02:00:55] __main__ INFO: \u001b[0mEpoch 4 Step 100/703 lr 0.100000 loss 2.1646 (2.1703) acc@1 0.2188 (0.1762) acc@5 0.7500 (0.6577)\n",
      "\u001b[32m[2020-07-01 02:01:27] __main__ INFO: \u001b[0mEpoch 4 Step 200/703 lr 0.100000 loss 2.1920 (2.1719) acc@1 0.1094 (0.1759) acc@5 0.6094 (0.6548)\n",
      "\u001b[32m[2020-07-01 02:01:59] __main__ INFO: \u001b[0mEpoch 4 Step 300/703 lr 0.100000 loss 2.1388 (2.1691) acc@1 0.2344 (0.1783) acc@5 0.6562 (0.6546)\n",
      "\u001b[32m[2020-07-01 02:02:31] __main__ INFO: \u001b[0mEpoch 4 Step 400/703 lr 0.100000 loss 2.1242 (2.1657) acc@1 0.2188 (0.1797) acc@5 0.7188 (0.6573)\n",
      "\u001b[32m[2020-07-01 02:03:03] __main__ INFO: \u001b[0mEpoch 4 Step 500/703 lr 0.100000 loss 2.1692 (2.1654) acc@1 0.1719 (0.1807) acc@5 0.6406 (0.6567)\n",
      "\u001b[32m[2020-07-01 02:03:35] __main__ INFO: \u001b[0mEpoch 4 Step 600/703 lr 0.100000 loss 2.1018 (2.1605) acc@1 0.1250 (0.1818) acc@5 0.7344 (0.6565)\n",
      "\u001b[32m[2020-07-01 02:04:06] __main__ INFO: \u001b[0mEpoch 4 Step 700/703 lr 0.100000 loss 2.0460 (2.1570) acc@1 0.2812 (0.1843) acc@5 0.7031 (0.6587)\n",
      "\u001b[32m[2020-07-01 02:04:07] __main__ INFO: \u001b[0mEpoch 4 Step 703/703 lr 0.100000 loss 2.1559 (2.1568) acc@1 0.1562 (0.1845) acc@5 0.6250 (0.6587)\n",
      "\u001b[32m[2020-07-01 02:04:07] __main__ INFO: \u001b[0mElapsed 224.72\n",
      "\u001b[32m[2020-07-01 02:04:07] __main__ INFO: \u001b[0mVal 4\n",
      "\u001b[32m[2020-07-01 02:04:15] __main__ INFO: \u001b[0mEpoch 4 loss 1.7377 acc@1 0.3562 acc@5 0.8620\n",
      "\u001b[32m[2020-07-01 02:04:15] __main__ INFO: \u001b[0mElapsed 7.83\n",
      "\u001b[32m[2020-07-01 02:04:15] __main__ INFO: \u001b[0mTrain 5 2812\n",
      "\u001b[32m[2020-07-01 02:04:47] __main__ INFO: \u001b[0mEpoch 5 Step 100/703 lr 0.100000 loss 1.9774 (2.1292) acc@1 0.3281 (0.1941) acc@5 0.7969 (0.6733)\n",
      "\u001b[32m[2020-07-01 02:05:19] __main__ INFO: \u001b[0mEpoch 5 Step 200/703 lr 0.100000 loss 2.0865 (2.1262) acc@1 0.2344 (0.1966) acc@5 0.7344 (0.6710)\n",
      "\u001b[32m[2020-07-01 02:05:51] __main__ INFO: \u001b[0mEpoch 5 Step 300/703 lr 0.100000 loss 2.0316 (2.1228) acc@1 0.2188 (0.1979) acc@5 0.7031 (0.6707)\n",
      "\u001b[32m[2020-07-01 02:06:23] __main__ INFO: \u001b[0mEpoch 5 Step 400/703 lr 0.100000 loss 1.9928 (2.1218) acc@1 0.2188 (0.1990) acc@5 0.7969 (0.6701)\n",
      "\u001b[32m[2020-07-01 02:06:55] __main__ INFO: \u001b[0mEpoch 5 Step 500/703 lr 0.100000 loss 2.1173 (2.1206) acc@1 0.1719 (0.2005) acc@5 0.6094 (0.6710)\n",
      "\u001b[32m[2020-07-01 02:07:27] __main__ INFO: \u001b[0mEpoch 5 Step 600/703 lr 0.100000 loss 2.1580 (2.1186) acc@1 0.1562 (0.2012) acc@5 0.7031 (0.6732)\n",
      "\u001b[32m[2020-07-01 02:07:59] __main__ INFO: \u001b[0mEpoch 5 Step 700/703 lr 0.100000 loss 2.1661 (2.1126) acc@1 0.1875 (0.2044) acc@5 0.6406 (0.6745)\n",
      "\u001b[32m[2020-07-01 02:08:00] __main__ INFO: \u001b[0mEpoch 5 Step 703/703 lr 0.100000 loss 2.1691 (2.1124) acc@1 0.2031 (0.2046) acc@5 0.6094 (0.6745)\n",
      "\u001b[32m[2020-07-01 02:08:00] __main__ INFO: \u001b[0mElapsed 225.05\n",
      "\u001b[32m[2020-07-01 02:08:00] __main__ INFO: \u001b[0mVal 5\n",
      "\u001b[32m[2020-07-01 02:08:08] __main__ INFO: \u001b[0mEpoch 5 loss 1.6780 acc@1 0.3796 acc@5 0.8824\n",
      "\u001b[32m[2020-07-01 02:08:08] __main__ INFO: \u001b[0mElapsed 7.82\n",
      "\u001b[32m[2020-07-01 02:08:08] __main__ INFO: \u001b[0mTrain 6 3515\n",
      "\u001b[32m[2020-07-01 02:08:40] __main__ INFO: \u001b[0mEpoch 6 Step 100/703 lr 0.100000 loss 2.0399 (2.0739) acc@1 0.2812 (0.2223) acc@5 0.7344 (0.6883)\n",
      "\u001b[32m[2020-07-01 02:09:12] __main__ INFO: \u001b[0mEpoch 6 Step 200/703 lr 0.100000 loss 2.0197 (2.0782) acc@1 0.2500 (0.2189) acc@5 0.6562 (0.6868)\n",
      "\u001b[32m[2020-07-01 02:09:44] __main__ INFO: \u001b[0mEpoch 6 Step 300/703 lr 0.100000 loss 2.0453 (2.0796) acc@1 0.2188 (0.2181) acc@5 0.7344 (0.6847)\n",
      "\u001b[32m[2020-07-01 02:10:16] __main__ INFO: \u001b[0mEpoch 6 Step 400/703 lr 0.100000 loss 2.2018 (2.0781) acc@1 0.1719 (0.2196) acc@5 0.6562 (0.6855)\n",
      "\u001b[32m[2020-07-01 02:10:48] __main__ INFO: \u001b[0mEpoch 6 Step 500/703 lr 0.100000 loss 1.8570 (2.0737) acc@1 0.2969 (0.2218) acc@5 0.7031 (0.6865)\n",
      "\u001b[32m[2020-07-01 02:11:20] __main__ INFO: \u001b[0mEpoch 6 Step 600/703 lr 0.100000 loss 2.1138 (2.0709) acc@1 0.1719 (0.2215) acc@5 0.6562 (0.6880)\n",
      "\u001b[32m[2020-07-01 02:11:52] __main__ INFO: \u001b[0mEpoch 6 Step 700/703 lr 0.100000 loss 2.0481 (2.0675) acc@1 0.3281 (0.2233) acc@5 0.7188 (0.6879)\n",
      "\u001b[32m[2020-07-01 02:11:53] __main__ INFO: \u001b[0mEpoch 6 Step 703/703 lr 0.100000 loss 2.0455 (2.0675) acc@1 0.2031 (0.2232) acc@5 0.7188 (0.6879)\n",
      "\u001b[32m[2020-07-01 02:11:53] __main__ INFO: \u001b[0mElapsed 225.04\n",
      "\u001b[32m[2020-07-01 02:11:53] __main__ INFO: \u001b[0mVal 6\n",
      "\u001b[32m[2020-07-01 02:12:01] __main__ INFO: \u001b[0mEpoch 6 loss 1.5282 acc@1 0.4260 acc@5 0.9142\n",
      "\u001b[32m[2020-07-01 02:12:01] __main__ INFO: \u001b[0mElapsed 7.81\n",
      "\u001b[32m[2020-07-01 02:12:01] __main__ INFO: \u001b[0mTrain 7 4218\n",
      "\u001b[32m[2020-07-01 02:12:33] __main__ INFO: \u001b[0mEpoch 7 Step 100/703 lr 0.100000 loss 1.9139 (2.0302) acc@1 0.4062 (0.2400) acc@5 0.6719 (0.6973)\n",
      "\u001b[32m[2020-07-01 02:13:05] __main__ INFO: \u001b[0mEpoch 7 Step 200/703 lr 0.100000 loss 2.0652 (2.0288) acc@1 0.1562 (0.2399) acc@5 0.6719 (0.7030)\n",
      "\u001b[32m[2020-07-01 02:13:37] __main__ INFO: \u001b[0mEpoch 7 Step 300/703 lr 0.100000 loss 2.2506 (2.0253) acc@1 0.1719 (0.2416) acc@5 0.7031 (0.7022)\n",
      "\u001b[32m[2020-07-01 02:14:09] __main__ INFO: \u001b[0mEpoch 7 Step 400/703 lr 0.100000 loss 2.2060 (2.0242) acc@1 0.0938 (0.2432) acc@5 0.5469 (0.7009)\n",
      "\u001b[32m[2020-07-01 02:14:41] __main__ INFO: \u001b[0mEpoch 7 Step 500/703 lr 0.100000 loss 2.0617 (2.0217) acc@1 0.2188 (0.2442) acc@5 0.5938 (0.7018)\n",
      "\u001b[32m[2020-07-01 02:15:13] __main__ INFO: \u001b[0mEpoch 7 Step 600/703 lr 0.100000 loss 2.0597 (2.0197) acc@1 0.2656 (0.2462) acc@5 0.6719 (0.7026)\n",
      "\u001b[32m[2020-07-01 02:15:45] __main__ INFO: \u001b[0mEpoch 7 Step 700/703 lr 0.100000 loss 1.9279 (2.0170) acc@1 0.2656 (0.2460) acc@5 0.7031 (0.7020)\n",
      "\u001b[32m[2020-07-01 02:15:46] __main__ INFO: \u001b[0mEpoch 7 Step 703/703 lr 0.100000 loss 2.0378 (2.0168) acc@1 0.2500 (0.2461) acc@5 0.6719 (0.7019)\n",
      "\u001b[32m[2020-07-01 02:15:46] __main__ INFO: \u001b[0mElapsed 224.92\n",
      "\u001b[32m[2020-07-01 02:15:46] __main__ INFO: \u001b[0mVal 7\n",
      "\u001b[32m[2020-07-01 02:15:54] __main__ INFO: \u001b[0mEpoch 7 loss 1.4302 acc@1 0.4900 acc@5 0.9174\n",
      "\u001b[32m[2020-07-01 02:15:54] __main__ INFO: \u001b[0mElapsed 7.81\n",
      "\u001b[32m[2020-07-01 02:15:54] __main__ INFO: \u001b[0mTrain 8 4921\n",
      "\u001b[32m[2020-07-01 02:16:26] __main__ INFO: \u001b[0mEpoch 8 Step 100/703 lr 0.100000 loss 1.9044 (1.9842) acc@1 0.2812 (0.2591) acc@5 0.7656 (0.7197)\n",
      "\u001b[32m[2020-07-01 02:16:58] __main__ INFO: \u001b[0mEpoch 8 Step 200/703 lr 0.100000 loss 1.9917 (1.9782) acc@1 0.2500 (0.2611) acc@5 0.7031 (0.7180)\n",
      "\u001b[32m[2020-07-01 02:17:30] __main__ INFO: \u001b[0mEpoch 8 Step 300/703 lr 0.100000 loss 2.0623 (1.9739) acc@1 0.2188 (0.2637) acc@5 0.7656 (0.7207)\n",
      "\u001b[32m[2020-07-01 02:18:02] __main__ INFO: \u001b[0mEpoch 8 Step 400/703 lr 0.100000 loss 1.9972 (1.9752) acc@1 0.3125 (0.2629) acc@5 0.6406 (0.7176)\n",
      "\u001b[32m[2020-07-01 02:18:34] __main__ INFO: \u001b[0mEpoch 8 Step 500/703 lr 0.100000 loss 2.1170 (1.9711) acc@1 0.2344 (0.2652) acc@5 0.6562 (0.7191)\n",
      "\u001b[32m[2020-07-01 02:19:06] __main__ INFO: \u001b[0mEpoch 8 Step 600/703 lr 0.100000 loss 1.8832 (1.9681) acc@1 0.3281 (0.2662) acc@5 0.7188 (0.7198)\n",
      "\u001b[32m[2020-07-01 02:19:38] __main__ INFO: \u001b[0mEpoch 8 Step 700/703 lr 0.100000 loss 1.9163 (1.9667) acc@1 0.3281 (0.2671) acc@5 0.7188 (0.7192)\n",
      "\u001b[32m[2020-07-01 02:19:38] __main__ INFO: \u001b[0mEpoch 8 Step 703/703 lr 0.100000 loss 1.9618 (1.9664) acc@1 0.2812 (0.2673) acc@5 0.7188 (0.7194)\n",
      "\u001b[32m[2020-07-01 02:19:39] __main__ INFO: \u001b[0mElapsed 224.78\n",
      "\u001b[32m[2020-07-01 02:19:39] __main__ INFO: \u001b[0mVal 8\n",
      "\u001b[32m[2020-07-01 02:19:46] __main__ INFO: \u001b[0mEpoch 8 loss 1.3405 acc@1 0.5260 acc@5 0.9320\n",
      "\u001b[32m[2020-07-01 02:19:46] __main__ INFO: \u001b[0mElapsed 7.84\n",
      "\u001b[32m[2020-07-01 02:19:46] __main__ INFO: \u001b[0mTrain 9 5624\n",
      "\u001b[32m[2020-07-01 02:20:18] __main__ INFO: \u001b[0mEpoch 9 Step 100/703 lr 0.100000 loss 2.1159 (1.9347) acc@1 0.2969 (0.2789) acc@5 0.7188 (0.7233)\n",
      "\u001b[32m[2020-07-01 02:20:50] __main__ INFO: \u001b[0mEpoch 9 Step 200/703 lr 0.100000 loss 1.9115 (1.9319) acc@1 0.2656 (0.2822) acc@5 0.7344 (0.7274)\n",
      "\u001b[32m[2020-07-01 02:21:22] __main__ INFO: \u001b[0mEpoch 9 Step 300/703 lr 0.100000 loss 1.9333 (1.9279) acc@1 0.2656 (0.2825) acc@5 0.7188 (0.7290)\n",
      "\u001b[32m[2020-07-01 02:21:54] __main__ INFO: \u001b[0mEpoch 9 Step 400/703 lr 0.100000 loss 2.0176 (1.9274) acc@1 0.2500 (0.2852) acc@5 0.6875 (0.7271)\n",
      "\u001b[32m[2020-07-01 02:22:26] __main__ INFO: \u001b[0mEpoch 9 Step 500/703 lr 0.100000 loss 1.9639 (1.9257) acc@1 0.3125 (0.2859) acc@5 0.7031 (0.7281)\n",
      "\u001b[32m[2020-07-01 02:22:58] __main__ INFO: \u001b[0mEpoch 9 Step 600/703 lr 0.100000 loss 1.9003 (1.9197) acc@1 0.2812 (0.2873) acc@5 0.7500 (0.7304)\n",
      "\u001b[32m[2020-07-01 02:23:30] __main__ INFO: \u001b[0mEpoch 9 Step 700/703 lr 0.100000 loss 2.1372 (1.9192) acc@1 0.1250 (0.2874) acc@5 0.6406 (0.7299)\n",
      "\u001b[32m[2020-07-01 02:23:31] __main__ INFO: \u001b[0mEpoch 9 Step 703/703 lr 0.100000 loss 1.9732 (1.9192) acc@1 0.2812 (0.2875) acc@5 0.6875 (0.7298)\n",
      "\u001b[32m[2020-07-01 02:23:31] __main__ INFO: \u001b[0mElapsed 224.53\n",
      "\u001b[32m[2020-07-01 02:23:31] __main__ INFO: \u001b[0mVal 9\n",
      "\u001b[32m[2020-07-01 02:23:39] __main__ INFO: \u001b[0mEpoch 9 loss 1.5987 acc@1 0.4632 acc@5 0.8854\n",
      "\u001b[32m[2020-07-01 02:23:39] __main__ INFO: \u001b[0mElapsed 7.79\n",
      "\u001b[32m[2020-07-01 02:23:39] __main__ INFO: \u001b[0mTrain 10 6327\n",
      "\u001b[32m[2020-07-01 02:24:11] __main__ INFO: \u001b[0mEpoch 10 Step 100/703 lr 0.100000 loss 1.8410 (1.8782) acc@1 0.3750 (0.3067) acc@5 0.6719 (0.7378)\n",
      "\u001b[32m[2020-07-01 02:24:43] __main__ INFO: \u001b[0mEpoch 10 Step 200/703 lr 0.100000 loss 1.8546 (1.8854) acc@1 0.3281 (0.3014) acc@5 0.7188 (0.7349)\n",
      "\u001b[32m[2020-07-01 02:25:15] __main__ INFO: \u001b[0mEpoch 10 Step 300/703 lr 0.100000 loss 1.6714 (1.8827) acc@1 0.3906 (0.3023) acc@5 0.7500 (0.7369)\n",
      "\u001b[32m[2020-07-01 02:25:46] __main__ INFO: \u001b[0mEpoch 10 Step 400/703 lr 0.100000 loss 1.8136 (1.8773) acc@1 0.3281 (0.3034) acc@5 0.7812 (0.7370)\n",
      "\u001b[32m[2020-07-01 02:26:18] __main__ INFO: \u001b[0mEpoch 10 Step 500/703 lr 0.100000 loss 1.7485 (1.8748) acc@1 0.3594 (0.3028) acc@5 0.7500 (0.7383)\n",
      "\u001b[32m[2020-07-01 02:26:50] __main__ INFO: \u001b[0mEpoch 10 Step 600/703 lr 0.100000 loss 2.0389 (1.8749) acc@1 0.2812 (0.3031) acc@5 0.6875 (0.7382)\n",
      "\u001b[32m[2020-07-01 02:27:22] __main__ INFO: \u001b[0mEpoch 10 Step 700/703 lr 0.100000 loss 1.6399 (1.8756) acc@1 0.3281 (0.3036) acc@5 0.7656 (0.7360)\n",
      "\u001b[32m[2020-07-01 02:27:23] __main__ INFO: \u001b[0mEpoch 10 Step 703/703 lr 0.100000 loss 1.8690 (1.8755) acc@1 0.2656 (0.3037) acc@5 0.7188 (0.7360)\n",
      "\u001b[32m[2020-07-01 02:27:23] __main__ INFO: \u001b[0mElapsed 224.72\n",
      "\u001b[32m[2020-07-01 02:27:23] __main__ INFO: \u001b[0mVal 10\n",
      "\u001b[32m[2020-07-01 02:27:31] __main__ INFO: \u001b[0mEpoch 10 loss 1.2404 acc@1 0.5612 acc@5 0.9520\n",
      "\u001b[32m[2020-07-01 02:27:31] __main__ INFO: \u001b[0mElapsed 7.81\n",
      "\u001b[32m[2020-07-01 02:27:31] __main__ INFO: \u001b[0mTrain 11 7030\n",
      "\u001b[32m[2020-07-01 02:28:03] __main__ INFO: \u001b[0mEpoch 11 Step 100/703 lr 0.100000 loss 1.8991 (1.8436) acc@1 0.2812 (0.3131) acc@5 0.7344 (0.7427)\n",
      "\u001b[32m[2020-07-01 02:28:35] __main__ INFO: \u001b[0mEpoch 11 Step 200/703 lr 0.100000 loss 1.6798 (1.8429) acc@1 0.3438 (0.3139) acc@5 0.8125 (0.7398)\n",
      "\u001b[32m[2020-07-01 02:29:07] __main__ INFO: \u001b[0mEpoch 11 Step 300/703 lr 0.100000 loss 1.7580 (1.8473) acc@1 0.3438 (0.3127) acc@5 0.7969 (0.7393)\n",
      "\u001b[32m[2020-07-01 02:29:39] __main__ INFO: \u001b[0mEpoch 11 Step 400/703 lr 0.100000 loss 1.9393 (1.8459) acc@1 0.2500 (0.3136) acc@5 0.6875 (0.7382)\n",
      "\u001b[32m[2020-07-01 02:30:11] __main__ INFO: \u001b[0mEpoch 11 Step 500/703 lr 0.100000 loss 1.5977 (1.8414) acc@1 0.3750 (0.3151) acc@5 0.8594 (0.7406)\n",
      "\u001b[32m[2020-07-01 02:30:43] __main__ INFO: \u001b[0mEpoch 11 Step 600/703 lr 0.100000 loss 1.7378 (1.8419) acc@1 0.3906 (0.3148) acc@5 0.7031 (0.7409)\n",
      "\u001b[32m[2020-07-01 02:31:15] __main__ INFO: \u001b[0mEpoch 11 Step 700/703 lr 0.100000 loss 1.7454 (1.8380) acc@1 0.2969 (0.3161) acc@5 0.7500 (0.7431)\n",
      "\u001b[32m[2020-07-01 02:31:16] __main__ INFO: \u001b[0mEpoch 11 Step 703/703 lr 0.100000 loss 1.8702 (1.8379) acc@1 0.2500 (0.3161) acc@5 0.6875 (0.7430)\n",
      "\u001b[32m[2020-07-01 02:31:16] __main__ INFO: \u001b[0mElapsed 224.88\n",
      "\u001b[32m[2020-07-01 02:31:16] __main__ INFO: \u001b[0mVal 11\n",
      "\u001b[32m[2020-07-01 02:31:24] __main__ INFO: \u001b[0mEpoch 11 loss 1.1421 acc@1 0.5972 acc@5 0.9506\n",
      "\u001b[32m[2020-07-01 02:31:24] __main__ INFO: \u001b[0mElapsed 7.79\n",
      "\u001b[32m[2020-07-01 02:31:24] __main__ INFO: \u001b[0mTrain 12 7733\n",
      "\u001b[32m[2020-07-01 02:31:56] __main__ INFO: \u001b[0mEpoch 12 Step 100/703 lr 0.100000 loss 1.7216 (1.8230) acc@1 0.3281 (0.3294) acc@5 0.8594 (0.7472)\n",
      "\u001b[32m[2020-07-01 02:32:28] __main__ INFO: \u001b[0mEpoch 12 Step 200/703 lr 0.100000 loss 1.8338 (1.8216) acc@1 0.2656 (0.3256) acc@5 0.7500 (0.7533)\n",
      "\u001b[32m[2020-07-01 02:33:00] __main__ INFO: \u001b[0mEpoch 12 Step 300/703 lr 0.100000 loss 1.7139 (1.8113) acc@1 0.3594 (0.3294) acc@5 0.7969 (0.7554)\n",
      "\u001b[32m[2020-07-01 02:33:32] __main__ INFO: \u001b[0mEpoch 12 Step 400/703 lr 0.100000 loss 1.5964 (1.8068) acc@1 0.4375 (0.3312) acc@5 0.8281 (0.7556)\n",
      "\u001b[32m[2020-07-01 02:34:04] __main__ INFO: \u001b[0mEpoch 12 Step 500/703 lr 0.100000 loss 1.8294 (1.8083) acc@1 0.3438 (0.3297) acc@5 0.8125 (0.7543)\n",
      "\u001b[32m[2020-07-01 02:34:36] __main__ INFO: \u001b[0mEpoch 12 Step 600/703 lr 0.100000 loss 1.8283 (1.8125) acc@1 0.3750 (0.3267) acc@5 0.7500 (0.7528)\n",
      "\u001b[32m[2020-07-01 02:35:08] __main__ INFO: \u001b[0mEpoch 12 Step 700/703 lr 0.100000 loss 2.0567 (1.8101) acc@1 0.2969 (0.3274) acc@5 0.6406 (0.7526)\n",
      "\u001b[32m[2020-07-01 02:35:09] __main__ INFO: \u001b[0mEpoch 12 Step 703/703 lr 0.100000 loss 1.7419 (1.8101) acc@1 0.2969 (0.3274) acc@5 0.7031 (0.7524)\n",
      "\u001b[32m[2020-07-01 02:35:09] __main__ INFO: \u001b[0mElapsed 224.73\n",
      "\u001b[32m[2020-07-01 02:35:09] __main__ INFO: \u001b[0mVal 12\n",
      "\u001b[32m[2020-07-01 02:35:16] __main__ INFO: \u001b[0mEpoch 12 loss 1.1566 acc@1 0.5968 acc@5 0.9574\n",
      "\u001b[32m[2020-07-01 02:35:16] __main__ INFO: \u001b[0mElapsed 7.82\n",
      "\u001b[32m[2020-07-01 02:35:16] __main__ INFO: \u001b[0mTrain 13 8436\n",
      "\u001b[32m[2020-07-01 02:35:49] __main__ INFO: \u001b[0mEpoch 13 Step 100/703 lr 0.100000 loss 1.6055 (1.7782) acc@1 0.4219 (0.3366) acc@5 0.7656 (0.7653)\n",
      "\u001b[32m[2020-07-01 02:36:20] __main__ INFO: \u001b[0mEpoch 13 Step 200/703 lr 0.100000 loss 1.7232 (1.7895) acc@1 0.3750 (0.3340) acc@5 0.7969 (0.7596)\n",
      "\u001b[32m[2020-07-01 02:36:52] __main__ INFO: \u001b[0mEpoch 13 Step 300/703 lr 0.100000 loss 1.7535 (1.7853) acc@1 0.3594 (0.3377) acc@5 0.8281 (0.7587)\n",
      "\u001b[32m[2020-07-01 02:37:24] __main__ INFO: \u001b[0mEpoch 13 Step 400/703 lr 0.100000 loss 1.7027 (1.7829) acc@1 0.3281 (0.3377) acc@5 0.7969 (0.7590)\n",
      "\u001b[32m[2020-07-01 02:37:56] __main__ INFO: \u001b[0mEpoch 13 Step 500/703 lr 0.100000 loss 1.8541 (1.7836) acc@1 0.2812 (0.3372) acc@5 0.7500 (0.7579)\n",
      "\u001b[32m[2020-07-01 02:38:28] __main__ INFO: \u001b[0mEpoch 13 Step 600/703 lr 0.100000 loss 1.7263 (1.7815) acc@1 0.3906 (0.3377) acc@5 0.7969 (0.7572)\n",
      "\u001b[32m[2020-07-01 02:39:00] __main__ INFO: \u001b[0mEpoch 13 Step 700/703 lr 0.100000 loss 1.7040 (1.7833) acc@1 0.3438 (0.3367) acc@5 0.7812 (0.7551)\n",
      "\u001b[32m[2020-07-01 02:39:01] __main__ INFO: \u001b[0mEpoch 13 Step 703/703 lr 0.100000 loss 1.8581 (1.7828) acc@1 0.3125 (0.3369) acc@5 0.7812 (0.7555)\n",
      "\u001b[32m[2020-07-01 02:39:01] __main__ INFO: \u001b[0mElapsed 224.53\n",
      "\u001b[32m[2020-07-01 02:39:01] __main__ INFO: \u001b[0mVal 13\n",
      "\u001b[32m[2020-07-01 02:39:09] __main__ INFO: \u001b[0mEpoch 13 loss 1.0915 acc@1 0.6182 acc@5 0.9572\n",
      "\u001b[32m[2020-07-01 02:39:09] __main__ INFO: \u001b[0mElapsed 7.80\n",
      "\u001b[32m[2020-07-01 02:39:09] __main__ INFO: \u001b[0mTrain 14 9139\n",
      "\u001b[32m[2020-07-01 02:39:41] __main__ INFO: \u001b[0mEpoch 14 Step 100/703 lr 0.100000 loss 2.0621 (1.7561) acc@1 0.2188 (0.3547) acc@5 0.6562 (0.7573)\n",
      "\u001b[32m[2020-07-01 02:40:13] __main__ INFO: \u001b[0mEpoch 14 Step 200/703 lr 0.100000 loss 1.7675 (1.7569) acc@1 0.3906 (0.3501) acc@5 0.7500 (0.7568)\n",
      "\u001b[32m[2020-07-01 02:40:45] __main__ INFO: \u001b[0mEpoch 14 Step 300/703 lr 0.100000 loss 1.8171 (1.7514) acc@1 0.3438 (0.3504) acc@5 0.7031 (0.7612)\n",
      "\u001b[32m[2020-07-01 02:41:17] __main__ INFO: \u001b[0mEpoch 14 Step 400/703 lr 0.100000 loss 1.9941 (1.7525) acc@1 0.2656 (0.3461) acc@5 0.6406 (0.7601)\n",
      "\u001b[32m[2020-07-01 02:41:49] __main__ INFO: \u001b[0mEpoch 14 Step 500/703 lr 0.100000 loss 1.8889 (1.7473) acc@1 0.3281 (0.3489) acc@5 0.7500 (0.7623)\n",
      "\u001b[32m[2020-07-01 02:42:21] __main__ INFO: \u001b[0mEpoch 14 Step 600/703 lr 0.100000 loss 1.8631 (1.7495) acc@1 0.2812 (0.3493) acc@5 0.7188 (0.7628)\n",
      "\u001b[32m[2020-07-01 02:42:52] __main__ INFO: \u001b[0mEpoch 14 Step 700/703 lr 0.100000 loss 1.5377 (1.7516) acc@1 0.4688 (0.3490) acc@5 0.8281 (0.7611)\n",
      "\u001b[32m[2020-07-01 02:42:53] __main__ INFO: \u001b[0mEpoch 14 Step 703/703 lr 0.100000 loss 1.7871 (1.7517) acc@1 0.2656 (0.3488) acc@5 0.7500 (0.7609)\n",
      "\u001b[32m[2020-07-01 02:42:53] __main__ INFO: \u001b[0mElapsed 224.70\n",
      "\u001b[32m[2020-07-01 02:42:53] __main__ INFO: \u001b[0mVal 14\n",
      "\u001b[32m[2020-07-01 02:43:01] __main__ INFO: \u001b[0mEpoch 14 loss 1.2090 acc@1 0.5782 acc@5 0.9536\n",
      "\u001b[32m[2020-07-01 02:43:01] __main__ INFO: \u001b[0mElapsed 7.79\n",
      "\u001b[32m[2020-07-01 02:43:01] __main__ INFO: \u001b[0mTrain 15 9842\n",
      "\u001b[32m[2020-07-01 02:43:33] __main__ INFO: \u001b[0mEpoch 15 Step 100/703 lr 0.100000 loss 1.9784 (1.7267) acc@1 0.2969 (0.3591) acc@5 0.6875 (0.7638)\n",
      "\u001b[32m[2020-07-01 02:44:05] __main__ INFO: \u001b[0mEpoch 15 Step 200/703 lr 0.100000 loss 1.6203 (1.7328) acc@1 0.3438 (0.3613) acc@5 0.7812 (0.7599)\n",
      "\u001b[32m[2020-07-01 02:44:37] __main__ INFO: \u001b[0mEpoch 15 Step 300/703 lr 0.100000 loss 1.7681 (1.7353) acc@1 0.3125 (0.3604) acc@5 0.8594 (0.7575)\n",
      "\u001b[32m[2020-07-01 02:45:09] __main__ INFO: \u001b[0mEpoch 15 Step 400/703 lr 0.100000 loss 1.4724 (1.7289) acc@1 0.4688 (0.3621) acc@5 0.7969 (0.7588)\n",
      "\u001b[32m[2020-07-01 02:45:41] __main__ INFO: \u001b[0mEpoch 15 Step 500/703 lr 0.100000 loss 1.7338 (1.7290) acc@1 0.3906 (0.3607) acc@5 0.7500 (0.7597)\n",
      "\u001b[32m[2020-07-01 02:46:13] __main__ INFO: \u001b[0mEpoch 15 Step 600/703 lr 0.100000 loss 1.7636 (1.7285) acc@1 0.3438 (0.3601) acc@5 0.8125 (0.7604)\n",
      "\u001b[32m[2020-07-01 02:46:45] __main__ INFO: \u001b[0mEpoch 15 Step 700/703 lr 0.100000 loss 1.6615 (1.7256) acc@1 0.3125 (0.3613) acc@5 0.7188 (0.7614)\n",
      "\u001b[32m[2020-07-01 02:46:46] __main__ INFO: \u001b[0mEpoch 15 Step 703/703 lr 0.100000 loss 1.5664 (1.7251) acc@1 0.4375 (0.3614) acc@5 0.8125 (0.7613)\n",
      "\u001b[32m[2020-07-01 02:46:46] __main__ INFO: \u001b[0mElapsed 224.43\n",
      "\u001b[32m[2020-07-01 02:46:46] __main__ INFO: \u001b[0mVal 15\n",
      "\u001b[32m[2020-07-01 02:46:54] __main__ INFO: \u001b[0mEpoch 15 loss 0.9122 acc@1 0.6874 acc@5 0.9728\n",
      "\u001b[32m[2020-07-01 02:46:54] __main__ INFO: \u001b[0mElapsed 7.82\n",
      "\u001b[32m[2020-07-01 02:46:54] __main__ INFO: \u001b[0mTrain 16 10545\n",
      "\u001b[32m[2020-07-01 02:47:25] __main__ INFO: \u001b[0mEpoch 16 Step 100/703 lr 0.100000 loss 1.9125 (1.7050) acc@1 0.2656 (0.3689) acc@5 0.7031 (0.7589)\n",
      "\u001b[32m[2020-07-01 02:47:57] __main__ INFO: \u001b[0mEpoch 16 Step 200/703 lr 0.100000 loss 1.7446 (1.6978) acc@1 0.3125 (0.3709) acc@5 0.7656 (0.7621)\n",
      "\u001b[32m[2020-07-01 02:48:29] __main__ INFO: \u001b[0mEpoch 16 Step 300/703 lr 0.100000 loss 1.6212 (1.6998) acc@1 0.4062 (0.3703) acc@5 0.7344 (0.7634)\n",
      "\u001b[32m[2020-07-01 02:49:01] __main__ INFO: \u001b[0mEpoch 16 Step 400/703 lr 0.100000 loss 1.6963 (1.7008) acc@1 0.3906 (0.3707) acc@5 0.7188 (0.7615)\n",
      "\u001b[32m[2020-07-01 02:49:33] __main__ INFO: \u001b[0mEpoch 16 Step 500/703 lr 0.100000 loss 1.7478 (1.7065) acc@1 0.3281 (0.3683) acc@5 0.7188 (0.7599)\n",
      "\u001b[32m[2020-07-01 02:50:05] __main__ INFO: \u001b[0mEpoch 16 Step 600/703 lr 0.100000 loss 1.7087 (1.7034) acc@1 0.4375 (0.3703) acc@5 0.7812 (0.7624)\n",
      "\u001b[32m[2020-07-01 02:50:37] __main__ INFO: \u001b[0mEpoch 16 Step 700/703 lr 0.100000 loss 1.8112 (1.7045) acc@1 0.3594 (0.3691) acc@5 0.7656 (0.7621)\n",
      "\u001b[32m[2020-07-01 02:50:38] __main__ INFO: \u001b[0mEpoch 16 Step 703/703 lr 0.100000 loss 1.5433 (1.7044) acc@1 0.3906 (0.3691) acc@5 0.7969 (0.7620)\n",
      "\u001b[32m[2020-07-01 02:50:38] __main__ INFO: \u001b[0mElapsed 224.61\n",
      "\u001b[32m[2020-07-01 02:50:38] __main__ INFO: \u001b[0mVal 16\n",
      "\u001b[32m[2020-07-01 02:50:46] __main__ INFO: \u001b[0mEpoch 16 loss 0.9512 acc@1 0.6706 acc@5 0.9732\n",
      "\u001b[32m[2020-07-01 02:50:46] __main__ INFO: \u001b[0mElapsed 7.79\n",
      "\u001b[32m[2020-07-01 02:50:46] __main__ INFO: \u001b[0mTrain 17 11248\n",
      "\u001b[32m[2020-07-01 02:51:18] __main__ INFO: \u001b[0mEpoch 17 Step 100/703 lr 0.100000 loss 1.5108 (1.6757) acc@1 0.3750 (0.3841) acc@5 0.8750 (0.7752)\n",
      "\u001b[32m[2020-07-01 02:51:50] __main__ INFO: \u001b[0mEpoch 17 Step 200/703 lr 0.100000 loss 1.6211 (1.6955) acc@1 0.4062 (0.3746) acc@5 0.8438 (0.7678)\n",
      "\u001b[32m[2020-07-01 02:52:22] __main__ INFO: \u001b[0mEpoch 17 Step 300/703 lr 0.100000 loss 1.7692 (1.6889) acc@1 0.4219 (0.3768) acc@5 0.7188 (0.7692)\n",
      "\u001b[32m[2020-07-01 02:52:54] __main__ INFO: \u001b[0mEpoch 17 Step 400/703 lr 0.100000 loss 1.9502 (1.6872) acc@1 0.3125 (0.3771) acc@5 0.7031 (0.7695)\n",
      "\u001b[32m[2020-07-01 02:53:26] __main__ INFO: \u001b[0mEpoch 17 Step 500/703 lr 0.100000 loss 1.5583 (1.6879) acc@1 0.4219 (0.3761) acc@5 0.7812 (0.7682)\n",
      "\u001b[32m[2020-07-01 02:53:58] __main__ INFO: \u001b[0mEpoch 17 Step 600/703 lr 0.100000 loss 1.6602 (1.6870) acc@1 0.3594 (0.3771) acc@5 0.7812 (0.7694)\n",
      "\u001b[32m[2020-07-01 02:54:30] __main__ INFO: \u001b[0mEpoch 17 Step 700/703 lr 0.100000 loss 1.6061 (1.6846) acc@1 0.4062 (0.3773) acc@5 0.7344 (0.7691)\n",
      "\u001b[32m[2020-07-01 02:54:31] __main__ INFO: \u001b[0mEpoch 17 Step 703/703 lr 0.100000 loss 1.7366 (1.6847) acc@1 0.3438 (0.3775) acc@5 0.7500 (0.7693)\n",
      "\u001b[32m[2020-07-01 02:54:31] __main__ INFO: \u001b[0mElapsed 224.78\n",
      "\u001b[32m[2020-07-01 02:54:31] __main__ INFO: \u001b[0mVal 17\n",
      "\u001b[32m[2020-07-01 02:54:39] __main__ INFO: \u001b[0mEpoch 17 loss 0.8070 acc@1 0.7170 acc@5 0.9756\n",
      "\u001b[32m[2020-07-01 02:54:39] __main__ INFO: \u001b[0mElapsed 7.82\n",
      "\u001b[32m[2020-07-01 02:54:39] __main__ INFO: \u001b[0mTrain 18 11951\n",
      "\u001b[32m[2020-07-01 02:55:11] __main__ INFO: \u001b[0mEpoch 18 Step 100/703 lr 0.100000 loss 1.5209 (1.6651) acc@1 0.4219 (0.3794) acc@5 0.7969 (0.7773)\n",
      "\u001b[32m[2020-07-01 02:55:42] __main__ INFO: \u001b[0mEpoch 18 Step 200/703 lr 0.100000 loss 1.6852 (1.6668) acc@1 0.4062 (0.3811) acc@5 0.7656 (0.7727)\n",
      "\u001b[32m[2020-07-01 02:56:14] __main__ INFO: \u001b[0mEpoch 18 Step 300/703 lr 0.100000 loss 1.6341 (1.6660) acc@1 0.3281 (0.3813) acc@5 0.8125 (0.7726)\n",
      "\u001b[32m[2020-07-01 02:56:46] __main__ INFO: \u001b[0mEpoch 18 Step 400/703 lr 0.100000 loss 1.5900 (1.6682) acc@1 0.4062 (0.3800) acc@5 0.8281 (0.7690)\n",
      "\u001b[32m[2020-07-01 02:57:18] __main__ INFO: \u001b[0mEpoch 18 Step 500/703 lr 0.100000 loss 1.8188 (1.6679) acc@1 0.3594 (0.3781) acc@5 0.7344 (0.7712)\n",
      "\u001b[32m[2020-07-01 02:57:50] __main__ INFO: \u001b[0mEpoch 18 Step 600/703 lr 0.100000 loss 1.8056 (1.6690) acc@1 0.2500 (0.3789) acc@5 0.7500 (0.7706)\n",
      "\u001b[32m[2020-07-01 02:58:22] __main__ INFO: \u001b[0mEpoch 18 Step 700/703 lr 0.100000 loss 1.6358 (1.6676) acc@1 0.4219 (0.3805) acc@5 0.8281 (0.7700)\n",
      "\u001b[32m[2020-07-01 02:58:23] __main__ INFO: \u001b[0mEpoch 18 Step 703/703 lr 0.100000 loss 1.7821 (1.6681) acc@1 0.3594 (0.3803) acc@5 0.7344 (0.7701)\n",
      "\u001b[32m[2020-07-01 02:58:23] __main__ INFO: \u001b[0mElapsed 224.42\n",
      "\u001b[32m[2020-07-01 02:58:23] __main__ INFO: \u001b[0mVal 18\n",
      "\u001b[32m[2020-07-01 02:58:31] __main__ INFO: \u001b[0mEpoch 18 loss 0.8600 acc@1 0.7064 acc@5 0.9740\n",
      "\u001b[32m[2020-07-01 02:58:31] __main__ INFO: \u001b[0mElapsed 7.80\n",
      "\u001b[32m[2020-07-01 02:58:31] __main__ INFO: \u001b[0mTrain 19 12654\n",
      "\u001b[32m[2020-07-01 02:59:03] __main__ INFO: \u001b[0mEpoch 19 Step 100/703 lr 0.100000 loss 1.5178 (1.6295) acc@1 0.4688 (0.3992) acc@5 0.8438 (0.7812)\n",
      "\u001b[32m[2020-07-01 02:59:35] __main__ INFO: \u001b[0mEpoch 19 Step 200/703 lr 0.100000 loss 1.5371 (1.6407) acc@1 0.4844 (0.3943) acc@5 0.7656 (0.7780)\n",
      "\u001b[32m[2020-07-01 03:00:07] __main__ INFO: \u001b[0mEpoch 19 Step 300/703 lr 0.100000 loss 1.6097 (1.6385) acc@1 0.3438 (0.3959) acc@5 0.7656 (0.7754)\n",
      "\u001b[32m[2020-07-01 03:00:38] __main__ INFO: \u001b[0mEpoch 19 Step 400/703 lr 0.100000 loss 1.5219 (1.6459) acc@1 0.4062 (0.3923) acc@5 0.7812 (0.7760)\n",
      "\u001b[32m[2020-07-01 03:01:10] __main__ INFO: \u001b[0mEpoch 19 Step 500/703 lr 0.100000 loss 1.6933 (1.6484) acc@1 0.4375 (0.3909) acc@5 0.8281 (0.7754)\n",
      "\u001b[32m[2020-07-01 03:01:42] __main__ INFO: \u001b[0mEpoch 19 Step 600/703 lr 0.100000 loss 1.6896 (1.6498) acc@1 0.3594 (0.3904) acc@5 0.6406 (0.7750)\n",
      "\u001b[32m[2020-07-01 03:02:14] __main__ INFO: \u001b[0mEpoch 19 Step 700/703 lr 0.100000 loss 1.6208 (1.6525) acc@1 0.4062 (0.3889) acc@5 0.8281 (0.7746)\n",
      "\u001b[32m[2020-07-01 03:02:15] __main__ INFO: \u001b[0mEpoch 19 Step 703/703 lr 0.100000 loss 1.4576 (1.6519) acc@1 0.4844 (0.3892) acc@5 0.8906 (0.7748)\n",
      "\u001b[32m[2020-07-01 03:02:15] __main__ INFO: \u001b[0mElapsed 224.38\n",
      "\u001b[32m[2020-07-01 03:02:15] __main__ INFO: \u001b[0mVal 19\n",
      "\u001b[32m[2020-07-01 03:02:23] __main__ INFO: \u001b[0mEpoch 19 loss 0.7941 acc@1 0.7238 acc@5 0.9798\n",
      "\u001b[32m[2020-07-01 03:02:23] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-01 03:02:23] __main__ INFO: \u001b[0mTrain 20 13357\n",
      "\u001b[32m[2020-07-01 03:02:55] __main__ INFO: \u001b[0mEpoch 20 Step 100/703 lr 0.100000 loss 1.6066 (1.6126) acc@1 0.3594 (0.4034) acc@5 0.7969 (0.7705)\n",
      "\u001b[32m[2020-07-01 03:03:27] __main__ INFO: \u001b[0mEpoch 20 Step 200/703 lr 0.100000 loss 1.5116 (1.6342) acc@1 0.4062 (0.3951) acc@5 0.8438 (0.7723)\n",
      "\u001b[32m[2020-07-01 03:03:59] __main__ INFO: \u001b[0mEpoch 20 Step 300/703 lr 0.100000 loss 1.4427 (1.6376) acc@1 0.4844 (0.3946) acc@5 0.8594 (0.7721)\n",
      "\u001b[32m[2020-07-01 03:04:31] __main__ INFO: \u001b[0mEpoch 20 Step 400/703 lr 0.100000 loss 1.6625 (1.6379) acc@1 0.4062 (0.3945) acc@5 0.8594 (0.7750)\n",
      "\u001b[32m[2020-07-01 03:05:02] __main__ INFO: \u001b[0mEpoch 20 Step 500/703 lr 0.100000 loss 1.6045 (1.6361) acc@1 0.4375 (0.3961) acc@5 0.8594 (0.7757)\n",
      "\u001b[32m[2020-07-01 03:05:34] __main__ INFO: \u001b[0mEpoch 20 Step 600/703 lr 0.100000 loss 1.5637 (1.6349) acc@1 0.3906 (0.3966) acc@5 0.7969 (0.7754)\n",
      "\u001b[32m[2020-07-01 03:06:06] __main__ INFO: \u001b[0mEpoch 20 Step 700/703 lr 0.100000 loss 1.7617 (1.6361) acc@1 0.3281 (0.3954) acc@5 0.6719 (0.7762)\n",
      "\u001b[32m[2020-07-01 03:06:07] __main__ INFO: \u001b[0mEpoch 20 Step 703/703 lr 0.100000 loss 1.4113 (1.6358) acc@1 0.4688 (0.3953) acc@5 0.8906 (0.7763)\n",
      "\u001b[32m[2020-07-01 03:06:07] __main__ INFO: \u001b[0mElapsed 224.26\n",
      "\u001b[32m[2020-07-01 03:06:07] __main__ INFO: \u001b[0mVal 20\n",
      "\u001b[32m[2020-07-01 03:06:15] __main__ INFO: \u001b[0mEpoch 20 loss 0.7735 acc@1 0.7278 acc@5 0.9810\n",
      "\u001b[32m[2020-07-01 03:06:15] __main__ INFO: \u001b[0mElapsed 7.80\n",
      "\u001b[32m[2020-07-01 03:06:15] __main__ INFO: \u001b[0mTrain 21 14060\n",
      "\u001b[32m[2020-07-01 03:06:47] __main__ INFO: \u001b[0mEpoch 21 Step 100/703 lr 0.100000 loss 1.9194 (1.6259) acc@1 0.2969 (0.3937) acc@5 0.7656 (0.7755)\n",
      "\u001b[32m[2020-07-01 03:07:19] __main__ INFO: \u001b[0mEpoch 21 Step 200/703 lr 0.100000 loss 1.6144 (1.6209) acc@1 0.3906 (0.3944) acc@5 0.7188 (0.7836)\n",
      "\u001b[32m[2020-07-01 03:07:51] __main__ INFO: \u001b[0mEpoch 21 Step 300/703 lr 0.100000 loss 1.6543 (1.6234) acc@1 0.2969 (0.3937) acc@5 0.7969 (0.7798)\n",
      "\u001b[32m[2020-07-01 03:08:23] __main__ INFO: \u001b[0mEpoch 21 Step 400/703 lr 0.100000 loss 1.6020 (1.6211) acc@1 0.4375 (0.3958) acc@5 0.7500 (0.7779)\n",
      "\u001b[32m[2020-07-01 03:08:55] __main__ INFO: \u001b[0mEpoch 21 Step 500/703 lr 0.100000 loss 1.6313 (1.6243) acc@1 0.3906 (0.3952) acc@5 0.7500 (0.7779)\n",
      "\u001b[32m[2020-07-01 03:09:27] __main__ INFO: \u001b[0mEpoch 21 Step 600/703 lr 0.100000 loss 1.7169 (1.6265) acc@1 0.4531 (0.3946) acc@5 0.7969 (0.7770)\n",
      "\u001b[32m[2020-07-01 03:09:59] __main__ INFO: \u001b[0mEpoch 21 Step 700/703 lr 0.100000 loss 1.4831 (1.6239) acc@1 0.4062 (0.3951) acc@5 0.8750 (0.7776)\n",
      "\u001b[32m[2020-07-01 03:10:00] __main__ INFO: \u001b[0mEpoch 21 Step 703/703 lr 0.100000 loss 1.4805 (1.6233) acc@1 0.4531 (0.3954) acc@5 0.8125 (0.7777)\n",
      "\u001b[32m[2020-07-01 03:10:00] __main__ INFO: \u001b[0mElapsed 224.57\n",
      "\u001b[32m[2020-07-01 03:10:00] __main__ INFO: \u001b[0mVal 21\n",
      "\u001b[32m[2020-07-01 03:10:07] __main__ INFO: \u001b[0mEpoch 21 loss 0.8298 acc@1 0.7170 acc@5 0.9772\n",
      "\u001b[32m[2020-07-01 03:10:07] __main__ INFO: \u001b[0mElapsed 7.79\n",
      "\u001b[32m[2020-07-01 03:10:07] __main__ INFO: \u001b[0mTrain 22 14763\n",
      "\u001b[32m[2020-07-01 03:10:39] __main__ INFO: \u001b[0mEpoch 22 Step 100/703 lr 0.100000 loss 1.7302 (1.6205) acc@1 0.3281 (0.4088) acc@5 0.7188 (0.7777)\n",
      "\u001b[32m[2020-07-01 03:11:11] __main__ INFO: \u001b[0mEpoch 22 Step 200/703 lr 0.100000 loss 1.6108 (1.6111) acc@1 0.4375 (0.4093) acc@5 0.6406 (0.7820)\n",
      "\u001b[32m[2020-07-01 03:11:43] __main__ INFO: \u001b[0mEpoch 22 Step 300/703 lr 0.100000 loss 1.6012 (1.6159) acc@1 0.4688 (0.4074) acc@5 0.7812 (0.7788)\n",
      "\u001b[32m[2020-07-01 03:12:15] __main__ INFO: \u001b[0mEpoch 22 Step 400/703 lr 0.100000 loss 1.5899 (1.6168) acc@1 0.4062 (0.4040) acc@5 0.6875 (0.7784)\n",
      "\u001b[32m[2020-07-01 03:12:47] __main__ INFO: \u001b[0mEpoch 22 Step 500/703 lr 0.100000 loss 1.8410 (1.6187) acc@1 0.3281 (0.4024) acc@5 0.7656 (0.7778)\n",
      "\u001b[32m[2020-07-01 03:13:19] __main__ INFO: \u001b[0mEpoch 22 Step 600/703 lr 0.100000 loss 1.7259 (1.6163) acc@1 0.3906 (0.4027) acc@5 0.6406 (0.7784)\n",
      "\u001b[32m[2020-07-01 03:13:51] __main__ INFO: \u001b[0mEpoch 22 Step 700/703 lr 0.100000 loss 1.7525 (1.6148) acc@1 0.3281 (0.4033) acc@5 0.7656 (0.7795)\n",
      "\u001b[32m[2020-07-01 03:13:52] __main__ INFO: \u001b[0mEpoch 22 Step 703/703 lr 0.100000 loss 1.4422 (1.6145) acc@1 0.4688 (0.4036) acc@5 0.8594 (0.7797)\n",
      "\u001b[32m[2020-07-01 03:13:52] __main__ INFO: \u001b[0mElapsed 224.78\n",
      "\u001b[32m[2020-07-01 03:13:52] __main__ INFO: \u001b[0mVal 22\n",
      "\u001b[32m[2020-07-01 03:14:00] __main__ INFO: \u001b[0mEpoch 22 loss 0.7768 acc@1 0.7288 acc@5 0.9816\n",
      "\u001b[32m[2020-07-01 03:14:00] __main__ INFO: \u001b[0mElapsed 7.81\n",
      "\u001b[32m[2020-07-01 03:14:00] __main__ INFO: \u001b[0mTrain 23 15466\n",
      "\u001b[32m[2020-07-01 03:14:32] __main__ INFO: \u001b[0mEpoch 23 Step 100/703 lr 0.100000 loss 1.8870 (1.6034) acc@1 0.4062 (0.4064) acc@5 0.7031 (0.7817)\n",
      "\u001b[32m[2020-07-01 03:15:04] __main__ INFO: \u001b[0mEpoch 23 Step 200/703 lr 0.100000 loss 1.5176 (1.6037) acc@1 0.4844 (0.4066) acc@5 0.8281 (0.7820)\n",
      "\u001b[32m[2020-07-01 03:15:36] __main__ INFO: \u001b[0mEpoch 23 Step 300/703 lr 0.100000 loss 1.4740 (1.6029) acc@1 0.4688 (0.4061) acc@5 0.7656 (0.7783)\n",
      "\u001b[32m[2020-07-01 03:16:08] __main__ INFO: \u001b[0mEpoch 23 Step 400/703 lr 0.100000 loss 1.7005 (1.6006) acc@1 0.3438 (0.4071) acc@5 0.7031 (0.7786)\n",
      "\u001b[32m[2020-07-01 03:16:39] __main__ INFO: \u001b[0mEpoch 23 Step 500/703 lr 0.100000 loss 1.5185 (1.5975) acc@1 0.4219 (0.4069) acc@5 0.7500 (0.7781)\n",
      "\u001b[32m[2020-07-01 03:17:11] __main__ INFO: \u001b[0mEpoch 23 Step 600/703 lr 0.100000 loss 1.5311 (1.5992) acc@1 0.4688 (0.4055) acc@5 0.7969 (0.7780)\n",
      "\u001b[32m[2020-07-01 03:17:43] __main__ INFO: \u001b[0mEpoch 23 Step 700/703 lr 0.100000 loss 1.7351 (1.6017) acc@1 0.3594 (0.4042) acc@5 0.7500 (0.7785)\n",
      "\u001b[32m[2020-07-01 03:17:44] __main__ INFO: \u001b[0mEpoch 23 Step 703/703 lr 0.100000 loss 1.6450 (1.6021) acc@1 0.3281 (0.4040) acc@5 0.7656 (0.7785)\n",
      "\u001b[32m[2020-07-01 03:17:44] __main__ INFO: \u001b[0mElapsed 224.22\n",
      "\u001b[32m[2020-07-01 03:17:44] __main__ INFO: \u001b[0mVal 23\n",
      "\u001b[32m[2020-07-01 03:17:52] __main__ INFO: \u001b[0mEpoch 23 loss 0.9885 acc@1 0.6876 acc@5 0.9634\n",
      "\u001b[32m[2020-07-01 03:17:52] __main__ INFO: \u001b[0mElapsed 7.81\n",
      "\u001b[32m[2020-07-01 03:17:52] __main__ INFO: \u001b[0mTrain 24 16169\n",
      "\u001b[32m[2020-07-01 03:18:24] __main__ INFO: \u001b[0mEpoch 24 Step 100/703 lr 0.100000 loss 1.7115 (1.5607) acc@1 0.3281 (0.4247) acc@5 0.7500 (0.7856)\n",
      "\u001b[32m[2020-07-01 03:18:56] __main__ INFO: \u001b[0mEpoch 24 Step 200/703 lr 0.100000 loss 1.3180 (1.5850) acc@1 0.5938 (0.4142) acc@5 0.8281 (0.7830)\n",
      "\u001b[32m[2020-07-01 03:19:28] __main__ INFO: \u001b[0mEpoch 24 Step 300/703 lr 0.100000 loss 1.7797 (1.5855) acc@1 0.4062 (0.4133) acc@5 0.7500 (0.7864)\n",
      "\u001b[32m[2020-07-01 03:20:00] __main__ INFO: \u001b[0mEpoch 24 Step 400/703 lr 0.100000 loss 1.4395 (1.5920) acc@1 0.4844 (0.4108) acc@5 0.8438 (0.7849)\n",
      "\u001b[32m[2020-07-01 03:20:32] __main__ INFO: \u001b[0mEpoch 24 Step 500/703 lr 0.100000 loss 1.5388 (1.5929) acc@1 0.4062 (0.4108) acc@5 0.8125 (0.7812)\n",
      "\u001b[32m[2020-07-01 03:21:04] __main__ INFO: \u001b[0mEpoch 24 Step 600/703 lr 0.100000 loss 1.5054 (1.5953) acc@1 0.4531 (0.4097) acc@5 0.8594 (0.7809)\n",
      "\u001b[32m[2020-07-01 03:21:36] __main__ INFO: \u001b[0mEpoch 24 Step 700/703 lr 0.100000 loss 1.7517 (1.5922) acc@1 0.3750 (0.4106) acc@5 0.7188 (0.7816)\n",
      "\u001b[32m[2020-07-01 03:21:37] __main__ INFO: \u001b[0mEpoch 24 Step 703/703 lr 0.100000 loss 1.5031 (1.5923) acc@1 0.4062 (0.4106) acc@5 0.8750 (0.7817)\n",
      "\u001b[32m[2020-07-01 03:21:37] __main__ INFO: \u001b[0mElapsed 224.60\n",
      "\u001b[32m[2020-07-01 03:21:37] __main__ INFO: \u001b[0mVal 24\n",
      "\u001b[32m[2020-07-01 03:21:44] __main__ INFO: \u001b[0mEpoch 24 loss 0.7848 acc@1 0.7414 acc@5 0.9770\n",
      "\u001b[32m[2020-07-01 03:21:44] __main__ INFO: \u001b[0mElapsed 7.79\n",
      "\u001b[32m[2020-07-01 03:21:44] __main__ INFO: \u001b[0mTrain 25 16872\n",
      "\u001b[32m[2020-07-01 03:22:16] __main__ INFO: \u001b[0mEpoch 25 Step 100/703 lr 0.100000 loss 1.6316 (1.5674) acc@1 0.4219 (0.4261) acc@5 0.7188 (0.7778)\n",
      "\u001b[32m[2020-07-01 03:22:48] __main__ INFO: \u001b[0mEpoch 25 Step 200/703 lr 0.100000 loss 1.4007 (1.5772) acc@1 0.5156 (0.4216) acc@5 0.8594 (0.7804)\n",
      "\u001b[32m[2020-07-01 03:23:20] __main__ INFO: \u001b[0mEpoch 25 Step 300/703 lr 0.100000 loss 1.6652 (1.5805) acc@1 0.3750 (0.4216) acc@5 0.7656 (0.7807)\n",
      "\u001b[32m[2020-07-01 03:23:52] __main__ INFO: \u001b[0mEpoch 25 Step 400/703 lr 0.100000 loss 1.6432 (1.5825) acc@1 0.4062 (0.4204) acc@5 0.7812 (0.7815)\n",
      "\u001b[32m[2020-07-01 03:24:24] __main__ INFO: \u001b[0mEpoch 25 Step 500/703 lr 0.100000 loss 1.9471 (1.5802) acc@1 0.2344 (0.4196) acc@5 0.6562 (0.7815)\n",
      "\u001b[32m[2020-07-01 03:24:56] __main__ INFO: \u001b[0mEpoch 25 Step 600/703 lr 0.100000 loss 1.7159 (1.5824) acc@1 0.3750 (0.4172) acc@5 0.7344 (0.7818)\n",
      "\u001b[32m[2020-07-01 03:25:28] __main__ INFO: \u001b[0mEpoch 25 Step 700/703 lr 0.100000 loss 1.6684 (1.5835) acc@1 0.3750 (0.4158) acc@5 0.7812 (0.7815)\n",
      "\u001b[32m[2020-07-01 03:25:29] __main__ INFO: \u001b[0mEpoch 25 Step 703/703 lr 0.100000 loss 1.7444 (1.5836) acc@1 0.3906 (0.4158) acc@5 0.7969 (0.7815)\n",
      "\u001b[32m[2020-07-01 03:25:29] __main__ INFO: \u001b[0mElapsed 224.54\n",
      "\u001b[32m[2020-07-01 03:25:29] __main__ INFO: \u001b[0mVal 25\n",
      "\u001b[32m[2020-07-01 03:25:37] __main__ INFO: \u001b[0mEpoch 25 loss 0.8762 acc@1 0.7054 acc@5 0.9738\n",
      "\u001b[32m[2020-07-01 03:25:37] __main__ INFO: \u001b[0mElapsed 7.80\n",
      "\u001b[32m[2020-07-01 03:25:37] __main__ INFO: \u001b[0mTrain 26 17575\n",
      "\u001b[32m[2020-07-01 03:26:09] __main__ INFO: \u001b[0mEpoch 26 Step 100/703 lr 0.100000 loss 1.7179 (1.5774) acc@1 0.3750 (0.4147) acc@5 0.7500 (0.7841)\n",
      "\u001b[32m[2020-07-01 03:26:41] __main__ INFO: \u001b[0mEpoch 26 Step 200/703 lr 0.100000 loss 1.7355 (1.5737) acc@1 0.4219 (0.4189) acc@5 0.7656 (0.7834)\n",
      "\u001b[32m[2020-07-01 03:27:13] __main__ INFO: \u001b[0mEpoch 26 Step 300/703 lr 0.100000 loss 1.5693 (1.5715) acc@1 0.3438 (0.4173) acc@5 0.7656 (0.7819)\n",
      "\u001b[32m[2020-07-01 03:27:44] __main__ INFO: \u001b[0mEpoch 26 Step 400/703 lr 0.100000 loss 1.4325 (1.5730) acc@1 0.4375 (0.4163) acc@5 0.7969 (0.7846)\n",
      "\u001b[32m[2020-07-01 03:28:16] __main__ INFO: \u001b[0mEpoch 26 Step 500/703 lr 0.100000 loss 1.5595 (1.5725) acc@1 0.3750 (0.4160) acc@5 0.7500 (0.7835)\n",
      "\u001b[32m[2020-07-01 03:28:48] __main__ INFO: \u001b[0mEpoch 26 Step 600/703 lr 0.100000 loss 1.6389 (1.5740) acc@1 0.4219 (0.4154) acc@5 0.7656 (0.7828)\n",
      "\u001b[32m[2020-07-01 03:29:20] __main__ INFO: \u001b[0mEpoch 26 Step 700/703 lr 0.100000 loss 1.5553 (1.5725) acc@1 0.3438 (0.4162) acc@5 0.7500 (0.7828)\n",
      "\u001b[32m[2020-07-01 03:29:21] __main__ INFO: \u001b[0mEpoch 26 Step 703/703 lr 0.100000 loss 1.8270 (1.5726) acc@1 0.2656 (0.4161) acc@5 0.7500 (0.7827)\n",
      "\u001b[32m[2020-07-01 03:29:21] __main__ INFO: \u001b[0mElapsed 224.27\n",
      "\u001b[32m[2020-07-01 03:29:21] __main__ INFO: \u001b[0mVal 26\n",
      "\u001b[32m[2020-07-01 03:29:29] __main__ INFO: \u001b[0mEpoch 26 loss 0.7307 acc@1 0.7574 acc@5 0.9820\n",
      "\u001b[32m[2020-07-01 03:29:29] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-01 03:29:29] __main__ INFO: \u001b[0mTrain 27 18278\n",
      "\u001b[32m[2020-07-01 03:30:01] __main__ INFO: \u001b[0mEpoch 27 Step 100/703 lr 0.100000 loss 1.5015 (1.5500) acc@1 0.4688 (0.4198) acc@5 0.7344 (0.7887)\n",
      "\u001b[32m[2020-07-01 03:30:33] __main__ INFO: \u001b[0mEpoch 27 Step 200/703 lr 0.100000 loss 1.5258 (1.5592) acc@1 0.4688 (0.4202) acc@5 0.7812 (0.7890)\n",
      "\u001b[32m[2020-07-01 03:31:04] __main__ INFO: \u001b[0mEpoch 27 Step 300/703 lr 0.100000 loss 1.4620 (1.5628) acc@1 0.4688 (0.4206) acc@5 0.7969 (0.7868)\n",
      "\u001b[32m[2020-07-01 03:31:36] __main__ INFO: \u001b[0mEpoch 27 Step 400/703 lr 0.100000 loss 1.7482 (1.5642) acc@1 0.3281 (0.4196) acc@5 0.7500 (0.7843)\n",
      "\u001b[32m[2020-07-01 03:32:08] __main__ INFO: \u001b[0mEpoch 27 Step 500/703 lr 0.100000 loss 1.5529 (1.5663) acc@1 0.3281 (0.4185) acc@5 0.8438 (0.7833)\n",
      "\u001b[32m[2020-07-01 03:32:40] __main__ INFO: \u001b[0mEpoch 27 Step 600/703 lr 0.100000 loss 1.5727 (1.5681) acc@1 0.4062 (0.4176) acc@5 0.7656 (0.7839)\n",
      "\u001b[32m[2020-07-01 03:33:12] __main__ INFO: \u001b[0mEpoch 27 Step 700/703 lr 0.100000 loss 1.6092 (1.5684) acc@1 0.4062 (0.4175) acc@5 0.7969 (0.7846)\n",
      "\u001b[32m[2020-07-01 03:33:13] __main__ INFO: \u001b[0mEpoch 27 Step 703/703 lr 0.100000 loss 1.4499 (1.5681) acc@1 0.4375 (0.4176) acc@5 0.8438 (0.7847)\n",
      "\u001b[32m[2020-07-01 03:33:13] __main__ INFO: \u001b[0mElapsed 224.27\n",
      "\u001b[32m[2020-07-01 03:33:13] __main__ INFO: \u001b[0mVal 27\n",
      "\u001b[32m[2020-07-01 03:33:21] __main__ INFO: \u001b[0mEpoch 27 loss 0.8003 acc@1 0.7340 acc@5 0.9770\n",
      "\u001b[32m[2020-07-01 03:33:21] __main__ INFO: \u001b[0mElapsed 7.79\n",
      "\u001b[32m[2020-07-01 03:33:21] __main__ INFO: \u001b[0mTrain 28 18981\n",
      "\u001b[32m[2020-07-01 03:33:53] __main__ INFO: \u001b[0mEpoch 28 Step 100/703 lr 0.100000 loss 1.7650 (1.5584) acc@1 0.4219 (0.4163) acc@5 0.7031 (0.7784)\n",
      "\u001b[32m[2020-07-01 03:34:25] __main__ INFO: \u001b[0mEpoch 28 Step 200/703 lr 0.100000 loss 1.6044 (1.5460) acc@1 0.3594 (0.4232) acc@5 0.8594 (0.7848)\n",
      "\u001b[32m[2020-07-01 03:34:57] __main__ INFO: \u001b[0mEpoch 28 Step 300/703 lr 0.100000 loss 1.4188 (1.5505) acc@1 0.5000 (0.4229) acc@5 0.8594 (0.7845)\n",
      "\u001b[32m[2020-07-01 03:35:28] __main__ INFO: \u001b[0mEpoch 28 Step 400/703 lr 0.100000 loss 1.4434 (1.5542) acc@1 0.4688 (0.4213) acc@5 0.7344 (0.7836)\n",
      "\u001b[32m[2020-07-01 03:36:00] __main__ INFO: \u001b[0mEpoch 28 Step 500/703 lr 0.100000 loss 1.6048 (1.5561) acc@1 0.4375 (0.4207) acc@5 0.8281 (0.7831)\n",
      "\u001b[32m[2020-07-01 03:36:32] __main__ INFO: \u001b[0mEpoch 28 Step 600/703 lr 0.100000 loss 1.4972 (1.5579) acc@1 0.4219 (0.4190) acc@5 0.8125 (0.7822)\n",
      "\u001b[32m[2020-07-01 03:37:04] __main__ INFO: \u001b[0mEpoch 28 Step 700/703 lr 0.100000 loss 1.4004 (1.5578) acc@1 0.4531 (0.4195) acc@5 0.7656 (0.7827)\n",
      "\u001b[32m[2020-07-01 03:37:05] __main__ INFO: \u001b[0mEpoch 28 Step 703/703 lr 0.100000 loss 1.5986 (1.5579) acc@1 0.3906 (0.4194) acc@5 0.7656 (0.7827)\n",
      "\u001b[32m[2020-07-01 03:37:05] __main__ INFO: \u001b[0mElapsed 224.27\n",
      "\u001b[32m[2020-07-01 03:37:05] __main__ INFO: \u001b[0mVal 28\n",
      "\u001b[32m[2020-07-01 03:37:13] __main__ INFO: \u001b[0mEpoch 28 loss 0.8077 acc@1 0.7396 acc@5 0.9790\n",
      "\u001b[32m[2020-07-01 03:37:13] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-01 03:37:13] __main__ INFO: \u001b[0mTrain 29 19684\n",
      "\u001b[32m[2020-07-01 03:37:45] __main__ INFO: \u001b[0mEpoch 29 Step 100/703 lr 0.100000 loss 1.5550 (1.5465) acc@1 0.4688 (0.4302) acc@5 0.7656 (0.7870)\n",
      "\u001b[32m[2020-07-01 03:38:17] __main__ INFO: \u001b[0mEpoch 29 Step 200/703 lr 0.100000 loss 1.8573 (1.5487) acc@1 0.3125 (0.4259) acc@5 0.6719 (0.7876)\n",
      "\u001b[32m[2020-07-01 03:38:49] __main__ INFO: \u001b[0mEpoch 29 Step 300/703 lr 0.100000 loss 1.3438 (1.5497) acc@1 0.5312 (0.4257) acc@5 0.9062 (0.7864)\n",
      "\u001b[32m[2020-07-01 03:39:21] __main__ INFO: \u001b[0mEpoch 29 Step 400/703 lr 0.100000 loss 1.7599 (1.5523) acc@1 0.3594 (0.4239) acc@5 0.7812 (0.7854)\n",
      "\u001b[32m[2020-07-01 03:39:53] __main__ INFO: \u001b[0mEpoch 29 Step 500/703 lr 0.100000 loss 1.5981 (1.5515) acc@1 0.3594 (0.4227) acc@5 0.7969 (0.7867)\n",
      "\u001b[32m[2020-07-01 03:40:24] __main__ INFO: \u001b[0mEpoch 29 Step 600/703 lr 0.100000 loss 1.5258 (1.5539) acc@1 0.4688 (0.4222) acc@5 0.8281 (0.7875)\n",
      "\u001b[32m[2020-07-01 03:40:56] __main__ INFO: \u001b[0mEpoch 29 Step 700/703 lr 0.100000 loss 1.4720 (1.5569) acc@1 0.4688 (0.4208) acc@5 0.7500 (0.7869)\n",
      "\u001b[32m[2020-07-01 03:40:57] __main__ INFO: \u001b[0mEpoch 29 Step 703/703 lr 0.100000 loss 1.4106 (1.5567) acc@1 0.4531 (0.4209) acc@5 0.7812 (0.7870)\n",
      "\u001b[32m[2020-07-01 03:40:57] __main__ INFO: \u001b[0mElapsed 224.50\n",
      "\u001b[32m[2020-07-01 03:40:57] __main__ INFO: \u001b[0mVal 29\n",
      "\u001b[32m[2020-07-01 03:41:05] __main__ INFO: \u001b[0mEpoch 29 loss 0.7773 acc@1 0.7462 acc@5 0.9782\n",
      "\u001b[32m[2020-07-01 03:41:05] __main__ INFO: \u001b[0mElapsed 7.82\n",
      "\u001b[32m[2020-07-01 03:41:05] __main__ INFO: \u001b[0mTrain 30 20387\n",
      "\u001b[32m[2020-07-01 03:41:37] __main__ INFO: \u001b[0mEpoch 30 Step 100/703 lr 0.100000 loss 1.3799 (1.5116) acc@1 0.4531 (0.4364) acc@5 0.8281 (0.7923)\n",
      "\u001b[32m[2020-07-01 03:42:09] __main__ INFO: \u001b[0mEpoch 30 Step 200/703 lr 0.100000 loss 1.7928 (1.5294) acc@1 0.3438 (0.4325) acc@5 0.7031 (0.7897)\n",
      "\u001b[32m[2020-07-01 03:42:41] __main__ INFO: \u001b[0mEpoch 30 Step 300/703 lr 0.100000 loss 1.3232 (1.5328) acc@1 0.5469 (0.4303) acc@5 0.7500 (0.7892)\n",
      "\u001b[32m[2020-07-01 03:43:13] __main__ INFO: \u001b[0mEpoch 30 Step 400/703 lr 0.100000 loss 1.4432 (1.5364) acc@1 0.4375 (0.4298) acc@5 0.8438 (0.7902)\n",
      "\u001b[32m[2020-07-01 03:43:45] __main__ INFO: \u001b[0mEpoch 30 Step 500/703 lr 0.100000 loss 1.6225 (1.5388) acc@1 0.3906 (0.4295) acc@5 0.7656 (0.7893)\n",
      "\u001b[32m[2020-07-01 03:44:17] __main__ INFO: \u001b[0mEpoch 30 Step 600/703 lr 0.100000 loss 1.3884 (1.5418) acc@1 0.4844 (0.4285) acc@5 0.8594 (0.7888)\n",
      "\u001b[32m[2020-07-01 03:44:49] __main__ INFO: \u001b[0mEpoch 30 Step 700/703 lr 0.100000 loss 1.7799 (1.5427) acc@1 0.3594 (0.4284) acc@5 0.7188 (0.7878)\n",
      "\u001b[32m[2020-07-01 03:44:50] __main__ INFO: \u001b[0mEpoch 30 Step 703/703 lr 0.100000 loss 1.4884 (1.5428) acc@1 0.4375 (0.4283) acc@5 0.8281 (0.7879)\n",
      "\u001b[32m[2020-07-01 03:44:50] __main__ INFO: \u001b[0mElapsed 224.37\n",
      "\u001b[32m[2020-07-01 03:44:50] __main__ INFO: \u001b[0mVal 30\n",
      "\u001b[32m[2020-07-01 03:44:57] __main__ INFO: \u001b[0mEpoch 30 loss 0.6664 acc@1 0.7756 acc@5 0.9864\n",
      "\u001b[32m[2020-07-01 03:44:57] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-01 03:44:57] __main__ INFO: \u001b[0mTrain 31 21090\n",
      "\u001b[32m[2020-07-01 03:45:29] __main__ INFO: \u001b[0mEpoch 31 Step 100/703 lr 0.100000 loss 1.5085 (1.5076) acc@1 0.3906 (0.4395) acc@5 0.7500 (0.7881)\n",
      "\u001b[32m[2020-07-01 03:46:01] __main__ INFO: \u001b[0mEpoch 31 Step 200/703 lr 0.100000 loss 1.4179 (1.5173) acc@1 0.5000 (0.4420) acc@5 0.8906 (0.7899)\n",
      "\u001b[32m[2020-07-01 03:46:33] __main__ INFO: \u001b[0mEpoch 31 Step 300/703 lr 0.100000 loss 1.6178 (1.5281) acc@1 0.3750 (0.4352) acc@5 0.7500 (0.7872)\n",
      "\u001b[32m[2020-07-01 03:47:05] __main__ INFO: \u001b[0mEpoch 31 Step 400/703 lr 0.100000 loss 1.6878 (1.5233) acc@1 0.4219 (0.4358) acc@5 0.7812 (0.7879)\n",
      "\u001b[32m[2020-07-01 03:47:37] __main__ INFO: \u001b[0mEpoch 31 Step 500/703 lr 0.100000 loss 1.6040 (1.5291) acc@1 0.3750 (0.4334) acc@5 0.7812 (0.7882)\n",
      "\u001b[32m[2020-07-01 03:48:09] __main__ INFO: \u001b[0mEpoch 31 Step 600/703 lr 0.100000 loss 1.8403 (1.5327) acc@1 0.3594 (0.4317) acc@5 0.7188 (0.7876)\n",
      "\u001b[32m[2020-07-01 03:48:41] __main__ INFO: \u001b[0mEpoch 31 Step 700/703 lr 0.100000 loss 1.5847 (1.5365) acc@1 0.4062 (0.4302) acc@5 0.7500 (0.7868)\n",
      "\u001b[32m[2020-07-01 03:48:42] __main__ INFO: \u001b[0mEpoch 31 Step 703/703 lr 0.100000 loss 1.5933 (1.5363) acc@1 0.4219 (0.4304) acc@5 0.7969 (0.7870)\n",
      "\u001b[32m[2020-07-01 03:48:42] __main__ INFO: \u001b[0mElapsed 224.25\n",
      "\u001b[32m[2020-07-01 03:48:42] __main__ INFO: \u001b[0mVal 31\n",
      "\u001b[32m[2020-07-01 03:48:49] __main__ INFO: \u001b[0mEpoch 31 loss 0.8078 acc@1 0.7250 acc@5 0.9822\n",
      "\u001b[32m[2020-07-01 03:48:49] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-01 03:48:49] __main__ INFO: \u001b[0mTrain 32 21793\n",
      "\u001b[32m[2020-07-01 03:49:21] __main__ INFO: \u001b[0mEpoch 32 Step 100/703 lr 0.100000 loss 1.3716 (1.5069) acc@1 0.5000 (0.4369) acc@5 0.8750 (0.7967)\n",
      "\u001b[32m[2020-07-01 03:49:53] __main__ INFO: \u001b[0mEpoch 32 Step 200/703 lr 0.100000 loss 1.6400 (1.5187) acc@1 0.4062 (0.4354) acc@5 0.8281 (0.7904)\n",
      "\u001b[32m[2020-07-01 03:50:25] __main__ INFO: \u001b[0mEpoch 32 Step 300/703 lr 0.100000 loss 1.3803 (1.5287) acc@1 0.5469 (0.4318) acc@5 0.8594 (0.7896)\n",
      "\u001b[32m[2020-07-01 03:50:57] __main__ INFO: \u001b[0mEpoch 32 Step 400/703 lr 0.100000 loss 1.2229 (1.5248) acc@1 0.5156 (0.4337) acc@5 0.8906 (0.7909)\n",
      "\u001b[32m[2020-07-01 03:51:29] __main__ INFO: \u001b[0mEpoch 32 Step 500/703 lr 0.100000 loss 1.3768 (1.5274) acc@1 0.4688 (0.4331) acc@5 0.8125 (0.7903)\n",
      "\u001b[32m[2020-07-01 03:52:01] __main__ INFO: \u001b[0mEpoch 32 Step 600/703 lr 0.100000 loss 1.2754 (1.5296) acc@1 0.5938 (0.4321) acc@5 0.8594 (0.7888)\n",
      "\u001b[32m[2020-07-01 03:52:33] __main__ INFO: \u001b[0mEpoch 32 Step 700/703 lr 0.100000 loss 1.4583 (1.5333) acc@1 0.4688 (0.4303) acc@5 0.8438 (0.7888)\n",
      "\u001b[32m[2020-07-01 03:52:33] __main__ INFO: \u001b[0mEpoch 32 Step 703/703 lr 0.100000 loss 1.6111 (1.5331) acc@1 0.3906 (0.4303) acc@5 0.8594 (0.7890)\n",
      "\u001b[32m[2020-07-01 03:52:34] __main__ INFO: \u001b[0mElapsed 224.13\n",
      "\u001b[32m[2020-07-01 03:52:34] __main__ INFO: \u001b[0mVal 32\n",
      "\u001b[32m[2020-07-01 03:52:41] __main__ INFO: \u001b[0mEpoch 32 loss 0.8311 acc@1 0.7218 acc@5 0.9782\n",
      "\u001b[32m[2020-07-01 03:52:41] __main__ INFO: \u001b[0mElapsed 7.81\n",
      "\u001b[32m[2020-07-01 03:52:41] __main__ INFO: \u001b[0mTrain 33 22496\n",
      "\u001b[32m[2020-07-01 03:53:13] __main__ INFO: \u001b[0mEpoch 33 Step 100/703 lr 0.100000 loss 1.4568 (1.5024) acc@1 0.4531 (0.4411) acc@5 0.8281 (0.7858)\n",
      "\u001b[32m[2020-07-01 03:53:45] __main__ INFO: \u001b[0mEpoch 33 Step 200/703 lr 0.100000 loss 1.4448 (1.5096) acc@1 0.5000 (0.4426) acc@5 0.8594 (0.7884)\n",
      "\u001b[32m[2020-07-01 03:54:17] __main__ INFO: \u001b[0mEpoch 33 Step 300/703 lr 0.100000 loss 1.5543 (1.5130) acc@1 0.3750 (0.4426) acc@5 0.7656 (0.7892)\n",
      "\u001b[32m[2020-07-01 03:54:49] __main__ INFO: \u001b[0mEpoch 33 Step 400/703 lr 0.100000 loss 1.2659 (1.5152) acc@1 0.5000 (0.4404) acc@5 0.8438 (0.7877)\n",
      "\u001b[32m[2020-07-01 03:55:21] __main__ INFO: \u001b[0mEpoch 33 Step 500/703 lr 0.100000 loss 1.8050 (1.5219) acc@1 0.3906 (0.4375) acc@5 0.7500 (0.7868)\n",
      "\u001b[32m[2020-07-01 03:55:53] __main__ INFO: \u001b[0mEpoch 33 Step 600/703 lr 0.100000 loss 1.6018 (1.5243) acc@1 0.3750 (0.4358) acc@5 0.8125 (0.7864)\n",
      "\u001b[32m[2020-07-01 03:56:25] __main__ INFO: \u001b[0mEpoch 33 Step 700/703 lr 0.100000 loss 1.5693 (1.5259) acc@1 0.4062 (0.4354) acc@5 0.7969 (0.7869)\n",
      "\u001b[32m[2020-07-01 03:56:26] __main__ INFO: \u001b[0mEpoch 33 Step 703/703 lr 0.100000 loss 1.4528 (1.5260) acc@1 0.4531 (0.4353) acc@5 0.8125 (0.7869)\n",
      "\u001b[32m[2020-07-01 03:56:26] __main__ INFO: \u001b[0mElapsed 224.39\n",
      "\u001b[32m[2020-07-01 03:56:26] __main__ INFO: \u001b[0mVal 33\n",
      "\u001b[32m[2020-07-01 03:56:34] __main__ INFO: \u001b[0mEpoch 33 loss 0.7459 acc@1 0.7564 acc@5 0.9808\n",
      "\u001b[32m[2020-07-01 03:56:34] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-01 03:56:34] __main__ INFO: \u001b[0mTrain 34 23199\n",
      "\u001b[32m[2020-07-01 03:57:05] __main__ INFO: \u001b[0mEpoch 34 Step 100/703 lr 0.100000 loss 1.5752 (1.4967) acc@1 0.4375 (0.4461) acc@5 0.7500 (0.7944)\n",
      "\u001b[32m[2020-07-01 03:57:37] __main__ INFO: \u001b[0mEpoch 34 Step 200/703 lr 0.100000 loss 1.6284 (1.5140) acc@1 0.3750 (0.4409) acc@5 0.8438 (0.7930)\n",
      "\u001b[32m[2020-07-01 03:58:09] __main__ INFO: \u001b[0mEpoch 34 Step 300/703 lr 0.100000 loss 1.4894 (1.5094) acc@1 0.4844 (0.4426) acc@5 0.7969 (0.7918)\n",
      "\u001b[32m[2020-07-01 03:58:41] __main__ INFO: \u001b[0mEpoch 34 Step 400/703 lr 0.100000 loss 1.7524 (1.5154) acc@1 0.3906 (0.4402) acc@5 0.7656 (0.7891)\n",
      "\u001b[32m[2020-07-01 03:59:13] __main__ INFO: \u001b[0mEpoch 34 Step 500/703 lr 0.100000 loss 1.6856 (1.5176) acc@1 0.2969 (0.4387) acc@5 0.7500 (0.7897)\n",
      "\u001b[32m[2020-07-01 03:59:45] __main__ INFO: \u001b[0mEpoch 34 Step 600/703 lr 0.100000 loss 1.6129 (1.5195) acc@1 0.4219 (0.4373) acc@5 0.7031 (0.7889)\n",
      "\u001b[32m[2020-07-01 04:00:17] __main__ INFO: \u001b[0mEpoch 34 Step 700/703 lr 0.100000 loss 1.7379 (1.5207) acc@1 0.3594 (0.4373) acc@5 0.6562 (0.7896)\n",
      "\u001b[32m[2020-07-01 04:00:18] __main__ INFO: \u001b[0mEpoch 34 Step 703/703 lr 0.100000 loss 1.4446 (1.5209) acc@1 0.4531 (0.4372) acc@5 0.9062 (0.7897)\n",
      "\u001b[32m[2020-07-01 04:00:18] __main__ INFO: \u001b[0mElapsed 224.16\n",
      "\u001b[32m[2020-07-01 04:00:18] __main__ INFO: \u001b[0mVal 34\n",
      "\u001b[32m[2020-07-01 04:00:25] __main__ INFO: \u001b[0mEpoch 34 loss 0.6403 acc@1 0.7786 acc@5 0.9854\n",
      "\u001b[32m[2020-07-01 04:00:25] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-01 04:00:25] __main__ INFO: \u001b[0mTrain 35 23902\n",
      "\u001b[32m[2020-07-01 04:00:57] __main__ INFO: \u001b[0mEpoch 35 Step 100/703 lr 0.100000 loss 1.3617 (1.5022) acc@1 0.5312 (0.4427) acc@5 0.8594 (0.7892)\n",
      "\u001b[32m[2020-07-01 04:01:29] __main__ INFO: \u001b[0mEpoch 35 Step 200/703 lr 0.100000 loss 1.3763 (1.5067) acc@1 0.4844 (0.4413) acc@5 0.7969 (0.7912)\n",
      "\u001b[32m[2020-07-01 04:02:01] __main__ INFO: \u001b[0mEpoch 35 Step 300/703 lr 0.100000 loss 1.4814 (1.5059) acc@1 0.3594 (0.4413) acc@5 0.7656 (0.7891)\n",
      "\u001b[32m[2020-07-01 04:02:33] __main__ INFO: \u001b[0mEpoch 35 Step 400/703 lr 0.100000 loss 1.2935 (1.5121) acc@1 0.5000 (0.4399) acc@5 0.8594 (0.7885)\n",
      "\u001b[32m[2020-07-01 04:03:05] __main__ INFO: \u001b[0mEpoch 35 Step 500/703 lr 0.100000 loss 1.2231 (1.5079) acc@1 0.5312 (0.4405) acc@5 0.8750 (0.7893)\n",
      "\u001b[32m[2020-07-01 04:03:37] __main__ INFO: \u001b[0mEpoch 35 Step 600/703 lr 0.100000 loss 1.5057 (1.5115) acc@1 0.3750 (0.4394) acc@5 0.7500 (0.7886)\n",
      "\u001b[32m[2020-07-01 04:04:09] __main__ INFO: \u001b[0mEpoch 35 Step 700/703 lr 0.100000 loss 1.2639 (1.5148) acc@1 0.4844 (0.4375) acc@5 0.8438 (0.7883)\n",
      "\u001b[32m[2020-07-01 04:04:10] __main__ INFO: \u001b[0mEpoch 35 Step 703/703 lr 0.100000 loss 1.5779 (1.5144) acc@1 0.4375 (0.4376) acc@5 0.8438 (0.7884)\n",
      "\u001b[32m[2020-07-01 04:04:10] __main__ INFO: \u001b[0mElapsed 224.27\n",
      "\u001b[32m[2020-07-01 04:04:10] __main__ INFO: \u001b[0mVal 35\n",
      "\u001b[32m[2020-07-01 04:04:18] __main__ INFO: \u001b[0mEpoch 35 loss 0.6473 acc@1 0.7840 acc@5 0.9830\n",
      "\u001b[32m[2020-07-01 04:04:18] __main__ INFO: \u001b[0mElapsed 7.80\n",
      "\u001b[32m[2020-07-01 04:04:18] __main__ INFO: \u001b[0mTrain 36 24605\n",
      "\u001b[32m[2020-07-01 04:04:50] __main__ INFO: \u001b[0mEpoch 36 Step 100/703 lr 0.100000 loss 1.3416 (1.4972) acc@1 0.4844 (0.4461) acc@5 0.7812 (0.7933)\n",
      "\u001b[32m[2020-07-01 04:05:21] __main__ INFO: \u001b[0mEpoch 36 Step 200/703 lr 0.100000 loss 1.4455 (1.4898) acc@1 0.4688 (0.4480) acc@5 0.7500 (0.7909)\n",
      "\u001b[32m[2020-07-01 04:05:53] __main__ INFO: \u001b[0mEpoch 36 Step 300/703 lr 0.100000 loss 1.6197 (1.5005) acc@1 0.4062 (0.4439) acc@5 0.7656 (0.7896)\n",
      "\u001b[32m[2020-07-01 04:06:25] __main__ INFO: \u001b[0mEpoch 36 Step 400/703 lr 0.100000 loss 1.5280 (1.4966) acc@1 0.4531 (0.4459) acc@5 0.7656 (0.7926)\n",
      "\u001b[32m[2020-07-01 04:06:57] __main__ INFO: \u001b[0mEpoch 36 Step 500/703 lr 0.100000 loss 1.3818 (1.4957) acc@1 0.4375 (0.4465) acc@5 0.7188 (0.7928)\n",
      "\u001b[32m[2020-07-01 04:07:29] __main__ INFO: \u001b[0mEpoch 36 Step 600/703 lr 0.100000 loss 1.5582 (1.5031) acc@1 0.3906 (0.4431) acc@5 0.8281 (0.7913)\n",
      "\u001b[32m[2020-07-01 04:08:01] __main__ INFO: \u001b[0mEpoch 36 Step 700/703 lr 0.100000 loss 1.6716 (1.5054) acc@1 0.4375 (0.4423) acc@5 0.7812 (0.7900)\n",
      "\u001b[32m[2020-07-01 04:08:02] __main__ INFO: \u001b[0mEpoch 36 Step 703/703 lr 0.100000 loss 1.2622 (1.5050) acc@1 0.5938 (0.4424) acc@5 0.8594 (0.7902)\n",
      "\u001b[32m[2020-07-01 04:08:02] __main__ INFO: \u001b[0mElapsed 224.52\n",
      "\u001b[32m[2020-07-01 04:08:02] __main__ INFO: \u001b[0mVal 36\n",
      "\u001b[32m[2020-07-01 04:08:10] __main__ INFO: \u001b[0mEpoch 36 loss 0.6263 acc@1 0.7906 acc@5 0.9848\n",
      "\u001b[32m[2020-07-01 04:08:10] __main__ INFO: \u001b[0mElapsed 7.80\n",
      "\u001b[32m[2020-07-01 04:08:10] __main__ INFO: \u001b[0mTrain 37 25308\n",
      "\u001b[32m[2020-07-01 04:08:42] __main__ INFO: \u001b[0mEpoch 37 Step 100/703 lr 0.100000 loss 1.4126 (1.4958) acc@1 0.5156 (0.4466) acc@5 0.8125 (0.7894)\n",
      "\u001b[32m[2020-07-01 04:09:14] __main__ INFO: \u001b[0mEpoch 37 Step 200/703 lr 0.100000 loss 1.4350 (1.5009) acc@1 0.5000 (0.4477) acc@5 0.8438 (0.7885)\n",
      "\u001b[32m[2020-07-01 04:09:46] __main__ INFO: \u001b[0mEpoch 37 Step 300/703 lr 0.100000 loss 1.6609 (1.4928) acc@1 0.3594 (0.4502) acc@5 0.7656 (0.7919)\n",
      "\u001b[32m[2020-07-01 04:10:18] __main__ INFO: \u001b[0mEpoch 37 Step 400/703 lr 0.100000 loss 1.4540 (1.4946) acc@1 0.4844 (0.4480) acc@5 0.7969 (0.7899)\n",
      "\u001b[32m[2020-07-01 04:10:50] __main__ INFO: \u001b[0mEpoch 37 Step 500/703 lr 0.100000 loss 1.6004 (1.4921) acc@1 0.4062 (0.4487) acc@5 0.7344 (0.7905)\n",
      "\u001b[32m[2020-07-01 04:11:21] __main__ INFO: \u001b[0mEpoch 37 Step 600/703 lr 0.100000 loss 1.3586 (1.4959) acc@1 0.4531 (0.4472) acc@5 0.8594 (0.7891)\n",
      "\u001b[32m[2020-07-01 04:11:53] __main__ INFO: \u001b[0mEpoch 37 Step 700/703 lr 0.100000 loss 1.6612 (1.4971) acc@1 0.4062 (0.4467) acc@5 0.7812 (0.7892)\n",
      "\u001b[32m[2020-07-01 04:11:54] __main__ INFO: \u001b[0mEpoch 37 Step 703/703 lr 0.100000 loss 1.5641 (1.4972) acc@1 0.4062 (0.4466) acc@5 0.7656 (0.7892)\n",
      "\u001b[32m[2020-07-01 04:11:54] __main__ INFO: \u001b[0mElapsed 224.43\n",
      "\u001b[32m[2020-07-01 04:11:54] __main__ INFO: \u001b[0mVal 37\n",
      "\u001b[32m[2020-07-01 04:12:02] __main__ INFO: \u001b[0mEpoch 37 loss 0.6682 acc@1 0.7760 acc@5 0.9858\n",
      "\u001b[32m[2020-07-01 04:12:02] __main__ INFO: \u001b[0mElapsed 7.81\n",
      "\u001b[32m[2020-07-01 04:12:02] __main__ INFO: \u001b[0mTrain 38 26011\n",
      "\u001b[32m[2020-07-01 04:12:34] __main__ INFO: \u001b[0mEpoch 38 Step 100/703 lr 0.100000 loss 1.5282 (1.4828) acc@1 0.4062 (0.4494) acc@5 0.7812 (0.7859)\n",
      "\u001b[32m[2020-07-01 04:13:06] __main__ INFO: \u001b[0mEpoch 38 Step 200/703 lr 0.100000 loss 1.3592 (1.4974) acc@1 0.4688 (0.4463) acc@5 0.8281 (0.7885)\n",
      "\u001b[32m[2020-07-01 04:13:38] __main__ INFO: \u001b[0mEpoch 38 Step 300/703 lr 0.100000 loss 1.7238 (1.4924) acc@1 0.3906 (0.4478) acc@5 0.7656 (0.7902)\n",
      "\u001b[32m[2020-07-01 04:14:10] __main__ INFO: \u001b[0mEpoch 38 Step 400/703 lr 0.100000 loss 1.4126 (1.4919) acc@1 0.4688 (0.4471) acc@5 0.8594 (0.7911)\n",
      "\u001b[32m[2020-07-01 04:14:42] __main__ INFO: \u001b[0mEpoch 38 Step 500/703 lr 0.100000 loss 1.6649 (1.4906) acc@1 0.3281 (0.4468) acc@5 0.7188 (0.7919)\n",
      "\u001b[32m[2020-07-01 04:15:14] __main__ INFO: \u001b[0mEpoch 38 Step 600/703 lr 0.100000 loss 1.3734 (1.4931) acc@1 0.5000 (0.4448) acc@5 0.8438 (0.7911)\n",
      "\u001b[32m[2020-07-01 04:15:46] __main__ INFO: \u001b[0mEpoch 38 Step 700/703 lr 0.100000 loss 1.2725 (1.4966) acc@1 0.5312 (0.4439) acc@5 0.9062 (0.7911)\n",
      "\u001b[32m[2020-07-01 04:15:47] __main__ INFO: \u001b[0mEpoch 38 Step 703/703 lr 0.100000 loss 1.5038 (1.4967) acc@1 0.4375 (0.4439) acc@5 0.7812 (0.7912)\n",
      "\u001b[32m[2020-07-01 04:15:47] __main__ INFO: \u001b[0mElapsed 224.50\n",
      "\u001b[32m[2020-07-01 04:15:47] __main__ INFO: \u001b[0mVal 38\n",
      "\u001b[32m[2020-07-01 04:15:54] __main__ INFO: \u001b[0mEpoch 38 loss 0.7151 acc@1 0.7670 acc@5 0.9874\n",
      "\u001b[32m[2020-07-01 04:15:54] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-01 04:15:54] __main__ INFO: \u001b[0mTrain 39 26714\n",
      "\u001b[32m[2020-07-01 04:16:26] __main__ INFO: \u001b[0mEpoch 39 Step 100/703 lr 0.100000 loss 1.8760 (1.4921) acc@1 0.2969 (0.4456) acc@5 0.7031 (0.7875)\n",
      "\u001b[32m[2020-07-01 04:16:58] __main__ INFO: \u001b[0mEpoch 39 Step 200/703 lr 0.100000 loss 1.5000 (1.4767) acc@1 0.4375 (0.4512) acc@5 0.7188 (0.7882)\n",
      "\u001b[32m[2020-07-01 04:17:30] __main__ INFO: \u001b[0mEpoch 39 Step 300/703 lr 0.100000 loss 1.4945 (1.4843) acc@1 0.5156 (0.4486) acc@5 0.8438 (0.7893)\n",
      "\u001b[32m[2020-07-01 04:18:02] __main__ INFO: \u001b[0mEpoch 39 Step 400/703 lr 0.100000 loss 1.7145 (1.4861) acc@1 0.3594 (0.4482) acc@5 0.7812 (0.7905)\n",
      "\u001b[32m[2020-07-01 04:18:34] __main__ INFO: \u001b[0mEpoch 39 Step 500/703 lr 0.100000 loss 1.8876 (1.4899) acc@1 0.2500 (0.4473) acc@5 0.7188 (0.7908)\n",
      "\u001b[32m[2020-07-01 04:19:06] __main__ INFO: \u001b[0mEpoch 39 Step 600/703 lr 0.100000 loss 1.5691 (1.4904) acc@1 0.3906 (0.4479) acc@5 0.6875 (0.7916)\n",
      "\u001b[32m[2020-07-01 04:19:38] __main__ INFO: \u001b[0mEpoch 39 Step 700/703 lr 0.100000 loss 1.4049 (1.4889) acc@1 0.5312 (0.4487) acc@5 0.7812 (0.7927)\n",
      "\u001b[32m[2020-07-01 04:19:39] __main__ INFO: \u001b[0mEpoch 39 Step 703/703 lr 0.100000 loss 1.3709 (1.4887) acc@1 0.4844 (0.4486) acc@5 0.7812 (0.7924)\n",
      "\u001b[32m[2020-07-01 04:19:39] __main__ INFO: \u001b[0mElapsed 224.36\n",
      "\u001b[32m[2020-07-01 04:19:39] __main__ INFO: \u001b[0mVal 39\n",
      "\u001b[32m[2020-07-01 04:19:47] __main__ INFO: \u001b[0mEpoch 39 loss 0.7570 acc@1 0.7548 acc@5 0.9844\n",
      "\u001b[32m[2020-07-01 04:19:47] __main__ INFO: \u001b[0mElapsed 7.79\n",
      "\u001b[32m[2020-07-01 04:19:47] __main__ INFO: \u001b[0mTrain 40 27417\n",
      "\u001b[32m[2020-07-01 04:20:18] __main__ INFO: \u001b[0mEpoch 40 Step 100/703 lr 0.100000 loss 1.4451 (1.4365) acc@1 0.5312 (0.4697) acc@5 0.8281 (0.8016)\n",
      "\u001b[32m[2020-07-01 04:20:50] __main__ INFO: \u001b[0mEpoch 40 Step 200/703 lr 0.100000 loss 1.3624 (1.4600) acc@1 0.5469 (0.4595) acc@5 0.9062 (0.7995)\n",
      "\u001b[32m[2020-07-01 04:21:22] __main__ INFO: \u001b[0mEpoch 40 Step 300/703 lr 0.100000 loss 1.7723 (1.4708) acc@1 0.3438 (0.4544) acc@5 0.7500 (0.7982)\n",
      "\u001b[32m[2020-07-01 04:21:54] __main__ INFO: \u001b[0mEpoch 40 Step 400/703 lr 0.100000 loss 1.5015 (1.4745) acc@1 0.4375 (0.4529) acc@5 0.7812 (0.7979)\n",
      "\u001b[32m[2020-07-01 04:22:26] __main__ INFO: \u001b[0mEpoch 40 Step 500/703 lr 0.100000 loss 1.4828 (1.4846) acc@1 0.4219 (0.4501) acc@5 0.7656 (0.7961)\n",
      "\u001b[32m[2020-07-01 04:22:58] __main__ INFO: \u001b[0mEpoch 40 Step 600/703 lr 0.100000 loss 1.3465 (1.4888) acc@1 0.5156 (0.4487) acc@5 0.8438 (0.7950)\n",
      "\u001b[32m[2020-07-01 04:23:30] __main__ INFO: \u001b[0mEpoch 40 Step 700/703 lr 0.100000 loss 1.4715 (1.4908) acc@1 0.4844 (0.4470) acc@5 0.7344 (0.7937)\n",
      "\u001b[32m[2020-07-01 04:23:31] __main__ INFO: \u001b[0mEpoch 40 Step 703/703 lr 0.100000 loss 1.5356 (1.4912) acc@1 0.4531 (0.4470) acc@5 0.7500 (0.7938)\n",
      "\u001b[32m[2020-07-01 04:23:31] __main__ INFO: \u001b[0mElapsed 224.15\n",
      "\u001b[32m[2020-07-01 04:23:31] __main__ INFO: \u001b[0mVal 40\n",
      "\u001b[32m[2020-07-01 04:23:38] __main__ INFO: \u001b[0mEpoch 40 loss 0.5572 acc@1 0.8094 acc@5 0.9896\n",
      "\u001b[32m[2020-07-01 04:23:38] __main__ INFO: \u001b[0mElapsed 7.79\n",
      "\u001b[32m[2020-07-01 04:23:38] __main__ INFO: \u001b[0mTrain 41 28120\n",
      "\u001b[32m[2020-07-01 04:24:10] __main__ INFO: \u001b[0mEpoch 41 Step 100/703 lr 0.100000 loss 1.4149 (1.4551) acc@1 0.5312 (0.4611) acc@5 0.7500 (0.7906)\n",
      "\u001b[32m[2020-07-01 04:24:42] __main__ INFO: \u001b[0mEpoch 41 Step 200/703 lr 0.100000 loss 1.4816 (1.4557) acc@1 0.4531 (0.4610) acc@5 0.7344 (0.7952)\n",
      "\u001b[32m[2020-07-01 04:25:14] __main__ INFO: \u001b[0mEpoch 41 Step 300/703 lr 0.100000 loss 1.2936 (1.4791) acc@1 0.5469 (0.4520) acc@5 0.8438 (0.7936)\n",
      "\u001b[32m[2020-07-01 04:25:46] __main__ INFO: \u001b[0mEpoch 41 Step 400/703 lr 0.100000 loss 1.6126 (1.4891) acc@1 0.3750 (0.4481) acc@5 0.6719 (0.7898)\n",
      "\u001b[32m[2020-07-01 04:26:18] __main__ INFO: \u001b[0mEpoch 41 Step 500/703 lr 0.100000 loss 1.2882 (1.4881) acc@1 0.5000 (0.4495) acc@5 0.7969 (0.7891)\n",
      "\u001b[32m[2020-07-01 04:26:50] __main__ INFO: \u001b[0mEpoch 41 Step 600/703 lr 0.100000 loss 1.5736 (1.4874) acc@1 0.4062 (0.4496) acc@5 0.8125 (0.7907)\n",
      "\u001b[32m[2020-07-01 04:27:22] __main__ INFO: \u001b[0mEpoch 41 Step 700/703 lr 0.100000 loss 1.3394 (1.4882) acc@1 0.5312 (0.4486) acc@5 0.7656 (0.7907)\n",
      "\u001b[32m[2020-07-01 04:27:23] __main__ INFO: \u001b[0mEpoch 41 Step 703/703 lr 0.100000 loss 1.3248 (1.4882) acc@1 0.5312 (0.4486) acc@5 0.8594 (0.7907)\n",
      "\u001b[32m[2020-07-01 04:27:23] __main__ INFO: \u001b[0mElapsed 224.41\n",
      "\u001b[32m[2020-07-01 04:27:23] __main__ INFO: \u001b[0mVal 41\n",
      "\u001b[32m[2020-07-01 04:27:31] __main__ INFO: \u001b[0mEpoch 41 loss 0.6919 acc@1 0.7732 acc@5 0.9846\n",
      "\u001b[32m[2020-07-01 04:27:31] __main__ INFO: \u001b[0mElapsed 7.82\n",
      "\u001b[32m[2020-07-01 04:27:31] __main__ INFO: \u001b[0mTrain 42 28823\n",
      "\u001b[32m[2020-07-01 04:28:03] __main__ INFO: \u001b[0mEpoch 42 Step 100/703 lr 0.100000 loss 1.7177 (1.4507) acc@1 0.4062 (0.4634) acc@5 0.7969 (0.7961)\n",
      "\u001b[32m[2020-07-01 04:28:35] __main__ INFO: \u001b[0mEpoch 42 Step 200/703 lr 0.100000 loss 1.3918 (1.4628) acc@1 0.4062 (0.4603) acc@5 0.8125 (0.7946)\n",
      "\u001b[32m[2020-07-01 04:29:06] __main__ INFO: \u001b[0mEpoch 42 Step 300/703 lr 0.100000 loss 1.3535 (1.4728) acc@1 0.5156 (0.4546) acc@5 0.7969 (0.7918)\n",
      "\u001b[32m[2020-07-01 04:29:38] __main__ INFO: \u001b[0mEpoch 42 Step 400/703 lr 0.100000 loss 1.4015 (1.4710) acc@1 0.4688 (0.4540) acc@5 0.7500 (0.7936)\n",
      "\u001b[32m[2020-07-01 04:30:10] __main__ INFO: \u001b[0mEpoch 42 Step 500/703 lr 0.100000 loss 1.4832 (1.4760) acc@1 0.4375 (0.4522) acc@5 0.8125 (0.7933)\n",
      "\u001b[32m[2020-07-01 04:30:42] __main__ INFO: \u001b[0mEpoch 42 Step 600/703 lr 0.100000 loss 1.3502 (1.4775) acc@1 0.4844 (0.4518) acc@5 0.8125 (0.7934)\n",
      "\u001b[32m[2020-07-01 04:31:14] __main__ INFO: \u001b[0mEpoch 42 Step 700/703 lr 0.100000 loss 1.4233 (1.4778) acc@1 0.4844 (0.4519) acc@5 0.8125 (0.7933)\n",
      "\u001b[32m[2020-07-01 04:31:15] __main__ INFO: \u001b[0mEpoch 42 Step 703/703 lr 0.100000 loss 1.5282 (1.4780) acc@1 0.4062 (0.4518) acc@5 0.7656 (0.7932)\n",
      "\u001b[32m[2020-07-01 04:31:15] __main__ INFO: \u001b[0mElapsed 224.44\n",
      "\u001b[32m[2020-07-01 04:31:15] __main__ INFO: \u001b[0mVal 42\n",
      "\u001b[32m[2020-07-01 04:31:23] __main__ INFO: \u001b[0mEpoch 42 loss 0.7132 acc@1 0.7716 acc@5 0.9774\n",
      "\u001b[32m[2020-07-01 04:31:23] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-01 04:31:23] __main__ INFO: \u001b[0mTrain 43 29526\n",
      "\u001b[32m[2020-07-01 04:31:55] __main__ INFO: \u001b[0mEpoch 43 Step 100/703 lr 0.100000 loss 1.8646 (1.4598) acc@1 0.3438 (0.4611) acc@5 0.7812 (0.7952)\n",
      "\u001b[32m[2020-07-01 04:32:27] __main__ INFO: \u001b[0mEpoch 43 Step 200/703 lr 0.100000 loss 1.6343 (1.4690) acc@1 0.3594 (0.4551) acc@5 0.9062 (0.7941)\n",
      "\u001b[32m[2020-07-01 04:32:59] __main__ INFO: \u001b[0mEpoch 43 Step 300/703 lr 0.100000 loss 1.4880 (1.4674) acc@1 0.4219 (0.4543) acc@5 0.7969 (0.7918)\n",
      "\u001b[32m[2020-07-01 04:33:31] __main__ INFO: \u001b[0mEpoch 43 Step 400/703 lr 0.100000 loss 1.4504 (1.4695) acc@1 0.4531 (0.4528) acc@5 0.7500 (0.7922)\n",
      "\u001b[32m[2020-07-01 04:34:03] __main__ INFO: \u001b[0mEpoch 43 Step 500/703 lr 0.100000 loss 1.6147 (1.4731) acc@1 0.4062 (0.4515) acc@5 0.8594 (0.7922)\n",
      "\u001b[32m[2020-07-01 04:34:35] __main__ INFO: \u001b[0mEpoch 43 Step 600/703 lr 0.100000 loss 1.5384 (1.4729) acc@1 0.3906 (0.4521) acc@5 0.7656 (0.7916)\n",
      "\u001b[32m[2020-07-01 04:35:07] __main__ INFO: \u001b[0mEpoch 43 Step 700/703 lr 0.100000 loss 1.3410 (1.4767) acc@1 0.4375 (0.4498) acc@5 0.8438 (0.7922)\n",
      "\u001b[32m[2020-07-01 04:35:07] __main__ INFO: \u001b[0mEpoch 43 Step 703/703 lr 0.100000 loss 1.7411 (1.4772) acc@1 0.4219 (0.4497) acc@5 0.7812 (0.7921)\n",
      "\u001b[32m[2020-07-01 04:35:08] __main__ INFO: \u001b[0mElapsed 224.60\n",
      "\u001b[32m[2020-07-01 04:35:08] __main__ INFO: \u001b[0mVal 43\n",
      "\u001b[32m[2020-07-01 04:35:15] __main__ INFO: \u001b[0mEpoch 43 loss 0.7081 acc@1 0.7688 acc@5 0.9840\n",
      "\u001b[32m[2020-07-01 04:35:15] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-01 04:35:15] __main__ INFO: \u001b[0mTrain 44 30229\n",
      "\u001b[32m[2020-07-01 04:35:47] __main__ INFO: \u001b[0mEpoch 44 Step 100/703 lr 0.100000 loss 1.5900 (1.4418) acc@1 0.4219 (0.4625) acc@5 0.8281 (0.7983)\n",
      "\u001b[32m[2020-07-01 04:36:19] __main__ INFO: \u001b[0mEpoch 44 Step 200/703 lr 0.100000 loss 1.6705 (1.4604) acc@1 0.3125 (0.4592) acc@5 0.7812 (0.7927)\n",
      "\u001b[32m[2020-07-01 04:36:51] __main__ INFO: \u001b[0mEpoch 44 Step 300/703 lr 0.100000 loss 1.2780 (1.4536) acc@1 0.5312 (0.4635) acc@5 0.8438 (0.7946)\n",
      "\u001b[32m[2020-07-01 04:37:23] __main__ INFO: \u001b[0mEpoch 44 Step 400/703 lr 0.100000 loss 1.5053 (1.4576) acc@1 0.4062 (0.4605) acc@5 0.7812 (0.7957)\n",
      "\u001b[32m[2020-07-01 04:37:55] __main__ INFO: \u001b[0mEpoch 44 Step 500/703 lr 0.100000 loss 1.5367 (1.4625) acc@1 0.4219 (0.4587) acc@5 0.8281 (0.7943)\n",
      "\u001b[32m[2020-07-01 04:38:27] __main__ INFO: \u001b[0mEpoch 44 Step 600/703 lr 0.100000 loss 1.5171 (1.4710) acc@1 0.4219 (0.4551) acc@5 0.7812 (0.7933)\n",
      "\u001b[32m[2020-07-01 04:38:58] __main__ INFO: \u001b[0mEpoch 44 Step 700/703 lr 0.100000 loss 1.4701 (1.4702) acc@1 0.4375 (0.4556) acc@5 0.7969 (0.7942)\n",
      "\u001b[32m[2020-07-01 04:38:59] __main__ INFO: \u001b[0mEpoch 44 Step 703/703 lr 0.100000 loss 1.6651 (1.4712) acc@1 0.3281 (0.4550) acc@5 0.7500 (0.7939)\n",
      "\u001b[32m[2020-07-01 04:38:59] __main__ INFO: \u001b[0mElapsed 224.15\n",
      "\u001b[32m[2020-07-01 04:38:59] __main__ INFO: \u001b[0mVal 44\n",
      "\u001b[32m[2020-07-01 04:39:07] __main__ INFO: \u001b[0mEpoch 44 loss 0.5703 acc@1 0.8126 acc@5 0.9896\n",
      "\u001b[32m[2020-07-01 04:39:07] __main__ INFO: \u001b[0mElapsed 7.79\n",
      "\u001b[32m[2020-07-01 04:39:07] __main__ INFO: \u001b[0mTrain 45 30932\n",
      "\u001b[32m[2020-07-01 04:39:39] __main__ INFO: \u001b[0mEpoch 45 Step 100/703 lr 0.100000 loss 1.6182 (1.4779) acc@1 0.4219 (0.4487) acc@5 0.7344 (0.7936)\n",
      "\u001b[32m[2020-07-01 04:40:11] __main__ INFO: \u001b[0mEpoch 45 Step 200/703 lr 0.100000 loss 1.3873 (1.4642) acc@1 0.4688 (0.4565) acc@5 0.7812 (0.7922)\n",
      "\u001b[32m[2020-07-01 04:40:43] __main__ INFO: \u001b[0mEpoch 45 Step 300/703 lr 0.100000 loss 1.2762 (1.4568) acc@1 0.5156 (0.4582) acc@5 0.8281 (0.7916)\n",
      "\u001b[32m[2020-07-01 04:41:15] __main__ INFO: \u001b[0mEpoch 45 Step 400/703 lr 0.100000 loss 1.2628 (1.4575) acc@1 0.5156 (0.4569) acc@5 0.8438 (0.7929)\n",
      "\u001b[32m[2020-07-01 04:41:47] __main__ INFO: \u001b[0mEpoch 45 Step 500/703 lr 0.100000 loss 1.3954 (1.4605) acc@1 0.5000 (0.4560) acc@5 0.8438 (0.7927)\n",
      "\u001b[32m[2020-07-01 04:42:19] __main__ INFO: \u001b[0mEpoch 45 Step 600/703 lr 0.100000 loss 1.3818 (1.4646) acc@1 0.5625 (0.4552) acc@5 0.8906 (0.7938)\n",
      "\u001b[32m[2020-07-01 04:42:51] __main__ INFO: \u001b[0mEpoch 45 Step 700/703 lr 0.100000 loss 1.3326 (1.4683) acc@1 0.5156 (0.4544) acc@5 0.7812 (0.7935)\n",
      "\u001b[32m[2020-07-01 04:42:52] __main__ INFO: \u001b[0mEpoch 45 Step 703/703 lr 0.100000 loss 1.5755 (1.4681) acc@1 0.4062 (0.4546) acc@5 0.8594 (0.7935)\n",
      "\u001b[32m[2020-07-01 04:42:52] __main__ INFO: \u001b[0mElapsed 224.54\n",
      "\u001b[32m[2020-07-01 04:42:52] __main__ INFO: \u001b[0mVal 45\n",
      "\u001b[32m[2020-07-01 04:43:00] __main__ INFO: \u001b[0mEpoch 45 loss 0.5780 acc@1 0.8032 acc@5 0.9890\n",
      "\u001b[32m[2020-07-01 04:43:00] __main__ INFO: \u001b[0mElapsed 7.79\n",
      "\u001b[32m[2020-07-01 04:43:00] __main__ INFO: \u001b[0mTrain 46 31635\n",
      "\u001b[32m[2020-07-01 04:43:32] __main__ INFO: \u001b[0mEpoch 46 Step 100/703 lr 0.100000 loss 1.5465 (1.4256) acc@1 0.4062 (0.4686) acc@5 0.8281 (0.8014)\n",
      "\u001b[32m[2020-07-01 04:44:04] __main__ INFO: \u001b[0mEpoch 46 Step 200/703 lr 0.100000 loss 1.4055 (1.4501) acc@1 0.4219 (0.4580) acc@5 0.7500 (0.7980)\n",
      "\u001b[32m[2020-07-01 04:44:35] __main__ INFO: \u001b[0mEpoch 46 Step 300/703 lr 0.100000 loss 1.3588 (1.4585) acc@1 0.5156 (0.4574) acc@5 0.7344 (0.7942)\n",
      "\u001b[32m[2020-07-01 04:45:07] __main__ INFO: \u001b[0mEpoch 46 Step 400/703 lr 0.100000 loss 1.6639 (1.4565) acc@1 0.3125 (0.4579) acc@5 0.7344 (0.7945)\n",
      "\u001b[32m[2020-07-01 04:45:39] __main__ INFO: \u001b[0mEpoch 46 Step 500/703 lr 0.100000 loss 1.5370 (1.4602) acc@1 0.3906 (0.4573) acc@5 0.7969 (0.7948)\n",
      "\u001b[32m[2020-07-01 04:46:11] __main__ INFO: \u001b[0mEpoch 46 Step 600/703 lr 0.100000 loss 1.4694 (1.4618) acc@1 0.4531 (0.4568) acc@5 0.7812 (0.7956)\n",
      "\u001b[32m[2020-07-01 04:46:43] __main__ INFO: \u001b[0mEpoch 46 Step 700/703 lr 0.100000 loss 1.4928 (1.4624) acc@1 0.4375 (0.4570) acc@5 0.7969 (0.7960)\n",
      "\u001b[32m[2020-07-01 04:46:44] __main__ INFO: \u001b[0mEpoch 46 Step 703/703 lr 0.100000 loss 1.5138 (1.4625) acc@1 0.4531 (0.4570) acc@5 0.7656 (0.7959)\n",
      "\u001b[32m[2020-07-01 04:46:44] __main__ INFO: \u001b[0mElapsed 224.37\n",
      "\u001b[32m[2020-07-01 04:46:44] __main__ INFO: \u001b[0mVal 46\n",
      "\u001b[32m[2020-07-01 04:46:52] __main__ INFO: \u001b[0mEpoch 46 loss 0.8322 acc@1 0.7448 acc@5 0.9708\n",
      "\u001b[32m[2020-07-01 04:46:52] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-01 04:46:52] __main__ INFO: \u001b[0mTrain 47 32338\n",
      "\u001b[32m[2020-07-01 04:47:24] __main__ INFO: \u001b[0mEpoch 47 Step 100/703 lr 0.100000 loss 1.4565 (1.4237) acc@1 0.4688 (0.4759) acc@5 0.8438 (0.8000)\n",
      "\u001b[32m[2020-07-01 04:47:56] __main__ INFO: \u001b[0mEpoch 47 Step 200/703 lr 0.100000 loss 1.1678 (1.4356) acc@1 0.5469 (0.4684) acc@5 0.8594 (0.7984)\n",
      "\u001b[32m[2020-07-01 04:48:28] __main__ INFO: \u001b[0mEpoch 47 Step 300/703 lr 0.100000 loss 1.5243 (1.4474) acc@1 0.4219 (0.4631) acc@5 0.7344 (0.7997)\n",
      "\u001b[32m[2020-07-01 04:48:59] __main__ INFO: \u001b[0mEpoch 47 Step 400/703 lr 0.100000 loss 1.4925 (1.4549) acc@1 0.4219 (0.4594) acc@5 0.7031 (0.7983)\n",
      "\u001b[32m[2020-07-01 04:49:31] __main__ INFO: \u001b[0mEpoch 47 Step 500/703 lr 0.100000 loss 1.3799 (1.4590) acc@1 0.4219 (0.4577) acc@5 0.8125 (0.7979)\n",
      "\u001b[32m[2020-07-01 04:50:03] __main__ INFO: \u001b[0mEpoch 47 Step 600/703 lr 0.100000 loss 1.3315 (1.4617) acc@1 0.5469 (0.4569) acc@5 0.7969 (0.7967)\n",
      "\u001b[32m[2020-07-01 04:50:35] __main__ INFO: \u001b[0mEpoch 47 Step 700/703 lr 0.100000 loss 1.4979 (1.4647) acc@1 0.4375 (0.4553) acc@5 0.7969 (0.7957)\n",
      "\u001b[32m[2020-07-01 04:50:36] __main__ INFO: \u001b[0mEpoch 47 Step 703/703 lr 0.100000 loss 1.5506 (1.4645) acc@1 0.3750 (0.4554) acc@5 0.7812 (0.7957)\n",
      "\u001b[32m[2020-07-01 04:50:36] __main__ INFO: \u001b[0mElapsed 224.34\n",
      "\u001b[32m[2020-07-01 04:50:36] __main__ INFO: \u001b[0mVal 47\n",
      "\u001b[32m[2020-07-01 04:50:44] __main__ INFO: \u001b[0mEpoch 47 loss 0.6354 acc@1 0.7878 acc@5 0.9860\n",
      "\u001b[32m[2020-07-01 04:50:44] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-01 04:50:44] __main__ INFO: \u001b[0mTrain 48 33041\n",
      "\u001b[32m[2020-07-01 04:51:16] __main__ INFO: \u001b[0mEpoch 48 Step 100/703 lr 0.100000 loss 1.2414 (1.4399) acc@1 0.5781 (0.4558) acc@5 0.7812 (0.7948)\n",
      "\u001b[32m[2020-07-01 04:51:48] __main__ INFO: \u001b[0mEpoch 48 Step 200/703 lr 0.100000 loss 1.5310 (1.4403) acc@1 0.4219 (0.4597) acc@5 0.7188 (0.7942)\n",
      "\u001b[32m[2020-07-01 04:52:20] __main__ INFO: \u001b[0mEpoch 48 Step 300/703 lr 0.100000 loss 1.6474 (1.4449) acc@1 0.3594 (0.4584) acc@5 0.8281 (0.7926)\n",
      "\u001b[32m[2020-07-01 04:52:52] __main__ INFO: \u001b[0mEpoch 48 Step 400/703 lr 0.100000 loss 1.4547 (1.4489) acc@1 0.4688 (0.4587) acc@5 0.8281 (0.7944)\n",
      "\u001b[32m[2020-07-01 04:53:23] __main__ INFO: \u001b[0mEpoch 48 Step 500/703 lr 0.100000 loss 1.4045 (1.4519) acc@1 0.5000 (0.4592) acc@5 0.7188 (0.7943)\n",
      "\u001b[32m[2020-07-01 04:53:55] __main__ INFO: \u001b[0mEpoch 48 Step 600/703 lr 0.100000 loss 1.3010 (1.4549) acc@1 0.4531 (0.4577) acc@5 0.8438 (0.7946)\n",
      "\u001b[32m[2020-07-01 04:54:27] __main__ INFO: \u001b[0mEpoch 48 Step 700/703 lr 0.100000 loss 1.9351 (1.4574) acc@1 0.2969 (0.4575) acc@5 0.7344 (0.7949)\n",
      "\u001b[32m[2020-07-01 04:54:28] __main__ INFO: \u001b[0mEpoch 48 Step 703/703 lr 0.100000 loss 1.6796 (1.4579) acc@1 0.3594 (0.4572) acc@5 0.8125 (0.7950)\n",
      "\u001b[32m[2020-07-01 04:54:28] __main__ INFO: \u001b[0mElapsed 224.21\n",
      "\u001b[32m[2020-07-01 04:54:28] __main__ INFO: \u001b[0mVal 48\n",
      "\u001b[32m[2020-07-01 04:54:36] __main__ INFO: \u001b[0mEpoch 48 loss 0.5388 acc@1 0.8220 acc@5 0.9910\n",
      "\u001b[32m[2020-07-01 04:54:36] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-01 04:54:36] __main__ INFO: \u001b[0mTrain 49 33744\n",
      "\u001b[32m[2020-07-01 04:55:08] __main__ INFO: \u001b[0mEpoch 49 Step 100/703 lr 0.100000 loss 1.3729 (1.4298) acc@1 0.5156 (0.4750) acc@5 0.8125 (0.7989)\n",
      "\u001b[32m[2020-07-01 04:55:40] __main__ INFO: \u001b[0mEpoch 49 Step 200/703 lr 0.100000 loss 1.3023 (1.4351) acc@1 0.5312 (0.4709) acc@5 0.7656 (0.7994)\n",
      "\u001b[32m[2020-07-01 04:56:12] __main__ INFO: \u001b[0mEpoch 49 Step 300/703 lr 0.100000 loss 1.2557 (1.4432) acc@1 0.5000 (0.4668) acc@5 0.8750 (0.7994)\n",
      "\u001b[32m[2020-07-01 04:56:43] __main__ INFO: \u001b[0mEpoch 49 Step 400/703 lr 0.100000 loss 1.0974 (1.4416) acc@1 0.6719 (0.4656) acc@5 0.8750 (0.7983)\n",
      "\u001b[32m[2020-07-01 04:57:15] __main__ INFO: \u001b[0mEpoch 49 Step 500/703 lr 0.100000 loss 1.4020 (1.4477) acc@1 0.5312 (0.4634) acc@5 0.8281 (0.7974)\n",
      "\u001b[32m[2020-07-01 04:57:47] __main__ INFO: \u001b[0mEpoch 49 Step 600/703 lr 0.100000 loss 1.4527 (1.4501) acc@1 0.4375 (0.4640) acc@5 0.7812 (0.7967)\n",
      "\u001b[32m[2020-07-01 04:58:19] __main__ INFO: \u001b[0mEpoch 49 Step 700/703 lr 0.100000 loss 1.4251 (1.4527) acc@1 0.5156 (0.4626) acc@5 0.8125 (0.7973)\n",
      "\u001b[32m[2020-07-01 04:58:20] __main__ INFO: \u001b[0mEpoch 49 Step 703/703 lr 0.100000 loss 1.4399 (1.4527) acc@1 0.4062 (0.4625) acc@5 0.7812 (0.7972)\n",
      "\u001b[32m[2020-07-01 04:58:20] __main__ INFO: \u001b[0mElapsed 224.17\n",
      "\u001b[32m[2020-07-01 04:58:20] __main__ INFO: \u001b[0mVal 49\n",
      "\u001b[32m[2020-07-01 04:58:28] __main__ INFO: \u001b[0mEpoch 49 loss 0.5558 acc@1 0.8150 acc@5 0.9876\n",
      "\u001b[32m[2020-07-01 04:58:28] __main__ INFO: \u001b[0mElapsed 7.82\n",
      "\u001b[32m[2020-07-01 04:58:28] __main__ INFO: \u001b[0mTrain 50 34447\n",
      "\u001b[32m[2020-07-01 04:59:00] __main__ INFO: \u001b[0mEpoch 50 Step 100/703 lr 0.100000 loss 1.5145 (1.4120) acc@1 0.4219 (0.4828) acc@5 0.7344 (0.8109)\n",
      "\u001b[32m[2020-07-01 04:59:32] __main__ INFO: \u001b[0mEpoch 50 Step 200/703 lr 0.100000 loss 1.4375 (1.4326) acc@1 0.4062 (0.4705) acc@5 0.7344 (0.8006)\n",
      "\u001b[32m[2020-07-01 05:00:03] __main__ INFO: \u001b[0mEpoch 50 Step 300/703 lr 0.100000 loss 1.6004 (1.4489) acc@1 0.3906 (0.4636) acc@5 0.7500 (0.7978)\n",
      "\u001b[32m[2020-07-01 05:00:35] __main__ INFO: \u001b[0mEpoch 50 Step 400/703 lr 0.100000 loss 1.5351 (1.4525) acc@1 0.4062 (0.4622) acc@5 0.8281 (0.7977)\n",
      "\u001b[32m[2020-07-01 05:01:07] __main__ INFO: \u001b[0mEpoch 50 Step 500/703 lr 0.100000 loss 1.6074 (1.4501) acc@1 0.3906 (0.4628) acc@5 0.8125 (0.7972)\n",
      "\u001b[32m[2020-07-01 05:01:39] __main__ INFO: \u001b[0mEpoch 50 Step 600/703 lr 0.100000 loss 1.4597 (1.4482) acc@1 0.4531 (0.4635) acc@5 0.7500 (0.7987)\n",
      "\u001b[32m[2020-07-01 05:02:11] __main__ INFO: \u001b[0mEpoch 50 Step 700/703 lr 0.100000 loss 1.4896 (1.4546) acc@1 0.3906 (0.4609) acc@5 0.8594 (0.7982)\n",
      "\u001b[32m[2020-07-01 05:02:12] __main__ INFO: \u001b[0mEpoch 50 Step 703/703 lr 0.100000 loss 1.2371 (1.4543) acc@1 0.5156 (0.4610) acc@5 0.8125 (0.7982)\n",
      "\u001b[32m[2020-07-01 05:02:12] __main__ INFO: \u001b[0mElapsed 224.12\n",
      "\u001b[32m[2020-07-01 05:02:12] __main__ INFO: \u001b[0mVal 50\n",
      "\u001b[32m[2020-07-01 05:02:20] __main__ INFO: \u001b[0mEpoch 50 loss 0.5823 acc@1 0.8036 acc@5 0.9892\n",
      "\u001b[32m[2020-07-01 05:02:20] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-01 05:02:20] __main__ INFO: \u001b[0mTrain 51 35150\n",
      "\u001b[32m[2020-07-01 05:02:52] __main__ INFO: \u001b[0mEpoch 51 Step 100/703 lr 0.100000 loss 1.4402 (1.4101) acc@1 0.4375 (0.4798) acc@5 0.8125 (0.8058)\n",
      "\u001b[32m[2020-07-01 05:03:23] __main__ INFO: \u001b[0mEpoch 51 Step 200/703 lr 0.100000 loss 1.2977 (1.4317) acc@1 0.4531 (0.4676) acc@5 0.8281 (0.7991)\n",
      "\u001b[32m[2020-07-01 05:03:55] __main__ INFO: \u001b[0mEpoch 51 Step 300/703 lr 0.100000 loss 1.3640 (1.4344) acc@1 0.4688 (0.4672) acc@5 0.8750 (0.7992)\n",
      "\u001b[32m[2020-07-01 05:04:27] __main__ INFO: \u001b[0mEpoch 51 Step 400/703 lr 0.100000 loss 1.3660 (1.4395) acc@1 0.4688 (0.4650) acc@5 0.8125 (0.7975)\n",
      "\u001b[32m[2020-07-01 05:04:59] __main__ INFO: \u001b[0mEpoch 51 Step 500/703 lr 0.100000 loss 1.2869 (1.4394) acc@1 0.5156 (0.4645) acc@5 0.7969 (0.7977)\n",
      "\u001b[32m[2020-07-01 05:05:31] __main__ INFO: \u001b[0mEpoch 51 Step 600/703 lr 0.100000 loss 1.5479 (1.4448) acc@1 0.4062 (0.4626) acc@5 0.7969 (0.7968)\n",
      "\u001b[32m[2020-07-01 05:06:03] __main__ INFO: \u001b[0mEpoch 51 Step 700/703 lr 0.100000 loss 1.8141 (1.4488) acc@1 0.3281 (0.4616) acc@5 0.6875 (0.7954)\n",
      "\u001b[32m[2020-07-01 05:06:04] __main__ INFO: \u001b[0mEpoch 51 Step 703/703 lr 0.100000 loss 1.5146 (1.4489) acc@1 0.4688 (0.4615) acc@5 0.7500 (0.7954)\n",
      "\u001b[32m[2020-07-01 05:06:04] __main__ INFO: \u001b[0mElapsed 224.20\n",
      "\u001b[32m[2020-07-01 05:06:04] __main__ INFO: \u001b[0mVal 51\n",
      "\u001b[32m[2020-07-01 05:06:12] __main__ INFO: \u001b[0mEpoch 51 loss 0.6095 acc@1 0.7984 acc@5 0.9870\n",
      "\u001b[32m[2020-07-01 05:06:12] __main__ INFO: \u001b[0mElapsed 7.79\n",
      "\u001b[32m[2020-07-01 05:06:12] __main__ INFO: \u001b[0mTrain 52 35853\n",
      "\u001b[32m[2020-07-01 05:06:44] __main__ INFO: \u001b[0mEpoch 52 Step 100/703 lr 0.100000 loss 1.3081 (1.4062) acc@1 0.4375 (0.4761) acc@5 0.7969 (0.7953)\n",
      "\u001b[32m[2020-07-01 05:07:16] __main__ INFO: \u001b[0mEpoch 52 Step 200/703 lr 0.100000 loss 1.4906 (1.4269) acc@1 0.4062 (0.4688) acc@5 0.7500 (0.7939)\n",
      "\u001b[32m[2020-07-01 05:07:47] __main__ INFO: \u001b[0mEpoch 52 Step 300/703 lr 0.100000 loss 1.4822 (1.4338) acc@1 0.4062 (0.4654) acc@5 0.8438 (0.7952)\n",
      "\u001b[32m[2020-07-01 05:08:19] __main__ INFO: \u001b[0mEpoch 52 Step 400/703 lr 0.100000 loss 1.4520 (1.4329) acc@1 0.4219 (0.4665) acc@5 0.8125 (0.7984)\n",
      "\u001b[32m[2020-07-01 05:08:51] __main__ INFO: \u001b[0mEpoch 52 Step 500/703 lr 0.100000 loss 1.5196 (1.4389) acc@1 0.4375 (0.4642) acc@5 0.7812 (0.7969)\n",
      "\u001b[32m[2020-07-01 05:09:23] __main__ INFO: \u001b[0mEpoch 52 Step 600/703 lr 0.100000 loss 1.7343 (1.4397) acc@1 0.3750 (0.4643) acc@5 0.6562 (0.7975)\n",
      "\u001b[32m[2020-07-01 05:09:55] __main__ INFO: \u001b[0mEpoch 52 Step 700/703 lr 0.100000 loss 1.4933 (1.4436) acc@1 0.4219 (0.4625) acc@5 0.7188 (0.7968)\n",
      "\u001b[32m[2020-07-01 05:09:56] __main__ INFO: \u001b[0mEpoch 52 Step 703/703 lr 0.100000 loss 1.4502 (1.4436) acc@1 0.5000 (0.4625) acc@5 0.7969 (0.7969)\n",
      "\u001b[32m[2020-07-01 05:09:56] __main__ INFO: \u001b[0mElapsed 224.15\n",
      "\u001b[32m[2020-07-01 05:09:56] __main__ INFO: \u001b[0mVal 52\n",
      "\u001b[32m[2020-07-01 05:10:04] __main__ INFO: \u001b[0mEpoch 52 loss 0.6527 acc@1 0.7852 acc@5 0.9840\n",
      "\u001b[32m[2020-07-01 05:10:04] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-01 05:10:04] __main__ INFO: \u001b[0mTrain 53 36556\n",
      "\u001b[32m[2020-07-01 05:10:36] __main__ INFO: \u001b[0mEpoch 53 Step 100/703 lr 0.100000 loss 1.5025 (1.4421) acc@1 0.4375 (0.4600) acc@5 0.8281 (0.7925)\n",
      "\u001b[32m[2020-07-01 05:11:08] __main__ INFO: \u001b[0mEpoch 53 Step 200/703 lr 0.100000 loss 1.3996 (1.4458) acc@1 0.4531 (0.4588) acc@5 0.7656 (0.7954)\n",
      "\u001b[32m[2020-07-01 05:11:39] __main__ INFO: \u001b[0mEpoch 53 Step 300/703 lr 0.100000 loss 1.2942 (1.4420) acc@1 0.4844 (0.4615) acc@5 0.7969 (0.7965)\n",
      "\u001b[32m[2020-07-01 05:12:11] __main__ INFO: \u001b[0mEpoch 53 Step 400/703 lr 0.100000 loss 1.3614 (1.4364) acc@1 0.5000 (0.4640) acc@5 0.8594 (0.8004)\n",
      "\u001b[32m[2020-07-01 05:12:43] __main__ INFO: \u001b[0mEpoch 53 Step 500/703 lr 0.100000 loss 1.4084 (1.4416) acc@1 0.5156 (0.4618) acc@5 0.8594 (0.7994)\n",
      "\u001b[32m[2020-07-01 05:13:15] __main__ INFO: \u001b[0mEpoch 53 Step 600/703 lr 0.100000 loss 1.2390 (1.4394) acc@1 0.5000 (0.4629) acc@5 0.7812 (0.7993)\n",
      "\u001b[32m[2020-07-01 05:13:47] __main__ INFO: \u001b[0mEpoch 53 Step 700/703 lr 0.100000 loss 1.2952 (1.4426) acc@1 0.5938 (0.4624) acc@5 0.8750 (0.7993)\n",
      "\u001b[32m[2020-07-01 05:13:48] __main__ INFO: \u001b[0mEpoch 53 Step 703/703 lr 0.100000 loss 1.2718 (1.4421) acc@1 0.5625 (0.4626) acc@5 0.9062 (0.7996)\n",
      "\u001b[32m[2020-07-01 05:13:48] __main__ INFO: \u001b[0mElapsed 224.23\n",
      "\u001b[32m[2020-07-01 05:13:48] __main__ INFO: \u001b[0mVal 53\n",
      "\u001b[32m[2020-07-01 05:13:56] __main__ INFO: \u001b[0mEpoch 53 loss 0.6310 acc@1 0.7870 acc@5 0.9888\n",
      "\u001b[32m[2020-07-01 05:13:56] __main__ INFO: \u001b[0mElapsed 7.80\n",
      "\u001b[32m[2020-07-01 05:13:56] __main__ INFO: \u001b[0mTrain 54 37259\n",
      "\u001b[32m[2020-07-01 05:14:28] __main__ INFO: \u001b[0mEpoch 54 Step 100/703 lr 0.100000 loss 1.7922 (1.4080) acc@1 0.3594 (0.4798) acc@5 0.6875 (0.8037)\n",
      "\u001b[32m[2020-07-01 05:15:00] __main__ INFO: \u001b[0mEpoch 54 Step 200/703 lr 0.100000 loss 1.5830 (1.4188) acc@1 0.3906 (0.4713) acc@5 0.7812 (0.8021)\n",
      "\u001b[32m[2020-07-01 05:15:32] __main__ INFO: \u001b[0mEpoch 54 Step 300/703 lr 0.100000 loss 1.4582 (1.4282) acc@1 0.4062 (0.4677) acc@5 0.7969 (0.7990)\n",
      "\u001b[32m[2020-07-01 05:16:03] __main__ INFO: \u001b[0mEpoch 54 Step 400/703 lr 0.100000 loss 1.6130 (1.4301) acc@1 0.4219 (0.4676) acc@5 0.7344 (0.7998)\n",
      "\u001b[32m[2020-07-01 05:16:35] __main__ INFO: \u001b[0mEpoch 54 Step 500/703 lr 0.100000 loss 1.3508 (1.4305) acc@1 0.5156 (0.4679) acc@5 0.8281 (0.7989)\n",
      "\u001b[32m[2020-07-01 05:17:07] __main__ INFO: \u001b[0mEpoch 54 Step 600/703 lr 0.100000 loss 1.3089 (1.4319) acc@1 0.4844 (0.4675) acc@5 0.7812 (0.7976)\n",
      "\u001b[32m[2020-07-01 05:17:39] __main__ INFO: \u001b[0mEpoch 54 Step 700/703 lr 0.100000 loss 1.6499 (1.4331) acc@1 0.3750 (0.4662) acc@5 0.7656 (0.7984)\n",
      "\u001b[32m[2020-07-01 05:17:40] __main__ INFO: \u001b[0mEpoch 54 Step 703/703 lr 0.100000 loss 1.8288 (1.4340) acc@1 0.3594 (0.4659) acc@5 0.7344 (0.7983)\n",
      "\u001b[32m[2020-07-01 05:17:40] __main__ INFO: \u001b[0mElapsed 224.45\n",
      "\u001b[32m[2020-07-01 05:17:40] __main__ INFO: \u001b[0mVal 54\n",
      "\u001b[32m[2020-07-01 05:17:48] __main__ INFO: \u001b[0mEpoch 54 loss 0.5892 acc@1 0.8034 acc@5 0.9870\n",
      "\u001b[32m[2020-07-01 05:17:48] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-01 05:17:48] __main__ INFO: \u001b[0mTrain 55 37962\n",
      "\u001b[32m[2020-07-01 05:18:20] __main__ INFO: \u001b[0mEpoch 55 Step 100/703 lr 0.100000 loss 1.4341 (1.4210) acc@1 0.4688 (0.4653) acc@5 0.7656 (0.7992)\n",
      "\u001b[32m[2020-07-01 05:18:52] __main__ INFO: \u001b[0mEpoch 55 Step 200/703 lr 0.100000 loss 1.5179 (1.4238) acc@1 0.4375 (0.4670) acc@5 0.7031 (0.7972)\n",
      "\u001b[32m[2020-07-01 05:19:24] __main__ INFO: \u001b[0mEpoch 55 Step 300/703 lr 0.100000 loss 1.3811 (1.4387) acc@1 0.5469 (0.4628) acc@5 0.8594 (0.7965)\n",
      "\u001b[32m[2020-07-01 05:19:56] __main__ INFO: \u001b[0mEpoch 55 Step 400/703 lr 0.100000 loss 1.2251 (1.4355) acc@1 0.5625 (0.4646) acc@5 0.8438 (0.7974)\n",
      "\u001b[32m[2020-07-01 05:20:27] __main__ INFO: \u001b[0mEpoch 55 Step 500/703 lr 0.100000 loss 1.6164 (1.4352) acc@1 0.3750 (0.4649) acc@5 0.7656 (0.7977)\n",
      "\u001b[32m[2020-07-01 05:20:59] __main__ INFO: \u001b[0mEpoch 55 Step 600/703 lr 0.100000 loss 1.4256 (1.4349) acc@1 0.4688 (0.4655) acc@5 0.8125 (0.7975)\n",
      "\u001b[32m[2020-07-01 05:21:31] __main__ INFO: \u001b[0mEpoch 55 Step 700/703 lr 0.100000 loss 1.4915 (1.4350) acc@1 0.3750 (0.4650) acc@5 0.8125 (0.7990)\n",
      "\u001b[32m[2020-07-01 05:21:32] __main__ INFO: \u001b[0mEpoch 55 Step 703/703 lr 0.100000 loss 1.3841 (1.4351) acc@1 0.4844 (0.4650) acc@5 0.8281 (0.7989)\n",
      "\u001b[32m[2020-07-01 05:21:32] __main__ INFO: \u001b[0mElapsed 224.23\n",
      "\u001b[32m[2020-07-01 05:21:32] __main__ INFO: \u001b[0mVal 55\n",
      "\u001b[32m[2020-07-01 05:21:40] __main__ INFO: \u001b[0mEpoch 55 loss 0.5505 acc@1 0.8160 acc@5 0.9880\n",
      "\u001b[32m[2020-07-01 05:21:40] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-01 05:21:40] __main__ INFO: \u001b[0mTrain 56 38665\n",
      "\u001b[32m[2020-07-01 05:22:12] __main__ INFO: \u001b[0mEpoch 56 Step 100/703 lr 0.100000 loss 1.6124 (1.4246) acc@1 0.4375 (0.4686) acc@5 0.7500 (0.7887)\n",
      "\u001b[32m[2020-07-01 05:22:44] __main__ INFO: \u001b[0mEpoch 56 Step 200/703 lr 0.100000 loss 1.4113 (1.4247) acc@1 0.4688 (0.4684) acc@5 0.7188 (0.7944)\n",
      "\u001b[32m[2020-07-01 05:23:16] __main__ INFO: \u001b[0mEpoch 56 Step 300/703 lr 0.100000 loss 1.4518 (1.4282) acc@1 0.4375 (0.4671) acc@5 0.7344 (0.7975)\n",
      "\u001b[32m[2020-07-01 05:23:47] __main__ INFO: \u001b[0mEpoch 56 Step 400/703 lr 0.100000 loss 1.6226 (1.4332) acc@1 0.3750 (0.4664) acc@5 0.7656 (0.7970)\n",
      "\u001b[32m[2020-07-01 05:24:19] __main__ INFO: \u001b[0mEpoch 56 Step 500/703 lr 0.100000 loss 1.4454 (1.4376) acc@1 0.4844 (0.4633) acc@5 0.8281 (0.7960)\n",
      "\u001b[32m[2020-07-01 05:24:51] __main__ INFO: \u001b[0mEpoch 56 Step 600/703 lr 0.100000 loss 1.2351 (1.4357) acc@1 0.6094 (0.4640) acc@5 0.8438 (0.7961)\n",
      "\u001b[32m[2020-07-01 05:25:23] __main__ INFO: \u001b[0mEpoch 56 Step 700/703 lr 0.100000 loss 1.4586 (1.4347) acc@1 0.4531 (0.4644) acc@5 0.8281 (0.7965)\n",
      "\u001b[32m[2020-07-01 05:25:24] __main__ INFO: \u001b[0mEpoch 56 Step 703/703 lr 0.100000 loss 1.3546 (1.4352) acc@1 0.5156 (0.4643) acc@5 0.8438 (0.7963)\n",
      "\u001b[32m[2020-07-01 05:25:24] __main__ INFO: \u001b[0mElapsed 224.04\n",
      "\u001b[32m[2020-07-01 05:25:24] __main__ INFO: \u001b[0mVal 56\n",
      "\u001b[32m[2020-07-01 05:25:32] __main__ INFO: \u001b[0mEpoch 56 loss 0.5448 acc@1 0.8194 acc@5 0.9902\n",
      "\u001b[32m[2020-07-01 05:25:32] __main__ INFO: \u001b[0mElapsed 7.80\n",
      "\u001b[32m[2020-07-01 05:25:32] __main__ INFO: \u001b[0mTrain 57 39368\n",
      "\u001b[32m[2020-07-01 05:26:04] __main__ INFO: \u001b[0mEpoch 57 Step 100/703 lr 0.100000 loss 1.1945 (1.4019) acc@1 0.5938 (0.4803) acc@5 0.7812 (0.7973)\n",
      "\u001b[32m[2020-07-01 05:26:36] __main__ INFO: \u001b[0mEpoch 57 Step 200/703 lr 0.100000 loss 1.5518 (1.4227) acc@1 0.4219 (0.4733) acc@5 0.7969 (0.7943)\n",
      "\u001b[32m[2020-07-01 05:27:08] __main__ INFO: \u001b[0mEpoch 57 Step 300/703 lr 0.100000 loss 1.3709 (1.4128) acc@1 0.4688 (0.4755) acc@5 0.8281 (0.7988)\n",
      "\u001b[32m[2020-07-01 05:27:39] __main__ INFO: \u001b[0mEpoch 57 Step 400/703 lr 0.100000 loss 1.3733 (1.4250) acc@1 0.5156 (0.4710) acc@5 0.7969 (0.7975)\n",
      "\u001b[32m[2020-07-01 05:28:11] __main__ INFO: \u001b[0mEpoch 57 Step 500/703 lr 0.100000 loss 1.8010 (1.4305) acc@1 0.4062 (0.4681) acc@5 0.7344 (0.7982)\n",
      "\u001b[32m[2020-07-01 05:28:43] __main__ INFO: \u001b[0mEpoch 57 Step 600/703 lr 0.100000 loss 1.4782 (1.4342) acc@1 0.4688 (0.4668) acc@5 0.8125 (0.7975)\n",
      "\u001b[32m[2020-07-01 05:29:15] __main__ INFO: \u001b[0mEpoch 57 Step 700/703 lr 0.100000 loss 1.7223 (1.4317) acc@1 0.3750 (0.4675) acc@5 0.7969 (0.7976)\n",
      "\u001b[32m[2020-07-01 05:29:16] __main__ INFO: \u001b[0mEpoch 57 Step 703/703 lr 0.100000 loss 1.6648 (1.4319) acc@1 0.4062 (0.4675) acc@5 0.7344 (0.7976)\n",
      "\u001b[32m[2020-07-01 05:29:16] __main__ INFO: \u001b[0mElapsed 224.46\n",
      "\u001b[32m[2020-07-01 05:29:16] __main__ INFO: \u001b[0mVal 57\n",
      "\u001b[32m[2020-07-01 05:29:24] __main__ INFO: \u001b[0mEpoch 57 loss 0.5877 acc@1 0.8000 acc@5 0.9898\n",
      "\u001b[32m[2020-07-01 05:29:24] __main__ INFO: \u001b[0mElapsed 7.81\n",
      "\u001b[32m[2020-07-01 05:29:24] __main__ INFO: \u001b[0mTrain 58 40071\n",
      "\u001b[32m[2020-07-01 05:29:56] __main__ INFO: \u001b[0mEpoch 58 Step 100/703 lr 0.100000 loss 1.2789 (1.4052) acc@1 0.5625 (0.4758) acc@5 0.7656 (0.8039)\n",
      "\u001b[32m[2020-07-01 05:30:28] __main__ INFO: \u001b[0mEpoch 58 Step 200/703 lr 0.100000 loss 1.4573 (1.4088) acc@1 0.4375 (0.4794) acc@5 0.7969 (0.8039)\n",
      "\u001b[32m[2020-07-01 05:31:00] __main__ INFO: \u001b[0mEpoch 58 Step 300/703 lr 0.100000 loss 1.5293 (1.4166) acc@1 0.3906 (0.4742) acc@5 0.7969 (0.8030)\n",
      "\u001b[32m[2020-07-01 05:31:32] __main__ INFO: \u001b[0mEpoch 58 Step 400/703 lr 0.100000 loss 1.5812 (1.4193) acc@1 0.3438 (0.4733) acc@5 0.7969 (0.8000)\n",
      "\u001b[32m[2020-07-01 05:32:03] __main__ INFO: \u001b[0mEpoch 58 Step 500/703 lr 0.100000 loss 1.3931 (1.4221) acc@1 0.5000 (0.4719) acc@5 0.8281 (0.7995)\n",
      "\u001b[32m[2020-07-01 05:32:35] __main__ INFO: \u001b[0mEpoch 58 Step 600/703 lr 0.100000 loss 1.3706 (1.4296) acc@1 0.5156 (0.4703) acc@5 0.7656 (0.7985)\n",
      "\u001b[32m[2020-07-01 05:33:07] __main__ INFO: \u001b[0mEpoch 58 Step 700/703 lr 0.100000 loss 1.5612 (1.4325) acc@1 0.4062 (0.4692) acc@5 0.7969 (0.7985)\n",
      "\u001b[32m[2020-07-01 05:33:08] __main__ INFO: \u001b[0mEpoch 58 Step 703/703 lr 0.100000 loss 1.1729 (1.4327) acc@1 0.5938 (0.4693) acc@5 0.9062 (0.7984)\n",
      "\u001b[32m[2020-07-01 05:33:08] __main__ INFO: \u001b[0mElapsed 224.19\n",
      "\u001b[32m[2020-07-01 05:33:08] __main__ INFO: \u001b[0mVal 58\n",
      "\u001b[32m[2020-07-01 05:33:16] __main__ INFO: \u001b[0mEpoch 58 loss 0.5855 acc@1 0.7980 acc@5 0.9886\n",
      "\u001b[32m[2020-07-01 05:33:16] __main__ INFO: \u001b[0mElapsed 7.80\n",
      "\u001b[32m[2020-07-01 05:33:16] __main__ INFO: \u001b[0mTrain 59 40774\n",
      "\u001b[32m[2020-07-01 05:33:48] __main__ INFO: \u001b[0mEpoch 59 Step 100/703 lr 0.100000 loss 1.5274 (1.3942) acc@1 0.3906 (0.4811) acc@5 0.7500 (0.7995)\n",
      "\u001b[32m[2020-07-01 05:34:20] __main__ INFO: \u001b[0mEpoch 59 Step 200/703 lr 0.100000 loss 1.4822 (1.4024) acc@1 0.3906 (0.4748) acc@5 0.7656 (0.8002)\n",
      "\u001b[32m[2020-07-01 05:34:52] __main__ INFO: \u001b[0mEpoch 59 Step 300/703 lr 0.100000 loss 1.5195 (1.4152) acc@1 0.4375 (0.4702) acc@5 0.7812 (0.7988)\n",
      "\u001b[32m[2020-07-01 05:35:24] __main__ INFO: \u001b[0mEpoch 59 Step 400/703 lr 0.100000 loss 1.7858 (1.4148) acc@1 0.3438 (0.4705) acc@5 0.8125 (0.7979)\n",
      "\u001b[32m[2020-07-01 05:35:55] __main__ INFO: \u001b[0mEpoch 59 Step 500/703 lr 0.100000 loss 1.2341 (1.4214) acc@1 0.5781 (0.4688) acc@5 0.8594 (0.7971)\n",
      "\u001b[32m[2020-07-01 05:36:27] __main__ INFO: \u001b[0mEpoch 59 Step 600/703 lr 0.100000 loss 1.4726 (1.4229) acc@1 0.4844 (0.4688) acc@5 0.9062 (0.7983)\n",
      "\u001b[32m[2020-07-01 05:36:59] __main__ INFO: \u001b[0mEpoch 59 Step 700/703 lr 0.100000 loss 1.3911 (1.4242) acc@1 0.5000 (0.4685) acc@5 0.8281 (0.7980)\n",
      "\u001b[32m[2020-07-01 05:37:00] __main__ INFO: \u001b[0mEpoch 59 Step 703/703 lr 0.100000 loss 1.2627 (1.4248) acc@1 0.5625 (0.4683) acc@5 0.8125 (0.7978)\n",
      "\u001b[32m[2020-07-01 05:37:00] __main__ INFO: \u001b[0mElapsed 223.99\n",
      "\u001b[32m[2020-07-01 05:37:00] __main__ INFO: \u001b[0mVal 59\n",
      "\u001b[32m[2020-07-01 05:37:08] __main__ INFO: \u001b[0mEpoch 59 loss 0.6427 acc@1 0.7978 acc@5 0.9860\n",
      "\u001b[32m[2020-07-01 05:37:08] __main__ INFO: \u001b[0mElapsed 7.79\n",
      "\u001b[32m[2020-07-01 05:37:08] __main__ INFO: \u001b[0mTrain 60 41477\n",
      "\u001b[32m[2020-07-01 05:37:40] __main__ INFO: \u001b[0mEpoch 60 Step 100/703 lr 0.100000 loss 1.2442 (1.3858) acc@1 0.5312 (0.4808) acc@5 0.8281 (0.8144)\n",
      "\u001b[32m[2020-07-01 05:38:12] __main__ INFO: \u001b[0mEpoch 60 Step 200/703 lr 0.100000 loss 1.4233 (1.4061) acc@1 0.3906 (0.4754) acc@5 0.8125 (0.8042)\n",
      "\u001b[32m[2020-07-01 05:38:44] __main__ INFO: \u001b[0mEpoch 60 Step 300/703 lr 0.100000 loss 1.5332 (1.4160) acc@1 0.4219 (0.4732) acc@5 0.7812 (0.8019)\n",
      "\u001b[32m[2020-07-01 05:39:15] __main__ INFO: \u001b[0mEpoch 60 Step 400/703 lr 0.100000 loss 1.5266 (1.4195) acc@1 0.4375 (0.4712) acc@5 0.8438 (0.8011)\n",
      "\u001b[32m[2020-07-01 05:39:47] __main__ INFO: \u001b[0mEpoch 60 Step 500/703 lr 0.100000 loss 1.6419 (1.4210) acc@1 0.4062 (0.4714) acc@5 0.7969 (0.8011)\n",
      "\u001b[32m[2020-07-01 05:40:19] __main__ INFO: \u001b[0mEpoch 60 Step 600/703 lr 0.100000 loss 1.2987 (1.4232) acc@1 0.5156 (0.4717) acc@5 0.8125 (0.7999)\n",
      "\u001b[32m[2020-07-01 05:40:51] __main__ INFO: \u001b[0mEpoch 60 Step 700/703 lr 0.100000 loss 1.2358 (1.4200) acc@1 0.5469 (0.4740) acc@5 0.8281 (0.8001)\n",
      "\u001b[32m[2020-07-01 05:40:52] __main__ INFO: \u001b[0mEpoch 60 Step 703/703 lr 0.100000 loss 1.3877 (1.4199) acc@1 0.5000 (0.4740) acc@5 0.8125 (0.8001)\n",
      "\u001b[32m[2020-07-01 05:40:52] __main__ INFO: \u001b[0mElapsed 224.28\n",
      "\u001b[32m[2020-07-01 05:40:52] __main__ INFO: \u001b[0mVal 60\n",
      "\u001b[32m[2020-07-01 05:41:00] __main__ INFO: \u001b[0mEpoch 60 loss 0.5740 acc@1 0.8076 acc@5 0.9888\n",
      "\u001b[32m[2020-07-01 05:41:00] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-01 05:41:00] __main__ INFO: \u001b[0mTrain 61 42180\n",
      "\u001b[32m[2020-07-01 05:41:32] __main__ INFO: \u001b[0mEpoch 61 Step 100/703 lr 0.100000 loss 1.5156 (1.4078) acc@1 0.4688 (0.4848) acc@5 0.8281 (0.8080)\n",
      "\u001b[32m[2020-07-01 05:42:04] __main__ INFO: \u001b[0mEpoch 61 Step 200/703 lr 0.100000 loss 1.5004 (1.4160) acc@1 0.3906 (0.4774) acc@5 0.7969 (0.8059)\n",
      "\u001b[32m[2020-07-01 05:42:36] __main__ INFO: \u001b[0mEpoch 61 Step 300/703 lr 0.100000 loss 1.1062 (1.4200) acc@1 0.5469 (0.4744) acc@5 0.8281 (0.8033)\n",
      "\u001b[32m[2020-07-01 05:43:07] __main__ INFO: \u001b[0mEpoch 61 Step 400/703 lr 0.100000 loss 1.4562 (1.4226) acc@1 0.5000 (0.4739) acc@5 0.8125 (0.8016)\n",
      "\u001b[32m[2020-07-01 05:43:39] __main__ INFO: \u001b[0mEpoch 61 Step 500/703 lr 0.100000 loss 1.5932 (1.4224) acc@1 0.4844 (0.4740) acc@5 0.7812 (0.8012)\n",
      "\u001b[32m[2020-07-01 05:44:11] __main__ INFO: \u001b[0mEpoch 61 Step 600/703 lr 0.100000 loss 1.3263 (1.4195) acc@1 0.4688 (0.4738) acc@5 0.7344 (0.8025)\n",
      "\u001b[32m[2020-07-01 05:44:43] __main__ INFO: \u001b[0mEpoch 61 Step 700/703 lr 0.100000 loss 1.3785 (1.4223) acc@1 0.5000 (0.4720) acc@5 0.7969 (0.8010)\n",
      "\u001b[32m[2020-07-01 05:44:44] __main__ INFO: \u001b[0mEpoch 61 Step 703/703 lr 0.100000 loss 1.3829 (1.4218) acc@1 0.4688 (0.4721) acc@5 0.8594 (0.8011)\n",
      "\u001b[32m[2020-07-01 05:44:44] __main__ INFO: \u001b[0mElapsed 223.98\n",
      "\u001b[32m[2020-07-01 05:44:44] __main__ INFO: \u001b[0mVal 61\n",
      "\u001b[32m[2020-07-01 05:44:52] __main__ INFO: \u001b[0mEpoch 61 loss 0.5832 acc@1 0.8008 acc@5 0.9884\n",
      "\u001b[32m[2020-07-01 05:44:52] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-01 05:44:52] __main__ INFO: \u001b[0mTrain 62 42883\n",
      "\u001b[32m[2020-07-01 05:45:24] __main__ INFO: \u001b[0mEpoch 62 Step 100/703 lr 0.100000 loss 1.4551 (1.3778) acc@1 0.4688 (0.4847) acc@5 0.7969 (0.8006)\n",
      "\u001b[32m[2020-07-01 05:45:55] __main__ INFO: \u001b[0mEpoch 62 Step 200/703 lr 0.100000 loss 1.3641 (1.4018) acc@1 0.4531 (0.4738) acc@5 0.8594 (0.8018)\n",
      "\u001b[32m[2020-07-01 05:46:27] __main__ INFO: \u001b[0mEpoch 62 Step 300/703 lr 0.100000 loss 1.1906 (1.4032) acc@1 0.5938 (0.4760) acc@5 0.8750 (0.8031)\n",
      "\u001b[32m[2020-07-01 05:46:59] __main__ INFO: \u001b[0mEpoch 62 Step 400/703 lr 0.100000 loss 1.2022 (1.4079) acc@1 0.5469 (0.4743) acc@5 0.8906 (0.8021)\n",
      "\u001b[32m[2020-07-01 05:47:31] __main__ INFO: \u001b[0mEpoch 62 Step 500/703 lr 0.100000 loss 1.6485 (1.4082) acc@1 0.3438 (0.4737) acc@5 0.7031 (0.8013)\n",
      "\u001b[32m[2020-07-01 05:48:03] __main__ INFO: \u001b[0mEpoch 62 Step 600/703 lr 0.100000 loss 1.5908 (1.4124) acc@1 0.4062 (0.4723) acc@5 0.7344 (0.8007)\n",
      "\u001b[32m[2020-07-01 05:48:35] __main__ INFO: \u001b[0mEpoch 62 Step 700/703 lr 0.100000 loss 1.4205 (1.4159) acc@1 0.4531 (0.4707) acc@5 0.8594 (0.8008)\n",
      "\u001b[32m[2020-07-01 05:48:36] __main__ INFO: \u001b[0mEpoch 62 Step 703/703 lr 0.100000 loss 1.4838 (1.4163) acc@1 0.3750 (0.4705) acc@5 0.7812 (0.8007)\n",
      "\u001b[32m[2020-07-01 05:48:36] __main__ INFO: \u001b[0mElapsed 224.17\n",
      "\u001b[32m[2020-07-01 05:48:36] __main__ INFO: \u001b[0mVal 62\n",
      "\u001b[32m[2020-07-01 05:48:44] __main__ INFO: \u001b[0mEpoch 62 loss 0.6364 acc@1 0.8018 acc@5 0.9858\n",
      "\u001b[32m[2020-07-01 05:48:44] __main__ INFO: \u001b[0mElapsed 7.80\n",
      "\u001b[32m[2020-07-01 05:48:44] __main__ INFO: \u001b[0mTrain 63 43586\n",
      "\u001b[32m[2020-07-01 05:49:16] __main__ INFO: \u001b[0mEpoch 63 Step 100/703 lr 0.100000 loss 1.3491 (1.3614) acc@1 0.4844 (0.4939) acc@5 0.8281 (0.8102)\n",
      "\u001b[32m[2020-07-01 05:49:48] __main__ INFO: \u001b[0mEpoch 63 Step 200/703 lr 0.100000 loss 1.6022 (1.3782) acc@1 0.4375 (0.4866) acc@5 0.8281 (0.8106)\n",
      "\u001b[32m[2020-07-01 05:50:20] __main__ INFO: \u001b[0mEpoch 63 Step 300/703 lr 0.100000 loss 1.2117 (1.3891) acc@1 0.5938 (0.4836) acc@5 0.8125 (0.8074)\n",
      "\u001b[32m[2020-07-01 05:50:51] __main__ INFO: \u001b[0mEpoch 63 Step 400/703 lr 0.100000 loss 1.3628 (1.4034) acc@1 0.5000 (0.4780) acc@5 0.7500 (0.8040)\n",
      "\u001b[32m[2020-07-01 05:51:23] __main__ INFO: \u001b[0mEpoch 63 Step 500/703 lr 0.100000 loss 1.4725 (1.4090) acc@1 0.4219 (0.4747) acc@5 0.7656 (0.8022)\n",
      "\u001b[32m[2020-07-01 05:51:55] __main__ INFO: \u001b[0mEpoch 63 Step 600/703 lr 0.100000 loss 1.2112 (1.4123) acc@1 0.5312 (0.4735) acc@5 0.8281 (0.8016)\n",
      "\u001b[32m[2020-07-01 05:52:27] __main__ INFO: \u001b[0mEpoch 63 Step 700/703 lr 0.100000 loss 1.3315 (1.4184) acc@1 0.5312 (0.4716) acc@5 0.8125 (0.8001)\n",
      "\u001b[32m[2020-07-01 05:52:28] __main__ INFO: \u001b[0mEpoch 63 Step 703/703 lr 0.100000 loss 1.6187 (1.4187) acc@1 0.3906 (0.4715) acc@5 0.6875 (0.8001)\n",
      "\u001b[32m[2020-07-01 05:52:28] __main__ INFO: \u001b[0mElapsed 224.44\n",
      "\u001b[32m[2020-07-01 05:52:28] __main__ INFO: \u001b[0mVal 63\n",
      "\u001b[32m[2020-07-01 05:52:36] __main__ INFO: \u001b[0mEpoch 63 loss 0.7008 acc@1 0.7806 acc@5 0.9836\n",
      "\u001b[32m[2020-07-01 05:52:36] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-01 05:52:36] __main__ INFO: \u001b[0mTrain 64 44289\n",
      "\u001b[32m[2020-07-01 05:53:08] __main__ INFO: \u001b[0mEpoch 64 Step 100/703 lr 0.100000 loss 1.4190 (1.3694) acc@1 0.4531 (0.4895) acc@5 0.7969 (0.7959)\n",
      "\u001b[32m[2020-07-01 05:53:40] __main__ INFO: \u001b[0mEpoch 64 Step 200/703 lr 0.100000 loss 1.2044 (1.3859) acc@1 0.5625 (0.4827) acc@5 0.9062 (0.8003)\n",
      "\u001b[32m[2020-07-01 05:54:11] __main__ INFO: \u001b[0mEpoch 64 Step 300/703 lr 0.100000 loss 1.2583 (1.3961) acc@1 0.5469 (0.4814) acc@5 0.8125 (0.7981)\n",
      "\u001b[32m[2020-07-01 05:54:43] __main__ INFO: \u001b[0mEpoch 64 Step 400/703 lr 0.100000 loss 1.3370 (1.3951) acc@1 0.4688 (0.4809) acc@5 0.8125 (0.7990)\n",
      "\u001b[32m[2020-07-01 05:55:15] __main__ INFO: \u001b[0mEpoch 64 Step 500/703 lr 0.100000 loss 1.4391 (1.4006) acc@1 0.5000 (0.4791) acc@5 0.7969 (0.7977)\n",
      "\u001b[32m[2020-07-01 05:55:47] __main__ INFO: \u001b[0mEpoch 64 Step 600/703 lr 0.100000 loss 1.5577 (1.4061) acc@1 0.3906 (0.4776) acc@5 0.8281 (0.7968)\n",
      "\u001b[32m[2020-07-01 05:56:19] __main__ INFO: \u001b[0mEpoch 64 Step 700/703 lr 0.100000 loss 1.2807 (1.4114) acc@1 0.5781 (0.4744) acc@5 0.8125 (0.7956)\n",
      "\u001b[32m[2020-07-01 05:56:20] __main__ INFO: \u001b[0mEpoch 64 Step 703/703 lr 0.100000 loss 1.5818 (1.4117) acc@1 0.4219 (0.4743) acc@5 0.6406 (0.7952)\n",
      "\u001b[32m[2020-07-01 05:56:20] __main__ INFO: \u001b[0mElapsed 224.15\n",
      "\u001b[32m[2020-07-01 05:56:20] __main__ INFO: \u001b[0mVal 64\n",
      "\u001b[32m[2020-07-01 05:56:28] __main__ INFO: \u001b[0mEpoch 64 loss 0.6294 acc@1 0.7970 acc@5 0.9856\n",
      "\u001b[32m[2020-07-01 05:56:28] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-01 05:56:28] __main__ INFO: \u001b[0mTrain 65 44992\n",
      "\u001b[32m[2020-07-01 05:57:00] __main__ INFO: \u001b[0mEpoch 65 Step 100/703 lr 0.100000 loss 1.3786 (1.4080) acc@1 0.5469 (0.4795) acc@5 0.7969 (0.8053)\n",
      "\u001b[32m[2020-07-01 05:57:32] __main__ INFO: \u001b[0mEpoch 65 Step 200/703 lr 0.100000 loss 1.4374 (1.3999) acc@1 0.4219 (0.4809) acc@5 0.7656 (0.8016)\n",
      "\u001b[32m[2020-07-01 05:58:03] __main__ INFO: \u001b[0mEpoch 65 Step 300/703 lr 0.100000 loss 1.3842 (1.4138) acc@1 0.5312 (0.4756) acc@5 0.8281 (0.8005)\n",
      "\u001b[32m[2020-07-01 05:58:35] __main__ INFO: \u001b[0mEpoch 65 Step 400/703 lr 0.100000 loss 1.2795 (1.4100) acc@1 0.5625 (0.4780) acc@5 0.8125 (0.8024)\n",
      "\u001b[32m[2020-07-01 05:59:07] __main__ INFO: \u001b[0mEpoch 65 Step 500/703 lr 0.100000 loss 1.5028 (1.4124) acc@1 0.4062 (0.4753) acc@5 0.7656 (0.8012)\n",
      "\u001b[32m[2020-07-01 05:59:39] __main__ INFO: \u001b[0mEpoch 65 Step 600/703 lr 0.100000 loss 1.4567 (1.4162) acc@1 0.4219 (0.4733) acc@5 0.8125 (0.8007)\n",
      "\u001b[32m[2020-07-01 06:00:11] __main__ INFO: \u001b[0mEpoch 65 Step 700/703 lr 0.100000 loss 1.4433 (1.4165) acc@1 0.4375 (0.4732) acc@5 0.7812 (0.8006)\n",
      "\u001b[32m[2020-07-01 06:00:12] __main__ INFO: \u001b[0mEpoch 65 Step 703/703 lr 0.100000 loss 1.4989 (1.4172) acc@1 0.4688 (0.4729) acc@5 0.7969 (0.8003)\n",
      "\u001b[32m[2020-07-01 06:00:12] __main__ INFO: \u001b[0mElapsed 224.04\n",
      "\u001b[32m[2020-07-01 06:00:12] __main__ INFO: \u001b[0mVal 65\n",
      "\u001b[32m[2020-07-01 06:00:20] __main__ INFO: \u001b[0mEpoch 65 loss 0.6564 acc@1 0.7938 acc@5 0.9886\n",
      "\u001b[32m[2020-07-01 06:00:20] __main__ INFO: \u001b[0mElapsed 7.81\n",
      "\u001b[32m[2020-07-01 06:00:20] __main__ INFO: \u001b[0mTrain 66 45695\n",
      "\u001b[32m[2020-07-01 06:00:52] __main__ INFO: \u001b[0mEpoch 66 Step 100/703 lr 0.100000 loss 1.1812 (1.3872) acc@1 0.5156 (0.4802) acc@5 0.8750 (0.8067)\n",
      "\u001b[32m[2020-07-01 06:04:03] __main__ INFO: \u001b[0mEpoch 66 Step 700/703 lr 0.100000 loss 1.5097 (1.4119) acc@1 0.4375 (0.4709) acc@5 0.7656 (0.8000)\n",
      "\u001b[32m[2020-07-01 06:04:04] __main__ INFO: \u001b[0mEpoch 66 Step 703/703 lr 0.100000 loss 1.4766 (1.4120) acc@1 0.4688 (0.4711) acc@5 0.7969 (0.8000)\n",
      "\u001b[32m[2020-07-01 06:04:04] __main__ INFO: \u001b[0mElapsed 224.24\n",
      "\u001b[32m[2020-07-01 06:04:04] __main__ INFO: \u001b[0mVal 66\n",
      "\u001b[32m[2020-07-01 06:04:12] __main__ INFO: \u001b[0mEpoch 66 loss 0.5871 acc@1 0.8028 acc@5 0.9878\n",
      "\u001b[32m[2020-07-01 06:04:12] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-01 06:04:12] __main__ INFO: \u001b[0mTrain 67 46398\n",
      "\u001b[32m[2020-07-01 06:04:44] __main__ INFO: \u001b[0mEpoch 67 Step 100/703 lr 0.100000 loss 1.4385 (1.3696) acc@1 0.4688 (0.4917) acc@5 0.7812 (0.8033)\n",
      "\u001b[32m[2020-07-01 06:05:16] __main__ INFO: \u001b[0mEpoch 67 Step 200/703 lr 0.100000 loss 1.4851 (1.3953) acc@1 0.4688 (0.4823) acc@5 0.8125 (0.8000)\n",
      "\u001b[32m[2020-07-01 06:05:47] __main__ INFO: \u001b[0mEpoch 67 Step 300/703 lr 0.100000 loss 1.2808 (1.3946) acc@1 0.4844 (0.4810) acc@5 0.8594 (0.7995)\n",
      "\u001b[32m[2020-07-01 06:06:19] __main__ INFO: \u001b[0mEpoch 67 Step 400/703 lr 0.100000 loss 1.5261 (1.3961) acc@1 0.4062 (0.4804) acc@5 0.7500 (0.7998)\n",
      "\u001b[32m[2020-07-01 06:06:51] __main__ INFO: \u001b[0mEpoch 67 Step 500/703 lr 0.100000 loss 1.2450 (1.4034) acc@1 0.5156 (0.4777) acc@5 0.8438 (0.7996)\n",
      "\u001b[32m[2020-07-01 06:07:23] __main__ INFO: \u001b[0mEpoch 67 Step 600/703 lr 0.100000 loss 1.2694 (1.4086) acc@1 0.5625 (0.4740) acc@5 0.8281 (0.7980)\n",
      "\u001b[32m[2020-07-01 06:07:55] __main__ INFO: \u001b[0mEpoch 67 Step 700/703 lr 0.100000 loss 1.4801 (1.4107) acc@1 0.4375 (0.4736) acc@5 0.7500 (0.7988)\n",
      "\u001b[32m[2020-07-01 06:07:56] __main__ INFO: \u001b[0mEpoch 67 Step 703/703 lr 0.100000 loss 1.1303 (1.4107) acc@1 0.6094 (0.4738) acc@5 0.8906 (0.7989)\n",
      "\u001b[32m[2020-07-01 06:07:56] __main__ INFO: \u001b[0mElapsed 224.31\n",
      "\u001b[32m[2020-07-01 06:07:56] __main__ INFO: \u001b[0mVal 67\n",
      "\u001b[32m[2020-07-01 06:08:04] __main__ INFO: \u001b[0mEpoch 67 loss 0.6310 acc@1 0.7938 acc@5 0.9884\n",
      "\u001b[32m[2020-07-01 06:08:04] __main__ INFO: \u001b[0mElapsed 7.79\n",
      "\u001b[32m[2020-07-01 06:08:04] __main__ INFO: \u001b[0mTrain 68 47101\n",
      "\u001b[32m[2020-07-01 06:08:36] __main__ INFO: \u001b[0mEpoch 68 Step 100/703 lr 0.100000 loss 1.5814 (1.3707) acc@1 0.3594 (0.4905) acc@5 0.7656 (0.8011)\n",
      "\u001b[32m[2020-07-01 06:09:08] __main__ INFO: \u001b[0mEpoch 68 Step 200/703 lr 0.100000 loss 1.3201 (1.3865) acc@1 0.4844 (0.4850) acc@5 0.7812 (0.7956)\n",
      "\u001b[32m[2020-07-01 06:09:39] __main__ INFO: \u001b[0mEpoch 68 Step 300/703 lr 0.100000 loss 1.4242 (1.3886) acc@1 0.5000 (0.4833) acc@5 0.7812 (0.7951)\n",
      "\u001b[32m[2020-07-01 06:10:11] __main__ INFO: \u001b[0mEpoch 68 Step 400/703 lr 0.100000 loss 1.5206 (1.3922) acc@1 0.4375 (0.4829) acc@5 0.6875 (0.7973)\n",
      "\u001b[32m[2020-07-01 06:10:43] __main__ INFO: \u001b[0mEpoch 68 Step 500/703 lr 0.100000 loss 1.4360 (1.4007) acc@1 0.4531 (0.4805) acc@5 0.7969 (0.7966)\n",
      "\u001b[32m[2020-07-01 06:11:15] __main__ INFO: \u001b[0mEpoch 68 Step 600/703 lr 0.100000 loss 1.2967 (1.4048) acc@1 0.5469 (0.4788) acc@5 0.7812 (0.7958)\n",
      "\u001b[32m[2020-07-01 06:11:47] __main__ INFO: \u001b[0mEpoch 68 Step 700/703 lr 0.100000 loss 1.6031 (1.4092) acc@1 0.4219 (0.4764) acc@5 0.6875 (0.7950)\n",
      "\u001b[32m[2020-07-01 06:11:48] __main__ INFO: \u001b[0mEpoch 68 Step 703/703 lr 0.100000 loss 1.3496 (1.4089) acc@1 0.4844 (0.4764) acc@5 0.8281 (0.7952)\n",
      "\u001b[32m[2020-07-01 06:11:48] __main__ INFO: \u001b[0mElapsed 224.20\n",
      "\u001b[32m[2020-07-01 06:11:48] __main__ INFO: \u001b[0mVal 68\n",
      "\u001b[32m[2020-07-01 06:11:56] __main__ INFO: \u001b[0mEpoch 68 loss 0.6146 acc@1 0.8008 acc@5 0.9898\n",
      "\u001b[32m[2020-07-01 06:11:56] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-01 06:11:56] __main__ INFO: \u001b[0mTrain 69 47804\n",
      "\u001b[32m[2020-07-01 06:12:28] __main__ INFO: \u001b[0mEpoch 69 Step 100/703 lr 0.100000 loss 1.2997 (1.3572) acc@1 0.4844 (0.4888) acc@5 0.8125 (0.7997)\n",
      "\u001b[32m[2020-07-01 06:13:00] __main__ INFO: \u001b[0mEpoch 69 Step 200/703 lr 0.100000 loss 1.2568 (1.3778) acc@1 0.5000 (0.4840) acc@5 0.7969 (0.8047)\n",
      "\u001b[32m[2020-07-01 06:13:31] __main__ INFO: \u001b[0mEpoch 69 Step 300/703 lr 0.100000 loss 1.4127 (1.3929) acc@1 0.4531 (0.4789) acc@5 0.7344 (0.8016)\n",
      "\u001b[32m[2020-07-01 06:14:03] __main__ INFO: \u001b[0mEpoch 69 Step 400/703 lr 0.100000 loss 1.4734 (1.3952) acc@1 0.4531 (0.4787) acc@5 0.7812 (0.8026)\n",
      "\u001b[32m[2020-07-01 06:14:35] __main__ INFO: \u001b[0mEpoch 69 Step 500/703 lr 0.100000 loss 1.7027 (1.3981) acc@1 0.3750 (0.4779) acc@5 0.7031 (0.8017)\n",
      "\u001b[32m[2020-07-01 06:15:07] __main__ INFO: \u001b[0mEpoch 69 Step 600/703 lr 0.100000 loss 1.4944 (1.4036) acc@1 0.3750 (0.4760) acc@5 0.7969 (0.8010)\n",
      "\u001b[32m[2020-07-01 06:15:39] __main__ INFO: \u001b[0mEpoch 69 Step 700/703 lr 0.100000 loss 1.5015 (1.4039) acc@1 0.4531 (0.4758) acc@5 0.7812 (0.8010)\n",
      "\u001b[32m[2020-07-01 06:15:40] __main__ INFO: \u001b[0mEpoch 69 Step 703/703 lr 0.100000 loss 1.3333 (1.4035) acc@1 0.5312 (0.4761) acc@5 0.8125 (0.8011)\n",
      "\u001b[32m[2020-07-01 06:15:40] __main__ INFO: \u001b[0mElapsed 224.15\n",
      "\u001b[32m[2020-07-01 06:15:40] __main__ INFO: \u001b[0mVal 69\n",
      "\u001b[32m[2020-07-01 06:15:48] __main__ INFO: \u001b[0mEpoch 69 loss 0.6131 acc@1 0.8058 acc@5 0.9878\n",
      "\u001b[32m[2020-07-01 06:15:48] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-01 06:15:48] __main__ INFO: \u001b[0mTrain 70 48507\n",
      "\u001b[32m[2020-07-01 06:16:20] __main__ INFO: \u001b[0mEpoch 70 Step 100/703 lr 0.100000 loss 1.4346 (1.3631) acc@1 0.4844 (0.4934) acc@5 0.7031 (0.8041)\n",
      "\u001b[32m[2020-07-01 06:16:51] __main__ INFO: \u001b[0mEpoch 70 Step 200/703 lr 0.100000 loss 1.5641 (1.3833) acc@1 0.3281 (0.4843) acc@5 0.7969 (0.8003)\n",
      "\u001b[32m[2020-07-01 06:17:23] __main__ INFO: \u001b[0mEpoch 70 Step 300/703 lr 0.100000 loss 1.5162 (1.3950) acc@1 0.4219 (0.4812) acc@5 0.7500 (0.7998)\n",
      "\u001b[32m[2020-07-01 06:17:55] __main__ INFO: \u001b[0mEpoch 70 Step 400/703 lr 0.100000 loss 1.2703 (1.3957) acc@1 0.5312 (0.4794) acc@5 0.8906 (0.8009)\n",
      "\u001b[32m[2020-07-01 06:18:27] __main__ INFO: \u001b[0mEpoch 70 Step 500/703 lr 0.100000 loss 1.5513 (1.4012) acc@1 0.4844 (0.4786) acc@5 0.8438 (0.8003)\n",
      "\u001b[32m[2020-07-01 06:18:59] __main__ INFO: \u001b[0mEpoch 70 Step 600/703 lr 0.100000 loss 1.5909 (1.4023) acc@1 0.4062 (0.4787) acc@5 0.7656 (0.8003)\n",
      "\u001b[32m[2020-07-01 06:19:31] __main__ INFO: \u001b[0mEpoch 70 Step 700/703 lr 0.100000 loss 1.2533 (1.4032) acc@1 0.5156 (0.4778) acc@5 0.8281 (0.8013)\n",
      "\u001b[32m[2020-07-01 06:19:32] __main__ INFO: \u001b[0mEpoch 70 Step 703/703 lr 0.100000 loss 1.4672 (1.4031) acc@1 0.4375 (0.4777) acc@5 0.7656 (0.8013)\n",
      "\u001b[32m[2020-07-01 06:19:32] __main__ INFO: \u001b[0mElapsed 223.86\n",
      "\u001b[32m[2020-07-01 06:19:32] __main__ INFO: \u001b[0mVal 70\n",
      "\u001b[32m[2020-07-01 06:19:39] __main__ INFO: \u001b[0mEpoch 70 loss 0.5581 acc@1 0.8102 acc@5 0.9894\n",
      "\u001b[32m[2020-07-01 06:19:39] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-01 06:19:39] __main__ INFO: \u001b[0mTrain 71 49210\n",
      "\u001b[32m[2020-07-01 06:20:11] __main__ INFO: \u001b[0mEpoch 71 Step 100/703 lr 0.100000 loss 1.3459 (1.3937) acc@1 0.5000 (0.4806) acc@5 0.8125 (0.8006)\n",
      "\u001b[32m[2020-07-01 06:20:43] __main__ INFO: \u001b[0mEpoch 71 Step 200/703 lr 0.100000 loss 1.7449 (1.3883) acc@1 0.3750 (0.4838) acc@5 0.7812 (0.8012)\n",
      "\u001b[32m[2020-07-01 06:21:15] __main__ INFO: \u001b[0mEpoch 71 Step 300/703 lr 0.100000 loss 1.3478 (1.3831) acc@1 0.4375 (0.4844) acc@5 0.7812 (0.8031)\n",
      "\u001b[32m[2020-07-01 06:21:47] __main__ INFO: \u001b[0mEpoch 71 Step 400/703 lr 0.100000 loss 1.5300 (1.3908) acc@1 0.3750 (0.4795) acc@5 0.7969 (0.8010)\n",
      "\u001b[32m[2020-07-01 06:22:19] __main__ INFO: \u001b[0mEpoch 71 Step 500/703 lr 0.100000 loss 1.4139 (1.3967) acc@1 0.4531 (0.4765) acc@5 0.7188 (0.7994)\n",
      "\u001b[32m[2020-07-01 06:22:50] __main__ INFO: \u001b[0mEpoch 71 Step 600/703 lr 0.100000 loss 1.4473 (1.3976) acc@1 0.4219 (0.4774) acc@5 0.7031 (0.7997)\n",
      "\u001b[32m[2020-07-01 06:23:22] __main__ INFO: \u001b[0mEpoch 71 Step 700/703 lr 0.100000 loss 1.5010 (1.4048) acc@1 0.4219 (0.4755) acc@5 0.7500 (0.7994)\n",
      "\u001b[32m[2020-07-01 06:23:23] __main__ INFO: \u001b[0mEpoch 71 Step 703/703 lr 0.100000 loss 1.3382 (1.4046) acc@1 0.4531 (0.4754) acc@5 0.7969 (0.7993)\n",
      "\u001b[32m[2020-07-01 06:23:23] __main__ INFO: \u001b[0mElapsed 223.95\n",
      "\u001b[32m[2020-07-01 06:23:23] __main__ INFO: \u001b[0mVal 71\n",
      "\u001b[32m[2020-07-01 06:23:31] __main__ INFO: \u001b[0mEpoch 71 loss 0.6071 acc@1 0.8034 acc@5 0.9904\n",
      "\u001b[32m[2020-07-01 06:23:31] __main__ INFO: \u001b[0mElapsed 7.80\n",
      "\u001b[32m[2020-07-01 06:23:31] __main__ INFO: \u001b[0mTrain 72 49913\n",
      "\u001b[32m[2020-07-01 06:24:03] __main__ INFO: \u001b[0mEpoch 72 Step 100/703 lr 0.100000 loss 1.5613 (1.3607) acc@1 0.4375 (0.4916) acc@5 0.7812 (0.8048)\n",
      "\u001b[32m[2020-07-01 06:24:35] __main__ INFO: \u001b[0mEpoch 72 Step 200/703 lr 0.100000 loss 1.3779 (1.3755) acc@1 0.4844 (0.4868) acc@5 0.7500 (0.8041)\n",
      "\u001b[32m[2020-07-01 06:25:07] __main__ INFO: \u001b[0mEpoch 72 Step 300/703 lr 0.100000 loss 1.3149 (1.3923) acc@1 0.5469 (0.4802) acc@5 0.8594 (0.8014)\n",
      "\u001b[32m[2020-07-01 06:25:39] __main__ INFO: \u001b[0mEpoch 72 Step 400/703 lr 0.100000 loss 1.4207 (1.3968) acc@1 0.4844 (0.4780) acc@5 0.8281 (0.8021)\n",
      "\u001b[32m[2020-07-01 06:26:11] __main__ INFO: \u001b[0mEpoch 72 Step 500/703 lr 0.100000 loss 1.2346 (1.3988) acc@1 0.5156 (0.4774) acc@5 0.8281 (0.8018)\n",
      "\u001b[32m[2020-07-01 06:26:43] __main__ INFO: \u001b[0mEpoch 72 Step 600/703 lr 0.100000 loss 1.4197 (1.4027) acc@1 0.4062 (0.4755) acc@5 0.7812 (0.8001)\n",
      "\u001b[32m[2020-07-01 06:27:14] __main__ INFO: \u001b[0mEpoch 72 Step 700/703 lr 0.100000 loss 1.6077 (1.4025) acc@1 0.4531 (0.4761) acc@5 0.8281 (0.8006)\n",
      "\u001b[32m[2020-07-01 06:27:15] __main__ INFO: \u001b[0mEpoch 72 Step 703/703 lr 0.100000 loss 1.6556 (1.4026) acc@1 0.3906 (0.4763) acc@5 0.7656 (0.8005)\n",
      "\u001b[32m[2020-07-01 06:27:15] __main__ INFO: \u001b[0mElapsed 224.19\n",
      "\u001b[32m[2020-07-01 06:27:15] __main__ INFO: \u001b[0mVal 72\n",
      "\u001b[32m[2020-07-01 06:27:23] __main__ INFO: \u001b[0mEpoch 72 loss 0.5259 acc@1 0.8304 acc@5 0.9916\n",
      "\u001b[32m[2020-07-01 06:27:23] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-01 06:27:23] __main__ INFO: \u001b[0mTrain 73 50616\n",
      "\u001b[32m[2020-07-01 06:27:55] __main__ INFO: \u001b[0mEpoch 73 Step 100/703 lr 0.100000 loss 1.5009 (1.3630) acc@1 0.4375 (0.4947) acc@5 0.7812 (0.8039)\n",
      "\u001b[32m[2020-07-01 06:28:27] __main__ INFO: \u001b[0mEpoch 73 Step 200/703 lr 0.100000 loss 1.1558 (1.3799) acc@1 0.5938 (0.4873) acc@5 0.7656 (0.8013)\n",
      "\u001b[32m[2020-07-01 06:28:59] __main__ INFO: \u001b[0mEpoch 73 Step 300/703 lr 0.100000 loss 1.4698 (1.3854) acc@1 0.4531 (0.4847) acc@5 0.7344 (0.7998)\n",
      "\u001b[32m[2020-07-01 06:29:31] __main__ INFO: \u001b[0mEpoch 73 Step 400/703 lr 0.100000 loss 1.4214 (1.3894) acc@1 0.4531 (0.4841) acc@5 0.7812 (0.7995)\n",
      "\u001b[32m[2020-07-01 06:30:02] __main__ INFO: \u001b[0mEpoch 73 Step 500/703 lr 0.100000 loss 1.4545 (1.3966) acc@1 0.4375 (0.4815) acc@5 0.7812 (0.8006)\n",
      "\u001b[32m[2020-07-01 06:30:34] __main__ INFO: \u001b[0mEpoch 73 Step 600/703 lr 0.100000 loss 1.7327 (1.4014) acc@1 0.3750 (0.4782) acc@5 0.7188 (0.7992)\n",
      "\u001b[32m[2020-07-01 06:31:06] __main__ INFO: \u001b[0mEpoch 73 Step 700/703 lr 0.100000 loss 1.2381 (1.3994) acc@1 0.5625 (0.4792) acc@5 0.8594 (0.8004)\n",
      "\u001b[32m[2020-07-01 06:31:07] __main__ INFO: \u001b[0mEpoch 73 Step 703/703 lr 0.100000 loss 1.4675 (1.3996) acc@1 0.4531 (0.4791) acc@5 0.7812 (0.8003)\n",
      "\u001b[32m[2020-07-01 06:31:07] __main__ INFO: \u001b[0mElapsed 223.90\n",
      "\u001b[32m[2020-07-01 06:31:07] __main__ INFO: \u001b[0mVal 73\n",
      "\u001b[32m[2020-07-01 06:31:15] __main__ INFO: \u001b[0mEpoch 73 loss 0.7392 acc@1 0.7712 acc@5 0.9888\n",
      "\u001b[32m[2020-07-01 06:31:15] __main__ INFO: \u001b[0mElapsed 7.80\n",
      "\u001b[32m[2020-07-01 06:31:15] __main__ INFO: \u001b[0mTrain 74 51319\n",
      "\u001b[32m[2020-07-01 06:31:47] __main__ INFO: \u001b[0mEpoch 74 Step 100/703 lr 0.100000 loss 1.4845 (1.3798) acc@1 0.4688 (0.4852) acc@5 0.8594 (0.7983)\n",
      "\u001b[32m[2020-07-01 06:32:19] __main__ INFO: \u001b[0mEpoch 74 Step 200/703 lr 0.100000 loss 1.3797 (1.3751) acc@1 0.4531 (0.4877) acc@5 0.7812 (0.8048)\n",
      "\u001b[32m[2020-07-01 06:32:50] __main__ INFO: \u001b[0mEpoch 74 Step 300/703 lr 0.100000 loss 1.3172 (1.3725) acc@1 0.5156 (0.4897) acc@5 0.8438 (0.8057)\n",
      "\u001b[32m[2020-07-01 06:33:22] __main__ INFO: \u001b[0mEpoch 74 Step 400/703 lr 0.100000 loss 1.3159 (1.3862) acc@1 0.5156 (0.4838) acc@5 0.8438 (0.8041)\n",
      "\u001b[32m[2020-07-01 06:33:54] __main__ INFO: \u001b[0mEpoch 74 Step 500/703 lr 0.100000 loss 1.4603 (1.3924) acc@1 0.4531 (0.4806) acc@5 0.7344 (0.8019)\n",
      "\u001b[32m[2020-07-01 06:34:26] __main__ INFO: \u001b[0mEpoch 74 Step 600/703 lr 0.100000 loss 1.4183 (1.3974) acc@1 0.4375 (0.4791) acc@5 0.7656 (0.8005)\n",
      "\u001b[32m[2020-07-01 06:34:58] __main__ INFO: \u001b[0mEpoch 74 Step 700/703 lr 0.100000 loss 1.4364 (1.3973) acc@1 0.5000 (0.4791) acc@5 0.7969 (0.7996)\n",
      "\u001b[32m[2020-07-01 06:34:59] __main__ INFO: \u001b[0mEpoch 74 Step 703/703 lr 0.100000 loss 1.3494 (1.3975) acc@1 0.4688 (0.4790) acc@5 0.7344 (0.7995)\n",
      "\u001b[32m[2020-07-01 06:34:59] __main__ INFO: \u001b[0mElapsed 224.10\n",
      "\u001b[32m[2020-07-01 06:34:59] __main__ INFO: \u001b[0mVal 74\n",
      "\u001b[32m[2020-07-01 06:35:07] __main__ INFO: \u001b[0mEpoch 74 loss 0.5945 acc@1 0.8096 acc@5 0.9898\n",
      "\u001b[32m[2020-07-01 06:35:07] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-01 06:35:07] __main__ INFO: \u001b[0mTrain 75 52022\n",
      "\u001b[32m[2020-07-01 06:35:39] __main__ INFO: \u001b[0mEpoch 75 Step 100/703 lr 0.100000 loss 1.2763 (1.3721) acc@1 0.5156 (0.4934) acc@5 0.8125 (0.8058)\n",
      "\u001b[32m[2020-07-01 06:36:10] __main__ INFO: \u001b[0mEpoch 75 Step 200/703 lr 0.100000 loss 1.4098 (1.3798) acc@1 0.4688 (0.4863) acc@5 0.7500 (0.8019)\n",
      "\u001b[32m[2020-07-01 06:36:42] __main__ INFO: \u001b[0mEpoch 75 Step 300/703 lr 0.100000 loss 1.2414 (1.3861) acc@1 0.5312 (0.4838) acc@5 0.7969 (0.7995)\n",
      "\u001b[32m[2020-07-01 06:37:14] __main__ INFO: \u001b[0mEpoch 75 Step 400/703 lr 0.100000 loss 1.2920 (1.3871) acc@1 0.4844 (0.4837) acc@5 0.8281 (0.8004)\n",
      "\u001b[32m[2020-07-01 06:37:46] __main__ INFO: \u001b[0mEpoch 75 Step 500/703 lr 0.100000 loss 1.2985 (1.3935) acc@1 0.5000 (0.4814) acc@5 0.8438 (0.7983)\n",
      "\u001b[32m[2020-07-01 06:38:18] __main__ INFO: \u001b[0mEpoch 75 Step 600/703 lr 0.100000 loss 1.5400 (1.3939) acc@1 0.4062 (0.4820) acc@5 0.7344 (0.7989)\n",
      "\u001b[32m[2020-07-01 06:38:50] __main__ INFO: \u001b[0mEpoch 75 Step 700/703 lr 0.100000 loss 1.4035 (1.3936) acc@1 0.4375 (0.4827) acc@5 0.7031 (0.7993)\n",
      "\u001b[32m[2020-07-01 06:38:51] __main__ INFO: \u001b[0mEpoch 75 Step 703/703 lr 0.100000 loss 1.3468 (1.3939) acc@1 0.4844 (0.4826) acc@5 0.7969 (0.7992)\n",
      "\u001b[32m[2020-07-01 06:38:51] __main__ INFO: \u001b[0mElapsed 223.95\n",
      "\u001b[32m[2020-07-01 06:38:51] __main__ INFO: \u001b[0mVal 75\n",
      "\u001b[32m[2020-07-01 06:38:58] __main__ INFO: \u001b[0mEpoch 75 loss 0.5088 acc@1 0.8308 acc@5 0.9924\n",
      "\u001b[32m[2020-07-01 06:38:58] __main__ INFO: \u001b[0mElapsed 7.79\n",
      "\u001b[32m[2020-07-01 06:38:58] __main__ INFO: \u001b[0mTrain 76 52725\n",
      "\u001b[32m[2020-07-01 06:39:30] __main__ INFO: \u001b[0mEpoch 76 Step 100/703 lr 0.100000 loss 1.1841 (1.3852) acc@1 0.5938 (0.4905) acc@5 0.8125 (0.8019)\n",
      "\u001b[32m[2020-07-01 06:40:02] __main__ INFO: \u001b[0mEpoch 76 Step 200/703 lr 0.100000 loss 1.4223 (1.3751) acc@1 0.4531 (0.4915) acc@5 0.8125 (0.8023)\n",
      "\u001b[32m[2020-07-01 06:40:34] __main__ INFO: \u001b[0mEpoch 76 Step 300/703 lr 0.100000 loss 1.4996 (1.3756) acc@1 0.4375 (0.4926) acc@5 0.7969 (0.8031)\n",
      "\u001b[32m[2020-07-01 06:41:06] __main__ INFO: \u001b[0mEpoch 76 Step 400/703 lr 0.100000 loss 1.5229 (1.3796) acc@1 0.3750 (0.4889) acc@5 0.7656 (0.8008)\n",
      "\u001b[32m[2020-07-01 06:41:38] __main__ INFO: \u001b[0mEpoch 76 Step 500/703 lr 0.100000 loss 1.2733 (1.3831) acc@1 0.5312 (0.4873) acc@5 0.8750 (0.8021)\n",
      "\u001b[32m[2020-07-01 06:42:10] __main__ INFO: \u001b[0mEpoch 76 Step 600/703 lr 0.100000 loss 1.4920 (1.3868) acc@1 0.4375 (0.4846) acc@5 0.8750 (0.8020)\n",
      "\u001b[32m[2020-07-01 06:42:41] __main__ INFO: \u001b[0mEpoch 76 Step 700/703 lr 0.100000 loss 1.4760 (1.3930) acc@1 0.5000 (0.4821) acc@5 0.7656 (0.8013)\n",
      "\u001b[32m[2020-07-01 06:42:42] __main__ INFO: \u001b[0mEpoch 76 Step 703/703 lr 0.100000 loss 1.6232 (1.3933) acc@1 0.3906 (0.4820) acc@5 0.8594 (0.8013)\n",
      "\u001b[32m[2020-07-01 06:42:42] __main__ INFO: \u001b[0mElapsed 223.94\n",
      "\u001b[32m[2020-07-01 06:42:42] __main__ INFO: \u001b[0mVal 76\n",
      "\u001b[32m[2020-07-01 06:42:50] __main__ INFO: \u001b[0mEpoch 76 loss 0.5878 acc@1 0.8034 acc@5 0.9876\n",
      "\u001b[32m[2020-07-01 06:42:50] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-01 06:42:50] __main__ INFO: \u001b[0mTrain 77 53428\n",
      "\u001b[32m[2020-07-01 06:43:22] __main__ INFO: \u001b[0mEpoch 77 Step 100/703 lr 0.100000 loss 1.3129 (1.3586) acc@1 0.5469 (0.4938) acc@5 0.8438 (0.8025)\n",
      "\u001b[32m[2020-07-01 06:43:54] __main__ INFO: \u001b[0mEpoch 77 Step 200/703 lr 0.100000 loss 1.3874 (1.3640) acc@1 0.4844 (0.4913) acc@5 0.7812 (0.8024)\n",
      "\u001b[32m[2020-07-01 06:44:26] __main__ INFO: \u001b[0mEpoch 77 Step 300/703 lr 0.100000 loss 1.2855 (1.3750) acc@1 0.5000 (0.4864) acc@5 0.8125 (0.8028)\n",
      "\u001b[32m[2020-07-01 06:44:58] __main__ INFO: \u001b[0mEpoch 77 Step 400/703 lr 0.100000 loss 1.3292 (1.3824) acc@1 0.5781 (0.4851) acc@5 0.8750 (0.8021)\n",
      "\u001b[32m[2020-07-01 06:45:29] __main__ INFO: \u001b[0mEpoch 77 Step 500/703 lr 0.100000 loss 1.3763 (1.3887) acc@1 0.4688 (0.4826) acc@5 0.7969 (0.8007)\n",
      "\u001b[32m[2020-07-01 06:46:01] __main__ INFO: \u001b[0mEpoch 77 Step 600/703 lr 0.100000 loss 1.2606 (1.3925) acc@1 0.5625 (0.4820) acc@5 0.8125 (0.7999)\n",
      "\u001b[32m[2020-07-01 06:46:33] __main__ INFO: \u001b[0mEpoch 77 Step 700/703 lr 0.100000 loss 1.2505 (1.3929) acc@1 0.5469 (0.4818) acc@5 0.8906 (0.8002)\n",
      "\u001b[32m[2020-07-01 06:46:34] __main__ INFO: \u001b[0mEpoch 77 Step 703/703 lr 0.100000 loss 1.5346 (1.3934) acc@1 0.4219 (0.4816) acc@5 0.8594 (0.8002)\n",
      "\u001b[32m[2020-07-01 06:46:34] __main__ INFO: \u001b[0mElapsed 223.96\n",
      "\u001b[32m[2020-07-01 06:46:34] __main__ INFO: \u001b[0mVal 77\n",
      "\u001b[32m[2020-07-01 06:46:42] __main__ INFO: \u001b[0mEpoch 77 loss 0.5178 acc@1 0.8314 acc@5 0.9896\n",
      "\u001b[32m[2020-07-01 06:46:42] __main__ INFO: \u001b[0mElapsed 7.80\n",
      "\u001b[32m[2020-07-01 06:46:42] __main__ INFO: \u001b[0mTrain 78 54131\n",
      "\u001b[32m[2020-07-01 06:47:14] __main__ INFO: \u001b[0mEpoch 78 Step 100/703 lr 0.100000 loss 1.4183 (1.3591) acc@1 0.5000 (0.4948) acc@5 0.7969 (0.8084)\n",
      "\u001b[32m[2020-07-01 06:47:45] __main__ INFO: \u001b[0mEpoch 78 Step 200/703 lr 0.100000 loss 1.3326 (1.3737) acc@1 0.4844 (0.4891) acc@5 0.7812 (0.8027)\n",
      "\u001b[32m[2020-07-01 06:48:17] __main__ INFO: \u001b[0mEpoch 78 Step 300/703 lr 0.100000 loss 1.4482 (1.3733) acc@1 0.4062 (0.4883) acc@5 0.6875 (0.8017)\n",
      "\u001b[32m[2020-07-01 06:48:49] __main__ INFO: \u001b[0mEpoch 78 Step 400/703 lr 0.100000 loss 1.3838 (1.3759) acc@1 0.5312 (0.4858) acc@5 0.8281 (0.8004)\n",
      "\u001b[32m[2020-07-01 06:49:21] __main__ INFO: \u001b[0mEpoch 78 Step 500/703 lr 0.100000 loss 1.3747 (1.3800) acc@1 0.4688 (0.4847) acc@5 0.8750 (0.8011)\n",
      "\u001b[32m[2020-07-01 06:49:53] __main__ INFO: \u001b[0mEpoch 78 Step 600/703 lr 0.100000 loss 1.2439 (1.3855) acc@1 0.4531 (0.4814) acc@5 0.8906 (0.8004)\n",
      "\u001b[32m[2020-07-01 06:50:25] __main__ INFO: \u001b[0mEpoch 78 Step 700/703 lr 0.100000 loss 1.3347 (1.3895) acc@1 0.4531 (0.4798) acc@5 0.8125 (0.7997)\n",
      "\u001b[32m[2020-07-01 06:50:26] __main__ INFO: \u001b[0mEpoch 78 Step 703/703 lr 0.100000 loss 1.5364 (1.3896) acc@1 0.3906 (0.4797) acc@5 0.7656 (0.7998)\n",
      "\u001b[32m[2020-07-01 06:50:26] __main__ INFO: \u001b[0mElapsed 223.79\n",
      "\u001b[32m[2020-07-01 06:50:26] __main__ INFO: \u001b[0mVal 78\n",
      "\u001b[32m[2020-07-01 06:50:33] __main__ INFO: \u001b[0mEpoch 78 loss 0.7365 acc@1 0.7716 acc@5 0.9898\n",
      "\u001b[32m[2020-07-01 06:50:33] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-01 06:50:33] __main__ INFO: \u001b[0mTrain 79 54834\n"
     ]
    }
   ],
   "source": [
    "# Train the model per the settings specified in the original paper\n",
    "os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "!python train.py --config configs/cifar/densenet.yaml \\\n",
    "    model.densenet.depth 100 \\\n",
    "    model.densenet.growth_rate 12 \\\n",
    "    train.batch_size 64 \\\n",
    "    train.base_lr 0.1 \\\n",
    "    dataset.name CIFAR10_RA_2_20 \\\n",
    "    train.output_dir /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_2_20_c10val/exp00 \\\n",
    "    scheduler.epochs 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-02 03:45:48] __main__ INFO: \u001b[0mdevice: cuda\n",
      "cudnn:\n",
      "  benchmark: True\n",
      "  deterministic: False\n",
      "dataset:\n",
      "  name: CIFAR10\n",
      "  dataset_dir: ~/.torch/datasets/CIFAR10\n",
      "  image_size: 32\n",
      "  n_channels: 3\n",
      "  n_classes: 10\n",
      "model:\n",
      "  type: cifar\n",
      "  name: densenet\n",
      "  init_mode: kaiming_fan_out\n",
      "  vgg:\n",
      "    n_channels: [64, 128, 256, 512, 512]\n",
      "    n_layers: [2, 2, 3, 3, 3]\n",
      "    use_bn: True\n",
      "  resnet:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "  resnet_preact:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "  wrn:\n",
      "    depth: 28\n",
      "    initial_channels: 16\n",
      "    widening_factor: 10\n",
      "    drop_rate: 0.0\n",
      "  densenet:\n",
      "    depth: 100\n",
      "    n_blocks: [6, 12, 24, 16]\n",
      "    block_type: bottleneck\n",
      "    growth_rate: 12\n",
      "    drop_rate: 0.0\n",
      "    compression_rate: 0.5\n",
      "  pyramidnet:\n",
      "    depth: 272\n",
      "    n_blocks: [3, 24, 36, 3]\n",
      "    initial_channels: 16\n",
      "    block_type: bottleneck\n",
      "    alpha: 200\n",
      "  resnext:\n",
      "    depth: 29\n",
      "    n_blocks: [3, 4, 6, 3]\n",
      "    initial_channels: 64\n",
      "    cardinality: 8\n",
      "    base_channels: 4\n",
      "  shake_shake:\n",
      "    depth: 26\n",
      "    initial_channels: 96\n",
      "    shake_forward: True\n",
      "    shake_backward: True\n",
      "    shake_image: True\n",
      "  se_resnet_preact:\n",
      "    depth: 110\n",
      "    initial_channels: 16\n",
      "    se_reduction: 16\n",
      "    block_type: basic\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "train:\n",
      "  checkpoint: /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_2_20_c10val/exp00/checkpoint_00400.pth\n",
      "  resume: False\n",
      "  precision: O0\n",
      "  batch_size: 64\n",
      "  subdivision: 1\n",
      "  optimizer: sgd\n",
      "  base_lr: 0.001\n",
      "  momentum: 0.9\n",
      "  nesterov: True\n",
      "  weight_decay: 0.0001\n",
      "  no_weight_decay_on_bn: False\n",
      "  gradient_clip: 0\n",
      "  start_epoch: 0\n",
      "  seed: 0\n",
      "  val_first: True\n",
      "  val_period: 1\n",
      "  val_ratio: 0.1\n",
      "  use_test_as_val: False\n",
      "  output_dir: /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_2_20_c10val/exp00_resume400_50\n",
      "  log_period: 100\n",
      "  checkpoint_period: 100\n",
      "  use_tensorboard: True\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: True\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "  distributed: False\n",
      "  dist:\n",
      "    backend: nccl\n",
      "    init_method: env://\n",
      "    world_size: -1\n",
      "    node_rank: -1\n",
      "    local_rank: 0\n",
      "    use_sync_bn: False\n",
      "tensorboard:\n",
      "  train_images: False\n",
      "  val_images: False\n",
      "  model_params: False\n",
      "optim:\n",
      "  adam:\n",
      "    betas: (0.9, 0.999)\n",
      "  lars:\n",
      "    eps: 1e-09\n",
      "    threshold: 0.01\n",
      "  adabound:\n",
      "    betas: (0.9, 0.999)\n",
      "    final_lr: 0.1\n",
      "    gamma: 0.001\n",
      "scheduler:\n",
      "  epochs: 50\n",
      "  warmup:\n",
      "    type: none\n",
      "    epochs: 0\n",
      "    start_factor: 0.001\n",
      "    exponent: 4\n",
      "  type: multistep\n",
      "  milestones: [150, 225]\n",
      "  lr_decay: 0.1\n",
      "  lr_min_factor: 0.001\n",
      "  T0: 10\n",
      "  T_mul: 1.0\n",
      "validation:\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: False\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "augmentation:\n",
      "  use_random_crop: True\n",
      "  use_random_horizontal_flip: True\n",
      "  use_cutout: False\n",
      "  use_random_erasing: False\n",
      "  use_dual_cutout: False\n",
      "  use_mixup: False\n",
      "  use_ricap: False\n",
      "  use_cutmix: False\n",
      "  use_label_smoothing: False\n",
      "  random_crop:\n",
      "    padding: 4\n",
      "    fill: 0\n",
      "    padding_mode: constant\n",
      "  random_horizontal_flip:\n",
      "    prob: 0.5\n",
      "  cutout:\n",
      "    prob: 1.0\n",
      "    mask_size: 16\n",
      "    cut_inside: False\n",
      "    mask_color: 0\n",
      "    dual_cutout_alpha: 0.1\n",
      "  random_erasing:\n",
      "    prob: 0.5\n",
      "    area_ratio_range: [0.02, 0.4]\n",
      "    min_aspect_ratio: 0.3\n",
      "    max_attempt: 20\n",
      "  mixup:\n",
      "    alpha: 1.0\n",
      "  ricap:\n",
      "    beta: 0.3\n",
      "  cutmix:\n",
      "    alpha: 1.0\n",
      "  label_smoothing:\n",
      "    epsilon: 0.1\n",
      "tta:\n",
      "  use_resize: False\n",
      "  use_center_crop: False\n",
      "  resize: 256\n",
      "test:\n",
      "  checkpoint: ''\n",
      "  output_dir: ''\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    pin_memory: False\n",
      "\u001b[32m[2020-07-02 03:45:48] __main__ INFO: \u001b[0menv_info:\n",
      "  pytorch_version: 1.4.0\n",
      "  cuda_version: 10.1\n",
      "  cudnn_version: 7603\n",
      "  num_gpus: 1\n",
      "  gpu_name: Tesla K80\n",
      "  gpu_capability: 3.7\n",
      "Files already downloaded and verified\n",
      "\u001b[32m[2020-07-02 03:45:51] __main__ INFO: \u001b[0mMACs  : 296.49M\n",
      "\u001b[32m[2020-07-02 03:45:51] __main__ INFO: \u001b[0m#params: 769.16K\n",
      "Selected optimization level O0:  Pure FP32 training.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n",
      "\u001b[32m[2020-07-02 03:45:51] __main__ INFO: \u001b[0mVal 0\n",
      "\u001b[32m[2020-07-02 03:46:03] __main__ INFO: \u001b[0mEpoch 0 loss 1.0180 acc@1 0.8096 acc@5 0.9856\n",
      "\u001b[32m[2020-07-02 03:46:03] __main__ INFO: \u001b[0mElapsed 11.36\n",
      "\u001b[32m[2020-07-02 03:46:03] __main__ INFO: \u001b[0mTrain 1 0\n",
      "\u001b[32m[2020-07-02 03:46:36] __main__ INFO: \u001b[0mEpoch 1 Step 100/703 lr 0.001000 loss 0.2766 (0.4901) acc@1 0.9219 (0.8642) acc@5 0.9844 (0.9906)\n",
      "\u001b[32m[2020-07-02 03:47:07] __main__ INFO: \u001b[0mEpoch 1 Step 200/703 lr 0.001000 loss 0.2959 (0.4432) acc@1 0.9531 (0.8745) acc@5 1.0000 (0.9933)\n",
      "\u001b[32m[2020-07-02 03:47:39] __main__ INFO: \u001b[0mEpoch 1 Step 300/703 lr 0.001000 loss 0.4190 (0.4129) acc@1 0.8594 (0.8800) acc@5 1.0000 (0.9938)\n",
      "\u001b[32m[2020-07-02 03:48:11] __main__ INFO: \u001b[0mEpoch 1 Step 400/703 lr 0.001000 loss 0.4123 (0.3941) acc@1 0.8594 (0.8852) acc@5 1.0000 (0.9945)\n",
      "\u001b[32m[2020-07-02 03:48:42] __main__ INFO: \u001b[0mEpoch 1 Step 500/703 lr 0.001000 loss 0.0776 (0.3775) acc@1 0.9688 (0.8883) acc@5 1.0000 (0.9948)\n",
      "\u001b[32m[2020-07-02 03:49:14] __main__ INFO: \u001b[0mEpoch 1 Step 600/703 lr 0.001000 loss 0.2709 (0.3678) acc@1 0.8906 (0.8901) acc@5 0.9844 (0.9949)\n",
      "\u001b[32m[2020-07-02 03:49:46] __main__ INFO: \u001b[0mEpoch 1 Step 700/703 lr 0.001000 loss 0.0528 (0.3596) acc@1 0.9844 (0.8918) acc@5 1.0000 (0.9954)\n",
      "\u001b[32m[2020-07-02 03:49:46] __main__ INFO: \u001b[0mEpoch 1 Step 703/703 lr 0.001000 loss 0.3847 (0.3590) acc@1 0.8438 (0.8918) acc@5 1.0000 (0.9954)\n",
      "\u001b[32m[2020-07-02 03:49:46] __main__ INFO: \u001b[0mElapsed 223.89\n",
      "\u001b[32m[2020-07-02 03:49:46] __main__ INFO: \u001b[0mVal 1\n",
      "\u001b[32m[2020-07-02 03:49:54] __main__ INFO: \u001b[0mEpoch 1 loss 0.3812 acc@1 0.8856 acc@5 0.9954\n",
      "\u001b[32m[2020-07-02 03:49:54] __main__ INFO: \u001b[0mElapsed 7.71\n",
      "\u001b[32m[2020-07-02 03:49:54] __main__ INFO: \u001b[0mTrain 2 703\n",
      "\u001b[32m[2020-07-02 03:50:26] __main__ INFO: \u001b[0mEpoch 2 Step 100/703 lr 0.001000 loss 0.3153 (0.2614) acc@1 0.9375 (0.9164) acc@5 1.0000 (0.9969)\n",
      "\u001b[32m[2020-07-02 03:50:58] __main__ INFO: \u001b[0mEpoch 2 Step 200/703 lr 0.001000 loss 0.1687 (0.2590) acc@1 0.9375 (0.9143) acc@5 1.0000 (0.9975)\n",
      "\u001b[32m[2020-07-02 03:51:29] __main__ INFO: \u001b[0mEpoch 2 Step 300/703 lr 0.001000 loss 0.1462 (0.2638) acc@1 0.9531 (0.9131) acc@5 1.0000 (0.9974)\n",
      "\u001b[32m[2020-07-02 03:52:01] __main__ INFO: \u001b[0mEpoch 2 Step 400/703 lr 0.001000 loss 0.3305 (0.2642) acc@1 0.9219 (0.9129) acc@5 0.9844 (0.9975)\n",
      "\u001b[32m[2020-07-02 03:52:32] __main__ INFO: \u001b[0mEpoch 2 Step 500/703 lr 0.001000 loss 0.2816 (0.2664) acc@1 0.9219 (0.9122) acc@5 1.0000 (0.9975)\n",
      "\u001b[32m[2020-07-02 03:53:04] __main__ INFO: \u001b[0mEpoch 2 Step 600/703 lr 0.001000 loss 0.3241 (0.2662) acc@1 0.8750 (0.9123) acc@5 1.0000 (0.9975)\n",
      "\u001b[32m[2020-07-02 03:53:36] __main__ INFO: \u001b[0mEpoch 2 Step 700/703 lr 0.001000 loss 0.2335 (0.2649) acc@1 0.9531 (0.9123) acc@5 1.0000 (0.9974)\n",
      "\u001b[32m[2020-07-02 03:53:37] __main__ INFO: \u001b[0mEpoch 2 Step 703/703 lr 0.001000 loss 0.1169 (0.2646) acc@1 0.9844 (0.9124) acc@5 1.0000 (0.9974)\n",
      "\u001b[32m[2020-07-02 03:53:37] __main__ INFO: \u001b[0mElapsed 222.61\n",
      "\u001b[32m[2020-07-02 03:53:37] __main__ INFO: \u001b[0mVal 2\n",
      "\u001b[32m[2020-07-02 03:53:44] __main__ INFO: \u001b[0mEpoch 2 loss 0.3476 acc@1 0.8940 acc@5 0.9964\n",
      "\u001b[32m[2020-07-02 03:53:44] __main__ INFO: \u001b[0mElapsed 7.66\n",
      "\u001b[32m[2020-07-02 03:53:44] __main__ INFO: \u001b[0mTrain 3 1406\n",
      "\u001b[32m[2020-07-02 03:54:16] __main__ INFO: \u001b[0mEpoch 3 Step 100/703 lr 0.001000 loss 0.2853 (0.2265) acc@1 0.9062 (0.9255) acc@5 1.0000 (0.9980)\n",
      "\u001b[32m[2020-07-02 03:54:48] __main__ INFO: \u001b[0mEpoch 3 Step 200/703 lr 0.001000 loss 0.1204 (0.2301) acc@1 0.9531 (0.9217) acc@5 1.0000 (0.9980)\n",
      "\u001b[32m[2020-07-02 03:55:20] __main__ INFO: \u001b[0mEpoch 3 Step 300/703 lr 0.001000 loss 0.3199 (0.2308) acc@1 0.8438 (0.9211) acc@5 1.0000 (0.9980)\n",
      "\u001b[32m[2020-07-02 03:55:51] __main__ INFO: \u001b[0mEpoch 3 Step 400/703 lr 0.001000 loss 0.1535 (0.2294) acc@1 0.9375 (0.9219) acc@5 1.0000 (0.9980)\n",
      "\u001b[32m[2020-07-02 03:56:23] __main__ INFO: \u001b[0mEpoch 3 Step 500/703 lr 0.001000 loss 0.2146 (0.2299) acc@1 0.8750 (0.9211) acc@5 1.0000 (0.9979)\n",
      "\u001b[32m[2020-07-02 03:56:55] __main__ INFO: \u001b[0mEpoch 3 Step 600/703 lr 0.001000 loss 0.2060 (0.2314) acc@1 0.8906 (0.9213) acc@5 1.0000 (0.9981)\n",
      "\u001b[32m[2020-07-02 03:57:26] __main__ INFO: \u001b[0mEpoch 3 Step 700/703 lr 0.001000 loss 0.2734 (0.2330) acc@1 0.9062 (0.9210) acc@5 1.0000 (0.9982)\n",
      "\u001b[32m[2020-07-02 03:57:27] __main__ INFO: \u001b[0mEpoch 3 Step 703/703 lr 0.001000 loss 0.1529 (0.2329) acc@1 0.9688 (0.9211) acc@5 1.0000 (0.9982)\n",
      "\u001b[32m[2020-07-02 03:57:27] __main__ INFO: \u001b[0mElapsed 222.57\n",
      "\u001b[32m[2020-07-02 03:57:27] __main__ INFO: \u001b[0mVal 3\n",
      "\u001b[32m[2020-07-02 03:57:35] __main__ INFO: \u001b[0mEpoch 3 loss 0.3241 acc@1 0.8988 acc@5 0.9964\n",
      "\u001b[32m[2020-07-02 03:57:35] __main__ INFO: \u001b[0mElapsed 7.66\n",
      "\u001b[32m[2020-07-02 03:57:35] __main__ INFO: \u001b[0mTrain 4 2109\n",
      "\u001b[32m[2020-07-02 03:58:06] __main__ INFO: \u001b[0mEpoch 4 Step 100/703 lr 0.001000 loss 0.2107 (0.2274) acc@1 0.9219 (0.9216) acc@5 0.9844 (0.9983)\n",
      "\u001b[32m[2020-07-02 03:58:38] __main__ INFO: \u001b[0mEpoch 4 Step 200/703 lr 0.001000 loss 0.2476 (0.2162) acc@1 0.9531 (0.9247) acc@5 1.0000 (0.9986)\n",
      "\u001b[32m[2020-07-02 03:59:10] __main__ INFO: \u001b[0mEpoch 4 Step 300/703 lr 0.001000 loss 0.1270 (0.2138) acc@1 0.9531 (0.9257) acc@5 1.0000 (0.9989)\n",
      "\u001b[32m[2020-07-02 03:59:41] __main__ INFO: \u001b[0mEpoch 4 Step 400/703 lr 0.001000 loss 0.2325 (0.2124) acc@1 0.8750 (0.9249) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-07-02 04:00:13] __main__ INFO: \u001b[0mEpoch 4 Step 500/703 lr 0.001000 loss 0.4804 (0.2128) acc@1 0.8750 (0.9254) acc@5 1.0000 (0.9989)\n",
      "\u001b[32m[2020-07-02 04:00:45] __main__ INFO: \u001b[0mEpoch 4 Step 600/703 lr 0.001000 loss 0.2122 (0.2135) acc@1 0.9531 (0.9254) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-07-02 04:01:16] __main__ INFO: \u001b[0mEpoch 4 Step 700/703 lr 0.001000 loss 0.1309 (0.2123) acc@1 0.9844 (0.9262) acc@5 1.0000 (0.9987)\n",
      "\u001b[32m[2020-07-02 04:01:17] __main__ INFO: \u001b[0mEpoch 4 Step 703/703 lr 0.001000 loss 0.1935 (0.2121) acc@1 0.9375 (0.9263) acc@5 1.0000 (0.9987)\n",
      "\u001b[32m[2020-07-02 04:01:17] __main__ INFO: \u001b[0mElapsed 222.43\n",
      "\u001b[32m[2020-07-02 04:01:17] __main__ INFO: \u001b[0mVal 4\n",
      "\u001b[32m[2020-07-02 04:01:25] __main__ INFO: \u001b[0mEpoch 4 loss 0.3200 acc@1 0.9018 acc@5 0.9968\n",
      "\u001b[32m[2020-07-02 04:01:25] __main__ INFO: \u001b[0mElapsed 7.67\n",
      "\u001b[32m[2020-07-02 04:01:25] __main__ INFO: \u001b[0mTrain 5 2812\n",
      "\u001b[32m[2020-07-02 04:01:57] __main__ INFO: \u001b[0mEpoch 5 Step 100/703 lr 0.001000 loss 0.0771 (0.1911) acc@1 0.9688 (0.9336) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-07-02 04:02:28] __main__ INFO: \u001b[0mEpoch 5 Step 200/703 lr 0.001000 loss 0.1600 (0.1946) acc@1 0.9375 (0.9330) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-07-02 04:03:00] __main__ INFO: \u001b[0mEpoch 5 Step 300/703 lr 0.001000 loss 0.1620 (0.1935) acc@1 0.9531 (0.9317) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-07-02 04:03:31] __main__ INFO: \u001b[0mEpoch 5 Step 400/703 lr 0.001000 loss 0.1058 (0.1915) acc@1 0.9688 (0.9330) acc@5 1.0000 (0.9987)\n",
      "\u001b[32m[2020-07-02 04:04:03] __main__ INFO: \u001b[0mEpoch 5 Step 500/703 lr 0.001000 loss 0.2889 (0.1916) acc@1 0.9062 (0.9338) acc@5 0.9844 (0.9988)\n",
      "\u001b[32m[2020-07-02 04:04:35] __main__ INFO: \u001b[0mEpoch 5 Step 600/703 lr 0.001000 loss 0.2557 (0.1930) acc@1 0.9062 (0.9334) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-07-02 04:05:06] __main__ INFO: \u001b[0mEpoch 5 Step 700/703 lr 0.001000 loss 0.1997 (0.1925) acc@1 0.9531 (0.9333) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-07-02 04:05:07] __main__ INFO: \u001b[0mEpoch 5 Step 703/703 lr 0.001000 loss 0.3630 (0.1928) acc@1 0.8906 (0.9332) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-07-02 04:05:07] __main__ INFO: \u001b[0mElapsed 222.49\n",
      "\u001b[32m[2020-07-02 04:05:07] __main__ INFO: \u001b[0mVal 5\n",
      "\u001b[32m[2020-07-02 04:05:15] __main__ INFO: \u001b[0mEpoch 5 loss 0.3092 acc@1 0.9044 acc@5 0.9970\n",
      "\u001b[32m[2020-07-02 04:05:15] __main__ INFO: \u001b[0mElapsed 7.75\n",
      "\u001b[32m[2020-07-02 04:05:15] __main__ INFO: \u001b[0mTrain 6 3515\n",
      "\u001b[32m[2020-07-02 04:05:47] __main__ INFO: \u001b[0mEpoch 6 Step 100/703 lr 0.001000 loss 0.1966 (0.1640) acc@1 0.9219 (0.9423) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-07-02 04:06:18] __main__ INFO: \u001b[0mEpoch 6 Step 200/703 lr 0.001000 loss 0.0952 (0.1700) acc@1 0.9688 (0.9413) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-07-02 04:06:50] __main__ INFO: \u001b[0mEpoch 6 Step 300/703 lr 0.001000 loss 0.1612 (0.1732) acc@1 0.9531 (0.9396) acc@5 1.0000 (0.9988)\n",
      "\u001b[32m[2020-07-02 04:07:22] __main__ INFO: \u001b[0mEpoch 6 Step 400/703 lr 0.001000 loss 0.1619 (0.1739) acc@1 0.9531 (0.9401) acc@5 1.0000 (0.9989)\n",
      "\u001b[32m[2020-07-02 04:07:53] __main__ INFO: \u001b[0mEpoch 6 Step 500/703 lr 0.001000 loss 0.3333 (0.1771) acc@1 0.9062 (0.9388) acc@5 1.0000 (0.9989)\n",
      "\u001b[32m[2020-07-02 04:08:25] __main__ INFO: \u001b[0mEpoch 6 Step 600/703 lr 0.001000 loss 0.2044 (0.1765) acc@1 0.9531 (0.9389) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-07-02 04:08:57] __main__ INFO: \u001b[0mEpoch 6 Step 700/703 lr 0.001000 loss 0.2384 (0.1784) acc@1 0.9375 (0.9383) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-07-02 04:08:58] __main__ INFO: \u001b[0mEpoch 6 Step 703/703 lr 0.001000 loss 0.1121 (0.1786) acc@1 0.9688 (0.9383) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-07-02 04:08:58] __main__ INFO: \u001b[0mElapsed 222.46\n",
      "\u001b[32m[2020-07-02 04:08:58] __main__ INFO: \u001b[0mVal 6\n",
      "\u001b[32m[2020-07-02 04:09:05] __main__ INFO: \u001b[0mEpoch 6 loss 0.3047 acc@1 0.9060 acc@5 0.9970\n",
      "\u001b[32m[2020-07-02 04:09:05] __main__ INFO: \u001b[0mElapsed 7.64\n",
      "\u001b[32m[2020-07-02 04:09:05] __main__ INFO: \u001b[0mTrain 7 4218\n",
      "\u001b[32m[2020-07-02 04:09:37] __main__ INFO: \u001b[0mEpoch 7 Step 100/703 lr 0.001000 loss 0.2020 (0.1625) acc@1 0.9375 (0.9419) acc@5 1.0000 (0.9989)\n",
      "\u001b[32m[2020-07-02 04:10:09] __main__ INFO: \u001b[0mEpoch 7 Step 200/703 lr 0.001000 loss 0.1001 (0.1639) acc@1 0.9844 (0.9426) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-07-02 04:10:40] __main__ INFO: \u001b[0mEpoch 7 Step 300/703 lr 0.001000 loss 0.1438 (0.1645) acc@1 0.9688 (0.9423) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-07-02 04:11:12] __main__ INFO: \u001b[0mEpoch 7 Step 400/703 lr 0.001000 loss 0.1417 (0.1661) acc@1 0.9531 (0.9417) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-07-02 04:11:43] __main__ INFO: \u001b[0mEpoch 7 Step 500/703 lr 0.001000 loss 0.2251 (0.1664) acc@1 0.9219 (0.9421) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-07-02 04:12:15] __main__ INFO: \u001b[0mEpoch 7 Step 600/703 lr 0.001000 loss 0.0795 (0.1677) acc@1 0.9688 (0.9420) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-07-02 04:12:47] __main__ INFO: \u001b[0mEpoch 7 Step 700/703 lr 0.001000 loss 0.2547 (0.1686) acc@1 0.9062 (0.9415) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-07-02 04:12:48] __main__ INFO: \u001b[0mEpoch 7 Step 703/703 lr 0.001000 loss 0.1848 (0.1685) acc@1 0.9219 (0.9415) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-07-02 04:12:48] __main__ INFO: \u001b[0mElapsed 222.60\n",
      "\u001b[32m[2020-07-02 04:12:48] __main__ INFO: \u001b[0mVal 7\n",
      "\u001b[32m[2020-07-02 04:12:55] __main__ INFO: \u001b[0mEpoch 7 loss 0.3085 acc@1 0.9054 acc@5 0.9970\n",
      "\u001b[32m[2020-07-02 04:12:55] __main__ INFO: \u001b[0mElapsed 7.67\n",
      "\u001b[32m[2020-07-02 04:12:55] __main__ INFO: \u001b[0mTrain 8 4921\n",
      "\u001b[32m[2020-07-02 04:13:27] __main__ INFO: \u001b[0mEpoch 8 Step 100/703 lr 0.001000 loss 0.1247 (0.1520) acc@1 0.9375 (0.9455) acc@5 1.0000 (0.9986)\n",
      "\u001b[32m[2020-07-02 04:13:59] __main__ INFO: \u001b[0mEpoch 8 Step 200/703 lr 0.001000 loss 0.1012 (0.1552) acc@1 0.9688 (0.9448) acc@5 1.0000 (0.9989)\n",
      "\u001b[32m[2020-07-02 04:14:30] __main__ INFO: \u001b[0mEpoch 8 Step 300/703 lr 0.001000 loss 0.1424 (0.1538) acc@1 0.9531 (0.9464) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-07-02 04:15:02] __main__ INFO: \u001b[0mEpoch 8 Step 400/703 lr 0.001000 loss 0.2118 (0.1596) acc@1 0.9219 (0.9441) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-07-02 04:15:34] __main__ INFO: \u001b[0mEpoch 8 Step 500/703 lr 0.001000 loss 0.1147 (0.1576) acc@1 0.9531 (0.9447) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-07-02 04:16:05] __main__ INFO: \u001b[0mEpoch 8 Step 600/703 lr 0.001000 loss 0.2207 (0.1584) acc@1 0.8906 (0.9449) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-07-02 04:16:37] __main__ INFO: \u001b[0mEpoch 8 Step 700/703 lr 0.001000 loss 0.2750 (0.1579) acc@1 0.9219 (0.9452) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-07-02 04:16:38] __main__ INFO: \u001b[0mEpoch 8 Step 703/703 lr 0.001000 loss 0.2117 (0.1582) acc@1 0.9219 (0.9451) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-07-02 04:16:38] __main__ INFO: \u001b[0mElapsed 222.56\n",
      "\u001b[32m[2020-07-02 04:16:38] __main__ INFO: \u001b[0mVal 8\n",
      "\u001b[32m[2020-07-02 04:16:46] __main__ INFO: \u001b[0mEpoch 8 loss 0.3040 acc@1 0.9074 acc@5 0.9968\n",
      "\u001b[32m[2020-07-02 04:16:46] __main__ INFO: \u001b[0mElapsed 7.71\n",
      "\u001b[32m[2020-07-02 04:16:46] __main__ INFO: \u001b[0mTrain 9 5624\n",
      "\u001b[32m[2020-07-02 04:17:17] __main__ INFO: \u001b[0mEpoch 9 Step 100/703 lr 0.001000 loss 0.1550 (0.1432) acc@1 0.9062 (0.9505) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-07-02 04:17:49] __main__ INFO: \u001b[0mEpoch 9 Step 200/703 lr 0.001000 loss 0.2443 (0.1426) acc@1 0.8750 (0.9497) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-07-02 04:18:21] __main__ INFO: \u001b[0mEpoch 9 Step 300/703 lr 0.001000 loss 0.1112 (0.1460) acc@1 0.9688 (0.9490) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-07-02 04:18:52] __main__ INFO: \u001b[0mEpoch 9 Step 400/703 lr 0.001000 loss 0.1391 (0.1438) acc@1 0.9531 (0.9500) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-07-02 04:19:24] __main__ INFO: \u001b[0mEpoch 9 Step 500/703 lr 0.001000 loss 0.0568 (0.1455) acc@1 0.9844 (0.9490) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-07-02 04:19:55] __main__ INFO: \u001b[0mEpoch 9 Step 600/703 lr 0.001000 loss 0.1968 (0.1476) acc@1 0.9531 (0.9487) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-07-02 04:20:27] __main__ INFO: \u001b[0mEpoch 9 Step 700/703 lr 0.001000 loss 0.0930 (0.1502) acc@1 0.9531 (0.9481) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-07-02 04:20:28] __main__ INFO: \u001b[0mEpoch 9 Step 703/703 lr 0.001000 loss 0.0458 (0.1500) acc@1 0.9688 (0.9481) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-07-02 04:20:28] __main__ INFO: \u001b[0mElapsed 222.27\n",
      "\u001b[32m[2020-07-02 04:20:28] __main__ INFO: \u001b[0mVal 9\n",
      "\u001b[32m[2020-07-02 04:20:36] __main__ INFO: \u001b[0mEpoch 9 loss 0.3030 acc@1 0.9102 acc@5 0.9962\n",
      "\u001b[32m[2020-07-02 04:20:36] __main__ INFO: \u001b[0mElapsed 7.69\n",
      "\u001b[32m[2020-07-02 04:20:36] __main__ INFO: \u001b[0mTrain 10 6327\n",
      "\u001b[32m[2020-07-02 04:21:07] __main__ INFO: \u001b[0mEpoch 10 Step 100/703 lr 0.001000 loss 0.2566 (0.1368) acc@1 0.9375 (0.9525) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-02 04:21:39] __main__ INFO: \u001b[0mEpoch 10 Step 200/703 lr 0.001000 loss 0.1381 (0.1378) acc@1 0.9531 (0.9506) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-02 04:22:11] __main__ INFO: \u001b[0mEpoch 10 Step 300/703 lr 0.001000 loss 0.1810 (0.1382) acc@1 0.9062 (0.9504) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-02 04:22:43] __main__ INFO: \u001b[0mEpoch 10 Step 400/703 lr 0.001000 loss 0.1047 (0.1394) acc@1 0.9688 (0.9500) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-02 04:23:14] __main__ INFO: \u001b[0mEpoch 10 Step 500/703 lr 0.001000 loss 0.1652 (0.1400) acc@1 0.9219 (0.9499) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-02 04:23:46] __main__ INFO: \u001b[0mEpoch 10 Step 600/703 lr 0.001000 loss 0.2086 (0.1394) acc@1 0.9375 (0.9501) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-02 04:24:18] __main__ INFO: \u001b[0mEpoch 10 Step 700/703 lr 0.001000 loss 0.1519 (0.1399) acc@1 0.9062 (0.9498) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-02 04:24:18] __main__ INFO: \u001b[0mEpoch 10 Step 703/703 lr 0.001000 loss 0.1268 (0.1399) acc@1 0.9531 (0.9499) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-02 04:24:19] __main__ INFO: \u001b[0mElapsed 222.83\n",
      "\u001b[32m[2020-07-02 04:24:19] __main__ INFO: \u001b[0mVal 10\n",
      "\u001b[32m[2020-07-02 04:24:26] __main__ INFO: \u001b[0mEpoch 10 loss 0.3008 acc@1 0.9068 acc@5 0.9970\n",
      "\u001b[32m[2020-07-02 04:24:26] __main__ INFO: \u001b[0mElapsed 7.65\n",
      "\u001b[32m[2020-07-02 04:24:26] __main__ INFO: \u001b[0mTrain 11 7030\n",
      "\u001b[32m[2020-07-02 04:24:58] __main__ INFO: \u001b[0mEpoch 11 Step 100/703 lr 0.001000 loss 0.1678 (0.1367) acc@1 0.9375 (0.9531) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-02 04:25:30] __main__ INFO: \u001b[0mEpoch 11 Step 200/703 lr 0.001000 loss 0.0960 (0.1325) acc@1 0.9531 (0.9538) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-02 04:26:01] __main__ INFO: \u001b[0mEpoch 11 Step 300/703 lr 0.001000 loss 0.1309 (0.1352) acc@1 0.9531 (0.9530) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-02 04:26:33] __main__ INFO: \u001b[0mEpoch 11 Step 400/703 lr 0.001000 loss 0.0881 (0.1327) acc@1 0.9688 (0.9541) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-02 04:27:05] __main__ INFO: \u001b[0mEpoch 11 Step 500/703 lr 0.001000 loss 0.1026 (0.1343) acc@1 0.9688 (0.9543) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-02 04:27:36] __main__ INFO: \u001b[0mEpoch 11 Step 600/703 lr 0.001000 loss 0.1719 (0.1319) acc@1 0.9531 (0.9549) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-02 04:28:08] __main__ INFO: \u001b[0mEpoch 11 Step 700/703 lr 0.001000 loss 0.0578 (0.1334) acc@1 0.9844 (0.9541) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-02 04:28:09] __main__ INFO: \u001b[0mEpoch 11 Step 703/703 lr 0.001000 loss 0.0605 (0.1331) acc@1 1.0000 (0.9543) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-02 04:28:09] __main__ INFO: \u001b[0mElapsed 222.57\n",
      "\u001b[32m[2020-07-02 04:28:09] __main__ INFO: \u001b[0mVal 11\n",
      "\u001b[32m[2020-07-02 04:28:16] __main__ INFO: \u001b[0mEpoch 11 loss 0.3005 acc@1 0.9096 acc@5 0.9966\n",
      "\u001b[32m[2020-07-02 04:28:16] __main__ INFO: \u001b[0mElapsed 7.64\n",
      "\u001b[32m[2020-07-02 04:28:16] __main__ INFO: \u001b[0mTrain 12 7733\n",
      "\u001b[32m[2020-07-02 04:28:48] __main__ INFO: \u001b[0mEpoch 12 Step 100/703 lr 0.001000 loss 0.1686 (0.1334) acc@1 0.9375 (0.9542) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-02 04:29:20] __main__ INFO: \u001b[0mEpoch 12 Step 200/703 lr 0.001000 loss 0.1889 (0.1288) acc@1 0.9219 (0.9556) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-02 04:29:51] __main__ INFO: \u001b[0mEpoch 12 Step 300/703 lr 0.001000 loss 0.1644 (0.1304) acc@1 0.9219 (0.9545) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-02 04:30:23] __main__ INFO: \u001b[0mEpoch 12 Step 400/703 lr 0.001000 loss 0.1408 (0.1277) acc@1 0.9219 (0.9555) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-02 04:30:55] __main__ INFO: \u001b[0mEpoch 12 Step 500/703 lr 0.001000 loss 0.1379 (0.1283) acc@1 0.9531 (0.9551) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-02 04:31:26] __main__ INFO: \u001b[0mEpoch 12 Step 600/703 lr 0.001000 loss 0.0274 (0.1282) acc@1 1.0000 (0.9554) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-02 04:31:58] __main__ INFO: \u001b[0mEpoch 12 Step 700/703 lr 0.001000 loss 0.2059 (0.1281) acc@1 0.9219 (0.9555) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-02 04:31:59] __main__ INFO: \u001b[0mEpoch 12 Step 703/703 lr 0.001000 loss 0.1105 (0.1282) acc@1 0.9531 (0.9554) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-02 04:31:59] __main__ INFO: \u001b[0mElapsed 222.65\n",
      "\u001b[32m[2020-07-02 04:31:59] __main__ INFO: \u001b[0mVal 12\n",
      "\u001b[32m[2020-07-02 04:32:07] __main__ INFO: \u001b[0mEpoch 12 loss 0.2960 acc@1 0.9104 acc@5 0.9966\n",
      "\u001b[32m[2020-07-02 04:32:07] __main__ INFO: \u001b[0mElapsed 7.66\n",
      "\u001b[32m[2020-07-02 04:32:07] __main__ INFO: \u001b[0mTrain 13 8436\n",
      "\u001b[32m[2020-07-02 04:32:38] __main__ INFO: \u001b[0mEpoch 13 Step 100/703 lr 0.001000 loss 0.0792 (0.1146) acc@1 0.9688 (0.9587) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-02 04:33:10] __main__ INFO: \u001b[0mEpoch 13 Step 200/703 lr 0.001000 loss 0.2503 (0.1201) acc@1 0.9688 (0.9572) acc@5 0.9844 (0.9996)\n",
      "\u001b[32m[2020-07-02 04:33:42] __main__ INFO: \u001b[0mEpoch 13 Step 300/703 lr 0.001000 loss 0.1210 (0.1198) acc@1 0.9688 (0.9575) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-02 04:34:13] __main__ INFO: \u001b[0mEpoch 13 Step 400/703 lr 0.001000 loss 0.1446 (0.1174) acc@1 0.9375 (0.9582) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-02 04:34:45] __main__ INFO: \u001b[0mEpoch 13 Step 500/703 lr 0.001000 loss 0.0530 (0.1200) acc@1 1.0000 (0.9582) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-07-02 04:35:17] __main__ INFO: \u001b[0mEpoch 13 Step 600/703 lr 0.001000 loss 0.0439 (0.1198) acc@1 1.0000 (0.9583) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-02 04:35:48] __main__ INFO: \u001b[0mEpoch 13 Step 700/703 lr 0.001000 loss 0.2113 (0.1202) acc@1 0.9531 (0.9586) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-02 04:35:49] __main__ INFO: \u001b[0mEpoch 13 Step 703/703 lr 0.001000 loss 0.1831 (0.1203) acc@1 0.9375 (0.9585) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-02 04:35:49] __main__ INFO: \u001b[0mElapsed 222.68\n",
      "\u001b[32m[2020-07-02 04:35:49] __main__ INFO: \u001b[0mVal 13\n",
      "\u001b[32m[2020-07-02 04:35:57] __main__ INFO: \u001b[0mEpoch 13 loss 0.2990 acc@1 0.9120 acc@5 0.9970\n",
      "\u001b[32m[2020-07-02 04:35:57] __main__ INFO: \u001b[0mElapsed 7.70\n",
      "\u001b[32m[2020-07-02 04:35:57] __main__ INFO: \u001b[0mTrain 14 9139\n",
      "\u001b[32m[2020-07-02 04:36:29] __main__ INFO: \u001b[0mEpoch 14 Step 100/703 lr 0.001000 loss 0.1736 (0.1088) acc@1 0.9688 (0.9647) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-02 04:37:00] __main__ INFO: \u001b[0mEpoch 14 Step 200/703 lr 0.001000 loss 0.0826 (0.1085) acc@1 0.9688 (0.9635) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-02 04:37:32] __main__ INFO: \u001b[0mEpoch 14 Step 300/703 lr 0.001000 loss 0.0925 (0.1112) acc@1 0.9688 (0.9622) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-02 04:38:04] __main__ INFO: \u001b[0mEpoch 14 Step 400/703 lr 0.001000 loss 0.1222 (0.1095) acc@1 0.9531 (0.9630) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-02 04:38:35] __main__ INFO: \u001b[0mEpoch 14 Step 500/703 lr 0.001000 loss 0.0350 (0.1096) acc@1 1.0000 (0.9634) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-02 04:39:07] __main__ INFO: \u001b[0mEpoch 14 Step 600/703 lr 0.001000 loss 0.0215 (0.1119) acc@1 1.0000 (0.9627) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-02 04:39:39] __main__ INFO: \u001b[0mEpoch 14 Step 700/703 lr 0.001000 loss 0.1047 (0.1118) acc@1 0.9688 (0.9627) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-02 04:39:40] __main__ INFO: \u001b[0mEpoch 14 Step 703/703 lr 0.001000 loss 0.1128 (0.1121) acc@1 0.9531 (0.9627) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-02 04:39:40] __main__ INFO: \u001b[0mElapsed 222.61\n",
      "\u001b[32m[2020-07-02 04:39:40] __main__ INFO: \u001b[0mVal 14\n",
      "\u001b[32m[2020-07-02 04:39:47] __main__ INFO: \u001b[0mEpoch 14 loss 0.3013 acc@1 0.9114 acc@5 0.9974\n",
      "\u001b[32m[2020-07-02 04:39:47] __main__ INFO: \u001b[0mElapsed 7.70\n",
      "\u001b[32m[2020-07-02 04:39:47] __main__ INFO: \u001b[0mTrain 15 9842\n",
      "\u001b[32m[2020-07-02 04:40:19] __main__ INFO: \u001b[0mEpoch 15 Step 100/703 lr 0.001000 loss 0.0674 (0.1002) acc@1 0.9688 (0.9653) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-02 04:40:51] __main__ INFO: \u001b[0mEpoch 15 Step 200/703 lr 0.001000 loss 0.1979 (0.1091) acc@1 0.9375 (0.9627) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-02 04:41:22] __main__ INFO: \u001b[0mEpoch 15 Step 300/703 lr 0.001000 loss 0.1169 (0.1071) acc@1 0.9375 (0.9632) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-02 04:41:54] __main__ INFO: \u001b[0mEpoch 15 Step 400/703 lr 0.001000 loss 0.0424 (0.1094) acc@1 1.0000 (0.9624) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-02 04:42:26] __main__ INFO: \u001b[0mEpoch 15 Step 500/703 lr 0.001000 loss 0.1557 (0.1099) acc@1 0.9531 (0.9626) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-02 04:42:58] __main__ INFO: \u001b[0mEpoch 15 Step 600/703 lr 0.001000 loss 0.1682 (0.1101) acc@1 0.9375 (0.9626) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-02 04:43:29] __main__ INFO: \u001b[0mEpoch 15 Step 700/703 lr 0.001000 loss 0.0822 (0.1096) acc@1 0.9844 (0.9628) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-02 04:43:30] __main__ INFO: \u001b[0mEpoch 15 Step 703/703 lr 0.001000 loss 0.0657 (0.1096) acc@1 0.9844 (0.9628) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-02 04:43:30] __main__ INFO: \u001b[0mElapsed 222.68\n",
      "\u001b[32m[2020-07-02 04:43:30] __main__ INFO: \u001b[0mVal 15\n",
      "\u001b[32m[2020-07-02 04:43:38] __main__ INFO: \u001b[0mEpoch 15 loss 0.3023 acc@1 0.9126 acc@5 0.9968\n",
      "\u001b[32m[2020-07-02 04:43:38] __main__ INFO: \u001b[0mElapsed 7.70\n",
      "\u001b[32m[2020-07-02 04:43:38] __main__ INFO: \u001b[0mTrain 16 10545\n",
      "\u001b[32m[2020-07-02 04:44:10] __main__ INFO: \u001b[0mEpoch 16 Step 100/703 lr 0.001000 loss 0.0566 (0.0966) acc@1 0.9844 (0.9656) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-02 04:44:41] __main__ INFO: \u001b[0mEpoch 16 Step 200/703 lr 0.001000 loss 0.1454 (0.0993) acc@1 0.9219 (0.9647) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-02 04:45:13] __main__ INFO: \u001b[0mEpoch 16 Step 300/703 lr 0.001000 loss 0.0890 (0.1004) acc@1 0.9844 (0.9647) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-02 04:45:45] __main__ INFO: \u001b[0mEpoch 16 Step 400/703 lr 0.001000 loss 0.0862 (0.1007) acc@1 0.9688 (0.9650) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-02 04:46:16] __main__ INFO: \u001b[0mEpoch 16 Step 500/703 lr 0.001000 loss 0.0331 (0.1042) acc@1 1.0000 (0.9641) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-02 04:46:48] __main__ INFO: \u001b[0mEpoch 16 Step 600/703 lr 0.001000 loss 0.0885 (0.1048) acc@1 0.9844 (0.9640) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-02 04:47:20] __main__ INFO: \u001b[0mEpoch 16 Step 700/703 lr 0.001000 loss 0.1126 (0.1040) acc@1 0.9688 (0.9639) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-02 04:47:20] __main__ INFO: \u001b[0mEpoch 16 Step 703/703 lr 0.001000 loss 0.1537 (0.1040) acc@1 0.9375 (0.9639) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-02 04:47:20] __main__ INFO: \u001b[0mElapsed 222.71\n",
      "\u001b[32m[2020-07-02 04:47:20] __main__ INFO: \u001b[0mVal 16\n",
      "\u001b[32m[2020-07-02 04:47:28] __main__ INFO: \u001b[0mEpoch 16 loss 0.3044 acc@1 0.9104 acc@5 0.9968\n",
      "\u001b[32m[2020-07-02 04:47:28] __main__ INFO: \u001b[0mElapsed 7.66\n",
      "\u001b[32m[2020-07-02 04:47:28] __main__ INFO: \u001b[0mTrain 17 11248\n",
      "\u001b[32m[2020-07-02 04:48:00] __main__ INFO: \u001b[0mEpoch 17 Step 100/703 lr 0.001000 loss 0.1412 (0.0917) acc@1 0.9219 (0.9680) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 04:48:32] __main__ INFO: \u001b[0mEpoch 17 Step 200/703 lr 0.001000 loss 0.1160 (0.0960) acc@1 0.9375 (0.9686) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-02 04:49:03] __main__ INFO: \u001b[0mEpoch 17 Step 300/703 lr 0.001000 loss 0.1164 (0.0967) acc@1 0.9688 (0.9681) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-02 04:49:35] __main__ INFO: \u001b[0mEpoch 17 Step 400/703 lr 0.001000 loss 0.0985 (0.0973) acc@1 0.9688 (0.9672) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-02 04:50:06] __main__ INFO: \u001b[0mEpoch 17 Step 500/703 lr 0.001000 loss 0.1572 (0.0972) acc@1 0.9531 (0.9667) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-02 04:50:38] __main__ INFO: \u001b[0mEpoch 17 Step 600/703 lr 0.001000 loss 0.0422 (0.0965) acc@1 1.0000 (0.9672) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-02 04:51:10] __main__ INFO: \u001b[0mEpoch 17 Step 700/703 lr 0.001000 loss 0.1212 (0.0973) acc@1 0.9688 (0.9671) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-02 04:51:11] __main__ INFO: \u001b[0mEpoch 17 Step 703/703 lr 0.001000 loss 0.0964 (0.0973) acc@1 0.9688 (0.9671) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-02 04:51:11] __main__ INFO: \u001b[0mElapsed 222.58\n",
      "\u001b[32m[2020-07-02 04:51:11] __main__ INFO: \u001b[0mVal 17\n",
      "\u001b[32m[2020-07-02 04:51:18] __main__ INFO: \u001b[0mEpoch 17 loss 0.3014 acc@1 0.9144 acc@5 0.9970\n",
      "\u001b[32m[2020-07-02 04:51:18] __main__ INFO: \u001b[0mElapsed 7.65\n",
      "\u001b[32m[2020-07-02 04:51:18] __main__ INFO: \u001b[0mTrain 18 11951\n",
      "\u001b[32m[2020-07-02 04:51:50] __main__ INFO: \u001b[0mEpoch 18 Step 100/703 lr 0.001000 loss 0.0968 (0.0877) acc@1 0.9531 (0.9697) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-02 04:52:22] __main__ INFO: \u001b[0mEpoch 18 Step 200/703 lr 0.001000 loss 0.0701 (0.0921) acc@1 0.9688 (0.9685) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-02 04:52:53] __main__ INFO: \u001b[0mEpoch 18 Step 300/703 lr 0.001000 loss 0.1228 (0.0923) acc@1 0.9688 (0.9690) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-02 04:53:25] __main__ INFO: \u001b[0mEpoch 18 Step 400/703 lr 0.001000 loss 0.0650 (0.0937) acc@1 0.9844 (0.9684) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-02 04:53:57] __main__ INFO: \u001b[0mEpoch 18 Step 500/703 lr 0.001000 loss 0.0895 (0.0944) acc@1 0.9688 (0.9678) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-02 04:54:28] __main__ INFO: \u001b[0mEpoch 18 Step 600/703 lr 0.001000 loss 0.1407 (0.0946) acc@1 0.9688 (0.9678) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-02 04:55:00] __main__ INFO: \u001b[0mEpoch 18 Step 700/703 lr 0.001000 loss 0.1138 (0.0930) acc@1 0.9531 (0.9684) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-02 04:55:01] __main__ INFO: \u001b[0mEpoch 18 Step 703/703 lr 0.001000 loss 0.1736 (0.0930) acc@1 0.9219 (0.9684) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-02 04:55:01] __main__ INFO: \u001b[0mElapsed 222.39\n",
      "\u001b[32m[2020-07-02 04:55:01] __main__ INFO: \u001b[0mVal 18\n",
      "\u001b[32m[2020-07-02 04:55:08] __main__ INFO: \u001b[0mEpoch 18 loss 0.3026 acc@1 0.9114 acc@5 0.9972\n",
      "\u001b[32m[2020-07-02 04:55:08] __main__ INFO: \u001b[0mElapsed 7.67\n",
      "\u001b[32m[2020-07-02 04:55:08] __main__ INFO: \u001b[0mTrain 19 12654\n",
      "\u001b[32m[2020-07-02 04:55:40] __main__ INFO: \u001b[0mEpoch 19 Step 100/703 lr 0.001000 loss 0.1181 (0.0936) acc@1 0.9688 (0.9681) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-02 04:56:12] __main__ INFO: \u001b[0mEpoch 19 Step 200/703 lr 0.001000 loss 0.1154 (0.0904) acc@1 0.9688 (0.9700) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-02 04:56:44] __main__ INFO: \u001b[0mEpoch 19 Step 300/703 lr 0.001000 loss 0.0978 (0.0890) acc@1 0.9844 (0.9706) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-02 04:57:15] __main__ INFO: \u001b[0mEpoch 19 Step 400/703 lr 0.001000 loss 0.0463 (0.0905) acc@1 1.0000 (0.9700) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-02 04:57:47] __main__ INFO: \u001b[0mEpoch 19 Step 500/703 lr 0.001000 loss 0.0385 (0.0910) acc@1 1.0000 (0.9699) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-02 04:58:18] __main__ INFO: \u001b[0mEpoch 19 Step 600/703 lr 0.001000 loss 0.0480 (0.0910) acc@1 0.9844 (0.9697) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-02 04:58:50] __main__ INFO: \u001b[0mEpoch 19 Step 700/703 lr 0.001000 loss 0.0860 (0.0901) acc@1 0.9531 (0.9697) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-02 04:58:51] __main__ INFO: \u001b[0mEpoch 19 Step 703/703 lr 0.001000 loss 0.0250 (0.0899) acc@1 1.0000 (0.9698) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-02 04:58:51] __main__ INFO: \u001b[0mElapsed 222.52\n",
      "\u001b[32m[2020-07-02 04:58:51] __main__ INFO: \u001b[0mVal 19\n",
      "\u001b[32m[2020-07-02 04:58:59] __main__ INFO: \u001b[0mEpoch 19 loss 0.3029 acc@1 0.9114 acc@5 0.9970\n",
      "\u001b[32m[2020-07-02 04:58:59] __main__ INFO: \u001b[0mElapsed 7.69\n",
      "\u001b[32m[2020-07-02 04:58:59] __main__ INFO: \u001b[0mTrain 20 13357\n",
      "\u001b[32m[2020-07-02 04:59:30] __main__ INFO: \u001b[0mEpoch 20 Step 100/703 lr 0.001000 loss 0.1176 (0.0869) acc@1 0.9531 (0.9712) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-07-02 05:00:02] __main__ INFO: \u001b[0mEpoch 20 Step 200/703 lr 0.001000 loss 0.0616 (0.0836) acc@1 0.9688 (0.9722) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-02 05:00:34] __main__ INFO: \u001b[0mEpoch 20 Step 300/703 lr 0.001000 loss 0.0297 (0.0844) acc@1 1.0000 (0.9715) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-02 05:01:05] __main__ INFO: \u001b[0mEpoch 20 Step 400/703 lr 0.001000 loss 0.0624 (0.0852) acc@1 0.9844 (0.9716) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-02 05:01:37] __main__ INFO: \u001b[0mEpoch 20 Step 500/703 lr 0.001000 loss 0.0945 (0.0841) acc@1 0.9688 (0.9721) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-02 05:02:09] __main__ INFO: \u001b[0mEpoch 20 Step 600/703 lr 0.001000 loss 0.2207 (0.0853) acc@1 0.9219 (0.9716) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-02 05:02:40] __main__ INFO: \u001b[0mEpoch 20 Step 700/703 lr 0.001000 loss 0.1558 (0.0862) acc@1 0.9531 (0.9715) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-02 05:02:41] __main__ INFO: \u001b[0mEpoch 20 Step 703/703 lr 0.001000 loss 0.0591 (0.0862) acc@1 0.9844 (0.9715) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-02 05:02:41] __main__ INFO: \u001b[0mElapsed 222.54\n",
      "\u001b[32m[2020-07-02 05:02:41] __main__ INFO: \u001b[0mVal 20\n",
      "\u001b[32m[2020-07-02 05:02:49] __main__ INFO: \u001b[0mEpoch 20 loss 0.3049 acc@1 0.9130 acc@5 0.9970\n",
      "\u001b[32m[2020-07-02 05:02:49] __main__ INFO: \u001b[0mElapsed 7.67\n",
      "\u001b[32m[2020-07-02 05:02:49] __main__ INFO: \u001b[0mTrain 21 14060\n",
      "\u001b[32m[2020-07-02 05:03:21] __main__ INFO: \u001b[0mEpoch 21 Step 100/703 lr 0.001000 loss 0.0394 (0.0854) acc@1 1.0000 (0.9727) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:03:52] __main__ INFO: \u001b[0mEpoch 21 Step 200/703 lr 0.001000 loss 0.1171 (0.0822) acc@1 0.9688 (0.9722) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:04:24] __main__ INFO: \u001b[0mEpoch 21 Step 300/703 lr 0.001000 loss 0.0352 (0.0844) acc@1 1.0000 (0.9708) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:04:56] __main__ INFO: \u001b[0mEpoch 21 Step 400/703 lr 0.001000 loss 0.0508 (0.0841) acc@1 0.9844 (0.9706) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:05:27] __main__ INFO: \u001b[0mEpoch 21 Step 500/703 lr 0.001000 loss 0.0482 (0.0806) acc@1 1.0000 (0.9725) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:05:59] __main__ INFO: \u001b[0mEpoch 21 Step 600/703 lr 0.001000 loss 0.0351 (0.0812) acc@1 0.9844 (0.9726) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:06:31] __main__ INFO: \u001b[0mEpoch 21 Step 700/703 lr 0.001000 loss 0.0776 (0.0809) acc@1 0.9531 (0.9733) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:06:32] __main__ INFO: \u001b[0mEpoch 21 Step 703/703 lr 0.001000 loss 0.0447 (0.0810) acc@1 1.0000 (0.9733) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:06:32] __main__ INFO: \u001b[0mElapsed 222.84\n",
      "\u001b[32m[2020-07-02 05:06:32] __main__ INFO: \u001b[0mVal 21\n",
      "\u001b[32m[2020-07-02 05:06:39] __main__ INFO: \u001b[0mEpoch 21 loss 0.3022 acc@1 0.9140 acc@5 0.9966\n",
      "\u001b[32m[2020-07-02 05:06:39] __main__ INFO: \u001b[0mElapsed 7.70\n",
      "\u001b[32m[2020-07-02 05:06:39] __main__ INFO: \u001b[0mTrain 22 14763\n",
      "\u001b[32m[2020-07-02 05:07:11] __main__ INFO: \u001b[0mEpoch 22 Step 100/703 lr 0.001000 loss 0.1232 (0.0758) acc@1 0.9375 (0.9738) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:07:43] __main__ INFO: \u001b[0mEpoch 22 Step 200/703 lr 0.001000 loss 0.0278 (0.0750) acc@1 1.0000 (0.9754) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-02 05:08:15] __main__ INFO: \u001b[0mEpoch 22 Step 300/703 lr 0.001000 loss 0.0756 (0.0752) acc@1 0.9688 (0.9756) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-02 05:08:46] __main__ INFO: \u001b[0mEpoch 22 Step 400/703 lr 0.001000 loss 0.1075 (0.0761) acc@1 0.9531 (0.9747) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-02 05:09:18] __main__ INFO: \u001b[0mEpoch 22 Step 500/703 lr 0.001000 loss 0.0591 (0.0767) acc@1 0.9844 (0.9742) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-02 05:09:50] __main__ INFO: \u001b[0mEpoch 22 Step 600/703 lr 0.001000 loss 0.0781 (0.0768) acc@1 0.9688 (0.9742) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:10:21] __main__ INFO: \u001b[0mEpoch 22 Step 700/703 lr 0.001000 loss 0.0730 (0.0780) acc@1 0.9844 (0.9738) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-02 05:10:22] __main__ INFO: \u001b[0mEpoch 22 Step 703/703 lr 0.001000 loss 0.0201 (0.0779) acc@1 1.0000 (0.9738) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-02 05:10:22] __main__ INFO: \u001b[0mElapsed 222.74\n",
      "\u001b[32m[2020-07-02 05:10:22] __main__ INFO: \u001b[0mVal 22\n",
      "\u001b[32m[2020-07-02 05:10:30] __main__ INFO: \u001b[0mEpoch 22 loss 0.3026 acc@1 0.9154 acc@5 0.9974\n",
      "\u001b[32m[2020-07-02 05:10:30] __main__ INFO: \u001b[0mElapsed 7.65\n",
      "\u001b[32m[2020-07-02 05:10:30] __main__ INFO: \u001b[0mTrain 23 15466\n",
      "\u001b[32m[2020-07-02 05:11:01] __main__ INFO: \u001b[0mEpoch 23 Step 100/703 lr 0.001000 loss 0.1199 (0.0753) acc@1 0.9375 (0.9734) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-02 05:11:33] __main__ INFO: \u001b[0mEpoch 23 Step 200/703 lr 0.001000 loss 0.0798 (0.0770) acc@1 0.9688 (0.9728) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:12:05] __main__ INFO: \u001b[0mEpoch 23 Step 300/703 lr 0.001000 loss 0.0913 (0.0754) acc@1 0.9688 (0.9738) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:12:36] __main__ INFO: \u001b[0mEpoch 23 Step 400/703 lr 0.001000 loss 0.0355 (0.0760) acc@1 1.0000 (0.9740) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:13:08] __main__ INFO: \u001b[0mEpoch 23 Step 500/703 lr 0.001000 loss 0.0813 (0.0748) acc@1 0.9531 (0.9748) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:13:40] __main__ INFO: \u001b[0mEpoch 23 Step 600/703 lr 0.001000 loss 0.0562 (0.0743) acc@1 0.9844 (0.9752) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-02 05:14:11] __main__ INFO: \u001b[0mEpoch 23 Step 700/703 lr 0.001000 loss 0.0503 (0.0754) acc@1 0.9844 (0.9753) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-02 05:14:12] __main__ INFO: \u001b[0mEpoch 23 Step 703/703 lr 0.001000 loss 0.0715 (0.0753) acc@1 0.9688 (0.9753) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-02 05:14:12] __main__ INFO: \u001b[0mElapsed 222.36\n",
      "\u001b[32m[2020-07-02 05:14:12] __main__ INFO: \u001b[0mVal 23\n",
      "\u001b[32m[2020-07-02 05:14:20] __main__ INFO: \u001b[0mEpoch 23 loss 0.3045 acc@1 0.9132 acc@5 0.9974\n",
      "\u001b[32m[2020-07-02 05:14:20] __main__ INFO: \u001b[0mElapsed 7.70\n",
      "\u001b[32m[2020-07-02 05:14:20] __main__ INFO: \u001b[0mTrain 24 16169\n",
      "\u001b[32m[2020-07-02 05:14:52] __main__ INFO: \u001b[0mEpoch 24 Step 100/703 lr 0.001000 loss 0.0592 (0.0691) acc@1 0.9844 (0.9770) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:15:23] __main__ INFO: \u001b[0mEpoch 24 Step 200/703 lr 0.001000 loss 0.0653 (0.0694) acc@1 0.9844 (0.9778) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:15:55] __main__ INFO: \u001b[0mEpoch 24 Step 300/703 lr 0.001000 loss 0.0551 (0.0699) acc@1 0.9688 (0.9774) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:16:27] __main__ INFO: \u001b[0mEpoch 24 Step 400/703 lr 0.001000 loss 0.1052 (0.0720) acc@1 0.9844 (0.9767) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:16:58] __main__ INFO: \u001b[0mEpoch 24 Step 500/703 lr 0.001000 loss 0.0391 (0.0724) acc@1 0.9844 (0.9772) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:17:30] __main__ INFO: \u001b[0mEpoch 24 Step 600/703 lr 0.001000 loss 0.0763 (0.0726) acc@1 0.9844 (0.9769) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:18:02] __main__ INFO: \u001b[0mEpoch 24 Step 700/703 lr 0.001000 loss 0.0987 (0.0710) acc@1 0.9531 (0.9773) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:18:03] __main__ INFO: \u001b[0mEpoch 24 Step 703/703 lr 0.001000 loss 0.0637 (0.0709) acc@1 0.9688 (0.9773) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:18:03] __main__ INFO: \u001b[0mElapsed 222.77\n",
      "\u001b[32m[2020-07-02 05:18:03] __main__ INFO: \u001b[0mVal 24\n",
      "\u001b[32m[2020-07-02 05:18:10] __main__ INFO: \u001b[0mEpoch 24 loss 0.3018 acc@1 0.9160 acc@5 0.9974\n",
      "\u001b[32m[2020-07-02 05:18:10] __main__ INFO: \u001b[0mElapsed 7.68\n",
      "\u001b[32m[2020-07-02 05:18:10] __main__ INFO: \u001b[0mTrain 25 16872\n",
      "\u001b[32m[2020-07-02 05:18:42] __main__ INFO: \u001b[0mEpoch 25 Step 100/703 lr 0.001000 loss 0.0884 (0.0626) acc@1 0.9688 (0.9798) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-02 05:19:14] __main__ INFO: \u001b[0mEpoch 25 Step 200/703 lr 0.001000 loss 0.0368 (0.0605) acc@1 1.0000 (0.9823) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-02 05:19:45] __main__ INFO: \u001b[0mEpoch 25 Step 300/703 lr 0.001000 loss 0.0883 (0.0648) acc@1 0.9375 (0.9799) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-02 05:20:17] __main__ INFO: \u001b[0mEpoch 25 Step 400/703 lr 0.001000 loss 0.1047 (0.0656) acc@1 0.9844 (0.9795) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:20:49] __main__ INFO: \u001b[0mEpoch 25 Step 500/703 lr 0.001000 loss 0.0927 (0.0666) acc@1 0.9531 (0.9792) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:21:20] __main__ INFO: \u001b[0mEpoch 25 Step 600/703 lr 0.001000 loss 0.0972 (0.0678) acc@1 0.9531 (0.9786) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:21:52] __main__ INFO: \u001b[0mEpoch 25 Step 700/703 lr 0.001000 loss 0.0421 (0.0688) acc@1 1.0000 (0.9781) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:21:53] __main__ INFO: \u001b[0mEpoch 25 Step 703/703 lr 0.001000 loss 0.0775 (0.0688) acc@1 0.9844 (0.9782) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:21:53] __main__ INFO: \u001b[0mElapsed 222.39\n",
      "\u001b[32m[2020-07-02 05:21:53] __main__ INFO: \u001b[0mVal 25\n",
      "\u001b[32m[2020-07-02 05:22:00] __main__ INFO: \u001b[0mEpoch 25 loss 0.3061 acc@1 0.9144 acc@5 0.9974\n",
      "\u001b[32m[2020-07-02 05:22:00] __main__ INFO: \u001b[0mElapsed 7.69\n",
      "\u001b[32m[2020-07-02 05:22:00] __main__ INFO: \u001b[0mTrain 26 17575\n",
      "\u001b[32m[2020-07-02 05:22:32] __main__ INFO: \u001b[0mEpoch 26 Step 100/703 lr 0.001000 loss 0.0707 (0.0591) acc@1 0.9688 (0.9819) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-02 05:23:04] __main__ INFO: \u001b[0mEpoch 26 Step 200/703 lr 0.001000 loss 0.0451 (0.0607) acc@1 1.0000 (0.9812) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:23:35] __main__ INFO: \u001b[0mEpoch 26 Step 300/703 lr 0.001000 loss 0.0492 (0.0617) acc@1 1.0000 (0.9808) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:24:07] __main__ INFO: \u001b[0mEpoch 26 Step 400/703 lr 0.001000 loss 0.0633 (0.0630) acc@1 0.9688 (0.9799) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:24:39] __main__ INFO: \u001b[0mEpoch 26 Step 500/703 lr 0.001000 loss 0.1015 (0.0639) acc@1 0.9688 (0.9795) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:25:10] __main__ INFO: \u001b[0mEpoch 26 Step 600/703 lr 0.001000 loss 0.0574 (0.0645) acc@1 0.9688 (0.9792) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:25:42] __main__ INFO: \u001b[0mEpoch 26 Step 700/703 lr 0.001000 loss 0.0512 (0.0652) acc@1 0.9844 (0.9793) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:25:43] __main__ INFO: \u001b[0mEpoch 26 Step 703/703 lr 0.001000 loss 0.1525 (0.0653) acc@1 0.9531 (0.9793) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:25:43] __main__ INFO: \u001b[0mElapsed 222.36\n",
      "\u001b[32m[2020-07-02 05:25:43] __main__ INFO: \u001b[0mVal 26\n",
      "\u001b[32m[2020-07-02 05:25:50] __main__ INFO: \u001b[0mEpoch 26 loss 0.3037 acc@1 0.9148 acc@5 0.9974\n",
      "\u001b[32m[2020-07-02 05:25:50] __main__ INFO: \u001b[0mElapsed 7.68\n",
      "\u001b[32m[2020-07-02 05:25:50] __main__ INFO: \u001b[0mTrain 27 18278\n",
      "\u001b[32m[2020-07-02 05:26:22] __main__ INFO: \u001b[0mEpoch 27 Step 100/703 lr 0.001000 loss 0.0181 (0.0537) acc@1 1.0000 (0.9842) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-02 05:26:54] __main__ INFO: \u001b[0mEpoch 27 Step 200/703 lr 0.001000 loss 0.0467 (0.0577) acc@1 0.9844 (0.9824) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:27:25] __main__ INFO: \u001b[0mEpoch 27 Step 300/703 lr 0.001000 loss 0.1638 (0.0616) acc@1 0.9375 (0.9805) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:27:57] __main__ INFO: \u001b[0mEpoch 27 Step 400/703 lr 0.001000 loss 0.0368 (0.0628) acc@1 1.0000 (0.9796) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:28:28] __main__ INFO: \u001b[0mEpoch 27 Step 500/703 lr 0.001000 loss 0.0616 (0.0626) acc@1 0.9844 (0.9799) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:29:00] __main__ INFO: \u001b[0mEpoch 27 Step 600/703 lr 0.001000 loss 0.0490 (0.0633) acc@1 1.0000 (0.9800) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:29:32] __main__ INFO: \u001b[0mEpoch 27 Step 700/703 lr 0.001000 loss 0.0333 (0.0641) acc@1 1.0000 (0.9796) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:29:33] __main__ INFO: \u001b[0mEpoch 27 Step 703/703 lr 0.001000 loss 0.0458 (0.0640) acc@1 0.9844 (0.9796) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:29:33] __main__ INFO: \u001b[0mElapsed 222.17\n",
      "\u001b[32m[2020-07-02 05:29:33] __main__ INFO: \u001b[0mVal 27\n",
      "\u001b[32m[2020-07-02 05:29:40] __main__ INFO: \u001b[0mEpoch 27 loss 0.3079 acc@1 0.9146 acc@5 0.9976\n",
      "\u001b[32m[2020-07-02 05:29:40] __main__ INFO: \u001b[0mElapsed 7.65\n",
      "\u001b[32m[2020-07-02 05:29:40] __main__ INFO: \u001b[0mTrain 28 18981\n",
      "\u001b[32m[2020-07-02 05:30:12] __main__ INFO: \u001b[0mEpoch 28 Step 100/703 lr 0.001000 loss 0.1134 (0.0650) acc@1 0.9688 (0.9781) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-02 05:30:44] __main__ INFO: \u001b[0mEpoch 28 Step 200/703 lr 0.001000 loss 0.0438 (0.0626) acc@1 0.9844 (0.9790) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:31:15] __main__ INFO: \u001b[0mEpoch 28 Step 300/703 lr 0.001000 loss 0.0446 (0.0596) acc@1 1.0000 (0.9803) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:31:47] __main__ INFO: \u001b[0mEpoch 28 Step 400/703 lr 0.001000 loss 0.0394 (0.0594) acc@1 0.9844 (0.9805) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:32:18] __main__ INFO: \u001b[0mEpoch 28 Step 500/703 lr 0.001000 loss 0.0299 (0.0592) acc@1 1.0000 (0.9810) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:32:50] __main__ INFO: \u001b[0mEpoch 28 Step 600/703 lr 0.001000 loss 0.0484 (0.0588) acc@1 0.9844 (0.9812) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:33:22] __main__ INFO: \u001b[0mEpoch 28 Step 700/703 lr 0.001000 loss 0.1057 (0.0603) acc@1 0.9531 (0.9805) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:33:23] __main__ INFO: \u001b[0mEpoch 28 Step 703/703 lr 0.001000 loss 0.0153 (0.0603) acc@1 1.0000 (0.9805) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:33:23] __main__ INFO: \u001b[0mElapsed 222.31\n",
      "\u001b[32m[2020-07-02 05:33:23] __main__ INFO: \u001b[0mVal 28\n",
      "\u001b[32m[2020-07-02 05:33:30] __main__ INFO: \u001b[0mEpoch 28 loss 0.3076 acc@1 0.9150 acc@5 0.9978\n",
      "\u001b[32m[2020-07-02 05:33:30] __main__ INFO: \u001b[0mElapsed 7.66\n",
      "\u001b[32m[2020-07-02 05:33:30] __main__ INFO: \u001b[0mTrain 29 19684\n",
      "\u001b[32m[2020-07-02 05:34:02] __main__ INFO: \u001b[0mEpoch 29 Step 100/703 lr 0.001000 loss 0.0473 (0.0535) acc@1 0.9844 (0.9834) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:34:34] __main__ INFO: \u001b[0mEpoch 29 Step 200/703 lr 0.001000 loss 0.0689 (0.0569) acc@1 0.9844 (0.9816) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:35:05] __main__ INFO: \u001b[0mEpoch 29 Step 300/703 lr 0.001000 loss 0.0872 (0.0574) acc@1 0.9688 (0.9814) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:35:37] __main__ INFO: \u001b[0mEpoch 29 Step 400/703 lr 0.001000 loss 0.1009 (0.0577) acc@1 0.9688 (0.9814) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:36:08] __main__ INFO: \u001b[0mEpoch 29 Step 500/703 lr 0.001000 loss 0.0577 (0.0567) acc@1 0.9844 (0.9819) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:36:40] __main__ INFO: \u001b[0mEpoch 29 Step 600/703 lr 0.001000 loss 0.0927 (0.0580) acc@1 0.9688 (0.9814) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:37:11] __main__ INFO: \u001b[0mEpoch 29 Step 700/703 lr 0.001000 loss 0.0466 (0.0572) acc@1 0.9844 (0.9819) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:37:12] __main__ INFO: \u001b[0mEpoch 29 Step 703/703 lr 0.001000 loss 0.0464 (0.0572) acc@1 0.9844 (0.9819) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:37:12] __main__ INFO: \u001b[0mElapsed 222.19\n",
      "\u001b[32m[2020-07-02 05:37:12] __main__ INFO: \u001b[0mVal 29\n",
      "\u001b[32m[2020-07-02 05:37:20] __main__ INFO: \u001b[0mEpoch 29 loss 0.3079 acc@1 0.9158 acc@5 0.9976\n",
      "\u001b[32m[2020-07-02 05:37:20] __main__ INFO: \u001b[0mElapsed 7.68\n",
      "\u001b[32m[2020-07-02 05:37:20] __main__ INFO: \u001b[0mTrain 30 20387\n",
      "\u001b[32m[2020-07-02 05:37:52] __main__ INFO: \u001b[0mEpoch 30 Step 100/703 lr 0.001000 loss 0.0794 (0.0523) acc@1 0.9844 (0.9841) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:38:23] __main__ INFO: \u001b[0mEpoch 30 Step 200/703 lr 0.001000 loss 0.0886 (0.0536) acc@1 0.9844 (0.9841) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:38:55] __main__ INFO: \u001b[0mEpoch 30 Step 300/703 lr 0.001000 loss 0.0720 (0.0552) acc@1 0.9844 (0.9833) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:39:27] __main__ INFO: \u001b[0mEpoch 30 Step 400/703 lr 0.001000 loss 0.0715 (0.0549) acc@1 0.9688 (0.9835) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:39:58] __main__ INFO: \u001b[0mEpoch 30 Step 500/703 lr 0.001000 loss 0.1158 (0.0553) acc@1 0.9375 (0.9832) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:40:30] __main__ INFO: \u001b[0mEpoch 30 Step 600/703 lr 0.001000 loss 0.0365 (0.0553) acc@1 0.9844 (0.9833) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:41:02] __main__ INFO: \u001b[0mEpoch 30 Step 700/703 lr 0.001000 loss 0.0752 (0.0551) acc@1 0.9688 (0.9835) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:41:03] __main__ INFO: \u001b[0mEpoch 30 Step 703/703 lr 0.001000 loss 0.1030 (0.0552) acc@1 0.9688 (0.9835) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:41:03] __main__ INFO: \u001b[0mElapsed 222.42\n",
      "\u001b[32m[2020-07-02 05:41:03] __main__ INFO: \u001b[0mVal 30\n",
      "\u001b[32m[2020-07-02 05:41:10] __main__ INFO: \u001b[0mEpoch 30 loss 0.3055 acc@1 0.9158 acc@5 0.9980\n",
      "\u001b[32m[2020-07-02 05:41:10] __main__ INFO: \u001b[0mElapsed 7.70\n",
      "\u001b[32m[2020-07-02 05:41:10] __main__ INFO: \u001b[0mTrain 31 21090\n",
      "\u001b[32m[2020-07-02 05:41:42] __main__ INFO: \u001b[0mEpoch 31 Step 100/703 lr 0.001000 loss 0.0613 (0.0525) acc@1 0.9844 (0.9836) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:42:14] __main__ INFO: \u001b[0mEpoch 31 Step 200/703 lr 0.001000 loss 0.0375 (0.0509) acc@1 0.9844 (0.9845) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:42:45] __main__ INFO: \u001b[0mEpoch 31 Step 300/703 lr 0.001000 loss 0.0886 (0.0522) acc@1 0.9688 (0.9840) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:43:17] __main__ INFO: \u001b[0mEpoch 31 Step 400/703 lr 0.001000 loss 0.0539 (0.0516) acc@1 0.9844 (0.9845) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:43:49] __main__ INFO: \u001b[0mEpoch 31 Step 500/703 lr 0.001000 loss 0.0429 (0.0522) acc@1 1.0000 (0.9844) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:44:20] __main__ INFO: \u001b[0mEpoch 31 Step 600/703 lr 0.001000 loss 0.0262 (0.0524) acc@1 1.0000 (0.9843) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:44:52] __main__ INFO: \u001b[0mEpoch 31 Step 700/703 lr 0.001000 loss 0.0865 (0.0519) acc@1 0.9688 (0.9843) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:44:53] __main__ INFO: \u001b[0mEpoch 31 Step 703/703 lr 0.001000 loss 0.0487 (0.0518) acc@1 0.9688 (0.9844) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:44:53] __main__ INFO: \u001b[0mElapsed 222.46\n",
      "\u001b[32m[2020-07-02 05:44:53] __main__ INFO: \u001b[0mVal 31\n",
      "\u001b[32m[2020-07-02 05:45:00] __main__ INFO: \u001b[0mEpoch 31 loss 0.3142 acc@1 0.9116 acc@5 0.9974\n",
      "\u001b[32m[2020-07-02 05:45:00] __main__ INFO: \u001b[0mElapsed 7.70\n",
      "\u001b[32m[2020-07-02 05:45:00] __main__ INFO: \u001b[0mTrain 32 21793\n",
      "\u001b[32m[2020-07-02 05:45:32] __main__ INFO: \u001b[0mEpoch 32 Step 100/703 lr 0.001000 loss 0.0254 (0.0455) acc@1 1.0000 (0.9892) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:46:04] __main__ INFO: \u001b[0mEpoch 32 Step 200/703 lr 0.001000 loss 0.0364 (0.0465) acc@1 0.9844 (0.9874) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:46:35] __main__ INFO: \u001b[0mEpoch 32 Step 300/703 lr 0.001000 loss 0.0723 (0.0487) acc@1 0.9844 (0.9857) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:47:07] __main__ INFO: \u001b[0mEpoch 32 Step 400/703 lr 0.001000 loss 0.0766 (0.0485) acc@1 0.9688 (0.9858) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:47:39] __main__ INFO: \u001b[0mEpoch 32 Step 500/703 lr 0.001000 loss 0.0840 (0.0493) acc@1 0.9688 (0.9854) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:48:10] __main__ INFO: \u001b[0mEpoch 32 Step 600/703 lr 0.001000 loss 0.0312 (0.0500) acc@1 1.0000 (0.9854) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:48:42] __main__ INFO: \u001b[0mEpoch 32 Step 700/703 lr 0.001000 loss 0.0428 (0.0499) acc@1 0.9844 (0.9853) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:48:43] __main__ INFO: \u001b[0mEpoch 32 Step 703/703 lr 0.001000 loss 0.0200 (0.0499) acc@1 1.0000 (0.9853) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:48:43] __main__ INFO: \u001b[0mElapsed 222.56\n",
      "\u001b[32m[2020-07-02 05:48:43] __main__ INFO: \u001b[0mVal 32\n",
      "\u001b[32m[2020-07-02 05:48:51] __main__ INFO: \u001b[0mEpoch 32 loss 0.3114 acc@1 0.9180 acc@5 0.9974\n",
      "\u001b[32m[2020-07-02 05:48:51] __main__ INFO: \u001b[0mElapsed 7.65\n",
      "\u001b[32m[2020-07-02 05:48:51] __main__ INFO: \u001b[0mTrain 33 22496\n",
      "\u001b[32m[2020-07-02 05:49:22] __main__ INFO: \u001b[0mEpoch 33 Step 100/703 lr 0.001000 loss 0.0110 (0.0505) acc@1 1.0000 (0.9830) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:49:54] __main__ INFO: \u001b[0mEpoch 33 Step 200/703 lr 0.001000 loss 0.0282 (0.0487) acc@1 0.9844 (0.9846) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:50:26] __main__ INFO: \u001b[0mEpoch 33 Step 300/703 lr 0.001000 loss 0.0443 (0.0500) acc@1 1.0000 (0.9841) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:50:57] __main__ INFO: \u001b[0mEpoch 33 Step 400/703 lr 0.001000 loss 0.0465 (0.0502) acc@1 0.9688 (0.9841) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:51:29] __main__ INFO: \u001b[0mEpoch 33 Step 500/703 lr 0.001000 loss 0.1196 (0.0509) acc@1 0.9688 (0.9840) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:52:00] __main__ INFO: \u001b[0mEpoch 33 Step 600/703 lr 0.001000 loss 0.0534 (0.0513) acc@1 0.9844 (0.9841) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:52:32] __main__ INFO: \u001b[0mEpoch 33 Step 700/703 lr 0.001000 loss 0.0156 (0.0513) acc@1 1.0000 (0.9841) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:52:33] __main__ INFO: \u001b[0mEpoch 33 Step 703/703 lr 0.001000 loss 0.0562 (0.0512) acc@1 0.9844 (0.9842) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:52:33] __main__ INFO: \u001b[0mElapsed 222.34\n",
      "\u001b[32m[2020-07-02 05:52:33] __main__ INFO: \u001b[0mVal 33\n",
      "\u001b[32m[2020-07-02 05:52:41] __main__ INFO: \u001b[0mEpoch 33 loss 0.3194 acc@1 0.9108 acc@5 0.9974\n",
      "\u001b[32m[2020-07-02 05:52:41] __main__ INFO: \u001b[0mElapsed 7.70\n",
      "\u001b[32m[2020-07-02 05:52:41] __main__ INFO: \u001b[0mTrain 34 23199\n",
      "\u001b[32m[2020-07-02 05:53:12] __main__ INFO: \u001b[0mEpoch 34 Step 100/703 lr 0.001000 loss 0.1273 (0.0479) acc@1 0.9531 (0.9861) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:53:44] __main__ INFO: \u001b[0mEpoch 34 Step 200/703 lr 0.001000 loss 0.0408 (0.0465) acc@1 1.0000 (0.9867) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:54:16] __main__ INFO: \u001b[0mEpoch 34 Step 300/703 lr 0.001000 loss 0.0745 (0.0470) acc@1 0.9844 (0.9864) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:54:47] __main__ INFO: \u001b[0mEpoch 34 Step 400/703 lr 0.001000 loss 0.0462 (0.0483) acc@1 0.9688 (0.9854) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:55:19] __main__ INFO: \u001b[0mEpoch 34 Step 500/703 lr 0.001000 loss 0.0812 (0.0490) acc@1 0.9844 (0.9848) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:55:50] __main__ INFO: \u001b[0mEpoch 34 Step 600/703 lr 0.001000 loss 0.0191 (0.0488) acc@1 1.0000 (0.9848) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:56:22] __main__ INFO: \u001b[0mEpoch 34 Step 700/703 lr 0.001000 loss 0.0220 (0.0486) acc@1 1.0000 (0.9851) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:56:23] __main__ INFO: \u001b[0mEpoch 34 Step 703/703 lr 0.001000 loss 0.0482 (0.0487) acc@1 1.0000 (0.9851) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 05:56:23] __main__ INFO: \u001b[0mElapsed 222.38\n",
      "\u001b[32m[2020-07-02 05:56:23] __main__ INFO: \u001b[0mVal 34\n",
      "\u001b[32m[2020-07-02 05:56:31] __main__ INFO: \u001b[0mEpoch 34 loss 0.3182 acc@1 0.9132 acc@5 0.9972\n",
      "\u001b[32m[2020-07-02 05:56:31] __main__ INFO: \u001b[0mElapsed 7.68\n",
      "\u001b[32m[2020-07-02 05:56:31] __main__ INFO: \u001b[0mTrain 35 23902\n",
      "\u001b[32m[2020-07-02 05:57:02] __main__ INFO: \u001b[0mEpoch 35 Step 100/703 lr 0.001000 loss 0.0198 (0.0511) acc@1 1.0000 (0.9828) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-02 05:57:34] __main__ INFO: \u001b[0mEpoch 35 Step 200/703 lr 0.001000 loss 0.0247 (0.0520) acc@1 1.0000 (0.9833) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:58:06] __main__ INFO: \u001b[0mEpoch 35 Step 300/703 lr 0.001000 loss 0.0365 (0.0511) acc@1 0.9844 (0.9834) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:58:37] __main__ INFO: \u001b[0mEpoch 35 Step 400/703 lr 0.001000 loss 0.0087 (0.0501) acc@1 1.0000 (0.9842) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:59:09] __main__ INFO: \u001b[0mEpoch 35 Step 500/703 lr 0.001000 loss 0.0892 (0.0488) acc@1 0.9844 (0.9847) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 05:59:41] __main__ INFO: \u001b[0mEpoch 35 Step 600/703 lr 0.001000 loss 0.0228 (0.0477) acc@1 1.0000 (0.9852) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 06:00:12] __main__ INFO: \u001b[0mEpoch 35 Step 700/703 lr 0.001000 loss 0.0490 (0.0478) acc@1 1.0000 (0.9852) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:00:13] __main__ INFO: \u001b[0mEpoch 35 Step 703/703 lr 0.001000 loss 0.0395 (0.0478) acc@1 0.9844 (0.9852) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:00:13] __main__ INFO: \u001b[0mElapsed 222.33\n",
      "\u001b[32m[2020-07-02 06:00:13] __main__ INFO: \u001b[0mVal 35\n",
      "\u001b[32m[2020-07-02 06:00:21] __main__ INFO: \u001b[0mEpoch 35 loss 0.3285 acc@1 0.9116 acc@5 0.9974\n",
      "\u001b[32m[2020-07-02 06:00:21] __main__ INFO: \u001b[0mElapsed 7.64\n",
      "\u001b[32m[2020-07-02 06:00:21] __main__ INFO: \u001b[0mTrain 36 24605\n",
      "\u001b[32m[2020-07-02 06:00:52] __main__ INFO: \u001b[0mEpoch 36 Step 100/703 lr 0.001000 loss 0.0208 (0.0436) acc@1 1.0000 (0.9869) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:01:24] __main__ INFO: \u001b[0mEpoch 36 Step 200/703 lr 0.001000 loss 0.0054 (0.0429) acc@1 1.0000 (0.9865) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:01:56] __main__ INFO: \u001b[0mEpoch 36 Step 300/703 lr 0.001000 loss 0.0194 (0.0406) acc@1 1.0000 (0.9881) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:02:27] __main__ INFO: \u001b[0mEpoch 36 Step 400/703 lr 0.001000 loss 0.0523 (0.0436) acc@1 0.9844 (0.9865) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:02:59] __main__ INFO: \u001b[0mEpoch 36 Step 500/703 lr 0.001000 loss 0.0327 (0.0443) acc@1 1.0000 (0.9863) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:03:30] __main__ INFO: \u001b[0mEpoch 36 Step 600/703 lr 0.001000 loss 0.0634 (0.0443) acc@1 1.0000 (0.9867) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:04:02] __main__ INFO: \u001b[0mEpoch 36 Step 700/703 lr 0.001000 loss 0.0495 (0.0455) acc@1 0.9844 (0.9862) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:04:03] __main__ INFO: \u001b[0mEpoch 36 Step 703/703 lr 0.001000 loss 0.0376 (0.0455) acc@1 0.9844 (0.9862) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:04:03] __main__ INFO: \u001b[0mElapsed 222.28\n",
      "\u001b[32m[2020-07-02 06:04:03] __main__ INFO: \u001b[0mVal 36\n",
      "\u001b[32m[2020-07-02 06:04:11] __main__ INFO: \u001b[0mEpoch 36 loss 0.3199 acc@1 0.9126 acc@5 0.9978\n",
      "\u001b[32m[2020-07-02 06:04:11] __main__ INFO: \u001b[0mElapsed 7.68\n",
      "\u001b[32m[2020-07-02 06:04:11] __main__ INFO: \u001b[0mTrain 37 25308\n",
      "\u001b[32m[2020-07-02 06:04:42] __main__ INFO: \u001b[0mEpoch 37 Step 100/703 lr 0.001000 loss 0.0139 (0.0420) acc@1 1.0000 (0.9891) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:05:14] __main__ INFO: \u001b[0mEpoch 37 Step 200/703 lr 0.001000 loss 0.1076 (0.0433) acc@1 0.9688 (0.9876) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:05:46] __main__ INFO: \u001b[0mEpoch 37 Step 300/703 lr 0.001000 loss 0.0196 (0.0437) acc@1 1.0000 (0.9868) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:06:17] __main__ INFO: \u001b[0mEpoch 37 Step 400/703 lr 0.001000 loss 0.0921 (0.0436) acc@1 0.9531 (0.9870) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:06:49] __main__ INFO: \u001b[0mEpoch 37 Step 500/703 lr 0.001000 loss 0.0169 (0.0436) acc@1 1.0000 (0.9868) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:07:20] __main__ INFO: \u001b[0mEpoch 37 Step 600/703 lr 0.001000 loss 0.0147 (0.0433) acc@1 1.0000 (0.9872) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:07:52] __main__ INFO: \u001b[0mEpoch 37 Step 700/703 lr 0.001000 loss 0.0793 (0.0428) acc@1 0.9688 (0.9873) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:07:53] __main__ INFO: \u001b[0mEpoch 37 Step 703/703 lr 0.001000 loss 0.0126 (0.0428) acc@1 1.0000 (0.9874) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:07:53] __main__ INFO: \u001b[0mElapsed 222.41\n",
      "\u001b[32m[2020-07-02 06:07:53] __main__ INFO: \u001b[0mVal 37\n",
      "\u001b[32m[2020-07-02 06:08:01] __main__ INFO: \u001b[0mEpoch 37 loss 0.3161 acc@1 0.9128 acc@5 0.9976\n",
      "\u001b[32m[2020-07-02 06:08:01] __main__ INFO: \u001b[0mElapsed 7.69\n",
      "\u001b[32m[2020-07-02 06:08:01] __main__ INFO: \u001b[0mTrain 38 26011\n",
      "\u001b[32m[2020-07-02 06:08:32] __main__ INFO: \u001b[0mEpoch 38 Step 100/703 lr 0.001000 loss 0.0161 (0.0434) acc@1 1.0000 (0.9859) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:09:04] __main__ INFO: \u001b[0mEpoch 38 Step 200/703 lr 0.001000 loss 0.0186 (0.0417) acc@1 1.0000 (0.9870) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:09:36] __main__ INFO: \u001b[0mEpoch 38 Step 300/703 lr 0.001000 loss 0.0819 (0.0406) acc@1 0.9688 (0.9880) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:10:07] __main__ INFO: \u001b[0mEpoch 38 Step 400/703 lr 0.001000 loss 0.0104 (0.0416) acc@1 1.0000 (0.9878) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:10:39] __main__ INFO: \u001b[0mEpoch 38 Step 500/703 lr 0.001000 loss 0.0082 (0.0418) acc@1 1.0000 (0.9878) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:11:11] __main__ INFO: \u001b[0mEpoch 38 Step 600/703 lr 0.001000 loss 0.0476 (0.0420) acc@1 0.9844 (0.9877) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-02 06:11:42] __main__ INFO: \u001b[0mEpoch 38 Step 700/703 lr 0.001000 loss 0.0452 (0.0420) acc@1 0.9688 (0.9877) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:11:43] __main__ INFO: \u001b[0mEpoch 38 Step 703/703 lr 0.001000 loss 0.0355 (0.0419) acc@1 0.9844 (0.9876) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:11:43] __main__ INFO: \u001b[0mElapsed 222.29\n",
      "\u001b[32m[2020-07-02 06:11:43] __main__ INFO: \u001b[0mVal 38\n",
      "\u001b[32m[2020-07-02 06:11:51] __main__ INFO: \u001b[0mEpoch 38 loss 0.3191 acc@1 0.9144 acc@5 0.9974\n",
      "\u001b[32m[2020-07-02 06:11:51] __main__ INFO: \u001b[0mElapsed 7.66\n",
      "\u001b[32m[2020-07-02 06:11:51] __main__ INFO: \u001b[0mTrain 39 26714\n",
      "\u001b[32m[2020-07-02 06:12:22] __main__ INFO: \u001b[0mEpoch 39 Step 100/703 lr 0.001000 loss 0.0399 (0.0372) acc@1 0.9844 (0.9905) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:12:54] __main__ INFO: \u001b[0mEpoch 39 Step 200/703 lr 0.001000 loss 0.0254 (0.0361) acc@1 0.9844 (0.9907) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:13:26] __main__ INFO: \u001b[0mEpoch 39 Step 300/703 lr 0.001000 loss 0.0350 (0.0380) acc@1 0.9844 (0.9891) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:13:57] __main__ INFO: \u001b[0mEpoch 39 Step 400/703 lr 0.001000 loss 0.0596 (0.0388) acc@1 0.9844 (0.9884) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:14:29] __main__ INFO: \u001b[0mEpoch 39 Step 500/703 lr 0.001000 loss 0.0151 (0.0394) acc@1 1.0000 (0.9884) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:15:01] __main__ INFO: \u001b[0mEpoch 39 Step 600/703 lr 0.001000 loss 0.0350 (0.0399) acc@1 0.9844 (0.9882) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:15:32] __main__ INFO: \u001b[0mEpoch 39 Step 700/703 lr 0.001000 loss 0.0095 (0.0402) acc@1 1.0000 (0.9881) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:15:33] __main__ INFO: \u001b[0mEpoch 39 Step 703/703 lr 0.001000 loss 0.0303 (0.0402) acc@1 0.9844 (0.9881) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:15:33] __main__ INFO: \u001b[0mElapsed 222.50\n",
      "\u001b[32m[2020-07-02 06:15:33] __main__ INFO: \u001b[0mVal 39\n",
      "\u001b[32m[2020-07-02 06:15:41] __main__ INFO: \u001b[0mEpoch 39 loss 0.3194 acc@1 0.9130 acc@5 0.9968\n",
      "\u001b[32m[2020-07-02 06:15:41] __main__ INFO: \u001b[0mElapsed 7.65\n",
      "\u001b[32m[2020-07-02 06:15:41] __main__ INFO: \u001b[0mTrain 40 27417\n",
      "\u001b[32m[2020-07-02 06:16:13] __main__ INFO: \u001b[0mEpoch 40 Step 100/703 lr 0.001000 loss 0.0172 (0.0340) acc@1 1.0000 (0.9908) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:16:44] __main__ INFO: \u001b[0mEpoch 40 Step 200/703 lr 0.001000 loss 0.0062 (0.0361) acc@1 1.0000 (0.9901) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:17:16] __main__ INFO: \u001b[0mEpoch 40 Step 300/703 lr 0.001000 loss 0.0631 (0.0367) acc@1 0.9844 (0.9898) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:17:47] __main__ INFO: \u001b[0mEpoch 40 Step 400/703 lr 0.001000 loss 0.0169 (0.0374) acc@1 1.0000 (0.9895) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:18:19] __main__ INFO: \u001b[0mEpoch 40 Step 500/703 lr 0.001000 loss 0.0476 (0.0382) acc@1 1.0000 (0.9888) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:18:51] __main__ INFO: \u001b[0mEpoch 40 Step 600/703 lr 0.001000 loss 0.0483 (0.0390) acc@1 0.9844 (0.9884) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:19:22] __main__ INFO: \u001b[0mEpoch 40 Step 700/703 lr 0.001000 loss 0.0340 (0.0395) acc@1 1.0000 (0.9884) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:19:23] __main__ INFO: \u001b[0mEpoch 40 Step 703/703 lr 0.001000 loss 0.0650 (0.0396) acc@1 0.9844 (0.9884) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:19:23] __main__ INFO: \u001b[0mElapsed 222.40\n",
      "\u001b[32m[2020-07-02 06:19:23] __main__ INFO: \u001b[0mVal 40\n",
      "\u001b[32m[2020-07-02 06:19:31] __main__ INFO: \u001b[0mEpoch 40 loss 0.3217 acc@1 0.9142 acc@5 0.9968\n",
      "\u001b[32m[2020-07-02 06:19:31] __main__ INFO: \u001b[0mElapsed 7.68\n",
      "\u001b[32m[2020-07-02 06:19:31] __main__ INFO: \u001b[0mTrain 41 28120\n",
      "\u001b[32m[2020-07-02 06:20:03] __main__ INFO: \u001b[0mEpoch 41 Step 100/703 lr 0.001000 loss 0.0694 (0.0366) acc@1 0.9688 (0.9891) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:20:34] __main__ INFO: \u001b[0mEpoch 41 Step 200/703 lr 0.001000 loss 0.0438 (0.0360) acc@1 0.9844 (0.9897) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:21:06] __main__ INFO: \u001b[0mEpoch 41 Step 300/703 lr 0.001000 loss 0.0372 (0.0362) acc@1 0.9688 (0.9895) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:21:38] __main__ INFO: \u001b[0mEpoch 41 Step 400/703 lr 0.001000 loss 0.0382 (0.0363) acc@1 0.9688 (0.9894) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:22:09] __main__ INFO: \u001b[0mEpoch 41 Step 500/703 lr 0.001000 loss 0.0126 (0.0364) acc@1 1.0000 (0.9895) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:22:41] __main__ INFO: \u001b[0mEpoch 41 Step 600/703 lr 0.001000 loss 0.0283 (0.0374) acc@1 1.0000 (0.9889) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:23:12] __main__ INFO: \u001b[0mEpoch 41 Step 700/703 lr 0.001000 loss 0.0679 (0.0376) acc@1 0.9844 (0.9889) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:23:13] __main__ INFO: \u001b[0mEpoch 41 Step 703/703 lr 0.001000 loss 0.0350 (0.0376) acc@1 1.0000 (0.9889) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:23:13] __main__ INFO: \u001b[0mElapsed 222.17\n",
      "\u001b[32m[2020-07-02 06:23:13] __main__ INFO: \u001b[0mVal 41\n",
      "\u001b[32m[2020-07-02 06:23:21] __main__ INFO: \u001b[0mEpoch 41 loss 0.3254 acc@1 0.9146 acc@5 0.9970\n",
      "\u001b[32m[2020-07-02 06:23:21] __main__ INFO: \u001b[0mElapsed 7.66\n",
      "\u001b[32m[2020-07-02 06:23:21] __main__ INFO: \u001b[0mTrain 42 28823\n",
      "\u001b[32m[2020-07-02 06:23:52] __main__ INFO: \u001b[0mEpoch 42 Step 100/703 lr 0.001000 loss 0.0141 (0.0384) acc@1 1.0000 (0.9897) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:24:24] __main__ INFO: \u001b[0mEpoch 42 Step 200/703 lr 0.001000 loss 0.0314 (0.0360) acc@1 0.9844 (0.9905) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:24:56] __main__ INFO: \u001b[0mEpoch 42 Step 300/703 lr 0.001000 loss 0.0912 (0.0361) acc@1 0.9688 (0.9902) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:25:27] __main__ INFO: \u001b[0mEpoch 42 Step 400/703 lr 0.001000 loss 0.0527 (0.0358) acc@1 0.9844 (0.9905) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:25:59] __main__ INFO: \u001b[0mEpoch 42 Step 500/703 lr 0.001000 loss 0.0346 (0.0367) acc@1 0.9844 (0.9899) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:26:31] __main__ INFO: \u001b[0mEpoch 42 Step 600/703 lr 0.001000 loss 0.0284 (0.0367) acc@1 0.9844 (0.9899) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:27:02] __main__ INFO: \u001b[0mEpoch 42 Step 700/703 lr 0.001000 loss 0.0275 (0.0369) acc@1 0.9844 (0.9898) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:27:03] __main__ INFO: \u001b[0mEpoch 42 Step 703/703 lr 0.001000 loss 0.0171 (0.0369) acc@1 1.0000 (0.9898) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:27:03] __main__ INFO: \u001b[0mElapsed 222.45\n",
      "\u001b[32m[2020-07-02 06:27:03] __main__ INFO: \u001b[0mVal 42\n",
      "\u001b[32m[2020-07-02 06:27:11] __main__ INFO: \u001b[0mEpoch 42 loss 0.3193 acc@1 0.9140 acc@5 0.9976\n",
      "\u001b[32m[2020-07-02 06:27:11] __main__ INFO: \u001b[0mElapsed 7.68\n",
      "\u001b[32m[2020-07-02 06:27:11] __main__ INFO: \u001b[0mTrain 43 29526\n",
      "\u001b[32m[2020-07-02 06:27:43] __main__ INFO: \u001b[0mEpoch 43 Step 100/703 lr 0.001000 loss 0.0207 (0.0319) acc@1 1.0000 (0.9909) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:28:14] __main__ INFO: \u001b[0mEpoch 43 Step 200/703 lr 0.001000 loss 0.0209 (0.0319) acc@1 1.0000 (0.9907) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:28:46] __main__ INFO: \u001b[0mEpoch 43 Step 300/703 lr 0.001000 loss 0.0407 (0.0347) acc@1 0.9844 (0.9897) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:29:17] __main__ INFO: \u001b[0mEpoch 43 Step 400/703 lr 0.001000 loss 0.0449 (0.0355) acc@1 1.0000 (0.9896) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:29:49] __main__ INFO: \u001b[0mEpoch 43 Step 500/703 lr 0.001000 loss 0.0162 (0.0350) acc@1 1.0000 (0.9901) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:30:21] __main__ INFO: \u001b[0mEpoch 43 Step 600/703 lr 0.001000 loss 0.1225 (0.0356) acc@1 0.9375 (0.9896) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:30:52] __main__ INFO: \u001b[0mEpoch 43 Step 700/703 lr 0.001000 loss 0.0506 (0.0359) acc@1 0.9688 (0.9895) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:30:53] __main__ INFO: \u001b[0mEpoch 43 Step 703/703 lr 0.001000 loss 0.0356 (0.0359) acc@1 1.0000 (0.9895) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:30:53] __main__ INFO: \u001b[0mElapsed 222.39\n",
      "\u001b[32m[2020-07-02 06:30:53] __main__ INFO: \u001b[0mVal 43\n",
      "\u001b[32m[2020-07-02 06:31:01] __main__ INFO: \u001b[0mEpoch 43 loss 0.3159 acc@1 0.9156 acc@5 0.9972\n",
      "\u001b[32m[2020-07-02 06:31:01] __main__ INFO: \u001b[0mElapsed 7.70\n",
      "\u001b[32m[2020-07-02 06:31:01] __main__ INFO: \u001b[0mTrain 44 30229\n",
      "\u001b[32m[2020-07-02 06:31:33] __main__ INFO: \u001b[0mEpoch 44 Step 100/703 lr 0.001000 loss 0.0803 (0.0332) acc@1 0.9531 (0.9895) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:32:04] __main__ INFO: \u001b[0mEpoch 44 Step 200/703 lr 0.001000 loss 0.0198 (0.0342) acc@1 1.0000 (0.9898) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:32:36] __main__ INFO: \u001b[0mEpoch 44 Step 300/703 lr 0.001000 loss 0.0081 (0.0338) acc@1 1.0000 (0.9897) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:33:08] __main__ INFO: \u001b[0mEpoch 44 Step 400/703 lr 0.001000 loss 0.0170 (0.0341) acc@1 1.0000 (0.9898) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:33:39] __main__ INFO: \u001b[0mEpoch 44 Step 500/703 lr 0.001000 loss 0.0170 (0.0352) acc@1 1.0000 (0.9895) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:34:11] __main__ INFO: \u001b[0mEpoch 44 Step 600/703 lr 0.001000 loss 0.0303 (0.0357) acc@1 0.9844 (0.9893) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:34:43] __main__ INFO: \u001b[0mEpoch 44 Step 700/703 lr 0.001000 loss 0.0298 (0.0353) acc@1 0.9844 (0.9894) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:34:43] __main__ INFO: \u001b[0mEpoch 44 Step 703/703 lr 0.001000 loss 0.0512 (0.0354) acc@1 0.9844 (0.9894) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:34:43] __main__ INFO: \u001b[0mElapsed 222.44\n",
      "\u001b[32m[2020-07-02 06:34:43] __main__ INFO: \u001b[0mVal 44\n",
      "\u001b[32m[2020-07-02 06:34:51] __main__ INFO: \u001b[0mEpoch 44 loss 0.3169 acc@1 0.9150 acc@5 0.9976\n",
      "\u001b[32m[2020-07-02 06:34:51] __main__ INFO: \u001b[0mElapsed 7.70\n",
      "\u001b[32m[2020-07-02 06:34:51] __main__ INFO: \u001b[0mTrain 45 30932\n",
      "\u001b[32m[2020-07-02 06:35:23] __main__ INFO: \u001b[0mEpoch 45 Step 100/703 lr 0.001000 loss 0.1421 (0.0357) acc@1 0.9688 (0.9884) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:35:55] __main__ INFO: \u001b[0mEpoch 45 Step 200/703 lr 0.001000 loss 0.0422 (0.0334) acc@1 0.9844 (0.9899) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:36:26] __main__ INFO: \u001b[0mEpoch 45 Step 300/703 lr 0.001000 loss 0.0406 (0.0326) acc@1 0.9844 (0.9903) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:36:58] __main__ INFO: \u001b[0mEpoch 45 Step 400/703 lr 0.001000 loss 0.0344 (0.0325) acc@1 0.9844 (0.9905) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:37:29] __main__ INFO: \u001b[0mEpoch 45 Step 500/703 lr 0.001000 loss 0.0434 (0.0327) acc@1 0.9844 (0.9906) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:38:01] __main__ INFO: \u001b[0mEpoch 45 Step 600/703 lr 0.001000 loss 0.0839 (0.0328) acc@1 0.9844 (0.9907) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:38:33] __main__ INFO: \u001b[0mEpoch 45 Step 700/703 lr 0.001000 loss 0.1621 (0.0331) acc@1 0.9219 (0.9905) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:38:34] __main__ INFO: \u001b[0mEpoch 45 Step 703/703 lr 0.001000 loss 0.0429 (0.0332) acc@1 0.9844 (0.9905) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:38:34] __main__ INFO: \u001b[0mElapsed 222.33\n",
      "\u001b[32m[2020-07-02 06:38:34] __main__ INFO: \u001b[0mVal 45\n",
      "\u001b[32m[2020-07-02 06:38:41] __main__ INFO: \u001b[0mEpoch 45 loss 0.3212 acc@1 0.9178 acc@5 0.9970\n",
      "\u001b[32m[2020-07-02 06:38:41] __main__ INFO: \u001b[0mElapsed 7.70\n",
      "\u001b[32m[2020-07-02 06:38:41] __main__ INFO: \u001b[0mTrain 46 31635\n",
      "\u001b[32m[2020-07-02 06:39:13] __main__ INFO: \u001b[0mEpoch 46 Step 100/703 lr 0.001000 loss 0.0140 (0.0299) acc@1 1.0000 (0.9928) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:39:45] __main__ INFO: \u001b[0mEpoch 46 Step 200/703 lr 0.001000 loss 0.0172 (0.0300) acc@1 1.0000 (0.9916) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:40:16] __main__ INFO: \u001b[0mEpoch 46 Step 300/703 lr 0.001000 loss 0.0072 (0.0304) acc@1 1.0000 (0.9916) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:40:48] __main__ INFO: \u001b[0mEpoch 46 Step 400/703 lr 0.001000 loss 0.0110 (0.0311) acc@1 1.0000 (0.9912) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:41:20] __main__ INFO: \u001b[0mEpoch 46 Step 500/703 lr 0.001000 loss 0.0224 (0.0316) acc@1 1.0000 (0.9910) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:41:51] __main__ INFO: \u001b[0mEpoch 46 Step 600/703 lr 0.001000 loss 0.0409 (0.0314) acc@1 0.9688 (0.9909) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:42:23] __main__ INFO: \u001b[0mEpoch 46 Step 700/703 lr 0.001000 loss 0.0386 (0.0316) acc@1 0.9844 (0.9906) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:42:24] __main__ INFO: \u001b[0mEpoch 46 Step 703/703 lr 0.001000 loss 0.0486 (0.0316) acc@1 0.9844 (0.9907) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:42:24] __main__ INFO: \u001b[0mElapsed 222.64\n",
      "\u001b[32m[2020-07-02 06:42:24] __main__ INFO: \u001b[0mVal 46\n",
      "\u001b[32m[2020-07-02 06:42:32] __main__ INFO: \u001b[0mEpoch 46 loss 0.3243 acc@1 0.9152 acc@5 0.9970\n",
      "\u001b[32m[2020-07-02 06:42:32] __main__ INFO: \u001b[0mElapsed 7.66\n",
      "\u001b[32m[2020-07-02 06:42:32] __main__ INFO: \u001b[0mTrain 47 32338\n",
      "\u001b[32m[2020-07-02 06:43:03] __main__ INFO: \u001b[0mEpoch 47 Step 100/703 lr 0.001000 loss 0.0111 (0.0286) acc@1 1.0000 (0.9927) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:43:35] __main__ INFO: \u001b[0mEpoch 47 Step 200/703 lr 0.001000 loss 0.0164 (0.0290) acc@1 1.0000 (0.9922) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:44:07] __main__ INFO: \u001b[0mEpoch 47 Step 300/703 lr 0.001000 loss 0.0114 (0.0281) acc@1 1.0000 (0.9930) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:44:38] __main__ INFO: \u001b[0mEpoch 47 Step 400/703 lr 0.001000 loss 0.0336 (0.0282) acc@1 1.0000 (0.9932) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:45:10] __main__ INFO: \u001b[0mEpoch 47 Step 500/703 lr 0.001000 loss 0.0420 (0.0287) acc@1 0.9844 (0.9930) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:45:41] __main__ INFO: \u001b[0mEpoch 47 Step 600/703 lr 0.001000 loss 0.0043 (0.0290) acc@1 1.0000 (0.9927) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:46:13] __main__ INFO: \u001b[0mEpoch 47 Step 700/703 lr 0.001000 loss 0.0136 (0.0294) acc@1 1.0000 (0.9924) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:46:14] __main__ INFO: \u001b[0mEpoch 47 Step 703/703 lr 0.001000 loss 0.0654 (0.0294) acc@1 0.9688 (0.9924) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:46:14] __main__ INFO: \u001b[0mElapsed 222.44\n",
      "\u001b[32m[2020-07-02 06:46:14] __main__ INFO: \u001b[0mVal 47\n",
      "\u001b[32m[2020-07-02 06:46:22] __main__ INFO: \u001b[0mEpoch 47 loss 0.3253 acc@1 0.9164 acc@5 0.9972\n",
      "\u001b[32m[2020-07-02 06:46:22] __main__ INFO: \u001b[0mElapsed 7.66\n",
      "\u001b[32m[2020-07-02 06:46:22] __main__ INFO: \u001b[0mTrain 48 33041\n",
      "\u001b[32m[2020-07-02 06:46:53] __main__ INFO: \u001b[0mEpoch 48 Step 100/703 lr 0.001000 loss 0.0375 (0.0282) acc@1 0.9844 (0.9919) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:47:25] __main__ INFO: \u001b[0mEpoch 48 Step 200/703 lr 0.001000 loss 0.0196 (0.0283) acc@1 1.0000 (0.9925) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:47:57] __main__ INFO: \u001b[0mEpoch 48 Step 300/703 lr 0.001000 loss 0.0407 (0.0281) acc@1 0.9844 (0.9927) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:48:28] __main__ INFO: \u001b[0mEpoch 48 Step 400/703 lr 0.001000 loss 0.0162 (0.0288) acc@1 1.0000 (0.9922) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:49:00] __main__ INFO: \u001b[0mEpoch 48 Step 500/703 lr 0.001000 loss 0.0054 (0.0299) acc@1 1.0000 (0.9918) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:49:32] __main__ INFO: \u001b[0mEpoch 48 Step 600/703 lr 0.001000 loss 0.0431 (0.0300) acc@1 0.9844 (0.9919) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:50:03] __main__ INFO: \u001b[0mEpoch 48 Step 700/703 lr 0.001000 loss 0.0152 (0.0305) acc@1 1.0000 (0.9917) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:50:04] __main__ INFO: \u001b[0mEpoch 48 Step 703/703 lr 0.001000 loss 0.0033 (0.0305) acc@1 1.0000 (0.9917) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:50:04] __main__ INFO: \u001b[0mElapsed 222.45\n",
      "\u001b[32m[2020-07-02 06:50:04] __main__ INFO: \u001b[0mVal 48\n",
      "\u001b[32m[2020-07-02 06:50:12] __main__ INFO: \u001b[0mEpoch 48 loss 0.3322 acc@1 0.9142 acc@5 0.9974\n",
      "\u001b[32m[2020-07-02 06:50:12] __main__ INFO: \u001b[0mElapsed 7.65\n",
      "\u001b[32m[2020-07-02 06:50:12] __main__ INFO: \u001b[0mTrain 49 33744\n",
      "\u001b[32m[2020-07-02 06:50:43] __main__ INFO: \u001b[0mEpoch 49 Step 100/703 lr 0.001000 loss 0.0192 (0.0292) acc@1 1.0000 (0.9920) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:51:15] __main__ INFO: \u001b[0mEpoch 49 Step 200/703 lr 0.001000 loss 0.0218 (0.0305) acc@1 1.0000 (0.9918) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:51:47] __main__ INFO: \u001b[0mEpoch 49 Step 300/703 lr 0.001000 loss 0.0293 (0.0292) acc@1 0.9844 (0.9921) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:52:18] __main__ INFO: \u001b[0mEpoch 49 Step 400/703 lr 0.001000 loss 0.0189 (0.0287) acc@1 1.0000 (0.9921) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:52:50] __main__ INFO: \u001b[0mEpoch 49 Step 500/703 lr 0.001000 loss 0.0216 (0.0282) acc@1 1.0000 (0.9925) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:53:22] __main__ INFO: \u001b[0mEpoch 49 Step 600/703 lr 0.001000 loss 0.0078 (0.0284) acc@1 1.0000 (0.9924) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:53:53] __main__ INFO: \u001b[0mEpoch 49 Step 700/703 lr 0.001000 loss 0.0213 (0.0283) acc@1 1.0000 (0.9923) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:53:54] __main__ INFO: \u001b[0mEpoch 49 Step 703/703 lr 0.001000 loss 0.0273 (0.0283) acc@1 0.9844 (0.9923) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:53:54] __main__ INFO: \u001b[0mElapsed 222.54\n",
      "\u001b[32m[2020-07-02 06:53:54] __main__ INFO: \u001b[0mVal 49\n",
      "\u001b[32m[2020-07-02 06:54:02] __main__ INFO: \u001b[0mEpoch 49 loss 0.3205 acc@1 0.9178 acc@5 0.9976\n",
      "\u001b[32m[2020-07-02 06:54:02] __main__ INFO: \u001b[0mElapsed 7.65\n",
      "\u001b[32m[2020-07-02 06:54:02] __main__ INFO: \u001b[0mTrain 50 34447\n",
      "\u001b[32m[2020-07-02 06:54:34] __main__ INFO: \u001b[0mEpoch 50 Step 100/703 lr 0.001000 loss 0.0199 (0.0262) acc@1 1.0000 (0.9923) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:55:05] __main__ INFO: \u001b[0mEpoch 50 Step 200/703 lr 0.001000 loss 0.0511 (0.0294) acc@1 0.9844 (0.9916) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:55:37] __main__ INFO: \u001b[0mEpoch 50 Step 300/703 lr 0.001000 loss 0.0590 (0.0275) acc@1 0.9844 (0.9930) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:56:09] __main__ INFO: \u001b[0mEpoch 50 Step 400/703 lr 0.001000 loss 0.0129 (0.0281) acc@1 1.0000 (0.9928) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:56:40] __main__ INFO: \u001b[0mEpoch 50 Step 500/703 lr 0.001000 loss 0.0167 (0.0278) acc@1 1.0000 (0.9929) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:57:12] __main__ INFO: \u001b[0mEpoch 50 Step 600/703 lr 0.001000 loss 0.0200 (0.0280) acc@1 1.0000 (0.9929) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:57:43] __main__ INFO: \u001b[0mEpoch 50 Step 700/703 lr 0.001000 loss 0.0515 (0.0281) acc@1 0.9844 (0.9929) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:57:44] __main__ INFO: \u001b[0mEpoch 50 Step 703/703 lr 0.001000 loss 0.0238 (0.0282) acc@1 1.0000 (0.9929) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-02 06:57:44] __main__ INFO: \u001b[0mElapsed 222.51\n",
      "\u001b[32m[2020-07-02 06:57:44] __main__ INFO: \u001b[0mVal 50\n",
      "\u001b[32m[2020-07-02 06:57:52] __main__ INFO: \u001b[0mEpoch 50 loss 0.3251 acc@1 0.9152 acc@5 0.9974\n",
      "\u001b[32m[2020-07-02 06:57:52] __main__ INFO: \u001b[0mElapsed 7.69\n",
      "\u001b[32m[2020-07-02 06:57:52] fvcore.common.checkpoint INFO: \u001b[0mSaving checkpoint to /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_2_20_c10val/exp00_resume400_50/checkpoint_00050.pth\n"
     ]
    }
   ],
   "source": [
    "# Resume training with the un-augmented data\n",
    "os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "!python train.py --config /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_2_20_c10val/exp00/config.yaml \\\n",
    "    train.checkpoint /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_2_20_c10val/exp00/checkpoint_00400.pth \\\n",
    "    dataset.name CIFAR10 \\\n",
    "    train.base_lr .001 \\\n",
    "    train.output_dir /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_2_20_c10val/exp00_resume400_50 \\\n",
    "    scheduler.epochs 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-02 12:22:41] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_2_20_c10val/exp00_resume400_50/checkpoint_00050.pth\n",
      "Files already downloaded and verified\n",
      "100%|| 157/157 [00:19<00:00,  8.17it/s]\n",
      "\u001b[32m[2020-07-02 12:23:01] __main__ INFO: \u001b[0mElapsed 19.22\n",
      "\u001b[32m[2020-07-02 12:23:01] __main__ INFO: \u001b[0mLoss 0.3482 Accuracy 0.9123\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10 test dataset \n",
    "# Write the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/densenet.yaml \\\n",
    "   model.densenet.depth 100 \\\n",
    "   model.densenet.growth_rate 12 \\\n",
    "   test.batch_size 64 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_2_20_c10val/exp00_resume400_50/checkpoint_00050.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_2_20_c10val/exp00_resume400_50/test_results_0050_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-02 12:24:06] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_2_20_c10val/exp00/checkpoint_00400.pth\n",
      "Files already downloaded and verified\n",
      "100%|| 157/157 [00:19<00:00,  8.21it/s]\n",
      "\u001b[32m[2020-07-02 12:24:26] __main__ INFO: \u001b[0mElapsed 19.13\n",
      "\u001b[32m[2020-07-02 12:24:26] __main__ INFO: \u001b[0mLoss 1.0119 Accuracy 0.8154\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10 test dataset \n",
    "# Write the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/densenet.yaml \\\n",
    "   model.densenet.depth 100 \\\n",
    "   model.densenet.growth_rate 12 \\\n",
    "   test.batch_size 64 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_2_20_c10val/exp00/checkpoint_00400.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_2_20_c10val/exp00/test_results_0400_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-02 12:25:26] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_2_20_c10val/exp00_resume400_50/checkpoint_00050.pth\n",
      "CIFAR 10.1\n",
      "100%|| 32/32 [00:04<00:00,  7.67it/s]\n",
      "\u001b[32m[2020-07-02 12:25:31] __main__ INFO: \u001b[0mElapsed 4.17\n",
      "\u001b[32m[2020-07-02 12:25:31] __main__ INFO: \u001b[0mLoss 0.7125 Accuracy 0.8315\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10.1 test dataset \n",
    "# Write the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/densenet.yaml \\\n",
    "   model.densenet.depth 100 \\\n",
    "   model.densenet.growth_rate 12 \\\n",
    "   test.batch_size 64 \\\n",
    "   dataset.name CIFAR101 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_2_20_c10val/exp00_resume400_50/checkpoint_00050.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_2_20_c10val/exp00_resume400_50/test_results_0050_cifar101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-02 12:28:28] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_2_20_c10val/exp00/checkpoint_00400.pth\n",
      "CIFAR 10.1\n",
      "100%|| 32/32 [00:04<00:00,  7.64it/s]\n",
      "\u001b[32m[2020-07-02 12:28:33] __main__ INFO: \u001b[0mElapsed 4.19\n",
      "\u001b[32m[2020-07-02 12:28:33] __main__ INFO: \u001b[0mLoss 1.8176 Accuracy 0.6815\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10.1 test dataset \n",
    "# Write the results to the test output directory specified.\n",
    "os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "!python evaluate.py --config configs/cifar/densenet.yaml \\\n",
    "    model.densenet.depth 100 \\\n",
    "    model.densenet.growth_rate 12 \\\n",
    "    test.batch_size 64 \\\n",
    "    dataset.name CIFAR101 \\\n",
    "    test.checkpoint /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_2_20_c10val/exp00/checkpoint_00400.pth \\\n",
    "    test.output_dir /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_2_20_c10val/exp00/test_results_0400_cifar101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-02 12:29:35] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_2_20_c10val/exp00/checkpoint_00300.pth\n",
      "Files already downloaded and verified\n",
      "100%|| 157/157 [00:19<00:00,  8.19it/s]\n",
      "\u001b[32m[2020-07-02 12:29:55] __main__ INFO: \u001b[0mElapsed 19.18\n",
      "\u001b[32m[2020-07-02 12:29:55] __main__ INFO: \u001b[0mLoss 0.9771 Accuracy 0.8119\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10 test dataset \n",
    "# Write the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/densenet.yaml \\\n",
    "   model.densenet.depth 100 \\\n",
    "   model.densenet.growth_rate 12 \\\n",
    "   test.batch_size 64 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_2_20_c10val/exp00/checkpoint_00300.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_2_20_c10val/exp00/test_results_0300_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-02 12:30:19] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_2_20_c10val/exp00/checkpoint_00300.pth\n",
      "CIFAR 10.1\n",
      "100%|| 32/32 [00:04<00:00,  7.64it/s]\n",
      "\u001b[32m[2020-07-02 12:30:23] __main__ INFO: \u001b[0mElapsed 4.19\n",
      "\u001b[32m[2020-07-02 12:30:23] __main__ INFO: \u001b[0mLoss 1.7810 Accuracy 0.6745\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10 test dataset \n",
    "# Write the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/densenet.yaml \\\n",
    "   model.densenet.depth 100 \\\n",
    "   model.densenet.growth_rate 12 \\\n",
    "   test.batch_size 64 \\\n",
    "   dataset.name CIFAR101 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_2_20_c10val/exp00/checkpoint_00300.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_2_20_c10val/exp00/test_results_0300_cifar101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the results to a CSV file so that we can analyze later.\n",
    "import pandas as pd\n",
    "\n",
    "results = {'Model': ['densenet_BC_100_12', 'densenet_BC_100_12', 'densenet_BC_100_12', 'densenet_BC_100_12'],\n",
    "           'Testset': ['cifar10', 'cifar10', 'cifar10', 'cifar10.1'],\n",
    "           'Epoch': [100, 200, 300, 300],\n",
    "           'Loss': [0.3681, 0.2279, 0.2223, 0.5098],\n",
    "           'Accuracy': [0.8875, 0.9456, 0.9484, 0.8830],\n",
    "           'Original_Accuracy': [95.5, 95.5, 95.5, 87.6],\n",
    "           'Original_CI': [(95.1, 95.9), (95.1, 95.9), (95.1, 95.9), (86.1, 89.0)]\n",
    "           }\n",
    "\n",
    "df = pd.DataFrame(results, columns = ['Model', 'Testset', 'Epoch', 'Loss', 'Accuracy', \n",
    "                                      'Original_Accuracy', 'Original_CI'])\n",
    "\n",
    "\n",
    "df.to_csv('/home/ec2-user/SageMaker/experiments/densenet_BC_100_12/exp00/results.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Testset</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Original_Accuracy</th>\n",
       "      <th>Original_CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>densenet_BC_100_12_ra_2_20_c10val</td>\n",
       "      <td>400</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>1.0119</td>\n",
       "      <td>0.8154</td>\n",
       "      <td>95.5</td>\n",
       "      <td>(95.1, 95.9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>densenet_BC_100_12_ra_2_20_c10val</td>\n",
       "      <td>300</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>0.9771</td>\n",
       "      <td>0.8119</td>\n",
       "      <td>95.5</td>\n",
       "      <td>(95.1, 95.9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>densenet_BC_100_12_ra_2_20_c10val</td>\n",
       "      <td>400</td>\n",
       "      <td>cifar10.1</td>\n",
       "      <td>1.8176</td>\n",
       "      <td>0.6815</td>\n",
       "      <td>87.6</td>\n",
       "      <td>(86.1, 89.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>densenet_BC_100_12_ra_2_20_c10val</td>\n",
       "      <td>300</td>\n",
       "      <td>cifar10.1</td>\n",
       "      <td>1.781</td>\n",
       "      <td>0.6745</td>\n",
       "      <td>87.6</td>\n",
       "      <td>(86.1, 89.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>densenet_BC_100_12_ra_2_20_refined400_c10val</td>\n",
       "      <td>50</td>\n",
       "      <td>cifar10.1</td>\n",
       "      <td>0.7125</td>\n",
       "      <td>0.8315</td>\n",
       "      <td>87.6</td>\n",
       "      <td>(86.1, 89.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>densenet_BC_100_12_ra_2_20_refined400_c10val</td>\n",
       "      <td>50</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>0.3482</td>\n",
       "      <td>0.9123</td>\n",
       "      <td>95.5</td>\n",
       "      <td>(95.1, 95.9)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Model Epoch    Testset    Loss  \\\n",
       "0             densenet_BC_100_12_ra_2_20_c10val   400    cifar10  1.0119   \n",
       "1             densenet_BC_100_12_ra_2_20_c10val   300    cifar10  0.9771   \n",
       "2             densenet_BC_100_12_ra_2_20_c10val   400  cifar10.1  1.8176   \n",
       "3             densenet_BC_100_12_ra_2_20_c10val   300  cifar10.1   1.781   \n",
       "4  densenet_BC_100_12_ra_2_20_refined400_c10val    50  cifar10.1  0.7125   \n",
       "5  densenet_BC_100_12_ra_2_20_refined400_c10val    50    cifar10  0.3482   \n",
       "\n",
       "  Accuracy  Original_Accuracy   Original_CI  \n",
       "0   0.8154               95.5  (95.1, 95.9)  \n",
       "1   0.8119               95.5  (95.1, 95.9)  \n",
       "2   0.6815               87.6  (86.1, 89.0)  \n",
       "3   0.6745               87.6  (86.1, 89.0)  \n",
       "4   0.8315               87.6  (86.1, 89.0)  \n",
       "5   0.9123               95.5  (95.1, 95.9)  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "a = pd.Series(['densenet_BC_100_12_ra_2_20_c10val', 400, 'cifar10', 1.0119, 0.8154])\n",
    "b = pd.Series(['densenet_BC_100_12_ra_2_20_c10val', 300, 'cifar10', 0.9771, 0.8119])\n",
    "c = pd.Series(['densenet_BC_100_12_ra_2_20_c10val', 400, 'cifar10.1', 1.8176, 0.6815])\n",
    "d = pd.Series(['densenet_BC_100_12_ra_2_20_c10val', 300, 'cifar10.1', 1.7810, 0.6745])\n",
    "\n",
    "e = pd.Series(['densenet_BC_100_12_ra_2_20_refined400_c10val', 50, 'cifar10.1', 0.7125, 0.8315])\n",
    "f = pd.Series(['densenet_BC_100_12_ra_2_20_refined400_c10val', 50, 'cifar10', 0.3482, 0.9123])\n",
    "# g = pd.Series(['resnet_basic_32_ra_2_5_refined300', 150, 'cifar10', 0.4499, 0.8795])\n",
    "# h = pd.Series(['resnet_basic_32_ra_2_5_refined300', 150, 'cifar10.1', 0.8206, 0.7710])\n",
    "               \n",
    "df_results = pd.concat([a,b,c,d,e,f], axis=1).T\n",
    "df_results.columns = ['Model', 'Epoch', 'Testset', 'Loss', 'Accuracy']\n",
    "\n",
    "df_results['Original_Accuracy'] = df_results.apply((lambda row: 95.5 if row[2] == 'cifar10' else 87.6), axis=1)\n",
    "df_results['Original_CI'] = df_results.apply((lambda row: (95.1, 95.9) if row[2] == 'cifar10' else (86.1, 89.0)), axis=1)\n",
    "\n",
    "df_results.to_csv('/home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_2_20_c10val/results.csv')\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peak inside the output file for predictions\n",
    "import numpy as np\n",
    "output = '/home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_2_20_c10val/exp00/test_results_0400/predictions.npz'\n",
    "npzfile = np.load(output)\n",
    "print(npzfile.files)\n",
    "npzfile['preds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the model checkpoints, configs, and results to S3 \n",
    "bucket='sagemaker-june29'\n",
    "prefix = 'sagemaker/results/original-models/densenet_BC_100_12_ra_2_20_c10val'\n",
    "path = '/home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_2_20_c10val'\n",
    "\n",
    "s3_resource = boto3.resource(\"s3\", region_name=\"us-east-2\")\n",
    "\n",
    "def uploadDirectory(local_path,bucket_name,s3_prefix):\n",
    "\n",
    "    my_bucket = s3_resource.Bucket(bucket_name)\n",
    "    \n",
    "    for path, subdirs, files in os.walk(local_path):\n",
    "        path = path.replace(\"\\\\\",\"/\")\n",
    "        directory_name = path.replace(local_path,\"\")\n",
    "        for file in files:\n",
    "            #print(\"Local File:\", os.path.join(path, file))\n",
    "            #print(\"      Dest:\", s3_prefix+directory_name+'/'+file)\n",
    "            my_bucket.upload_file(os.path.join(path, file), s3_prefix+directory_name+'/'+file)\n",
    "    \n",
    "uploadDirectory(path,bucket,prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
