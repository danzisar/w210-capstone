{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DenseNet\n",
    "\n",
    " - Training Dataset:  RandAugment, N=1, M=20\n",
    "   Validation with Unaugmented Data\n",
    " - Sagemaker Notebook must be of type, conda_pytorch_p36\n",
    " \n",
    "#### Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy \n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 1)) (1.18.1)\n",
      "Requirement already satisfied: torch>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 2)) (1.4.0)\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 3)) (0.5.0)\n",
      "Requirement already satisfied: fvcore in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (0.1.1.post20200716)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 5)) (4.44.1)\n",
      "Requirement already satisfied: yacs in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 6)) (0.1.7)\n",
      "Requirement already satisfied: apex from git+https://github.com/NVIDIA/apex.git#egg=apex in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 7)) (0.1)\n",
      "Requirement already satisfied: termcolor in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 8)) (1.1.0)\n",
      "Requirement already satisfied: thop<0.0.31.post2004070130 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 9)) (0.0.31.post2001170342)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 3)) (1.14.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 3)) (7.0.0)\n",
      "Requirement already satisfied: portalocker in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from fvcore->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (1.7.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from fvcore->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (5.3.1)\n",
      "Requirement already satisfied: tabulate in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from fvcore->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (0.8.7)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: tensorboard in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (2.2.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.4.1)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (3.12.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.19.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (3.2.2)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.30.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.18.1)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.34.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.0.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.9.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (2.23.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (46.1.3.post20200330)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.7.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.14.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard) (3.4.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.1.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (1.5.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.4.5.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (1.25.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard) (2.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r '/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt'\n",
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-19 11:10:55] __main__ INFO: \u001b[0mdevice: cuda\n",
      "cudnn:\n",
      "  benchmark: True\n",
      "  deterministic: False\n",
      "dataset:\n",
      "  name: CIFAR10_RA_1_20\n",
      "  dataset_dir: ''\n",
      "  image_size: 32\n",
      "  n_channels: 3\n",
      "  n_classes: 10\n",
      "model:\n",
      "  type: cifar\n",
      "  name: densenet\n",
      "  init_mode: kaiming_fan_out\n",
      "  vgg:\n",
      "    n_channels: [64, 128, 256, 512, 512]\n",
      "    n_layers: [2, 2, 3, 3, 3]\n",
      "    use_bn: True\n",
      "  resnet:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "  resnet_preact:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "  wrn:\n",
      "    depth: 28\n",
      "    initial_channels: 16\n",
      "    widening_factor: 10\n",
      "    drop_rate: 0.0\n",
      "  densenet:\n",
      "    depth: 100\n",
      "    n_blocks: [6, 12, 24, 16]\n",
      "    block_type: bottleneck\n",
      "    growth_rate: 12\n",
      "    drop_rate: 0.0\n",
      "    compression_rate: 0.5\n",
      "  pyramidnet:\n",
      "    depth: 272\n",
      "    n_blocks: [3, 24, 36, 3]\n",
      "    initial_channels: 16\n",
      "    block_type: bottleneck\n",
      "    alpha: 200\n",
      "  resnext:\n",
      "    depth: 29\n",
      "    n_blocks: [3, 4, 6, 3]\n",
      "    initial_channels: 64\n",
      "    cardinality: 8\n",
      "    base_channels: 4\n",
      "  shake_shake:\n",
      "    depth: 26\n",
      "    initial_channels: 96\n",
      "    shake_forward: True\n",
      "    shake_backward: True\n",
      "    shake_image: True\n",
      "  se_resnet_preact:\n",
      "    depth: 110\n",
      "    initial_channels: 16\n",
      "    se_reduction: 16\n",
      "    block_type: basic\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "train:\n",
      "  checkpoint: ''\n",
      "  resume: False\n",
      "  precision: O0\n",
      "  batch_size: 64\n",
      "  subdivision: 1\n",
      "  optimizer: sgd\n",
      "  base_lr: 0.1\n",
      "  momentum: 0.9\n",
      "  nesterov: True\n",
      "  weight_decay: 0.0001\n",
      "  no_weight_decay_on_bn: False\n",
      "  gradient_clip: 0\n",
      "  start_epoch: 0\n",
      "  seed: 0\n",
      "  val_first: True\n",
      "  val_period: 1\n",
      "  val_ratio: 0.1\n",
      "  use_test_as_val: False\n",
      "  output_dir: /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_1_20_c10val/exp00\n",
      "  log_period: 100\n",
      "  checkpoint_period: 100\n",
      "  use_tensorboard: True\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: True\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "  distributed: False\n",
      "  dist:\n",
      "    backend: nccl\n",
      "    init_method: env://\n",
      "    world_size: -1\n",
      "    node_rank: -1\n",
      "    local_rank: 0\n",
      "    use_sync_bn: False\n",
      "tensorboard:\n",
      "  train_images: False\n",
      "  val_images: False\n",
      "  model_params: False\n",
      "optim:\n",
      "  adam:\n",
      "    betas: (0.9, 0.999)\n",
      "  lars:\n",
      "    eps: 1e-09\n",
      "    threshold: 0.01\n",
      "  adabound:\n",
      "    betas: (0.9, 0.999)\n",
      "    final_lr: 0.1\n",
      "    gamma: 0.001\n",
      "scheduler:\n",
      "  epochs: 400\n",
      "  warmup:\n",
      "    type: none\n",
      "    epochs: 0\n",
      "    start_factor: 0.001\n",
      "    exponent: 4\n",
      "  type: multistep\n",
      "  milestones: [150, 225]\n",
      "  lr_decay: 0.1\n",
      "  lr_min_factor: 0.001\n",
      "  T0: 10\n",
      "  T_mul: 1.0\n",
      "validation:\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: False\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "augmentation:\n",
      "  use_random_crop: True\n",
      "  use_random_horizontal_flip: True\n",
      "  use_cutout: False\n",
      "  use_random_erasing: False\n",
      "  use_dual_cutout: False\n",
      "  use_mixup: False\n",
      "  use_ricap: False\n",
      "  use_cutmix: False\n",
      "  use_label_smoothing: False\n",
      "  random_crop:\n",
      "    padding: 4\n",
      "    fill: 0\n",
      "    padding_mode: constant\n",
      "  random_horizontal_flip:\n",
      "    prob: 0.5\n",
      "  cutout:\n",
      "    prob: 1.0\n",
      "    mask_size: 16\n",
      "    cut_inside: False\n",
      "    mask_color: 0\n",
      "    dual_cutout_alpha: 0.1\n",
      "  random_erasing:\n",
      "    prob: 0.5\n",
      "    area_ratio_range: [0.02, 0.4]\n",
      "    min_aspect_ratio: 0.3\n",
      "    max_attempt: 20\n",
      "  mixup:\n",
      "    alpha: 1.0\n",
      "  ricap:\n",
      "    beta: 0.3\n",
      "  cutmix:\n",
      "    alpha: 1.0\n",
      "  label_smoothing:\n",
      "    epsilon: 0.1\n",
      "tta:\n",
      "  use_resize: False\n",
      "  use_center_crop: False\n",
      "  resize: 256\n",
      "test:\n",
      "  checkpoint: ''\n",
      "  output_dir: ''\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    pin_memory: False\n",
      "\u001b[32m[2020-07-19 11:10:55] __main__ INFO: \u001b[0menv_info:\n",
      "  pytorch_version: 1.4.0\n",
      "  cuda_version: 10.1\n",
      "  cudnn_version: 7603\n",
      "  num_gpus: 1\n",
      "  gpu_name: Tesla K80\n",
      "  gpu_capability: 3.7\n",
      "Files already downloaded and verified\n",
      "\u001b[32m[2020-07-19 11:11:01] __main__ INFO: \u001b[0mMACs  : 296.49M\n",
      "\u001b[32m[2020-07-19 11:11:01] __main__ INFO: \u001b[0m#params: 769.16K\n",
      "Selected optimization level O0:  Pure FP32 training.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n",
      "\u001b[32m[2020-07-19 11:11:01] __main__ INFO: \u001b[0mVal 0\n",
      "\u001b[32m[2020-07-19 11:11:13] __main__ INFO: \u001b[0mEpoch 0 loss 30056578.9952 acc@1 0.1012 acc@5 0.5040\n",
      "\u001b[32m[2020-07-19 11:11:13] __main__ INFO: \u001b[0mElapsed 11.38\n",
      "\u001b[32m[2020-07-19 11:11:13] __main__ INFO: \u001b[0mTrain 1 0\n",
      "\u001b[32m[2020-07-19 11:11:46] __main__ INFO: \u001b[0mEpoch 1 Step 100/703 lr 0.100000 loss 2.3886 (2.8510) acc@1 0.0938 (0.1272) acc@5 0.6875 (0.5444)\n",
      "\u001b[32m[2020-07-19 11:12:18] __main__ INFO: \u001b[0mEpoch 1 Step 200/703 lr 0.100000 loss 2.2773 (2.5866) acc@1 0.1250 (0.1359) acc@5 0.6406 (0.5760)\n",
      "\u001b[32m[2020-07-19 11:12:50] __main__ INFO: \u001b[0mEpoch 1 Step 300/703 lr 0.100000 loss 2.1984 (2.4758) acc@1 0.1719 (0.1446) acc@5 0.5625 (0.5969)\n",
      "\u001b[32m[2020-07-19 11:13:22] __main__ INFO: \u001b[0mEpoch 1 Step 400/703 lr 0.100000 loss 2.2004 (2.4104) acc@1 0.2344 (0.1520) acc@5 0.6406 (0.6112)\n",
      "\u001b[32m[2020-07-19 11:13:54] __main__ INFO: \u001b[0mEpoch 1 Step 500/703 lr 0.100000 loss 2.0595 (2.3594) acc@1 0.1875 (0.1603) acc@5 0.7500 (0.6263)\n",
      "\u001b[32m[2020-07-19 11:14:26] __main__ INFO: \u001b[0mEpoch 1 Step 600/703 lr 0.100000 loss 2.1873 (2.3226) acc@1 0.1719 (0.1671) acc@5 0.6719 (0.6374)\n",
      "\u001b[32m[2020-07-19 11:14:58] __main__ INFO: \u001b[0mEpoch 1 Step 700/703 lr 0.100000 loss 2.0041 (2.2907) acc@1 0.2031 (0.1738) acc@5 0.7969 (0.6477)\n",
      "\u001b[32m[2020-07-19 11:14:59] __main__ INFO: \u001b[0mEpoch 1 Step 703/703 lr 0.100000 loss 2.0944 (2.2899) acc@1 0.2031 (0.1739) acc@5 0.7188 (0.6479)\n",
      "\u001b[32m[2020-07-19 11:14:59] __main__ INFO: \u001b[0mElapsed 226.21\n",
      "\u001b[32m[2020-07-19 11:14:59] __main__ INFO: \u001b[0mVal 1\n",
      "\u001b[32m[2020-07-19 11:15:06] __main__ INFO: \u001b[0mEpoch 1 loss 1.7994 acc@1 0.3256 acc@5 0.8618\n",
      "\u001b[32m[2020-07-19 11:15:06] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-19 11:15:06] __main__ INFO: \u001b[0mTrain 2 703\n",
      "\u001b[32m[2020-07-19 11:15:39] __main__ INFO: \u001b[0mEpoch 2 Step 100/703 lr 0.100000 loss 2.1310 (2.0766) acc@1 0.1875 (0.2195) acc@5 0.6719 (0.7153)\n",
      "\u001b[32m[2020-07-19 11:16:11] __main__ INFO: \u001b[0mEpoch 2 Step 200/703 lr 0.100000 loss 2.0824 (2.0668) acc@1 0.1562 (0.2272) acc@5 0.7344 (0.7204)\n",
      "\u001b[32m[2020-07-19 11:16:43] __main__ INFO: \u001b[0mEpoch 2 Step 300/703 lr 0.100000 loss 2.1477 (2.0534) acc@1 0.2500 (0.2332) acc@5 0.6719 (0.7274)\n",
      "\u001b[32m[2020-07-19 11:17:15] __main__ INFO: \u001b[0mEpoch 2 Step 400/703 lr 0.100000 loss 2.0377 (2.0389) acc@1 0.2500 (0.2399) acc@5 0.8281 (0.7319)\n",
      "\u001b[32m[2020-07-19 11:17:47] __main__ INFO: \u001b[0mEpoch 2 Step 500/703 lr 0.100000 loss 2.0150 (2.0293) acc@1 0.2969 (0.2463) acc@5 0.7500 (0.7346)\n",
      "\u001b[32m[2020-07-19 11:18:19] __main__ INFO: \u001b[0mEpoch 2 Step 600/703 lr 0.100000 loss 1.9774 (2.0222) acc@1 0.2188 (0.2494) acc@5 0.7344 (0.7370)\n",
      "\u001b[32m[2020-07-19 11:18:51] __main__ INFO: \u001b[0mEpoch 2 Step 700/703 lr 0.100000 loss 1.8818 (2.0148) acc@1 0.2812 (0.2521) acc@5 0.7812 (0.7393)\n",
      "\u001b[32m[2020-07-19 11:18:51] __main__ INFO: \u001b[0mEpoch 2 Step 703/703 lr 0.100000 loss 2.0034 (2.0144) acc@1 0.2188 (0.2523) acc@5 0.7344 (0.7392)\n",
      "\u001b[32m[2020-07-19 11:18:51] __main__ INFO: \u001b[0mElapsed 225.01\n",
      "\u001b[32m[2020-07-19 11:18:51] __main__ INFO: \u001b[0mVal 2\n",
      "\u001b[32m[2020-07-19 11:18:59] __main__ INFO: \u001b[0mEpoch 2 loss 1.5329 acc@1 0.4260 acc@5 0.9082\n",
      "\u001b[32m[2020-07-19 11:18:59] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-19 11:18:59] __main__ INFO: \u001b[0mTrain 3 1406\n",
      "\u001b[32m[2020-07-19 11:19:31] __main__ INFO: \u001b[0mEpoch 3 Step 100/703 lr 0.100000 loss 1.8001 (1.9338) acc@1 0.3281 (0.2866) acc@5 0.8594 (0.7688)\n",
      "\u001b[32m[2020-07-19 11:20:03] __main__ INFO: \u001b[0mEpoch 3 Step 200/703 lr 0.100000 loss 1.8062 (1.9282) acc@1 0.2969 (0.2841) acc@5 0.8281 (0.7664)\n",
      "\u001b[32m[2020-07-19 11:20:35] __main__ INFO: \u001b[0mEpoch 3 Step 300/703 lr 0.100000 loss 1.7949 (1.9102) acc@1 0.2969 (0.2931) acc@5 0.7656 (0.7706)\n",
      "\u001b[32m[2020-07-19 11:21:07] __main__ INFO: \u001b[0mEpoch 3 Step 400/703 lr 0.100000 loss 1.8121 (1.8964) acc@1 0.4844 (0.3010) acc@5 0.8125 (0.7748)\n",
      "\u001b[32m[2020-07-19 11:21:39] __main__ INFO: \u001b[0mEpoch 3 Step 500/703 lr 0.100000 loss 1.7500 (1.8851) acc@1 0.3906 (0.3062) acc@5 0.8125 (0.7778)\n",
      "\u001b[32m[2020-07-19 11:22:11] __main__ INFO: \u001b[0mEpoch 3 Step 600/703 lr 0.100000 loss 1.8505 (1.8748) acc@1 0.2969 (0.3099) acc@5 0.7500 (0.7790)\n",
      "\u001b[32m[2020-07-19 11:22:43] __main__ INFO: \u001b[0mEpoch 3 Step 700/703 lr 0.100000 loss 1.7604 (1.8630) acc@1 0.3750 (0.3142) acc@5 0.7656 (0.7817)\n",
      "\u001b[32m[2020-07-19 11:22:44] __main__ INFO: \u001b[0mEpoch 3 Step 703/703 lr 0.100000 loss 1.7664 (1.8628) acc@1 0.3438 (0.3141) acc@5 0.7969 (0.7817)\n",
      "\u001b[32m[2020-07-19 11:22:44] __main__ INFO: \u001b[0mElapsed 225.03\n",
      "\u001b[32m[2020-07-19 11:22:44] __main__ INFO: \u001b[0mVal 3\n",
      "\u001b[32m[2020-07-19 11:22:52] __main__ INFO: \u001b[0mEpoch 3 loss 1.4278 acc@1 0.4874 acc@5 0.9264\n",
      "\u001b[32m[2020-07-19 11:22:52] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-19 11:22:52] __main__ INFO: \u001b[0mTrain 4 2109\n",
      "\u001b[32m[2020-07-19 11:23:24] __main__ INFO: \u001b[0mEpoch 4 Step 100/703 lr 0.100000 loss 1.5723 (1.7545) acc@1 0.3906 (0.3577) acc@5 0.8750 (0.8002)\n",
      "\u001b[32m[2020-07-19 11:23:56] __main__ INFO: \u001b[0mEpoch 4 Step 200/703 lr 0.100000 loss 1.9716 (1.7516) acc@1 0.2812 (0.3597) acc@5 0.7812 (0.8040)\n",
      "\u001b[32m[2020-07-19 11:24:28] __main__ INFO: \u001b[0mEpoch 4 Step 300/703 lr 0.100000 loss 1.8220 (1.7443) acc@1 0.3750 (0.3616) acc@5 0.8125 (0.8094)\n",
      "\u001b[32m[2020-07-19 11:25:00] __main__ INFO: \u001b[0mEpoch 4 Step 400/703 lr 0.100000 loss 1.6814 (1.7400) acc@1 0.3750 (0.3642) acc@5 0.8438 (0.8106)\n",
      "\u001b[32m[2020-07-19 11:25:32] __main__ INFO: \u001b[0mEpoch 4 Step 500/703 lr 0.100000 loss 1.8245 (1.7390) acc@1 0.3438 (0.3639) acc@5 0.7500 (0.8116)\n",
      "\u001b[32m[2020-07-19 11:26:04] __main__ INFO: \u001b[0mEpoch 4 Step 600/703 lr 0.100000 loss 1.6634 (1.7319) acc@1 0.3594 (0.3672) acc@5 0.8125 (0.8123)\n",
      "\u001b[32m[2020-07-19 11:26:36] __main__ INFO: \u001b[0mEpoch 4 Step 700/703 lr 0.100000 loss 1.6445 (1.7216) acc@1 0.4844 (0.3716) acc@5 0.7969 (0.8143)\n",
      "\u001b[32m[2020-07-19 11:26:37] __main__ INFO: \u001b[0mEpoch 4 Step 703/703 lr 0.100000 loss 1.8852 (1.7219) acc@1 0.3125 (0.3715) acc@5 0.7344 (0.8142)\n",
      "\u001b[32m[2020-07-19 11:26:37] __main__ INFO: \u001b[0mElapsed 225.21\n",
      "\u001b[32m[2020-07-19 11:26:37] __main__ INFO: \u001b[0mVal 4\n",
      "\u001b[32m[2020-07-19 11:26:45] __main__ INFO: \u001b[0mEpoch 4 loss 1.2806 acc@1 0.5556 acc@5 0.9330\n",
      "\u001b[32m[2020-07-19 11:26:45] __main__ INFO: \u001b[0mElapsed 7.85\n",
      "\u001b[32m[2020-07-19 11:26:45] __main__ INFO: \u001b[0mTrain 5 2812\n",
      "\u001b[32m[2020-07-19 11:27:17] __main__ INFO: \u001b[0mEpoch 5 Step 100/703 lr 0.100000 loss 1.4686 (1.6436) acc@1 0.3438 (0.3961) acc@5 0.8281 (0.8213)\n",
      "\u001b[32m[2020-07-19 11:27:49] __main__ INFO: \u001b[0mEpoch 5 Step 200/703 lr 0.100000 loss 1.4969 (1.6367) acc@1 0.4219 (0.4035) acc@5 0.8281 (0.8273)\n",
      "\u001b[32m[2020-07-19 11:28:21] __main__ INFO: \u001b[0mEpoch 5 Step 300/703 lr 0.100000 loss 1.7839 (1.6400) acc@1 0.4688 (0.4038) acc@5 0.7969 (0.8265)\n",
      "\u001b[32m[2020-07-19 11:28:53] __main__ INFO: \u001b[0mEpoch 5 Step 400/703 lr 0.100000 loss 1.7446 (1.6355) acc@1 0.3906 (0.4069) acc@5 0.7344 (0.8272)\n",
      "\u001b[32m[2020-07-19 11:29:25] __main__ INFO: \u001b[0mEpoch 5 Step 500/703 lr 0.100000 loss 1.6533 (1.6273) acc@1 0.3906 (0.4091) acc@5 0.8281 (0.8284)\n",
      "\u001b[32m[2020-07-19 11:29:57] __main__ INFO: \u001b[0mEpoch 5 Step 600/703 lr 0.100000 loss 1.5168 (1.6206) acc@1 0.5156 (0.4102) acc@5 0.9375 (0.8299)\n",
      "\u001b[32m[2020-07-19 11:30:29] __main__ INFO: \u001b[0mEpoch 5 Step 700/703 lr 0.100000 loss 1.5154 (1.6100) acc@1 0.3594 (0.4140) acc@5 0.8594 (0.8316)\n",
      "\u001b[32m[2020-07-19 11:30:30] __main__ INFO: \u001b[0mEpoch 5 Step 703/703 lr 0.100000 loss 1.6276 (1.6108) acc@1 0.4062 (0.4138) acc@5 0.8594 (0.8314)\n",
      "\u001b[32m[2020-07-19 11:30:30] __main__ INFO: \u001b[0mElapsed 225.08\n",
      "\u001b[32m[2020-07-19 11:30:30] __main__ INFO: \u001b[0mVal 5\n",
      "\u001b[32m[2020-07-19 11:30:38] __main__ INFO: \u001b[0mEpoch 5 loss 1.1248 acc@1 0.6026 acc@5 0.9516\n",
      "\u001b[32m[2020-07-19 11:30:38] __main__ INFO: \u001b[0mElapsed 7.79\n",
      "\u001b[32m[2020-07-19 11:30:38] __main__ INFO: \u001b[0mTrain 6 3515\n",
      "\u001b[32m[2020-07-19 11:31:10] __main__ INFO: \u001b[0mEpoch 6 Step 100/703 lr 0.100000 loss 1.4687 (1.5542) acc@1 0.4844 (0.4305) acc@5 0.8281 (0.8425)\n",
      "\u001b[32m[2020-07-19 11:31:42] __main__ INFO: \u001b[0mEpoch 6 Step 200/703 lr 0.100000 loss 1.2822 (1.5404) acc@1 0.5469 (0.4374) acc@5 0.8594 (0.8429)\n",
      "\u001b[32m[2020-07-19 11:32:14] __main__ INFO: \u001b[0mEpoch 6 Step 300/703 lr 0.100000 loss 1.4755 (1.5345) acc@1 0.5312 (0.4396) acc@5 0.8594 (0.8443)\n",
      "\u001b[32m[2020-07-19 11:32:46] __main__ INFO: \u001b[0mEpoch 6 Step 400/703 lr 0.100000 loss 1.6028 (1.5286) acc@1 0.3750 (0.4446) acc@5 0.8750 (0.8436)\n",
      "\u001b[32m[2020-07-19 11:33:18] __main__ INFO: \u001b[0mEpoch 6 Step 500/703 lr 0.100000 loss 1.3386 (1.5244) acc@1 0.5625 (0.4484) acc@5 0.8281 (0.8444)\n",
      "\u001b[32m[2020-07-19 11:33:50] __main__ INFO: \u001b[0mEpoch 6 Step 600/703 lr 0.100000 loss 1.5408 (1.5171) acc@1 0.4219 (0.4509) acc@5 0.7969 (0.8449)\n",
      "\u001b[32m[2020-07-19 11:34:22] __main__ INFO: \u001b[0mEpoch 6 Step 700/703 lr 0.100000 loss 1.5389 (1.5169) acc@1 0.4844 (0.4510) acc@5 0.9531 (0.8443)\n",
      "\u001b[32m[2020-07-19 11:34:23] __main__ INFO: \u001b[0mEpoch 6 Step 703/703 lr 0.100000 loss 1.4169 (1.5163) acc@1 0.5312 (0.4512) acc@5 0.8906 (0.8445)\n",
      "\u001b[32m[2020-07-19 11:34:23] __main__ INFO: \u001b[0mElapsed 224.87\n",
      "\u001b[32m[2020-07-19 11:34:23] __main__ INFO: \u001b[0mVal 6\n",
      "\u001b[32m[2020-07-19 11:34:31] __main__ INFO: \u001b[0mEpoch 6 loss 1.0199 acc@1 0.6416 acc@5 0.9670\n",
      "\u001b[32m[2020-07-19 11:34:31] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-19 11:34:31] __main__ INFO: \u001b[0mTrain 7 4218\n",
      "\u001b[32m[2020-07-19 11:35:03] __main__ INFO: \u001b[0mEpoch 7 Step 100/703 lr 0.100000 loss 1.2124 (1.4525) acc@1 0.4844 (0.4689) acc@5 0.8750 (0.8573)\n",
      "\u001b[32m[2020-07-19 11:35:35] __main__ INFO: \u001b[0mEpoch 7 Step 200/703 lr 0.100000 loss 1.5608 (1.4644) acc@1 0.4062 (0.4657) acc@5 0.8750 (0.8537)\n",
      "\u001b[32m[2020-07-19 11:36:07] __main__ INFO: \u001b[0mEpoch 7 Step 300/703 lr 0.100000 loss 1.5587 (1.4495) acc@1 0.4844 (0.4730) acc@5 0.7812 (0.8534)\n",
      "\u001b[32m[2020-07-19 11:36:39] __main__ INFO: \u001b[0mEpoch 7 Step 400/703 lr 0.100000 loss 1.4589 (1.4424) acc@1 0.4219 (0.4767) acc@5 0.8906 (0.8533)\n",
      "\u001b[32m[2020-07-19 11:37:11] __main__ INFO: \u001b[0mEpoch 7 Step 500/703 lr 0.100000 loss 1.4283 (1.4334) acc@1 0.5156 (0.4801) acc@5 0.8906 (0.8544)\n",
      "\u001b[32m[2020-07-19 11:37:43] __main__ INFO: \u001b[0mEpoch 7 Step 600/703 lr 0.100000 loss 1.3838 (1.4264) acc@1 0.4531 (0.4832) acc@5 0.8438 (0.8565)\n",
      "\u001b[32m[2020-07-19 11:38:15] __main__ INFO: \u001b[0mEpoch 7 Step 700/703 lr 0.100000 loss 1.2719 (1.4206) acc@1 0.5156 (0.4846) acc@5 0.8594 (0.8565)\n",
      "\u001b[32m[2020-07-19 11:38:16] __main__ INFO: \u001b[0mEpoch 7 Step 703/703 lr 0.100000 loss 1.1794 (1.4200) acc@1 0.6094 (0.4849) acc@5 0.9375 (0.8566)\n",
      "\u001b[32m[2020-07-19 11:38:16] __main__ INFO: \u001b[0mElapsed 224.91\n",
      "\u001b[32m[2020-07-19 11:38:16] __main__ INFO: \u001b[0mVal 7\n",
      "\u001b[32m[2020-07-19 11:38:23] __main__ INFO: \u001b[0mEpoch 7 loss 0.8514 acc@1 0.6968 acc@5 0.9742\n",
      "\u001b[32m[2020-07-19 11:38:23] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-19 11:38:23] __main__ INFO: \u001b[0mTrain 8 4921\n",
      "\u001b[32m[2020-07-19 11:38:55] __main__ INFO: \u001b[0mEpoch 8 Step 100/703 lr 0.100000 loss 1.4874 (1.3732) acc@1 0.4219 (0.5052) acc@5 0.7969 (0.8670)\n",
      "\u001b[32m[2020-07-19 11:39:28] __main__ INFO: \u001b[0mEpoch 8 Step 200/703 lr 0.100000 loss 1.2666 (1.3740) acc@1 0.6406 (0.5068) acc@5 0.8594 (0.8642)\n",
      "\u001b[32m[2020-07-19 11:40:00] __main__ INFO: \u001b[0mEpoch 8 Step 300/703 lr 0.100000 loss 1.3443 (1.3764) acc@1 0.6094 (0.5055) acc@5 0.9219 (0.8645)\n",
      "\u001b[32m[2020-07-19 11:40:32] __main__ INFO: \u001b[0mEpoch 8 Step 400/703 lr 0.100000 loss 1.5743 (1.3655) acc@1 0.3906 (0.5071) acc@5 0.8125 (0.8649)\n",
      "\u001b[32m[2020-07-19 11:41:04] __main__ INFO: \u001b[0mEpoch 8 Step 500/703 lr 0.100000 loss 1.4394 (1.3631) acc@1 0.5000 (0.5073) acc@5 0.8750 (0.8645)\n",
      "\u001b[32m[2020-07-19 11:41:36] __main__ INFO: \u001b[0mEpoch 8 Step 600/703 lr 0.100000 loss 1.5626 (1.3612) acc@1 0.4375 (0.5084) acc@5 0.8281 (0.8641)\n",
      "\u001b[32m[2020-07-19 11:42:08] __main__ INFO: \u001b[0mEpoch 8 Step 700/703 lr 0.100000 loss 1.1761 (1.3591) acc@1 0.5781 (0.5083) acc@5 0.9062 (0.8639)\n",
      "\u001b[32m[2020-07-19 11:42:08] __main__ INFO: \u001b[0mEpoch 8 Step 703/703 lr 0.100000 loss 1.2635 (1.3589) acc@1 0.5469 (0.5084) acc@5 0.8281 (0.8638)\n",
      "\u001b[32m[2020-07-19 11:42:09] __main__ INFO: \u001b[0mElapsed 225.17\n",
      "\u001b[32m[2020-07-19 11:42:09] __main__ INFO: \u001b[0mVal 8\n",
      "\u001b[32m[2020-07-19 11:42:16] __main__ INFO: \u001b[0mEpoch 8 loss 0.9147 acc@1 0.6880 acc@5 0.9794\n",
      "\u001b[32m[2020-07-19 11:42:16] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-19 11:42:16] __main__ INFO: \u001b[0mTrain 9 5624\n",
      "\u001b[32m[2020-07-19 11:42:48] __main__ INFO: \u001b[0mEpoch 9 Step 100/703 lr 0.100000 loss 1.3467 (1.3058) acc@1 0.5312 (0.5272) acc@5 0.8281 (0.8719)\n",
      "\u001b[32m[2020-07-19 11:43:20] __main__ INFO: \u001b[0mEpoch 9 Step 200/703 lr 0.100000 loss 1.3567 (1.2994) acc@1 0.4531 (0.5298) acc@5 0.8438 (0.8694)\n",
      "\u001b[32m[2020-07-19 11:43:52] __main__ INFO: \u001b[0mEpoch 9 Step 300/703 lr 0.100000 loss 1.1882 (1.3065) acc@1 0.5156 (0.5252) acc@5 0.9375 (0.8705)\n",
      "\u001b[32m[2020-07-19 11:44:24] __main__ INFO: \u001b[0mEpoch 9 Step 400/703 lr 0.100000 loss 1.3400 (1.3111) acc@1 0.5156 (0.5230) acc@5 0.8594 (0.8678)\n",
      "\u001b[32m[2020-07-19 11:44:56] __main__ INFO: \u001b[0mEpoch 9 Step 500/703 lr 0.100000 loss 1.5950 (1.3100) acc@1 0.4844 (0.5234) acc@5 0.7812 (0.8687)\n",
      "\u001b[32m[2020-07-19 11:45:29] __main__ INFO: \u001b[0mEpoch 9 Step 600/703 lr 0.100000 loss 1.5196 (1.3066) acc@1 0.4375 (0.5239) acc@5 0.8594 (0.8702)\n",
      "\u001b[32m[2020-07-19 11:46:01] __main__ INFO: \u001b[0mEpoch 9 Step 700/703 lr 0.100000 loss 1.5319 (1.3038) acc@1 0.4688 (0.5253) acc@5 0.8438 (0.8702)\n",
      "\u001b[32m[2020-07-19 11:46:02] __main__ INFO: \u001b[0mEpoch 9 Step 703/703 lr 0.100000 loss 1.2765 (1.3037) acc@1 0.6250 (0.5256) acc@5 0.8906 (0.8703)\n",
      "\u001b[32m[2020-07-19 11:46:02] __main__ INFO: \u001b[0mElapsed 225.37\n",
      "\u001b[32m[2020-07-19 11:46:02] __main__ INFO: \u001b[0mVal 9\n",
      "\u001b[32m[2020-07-19 11:46:09] __main__ INFO: \u001b[0mEpoch 9 loss 0.8832 acc@1 0.6956 acc@5 0.9762\n",
      "\u001b[32m[2020-07-19 11:46:09] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-19 11:46:09] __main__ INFO: \u001b[0mTrain 10 6327\n",
      "\u001b[32m[2020-07-19 11:46:42] __main__ INFO: \u001b[0mEpoch 10 Step 100/703 lr 0.100000 loss 1.2275 (1.2498) acc@1 0.5312 (0.5486) acc@5 0.9375 (0.8769)\n",
      "\u001b[32m[2020-07-19 11:47:14] __main__ INFO: \u001b[0mEpoch 10 Step 200/703 lr 0.100000 loss 1.4254 (1.2620) acc@1 0.4531 (0.5451) acc@5 0.8281 (0.8729)\n",
      "\u001b[32m[2020-07-19 11:47:46] __main__ INFO: \u001b[0mEpoch 10 Step 300/703 lr 0.100000 loss 1.2715 (1.2573) acc@1 0.5312 (0.5454) acc@5 0.9062 (0.8719)\n",
      "\u001b[32m[2020-07-19 11:48:18] __main__ INFO: \u001b[0mEpoch 10 Step 400/703 lr 0.100000 loss 1.3173 (1.2595) acc@1 0.5312 (0.5433) acc@5 0.8594 (0.8740)\n",
      "\u001b[32m[2020-07-19 11:48:50] __main__ INFO: \u001b[0mEpoch 10 Step 500/703 lr 0.100000 loss 1.0848 (1.2547) acc@1 0.5938 (0.5433) acc@5 0.9375 (0.8738)\n",
      "\u001b[32m[2020-07-19 11:49:22] __main__ INFO: \u001b[0mEpoch 10 Step 600/703 lr 0.100000 loss 1.2261 (1.2595) acc@1 0.5781 (0.5426) acc@5 0.8750 (0.8720)\n",
      "\u001b[32m[2020-07-19 11:49:54] __main__ INFO: \u001b[0mEpoch 10 Step 700/703 lr 0.100000 loss 1.5009 (1.2623) acc@1 0.4531 (0.5410) acc@5 0.7812 (0.8709)\n",
      "\u001b[32m[2020-07-19 11:49:55] __main__ INFO: \u001b[0mEpoch 10 Step 703/703 lr 0.100000 loss 1.3927 (1.2628) acc@1 0.4688 (0.5407) acc@5 0.8438 (0.8707)\n",
      "\u001b[32m[2020-07-19 11:49:55] __main__ INFO: \u001b[0mElapsed 225.20\n",
      "\u001b[32m[2020-07-19 11:49:55] __main__ INFO: \u001b[0mVal 10\n",
      "\u001b[32m[2020-07-19 11:50:02] __main__ INFO: \u001b[0mEpoch 10 loss 0.7120 acc@1 0.7552 acc@5 0.9852\n",
      "\u001b[32m[2020-07-19 11:50:02] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-19 11:50:02] __main__ INFO: \u001b[0mTrain 11 7030\n",
      "\u001b[32m[2020-07-19 11:50:34] __main__ INFO: \u001b[0mEpoch 11 Step 100/703 lr 0.100000 loss 1.3621 (1.2138) acc@1 0.5000 (0.5553) acc@5 0.8438 (0.8812)\n",
      "\u001b[32m[2020-07-19 11:51:06] __main__ INFO: \u001b[0mEpoch 11 Step 200/703 lr 0.100000 loss 1.3578 (1.2319) acc@1 0.5156 (0.5482) acc@5 0.8281 (0.8714)\n",
      "\u001b[32m[2020-07-19 11:51:38] __main__ INFO: \u001b[0mEpoch 11 Step 300/703 lr 0.100000 loss 1.2005 (1.2384) acc@1 0.5781 (0.5486) acc@5 0.8594 (0.8715)\n",
      "\u001b[32m[2020-07-19 11:52:10] __main__ INFO: \u001b[0mEpoch 11 Step 400/703 lr 0.100000 loss 1.4122 (1.2323) acc@1 0.5938 (0.5505) acc@5 0.8906 (0.8734)\n",
      "\u001b[32m[2020-07-19 11:52:43] __main__ INFO: \u001b[0mEpoch 11 Step 500/703 lr 0.100000 loss 0.8968 (1.2292) acc@1 0.7344 (0.5532) acc@5 0.9688 (0.8743)\n",
      "\u001b[32m[2020-07-19 11:53:15] __main__ INFO: \u001b[0mEpoch 11 Step 600/703 lr 0.100000 loss 1.2344 (1.2280) acc@1 0.5625 (0.5530) acc@5 0.8281 (0.8751)\n",
      "\u001b[32m[2020-07-19 11:53:46] __main__ INFO: \u001b[0mEpoch 11 Step 700/703 lr 0.100000 loss 1.5276 (1.2261) acc@1 0.4375 (0.5547) acc@5 0.8438 (0.8750)\n",
      "\u001b[32m[2020-07-19 11:53:47] __main__ INFO: \u001b[0mEpoch 11 Step 703/703 lr 0.100000 loss 1.1751 (1.2262) acc@1 0.5312 (0.5546) acc@5 0.9062 (0.8749)\n",
      "\u001b[32m[2020-07-19 11:53:47] __main__ INFO: \u001b[0mElapsed 225.07\n",
      "\u001b[32m[2020-07-19 11:53:47] __main__ INFO: \u001b[0mVal 11\n",
      "\u001b[32m[2020-07-19 11:53:55] __main__ INFO: \u001b[0mEpoch 11 loss 0.7613 acc@1 0.7522 acc@5 0.9808\n",
      "\u001b[32m[2020-07-19 11:53:55] __main__ INFO: \u001b[0mElapsed 7.75\n",
      "\u001b[32m[2020-07-19 11:53:55] __main__ INFO: \u001b[0mTrain 12 7733\n",
      "\u001b[32m[2020-07-19 11:54:27] __main__ INFO: \u001b[0mEpoch 12 Step 100/703 lr 0.100000 loss 1.1976 (1.1883) acc@1 0.5469 (0.5606) acc@5 0.9062 (0.8798)\n",
      "\u001b[32m[2020-07-19 11:54:59] __main__ INFO: \u001b[0mEpoch 12 Step 200/703 lr 0.100000 loss 1.1282 (1.1973) acc@1 0.6094 (0.5613) acc@5 0.9062 (0.8773)\n",
      "\u001b[32m[2020-07-19 11:55:31] __main__ INFO: \u001b[0mEpoch 12 Step 300/703 lr 0.100000 loss 1.1791 (1.1910) acc@1 0.5000 (0.5651) acc@5 0.9062 (0.8785)\n",
      "\u001b[32m[2020-07-19 11:56:03] __main__ INFO: \u001b[0mEpoch 12 Step 400/703 lr 0.100000 loss 1.1372 (1.1883) acc@1 0.6562 (0.5672) acc@5 0.8750 (0.8793)\n",
      "\u001b[32m[2020-07-19 11:56:35] __main__ INFO: \u001b[0mEpoch 12 Step 500/703 lr 0.100000 loss 1.2441 (1.1941) acc@1 0.5781 (0.5639) acc@5 0.8594 (0.8786)\n",
      "\u001b[32m[2020-07-19 11:57:07] __main__ INFO: \u001b[0mEpoch 12 Step 600/703 lr 0.100000 loss 1.1997 (1.1975) acc@1 0.5625 (0.5630) acc@5 0.8906 (0.8786)\n",
      "\u001b[32m[2020-07-19 11:57:39] __main__ INFO: \u001b[0mEpoch 12 Step 700/703 lr 0.100000 loss 1.3026 (1.2020) acc@1 0.5156 (0.5619) acc@5 0.8438 (0.8780)\n",
      "\u001b[32m[2020-07-19 11:57:40] __main__ INFO: \u001b[0mEpoch 12 Step 703/703 lr 0.100000 loss 1.0351 (1.2015) acc@1 0.6562 (0.5621) acc@5 0.9062 (0.8781)\n",
      "\u001b[32m[2020-07-19 11:57:40] __main__ INFO: \u001b[0mElapsed 225.03\n",
      "\u001b[32m[2020-07-19 11:57:40] __main__ INFO: \u001b[0mVal 12\n",
      "\u001b[32m[2020-07-19 11:57:48] __main__ INFO: \u001b[0mEpoch 12 loss 0.6927 acc@1 0.7540 acc@5 0.9838\n",
      "\u001b[32m[2020-07-19 11:57:48] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-19 11:57:48] __main__ INFO: \u001b[0mTrain 13 8436\n",
      "\u001b[32m[2020-07-19 11:58:20] __main__ INFO: \u001b[0mEpoch 13 Step 100/703 lr 0.100000 loss 0.9962 (1.1667) acc@1 0.6875 (0.5744) acc@5 0.9219 (0.8853)\n",
      "\u001b[32m[2020-07-19 11:58:52] __main__ INFO: \u001b[0mEpoch 13 Step 200/703 lr 0.100000 loss 1.0285 (1.1685) acc@1 0.6406 (0.5722) acc@5 0.9375 (0.8830)\n",
      "\u001b[32m[2020-07-19 11:59:24] __main__ INFO: \u001b[0mEpoch 13 Step 300/703 lr 0.100000 loss 1.1109 (1.1726) acc@1 0.5781 (0.5735) acc@5 0.9062 (0.8807)\n",
      "\u001b[32m[2020-07-19 11:59:56] __main__ INFO: \u001b[0mEpoch 13 Step 400/703 lr 0.100000 loss 1.2049 (1.1707) acc@1 0.5000 (0.5755) acc@5 0.8750 (0.8822)\n",
      "\u001b[32m[2020-07-19 12:00:28] __main__ INFO: \u001b[0mEpoch 13 Step 500/703 lr 0.100000 loss 1.1355 (1.1711) acc@1 0.5938 (0.5746) acc@5 0.9375 (0.8819)\n",
      "\u001b[32m[2020-07-19 12:01:00] __main__ INFO: \u001b[0mEpoch 13 Step 600/703 lr 0.100000 loss 1.0673 (1.1706) acc@1 0.5938 (0.5738) acc@5 0.9219 (0.8823)\n",
      "\u001b[32m[2020-07-19 12:01:32] __main__ INFO: \u001b[0mEpoch 13 Step 700/703 lr 0.100000 loss 1.2478 (1.1742) acc@1 0.4688 (0.5721) acc@5 0.8750 (0.8805)\n",
      "\u001b[32m[2020-07-19 12:01:33] __main__ INFO: \u001b[0mEpoch 13 Step 703/703 lr 0.100000 loss 1.1630 (1.1742) acc@1 0.5938 (0.5721) acc@5 0.8594 (0.8805)\n",
      "\u001b[32m[2020-07-19 12:01:33] __main__ INFO: \u001b[0mElapsed 225.17\n",
      "\u001b[32m[2020-07-19 12:01:33] __main__ INFO: \u001b[0mVal 13\n",
      "\u001b[32m[2020-07-19 12:01:41] __main__ INFO: \u001b[0mEpoch 13 loss 0.6550 acc@1 0.7772 acc@5 0.9834\n",
      "\u001b[32m[2020-07-19 12:01:41] __main__ INFO: \u001b[0mElapsed 7.75\n",
      "\u001b[32m[2020-07-19 12:01:41] __main__ INFO: \u001b[0mTrain 14 9139\n",
      "\u001b[32m[2020-07-19 12:02:13] __main__ INFO: \u001b[0mEpoch 14 Step 100/703 lr 0.100000 loss 1.4707 (1.1429) acc@1 0.4688 (0.5778) acc@5 0.8906 (0.8802)\n",
      "\u001b[32m[2020-07-19 14:15:44] __main__ INFO: \u001b[0mEpoch 48 Step 400/703 lr 0.100000 loss 0.9874 (0.9134) acc@1 0.5938 (0.6648) acc@5 0.8906 (0.8941)\n",
      "\u001b[32m[2020-07-19 14:16:16] __main__ INFO: \u001b[0mEpoch 48 Step 500/703 lr 0.100000 loss 1.0289 (0.9231) acc@1 0.6406 (0.6598) acc@5 0.8906 (0.8932)\n",
      "\u001b[32m[2020-07-19 14:16:48] __main__ INFO: \u001b[0mEpoch 48 Step 600/703 lr 0.100000 loss 0.8776 (0.9202) acc@1 0.7188 (0.6606) acc@5 0.8906 (0.8935)\n",
      "\u001b[32m[2020-07-19 14:17:20] __main__ INFO: \u001b[0mEpoch 48 Step 700/703 lr 0.100000 loss 1.2662 (0.9229) acc@1 0.5781 (0.6597) acc@5 0.8750 (0.8938)\n",
      "\u001b[32m[2020-07-19 14:17:21] __main__ INFO: \u001b[0mEpoch 48 Step 703/703 lr 0.100000 loss 1.3191 (0.9235) acc@1 0.5469 (0.6595) acc@5 0.8125 (0.8937)\n",
      "\u001b[32m[2020-07-19 14:17:21] __main__ INFO: \u001b[0mElapsed 224.62\n",
      "\u001b[32m[2020-07-19 14:17:21] __main__ INFO: \u001b[0mVal 48\n",
      "\u001b[32m[2020-07-19 14:17:29] __main__ INFO: \u001b[0mEpoch 48 loss 0.4654 acc@1 0.8370 acc@5 0.9934\n",
      "\u001b[32m[2020-07-19 14:17:29] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-19 14:17:29] __main__ INFO: \u001b[0mTrain 49 33744\n",
      "\u001b[32m[2020-07-19 14:18:01] __main__ INFO: \u001b[0mEpoch 49 Step 100/703 lr 0.100000 loss 0.8976 (0.8775) acc@1 0.6875 (0.6745) acc@5 0.9219 (0.8961)\n",
      "\u001b[32m[2020-07-19 14:18:33] __main__ INFO: \u001b[0mEpoch 49 Step 200/703 lr 0.100000 loss 0.7963 (0.8889) acc@1 0.6875 (0.6722) acc@5 0.8750 (0.8966)\n",
      "\u001b[32m[2020-07-19 14:19:05] __main__ INFO: \u001b[0mEpoch 49 Step 300/703 lr 0.100000 loss 0.8594 (0.9006) acc@1 0.6875 (0.6680) acc@5 0.8906 (0.8961)\n",
      "\u001b[32m[2020-07-19 14:19:37] __main__ INFO: \u001b[0mEpoch 49 Step 400/703 lr 0.100000 loss 0.9934 (0.9091) acc@1 0.6250 (0.6645) acc@5 0.9062 (0.8959)\n",
      "\u001b[32m[2020-07-19 14:20:09] __main__ INFO: \u001b[0mEpoch 49 Step 500/703 lr 0.100000 loss 0.8914 (0.9129) acc@1 0.7188 (0.6636) acc@5 0.9062 (0.8960)\n",
      "\u001b[32m[2020-07-19 14:20:41] __main__ INFO: \u001b[0mEpoch 49 Step 600/703 lr 0.100000 loss 0.7301 (0.9155) acc@1 0.6719 (0.6621) acc@5 0.9062 (0.8953)\n",
      "\u001b[32m[2020-07-19 14:21:13] __main__ INFO: \u001b[0mEpoch 49 Step 700/703 lr 0.100000 loss 0.8670 (0.9221) acc@1 0.6875 (0.6605) acc@5 0.8906 (0.8951)\n",
      "\u001b[32m[2020-07-19 14:21:14] __main__ INFO: \u001b[0mEpoch 49 Step 703/703 lr 0.100000 loss 0.8761 (0.9219) acc@1 0.6562 (0.6605) acc@5 0.9219 (0.8952)\n",
      "\u001b[32m[2020-07-19 14:21:14] __main__ INFO: \u001b[0mElapsed 225.31\n",
      "\u001b[32m[2020-07-19 14:21:14] __main__ INFO: \u001b[0mVal 49\n",
      "\u001b[32m[2020-07-19 14:21:22] __main__ INFO: \u001b[0mEpoch 49 loss 0.3860 acc@1 0.8706 acc@5 0.9968\n",
      "\u001b[32m[2020-07-19 14:21:22] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-19 14:21:22] __main__ INFO: \u001b[0mTrain 50 34447\n",
      "\u001b[32m[2020-07-19 14:21:54] __main__ INFO: \u001b[0mEpoch 50 Step 100/703 lr 0.100000 loss 0.7278 (0.8696) acc@1 0.6719 (0.6720) acc@5 0.9062 (0.8981)\n",
      "\u001b[32m[2020-07-19 14:22:26] __main__ INFO: \u001b[0mEpoch 50 Step 200/703 lr 0.100000 loss 0.8370 (0.8927) acc@1 0.7031 (0.6658) acc@5 0.9219 (0.8956)\n",
      "\u001b[32m[2020-07-19 14:22:58] __main__ INFO: \u001b[0mEpoch 50 Step 300/703 lr 0.100000 loss 0.9120 (0.9040) acc@1 0.7031 (0.6634) acc@5 0.8750 (0.8959)\n",
      "\u001b[32m[2020-07-19 14:23:30] __main__ INFO: \u001b[0mEpoch 50 Step 400/703 lr 0.100000 loss 1.0477 (0.9126) acc@1 0.6250 (0.6622) acc@5 0.8750 (0.8970)\n",
      "\u001b[32m[2020-07-19 14:24:02] __main__ INFO: \u001b[0mEpoch 50 Step 500/703 lr 0.100000 loss 1.0309 (0.9149) acc@1 0.6250 (0.6621) acc@5 0.9062 (0.8963)\n",
      "\u001b[32m[2020-07-19 14:24:34] __main__ INFO: \u001b[0mEpoch 50 Step 600/703 lr 0.100000 loss 0.7193 (0.9111) acc@1 0.7188 (0.6634) acc@5 0.9531 (0.8968)\n",
      "\u001b[32m[2020-07-19 14:25:06] __main__ INFO: \u001b[0mEpoch 50 Step 700/703 lr 0.100000 loss 0.8123 (0.9191) acc@1 0.7188 (0.6606) acc@5 0.9062 (0.8965)\n",
      "\u001b[32m[2020-07-19 14:25:07] __main__ INFO: \u001b[0mEpoch 50 Step 703/703 lr 0.100000 loss 0.8413 (0.9194) acc@1 0.6719 (0.6606) acc@5 0.8906 (0.8965)\n",
      "\u001b[32m[2020-07-19 14:25:07] __main__ INFO: \u001b[0mElapsed 225.02\n",
      "\u001b[32m[2020-07-19 14:25:07] __main__ INFO: \u001b[0mVal 50\n",
      "\u001b[32m[2020-07-19 14:25:15] __main__ INFO: \u001b[0mEpoch 50 loss 0.4738 acc@1 0.8298 acc@5 0.9958\n",
      "\u001b[32m[2020-07-19 14:25:15] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-19 14:25:15] __main__ INFO: \u001b[0mTrain 51 35150\n",
      "\u001b[32m[2020-07-19 14:25:47] __main__ INFO: \u001b[0mEpoch 51 Step 100/703 lr 0.100000 loss 0.9669 (0.8850) acc@1 0.6406 (0.6697) acc@5 0.9062 (0.8972)\n",
      "\u001b[32m[2020-07-19 14:26:19] __main__ INFO: \u001b[0mEpoch 51 Step 200/703 lr 0.100000 loss 0.8181 (0.9042) acc@1 0.7031 (0.6634) acc@5 0.9062 (0.8965)\n",
      "\u001b[32m[2020-07-19 14:26:51] __main__ INFO: \u001b[0mEpoch 51 Step 300/703 lr 0.100000 loss 1.0032 (0.9068) acc@1 0.6250 (0.6626) acc@5 0.8750 (0.8990)\n",
      "\u001b[32m[2020-07-19 14:27:23] __main__ INFO: \u001b[0mEpoch 51 Step 400/703 lr 0.100000 loss 1.1617 (0.9133) acc@1 0.5938 (0.6611) acc@5 0.9688 (0.8997)\n",
      "\u001b[32m[2020-07-19 14:27:55] __main__ INFO: \u001b[0mEpoch 51 Step 500/703 lr 0.100000 loss 1.1361 (0.9137) acc@1 0.5938 (0.6602) acc@5 0.8594 (0.8998)\n",
      "\u001b[32m[2020-07-19 14:28:27] __main__ INFO: \u001b[0mEpoch 51 Step 600/703 lr 0.100000 loss 0.8244 (0.9175) acc@1 0.6875 (0.6596) acc@5 0.9375 (0.8980)\n",
      "\u001b[32m[2020-07-19 14:28:59] __main__ INFO: \u001b[0mEpoch 51 Step 700/703 lr 0.100000 loss 0.8895 (0.9167) acc@1 0.6406 (0.6604) acc@5 0.8438 (0.8968)\n",
      "\u001b[32m[2020-07-19 14:29:00] __main__ INFO: \u001b[0mEpoch 51 Step 703/703 lr 0.100000 loss 0.9734 (0.9171) acc@1 0.6250 (0.6603) acc@5 0.8906 (0.8968)\n",
      "\u001b[32m[2020-07-19 14:29:00] __main__ INFO: \u001b[0mElapsed 225.11\n",
      "\u001b[32m[2020-07-19 14:29:00] __main__ INFO: \u001b[0mVal 51\n",
      "\u001b[32m[2020-07-19 14:29:07] __main__ INFO: \u001b[0mEpoch 51 loss 0.4462 acc@1 0.8586 acc@5 0.9944\n",
      "\u001b[32m[2020-07-19 14:29:07] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-19 14:29:07] __main__ INFO: \u001b[0mTrain 52 35853\n",
      "\u001b[32m[2020-07-19 14:29:40] __main__ INFO: \u001b[0mEpoch 52 Step 100/703 lr 0.100000 loss 0.6766 (0.8756) acc@1 0.7500 (0.6783) acc@5 0.8750 (0.8978)\n",
      "\u001b[32m[2020-07-19 14:30:12] __main__ INFO: \u001b[0mEpoch 52 Step 200/703 lr 0.100000 loss 0.8217 (0.8796) acc@1 0.6875 (0.6753) acc@5 0.9531 (0.8967)\n",
      "\u001b[32m[2020-07-19 14:30:44] __main__ INFO: \u001b[0mEpoch 52 Step 300/703 lr 0.100000 loss 0.8480 (0.8900) acc@1 0.7188 (0.6706) acc@5 0.9062 (0.8955)\n",
      "\u001b[32m[2020-07-19 14:31:15] __main__ INFO: \u001b[0mEpoch 52 Step 400/703 lr 0.100000 loss 0.8258 (0.8995) acc@1 0.7031 (0.6668) acc@5 0.9375 (0.8956)\n",
      "\u001b[32m[2020-07-19 14:31:47] __main__ INFO: \u001b[0mEpoch 52 Step 500/703 lr 0.100000 loss 1.0824 (0.9066) acc@1 0.5938 (0.6645) acc@5 0.8750 (0.8950)\n",
      "\u001b[32m[2020-07-19 14:32:19] __main__ INFO: \u001b[0mEpoch 52 Step 600/703 lr 0.100000 loss 0.8534 (0.9088) acc@1 0.6719 (0.6638) acc@5 0.8906 (0.8952)\n",
      "\u001b[32m[2020-07-19 14:32:51] __main__ INFO: \u001b[0mEpoch 52 Step 700/703 lr 0.100000 loss 0.8865 (0.9142) acc@1 0.6250 (0.6615) acc@5 0.8594 (0.8947)\n",
      "\u001b[32m[2020-07-19 14:32:52] __main__ INFO: \u001b[0mEpoch 52 Step 703/703 lr 0.100000 loss 0.8611 (0.9142) acc@1 0.6875 (0.6616) acc@5 0.9844 (0.8948)\n",
      "\u001b[32m[2020-07-19 14:32:52] __main__ INFO: \u001b[0mElapsed 224.89\n",
      "\u001b[32m[2020-07-19 14:32:52] __main__ INFO: \u001b[0mVal 52\n",
      "\u001b[32m[2020-07-19 14:33:00] __main__ INFO: \u001b[0mEpoch 52 loss 0.4618 acc@1 0.8392 acc@5 0.9942\n",
      "\u001b[32m[2020-07-19 14:33:00] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-19 14:33:00] __main__ INFO: \u001b[0mTrain 53 36556\n",
      "\u001b[32m[2020-07-19 14:33:32] __main__ INFO: \u001b[0mEpoch 53 Step 100/703 lr 0.100000 loss 0.7852 (0.8737) acc@1 0.6875 (0.6813) acc@5 0.8906 (0.8959)\n",
      "\u001b[32m[2020-07-19 14:34:04] __main__ INFO: \u001b[0mEpoch 53 Step 200/703 lr 0.100000 loss 0.7412 (0.8812) acc@1 0.7188 (0.6794) acc@5 0.9375 (0.8976)\n",
      "\u001b[32m[2020-07-19 14:34:36] __main__ INFO: \u001b[0mEpoch 53 Step 300/703 lr 0.100000 loss 0.8062 (0.8809) acc@1 0.6875 (0.6782) acc@5 0.9219 (0.8974)\n",
      "\u001b[32m[2020-07-19 14:35:08] __main__ INFO: \u001b[0mEpoch 53 Step 400/703 lr 0.100000 loss 0.9824 (0.8937) acc@1 0.6250 (0.6738) acc@5 0.9062 (0.8970)\n",
      "\u001b[32m[2020-07-19 14:35:40] __main__ INFO: \u001b[0mEpoch 53 Step 500/703 lr 0.100000 loss 0.9782 (0.9041) acc@1 0.6250 (0.6698) acc@5 0.8906 (0.8962)\n",
      "\u001b[32m[2020-07-19 14:36:12] __main__ INFO: \u001b[0mEpoch 53 Step 600/703 lr 0.100000 loss 1.1542 (0.9013) acc@1 0.6250 (0.6695) acc@5 0.8281 (0.8963)\n",
      "\u001b[32m[2020-07-19 14:36:44] __main__ INFO: \u001b[0mEpoch 53 Step 700/703 lr 0.100000 loss 1.1177 (0.9086) acc@1 0.6094 (0.6663) acc@5 0.8750 (0.8957)\n",
      "\u001b[32m[2020-07-19 14:36:45] __main__ INFO: \u001b[0mEpoch 53 Step 703/703 lr 0.100000 loss 0.8121 (0.9085) acc@1 0.6875 (0.6663) acc@5 0.8906 (0.8958)\n",
      "\u001b[32m[2020-07-19 14:36:45] __main__ INFO: \u001b[0mElapsed 224.99\n",
      "\u001b[32m[2020-07-19 14:36:45] __main__ INFO: \u001b[0mVal 53\n",
      "\u001b[32m[2020-07-19 14:36:53] __main__ INFO: \u001b[0mEpoch 53 loss 0.4029 acc@1 0.8646 acc@5 0.9944\n",
      "\u001b[32m[2020-07-19 14:36:53] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-19 14:36:53] __main__ INFO: \u001b[0mTrain 54 37259\n",
      "\u001b[32m[2020-07-19 14:37:25] __main__ INFO: \u001b[0mEpoch 54 Step 100/703 lr 0.100000 loss 1.0126 (0.8787) acc@1 0.6719 (0.6758) acc@5 0.8438 (0.8912)\n",
      "\u001b[32m[2020-07-19 14:37:57] __main__ INFO: \u001b[0mEpoch 54 Step 200/703 lr 0.100000 loss 1.0969 (0.8920) acc@1 0.5469 (0.6730) acc@5 0.8750 (0.8941)\n",
      "\u001b[32m[2020-07-19 14:38:29] __main__ INFO: \u001b[0mEpoch 54 Step 300/703 lr 0.100000 loss 0.9029 (0.8971) acc@1 0.6562 (0.6714) acc@5 0.9062 (0.8929)\n",
      "\u001b[32m[2020-07-19 14:39:01] __main__ INFO: \u001b[0mEpoch 54 Step 400/703 lr 0.100000 loss 0.7347 (0.8967) acc@1 0.7188 (0.6692) acc@5 0.8750 (0.8941)\n",
      "\u001b[32m[2020-07-19 14:39:33] __main__ INFO: \u001b[0mEpoch 54 Step 500/703 lr 0.100000 loss 0.9969 (0.9019) acc@1 0.6250 (0.6681) acc@5 0.8906 (0.8943)\n",
      "\u001b[32m[2020-07-19 14:40:05] __main__ INFO: \u001b[0mEpoch 54 Step 600/703 lr 0.100000 loss 0.8337 (0.9063) acc@1 0.6719 (0.6666) acc@5 0.8750 (0.8944)\n",
      "\u001b[32m[2020-07-19 14:40:37] __main__ INFO: \u001b[0mEpoch 54 Step 700/703 lr 0.100000 loss 1.0804 (0.9083) acc@1 0.6562 (0.6655) acc@5 0.8750 (0.8946)\n",
      "\u001b[32m[2020-07-19 14:40:38] __main__ INFO: \u001b[0mEpoch 54 Step 703/703 lr 0.100000 loss 1.0295 (0.9089) acc@1 0.5938 (0.6653) acc@5 0.8906 (0.8944)\n",
      "\u001b[32m[2020-07-19 14:40:38] __main__ INFO: \u001b[0mElapsed 225.48\n",
      "\u001b[32m[2020-07-19 14:40:38] __main__ INFO: \u001b[0mVal 54\n",
      "\u001b[32m[2020-07-19 14:40:46] __main__ INFO: \u001b[0mEpoch 54 loss 0.5001 acc@1 0.8324 acc@5 0.9940\n",
      "\u001b[32m[2020-07-19 14:40:46] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-19 14:40:46] __main__ INFO: \u001b[0mTrain 55 37962\n",
      "\u001b[32m[2020-07-19 14:41:18] __main__ INFO: \u001b[0mEpoch 55 Step 100/703 lr 0.100000 loss 0.7611 (0.8771) acc@1 0.7031 (0.6695) acc@5 0.9219 (0.8939)\n",
      "\u001b[32m[2020-07-19 14:41:50] __main__ INFO: \u001b[0mEpoch 55 Step 200/703 lr 0.100000 loss 0.8985 (0.8830) acc@1 0.6250 (0.6709) acc@5 0.8750 (0.8926)\n",
      "\u001b[32m[2020-07-19 14:42:22] __main__ INFO: \u001b[0mEpoch 55 Step 300/703 lr 0.100000 loss 0.7600 (0.8917) acc@1 0.7344 (0.6694) acc@5 0.8438 (0.8923)\n",
      "\u001b[32m[2020-07-19 14:42:54] __main__ INFO: \u001b[0mEpoch 55 Step 400/703 lr 0.100000 loss 0.7261 (0.8937) acc@1 0.7031 (0.6689) acc@5 0.8906 (0.8933)\n",
      "\u001b[32m[2020-07-19 14:43:26] __main__ INFO: \u001b[0mEpoch 55 Step 500/703 lr 0.100000 loss 1.0530 (0.8999) acc@1 0.6406 (0.6669) acc@5 0.9531 (0.8951)\n",
      "\u001b[32m[2020-07-19 14:43:58] __main__ INFO: \u001b[0mEpoch 55 Step 600/703 lr 0.100000 loss 1.0806 (0.8996) acc@1 0.6094 (0.6669) acc@5 0.8281 (0.8948)\n",
      "\u001b[32m[2020-07-19 14:44:30] __main__ INFO: \u001b[0mEpoch 55 Step 700/703 lr 0.100000 loss 0.9952 (0.9039) acc@1 0.6406 (0.6656) acc@5 0.9219 (0.8948)\n",
      "\u001b[32m[2020-07-19 14:44:31] __main__ INFO: \u001b[0mEpoch 55 Step 703/703 lr 0.100000 loss 0.9285 (0.9040) acc@1 0.6406 (0.6655) acc@5 0.9531 (0.8950)\n",
      "\u001b[32m[2020-07-19 14:44:31] __main__ INFO: \u001b[0mElapsed 225.14\n",
      "\u001b[32m[2020-07-19 14:44:31] __main__ INFO: \u001b[0mVal 55\n",
      "\u001b[32m[2020-07-19 14:44:39] __main__ INFO: \u001b[0mEpoch 55 loss 0.3923 acc@1 0.8620 acc@5 0.9948\n",
      "\u001b[32m[2020-07-19 14:44:39] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-19 14:44:39] __main__ INFO: \u001b[0mTrain 56 38665\n",
      "\u001b[32m[2020-07-19 14:45:11] __main__ INFO: \u001b[0mEpoch 56 Step 100/703 lr 0.100000 loss 0.7349 (0.8739) acc@1 0.7188 (0.6772) acc@5 0.8750 (0.8966)\n",
      "\u001b[32m[2020-07-19 14:45:43] __main__ INFO: \u001b[0mEpoch 56 Step 200/703 lr 0.100000 loss 0.8592 (0.8771) acc@1 0.6875 (0.6747) acc@5 0.8281 (0.8959)\n",
      "\u001b[32m[2020-07-19 14:46:15] __main__ INFO: \u001b[0mEpoch 56 Step 300/703 lr 0.100000 loss 0.7381 (0.8847) acc@1 0.7188 (0.6697) acc@5 0.9219 (0.8962)\n",
      "\u001b[32m[2020-07-19 14:46:47] __main__ INFO: \u001b[0mEpoch 56 Step 400/703 lr 0.100000 loss 1.0902 (0.8917) acc@1 0.6406 (0.6688) acc@5 0.9375 (0.8952)\n",
      "\u001b[32m[2020-07-19 14:47:20] __main__ INFO: \u001b[0mEpoch 56 Step 500/703 lr 0.100000 loss 0.8733 (0.8950) acc@1 0.6875 (0.6691) acc@5 0.9062 (0.8958)\n",
      "\u001b[32m[2020-07-19 14:47:52] __main__ INFO: \u001b[0mEpoch 56 Step 600/703 lr 0.100000 loss 0.7800 (0.9005) acc@1 0.6562 (0.6670) acc@5 0.8594 (0.8952)\n",
      "\u001b[32m[2020-07-19 14:48:24] __main__ INFO: \u001b[0mEpoch 56 Step 700/703 lr 0.100000 loss 0.8601 (0.8983) acc@1 0.7031 (0.6682) acc@5 0.9531 (0.8960)\n",
      "\u001b[32m[2020-07-19 14:48:25] __main__ INFO: \u001b[0mEpoch 56 Step 703/703 lr 0.100000 loss 1.1075 (0.8983) acc@1 0.6094 (0.6683) acc@5 0.9062 (0.8961)\n",
      "\u001b[32m[2020-07-19 14:48:25] __main__ INFO: \u001b[0mElapsed 225.69\n",
      "\u001b[32m[2020-07-19 14:48:25] __main__ INFO: \u001b[0mVal 56\n",
      "\u001b[32m[2020-07-19 14:48:32] __main__ INFO: \u001b[0mEpoch 56 loss 0.4702 acc@1 0.8392 acc@5 0.9940\n",
      "\u001b[32m[2020-07-19 14:48:32] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-19 14:48:32] __main__ INFO: \u001b[0mTrain 57 39368\n",
      "\u001b[32m[2020-07-19 14:49:05] __main__ INFO: \u001b[0mEpoch 57 Step 100/703 lr 0.100000 loss 0.9328 (0.8611) acc@1 0.6875 (0.6828) acc@5 0.8594 (0.8988)\n",
      "\u001b[32m[2020-07-19 14:49:37] __main__ INFO: \u001b[0mEpoch 57 Step 200/703 lr 0.100000 loss 0.6836 (0.8764) acc@1 0.7812 (0.6768) acc@5 0.9219 (0.9008)\n",
      "\u001b[32m[2020-07-19 14:50:09] __main__ INFO: \u001b[0mEpoch 57 Step 300/703 lr 0.100000 loss 0.8904 (0.8910) acc@1 0.6562 (0.6717) acc@5 0.8594 (0.8969)\n",
      "\u001b[32m[2020-07-19 14:50:41] __main__ INFO: \u001b[0mEpoch 57 Step 400/703 lr 0.100000 loss 0.9652 (0.8944) acc@1 0.6875 (0.6709) acc@5 0.8438 (0.8968)\n",
      "\u001b[32m[2020-07-19 14:51:13] __main__ INFO: \u001b[0mEpoch 57 Step 500/703 lr 0.100000 loss 0.7283 (0.9027) acc@1 0.7500 (0.6676) acc@5 0.9375 (0.8974)\n",
      "\u001b[32m[2020-07-19 14:51:45] __main__ INFO: \u001b[0mEpoch 57 Step 600/703 lr 0.100000 loss 0.7183 (0.9025) acc@1 0.7500 (0.6683) acc@5 0.9062 (0.8974)\n",
      "\u001b[32m[2020-07-19 14:52:17] __main__ INFO: \u001b[0mEpoch 57 Step 700/703 lr 0.100000 loss 0.8760 (0.9030) acc@1 0.6875 (0.6672) acc@5 0.9531 (0.8967)\n",
      "\u001b[32m[2020-07-19 14:52:18] __main__ INFO: \u001b[0mEpoch 57 Step 703/703 lr 0.100000 loss 0.9258 (0.9028) acc@1 0.6875 (0.6673) acc@5 0.8438 (0.8966)\n",
      "\u001b[32m[2020-07-19 14:52:18] __main__ INFO: \u001b[0mElapsed 225.46\n",
      "\u001b[32m[2020-07-19 14:52:18] __main__ INFO: \u001b[0mVal 57\n",
      "\u001b[32m[2020-07-19 14:52:26] __main__ INFO: \u001b[0mEpoch 57 loss 0.4286 acc@1 0.8622 acc@5 0.9962\n",
      "\u001b[32m[2020-07-19 14:52:26] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-19 14:52:26] __main__ INFO: \u001b[0mTrain 58 40071\n",
      "\u001b[32m[2020-07-19 14:52:58] __main__ INFO: \u001b[0mEpoch 58 Step 100/703 lr 0.100000 loss 0.7701 (0.8669) acc@1 0.6719 (0.6805) acc@5 0.9219 (0.8981)\n",
      "\u001b[32m[2020-07-19 14:53:30] __main__ INFO: \u001b[0mEpoch 58 Step 200/703 lr 0.100000 loss 0.8336 (0.8680) acc@1 0.6406 (0.6830) acc@5 0.9219 (0.8986)\n",
      "\u001b[32m[2020-07-19 14:54:02] __main__ INFO: \u001b[0mEpoch 58 Step 300/703 lr 0.100000 loss 1.0304 (0.8797) acc@1 0.5938 (0.6766) acc@5 0.8750 (0.8978)\n",
      "\u001b[32m[2020-07-19 14:54:34] __main__ INFO: \u001b[0mEpoch 58 Step 400/703 lr 0.100000 loss 1.1202 (0.8921) acc@1 0.5625 (0.6718) acc@5 0.9062 (0.8957)\n",
      "\u001b[32m[2020-07-19 14:55:06] __main__ INFO: \u001b[0mEpoch 58 Step 500/703 lr 0.100000 loss 1.0292 (0.8923) acc@1 0.5781 (0.6720) acc@5 0.9062 (0.8969)\n",
      "\u001b[32m[2020-07-19 14:55:38] __main__ INFO: \u001b[0mEpoch 58 Step 600/703 lr 0.100000 loss 1.0189 (0.8962) acc@1 0.6094 (0.6700) acc@5 0.8750 (0.8968)\n",
      "\u001b[32m[2020-07-19 14:56:10] __main__ INFO: \u001b[0mEpoch 58 Step 700/703 lr 0.100000 loss 0.7984 (0.8985) acc@1 0.7031 (0.6692) acc@5 0.9062 (0.8963)\n",
      "\u001b[32m[2020-07-19 14:56:11] __main__ INFO: \u001b[0mEpoch 58 Step 703/703 lr 0.100000 loss 1.0402 (0.8990) acc@1 0.5469 (0.6690) acc@5 0.8594 (0.8963)\n",
      "\u001b[32m[2020-07-19 14:56:11] __main__ INFO: \u001b[0mElapsed 225.42\n",
      "\u001b[32m[2020-07-19 14:56:11] __main__ INFO: \u001b[0mVal 58\n",
      "\u001b[32m[2020-07-19 14:56:19] __main__ INFO: \u001b[0mEpoch 58 loss 0.4375 acc@1 0.8596 acc@5 0.9946\n",
      "\u001b[32m[2020-07-19 14:56:19] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-19 14:56:19] __main__ INFO: \u001b[0mTrain 59 40774\n",
      "\u001b[32m[2020-07-19 14:56:51] __main__ INFO: \u001b[0mEpoch 59 Step 100/703 lr 0.100000 loss 0.7468 (0.8853) acc@1 0.6719 (0.6700) acc@5 0.8906 (0.8961)\n",
      "\u001b[32m[2020-07-19 14:57:23] __main__ INFO: \u001b[0mEpoch 59 Step 200/703 lr 0.100000 loss 0.8908 (0.8816) acc@1 0.6562 (0.6714) acc@5 0.8594 (0.8960)\n",
      "\u001b[32m[2020-07-19 14:57:55] __main__ INFO: \u001b[0mEpoch 59 Step 300/703 lr 0.100000 loss 0.6436 (0.8817) acc@1 0.8125 (0.6739) acc@5 0.9062 (0.8959)\n",
      "\u001b[32m[2020-07-19 14:58:27] __main__ INFO: \u001b[0mEpoch 59 Step 400/703 lr 0.100000 loss 0.9274 (0.8850) acc@1 0.6562 (0.6713) acc@5 0.9375 (0.8962)\n",
      "\u001b[32m[2020-07-19 14:58:59] __main__ INFO: \u001b[0mEpoch 59 Step 500/703 lr 0.100000 loss 0.9334 (0.8911) acc@1 0.6250 (0.6677) acc@5 0.8438 (0.8956)\n",
      "\u001b[32m[2020-07-19 14:59:31] __main__ INFO: \u001b[0mEpoch 59 Step 600/703 lr 0.100000 loss 0.8543 (0.8929) acc@1 0.6562 (0.6677) acc@5 0.8906 (0.8964)\n",
      "\u001b[32m[2020-07-19 15:00:03] __main__ INFO: \u001b[0mEpoch 59 Step 700/703 lr 0.100000 loss 1.0462 (0.8967) acc@1 0.5781 (0.6662) acc@5 0.9062 (0.8958)\n",
      "\u001b[32m[2020-07-19 15:00:04] __main__ INFO: \u001b[0mEpoch 59 Step 703/703 lr 0.100000 loss 0.8527 (0.8969) acc@1 0.7031 (0.6662) acc@5 0.8594 (0.8959)\n",
      "\u001b[32m[2020-07-19 15:00:04] __main__ INFO: \u001b[0mElapsed 225.27\n",
      "\u001b[32m[2020-07-19 15:00:04] __main__ INFO: \u001b[0mVal 59\n",
      "\u001b[32m[2020-07-19 15:00:12] __main__ INFO: \u001b[0mEpoch 59 loss 0.3981 acc@1 0.8684 acc@5 0.9930\n",
      "\u001b[32m[2020-07-19 15:00:12] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-19 15:00:12] __main__ INFO: \u001b[0mTrain 60 41477\n",
      "\u001b[32m[2020-07-19 15:00:44] __main__ INFO: \u001b[0mEpoch 60 Step 100/703 lr 0.100000 loss 0.7378 (0.8775) acc@1 0.6875 (0.6706) acc@5 0.8750 (0.8927)\n",
      "\u001b[32m[2020-07-19 15:01:16] __main__ INFO: \u001b[0mEpoch 60 Step 200/703 lr 0.100000 loss 0.9237 (0.8785) acc@1 0.6562 (0.6721) acc@5 0.9219 (0.8964)\n",
      "\u001b[32m[2020-07-19 15:01:48] __main__ INFO: \u001b[0mEpoch 60 Step 300/703 lr 0.100000 loss 0.9411 (0.8897) acc@1 0.6875 (0.6694) acc@5 0.8750 (0.8967)\n",
      "\u001b[32m[2020-07-19 15:02:20] __main__ INFO: \u001b[0mEpoch 60 Step 400/703 lr 0.100000 loss 1.0364 (0.8886) acc@1 0.5781 (0.6702) acc@5 0.9062 (0.8969)\n",
      "\u001b[32m[2020-07-19 15:02:52] __main__ INFO: \u001b[0mEpoch 60 Step 500/703 lr 0.100000 loss 0.7348 (0.8946) acc@1 0.7656 (0.6684) acc@5 0.9062 (0.8966)\n",
      "\u001b[32m[2020-07-19 15:03:24] __main__ INFO: \u001b[0mEpoch 60 Step 600/703 lr 0.100000 loss 0.8973 (0.8908) acc@1 0.6562 (0.6706) acc@5 0.9219 (0.8974)\n",
      "\u001b[32m[2020-07-19 15:03:57] __main__ INFO: \u001b[0mEpoch 60 Step 700/703 lr 0.100000 loss 0.8405 (0.8948) acc@1 0.7188 (0.6701) acc@5 0.9375 (0.8973)\n",
      "\u001b[32m[2020-07-19 15:03:57] __main__ INFO: \u001b[0mEpoch 60 Step 703/703 lr 0.100000 loss 1.2603 (0.8948) acc@1 0.5469 (0.6701) acc@5 0.7812 (0.8971)\n",
      "\u001b[32m[2020-07-19 15:03:57] __main__ INFO: \u001b[0mElapsed 225.53\n",
      "\u001b[32m[2020-07-19 15:03:57] __main__ INFO: \u001b[0mVal 60\n",
      "\u001b[32m[2020-07-19 15:04:05] __main__ INFO: \u001b[0mEpoch 60 loss 0.3380 acc@1 0.8852 acc@5 0.9956\n",
      "\u001b[32m[2020-07-19 15:04:05] __main__ INFO: \u001b[0mElapsed 7.79\n",
      "\u001b[32m[2020-07-19 15:04:05] __main__ INFO: \u001b[0mTrain 61 42180\n",
      "\u001b[32m[2020-07-19 15:04:37] __main__ INFO: \u001b[0mEpoch 61 Step 100/703 lr 0.100000 loss 0.7551 (0.8533) acc@1 0.7031 (0.6827) acc@5 0.9375 (0.8983)\n",
      "\u001b[32m[2020-07-19 15:05:10] __main__ INFO: \u001b[0mEpoch 61 Step 200/703 lr 0.100000 loss 0.8370 (0.8657) acc@1 0.6875 (0.6780) acc@5 0.9219 (0.8965)\n",
      "\u001b[32m[2020-07-19 15:05:42] __main__ INFO: \u001b[0mEpoch 61 Step 300/703 lr 0.100000 loss 0.9564 (0.8789) acc@1 0.6719 (0.6753) acc@5 0.8281 (0.8968)\n",
      "\u001b[32m[2020-07-19 15:06:14] __main__ INFO: \u001b[0mEpoch 61 Step 400/703 lr 0.100000 loss 0.7983 (0.8847) acc@1 0.7500 (0.6745) acc@5 0.8906 (0.8972)\n",
      "\u001b[32m[2020-07-19 15:06:46] __main__ INFO: \u001b[0mEpoch 61 Step 500/703 lr 0.100000 loss 1.0768 (0.8896) acc@1 0.6250 (0.6732) acc@5 0.9062 (0.8959)\n",
      "\u001b[32m[2020-07-19 15:07:18] __main__ INFO: \u001b[0mEpoch 61 Step 600/703 lr 0.100000 loss 0.8042 (0.8891) acc@1 0.6719 (0.6735) acc@5 0.9688 (0.8959)\n",
      "\u001b[32m[2020-07-19 15:07:50] __main__ INFO: \u001b[0mEpoch 61 Step 700/703 lr 0.100000 loss 0.9743 (0.8905) acc@1 0.6250 (0.6729) acc@5 0.8281 (0.8952)\n",
      "\u001b[32m[2020-07-19 15:07:51] __main__ INFO: \u001b[0mEpoch 61 Step 703/703 lr 0.100000 loss 0.7844 (0.8905) acc@1 0.7500 (0.6729) acc@5 0.9219 (0.8953)\n",
      "\u001b[32m[2020-07-19 15:07:51] __main__ INFO: \u001b[0mElapsed 225.39\n",
      "\u001b[32m[2020-07-19 15:07:51] __main__ INFO: \u001b[0mVal 61\n",
      "\u001b[32m[2020-07-19 15:07:58] __main__ INFO: \u001b[0mEpoch 61 loss 0.4256 acc@1 0.8618 acc@5 0.9960\n",
      "\u001b[32m[2020-07-19 15:07:58] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-19 15:07:58] __main__ INFO: \u001b[0mTrain 62 42883\n",
      "\u001b[32m[2020-07-19 15:08:31] __main__ INFO: \u001b[0mEpoch 62 Step 100/703 lr 0.100000 loss 0.7508 (0.8441) acc@1 0.7188 (0.6886) acc@5 0.8750 (0.9033)\n",
      "\u001b[32m[2020-07-19 15:09:03] __main__ INFO: \u001b[0mEpoch 62 Step 200/703 lr 0.100000 loss 0.8193 (0.8697) acc@1 0.6719 (0.6791) acc@5 0.9219 (0.8990)\n",
      "\u001b[32m[2020-07-19 15:09:35] __main__ INFO: \u001b[0mEpoch 62 Step 300/703 lr 0.100000 loss 0.9093 (0.8688) acc@1 0.6562 (0.6790) acc@5 0.9375 (0.8990)\n",
      "\u001b[32m[2020-07-19 15:10:07] __main__ INFO: \u001b[0mEpoch 62 Step 400/703 lr 0.100000 loss 0.7170 (0.8747) acc@1 0.7344 (0.6767) acc@5 0.9219 (0.8992)\n",
      "\u001b[32m[2020-07-19 15:10:39] __main__ INFO: \u001b[0mEpoch 62 Step 500/703 lr 0.100000 loss 0.7922 (0.8823) acc@1 0.6719 (0.6735) acc@5 0.9219 (0.8992)\n",
      "\u001b[32m[2020-07-19 15:11:11] __main__ INFO: \u001b[0mEpoch 62 Step 600/703 lr 0.100000 loss 0.9307 (0.8867) acc@1 0.6250 (0.6724) acc@5 0.9062 (0.8985)\n",
      "\u001b[32m[2020-07-19 15:11:43] __main__ INFO: \u001b[0mEpoch 62 Step 700/703 lr 0.100000 loss 0.9229 (0.8941) acc@1 0.6719 (0.6694) acc@5 0.9219 (0.8973)\n",
      "\u001b[32m[2020-07-19 15:11:44] __main__ INFO: \u001b[0mEpoch 62 Step 703/703 lr 0.100000 loss 0.7544 (0.8941) acc@1 0.7500 (0.6695) acc@5 0.8750 (0.8972)\n",
      "\u001b[32m[2020-07-19 15:11:44] __main__ INFO: \u001b[0mElapsed 225.27\n",
      "\u001b[32m[2020-07-19 15:11:44] __main__ INFO: \u001b[0mVal 62\n",
      "\u001b[32m[2020-07-19 15:11:51] __main__ INFO: \u001b[0mEpoch 62 loss 0.3942 acc@1 0.8670 acc@5 0.9948\n",
      "\u001b[32m[2020-07-19 15:11:51] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-19 15:11:51] __main__ INFO: \u001b[0mTrain 63 43586\n",
      "\u001b[32m[2020-07-19 15:12:24] __main__ INFO: \u001b[0mEpoch 63 Step 100/703 lr 0.100000 loss 0.5957 (0.8583) acc@1 0.7812 (0.6855) acc@5 0.9531 (0.8969)\n",
      "\u001b[32m[2020-07-19 15:12:56] __main__ INFO: \u001b[0mEpoch 63 Step 200/703 lr 0.100000 loss 1.2333 (0.8649) acc@1 0.6250 (0.6833) acc@5 0.8594 (0.8961)\n",
      "\u001b[32m[2020-07-19 15:13:27] __main__ INFO: \u001b[0mEpoch 63 Step 300/703 lr 0.100000 loss 0.7376 (0.8654) acc@1 0.7188 (0.6817) acc@5 0.9531 (0.8978)\n",
      "\u001b[32m[2020-07-19 15:13:59] __main__ INFO: \u001b[0mEpoch 63 Step 400/703 lr 0.100000 loss 0.9434 (0.8748) acc@1 0.6562 (0.6785) acc@5 0.8906 (0.8972)\n",
      "\u001b[32m[2020-07-19 15:14:31] __main__ INFO: \u001b[0mEpoch 63 Step 500/703 lr 0.100000 loss 0.9247 (0.8844) acc@1 0.6250 (0.6748) acc@5 0.8906 (0.8975)\n",
      "\u001b[32m[2020-07-19 15:15:03] __main__ INFO: \u001b[0mEpoch 63 Step 600/703 lr 0.100000 loss 0.7202 (0.8851) acc@1 0.7188 (0.6749) acc@5 0.9375 (0.8977)\n",
      "\u001b[32m[2020-07-19 15:15:35] __main__ INFO: \u001b[0mEpoch 63 Step 700/703 lr 0.100000 loss 0.7930 (0.8882) acc@1 0.7344 (0.6735) acc@5 0.9062 (0.8976)\n",
      "\u001b[32m[2020-07-19 15:15:36] __main__ INFO: \u001b[0mEpoch 63 Step 703/703 lr 0.100000 loss 0.8427 (0.8886) acc@1 0.6719 (0.6733) acc@5 0.8906 (0.8975)\n",
      "\u001b[32m[2020-07-19 15:15:36] __main__ INFO: \u001b[0mElapsed 224.77\n",
      "\u001b[32m[2020-07-19 15:15:36] __main__ INFO: \u001b[0mVal 63\n",
      "\u001b[32m[2020-07-19 15:15:44] __main__ INFO: \u001b[0mEpoch 63 loss 0.4154 acc@1 0.8558 acc@5 0.9946\n",
      "\u001b[32m[2020-07-19 15:15:44] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-19 15:15:44] __main__ INFO: \u001b[0mTrain 64 44289\n",
      "\u001b[32m[2020-07-19 15:16:16] __main__ INFO: \u001b[0mEpoch 64 Step 100/703 lr 0.100000 loss 0.8138 (0.8575) acc@1 0.7031 (0.6819) acc@5 0.8906 (0.8978)\n",
      "\u001b[32m[2020-07-19 15:16:48] __main__ INFO: \u001b[0mEpoch 64 Step 200/703 lr 0.100000 loss 0.9521 (0.8638) acc@1 0.6562 (0.6833) acc@5 0.8750 (0.8983)\n",
      "\u001b[32m[2020-07-19 15:17:20] __main__ INFO: \u001b[0mEpoch 64 Step 300/703 lr 0.100000 loss 0.5805 (0.8728) acc@1 0.7812 (0.6777) acc@5 0.9531 (0.8957)\n",
      "\u001b[32m[2020-07-19 15:17:52] __main__ INFO: \u001b[0mEpoch 64 Step 400/703 lr 0.100000 loss 1.1256 (0.8795) acc@1 0.6250 (0.6751) acc@5 0.8906 (0.8956)\n",
      "\u001b[32m[2020-07-19 15:18:24] __main__ INFO: \u001b[0mEpoch 64 Step 500/703 lr 0.100000 loss 1.0045 (0.8858) acc@1 0.6094 (0.6739) acc@5 0.8438 (0.8959)\n",
      "\u001b[32m[2020-07-19 15:18:56] __main__ INFO: \u001b[0mEpoch 64 Step 600/703 lr 0.100000 loss 0.9365 (0.8922) acc@1 0.6250 (0.6720) acc@5 0.9219 (0.8961)\n",
      "\u001b[32m[2020-07-19 15:19:28] __main__ INFO: \u001b[0mEpoch 64 Step 700/703 lr 0.100000 loss 0.6561 (0.8892) acc@1 0.7812 (0.6733) acc@5 0.9062 (0.8971)\n",
      "\u001b[32m[2020-07-19 15:19:29] __main__ INFO: \u001b[0mEpoch 64 Step 703/703 lr 0.100000 loss 0.7330 (0.8893) acc@1 0.7656 (0.6732) acc@5 0.9062 (0.8971)\n",
      "\u001b[32m[2020-07-19 15:19:29] __main__ INFO: \u001b[0mElapsed 225.00\n",
      "\u001b[32m[2020-07-19 15:19:29] __main__ INFO: \u001b[0mVal 64\n",
      "\u001b[32m[2020-07-19 15:19:37] __main__ INFO: \u001b[0mEpoch 64 loss 0.3972 acc@1 0.8628 acc@5 0.9960\n",
      "\u001b[32m[2020-07-19 15:19:37] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-19 15:19:37] __main__ INFO: \u001b[0mTrain 65 44992\n",
      "\u001b[32m[2020-07-19 15:20:09] __main__ INFO: \u001b[0mEpoch 65 Step 100/703 lr 0.100000 loss 0.7561 (0.8625) acc@1 0.6875 (0.6830) acc@5 0.8594 (0.8917)\n",
      "\u001b[32m[2020-07-19 15:20:41] __main__ INFO: \u001b[0mEpoch 65 Step 200/703 lr 0.100000 loss 0.8035 (0.8688) acc@1 0.7188 (0.6802) acc@5 0.8906 (0.8909)\n",
      "\u001b[32m[2020-07-19 15:21:13] __main__ INFO: \u001b[0mEpoch 65 Step 300/703 lr 0.100000 loss 0.7612 (0.8675) acc@1 0.7031 (0.6798) acc@5 0.9062 (0.8943)\n",
      "\u001b[32m[2020-07-19 15:21:45] __main__ INFO: \u001b[0mEpoch 65 Step 400/703 lr 0.100000 loss 0.7044 (0.8753) acc@1 0.7188 (0.6785) acc@5 0.9844 (0.8945)\n",
      "\u001b[32m[2020-07-19 15:22:17] __main__ INFO: \u001b[0mEpoch 65 Step 500/703 lr 0.100000 loss 0.8843 (0.8812) acc@1 0.6875 (0.6764) acc@5 0.8906 (0.8951)\n",
      "\u001b[32m[2020-07-19 15:22:49] __main__ INFO: \u001b[0mEpoch 65 Step 600/703 lr 0.100000 loss 0.8185 (0.8786) acc@1 0.7031 (0.6768) acc@5 0.8906 (0.8967)\n",
      "\u001b[32m[2020-07-19 15:23:21] __main__ INFO: \u001b[0mEpoch 65 Step 700/703 lr 0.100000 loss 0.7213 (0.8822) acc@1 0.7812 (0.6752) acc@5 0.9375 (0.8965)\n",
      "\u001b[32m[2020-07-19 15:23:22] __main__ INFO: \u001b[0mEpoch 65 Step 703/703 lr 0.100000 loss 1.0251 (0.8824) acc@1 0.5781 (0.6752) acc@5 0.9219 (0.8966)\n",
      "\u001b[32m[2020-07-19 15:23:22] __main__ INFO: \u001b[0mElapsed 225.63\n",
      "\u001b[32m[2020-07-19 15:23:22] __main__ INFO: \u001b[0mVal 65\n",
      "\u001b[32m[2020-07-19 15:23:30] __main__ INFO: \u001b[0mEpoch 65 loss 0.5176 acc@1 0.8252 acc@5 0.9960\n",
      "\u001b[32m[2020-07-19 15:23:30] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-19 15:23:30] __main__ INFO: \u001b[0mTrain 66 45695\n",
      "\u001b[32m[2020-07-19 15:24:02] __main__ INFO: \u001b[0mEpoch 66 Step 100/703 lr 0.100000 loss 0.9653 (0.8540) acc@1 0.6250 (0.6855) acc@5 0.8594 (0.8945)\n",
      "\u001b[32m[2020-07-19 15:24:34] __main__ INFO: \u001b[0mEpoch 66 Step 200/703 lr 0.100000 loss 0.8288 (0.8619) acc@1 0.7031 (0.6802) acc@5 0.8906 (0.8916)\n",
      "\u001b[32m[2020-07-19 15:25:06] __main__ INFO: \u001b[0mEpoch 66 Step 300/703 lr 0.100000 loss 0.7893 (0.8694) acc@1 0.7344 (0.6794) acc@5 0.9219 (0.8938)\n",
      "\u001b[32m[2020-07-19 15:25:39] __main__ INFO: \u001b[0mEpoch 66 Step 400/703 lr 0.100000 loss 0.8723 (0.8697) acc@1 0.7031 (0.6784) acc@5 0.9062 (0.8964)\n",
      "\u001b[32m[2020-07-19 15:26:10] __main__ INFO: \u001b[0mEpoch 66 Step 500/703 lr 0.100000 loss 0.9522 (0.8760) acc@1 0.6250 (0.6765) acc@5 0.8906 (0.8959)\n",
      "\u001b[32m[2020-07-19 15:26:43] __main__ INFO: \u001b[0mEpoch 66 Step 600/703 lr 0.100000 loss 0.8641 (0.8816) acc@1 0.6406 (0.6749) acc@5 0.9219 (0.8965)\n",
      "\u001b[32m[2020-07-19 15:27:15] __main__ INFO: \u001b[0mEpoch 66 Step 700/703 lr 0.100000 loss 1.0801 (0.8839) acc@1 0.6719 (0.6743) acc@5 0.8750 (0.8967)\n",
      "\u001b[32m[2020-07-19 15:27:16] __main__ INFO: \u001b[0mEpoch 66 Step 703/703 lr 0.100000 loss 0.9079 (0.8842) acc@1 0.6719 (0.6743) acc@5 0.9062 (0.8966)\n",
      "\u001b[32m[2020-07-19 15:27:16] __main__ INFO: \u001b[0mElapsed 225.33\n",
      "\u001b[32m[2020-07-19 15:27:16] __main__ INFO: \u001b[0mVal 66\n",
      "\u001b[32m[2020-07-19 15:27:23] __main__ INFO: \u001b[0mEpoch 66 loss 0.3679 acc@1 0.8788 acc@5 0.9958\n",
      "\u001b[32m[2020-07-19 15:27:23] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-19 15:27:23] __main__ INFO: \u001b[0mTrain 67 46398\n",
      "\u001b[32m[2020-07-19 15:27:55] __main__ INFO: \u001b[0mEpoch 67 Step 100/703 lr 0.100000 loss 0.8664 (0.8557) acc@1 0.6719 (0.6859) acc@5 0.8906 (0.8964)\n",
      "\u001b[32m[2020-07-19 15:28:28] __main__ INFO: \u001b[0mEpoch 67 Step 200/703 lr 0.100000 loss 0.9850 (0.8559) acc@1 0.7031 (0.6855) acc@5 0.9062 (0.8977)\n",
      "\u001b[32m[2020-07-19 15:29:00] __main__ INFO: \u001b[0mEpoch 67 Step 300/703 lr 0.100000 loss 0.9574 (0.8671) acc@1 0.6250 (0.6821) acc@5 0.8750 (0.8964)\n",
      "\u001b[32m[2020-07-19 15:29:32] __main__ INFO: \u001b[0mEpoch 67 Step 400/703 lr 0.100000 loss 0.9223 (0.8793) acc@1 0.5625 (0.6770) acc@5 0.9219 (0.8966)\n",
      "\u001b[32m[2020-07-19 15:30:04] __main__ INFO: \u001b[0mEpoch 67 Step 500/703 lr 0.100000 loss 0.8885 (0.8827) acc@1 0.6562 (0.6752) acc@5 0.9531 (0.8967)\n",
      "\u001b[32m[2020-07-19 15:41:11] __main__ INFO: \u001b[0mEpoch 70 Step 400/703 lr 0.100000 loss 1.1123 (0.8735) acc@1 0.5781 (0.6767) acc@5 0.8438 (0.8981)\n",
      "\u001b[32m[2020-07-19 15:41:43] __main__ INFO: \u001b[0mEpoch 70 Step 500/703 lr 0.100000 loss 0.8450 (0.8792) acc@1 0.7188 (0.6742) acc@5 0.9219 (0.8981)\n",
      "\u001b[32m[2020-07-19 15:42:15] __main__ INFO: \u001b[0mEpoch 70 Step 600/703 lr 0.100000 loss 0.9040 (0.8838) acc@1 0.6719 (0.6730) acc@5 0.8906 (0.8974)\n",
      "\u001b[32m[2020-07-19 15:42:47] __main__ INFO: \u001b[0mEpoch 70 Step 700/703 lr 0.100000 loss 0.8466 (0.8843) acc@1 0.6562 (0.6727) acc@5 0.9219 (0.8981)\n",
      "\u001b[32m[2020-07-19 15:42:48] __main__ INFO: \u001b[0mEpoch 70 Step 703/703 lr 0.100000 loss 0.8833 (0.8840) acc@1 0.6250 (0.6726) acc@5 0.9375 (0.8983)\n",
      "\u001b[32m[2020-07-19 15:42:48] __main__ INFO: \u001b[0mElapsed 224.97\n",
      "\u001b[32m[2020-07-19 15:42:48] __main__ INFO: \u001b[0mVal 70\n",
      "\u001b[32m[2020-07-19 15:42:56] __main__ INFO: \u001b[0mEpoch 70 loss 0.3738 acc@1 0.8762 acc@5 0.9966\n",
      "\u001b[32m[2020-07-19 15:42:56] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-19 15:42:56] __main__ INFO: \u001b[0mTrain 71 49210\n",
      "\u001b[32m[2020-07-19 15:43:28] __main__ INFO: \u001b[0mEpoch 71 Step 100/703 lr 0.100000 loss 0.9294 (0.8674) acc@1 0.6719 (0.6772) acc@5 0.8906 (0.8948)\n",
      "\u001b[32m[2020-07-19 15:44:00] __main__ INFO: \u001b[0mEpoch 71 Step 200/703 lr 0.100000 loss 0.8217 (0.8630) acc@1 0.6719 (0.6783) acc@5 0.9531 (0.8975)\n",
      "\u001b[32m[2020-07-19 15:44:32] __main__ INFO: \u001b[0mEpoch 71 Step 300/703 lr 0.100000 loss 0.9310 (0.8689) acc@1 0.6719 (0.6807) acc@5 0.9375 (0.8969)\n",
      "\u001b[32m[2020-07-19 15:45:04] __main__ INFO: \u001b[0mEpoch 71 Step 400/703 lr 0.100000 loss 0.8553 (0.8720) acc@1 0.6406 (0.6795) acc@5 0.8750 (0.8983)\n",
      "\u001b[32m[2020-07-19 15:45:36] __main__ INFO: \u001b[0mEpoch 71 Step 500/703 lr 0.100000 loss 0.7606 (0.8761) acc@1 0.6875 (0.6782) acc@5 0.9219 (0.8969)\n",
      "\u001b[32m[2020-07-19 15:46:08] __main__ INFO: \u001b[0mEpoch 71 Step 600/703 lr 0.100000 loss 1.0236 (0.8742) acc@1 0.6250 (0.6787) acc@5 0.8750 (0.8978)\n",
      "\u001b[32m[2020-07-19 15:46:40] __main__ INFO: \u001b[0mEpoch 71 Step 700/703 lr 0.100000 loss 0.9350 (0.8773) acc@1 0.6562 (0.6771) acc@5 0.8438 (0.8986)\n",
      "\u001b[32m[2020-07-19 15:46:41] __main__ INFO: \u001b[0mEpoch 71 Step 703/703 lr 0.100000 loss 0.7742 (0.8770) acc@1 0.7344 (0.6772) acc@5 0.8906 (0.8985)\n",
      "\u001b[32m[2020-07-19 15:46:41] __main__ INFO: \u001b[0mElapsed 225.05\n",
      "\u001b[32m[2020-07-19 15:46:41] __main__ INFO: \u001b[0mVal 71\n",
      "\u001b[32m[2020-07-19 15:46:48] __main__ INFO: \u001b[0mEpoch 71 loss 0.3724 acc@1 0.8790 acc@5 0.9944\n",
      "\u001b[32m[2020-07-19 15:46:48] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-19 15:46:48] __main__ INFO: \u001b[0mTrain 72 49913\n",
      "\u001b[32m[2020-07-19 15:47:20] __main__ INFO: \u001b[0mEpoch 72 Step 100/703 lr 0.100000 loss 1.0160 (0.8515) acc@1 0.6094 (0.6825) acc@5 0.8906 (0.9033)\n",
      "\u001b[32m[2020-07-19 15:47:52] __main__ INFO: \u001b[0mEpoch 72 Step 200/703 lr 0.100000 loss 0.7153 (0.8564) acc@1 0.7188 (0.6789) acc@5 0.9219 (0.8990)\n",
      "\u001b[32m[2020-07-19 15:48:24] __main__ INFO: \u001b[0mEpoch 72 Step 300/703 lr 0.100000 loss 0.7559 (0.8541) acc@1 0.7344 (0.6821) acc@5 0.9062 (0.9000)\n",
      "\u001b[32m[2020-07-19 15:48:56] __main__ INFO: \u001b[0mEpoch 72 Step 400/703 lr 0.100000 loss 0.6938 (0.8643) acc@1 0.7969 (0.6798) acc@5 0.9531 (0.8980)\n",
      "\u001b[32m[2020-07-19 15:49:28] __main__ INFO: \u001b[0mEpoch 72 Step 500/703 lr 0.100000 loss 0.6732 (0.8691) acc@1 0.7500 (0.6781) acc@5 0.9219 (0.8981)\n",
      "\u001b[32m[2020-07-19 15:50:00] __main__ INFO: \u001b[0mEpoch 72 Step 600/703 lr 0.100000 loss 1.0435 (0.8718) acc@1 0.6406 (0.6778) acc@5 0.8906 (0.8984)\n",
      "\u001b[32m[2020-07-19 15:50:32] __main__ INFO: \u001b[0mEpoch 72 Step 700/703 lr 0.100000 loss 0.9055 (0.8739) acc@1 0.6719 (0.6767) acc@5 0.8750 (0.8982)\n",
      "\u001b[32m[2020-07-19 15:50:33] __main__ INFO: \u001b[0mEpoch 72 Step 703/703 lr 0.100000 loss 0.9028 (0.8748) acc@1 0.6250 (0.6765) acc@5 0.8906 (0.8981)\n",
      "\u001b[32m[2020-07-19 15:50:33] __main__ INFO: \u001b[0mElapsed 224.46\n",
      "\u001b[32m[2020-07-19 15:50:33] __main__ INFO: \u001b[0mVal 72\n",
      "\u001b[32m[2020-07-19 15:50:41] __main__ INFO: \u001b[0mEpoch 72 loss 0.4561 acc@1 0.8546 acc@5 0.9928\n",
      "\u001b[32m[2020-07-19 15:50:41] __main__ INFO: \u001b[0mElapsed 7.80\n",
      "\u001b[32m[2020-07-19 15:50:41] __main__ INFO: \u001b[0mTrain 73 50616\n",
      "\u001b[32m[2020-07-19 15:51:13] __main__ INFO: \u001b[0mEpoch 73 Step 100/703 lr 0.100000 loss 0.9477 (0.8519) acc@1 0.6875 (0.6817) acc@5 0.8906 (0.8952)\n",
      "\u001b[32m[2020-07-19 15:51:45] __main__ INFO: \u001b[0mEpoch 73 Step 200/703 lr 0.100000 loss 0.7884 (0.8628) acc@1 0.6562 (0.6813) acc@5 0.8750 (0.8953)\n",
      "\u001b[32m[2020-07-19 15:52:17] __main__ INFO: \u001b[0mEpoch 73 Step 300/703 lr 0.100000 loss 0.9183 (0.8689) acc@1 0.6562 (0.6790) acc@5 0.8906 (0.8954)\n",
      "\u001b[32m[2020-07-19 15:52:49] __main__ INFO: \u001b[0mEpoch 73 Step 400/703 lr 0.100000 loss 0.8459 (0.8757) acc@1 0.7188 (0.6771) acc@5 0.9531 (0.8957)\n",
      "\u001b[32m[2020-07-19 15:53:21] __main__ INFO: \u001b[0mEpoch 73 Step 500/703 lr 0.100000 loss 1.0756 (0.8764) acc@1 0.6094 (0.6765) acc@5 0.9219 (0.8965)\n",
      "\u001b[32m[2020-07-19 15:53:53] __main__ INFO: \u001b[0mEpoch 73 Step 600/703 lr 0.100000 loss 0.8620 (0.8792) acc@1 0.6875 (0.6747) acc@5 0.8750 (0.8968)\n",
      "\u001b[32m[2020-07-19 15:54:25] __main__ INFO: \u001b[0mEpoch 73 Step 700/703 lr 0.100000 loss 0.6580 (0.8775) acc@1 0.7188 (0.6753) acc@5 0.9062 (0.8967)\n",
      "\u001b[32m[2020-07-19 15:54:26] __main__ INFO: \u001b[0mEpoch 73 Step 703/703 lr 0.100000 loss 0.7277 (0.8776) acc@1 0.7500 (0.6753) acc@5 0.9375 (0.8967)\n",
      "\u001b[32m[2020-07-19 15:54:26] __main__ INFO: \u001b[0mElapsed 224.95\n",
      "\u001b[32m[2020-07-19 15:54:26] __main__ INFO: \u001b[0mVal 73\n",
      "\u001b[32m[2020-07-19 15:54:33] __main__ INFO: \u001b[0mEpoch 73 loss 0.4340 acc@1 0.8568 acc@5 0.9948\n",
      "\u001b[32m[2020-07-19 15:54:33] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-19 15:54:33] __main__ INFO: \u001b[0mTrain 74 51319\n",
      "\u001b[32m[2020-07-19 15:55:05] __main__ INFO: \u001b[0mEpoch 74 Step 100/703 lr 0.100000 loss 0.7969 (0.8539) acc@1 0.7031 (0.6863) acc@5 0.8906 (0.9005)\n",
      "\u001b[32m[2020-07-19 15:55:37] __main__ INFO: \u001b[0mEpoch 74 Step 200/703 lr 0.100000 loss 0.8794 (0.8543) acc@1 0.6875 (0.6866) acc@5 0.9688 (0.9016)\n",
      "\u001b[32m[2020-07-19 15:56:09] __main__ INFO: \u001b[0mEpoch 74 Step 300/703 lr 0.100000 loss 1.1136 (0.8559) acc@1 0.6094 (0.6860) acc@5 0.8594 (0.9012)\n",
      "\u001b[32m[2020-07-19 15:56:41] __main__ INFO: \u001b[0mEpoch 74 Step 400/703 lr 0.100000 loss 0.9481 (0.8647) acc@1 0.6562 (0.6832) acc@5 0.9062 (0.9008)\n",
      "\u001b[32m[2020-07-19 15:57:13] __main__ INFO: \u001b[0mEpoch 74 Step 500/703 lr 0.100000 loss 0.7014 (0.8684) acc@1 0.7344 (0.6816) acc@5 0.8750 (0.8989)\n",
      "\u001b[32m[2020-07-19 15:57:45] __main__ INFO: \u001b[0mEpoch 74 Step 600/703 lr 0.100000 loss 0.9730 (0.8723) acc@1 0.6875 (0.6798) acc@5 0.9062 (0.8995)\n",
      "\u001b[32m[2020-07-19 15:58:17] __main__ INFO: \u001b[0mEpoch 74 Step 700/703 lr 0.100000 loss 1.0748 (0.8743) acc@1 0.6094 (0.6790) acc@5 0.8438 (0.8991)\n",
      "\u001b[32m[2020-07-19 15:58:18] __main__ INFO: \u001b[0mEpoch 74 Step 703/703 lr 0.100000 loss 0.8118 (0.8746) acc@1 0.6875 (0.6788) acc@5 0.9531 (0.8991)\n",
      "\u001b[32m[2020-07-19 15:58:18] __main__ INFO: \u001b[0mElapsed 224.79\n",
      "\u001b[32m[2020-07-19 15:58:18] __main__ INFO: \u001b[0mVal 74\n",
      "\u001b[32m[2020-07-19 15:58:26] __main__ INFO: \u001b[0mEpoch 74 loss 0.3577 acc@1 0.8796 acc@5 0.9958\n",
      "\u001b[32m[2020-07-19 15:58:26] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-19 15:58:26] __main__ INFO: \u001b[0mTrain 75 52022\n",
      "\u001b[32m[2020-07-19 15:58:58] __main__ INFO: \u001b[0mEpoch 75 Step 100/703 lr 0.100000 loss 0.8073 (0.8461) acc@1 0.6875 (0.6852) acc@5 0.8906 (0.9030)\n",
      "\u001b[32m[2020-07-19 15:59:30] __main__ INFO: \u001b[0mEpoch 75 Step 200/703 lr 0.100000 loss 0.7704 (0.8402) acc@1 0.6875 (0.6871) acc@5 0.8750 (0.9004)\n",
      "\u001b[32m[2020-07-19 16:00:02] __main__ INFO: \u001b[0mEpoch 75 Step 300/703 lr 0.100000 loss 0.7564 (0.8458) acc@1 0.7188 (0.6846) acc@5 0.8906 (0.9002)\n",
      "\u001b[32m[2020-07-19 16:00:34] __main__ INFO: \u001b[0mEpoch 75 Step 400/703 lr 0.100000 loss 0.8777 (0.8563) acc@1 0.6406 (0.6814) acc@5 0.9062 (0.8989)\n",
      "\u001b[32m[2020-07-19 16:01:06] __main__ INFO: \u001b[0mEpoch 75 Step 500/703 lr 0.100000 loss 0.7100 (0.8602) acc@1 0.7656 (0.6803) acc@5 0.9219 (0.8986)\n",
      "\u001b[32m[2020-07-19 16:01:38] __main__ INFO: \u001b[0mEpoch 75 Step 600/703 lr 0.100000 loss 0.9327 (0.8658) acc@1 0.6094 (0.6790) acc@5 0.9062 (0.8982)\n",
      "\u001b[32m[2020-07-19 16:02:10] __main__ INFO: \u001b[0mEpoch 75 Step 700/703 lr 0.100000 loss 1.0454 (0.8657) acc@1 0.5938 (0.6795) acc@5 0.8750 (0.8982)\n",
      "\u001b[32m[2020-07-19 16:02:11] __main__ INFO: \u001b[0mEpoch 75 Step 703/703 lr 0.100000 loss 0.8911 (0.8657) acc@1 0.6406 (0.6795) acc@5 0.8438 (0.8982)\n",
      "\u001b[32m[2020-07-19 16:02:11] __main__ INFO: \u001b[0mElapsed 224.87\n",
      "\u001b[32m[2020-07-19 16:02:11] __main__ INFO: \u001b[0mVal 75\n",
      "\u001b[32m[2020-07-19 16:02:19] __main__ INFO: \u001b[0mEpoch 75 loss 0.3971 acc@1 0.8704 acc@5 0.9962\n",
      "\u001b[32m[2020-07-19 16:02:19] __main__ INFO: \u001b[0mElapsed 7.80\n",
      "\u001b[32m[2020-07-19 16:02:19] __main__ INFO: \u001b[0mTrain 76 52725\n",
      "\u001b[32m[2020-07-19 16:02:51] __main__ INFO: \u001b[0mEpoch 76 Step 100/703 lr 0.100000 loss 0.8605 (0.8310) acc@1 0.6562 (0.6927) acc@5 0.8125 (0.8984)\n",
      "\u001b[32m[2020-07-19 16:03:23] __main__ INFO: \u001b[0mEpoch 76 Step 200/703 lr 0.100000 loss 0.8875 (0.8386) acc@1 0.6094 (0.6923) acc@5 0.8906 (0.8995)\n",
      "\u001b[32m[2020-07-19 16:03:54] __main__ INFO: \u001b[0mEpoch 76 Step 300/703 lr 0.100000 loss 0.8814 (0.8572) acc@1 0.7031 (0.6845) acc@5 0.9062 (0.8989)\n",
      "\u001b[32m[2020-07-19 16:04:26] __main__ INFO: \u001b[0mEpoch 76 Step 400/703 lr 0.100000 loss 0.8711 (0.8546) acc@1 0.6875 (0.6857) acc@5 0.8594 (0.8992)\n",
      "\u001b[32m[2020-07-19 16:04:58] __main__ INFO: \u001b[0mEpoch 76 Step 500/703 lr 0.100000 loss 0.7690 (0.8605) acc@1 0.7188 (0.6830) acc@5 0.9062 (0.8985)\n",
      "\u001b[32m[2020-07-19 16:05:30] __main__ INFO: \u001b[0mEpoch 76 Step 600/703 lr 0.100000 loss 1.0241 (0.8688) acc@1 0.6875 (0.6803) acc@5 0.9062 (0.8977)\n",
      "\u001b[32m[2020-07-19 16:06:02] __main__ INFO: \u001b[0mEpoch 76 Step 700/703 lr 0.100000 loss 0.6942 (0.8720) acc@1 0.7812 (0.6793) acc@5 0.9062 (0.8982)\n",
      "\u001b[32m[2020-07-19 16:06:03] __main__ INFO: \u001b[0mEpoch 76 Step 703/703 lr 0.100000 loss 0.7400 (0.8715) acc@1 0.7188 (0.6795) acc@5 0.9531 (0.8983)\n",
      "\u001b[32m[2020-07-19 16:06:03] __main__ INFO: \u001b[0mElapsed 224.72\n",
      "\u001b[32m[2020-07-19 16:06:03] __main__ INFO: \u001b[0mVal 76\n",
      "\u001b[32m[2020-07-19 16:06:11] __main__ INFO: \u001b[0mEpoch 76 loss 0.3646 acc@1 0.8720 acc@5 0.9968\n",
      "\u001b[32m[2020-07-19 16:06:11] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-19 16:06:11] __main__ INFO: \u001b[0mTrain 77 53428\n",
      "\u001b[32m[2020-07-19 16:06:43] __main__ INFO: \u001b[0mEpoch 77 Step 100/703 lr 0.100000 loss 0.7450 (0.8191) acc@1 0.7188 (0.6948) acc@5 0.9062 (0.9050)\n",
      "\u001b[32m[2020-07-19 16:07:15] __main__ INFO: \u001b[0mEpoch 77 Step 200/703 lr 0.100000 loss 0.7893 (0.8252) acc@1 0.7500 (0.6913) acc@5 0.9375 (0.9027)\n",
      "\u001b[32m[2020-07-19 16:07:47] __main__ INFO: \u001b[0mEpoch 77 Step 300/703 lr 0.100000 loss 0.8317 (0.8295) acc@1 0.7188 (0.6924) acc@5 0.9062 (0.9005)\n",
      "\u001b[32m[2020-07-19 16:08:19] __main__ INFO: \u001b[0mEpoch 77 Step 400/703 lr 0.100000 loss 0.9630 (0.8458) acc@1 0.6250 (0.6857) acc@5 0.9219 (0.8978)\n",
      "\u001b[32m[2020-07-19 16:08:51] __main__ INFO: \u001b[0mEpoch 77 Step 500/703 lr 0.100000 loss 0.7021 (0.8525) acc@1 0.7344 (0.6830) acc@5 0.9531 (0.8974)\n",
      "\u001b[32m[2020-07-19 16:09:23] __main__ INFO: \u001b[0mEpoch 77 Step 600/703 lr 0.100000 loss 1.0341 (0.8602) acc@1 0.6250 (0.6796) acc@5 0.8594 (0.8969)\n",
      "\u001b[32m[2020-07-19 16:09:55] __main__ INFO: \u001b[0mEpoch 77 Step 700/703 lr 0.100000 loss 0.7649 (0.8671) acc@1 0.7344 (0.6779) acc@5 0.8750 (0.8965)\n",
      "\u001b[32m[2020-07-19 16:09:56] __main__ INFO: \u001b[0mEpoch 77 Step 703/703 lr 0.100000 loss 0.8501 (0.8673) acc@1 0.7188 (0.6779) acc@5 0.9531 (0.8966)\n",
      "\u001b[32m[2020-07-19 16:09:56] __main__ INFO: \u001b[0mElapsed 224.69\n",
      "\u001b[32m[2020-07-19 16:09:56] __main__ INFO: \u001b[0mVal 77\n",
      "\u001b[32m[2020-07-19 16:10:04] __main__ INFO: \u001b[0mEpoch 77 loss 0.3929 acc@1 0.8646 acc@5 0.9950\n",
      "\u001b[32m[2020-07-19 16:10:04] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-19 16:10:04] __main__ INFO: \u001b[0mTrain 78 54131\n",
      "\u001b[32m[2020-07-19 16:10:36] __main__ INFO: \u001b[0mEpoch 78 Step 100/703 lr 0.100000 loss 0.8749 (0.8599) acc@1 0.7031 (0.6808) acc@5 0.9219 (0.8978)\n",
      "\u001b[32m[2020-07-19 16:11:08] __main__ INFO: \u001b[0mEpoch 78 Step 200/703 lr 0.100000 loss 0.9522 (0.8502) acc@1 0.6719 (0.6834) acc@5 0.9219 (0.8970)\n",
      "\u001b[32m[2020-07-19 16:11:40] __main__ INFO: \u001b[0mEpoch 78 Step 300/703 lr 0.100000 loss 0.9199 (0.8550) acc@1 0.7344 (0.6810) acc@5 0.8906 (0.8989)\n",
      "\u001b[32m[2020-07-19 16:12:12] __main__ INFO: \u001b[0mEpoch 78 Step 400/703 lr 0.100000 loss 0.8531 (0.8576) acc@1 0.7188 (0.6822) acc@5 0.8594 (0.8989)\n",
      "\u001b[32m[2020-07-19 16:12:44] __main__ INFO: \u001b[0mEpoch 78 Step 500/703 lr 0.100000 loss 1.0698 (0.8642) acc@1 0.5938 (0.6797) acc@5 0.8906 (0.8984)\n",
      "\u001b[32m[2020-07-19 16:13:16] __main__ INFO: \u001b[0mEpoch 78 Step 600/703 lr 0.100000 loss 1.1823 (0.8648) acc@1 0.6094 (0.6798) acc@5 0.8594 (0.8988)\n",
      "\u001b[32m[2020-07-19 16:13:48] __main__ INFO: \u001b[0mEpoch 78 Step 700/703 lr 0.100000 loss 0.8678 (0.8691) acc@1 0.6250 (0.6780) acc@5 0.8125 (0.8978)\n",
      "\u001b[32m[2020-07-19 16:13:49] __main__ INFO: \u001b[0mEpoch 78 Step 703/703 lr 0.100000 loss 0.7035 (0.8685) acc@1 0.7500 (0.6782) acc@5 0.9062 (0.8978)\n",
      "\u001b[32m[2020-07-19 16:13:49] __main__ INFO: \u001b[0mElapsed 225.01\n",
      "\u001b[32m[2020-07-19 16:13:49] __main__ INFO: \u001b[0mVal 78\n",
      "\u001b[32m[2020-07-19 16:13:56] __main__ INFO: \u001b[0mEpoch 78 loss 0.3887 acc@1 0.8704 acc@5 0.9954\n",
      "\u001b[32m[2020-07-19 16:13:56] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-19 16:13:56] __main__ INFO: \u001b[0mTrain 79 54834\n",
      "\u001b[32m[2020-07-19 16:14:28] __main__ INFO: \u001b[0mEpoch 79 Step 100/703 lr 0.100000 loss 0.6546 (0.8228) acc@1 0.7656 (0.6963) acc@5 0.9375 (0.8995)\n",
      "\u001b[32m[2020-07-19 16:15:00] __main__ INFO: \u001b[0mEpoch 79 Step 200/703 lr 0.100000 loss 1.0145 (0.8481) acc@1 0.6406 (0.6866) acc@5 0.8438 (0.8973)\n",
      "\u001b[32m[2020-07-19 16:15:32] __main__ INFO: \u001b[0mEpoch 79 Step 300/703 lr 0.100000 loss 0.8804 (0.8569) acc@1 0.6562 (0.6830) acc@5 0.9219 (0.8968)\n",
      "\u001b[32m[2020-07-19 16:16:04] __main__ INFO: \u001b[0mEpoch 79 Step 400/703 lr 0.100000 loss 0.9063 (0.8661) acc@1 0.6562 (0.6786) acc@5 0.8594 (0.8970)\n",
      "\u001b[32m[2020-07-19 16:16:36] __main__ INFO: \u001b[0mEpoch 79 Step 500/703 lr 0.100000 loss 1.0298 (0.8654) acc@1 0.6406 (0.6791) acc@5 0.8281 (0.8980)\n",
      "\u001b[32m[2020-07-19 16:17:08] __main__ INFO: \u001b[0mEpoch 79 Step 600/703 lr 0.100000 loss 0.9665 (0.8643) acc@1 0.6250 (0.6794) acc@5 0.9531 (0.8989)\n",
      "\u001b[32m[2020-07-19 16:17:40] __main__ INFO: \u001b[0mEpoch 79 Step 700/703 lr 0.100000 loss 0.7352 (0.8643) acc@1 0.7812 (0.6793) acc@5 0.9531 (0.8984)\n",
      "\u001b[32m[2020-07-19 16:17:41] __main__ INFO: \u001b[0mEpoch 79 Step 703/703 lr 0.100000 loss 0.7794 (0.8642) acc@1 0.6719 (0.6792) acc@5 0.9375 (0.8984)\n",
      "\u001b[32m[2020-07-19 16:17:41] __main__ INFO: \u001b[0mElapsed 224.88\n",
      "\u001b[32m[2020-07-19 16:17:41] __main__ INFO: \u001b[0mVal 79\n",
      "\u001b[32m[2020-07-19 16:17:49] __main__ INFO: \u001b[0mEpoch 79 loss 0.4182 acc@1 0.8620 acc@5 0.9950\n",
      "\u001b[32m[2020-07-19 16:17:49] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-19 16:17:49] __main__ INFO: \u001b[0mTrain 80 55537\n",
      "\u001b[32m[2020-07-19 16:18:21] __main__ INFO: \u001b[0mEpoch 80 Step 100/703 lr 0.100000 loss 0.7166 (0.8394) acc@1 0.7500 (0.6927) acc@5 0.8438 (0.8964)\n",
      "\u001b[32m[2020-07-19 16:18:53] __main__ INFO: \u001b[0mEpoch 80 Step 200/703 lr 0.100000 loss 0.8392 (0.8439) acc@1 0.6719 (0.6905) acc@5 0.9062 (0.8989)\n",
      "\u001b[32m[2020-07-19 16:19:25] __main__ INFO: \u001b[0mEpoch 80 Step 300/703 lr 0.100000 loss 0.8321 (0.8493) acc@1 0.7344 (0.6869) acc@5 0.9219 (0.8977)\n",
      "\u001b[32m[2020-07-19 16:19:57] __main__ INFO: \u001b[0mEpoch 80 Step 400/703 lr 0.100000 loss 0.8711 (0.8558) acc@1 0.6875 (0.6847) acc@5 0.9531 (0.8979)\n",
      "\u001b[32m[2020-07-19 16:20:29] __main__ INFO: \u001b[0mEpoch 80 Step 500/703 lr 0.100000 loss 1.0064 (0.8584) acc@1 0.6250 (0.6830) acc@5 0.8594 (0.8984)\n",
      "\u001b[32m[2020-07-19 16:21:01] __main__ INFO: \u001b[0mEpoch 80 Step 600/703 lr 0.100000 loss 0.7681 (0.8634) acc@1 0.7500 (0.6814) acc@5 0.9219 (0.8973)\n",
      "\u001b[32m[2020-07-19 16:21:33] __main__ INFO: \u001b[0mEpoch 80 Step 700/703 lr 0.100000 loss 0.9336 (0.8624) acc@1 0.6719 (0.6811) acc@5 0.8906 (0.8977)\n",
      "\u001b[32m[2020-07-19 16:21:34] __main__ INFO: \u001b[0mEpoch 80 Step 703/703 lr 0.100000 loss 1.1523 (0.8635) acc@1 0.5469 (0.6807) acc@5 0.8438 (0.8976)\n",
      "\u001b[32m[2020-07-19 16:21:34] __main__ INFO: \u001b[0mElapsed 225.11\n",
      "\u001b[32m[2020-07-19 16:21:34] __main__ INFO: \u001b[0mVal 80\n",
      "\u001b[32m[2020-07-19 16:21:42] __main__ INFO: \u001b[0mEpoch 80 loss 0.4571 acc@1 0.8532 acc@5 0.9942\n",
      "\u001b[32m[2020-07-19 16:21:42] __main__ INFO: \u001b[0mElapsed 7.75\n",
      "\u001b[32m[2020-07-19 16:21:42] __main__ INFO: \u001b[0mTrain 81 56240\n",
      "\u001b[32m[2020-07-19 16:22:14] __main__ INFO: \u001b[0mEpoch 81 Step 100/703 lr 0.100000 loss 0.8730 (0.8521) acc@1 0.6406 (0.6819) acc@5 0.8750 (0.9003)\n",
      "\u001b[32m[2020-07-19 16:22:46] __main__ INFO: \u001b[0mEpoch 81 Step 200/703 lr 0.100000 loss 0.7977 (0.8446) acc@1 0.7031 (0.6877) acc@5 0.8594 (0.9002)\n",
      "\u001b[32m[2020-07-19 16:23:18] __main__ INFO: \u001b[0mEpoch 81 Step 300/703 lr 0.100000 loss 0.8050 (0.8520) acc@1 0.6406 (0.6845) acc@5 0.9688 (0.8987)\n",
      "\u001b[32m[2020-07-19 16:23:50] __main__ INFO: \u001b[0mEpoch 81 Step 400/703 lr 0.100000 loss 0.9683 (0.8496) acc@1 0.6406 (0.6855) acc@5 0.8125 (0.8988)\n",
      "\u001b[32m[2020-07-19 16:24:22] __main__ INFO: \u001b[0mEpoch 81 Step 500/703 lr 0.100000 loss 1.0992 (0.8585) acc@1 0.5625 (0.6822) acc@5 0.8125 (0.8977)\n",
      "\u001b[32m[2020-07-19 16:24:54] __main__ INFO: \u001b[0mEpoch 81 Step 600/703 lr 0.100000 loss 0.8068 (0.8593) acc@1 0.7188 (0.6820) acc@5 0.8750 (0.8985)\n",
      "\u001b[32m[2020-07-19 16:25:26] __main__ INFO: \u001b[0mEpoch 81 Step 700/703 lr 0.100000 loss 1.0152 (0.8646) acc@1 0.6562 (0.6804) acc@5 0.8594 (0.8987)\n",
      "\u001b[32m[2020-07-19 16:25:27] __main__ INFO: \u001b[0mEpoch 81 Step 703/703 lr 0.100000 loss 0.8376 (0.8646) acc@1 0.7188 (0.6806) acc@5 0.9062 (0.8986)\n",
      "\u001b[32m[2020-07-19 16:25:27] __main__ INFO: \u001b[0mElapsed 225.04\n",
      "\u001b[32m[2020-07-19 16:25:27] __main__ INFO: \u001b[0mVal 81\n",
      "\u001b[32m[2020-07-19 16:25:35] __main__ INFO: \u001b[0mEpoch 81 loss 0.5852 acc@1 0.8132 acc@5 0.9946\n",
      "\u001b[32m[2020-07-19 16:25:35] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-19 16:25:35] __main__ INFO: \u001b[0mTrain 82 56943\n",
      "\u001b[32m[2020-07-19 16:26:07] __main__ INFO: \u001b[0mEpoch 82 Step 100/703 lr 0.100000 loss 0.8970 (0.8256) acc@1 0.6094 (0.6970) acc@5 0.8906 (0.9011)\n",
      "\u001b[32m[2020-07-19 16:26:39] __main__ INFO: \u001b[0mEpoch 82 Step 200/703 lr 0.100000 loss 0.8971 (0.8344) acc@1 0.6562 (0.6923) acc@5 0.8750 (0.8991)\n",
      "\u001b[32m[2020-07-19 16:27:11] __main__ INFO: \u001b[0mEpoch 82 Step 300/703 lr 0.100000 loss 0.6482 (0.8484) acc@1 0.7656 (0.6872) acc@5 0.9688 (0.9001)\n",
      "\u001b[32m[2020-07-19 16:27:43] __main__ INFO: \u001b[0mEpoch 82 Step 400/703 lr 0.100000 loss 1.0554 (0.8582) acc@1 0.6094 (0.6841) acc@5 0.8594 (0.9001)\n",
      "\u001b[32m[2020-07-19 16:28:15] __main__ INFO: \u001b[0mEpoch 82 Step 500/703 lr 0.100000 loss 0.6773 (0.8600) acc@1 0.7344 (0.6831) acc@5 0.9062 (0.8992)\n",
      "\u001b[32m[2020-07-19 16:28:47] __main__ INFO: \u001b[0mEpoch 82 Step 600/703 lr 0.100000 loss 0.7872 (0.8618) acc@1 0.6875 (0.6816) acc@5 0.8906 (0.8988)\n",
      "\u001b[32m[2020-07-19 16:29:19] __main__ INFO: \u001b[0mEpoch 82 Step 700/703 lr 0.100000 loss 0.8517 (0.8658) acc@1 0.7188 (0.6800) acc@5 0.8750 (0.8982)\n",
      "\u001b[32m[2020-07-19 16:29:20] __main__ INFO: \u001b[0mEpoch 82 Step 703/703 lr 0.100000 loss 1.1245 (0.8661) acc@1 0.5938 (0.6800) acc@5 0.8750 (0.8982)\n",
      "\u001b[32m[2020-07-19 16:29:20] __main__ INFO: \u001b[0mElapsed 225.14\n",
      "\u001b[32m[2020-07-19 16:29:20] __main__ INFO: \u001b[0mVal 82\n",
      "\u001b[32m[2020-07-19 16:29:28] __main__ INFO: \u001b[0mEpoch 82 loss 0.5317 acc@1 0.8386 acc@5 0.9910\n",
      "\u001b[32m[2020-07-19 16:29:28] __main__ INFO: \u001b[0mElapsed 7.75\n",
      "\u001b[32m[2020-07-19 16:29:28] __main__ INFO: \u001b[0mTrain 83 57646\n",
      "\u001b[32m[2020-07-19 16:30:00] __main__ INFO: \u001b[0mEpoch 83 Step 100/703 lr 0.100000 loss 0.5687 (0.8363) acc@1 0.7812 (0.6863) acc@5 0.9219 (0.8928)\n",
      "\u001b[32m[2020-07-19 16:30:32] __main__ INFO: \u001b[0mEpoch 83 Step 200/703 lr 0.100000 loss 0.8088 (0.8393) acc@1 0.7031 (0.6862) acc@5 0.9062 (0.8937)\n",
      "\u001b[32m[2020-07-19 16:31:04] __main__ INFO: \u001b[0mEpoch 83 Step 300/703 lr 0.100000 loss 0.7240 (0.8378) acc@1 0.7031 (0.6875) acc@5 0.9062 (0.8972)\n",
      "\u001b[32m[2020-07-19 16:31:36] __main__ INFO: \u001b[0mEpoch 83 Step 400/703 lr 0.100000 loss 0.8201 (0.8509) acc@1 0.6719 (0.6835) acc@5 0.9375 (0.8975)\n",
      "\u001b[32m[2020-07-19 16:32:08] __main__ INFO: \u001b[0mEpoch 83 Step 500/703 lr 0.100000 loss 0.9001 (0.8533) acc@1 0.6875 (0.6817) acc@5 0.9688 (0.8989)\n",
      "\u001b[32m[2020-07-19 16:32:40] __main__ INFO: \u001b[0mEpoch 83 Step 600/703 lr 0.100000 loss 0.8861 (0.8569) acc@1 0.6562 (0.6810) acc@5 0.8906 (0.8984)\n",
      "\u001b[32m[2020-07-19 16:33:12] __main__ INFO: \u001b[0mEpoch 83 Step 700/703 lr 0.100000 loss 0.9481 (0.8588) acc@1 0.6875 (0.6803) acc@5 0.8906 (0.8987)\n",
      "\u001b[32m[2020-07-19 16:33:13] __main__ INFO: \u001b[0mEpoch 83 Step 703/703 lr 0.100000 loss 0.8402 (0.8593) acc@1 0.6562 (0.6800) acc@5 0.8906 (0.8986)\n",
      "\u001b[32m[2020-07-19 16:33:13] __main__ INFO: \u001b[0mElapsed 225.29\n",
      "\u001b[32m[2020-07-19 16:33:13] __main__ INFO: \u001b[0mVal 83\n",
      "\u001b[32m[2020-07-19 16:33:21] __main__ INFO: \u001b[0mEpoch 83 loss 0.4807 acc@1 0.8452 acc@5 0.9948\n",
      "\u001b[32m[2020-07-19 16:33:21] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-19 16:33:21] __main__ INFO: \u001b[0mTrain 84 58349\n",
      "\u001b[32m[2020-07-19 16:33:53] __main__ INFO: \u001b[0mEpoch 84 Step 100/703 lr 0.100000 loss 1.0453 (0.8184) acc@1 0.5625 (0.6956) acc@5 0.7969 (0.8998)\n",
      "\u001b[32m[2020-07-19 16:34:25] __main__ INFO: \u001b[0mEpoch 84 Step 200/703 lr 0.100000 loss 0.8936 (0.8375) acc@1 0.6562 (0.6886) acc@5 0.9375 (0.9002)\n",
      "\u001b[32m[2020-07-19 16:34:57] __main__ INFO: \u001b[0mEpoch 84 Step 300/703 lr 0.100000 loss 0.7477 (0.8450) acc@1 0.7344 (0.6859) acc@5 0.8594 (0.8988)\n",
      "\u001b[32m[2020-07-19 16:35:29] __main__ INFO: \u001b[0mEpoch 84 Step 400/703 lr 0.100000 loss 1.1057 (0.8533) acc@1 0.5156 (0.6818) acc@5 0.8438 (0.8978)\n",
      "\u001b[32m[2020-07-19 16:36:01] __main__ INFO: \u001b[0mEpoch 84 Step 500/703 lr 0.100000 loss 0.7605 (0.8540) acc@1 0.7812 (0.6817) acc@5 0.9062 (0.8980)\n",
      "\u001b[32m[2020-07-19 16:36:33] __main__ INFO: \u001b[0mEpoch 84 Step 600/703 lr 0.100000 loss 1.0111 (0.8555) acc@1 0.6406 (0.6820) acc@5 0.8438 (0.8982)\n",
      "\u001b[32m[2020-07-19 16:37:05] __main__ INFO: \u001b[0mEpoch 84 Step 700/703 lr 0.100000 loss 0.8230 (0.8608) acc@1 0.6719 (0.6799) acc@5 0.9219 (0.8988)\n",
      "\u001b[32m[2020-07-19 16:37:06] __main__ INFO: \u001b[0mEpoch 84 Step 703/703 lr 0.100000 loss 0.9413 (0.8610) acc@1 0.5938 (0.6798) acc@5 0.8906 (0.8988)\n",
      "\u001b[32m[2020-07-19 16:37:06] __main__ INFO: \u001b[0mElapsed 225.27\n",
      "\u001b[32m[2020-07-19 16:37:06] __main__ INFO: \u001b[0mVal 84\n",
      "\u001b[32m[2020-07-19 16:37:14] __main__ INFO: \u001b[0mEpoch 84 loss 0.3767 acc@1 0.8746 acc@5 0.9972\n",
      "\u001b[32m[2020-07-19 16:37:14] __main__ INFO: \u001b[0mElapsed 7.74\n",
      "\u001b[32m[2020-07-19 16:37:14] __main__ INFO: \u001b[0mTrain 85 59052\n",
      "\u001b[32m[2020-07-19 16:37:46] __main__ INFO: \u001b[0mEpoch 85 Step 100/703 lr 0.100000 loss 0.9094 (0.8141) acc@1 0.6562 (0.6977) acc@5 0.8594 (0.9019)\n",
      "\u001b[32m[2020-07-19 16:38:18] __main__ INFO: \u001b[0mEpoch 85 Step 200/703 lr 0.100000 loss 0.7635 (0.8231) acc@1 0.7188 (0.6949) acc@5 0.8906 (0.9005)\n",
      "\u001b[32m[2020-07-19 16:38:50] __main__ INFO: \u001b[0mEpoch 85 Step 300/703 lr 0.100000 loss 0.8789 (0.8381) acc@1 0.6875 (0.6879) acc@5 0.8750 (0.9019)\n",
      "\u001b[32m[2020-07-19 16:39:21] __main__ INFO: \u001b[0mEpoch 85 Step 400/703 lr 0.100000 loss 0.8859 (0.8480) acc@1 0.7031 (0.6854) acc@5 0.8750 (0.9000)\n",
      "\u001b[32m[2020-07-19 16:39:53] __main__ INFO: \u001b[0mEpoch 85 Step 500/703 lr 0.100000 loss 0.7861 (0.8536) acc@1 0.7344 (0.6842) acc@5 0.9375 (0.8990)\n",
      "\u001b[32m[2020-07-19 16:40:25] __main__ INFO: \u001b[0mEpoch 85 Step 600/703 lr 0.100000 loss 0.9077 (0.8580) acc@1 0.6719 (0.6839) acc@5 0.9219 (0.8983)\n",
      "\u001b[32m[2020-07-19 16:40:58] __main__ INFO: \u001b[0mEpoch 85 Step 700/703 lr 0.100000 loss 1.0902 (0.8577) acc@1 0.5000 (0.6842) acc@5 0.8594 (0.8986)\n",
      "\u001b[32m[2020-07-19 16:40:59] __main__ INFO: \u001b[0mEpoch 85 Step 703/703 lr 0.100000 loss 0.7678 (0.8573) acc@1 0.7344 (0.6843) acc@5 0.9375 (0.8988)\n",
      "\u001b[32m[2020-07-19 16:40:59] __main__ INFO: \u001b[0mElapsed 224.98\n",
      "\u001b[32m[2020-07-19 16:40:59] __main__ INFO: \u001b[0mVal 85\n",
      "\u001b[32m[2020-07-19 16:41:06] __main__ INFO: \u001b[0mEpoch 85 loss 0.3482 acc@1 0.8856 acc@5 0.9962\n",
      "\u001b[32m[2020-07-19 16:41:06] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-19 16:41:06] __main__ INFO: \u001b[0mTrain 86 59755\n",
      "\u001b[32m[2020-07-19 16:41:39] __main__ INFO: \u001b[0mEpoch 86 Step 100/703 lr 0.100000 loss 0.9683 (0.8391) acc@1 0.5938 (0.6842) acc@5 0.9062 (0.8962)\n",
      "\u001b[32m[2020-07-19 16:42:10] __main__ INFO: \u001b[0mEpoch 86 Step 200/703 lr 0.100000 loss 1.1273 (0.8433) acc@1 0.6562 (0.6832) acc@5 0.8438 (0.8980)\n",
      "\u001b[32m[2020-07-19 16:42:43] __main__ INFO: \u001b[0mEpoch 86 Step 300/703 lr 0.100000 loss 0.7742 (0.8446) acc@1 0.7188 (0.6845) acc@5 0.9219 (0.8979)\n",
      "\u001b[32m[2020-07-19 16:43:15] __main__ INFO: \u001b[0mEpoch 86 Step 400/703 lr 0.100000 loss 0.6460 (0.8464) acc@1 0.7656 (0.6855) acc@5 0.9688 (0.8988)\n",
      "\u001b[32m[2020-07-19 16:43:47] __main__ INFO: \u001b[0mEpoch 86 Step 500/703 lr 0.100000 loss 0.9526 (0.8502) acc@1 0.6406 (0.6847) acc@5 0.9062 (0.8980)\n",
      "\u001b[32m[2020-07-19 16:44:19] __main__ INFO: \u001b[0mEpoch 86 Step 600/703 lr 0.100000 loss 0.7649 (0.8532) acc@1 0.6875 (0.6832) acc@5 0.9062 (0.8984)\n",
      "\u001b[32m[2020-07-19 16:44:51] __main__ INFO: \u001b[0mEpoch 86 Step 700/703 lr 0.100000 loss 0.7834 (0.8578) acc@1 0.7031 (0.6817) acc@5 0.9531 (0.8979)\n",
      "\u001b[32m[2020-07-19 16:44:52] __main__ INFO: \u001b[0mEpoch 86 Step 703/703 lr 0.100000 loss 0.9677 (0.8579) acc@1 0.6094 (0.6815) acc@5 0.8906 (0.8979)\n",
      "\u001b[32m[2020-07-19 16:44:52] __main__ INFO: \u001b[0mElapsed 225.18\n",
      "\u001b[32m[2020-07-19 16:44:52] __main__ INFO: \u001b[0mVal 86\n",
      "\u001b[32m[2020-07-19 16:44:59] __main__ INFO: \u001b[0mEpoch 86 loss 0.3881 acc@1 0.8696 acc@5 0.9964\n",
      "\u001b[32m[2020-07-19 16:44:59] __main__ INFO: \u001b[0mElapsed 7.75\n",
      "\u001b[32m[2020-07-19 16:44:59] __main__ INFO: \u001b[0mTrain 87 60458\n",
      "\u001b[32m[2020-07-19 16:45:31] __main__ INFO: \u001b[0mEpoch 87 Step 100/703 lr 0.100000 loss 0.7208 (0.8229) acc@1 0.7344 (0.6906) acc@5 0.9062 (0.9023)\n",
      "\u001b[32m[2020-07-19 16:46:03] __main__ INFO: \u001b[0mEpoch 87 Step 200/703 lr 0.100000 loss 0.8569 (0.8235) acc@1 0.6719 (0.6914) acc@5 0.9219 (0.9039)\n",
      "\u001b[32m[2020-07-19 16:46:35] __main__ INFO: \u001b[0mEpoch 87 Step 300/703 lr 0.100000 loss 0.8723 (0.8361) acc@1 0.7031 (0.6894) acc@5 0.8438 (0.9013)\n",
      "\u001b[32m[2020-07-19 16:47:07] __main__ INFO: \u001b[0mEpoch 87 Step 400/703 lr 0.100000 loss 1.2659 (0.8421) acc@1 0.5469 (0.6859) acc@5 0.8438 (0.8998)\n",
      "\u001b[32m[2020-07-19 16:47:39] __main__ INFO: \u001b[0mEpoch 87 Step 500/703 lr 0.100000 loss 0.8462 (0.8496) acc@1 0.7188 (0.6829) acc@5 0.9531 (0.8985)\n",
      "\u001b[32m[2020-07-19 16:48:11] __main__ INFO: \u001b[0mEpoch 87 Step 600/703 lr 0.100000 loss 0.8976 (0.8501) acc@1 0.6250 (0.6839) acc@5 0.9375 (0.8989)\n",
      "\u001b[32m[2020-07-19 16:48:43] __main__ INFO: \u001b[0mEpoch 87 Step 700/703 lr 0.100000 loss 0.8587 (0.8563) acc@1 0.6562 (0.6822) acc@5 0.9375 (0.8990)\n",
      "\u001b[32m[2020-07-19 16:48:44] __main__ INFO: \u001b[0mEpoch 87 Step 703/703 lr 0.100000 loss 0.8704 (0.8560) acc@1 0.7031 (0.6823) acc@5 0.9375 (0.8993)\n",
      "\u001b[32m[2020-07-19 16:48:44] __main__ INFO: \u001b[0mElapsed 225.03\n",
      "\u001b[32m[2020-07-19 16:48:44] __main__ INFO: \u001b[0mVal 87\n",
      "\u001b[32m[2020-07-19 16:48:52] __main__ INFO: \u001b[0mEpoch 87 loss 0.4396 acc@1 0.8556 acc@5 0.9956\n",
      "\u001b[32m[2020-07-19 16:48:52] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-19 16:48:52] __main__ INFO: \u001b[0mTrain 88 61161\n",
      "\u001b[32m[2020-07-19 16:49:24] __main__ INFO: \u001b[0mEpoch 88 Step 100/703 lr 0.100000 loss 0.7184 (0.8216) acc@1 0.7188 (0.6980) acc@5 0.8906 (0.8994)\n",
      "\u001b[32m[2020-07-19 16:49:56] __main__ INFO: \u001b[0mEpoch 88 Step 200/703 lr 0.100000 loss 0.7958 (0.8337) acc@1 0.6719 (0.6916) acc@5 0.9219 (0.8977)\n",
      "\u001b[32m[2020-07-19 16:50:28] __main__ INFO: \u001b[0mEpoch 88 Step 300/703 lr 0.100000 loss 0.7652 (0.8426) acc@1 0.7188 (0.6894) acc@5 0.9844 (0.9002)\n",
      "\u001b[32m[2020-07-19 16:51:00] __main__ INFO: \u001b[0mEpoch 88 Step 400/703 lr 0.100000 loss 0.7237 (0.8478) acc@1 0.7344 (0.6877) acc@5 0.9219 (0.9006)\n",
      "\u001b[32m[2020-07-19 16:51:32] __main__ INFO: \u001b[0mEpoch 88 Step 500/703 lr 0.100000 loss 0.7789 (0.8477) acc@1 0.6250 (0.6867) acc@5 0.9375 (0.9008)\n",
      "\u001b[32m[2020-07-19 16:52:04] __main__ INFO: \u001b[0mEpoch 88 Step 600/703 lr 0.100000 loss 0.8235 (0.8532) acc@1 0.6406 (0.6842) acc@5 0.9062 (0.8994)\n",
      "\u001b[32m[2020-07-19 16:52:36] __main__ INFO: \u001b[0mEpoch 88 Step 700/703 lr 0.100000 loss 0.8225 (0.8583) acc@1 0.6875 (0.6827) acc@5 0.9062 (0.8991)\n",
      "\u001b[32m[2020-07-19 16:52:37] __main__ INFO: \u001b[0mEpoch 88 Step 703/703 lr 0.100000 loss 0.8462 (0.8586) acc@1 0.6250 (0.6826) acc@5 0.8906 (0.8990)\n",
      "\u001b[32m[2020-07-19 16:52:37] __main__ INFO: \u001b[0mElapsed 224.77\n",
      "\u001b[32m[2020-07-19 16:52:37] __main__ INFO: \u001b[0mVal 88\n",
      "\u001b[32m[2020-07-19 16:52:45] __main__ INFO: \u001b[0mEpoch 88 loss 0.3789 acc@1 0.8744 acc@5 0.9950\n",
      "\u001b[32m[2020-07-19 16:52:45] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-19 16:52:45] __main__ INFO: \u001b[0mTrain 89 61864\n",
      "\u001b[32m[2020-07-19 16:53:17] __main__ INFO: \u001b[0mEpoch 89 Step 100/703 lr 0.100000 loss 0.9963 (0.7883) acc@1 0.6406 (0.7125) acc@5 0.9375 (0.9064)\n",
      "\u001b[32m[2020-07-19 16:53:49] __main__ INFO: \u001b[0mEpoch 89 Step 200/703 lr 0.100000 loss 0.8576 (0.8295) acc@1 0.6406 (0.6945) acc@5 0.8438 (0.8995)\n",
      "\u001b[32m[2020-07-19 16:54:21] __main__ INFO: \u001b[0mEpoch 89 Step 300/703 lr 0.100000 loss 0.7450 (0.8397) acc@1 0.6875 (0.6903) acc@5 0.9219 (0.9001)\n",
      "\u001b[32m[2020-07-19 16:54:53] __main__ INFO: \u001b[0mEpoch 89 Step 400/703 lr 0.100000 loss 0.9214 (0.8432) acc@1 0.6875 (0.6887) acc@5 0.9062 (0.9007)\n",
      "\u001b[32m[2020-07-19 16:55:25] __main__ INFO: \u001b[0mEpoch 89 Step 500/703 lr 0.100000 loss 0.8848 (0.8421) acc@1 0.7031 (0.6888) acc@5 0.8594 (0.9001)\n",
      "\u001b[32m[2020-07-19 16:55:57] __main__ INFO: \u001b[0mEpoch 89 Step 600/703 lr 0.100000 loss 0.6590 (0.8448) acc@1 0.7812 (0.6868) acc@5 0.9531 (0.8990)\n",
      "\u001b[32m[2020-07-19 16:56:29] __main__ INFO: \u001b[0mEpoch 89 Step 700/703 lr 0.100000 loss 1.0244 (0.8534) acc@1 0.6094 (0.6843) acc@5 0.8906 (0.8985)\n",
      "\u001b[32m[2020-07-19 16:56:30] __main__ INFO: \u001b[0mEpoch 89 Step 703/703 lr 0.100000 loss 0.8587 (0.8535) acc@1 0.6719 (0.6842) acc@5 0.9531 (0.8986)\n",
      "\u001b[32m[2020-07-19 16:56:30] __main__ INFO: \u001b[0mElapsed 225.20\n",
      "\u001b[32m[2020-07-19 16:56:30] __main__ INFO: \u001b[0mVal 89\n",
      "\u001b[32m[2020-07-19 16:56:38] __main__ INFO: \u001b[0mEpoch 89 loss 0.3285 acc@1 0.8900 acc@5 0.9960\n",
      "\u001b[32m[2020-07-19 16:56:38] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-19 16:56:38] __main__ INFO: \u001b[0mTrain 90 62567\n",
      "\u001b[32m[2020-07-19 16:57:10] __main__ INFO: \u001b[0mEpoch 90 Step 100/703 lr 0.100000 loss 0.9759 (0.8369) acc@1 0.7188 (0.6895) acc@5 0.9062 (0.9003)\n",
      "\u001b[32m[2020-07-19 16:57:42] __main__ INFO: \u001b[0mEpoch 90 Step 200/703 lr 0.100000 loss 0.8553 (0.8354) acc@1 0.7188 (0.6898) acc@5 0.9062 (0.9014)\n",
      "\u001b[32m[2020-07-19 16:58:14] __main__ INFO: \u001b[0mEpoch 90 Step 300/703 lr 0.100000 loss 0.9803 (0.8410) acc@1 0.6406 (0.6883) acc@5 0.8438 (0.9006)\n",
      "\u001b[32m[2020-07-19 16:58:46] __main__ INFO: \u001b[0mEpoch 90 Step 400/703 lr 0.100000 loss 0.8204 (0.8369) acc@1 0.6719 (0.6893) acc@5 0.8906 (0.9004)\n",
      "\u001b[32m[2020-07-19 16:59:18] __main__ INFO: \u001b[0mEpoch 90 Step 500/703 lr 0.100000 loss 0.7709 (0.8398) acc@1 0.7031 (0.6877) acc@5 0.8750 (0.9011)\n",
      "\u001b[32m[2020-07-19 16:59:50] __main__ INFO: \u001b[0mEpoch 90 Step 600/703 lr 0.100000 loss 0.8616 (0.8488) acc@1 0.6719 (0.6846) acc@5 0.8750 (0.8996)\n",
      "\u001b[32m[2020-07-19 17:00:22] __main__ INFO: \u001b[0mEpoch 90 Step 700/703 lr 0.100000 loss 0.7273 (0.8524) acc@1 0.7500 (0.6838) acc@5 0.9688 (0.8991)\n",
      "\u001b[32m[2020-07-19 17:00:23] __main__ INFO: \u001b[0mEpoch 90 Step 703/703 lr 0.100000 loss 0.6438 (0.8523) acc@1 0.7500 (0.6838) acc@5 0.8750 (0.8990)\n",
      "\u001b[32m[2020-07-19 17:00:23] __main__ INFO: \u001b[0mElapsed 225.25\n",
      "\u001b[32m[2020-07-19 17:00:23] __main__ INFO: \u001b[0mVal 90\n",
      "\u001b[32m[2020-07-19 17:00:31] __main__ INFO: \u001b[0mEpoch 90 loss 0.3732 acc@1 0.8724 acc@5 0.9966\n",
      "\u001b[32m[2020-07-19 17:00:31] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-19 17:00:31] __main__ INFO: \u001b[0mTrain 91 63270\n",
      "\u001b[32m[2020-07-19 17:01:03] __main__ INFO: \u001b[0mEpoch 91 Step 100/703 lr 0.100000 loss 0.7814 (0.8047) acc@1 0.6562 (0.7022) acc@5 0.8438 (0.9022)\n",
      "\u001b[32m[2020-07-19 17:01:35] __main__ INFO: \u001b[0mEpoch 91 Step 200/703 lr 0.100000 loss 0.8174 (0.8007) acc@1 0.7031 (0.7052) acc@5 0.9219 (0.9036)\n",
      "\u001b[32m[2020-07-19 17:02:07] __main__ INFO: \u001b[0mEpoch 91 Step 300/703 lr 0.100000 loss 0.9437 (0.8195) acc@1 0.6250 (0.6960) acc@5 0.8438 (0.9038)\n",
      "\u001b[32m[2020-07-19 17:02:39] __main__ INFO: \u001b[0mEpoch 91 Step 400/703 lr 0.100000 loss 0.9172 (0.8229) acc@1 0.6719 (0.6955) acc@5 0.8906 (0.9037)\n",
      "\u001b[32m[2020-07-19 17:03:11] __main__ INFO: \u001b[0mEpoch 91 Step 500/703 lr 0.100000 loss 0.6535 (0.8310) acc@1 0.7969 (0.6923) acc@5 0.9375 (0.9038)\n",
      "\u001b[32m[2020-07-19 17:03:43] __main__ INFO: \u001b[0mEpoch 91 Step 600/703 lr 0.100000 loss 0.7818 (0.8414) acc@1 0.7500 (0.6889) acc@5 0.9688 (0.9020)\n",
      "\u001b[32m[2020-07-19 17:04:15] __main__ INFO: \u001b[0mEpoch 91 Step 700/703 lr 0.100000 loss 0.7902 (0.8480) acc@1 0.7031 (0.6867) acc@5 0.8750 (0.9008)\n",
      "\u001b[32m[2020-07-19 17:04:16] __main__ INFO: \u001b[0mEpoch 91 Step 703/703 lr 0.100000 loss 0.9070 (0.8477) acc@1 0.6719 (0.6869) acc@5 0.9062 (0.9008)\n",
      "\u001b[32m[2020-07-19 17:04:16] __main__ INFO: \u001b[0mElapsed 225.45\n",
      "\u001b[32m[2020-07-19 17:04:16] __main__ INFO: \u001b[0mVal 91\n",
      "\u001b[32m[2020-07-19 17:04:24] __main__ INFO: \u001b[0mEpoch 91 loss 0.4081 acc@1 0.8636 acc@5 0.9958\n",
      "\u001b[32m[2020-07-19 17:04:24] __main__ INFO: \u001b[0mElapsed 7.74\n",
      "\u001b[32m[2020-07-19 17:04:24] __main__ INFO: \u001b[0mTrain 92 63973\n",
      "\u001b[32m[2020-07-19 17:04:56] __main__ INFO: \u001b[0mEpoch 92 Step 100/703 lr 0.100000 loss 1.0459 (0.8357) acc@1 0.6094 (0.6952) acc@5 0.8594 (0.8964)\n",
      "\u001b[32m[2020-07-19 17:05:28] __main__ INFO: \u001b[0mEpoch 92 Step 200/703 lr 0.100000 loss 0.8685 (0.8431) acc@1 0.6719 (0.6855) acc@5 0.9062 (0.8985)\n",
      "\u001b[32m[2020-07-19 17:06:00] __main__ INFO: \u001b[0mEpoch 92 Step 300/703 lr 0.100000 loss 0.8291 (0.8393) acc@1 0.7031 (0.6879) acc@5 0.8750 (0.8999)\n",
      "\u001b[32m[2020-07-19 17:06:32] __main__ INFO: \u001b[0mEpoch 92 Step 400/703 lr 0.100000 loss 0.8312 (0.8494) acc@1 0.6719 (0.6846) acc@5 0.8906 (0.8990)\n",
      "\u001b[32m[2020-07-19 17:07:04] __main__ INFO: \u001b[0mEpoch 92 Step 500/703 lr 0.100000 loss 0.7922 (0.8565) acc@1 0.7031 (0.6820) acc@5 0.9375 (0.8974)\n",
      "\u001b[32m[2020-07-19 17:07:36] __main__ INFO: \u001b[0mEpoch 92 Step 600/703 lr 0.100000 loss 0.7455 (0.8528) acc@1 0.7031 (0.6837) acc@5 0.9219 (0.8983)\n",
      "\u001b[32m[2020-07-19 17:08:08] __main__ INFO: \u001b[0mEpoch 92 Step 700/703 lr 0.100000 loss 0.9592 (0.8548) acc@1 0.5938 (0.6830) acc@5 0.8750 (0.8990)\n",
      "\u001b[32m[2020-07-19 17:08:09] __main__ INFO: \u001b[0mEpoch 92 Step 703/703 lr 0.100000 loss 0.8723 (0.8546) acc@1 0.7031 (0.6832) acc@5 0.9375 (0.8991)\n",
      "\u001b[32m[2020-07-19 17:08:09] __main__ INFO: \u001b[0mElapsed 224.86\n",
      "\u001b[32m[2020-07-19 17:08:09] __main__ INFO: \u001b[0mVal 92\n",
      "\u001b[32m[2020-07-19 17:08:16] __main__ INFO: \u001b[0mEpoch 92 loss 0.3689 acc@1 0.8774 acc@5 0.9962\n",
      "\u001b[32m[2020-07-19 17:08:16] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-19 17:08:16] __main__ INFO: \u001b[0mTrain 93 64676\n",
      "\u001b[32m[2020-07-19 17:08:49] __main__ INFO: \u001b[0mEpoch 93 Step 100/703 lr 0.100000 loss 0.8657 (0.8251) acc@1 0.6719 (0.6939) acc@5 0.8750 (0.8988)\n",
      "\u001b[32m[2020-07-19 17:09:21] __main__ INFO: \u001b[0mEpoch 93 Step 200/703 lr 0.100000 loss 0.7098 (0.8319) acc@1 0.7344 (0.6923) acc@5 0.9062 (0.8980)\n",
      "\u001b[32m[2020-07-19 17:09:53] __main__ INFO: \u001b[0mEpoch 93 Step 300/703 lr 0.100000 loss 0.6824 (0.8436) acc@1 0.7500 (0.6892) acc@5 0.9062 (0.8966)\n",
      "\u001b[32m[2020-07-19 17:10:25] __main__ INFO: \u001b[0mEpoch 93 Step 400/703 lr 0.100000 loss 0.7911 (0.8396) acc@1 0.6562 (0.6895) acc@5 0.8906 (0.8982)\n",
      "\u001b[32m[2020-07-19 17:10:56] __main__ INFO: \u001b[0mEpoch 93 Step 500/703 lr 0.100000 loss 1.0495 (0.8449) acc@1 0.5781 (0.6881) acc@5 0.8750 (0.8979)\n",
      "\u001b[32m[2020-07-19 17:11:28] __main__ INFO: \u001b[0mEpoch 93 Step 600/703 lr 0.100000 loss 0.7804 (0.8442) acc@1 0.6562 (0.6874) acc@5 0.8594 (0.8991)\n",
      "\u001b[32m[2020-07-19 17:12:00] __main__ INFO: \u001b[0mEpoch 93 Step 700/703 lr 0.100000 loss 1.0320 (0.8480) acc@1 0.5938 (0.6856) acc@5 0.8281 (0.8986)\n",
      "\u001b[32m[2020-07-19 17:12:01] __main__ INFO: \u001b[0mEpoch 93 Step 703/703 lr 0.100000 loss 1.0789 (0.8480) acc@1 0.6094 (0.6855) acc@5 0.8750 (0.8986)\n",
      "\u001b[32m[2020-07-19 17:12:01] __main__ INFO: \u001b[0mElapsed 224.77\n",
      "\u001b[32m[2020-07-19 17:12:01] __main__ INFO: \u001b[0mVal 93\n",
      "\u001b[32m[2020-07-19 17:12:09] __main__ INFO: \u001b[0mEpoch 93 loss 0.5043 acc@1 0.8394 acc@5 0.9930\n",
      "\u001b[32m[2020-07-19 17:12:09] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-19 17:12:09] __main__ INFO: \u001b[0mTrain 94 65379\n",
      "\u001b[32m[2020-07-19 17:12:41] __main__ INFO: \u001b[0mEpoch 94 Step 100/703 lr 0.100000 loss 1.1570 (0.8202) acc@1 0.5625 (0.6967) acc@5 0.7812 (0.9034)\n",
      "\u001b[32m[2020-07-19 17:13:13] __main__ INFO: \u001b[0mEpoch 94 Step 200/703 lr 0.100000 loss 0.8350 (0.8193) acc@1 0.6875 (0.6966) acc@5 0.8750 (0.9039)\n",
      "\u001b[32m[2020-07-19 17:13:45] __main__ INFO: \u001b[0mEpoch 94 Step 300/703 lr 0.100000 loss 0.8144 (0.8310) acc@1 0.6406 (0.6927) acc@5 0.9062 (0.9023)\n",
      "\u001b[32m[2020-07-19 17:14:17] __main__ INFO: \u001b[0mEpoch 94 Step 400/703 lr 0.100000 loss 0.9209 (0.8414) acc@1 0.6875 (0.6897) acc@5 0.8906 (0.9020)\n",
      "\u001b[32m[2020-07-19 17:14:49] __main__ INFO: \u001b[0mEpoch 94 Step 500/703 lr 0.100000 loss 0.8569 (0.8458) acc@1 0.5938 (0.6865) acc@5 0.8594 (0.9013)\n",
      "\u001b[32m[2020-07-19 17:15:21] __main__ INFO: \u001b[0mEpoch 94 Step 600/703 lr 0.100000 loss 0.8770 (0.8471) acc@1 0.7031 (0.6859) acc@5 0.8125 (0.9005)\n",
      "\u001b[32m[2020-07-19 17:15:53] __main__ INFO: \u001b[0mEpoch 94 Step 700/703 lr 0.100000 loss 1.0784 (0.8506) acc@1 0.6094 (0.6852) acc@5 0.9062 (0.9000)\n",
      "\u001b[32m[2020-07-19 17:15:54] __main__ INFO: \u001b[0mEpoch 94 Step 703/703 lr 0.100000 loss 0.8500 (0.8504) acc@1 0.7031 (0.6852) acc@5 0.8594 (0.9000)\n",
      "\u001b[32m[2020-07-19 17:15:54] __main__ INFO: \u001b[0mElapsed 224.98\n",
      "\u001b[32m[2020-07-19 17:15:54] __main__ INFO: \u001b[0mVal 94\n",
      "\u001b[32m[2020-07-19 17:16:02] __main__ INFO: \u001b[0mEpoch 94 loss 0.4576 acc@1 0.8466 acc@5 0.9922\n",
      "\u001b[32m[2020-07-19 17:16:02] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-19 17:16:02] __main__ INFO: \u001b[0mTrain 95 66082\n",
      "\u001b[32m[2020-07-19 17:16:34] __main__ INFO: \u001b[0mEpoch 95 Step 100/703 lr 0.100000 loss 0.6121 (0.8154) acc@1 0.7656 (0.6963) acc@5 0.9375 (0.9023)\n",
      "\u001b[32m[2020-07-19 17:17:06] __main__ INFO: \u001b[0mEpoch 95 Step 200/703 lr 0.100000 loss 0.9617 (0.8290) acc@1 0.6094 (0.6902) acc@5 0.8281 (0.8993)\n",
      "\u001b[32m[2020-07-19 17:17:38] __main__ INFO: \u001b[0mEpoch 95 Step 300/703 lr 0.100000 loss 0.8240 (0.8380) acc@1 0.6719 (0.6877) acc@5 0.8594 (0.8969)\n",
      "\u001b[32m[2020-07-19 17:18:10] __main__ INFO: \u001b[0mEpoch 95 Step 400/703 lr 0.100000 loss 0.9012 (0.8446) acc@1 0.6562 (0.6856) acc@5 0.9062 (0.8989)\n",
      "\u001b[32m[2020-07-19 17:18:42] __main__ INFO: \u001b[0mEpoch 95 Step 500/703 lr 0.100000 loss 0.7977 (0.8457) acc@1 0.6875 (0.6853) acc@5 0.8594 (0.8995)\n",
      "\u001b[32m[2020-07-19 17:19:14] __main__ INFO: \u001b[0mEpoch 95 Step 600/703 lr 0.100000 loss 1.0092 (0.8507) acc@1 0.6406 (0.6838) acc@5 0.9062 (0.8985)\n",
      "\u001b[32m[2020-07-19 17:19:46] __main__ INFO: \u001b[0mEpoch 95 Step 700/703 lr 0.100000 loss 0.9413 (0.8512) acc@1 0.6562 (0.6835) acc@5 0.8438 (0.8986)\n",
      "\u001b[32m[2020-07-19 17:19:47] __main__ INFO: \u001b[0mEpoch 95 Step 703/703 lr 0.100000 loss 0.6789 (0.8505) acc@1 0.7656 (0.6838) acc@5 0.9531 (0.8987)\n",
      "\u001b[32m[2020-07-19 17:19:47] __main__ INFO: \u001b[0mElapsed 224.97\n",
      "\u001b[32m[2020-07-19 17:19:47] __main__ INFO: \u001b[0mVal 95\n",
      "\u001b[32m[2020-07-19 17:19:54] __main__ INFO: \u001b[0mEpoch 95 loss 0.3457 acc@1 0.8862 acc@5 0.9966\n",
      "\u001b[32m[2020-07-19 17:19:54] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-19 17:19:54] __main__ INFO: \u001b[0mTrain 96 66785\n",
      "\u001b[32m[2020-07-19 17:20:27] __main__ INFO: \u001b[0mEpoch 96 Step 100/703 lr 0.100000 loss 0.8148 (0.8194) acc@1 0.7031 (0.7003) acc@5 0.9219 (0.9034)\n",
      "\u001b[32m[2020-07-19 17:20:58] __main__ INFO: \u001b[0mEpoch 96 Step 200/703 lr 0.100000 loss 0.7746 (0.8278) acc@1 0.7344 (0.6971) acc@5 0.9375 (0.9014)\n",
      "\u001b[32m[2020-07-19 17:21:30] __main__ INFO: \u001b[0mEpoch 96 Step 300/703 lr 0.100000 loss 0.9020 (0.8367) acc@1 0.6875 (0.6921) acc@5 0.8750 (0.9008)\n",
      "\u001b[32m[2020-07-19 17:22:02] __main__ INFO: \u001b[0mEpoch 96 Step 400/703 lr 0.100000 loss 0.7349 (0.8350) acc@1 0.7188 (0.6925) acc@5 0.9219 (0.9018)\n",
      "\u001b[32m[2020-07-19 17:22:34] __main__ INFO: \u001b[0mEpoch 96 Step 500/703 lr 0.100000 loss 0.7686 (0.8411) acc@1 0.7344 (0.6897) acc@5 0.8906 (0.9015)\n",
      "\u001b[32m[2020-07-19 17:23:06] __main__ INFO: \u001b[0mEpoch 96 Step 600/703 lr 0.100000 loss 0.7458 (0.8452) acc@1 0.7344 (0.6872) acc@5 0.9062 (0.9000)\n",
      "\u001b[32m[2020-07-19 17:23:38] __main__ INFO: \u001b[0mEpoch 96 Step 700/703 lr 0.100000 loss 0.9167 (0.8516) acc@1 0.6562 (0.6854) acc@5 0.9375 (0.9000)\n",
      "\u001b[32m[2020-07-19 17:23:39] __main__ INFO: \u001b[0mEpoch 96 Step 703/703 lr 0.100000 loss 0.9495 (0.8519) acc@1 0.6406 (0.6854) acc@5 0.8438 (0.8999)\n",
      "\u001b[32m[2020-07-19 17:23:39] __main__ INFO: \u001b[0mElapsed 224.95\n",
      "\u001b[32m[2020-07-19 17:23:39] __main__ INFO: \u001b[0mVal 96\n",
      "\u001b[32m[2020-07-19 17:23:47] __main__ INFO: \u001b[0mEpoch 96 loss 0.3838 acc@1 0.8720 acc@5 0.9958\n",
      "\u001b[32m[2020-07-19 17:23:47] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-19 17:23:47] __main__ INFO: \u001b[0mTrain 97 67488\n",
      "\u001b[32m[2020-07-19 17:24:19] __main__ INFO: \u001b[0mEpoch 97 Step 100/703 lr 0.100000 loss 0.8489 (0.8333) acc@1 0.7031 (0.6894) acc@5 0.8594 (0.9017)\n",
      "\u001b[32m[2020-07-19 17:24:51] __main__ INFO: \u001b[0mEpoch 97 Step 200/703 lr 0.100000 loss 0.8924 (0.8296) acc@1 0.6875 (0.6920) acc@5 0.8594 (0.9020)\n",
      "\u001b[32m[2020-07-19 17:25:23] __main__ INFO: \u001b[0mEpoch 97 Step 300/703 lr 0.100000 loss 1.0993 (0.8322) acc@1 0.5938 (0.6894) acc@5 0.8906 (0.9013)\n",
      "\u001b[32m[2020-07-19 17:25:55] __main__ INFO: \u001b[0mEpoch 97 Step 400/703 lr 0.100000 loss 0.7535 (0.8384) acc@1 0.6875 (0.6868) acc@5 0.8906 (0.9013)\n",
      "\u001b[32m[2020-07-19 17:26:27] __main__ INFO: \u001b[0mEpoch 97 Step 500/703 lr 0.100000 loss 1.0171 (0.8463) acc@1 0.5938 (0.6851) acc@5 0.8750 (0.9000)\n",
      "\u001b[32m[2020-07-19 17:26:59] __main__ INFO: \u001b[0mEpoch 97 Step 600/703 lr 0.100000 loss 1.0280 (0.8497) acc@1 0.6406 (0.6849) acc@5 0.7812 (0.9002)\n",
      "\u001b[32m[2020-07-19 17:27:31] __main__ INFO: \u001b[0mEpoch 97 Step 700/703 lr 0.100000 loss 0.8725 (0.8508) acc@1 0.6250 (0.6843) acc@5 0.8594 (0.8994)\n",
      "\u001b[32m[2020-07-19 17:27:32] __main__ INFO: \u001b[0mEpoch 97 Step 703/703 lr 0.100000 loss 0.5970 (0.8502) acc@1 0.7812 (0.6845) acc@5 0.9375 (0.8994)\n",
      "\u001b[32m[2020-07-19 17:27:32] __main__ INFO: \u001b[0mElapsed 224.88\n",
      "\u001b[32m[2020-07-19 17:27:32] __main__ INFO: \u001b[0mVal 97\n",
      "\u001b[32m[2020-07-19 17:27:40] __main__ INFO: \u001b[0mEpoch 97 loss 0.3241 acc@1 0.8888 acc@5 0.9970\n",
      "\u001b[32m[2020-07-19 17:27:40] __main__ INFO: \u001b[0mElapsed 7.74\n",
      "\u001b[32m[2020-07-19 17:27:40] __main__ INFO: \u001b[0mTrain 98 68191\n",
      "\u001b[32m[2020-07-19 17:28:12] __main__ INFO: \u001b[0mEpoch 98 Step 100/703 lr 0.100000 loss 0.8177 (0.8231) acc@1 0.6875 (0.6936) acc@5 0.8906 (0.8997)\n",
      "\u001b[32m[2020-07-19 17:28:44] __main__ INFO: \u001b[0mEpoch 98 Step 200/703 lr 0.100000 loss 0.9976 (0.8199) acc@1 0.6094 (0.6952) acc@5 0.8906 (0.8991)\n",
      "\u001b[32m[2020-07-19 17:29:16] __main__ INFO: \u001b[0mEpoch 98 Step 300/703 lr 0.100000 loss 0.6936 (0.8373) acc@1 0.7500 (0.6903) acc@5 0.9219 (0.8967)\n",
      "\u001b[32m[2020-07-19 17:29:48] __main__ INFO: \u001b[0mEpoch 98 Step 400/703 lr 0.100000 loss 0.9281 (0.8363) acc@1 0.6406 (0.6904) acc@5 0.9219 (0.8979)\n",
      "\u001b[32m[2020-07-19 17:30:20] __main__ INFO: \u001b[0mEpoch 98 Step 500/703 lr 0.100000 loss 0.8027 (0.8389) acc@1 0.7188 (0.6895) acc@5 0.8906 (0.8987)\n",
      "\u001b[32m[2020-07-19 17:30:52] __main__ INFO: \u001b[0mEpoch 98 Step 600/703 lr 0.100000 loss 0.6863 (0.8389) acc@1 0.7812 (0.6905) acc@5 0.9219 (0.8987)\n",
      "\u001b[32m[2020-07-19 17:31:24] __main__ INFO: \u001b[0mEpoch 98 Step 700/703 lr 0.100000 loss 0.7068 (0.8427) acc@1 0.7344 (0.6894) acc@5 0.9375 (0.8982)\n",
      "\u001b[32m[2020-07-19 17:31:25] __main__ INFO: \u001b[0mEpoch 98 Step 703/703 lr 0.100000 loss 1.3218 (0.8437) acc@1 0.5469 (0.6892) acc@5 0.8125 (0.8980)\n",
      "\u001b[32m[2020-07-19 17:31:25] __main__ INFO: \u001b[0mElapsed 224.73\n",
      "\u001b[32m[2020-07-19 17:31:25] __main__ INFO: \u001b[0mVal 98\n",
      "\u001b[32m[2020-07-19 17:31:32] __main__ INFO: \u001b[0mEpoch 98 loss 0.3881 acc@1 0.8748 acc@5 0.9950\n",
      "\u001b[32m[2020-07-19 17:31:32] __main__ INFO: \u001b[0mElapsed 7.75\n",
      "\u001b[32m[2020-07-19 17:31:32] __main__ INFO: \u001b[0mTrain 99 68894\n",
      "\u001b[32m[2020-07-19 17:32:04] __main__ INFO: \u001b[0mEpoch 99 Step 100/703 lr 0.100000 loss 0.8383 (0.8358) acc@1 0.7031 (0.6892) acc@5 0.9375 (0.8997)\n",
      "\u001b[32m[2020-07-19 17:32:36] __main__ INFO: \u001b[0mEpoch 99 Step 200/703 lr 0.100000 loss 0.7520 (0.8384) acc@1 0.7031 (0.6885) acc@5 0.9219 (0.8998)\n",
      "\u001b[32m[2020-07-19 17:33:08] __main__ INFO: \u001b[0mEpoch 99 Step 300/703 lr 0.100000 loss 0.8935 (0.8457) acc@1 0.6406 (0.6848) acc@5 0.8906 (0.8973)\n",
      "\u001b[32m[2020-07-19 17:33:40] __main__ INFO: \u001b[0mEpoch 99 Step 400/703 lr 0.100000 loss 0.6974 (0.8486) acc@1 0.7344 (0.6832) acc@5 0.8906 (0.8976)\n",
      "\u001b[32m[2020-07-19 17:34:12] __main__ INFO: \u001b[0mEpoch 99 Step 500/703 lr 0.100000 loss 0.7960 (0.8518) acc@1 0.6719 (0.6826) acc@5 0.9219 (0.8965)\n",
      "\u001b[32m[2020-07-19 17:34:44] __main__ INFO: \u001b[0mEpoch 99 Step 600/703 lr 0.100000 loss 1.0470 (0.8508) acc@1 0.5938 (0.6833) acc@5 0.8906 (0.8973)\n",
      "\u001b[32m[2020-07-19 17:35:16] __main__ INFO: \u001b[0mEpoch 99 Step 700/703 lr 0.100000 loss 0.9494 (0.8501) acc@1 0.6406 (0.6838) acc@5 0.8594 (0.8977)\n",
      "\u001b[32m[2020-07-19 17:35:17] __main__ INFO: \u001b[0mEpoch 99 Step 703/703 lr 0.100000 loss 0.9411 (0.8499) acc@1 0.6250 (0.6839) acc@5 0.7969 (0.8975)\n",
      "\u001b[32m[2020-07-19 17:35:17] __main__ INFO: \u001b[0mElapsed 224.91\n",
      "\u001b[32m[2020-07-19 17:35:17] __main__ INFO: \u001b[0mVal 99\n",
      "\u001b[32m[2020-07-19 17:35:25] __main__ INFO: \u001b[0mEpoch 99 loss 0.3522 acc@1 0.8838 acc@5 0.9962\n",
      "\u001b[32m[2020-07-19 17:35:25] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-19 17:35:25] __main__ INFO: \u001b[0mTrain 100 69597\n",
      "\u001b[32m[2020-07-19 17:35:57] __main__ INFO: \u001b[0mEpoch 100 Step 100/703 lr 0.100000 loss 0.6153 (0.8081) acc@1 0.8125 (0.7019) acc@5 0.9531 (0.8983)\n",
      "\u001b[32m[2020-07-19 17:36:29] __main__ INFO: \u001b[0mEpoch 100 Step 200/703 lr 0.100000 loss 0.7557 (0.8254) acc@1 0.7656 (0.6941) acc@5 0.8281 (0.8976)\n",
      "\u001b[32m[2020-07-19 17:37:01] __main__ INFO: \u001b[0mEpoch 100 Step 300/703 lr 0.100000 loss 0.8134 (0.8293) acc@1 0.6719 (0.6934) acc@5 0.9375 (0.8984)\n",
      "\u001b[32m[2020-07-19 17:37:33] __main__ INFO: \u001b[0mEpoch 100 Step 400/703 lr 0.100000 loss 0.6991 (0.8407) acc@1 0.7500 (0.6884) acc@5 0.9062 (0.8984)\n",
      "\u001b[32m[2020-07-19 17:38:05] __main__ INFO: \u001b[0mEpoch 100 Step 500/703 lr 0.100000 loss 0.6866 (0.8431) acc@1 0.6875 (0.6878) acc@5 0.9531 (0.8988)\n",
      "\u001b[32m[2020-07-19 17:38:37] __main__ INFO: \u001b[0mEpoch 100 Step 600/703 lr 0.100000 loss 0.9257 (0.8446) acc@1 0.6875 (0.6868) acc@5 0.8594 (0.8990)\n",
      "\u001b[32m[2020-07-19 17:39:09] __main__ INFO: \u001b[0mEpoch 100 Step 700/703 lr 0.100000 loss 0.9483 (0.8486) acc@1 0.7031 (0.6863) acc@5 0.9375 (0.8987)\n",
      "\u001b[32m[2020-07-19 17:39:10] __main__ INFO: \u001b[0mEpoch 100 Step 703/703 lr 0.100000 loss 1.0922 (0.8490) acc@1 0.5938 (0.6862) acc@5 0.8750 (0.8987)\n",
      "\u001b[32m[2020-07-19 17:39:10] __main__ INFO: \u001b[0mElapsed 224.74\n",
      "\u001b[32m[2020-07-19 17:39:10] __main__ INFO: \u001b[0mVal 100\n",
      "\u001b[32m[2020-07-19 17:39:17] __main__ INFO: \u001b[0mEpoch 100 loss 0.3410 acc@1 0.8840 acc@5 0.9966\n",
      "\u001b[32m[2020-07-19 17:39:17] __main__ INFO: \u001b[0mElapsed 7.73\n",
      "\u001b[32m[2020-07-19 17:39:18] fvcore.common.checkpoint INFO: \u001b[0mSaving checkpoint to /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_1_20_c10val/exp00/checkpoint_00100.pth\n",
      "\u001b[32m[2020-07-19 17:39:18] __main__ INFO: \u001b[0mTrain 101 70300\n",
      "\u001b[32m[2020-07-19 17:39:50] __main__ INFO: \u001b[0mEpoch 101 Step 100/703 lr 0.100000 loss 1.0360 (0.8127) acc@1 0.6406 (0.6953) acc@5 0.9531 (0.9005)\n",
      "\u001b[32m[2020-07-19 17:40:22] __main__ INFO: \u001b[0mEpoch 101 Step 200/703 lr 0.100000 loss 0.8306 (0.8195) acc@1 0.6719 (0.6937) acc@5 0.8594 (0.8982)\n",
      "\u001b[32m[2020-07-19 17:40:54] __main__ INFO: \u001b[0mEpoch 101 Step 300/703 lr 0.100000 loss 0.7571 (0.8263) acc@1 0.7031 (0.6918) acc@5 0.9219 (0.8965)\n",
      "\u001b[32m[2020-07-19 17:41:26] __main__ INFO: \u001b[0mEpoch 101 Step 400/703 lr 0.100000 loss 0.8266 (0.8396) acc@1 0.6719 (0.6861) acc@5 0.8750 (0.8959)\n",
      "\u001b[32m[2020-07-19 17:41:58] __main__ INFO: \u001b[0mEpoch 101 Step 500/703 lr 0.100000 loss 0.7483 (0.8406) acc@1 0.7812 (0.6871) acc@5 0.9531 (0.8976)\n",
      "\u001b[32m[2020-07-19 17:42:30] __main__ INFO: \u001b[0mEpoch 101 Step 600/703 lr 0.100000 loss 0.6836 (0.8403) acc@1 0.7344 (0.6877) acc@5 0.9531 (0.8985)\n",
      "\u001b[32m[2020-07-19 17:43:02] __main__ INFO: \u001b[0mEpoch 101 Step 700/703 lr 0.100000 loss 0.8365 (0.8443) acc@1 0.7031 (0.6865) acc@5 0.9062 (0.8978)\n",
      "\u001b[32m[2020-07-19 17:43:02] __main__ INFO: \u001b[0mEpoch 101 Step 703/703 lr 0.100000 loss 0.9619 (0.8444) acc@1 0.6562 (0.6866) acc@5 0.8906 (0.8979)\n",
      "\u001b[32m[2020-07-19 17:43:02] __main__ INFO: \u001b[0mElapsed 224.85\n",
      "\u001b[32m[2020-07-19 17:43:02] __main__ INFO: \u001b[0mVal 101\n",
      "\u001b[32m[2020-07-19 17:43:10] __main__ INFO: \u001b[0mEpoch 101 loss 0.3499 acc@1 0.8864 acc@5 0.9952\n",
      "\u001b[32m[2020-07-19 17:43:10] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-19 17:43:10] __main__ INFO: \u001b[0mTrain 102 71003\n",
      "\u001b[32m[2020-07-19 17:43:42] __main__ INFO: \u001b[0mEpoch 102 Step 100/703 lr 0.100000 loss 0.8955 (0.8051) acc@1 0.6562 (0.6995) acc@5 0.8594 (0.8948)\n",
      "\u001b[32m[2020-07-19 17:44:14] __main__ INFO: \u001b[0mEpoch 102 Step 200/703 lr 0.100000 loss 0.6940 (0.8189) acc@1 0.7031 (0.6931) acc@5 0.9219 (0.8984)\n",
      "\u001b[32m[2020-07-19 17:44:46] __main__ INFO: \u001b[0mEpoch 102 Step 300/703 lr 0.100000 loss 0.5875 (0.8225) acc@1 0.7969 (0.6931) acc@5 1.0000 (0.8990)\n",
      "\u001b[32m[2020-07-19 17:45:18] __main__ INFO: \u001b[0mEpoch 102 Step 400/703 lr 0.100000 loss 0.8328 (0.8320) acc@1 0.6719 (0.6901) acc@5 0.9531 (0.8980)\n",
      "\u001b[32m[2020-07-19 17:45:50] __main__ INFO: \u001b[0mEpoch 102 Step 500/703 lr 0.100000 loss 0.9355 (0.8401) acc@1 0.7188 (0.6867) acc@5 0.8906 (0.8981)\n",
      "\u001b[32m[2020-07-19 17:46:22] __main__ INFO: \u001b[0mEpoch 102 Step 600/703 lr 0.100000 loss 0.9736 (0.8450) acc@1 0.6250 (0.6845) acc@5 0.9531 (0.8978)\n",
      "\u001b[32m[2020-07-19 17:46:54] __main__ INFO: \u001b[0mEpoch 102 Step 700/703 lr 0.100000 loss 0.7765 (0.8444) acc@1 0.7188 (0.6853) acc@5 0.9219 (0.8990)\n",
      "\u001b[32m[2020-07-19 17:46:55] __main__ INFO: \u001b[0mEpoch 102 Step 703/703 lr 0.100000 loss 0.7471 (0.8443) acc@1 0.7188 (0.6853) acc@5 0.8438 (0.8989)\n",
      "\u001b[32m[2020-07-19 17:46:55] __main__ INFO: \u001b[0mElapsed 224.78\n",
      "\u001b[32m[2020-07-19 17:46:55] __main__ INFO: \u001b[0mVal 102\n",
      "\u001b[32m[2020-07-19 17:47:03] __main__ INFO: \u001b[0mEpoch 102 loss 0.4558 acc@1 0.8486 acc@5 0.9962\n",
      "\u001b[32m[2020-07-19 17:47:03] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-19 17:47:03] __main__ INFO: \u001b[0mTrain 103 71706\n",
      "\u001b[32m[2020-07-19 17:47:35] __main__ INFO: \u001b[0mEpoch 103 Step 100/703 lr 0.100000 loss 0.5601 (0.8071) acc@1 0.7969 (0.7023) acc@5 0.9375 (0.9005)\n",
      "\u001b[32m[2020-07-19 17:48:07] __main__ INFO: \u001b[0mEpoch 103 Step 200/703 lr 0.100000 loss 0.7850 (0.8175) acc@1 0.7344 (0.6984) acc@5 0.8906 (0.8994)\n",
      "\u001b[32m[2020-07-19 17:48:39] __main__ INFO: \u001b[0mEpoch 103 Step 300/703 lr 0.100000 loss 0.9373 (0.8298) acc@1 0.6875 (0.6926) acc@5 0.8281 (0.8966)\n",
      "\u001b[32m[2020-07-19 17:49:11] __main__ INFO: \u001b[0mEpoch 103 Step 400/703 lr 0.100000 loss 0.9213 (0.8341) acc@1 0.6562 (0.6910) acc@5 0.8438 (0.8962)\n",
      "\u001b[32m[2020-07-19 17:49:43] __main__ INFO: \u001b[0mEpoch 103 Step 500/703 lr 0.100000 loss 1.1429 (0.8361) acc@1 0.5938 (0.6904) acc@5 0.8594 (0.8972)\n",
      "\u001b[32m[2020-07-19 17:50:15] __main__ INFO: \u001b[0mEpoch 103 Step 600/703 lr 0.100000 loss 1.0844 (0.8377) acc@1 0.6875 (0.6889) acc@5 0.8750 (0.8976)\n",
      "\u001b[32m[2020-07-19 17:50:47] __main__ INFO: \u001b[0mEpoch 103 Step 700/703 lr 0.100000 loss 0.8868 (0.8418) acc@1 0.6250 (0.6874) acc@5 0.8594 (0.8979)\n",
      "\u001b[32m[2020-07-19 17:50:48] __main__ INFO: \u001b[0mEpoch 103 Step 703/703 lr 0.100000 loss 1.0074 (0.8420) acc@1 0.6250 (0.6874) acc@5 0.8125 (0.8978)\n",
      "\u001b[32m[2020-07-19 17:50:48] __main__ INFO: \u001b[0mElapsed 224.99\n",
      "\u001b[32m[2020-07-19 17:50:48] __main__ INFO: \u001b[0mVal 103\n",
      "\u001b[32m[2020-07-19 17:50:56] __main__ INFO: \u001b[0mEpoch 103 loss 0.3738 acc@1 0.8760 acc@5 0.9968\n",
      "\u001b[32m[2020-07-19 17:50:56] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-19 17:50:56] __main__ INFO: \u001b[0mTrain 104 72409\n",
      "\u001b[32m[2020-07-19 17:51:28] __main__ INFO: \u001b[0mEpoch 104 Step 100/703 lr 0.100000 loss 0.6834 (0.8188) acc@1 0.7500 (0.6998) acc@5 0.8906 (0.9058)\n",
      "\u001b[32m[2020-07-19 17:52:00] __main__ INFO: \u001b[0mEpoch 104 Step 200/703 lr 0.100000 loss 0.9207 (0.8249) acc@1 0.6719 (0.6971) acc@5 0.9062 (0.9029)\n",
      "\u001b[32m[2020-07-19 17:52:32] __main__ INFO: \u001b[0mEpoch 104 Step 300/703 lr 0.100000 loss 0.8647 (0.8298) acc@1 0.6719 (0.6961) acc@5 0.8750 (0.9006)\n",
      "\u001b[32m[2020-07-19 17:53:04] __main__ INFO: \u001b[0mEpoch 104 Step 400/703 lr 0.100000 loss 0.9517 (0.8390) acc@1 0.6250 (0.6925) acc@5 0.9062 (0.9001)\n",
      "\u001b[32m[2020-07-19 17:53:36] __main__ INFO: \u001b[0mEpoch 104 Step 500/703 lr 0.100000 loss 0.8681 (0.8399) acc@1 0.7188 (0.6919) acc@5 0.8594 (0.9009)\n",
      "\u001b[32m[2020-07-19 17:54:07] __main__ INFO: \u001b[0mEpoch 104 Step 600/703 lr 0.100000 loss 1.0846 (0.8436) acc@1 0.5625 (0.6893) acc@5 0.8125 (0.9002)\n",
      "\u001b[32m[2020-07-19 17:54:39] __main__ INFO: \u001b[0mEpoch 104 Step 700/703 lr 0.100000 loss 0.6744 (0.8439) acc@1 0.7812 (0.6895) acc@5 0.9062 (0.9011)\n",
      "\u001b[32m[2020-07-19 17:54:40] __main__ INFO: \u001b[0mEpoch 104 Step 703/703 lr 0.100000 loss 0.5353 (0.8435) acc@1 0.8125 (0.6897) acc@5 0.9219 (0.9010)\n",
      "\u001b[32m[2020-07-19 17:54:40] __main__ INFO: \u001b[0mElapsed 224.86\n",
      "\u001b[32m[2020-07-19 17:54:40] __main__ INFO: \u001b[0mVal 104\n",
      "\u001b[32m[2020-07-19 17:54:48] __main__ INFO: \u001b[0mEpoch 104 loss 0.3763 acc@1 0.8706 acc@5 0.9958\n",
      "\u001b[32m[2020-07-19 17:54:48] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-19 17:54:48] __main__ INFO: \u001b[0mTrain 105 73112\n",
      "\u001b[32m[2020-07-19 17:55:20] __main__ INFO: \u001b[0mEpoch 105 Step 100/703 lr 0.100000 loss 0.9867 (0.7924) acc@1 0.7031 (0.7086) acc@5 0.8906 (0.9045)\n",
      "\u001b[32m[2020-07-19 17:55:52] __main__ INFO: \u001b[0mEpoch 105 Step 200/703 lr 0.100000 loss 0.8936 (0.8087) acc@1 0.6562 (0.7009) acc@5 0.9375 (0.9023)\n",
      "\u001b[32m[2020-07-19 17:56:24] __main__ INFO: \u001b[0mEpoch 105 Step 300/703 lr 0.100000 loss 0.8416 (0.8266) acc@1 0.6406 (0.6938) acc@5 0.8906 (0.8994)\n",
      "\u001b[32m[2020-07-19 17:56:56] __main__ INFO: \u001b[0mEpoch 105 Step 400/703 lr 0.100000 loss 0.8951 (0.8354) acc@1 0.6562 (0.6912) acc@5 0.9062 (0.8986)\n",
      "\u001b[32m[2020-07-19 17:57:28] __main__ INFO: \u001b[0mEpoch 105 Step 500/703 lr 0.100000 loss 0.7870 (0.8398) acc@1 0.7344 (0.6892) acc@5 0.9062 (0.8994)\n",
      "\u001b[32m[2020-07-19 17:58:00] __main__ INFO: \u001b[0mEpoch 105 Step 600/703 lr 0.100000 loss 0.7142 (0.8392) acc@1 0.7969 (0.6898) acc@5 0.9375 (0.8993)\n",
      "\u001b[32m[2020-07-19 17:58:32] __main__ INFO: \u001b[0mEpoch 105 Step 700/703 lr 0.100000 loss 1.1563 (0.8419) acc@1 0.5781 (0.6893) acc@5 0.9062 (0.8994)\n",
      "\u001b[32m[2020-07-19 17:58:33] __main__ INFO: \u001b[0mEpoch 105 Step 703/703 lr 0.100000 loss 1.0965 (0.8418) acc@1 0.5938 (0.6893) acc@5 0.8750 (0.8994)\n",
      "\u001b[32m[2020-07-19 17:58:33] __main__ INFO: \u001b[0mElapsed 224.82\n",
      "\u001b[32m[2020-07-19 17:58:33] __main__ INFO: \u001b[0mVal 105\n",
      "\u001b[32m[2020-07-19 17:58:41] __main__ INFO: \u001b[0mEpoch 105 loss 0.4841 acc@1 0.8362 acc@5 0.9942\n",
      "\u001b[32m[2020-07-19 17:58:41] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-19 17:58:41] __main__ INFO: \u001b[0mTrain 106 73815\n",
      "\u001b[32m[2020-07-19 17:59:13] __main__ INFO: \u001b[0mEpoch 106 Step 100/703 lr 0.100000 loss 0.8569 (0.7948) acc@1 0.6875 (0.6995) acc@5 0.8750 (0.9025)\n",
      "\u001b[32m[2020-07-19 17:59:45] __main__ INFO: \u001b[0mEpoch 106 Step 200/703 lr 0.100000 loss 0.6590 (0.8145) acc@1 0.7344 (0.6956) acc@5 0.9375 (0.9015)\n",
      "\u001b[32m[2020-07-19 18:00:17] __main__ INFO: \u001b[0mEpoch 106 Step 300/703 lr 0.100000 loss 0.9089 (0.8259) acc@1 0.6250 (0.6915) acc@5 0.8594 (0.8981)\n",
      "\u001b[32m[2020-07-19 18:00:49] __main__ INFO: \u001b[0mEpoch 106 Step 400/703 lr 0.100000 loss 0.9383 (0.8310) acc@1 0.6719 (0.6901) acc@5 0.8750 (0.8995)\n",
      "\u001b[32m[2020-07-19 18:01:21] __main__ INFO: \u001b[0mEpoch 106 Step 500/703 lr 0.100000 loss 0.7723 (0.8304) acc@1 0.7031 (0.6913) acc@5 0.9062 (0.8997)\n",
      "\u001b[32m[2020-07-19 18:01:53] __main__ INFO: \u001b[0mEpoch 106 Step 600/703 lr 0.100000 loss 0.9109 (0.8341) acc@1 0.6562 (0.6898) acc@5 0.8594 (0.8993)\n",
      "\u001b[32m[2020-07-19 18:02:25] __main__ INFO: \u001b[0mEpoch 106 Step 700/703 lr 0.100000 loss 0.8871 (0.8389) acc@1 0.6250 (0.6881) acc@5 0.8750 (0.8988)\n",
      "\u001b[32m[2020-07-19 18:02:26] __main__ INFO: \u001b[0mEpoch 106 Step 703/703 lr 0.100000 loss 0.8015 (0.8388) acc@1 0.7656 (0.6882) acc@5 0.9219 (0.8988)\n",
      "\u001b[32m[2020-07-19 18:02:26] __main__ INFO: \u001b[0mElapsed 225.21\n",
      "\u001b[32m[2020-07-19 18:02:26] __main__ INFO: \u001b[0mVal 106\n",
      "\u001b[32m[2020-07-19 18:02:34] __main__ INFO: \u001b[0mEpoch 106 loss 0.4348 acc@1 0.8614 acc@5 0.9948\n",
      "\u001b[32m[2020-07-19 18:02:34] __main__ INFO: \u001b[0mElapsed 7.75\n",
      "\u001b[32m[2020-07-19 18:02:34] __main__ INFO: \u001b[0mTrain 107 74518\n",
      "\u001b[32m[2020-07-19 18:03:06] __main__ INFO: \u001b[0mEpoch 107 Step 100/703 lr 0.100000 loss 1.0390 (0.8151) acc@1 0.6562 (0.6995) acc@5 0.8281 (0.8961)\n",
      "\u001b[32m[2020-07-19 18:03:38] __main__ INFO: \u001b[0mEpoch 107 Step 200/703 lr 0.100000 loss 0.8344 (0.8279) acc@1 0.6719 (0.6923) acc@5 0.8750 (0.8963)\n",
      "\u001b[32m[2020-07-19 18:04:10] __main__ INFO: \u001b[0mEpoch 107 Step 300/703 lr 0.100000 loss 0.8254 (0.8274) acc@1 0.7188 (0.6928) acc@5 0.9375 (0.9006)\n",
      "\u001b[32m[2020-07-19 18:04:42] __main__ INFO: \u001b[0mEpoch 107 Step 400/703 lr 0.100000 loss 1.0700 (0.8306) acc@1 0.6094 (0.6925) acc@5 0.8438 (0.9005)\n",
      "\u001b[32m[2020-07-19 18:05:14] __main__ INFO: \u001b[0mEpoch 107 Step 500/703 lr 0.100000 loss 0.8051 (0.8318) acc@1 0.7031 (0.6925) acc@5 0.8750 (0.9000)\n",
      "\u001b[32m[2020-07-19 18:05:46] __main__ INFO: \u001b[0mEpoch 107 Step 600/703 lr 0.100000 loss 0.8629 (0.8385) acc@1 0.6875 (0.6893) acc@5 0.9062 (0.8997)\n",
      "\u001b[32m[2020-07-19 18:06:18] __main__ INFO: \u001b[0mEpoch 107 Step 700/703 lr 0.100000 loss 0.6237 (0.8404) acc@1 0.7969 (0.6882) acc@5 0.9531 (0.8988)\n",
      "\u001b[32m[2020-07-19 18:06:19] __main__ INFO: \u001b[0mEpoch 107 Step 703/703 lr 0.100000 loss 0.7815 (0.8401) acc@1 0.6719 (0.6883) acc@5 0.8594 (0.8989)\n",
      "\u001b[32m[2020-07-19 18:06:19] __main__ INFO: \u001b[0mElapsed 225.13\n",
      "\u001b[32m[2020-07-19 18:06:19] __main__ INFO: \u001b[0mVal 107\n",
      "\u001b[32m[2020-07-19 18:06:27] __main__ INFO: \u001b[0mEpoch 107 loss 0.3598 acc@1 0.8762 acc@5 0.9960\n",
      "\u001b[32m[2020-07-19 18:06:27] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-19 18:06:27] __main__ INFO: \u001b[0mTrain 108 75221\n",
      "\u001b[32m[2020-07-19 18:06:59] __main__ INFO: \u001b[0mEpoch 108 Step 100/703 lr 0.100000 loss 0.8954 (0.7816) acc@1 0.6719 (0.7109) acc@5 0.9219 (0.8994)\n",
      "\u001b[32m[2020-07-19 18:07:31] __main__ INFO: \u001b[0mEpoch 108 Step 200/703 lr 0.100000 loss 0.6079 (0.8033) acc@1 0.7812 (0.7027) acc@5 0.9688 (0.8998)\n",
      "\u001b[32m[2020-07-19 18:08:03] __main__ INFO: \u001b[0mEpoch 108 Step 300/703 lr 0.100000 loss 0.7558 (0.8230) acc@1 0.6719 (0.6930) acc@5 0.9062 (0.8975)\n",
      "\u001b[32m[2020-07-19 18:08:35] __main__ INFO: \u001b[0mEpoch 108 Step 400/703 lr 0.100000 loss 0.8941 (0.8224) acc@1 0.6719 (0.6946) acc@5 0.9375 (0.8988)\n",
      "\u001b[32m[2020-07-19 18:09:07] __main__ INFO: \u001b[0mEpoch 108 Step 500/703 lr 0.100000 loss 0.8400 (0.8341) acc@1 0.6875 (0.6907) acc@5 0.8750 (0.8983)\n",
      "\u001b[32m[2020-07-19 18:09:38] __main__ INFO: \u001b[0mEpoch 108 Step 600/703 lr 0.100000 loss 1.2399 (0.8424) acc@1 0.5469 (0.6883) acc@5 0.9062 (0.8983)\n",
      "\u001b[32m[2020-07-19 18:10:11] __main__ INFO: \u001b[0mEpoch 108 Step 700/703 lr 0.100000 loss 0.8500 (0.8460) acc@1 0.6250 (0.6870) acc@5 0.8750 (0.8985)\n",
      "\u001b[32m[2020-07-19 18:10:11] __main__ INFO: \u001b[0mEpoch 108 Step 703/703 lr 0.100000 loss 0.8520 (0.8462) acc@1 0.6875 (0.6869) acc@5 0.9219 (0.8985)\n",
      "\u001b[32m[2020-07-19 18:10:12] __main__ INFO: \u001b[0mElapsed 224.80\n",
      "\u001b[32m[2020-07-19 18:10:12] __main__ INFO: \u001b[0mVal 108\n",
      "\u001b[32m[2020-07-19 18:10:19] __main__ INFO: \u001b[0mEpoch 108 loss 0.3668 acc@1 0.8776 acc@5 0.9960\n",
      "\u001b[32m[2020-07-19 18:10:19] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-19 18:10:19] __main__ INFO: \u001b[0mTrain 109 75924\n",
      "\u001b[32m[2020-07-19 18:10:51] __main__ INFO: \u001b[0mEpoch 109 Step 100/703 lr 0.100000 loss 0.7925 (0.8059) acc@1 0.6875 (0.6986) acc@5 0.9219 (0.9041)\n",
      "\u001b[32m[2020-07-19 18:11:23] __main__ INFO: \u001b[0mEpoch 109 Step 200/703 lr 0.100000 loss 0.5911 (0.8185) acc@1 0.7969 (0.6952) acc@5 0.9375 (0.9033)\n",
      "\u001b[32m[2020-07-19 18:11:55] __main__ INFO: \u001b[0mEpoch 109 Step 300/703 lr 0.100000 loss 0.8270 (0.8292) acc@1 0.6250 (0.6918) acc@5 0.9219 (0.9028)\n",
      "\u001b[32m[2020-07-19 18:12:27] __main__ INFO: \u001b[0mEpoch 109 Step 400/703 lr 0.100000 loss 0.8374 (0.8312) acc@1 0.6875 (0.6908) acc@5 0.9062 (0.9019)\n",
      "\u001b[32m[2020-07-19 18:12:59] __main__ INFO: \u001b[0mEpoch 109 Step 500/703 lr 0.100000 loss 0.7670 (0.8350) acc@1 0.6719 (0.6895) acc@5 0.8594 (0.9011)\n",
      "\u001b[32m[2020-07-19 18:13:31] __main__ INFO: \u001b[0mEpoch 109 Step 600/703 lr 0.100000 loss 0.8771 (0.8345) acc@1 0.6562 (0.6896) acc@5 0.8750 (0.9008)\n",
      "\u001b[32m[2020-07-19 18:14:03] __main__ INFO: \u001b[0mEpoch 109 Step 700/703 lr 0.100000 loss 0.8731 (0.8412) acc@1 0.6406 (0.6871) acc@5 0.9531 (0.8997)\n",
      "\u001b[32m[2020-07-19 18:14:04] __main__ INFO: \u001b[0mEpoch 109 Step 703/703 lr 0.100000 loss 0.7010 (0.8407) acc@1 0.7500 (0.6873) acc@5 0.9062 (0.8998)\n",
      "\u001b[32m[2020-07-19 18:14:04] __main__ INFO: \u001b[0mElapsed 224.82\n",
      "\u001b[32m[2020-07-19 18:14:04] __main__ INFO: \u001b[0mVal 109\n",
      "\u001b[32m[2020-07-19 18:14:12] __main__ INFO: \u001b[0mEpoch 109 loss 0.3729 acc@1 0.8736 acc@5 0.9952\n",
      "\u001b[32m[2020-07-19 18:14:12] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-19 18:14:12] __main__ INFO: \u001b[0mTrain 110 76627\n",
      "\u001b[32m[2020-07-19 18:14:44] __main__ INFO: \u001b[0mEpoch 110 Step 100/703 lr 0.100000 loss 0.6931 (0.8071) acc@1 0.7500 (0.7013) acc@5 0.9375 (0.9039)\n",
      "\u001b[32m[2020-07-19 18:15:16] __main__ INFO: \u001b[0mEpoch 110 Step 200/703 lr 0.100000 loss 0.9550 (0.8222) acc@1 0.6562 (0.6951) acc@5 0.8906 (0.8981)\n",
      "\u001b[32m[2020-07-19 18:15:48] __main__ INFO: \u001b[0mEpoch 110 Step 300/703 lr 0.100000 loss 0.9048 (0.8302) acc@1 0.6719 (0.6934) acc@5 0.9219 (0.8988)\n",
      "\u001b[32m[2020-07-19 18:16:20] __main__ INFO: \u001b[0mEpoch 110 Step 400/703 lr 0.100000 loss 0.9019 (0.8356) acc@1 0.6094 (0.6909) acc@5 0.9062 (0.8987)\n",
      "\u001b[32m[2020-07-19 18:16:52] __main__ INFO: \u001b[0mEpoch 110 Step 500/703 lr 0.100000 loss 0.8192 (0.8340) acc@1 0.6562 (0.6912) acc@5 0.8594 (0.8990)\n",
      "\u001b[32m[2020-07-19 18:17:24] __main__ INFO: \u001b[0mEpoch 110 Step 600/703 lr 0.100000 loss 0.6713 (0.8367) acc@1 0.7812 (0.6904) acc@5 0.9375 (0.8995)\n",
      "\u001b[32m[2020-07-19 18:17:56] __main__ INFO: \u001b[0mEpoch 110 Step 700/703 lr 0.100000 loss 0.8073 (0.8347) acc@1 0.6875 (0.6920) acc@5 0.9219 (0.9001)\n",
      "\u001b[32m[2020-07-19 18:17:57] __main__ INFO: \u001b[0mEpoch 110 Step 703/703 lr 0.100000 loss 0.8096 (0.8348) acc@1 0.7031 (0.6919) acc@5 0.8750 (0.9000)\n",
      "\u001b[32m[2020-07-19 18:17:57] __main__ INFO: \u001b[0mElapsed 224.82\n",
      "\u001b[32m[2020-07-19 18:17:57] __main__ INFO: \u001b[0mVal 110\n",
      "\u001b[32m[2020-07-19 18:18:04] __main__ INFO: \u001b[0mEpoch 110 loss 0.4629 acc@1 0.8476 acc@5 0.9956\n",
      "\u001b[32m[2020-07-19 18:18:04] __main__ INFO: \u001b[0mElapsed 7.74\n",
      "\u001b[32m[2020-07-19 18:18:04] __main__ INFO: \u001b[0mTrain 111 77330\n",
      "\u001b[32m[2020-07-19 18:18:36] __main__ INFO: \u001b[0mEpoch 111 Step 100/703 lr 0.100000 loss 0.4576 (0.8055) acc@1 0.8281 (0.7025) acc@5 0.9375 (0.9030)\n",
      "\u001b[32m[2020-07-19 18:19:08] __main__ INFO: \u001b[0mEpoch 111 Step 200/703 lr 0.100000 loss 0.7140 (0.8298) acc@1 0.7188 (0.6921) acc@5 0.9062 (0.8995)\n",
      "\u001b[32m[2020-07-19 18:19:40] __main__ INFO: \u001b[0mEpoch 111 Step 300/703 lr 0.100000 loss 0.6252 (0.8306) acc@1 0.7344 (0.6910) acc@5 0.8906 (0.8984)\n",
      "\u001b[32m[2020-07-19 18:20:12] __main__ INFO: \u001b[0mEpoch 111 Step 400/703 lr 0.100000 loss 0.9803 (0.8287) acc@1 0.6562 (0.6927) acc@5 0.8750 (0.8981)\n",
      "\u001b[32m[2020-07-19 18:20:44] __main__ INFO: \u001b[0mEpoch 111 Step 500/703 lr 0.100000 loss 0.9877 (0.8374) acc@1 0.7031 (0.6894) acc@5 0.8594 (0.8992)\n",
      "\u001b[32m[2020-07-19 18:21:16] __main__ INFO: \u001b[0mEpoch 111 Step 600/703 lr 0.100000 loss 0.9034 (0.8369) acc@1 0.6406 (0.6886) acc@5 0.8281 (0.9003)\n",
      "\u001b[32m[2020-07-19 18:21:48] __main__ INFO: \u001b[0mEpoch 111 Step 700/703 lr 0.100000 loss 0.9166 (0.8421) acc@1 0.6562 (0.6869) acc@5 0.9375 (0.8991)\n",
      "\u001b[32m[2020-07-19 18:21:49] __main__ INFO: \u001b[0mEpoch 111 Step 703/703 lr 0.100000 loss 0.8920 (0.8425) acc@1 0.6562 (0.6869) acc@5 0.9375 (0.8990)\n",
      "\u001b[32m[2020-07-19 18:21:49] __main__ INFO: \u001b[0mElapsed 224.65\n",
      "\u001b[32m[2020-07-19 18:21:49] __main__ INFO: \u001b[0mVal 111\n",
      "\u001b[32m[2020-07-19 18:21:57] __main__ INFO: \u001b[0mEpoch 111 loss 0.4056 acc@1 0.8644 acc@5 0.9966\n",
      "\u001b[32m[2020-07-19 18:21:57] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-19 18:21:57] __main__ INFO: \u001b[0mTrain 112 78033\n",
      "\u001b[32m[2020-07-19 18:22:29] __main__ INFO: \u001b[0mEpoch 112 Step 100/703 lr 0.100000 loss 0.7900 (0.8255) acc@1 0.7031 (0.6891) acc@5 0.9062 (0.8920)\n",
      "\u001b[32m[2020-07-19 18:23:01] __main__ INFO: \u001b[0mEpoch 112 Step 200/703 lr 0.100000 loss 0.9000 (0.8162) acc@1 0.7031 (0.6955) acc@5 0.9531 (0.8993)\n",
      "\u001b[32m[2020-07-19 18:23:33] __main__ INFO: \u001b[0mEpoch 112 Step 300/703 lr 0.100000 loss 1.0168 (0.8178) acc@1 0.6094 (0.6942) acc@5 0.9062 (0.8995)\n",
      "\u001b[32m[2020-07-19 18:24:05] __main__ INFO: \u001b[0mEpoch 112 Step 400/703 lr 0.100000 loss 0.8765 (0.8255) acc@1 0.6719 (0.6910) acc@5 0.9062 (0.8999)\n",
      "\u001b[32m[2020-07-19 18:24:37] __main__ INFO: \u001b[0mEpoch 112 Step 500/703 lr 0.100000 loss 0.7220 (0.8299) acc@1 0.7344 (0.6899) acc@5 0.9375 (0.8993)\n",
      "\u001b[32m[2020-07-19 18:25:09] __main__ INFO: \u001b[0mEpoch 112 Step 600/703 lr 0.100000 loss 0.6945 (0.8379) acc@1 0.7188 (0.6873) acc@5 0.8906 (0.8979)\n",
      "\u001b[32m[2020-07-19 18:25:41] __main__ INFO: \u001b[0mEpoch 112 Step 700/703 lr 0.100000 loss 0.9077 (0.8381) acc@1 0.7031 (0.6880) acc@5 0.8906 (0.8984)\n",
      "\u001b[32m[2020-07-19 18:25:42] __main__ INFO: \u001b[0mEpoch 112 Step 703/703 lr 0.100000 loss 0.8919 (0.8384) acc@1 0.7031 (0.6879) acc@5 0.9062 (0.8982)\n",
      "\u001b[32m[2020-07-19 18:25:42] __main__ INFO: \u001b[0mElapsed 224.85\n",
      "\u001b[32m[2020-07-19 18:25:42] __main__ INFO: \u001b[0mVal 112\n",
      "\u001b[32m[2020-07-19 18:25:49] __main__ INFO: \u001b[0mEpoch 112 loss 0.3102 acc@1 0.8964 acc@5 0.9976\n",
      "\u001b[32m[2020-07-19 18:25:49] __main__ INFO: \u001b[0mElapsed 7.75\n",
      "\u001b[32m[2020-07-19 18:25:49] __main__ INFO: \u001b[0mTrain 113 78736\n",
      "\u001b[32m[2020-07-19 18:26:21] __main__ INFO: \u001b[0mEpoch 113 Step 100/703 lr 0.100000 loss 0.9152 (0.8103) acc@1 0.6875 (0.6989) acc@5 0.9219 (0.9008)\n",
      "\u001b[32m[2020-07-19 18:26:53] __main__ INFO: \u001b[0mEpoch 113 Step 200/703 lr 0.100000 loss 0.9675 (0.8244) acc@1 0.5938 (0.6948) acc@5 0.8750 (0.8999)\n",
      "\u001b[32m[2020-07-19 18:27:25] __main__ INFO: \u001b[0mEpoch 113 Step 300/703 lr 0.100000 loss 0.8832 (0.8300) acc@1 0.6406 (0.6930) acc@5 0.9375 (0.8985)\n",
      "\u001b[32m[2020-07-19 18:27:57] __main__ INFO: \u001b[0mEpoch 113 Step 400/703 lr 0.100000 loss 0.7122 (0.8327) acc@1 0.7344 (0.6916) acc@5 0.9062 (0.8975)\n",
      "\u001b[32m[2020-07-19 18:28:29] __main__ INFO: \u001b[0mEpoch 113 Step 500/703 lr 0.100000 loss 0.9000 (0.8315) acc@1 0.6250 (0.6914) acc@5 0.8906 (0.8983)\n",
      "\u001b[32m[2020-07-19 18:29:02] __main__ INFO: \u001b[0mEpoch 113 Step 600/703 lr 0.100000 loss 0.6904 (0.8340) acc@1 0.7812 (0.6903) acc@5 0.9062 (0.8981)\n",
      "\u001b[32m[2020-07-19 18:29:33] __main__ INFO: \u001b[0mEpoch 113 Step 700/703 lr 0.100000 loss 0.8016 (0.8340) acc@1 0.7031 (0.6902) acc@5 0.8906 (0.8992)\n",
      "\u001b[32m[2020-07-19 18:29:34] __main__ INFO: \u001b[0mEpoch 113 Step 703/703 lr 0.100000 loss 1.0534 (0.8342) acc@1 0.5781 (0.6901) acc@5 0.7812 (0.8989)\n",
      "\u001b[32m[2020-07-19 18:29:34] __main__ INFO: \u001b[0mElapsed 224.99\n",
      "\u001b[32m[2020-07-19 18:29:34] __main__ INFO: \u001b[0mVal 113\n",
      "\u001b[32m[2020-07-19 18:29:42] __main__ INFO: \u001b[0mEpoch 113 loss 0.4894 acc@1 0.8424 acc@5 0.9932\n",
      "\u001b[32m[2020-07-19 18:29:42] __main__ INFO: \u001b[0mElapsed 7.75\n",
      "\u001b[32m[2020-07-19 18:29:42] __main__ INFO: \u001b[0mTrain 114 79439\n",
      "\u001b[32m[2020-07-19 18:30:14] __main__ INFO: \u001b[0mEpoch 114 Step 100/703 lr 0.100000 loss 0.7597 (0.8113) acc@1 0.7656 (0.6963) acc@5 0.9219 (0.9016)\n",
      "\u001b[32m[2020-07-19 18:30:46] __main__ INFO: \u001b[0mEpoch 114 Step 200/703 lr 0.100000 loss 1.1442 (0.8175) acc@1 0.6250 (0.6951) acc@5 0.8906 (0.9015)\n",
      "\u001b[32m[2020-07-19 18:31:18] __main__ INFO: \u001b[0mEpoch 114 Step 300/703 lr 0.100000 loss 0.7986 (0.8320) acc@1 0.7188 (0.6915) acc@5 0.9062 (0.9001)\n",
      "\u001b[32m[2020-07-19 18:31:50] __main__ INFO: \u001b[0mEpoch 114 Step 400/703 lr 0.100000 loss 0.5306 (0.8288) acc@1 0.8125 (0.6939) acc@5 0.9531 (0.9004)\n",
      "\u001b[32m[2020-07-19 18:32:22] __main__ INFO: \u001b[0mEpoch 114 Step 500/703 lr 0.100000 loss 0.7641 (0.8315) acc@1 0.7031 (0.6933) acc@5 0.8750 (0.8998)\n",
      "\u001b[32m[2020-07-19 18:32:54] __main__ INFO: \u001b[0mEpoch 114 Step 600/703 lr 0.100000 loss 1.0404 (0.8328) acc@1 0.5938 (0.6929) acc@5 0.8438 (0.8991)\n",
      "\u001b[32m[2020-07-19 18:33:26] __main__ INFO: \u001b[0mEpoch 114 Step 700/703 lr 0.100000 loss 0.8813 (0.8371) acc@1 0.6562 (0.6912) acc@5 0.9062 (0.8983)\n",
      "\u001b[32m[2020-07-19 18:33:27] __main__ INFO: \u001b[0mEpoch 114 Step 703/703 lr 0.100000 loss 0.6965 (0.8374) acc@1 0.7031 (0.6910) acc@5 0.9062 (0.8983)\n",
      "\u001b[32m[2020-07-19 18:33:27] __main__ INFO: \u001b[0mElapsed 224.64\n",
      "\u001b[32m[2020-07-19 18:33:27] __main__ INFO: \u001b[0mVal 114\n",
      "\u001b[32m[2020-07-19 18:33:35] __main__ INFO: \u001b[0mEpoch 114 loss 0.3099 acc@1 0.8944 acc@5 0.9982\n",
      "\u001b[32m[2020-07-19 18:33:35] __main__ INFO: \u001b[0mElapsed 7.74\n",
      "\u001b[32m[2020-07-19 18:33:35] __main__ INFO: \u001b[0mTrain 115 80142\n",
      "\u001b[32m[2020-07-19 18:34:07] __main__ INFO: \u001b[0mEpoch 115 Step 100/703 lr 0.100000 loss 0.8402 (0.7755) acc@1 0.6719 (0.7158) acc@5 0.9531 (0.9033)\n",
      "\u001b[32m[2020-07-19 18:34:39] __main__ INFO: \u001b[0mEpoch 115 Step 200/703 lr 0.100000 loss 0.5938 (0.7991) acc@1 0.7812 (0.7049) acc@5 0.9531 (0.9026)\n",
      "\u001b[32m[2020-07-19 18:35:10] __main__ INFO: \u001b[0mEpoch 115 Step 300/703 lr 0.100000 loss 0.8332 (0.8152) acc@1 0.6719 (0.6973) acc@5 0.9375 (0.9007)\n",
      "\u001b[32m[2020-07-19 18:35:42] __main__ INFO: \u001b[0mEpoch 115 Step 400/703 lr 0.100000 loss 0.8521 (0.8208) acc@1 0.6875 (0.6950) acc@5 0.8750 (0.8999)\n",
      "\u001b[32m[2020-07-19 18:36:14] __main__ INFO: \u001b[0mEpoch 115 Step 500/703 lr 0.100000 loss 0.9850 (0.8246) acc@1 0.6719 (0.6932) acc@5 0.8906 (0.8995)\n",
      "\u001b[32m[2020-07-19 18:36:46] __main__ INFO: \u001b[0mEpoch 115 Step 600/703 lr 0.100000 loss 0.9486 (0.8316) acc@1 0.6562 (0.6912) acc@5 0.8438 (0.8990)\n",
      "\u001b[32m[2020-07-19 18:37:18] __main__ INFO: \u001b[0mEpoch 115 Step 700/703 lr 0.100000 loss 0.7612 (0.8332) acc@1 0.7344 (0.6912) acc@5 0.9531 (0.8997)\n",
      "\u001b[32m[2020-07-19 18:37:19] __main__ INFO: \u001b[0mEpoch 115 Step 703/703 lr 0.100000 loss 0.5823 (0.8334) acc@1 0.7656 (0.6910) acc@5 0.9844 (0.8997)\n",
      "\u001b[32m[2020-07-19 18:37:19] __main__ INFO: \u001b[0mElapsed 224.86\n",
      "\u001b[32m[2020-07-19 18:37:19] __main__ INFO: \u001b[0mVal 115\n",
      "\u001b[32m[2020-07-19 18:37:27] __main__ INFO: \u001b[0mEpoch 115 loss 0.4540 acc@1 0.8530 acc@5 0.9948\n",
      "\u001b[32m[2020-07-19 18:37:27] __main__ INFO: \u001b[0mElapsed 7.74\n",
      "\u001b[32m[2020-07-19 18:37:27] __main__ INFO: \u001b[0mTrain 116 80845\n",
      "\u001b[32m[2020-07-19 18:37:59] __main__ INFO: \u001b[0mEpoch 116 Step 100/703 lr 0.100000 loss 1.0537 (0.8089) acc@1 0.5625 (0.6934) acc@5 0.8906 (0.8980)\n",
      "\u001b[32m[2020-07-19 18:38:31] __main__ INFO: \u001b[0mEpoch 116 Step 200/703 lr 0.100000 loss 0.8853 (0.8138) acc@1 0.6562 (0.6939) acc@5 0.9219 (0.8991)\n",
      "\u001b[32m[2020-07-19 18:39:03] __main__ INFO: \u001b[0mEpoch 116 Step 300/703 lr 0.100000 loss 0.7996 (0.8345) acc@1 0.6719 (0.6870) acc@5 0.9531 (0.8964)\n",
      "\u001b[32m[2020-07-19 18:39:35] __main__ INFO: \u001b[0mEpoch 116 Step 400/703 lr 0.100000 loss 0.9319 (0.8365) acc@1 0.6719 (0.6882) acc@5 0.8906 (0.8977)\n",
      "\u001b[32m[2020-07-19 18:40:07] __main__ INFO: \u001b[0mEpoch 116 Step 500/703 lr 0.100000 loss 1.0128 (0.8348) acc@1 0.6719 (0.6894) acc@5 0.9688 (0.8986)\n",
      "\u001b[32m[2020-07-19 18:40:39] __main__ INFO: \u001b[0mEpoch 116 Step 600/703 lr 0.100000 loss 0.8449 (0.8353) acc@1 0.6250 (0.6898) acc@5 0.8906 (0.8988)\n",
      "\u001b[32m[2020-07-19 18:41:11] __main__ INFO: \u001b[0mEpoch 116 Step 700/703 lr 0.100000 loss 0.6874 (0.8353) acc@1 0.7500 (0.6898) acc@5 0.9375 (0.8983)\n",
      "\u001b[32m[2020-07-19 18:41:12] __main__ INFO: \u001b[0mEpoch 116 Step 703/703 lr 0.100000 loss 0.9058 (0.8353) acc@1 0.6719 (0.6898) acc@5 0.9062 (0.8983)\n",
      "\u001b[32m[2020-07-19 18:41:12] __main__ INFO: \u001b[0mElapsed 224.95\n",
      "\u001b[32m[2020-07-19 18:41:12] __main__ INFO: \u001b[0mVal 116\n",
      "\u001b[32m[2020-07-19 18:41:20] __main__ INFO: \u001b[0mEpoch 116 loss 0.4994 acc@1 0.8402 acc@5 0.9946\n",
      "\u001b[32m[2020-07-19 18:41:20] __main__ INFO: \u001b[0mElapsed 7.75\n",
      "\u001b[32m[2020-07-19 18:41:20] __main__ INFO: \u001b[0mTrain 117 81548\n",
      "\u001b[32m[2020-07-19 18:41:52] __main__ INFO: \u001b[0mEpoch 117 Step 100/703 lr 0.100000 loss 0.8484 (0.7870) acc@1 0.7031 (0.7044) acc@5 0.9531 (0.9030)\n",
      "\u001b[32m[2020-07-19 18:42:24] __main__ INFO: \u001b[0mEpoch 117 Step 200/703 lr 0.100000 loss 0.7011 (0.8189) acc@1 0.7344 (0.6963) acc@5 0.8438 (0.9012)\n",
      "\u001b[32m[2020-07-19 18:42:56] __main__ INFO: \u001b[0mEpoch 117 Step 300/703 lr 0.100000 loss 0.8586 (0.8248) acc@1 0.6875 (0.6946) acc@5 0.8281 (0.8994)\n",
      "\u001b[32m[2020-07-19 18:43:28] __main__ INFO: \u001b[0mEpoch 117 Step 400/703 lr 0.100000 loss 0.8791 (0.8256) acc@1 0.6875 (0.6952) acc@5 0.9062 (0.9003)\n",
      "\u001b[32m[2020-07-19 18:44:00] __main__ INFO: \u001b[0mEpoch 117 Step 500/703 lr 0.100000 loss 0.6968 (0.8283) acc@1 0.7500 (0.6934) acc@5 0.9062 (0.8998)\n",
      "\u001b[32m[2020-07-19 18:44:32] __main__ INFO: \u001b[0mEpoch 117 Step 600/703 lr 0.100000 loss 0.8673 (0.8319) acc@1 0.6719 (0.6919) acc@5 0.9219 (0.8990)\n",
      "\u001b[32m[2020-07-19 18:45:03] __main__ INFO: \u001b[0mEpoch 117 Step 700/703 lr 0.100000 loss 1.0383 (0.8356) acc@1 0.6094 (0.6907) acc@5 0.8750 (0.8996)\n",
      "\u001b[32m[2020-07-19 18:45:04] __main__ INFO: \u001b[0mEpoch 117 Step 703/703 lr 0.100000 loss 0.7857 (0.8356) acc@1 0.7344 (0.6908) acc@5 0.9062 (0.8996)\n",
      "\u001b[32m[2020-07-19 18:45:04] __main__ INFO: \u001b[0mElapsed 224.55\n",
      "\u001b[32m[2020-07-19 18:45:04] __main__ INFO: \u001b[0mVal 117\n",
      "\u001b[32m[2020-07-19 18:45:12] __main__ INFO: \u001b[0mEpoch 117 loss 0.3293 acc@1 0.8920 acc@5 0.9956\n",
      "\u001b[32m[2020-07-19 18:45:12] __main__ INFO: \u001b[0mElapsed 7.75\n",
      "\u001b[32m[2020-07-19 18:45:12] __main__ INFO: \u001b[0mTrain 118 82251\n",
      "\u001b[32m[2020-07-19 18:45:44] __main__ INFO: \u001b[0mEpoch 118 Step 100/703 lr 0.100000 loss 0.6956 (0.7989) acc@1 0.7344 (0.7027) acc@5 0.9062 (0.9009)\n",
      "\u001b[32m[2020-07-19 18:46:16] __main__ INFO: \u001b[0mEpoch 118 Step 200/703 lr 0.100000 loss 0.8389 (0.8081) acc@1 0.6406 (0.6980) acc@5 0.9062 (0.9017)\n",
      "\u001b[32m[2020-07-19 18:46:48] __main__ INFO: \u001b[0mEpoch 118 Step 300/703 lr 0.100000 loss 0.9900 (0.8212) acc@1 0.6719 (0.6936) acc@5 0.9062 (0.9014)\n",
      "\u001b[32m[2020-07-19 18:47:20] __main__ INFO: \u001b[0mEpoch 118 Step 400/703 lr 0.100000 loss 0.7850 (0.8223) acc@1 0.7031 (0.6929) acc@5 0.9531 (0.9010)\n",
      "\u001b[32m[2020-07-19 18:47:52] __main__ INFO: \u001b[0mEpoch 118 Step 500/703 lr 0.100000 loss 1.0004 (0.8265) acc@1 0.6406 (0.6920) acc@5 0.8438 (0.9002)\n",
      "\u001b[32m[2020-07-19 18:48:24] __main__ INFO: \u001b[0mEpoch 118 Step 600/703 lr 0.100000 loss 1.0185 (0.8284) acc@1 0.6406 (0.6918) acc@5 0.8438 (0.8999)\n",
      "\u001b[32m[2020-07-19 18:48:56] __main__ INFO: \u001b[0mEpoch 118 Step 700/703 lr 0.100000 loss 0.8697 (0.8326) acc@1 0.6406 (0.6910) acc@5 0.8906 (0.9003)\n",
      "\u001b[32m[2020-07-19 18:48:57] __main__ INFO: \u001b[0mEpoch 118 Step 703/703 lr 0.100000 loss 0.9211 (0.8329) acc@1 0.7031 (0.6909) acc@5 0.9375 (0.9004)\n",
      "\u001b[32m[2020-07-19 18:48:57] __main__ INFO: \u001b[0mElapsed 224.55\n",
      "\u001b[32m[2020-07-19 18:48:57] __main__ INFO: \u001b[0mVal 118\n",
      "\u001b[32m[2020-07-19 18:49:04] __main__ INFO: \u001b[0mEpoch 118 loss 0.4240 acc@1 0.8620 acc@5 0.9956\n",
      "\u001b[32m[2020-07-19 18:49:04] __main__ INFO: \u001b[0mElapsed 7.75\n",
      "\u001b[32m[2020-07-19 18:49:04] __main__ INFO: \u001b[0mTrain 119 82954\n",
      "\u001b[32m[2020-07-19 18:49:37] __main__ INFO: \u001b[0mEpoch 119 Step 100/703 lr 0.100000 loss 0.7621 (0.8268) acc@1 0.6875 (0.6977) acc@5 0.8906 (0.8959)\n",
      "\u001b[32m[2020-07-19 18:50:08] __main__ INFO: \u001b[0mEpoch 119 Step 200/703 lr 0.100000 loss 0.8449 (0.8272) acc@1 0.6562 (0.6964) acc@5 0.9219 (0.8985)\n",
      "\u001b[32m[2020-07-19 18:50:40] __main__ INFO: \u001b[0mEpoch 119 Step 300/703 lr 0.100000 loss 0.8290 (0.8287) acc@1 0.7188 (0.6949) acc@5 0.9062 (0.8990)\n",
      "\u001b[32m[2020-07-19 18:51:12] __main__ INFO: \u001b[0mEpoch 119 Step 400/703 lr 0.100000 loss 0.6327 (0.8337) acc@1 0.7656 (0.6924) acc@5 0.9375 (0.8989)\n",
      "\u001b[32m[2020-07-19 18:51:44] __main__ INFO: \u001b[0mEpoch 119 Step 500/703 lr 0.100000 loss 0.6661 (0.8290) acc@1 0.7188 (0.6932) acc@5 0.9531 (0.8996)\n",
      "\u001b[32m[2020-07-19 18:52:16] __main__ INFO: \u001b[0mEpoch 119 Step 600/703 lr 0.100000 loss 0.8093 (0.8334) acc@1 0.6562 (0.6914) acc@5 0.8594 (0.8999)\n",
      "\u001b[32m[2020-07-19 18:52:48] __main__ INFO: \u001b[0mEpoch 119 Step 700/703 lr 0.100000 loss 0.6142 (0.8358) acc@1 0.7812 (0.6906) acc@5 0.9375 (0.8992)\n",
      "\u001b[32m[2020-07-19 18:52:49] __main__ INFO: \u001b[0mEpoch 119 Step 703/703 lr 0.100000 loss 1.0939 (0.8364) acc@1 0.6250 (0.6903) acc@5 0.8281 (0.8990)\n",
      "\u001b[32m[2020-07-19 18:52:49] __main__ INFO: \u001b[0mElapsed 224.77\n",
      "\u001b[32m[2020-07-19 18:52:49] __main__ INFO: \u001b[0mVal 119\n",
      "\u001b[32m[2020-07-19 18:52:57] __main__ INFO: \u001b[0mEpoch 119 loss 0.2975 acc@1 0.8956 acc@5 0.9978\n",
      "\u001b[32m[2020-07-19 18:52:57] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-19 18:52:57] __main__ INFO: \u001b[0mTrain 120 83657\n",
      "\u001b[32m[2020-07-19 18:53:29] __main__ INFO: \u001b[0mEpoch 120 Step 100/703 lr 0.100000 loss 0.9911 (0.7912) acc@1 0.6250 (0.7072) acc@5 0.8906 (0.8997)\n",
      "\u001b[32m[2020-07-19 18:54:01] __main__ INFO: \u001b[0mEpoch 120 Step 200/703 lr 0.100000 loss 0.9021 (0.8067) acc@1 0.6875 (0.7006) acc@5 0.8750 (0.8991)\n",
      "\u001b[32m[2020-07-19 18:54:33] __main__ INFO: \u001b[0mEpoch 120 Step 300/703 lr 0.100000 loss 1.0612 (0.8233) acc@1 0.6406 (0.6955) acc@5 0.8750 (0.8977)\n",
      "\u001b[32m[2020-07-19 18:55:05] __main__ INFO: \u001b[0mEpoch 120 Step 400/703 lr 0.100000 loss 0.8249 (0.8220) acc@1 0.6719 (0.6954) acc@5 0.9219 (0.8981)\n",
      "\u001b[32m[2020-07-19 18:55:37] __main__ INFO: \u001b[0mEpoch 120 Step 500/703 lr 0.100000 loss 0.7259 (0.8186) acc@1 0.7344 (0.6973) acc@5 0.9375 (0.8986)\n",
      "\u001b[32m[2020-07-19 18:56:09] __main__ INFO: \u001b[0mEpoch 120 Step 600/703 lr 0.100000 loss 0.9281 (0.8251) acc@1 0.6094 (0.6943) acc@5 0.9219 (0.8991)\n",
      "\u001b[32m[2020-07-19 18:56:40] __main__ INFO: \u001b[0mEpoch 120 Step 700/703 lr 0.100000 loss 0.8333 (0.8307) acc@1 0.7344 (0.6914) acc@5 0.9375 (0.8990)\n",
      "\u001b[32m[2020-07-19 18:56:41] __main__ INFO: \u001b[0mEpoch 120 Step 703/703 lr 0.100000 loss 0.5227 (0.8302) acc@1 0.7812 (0.6915) acc@5 0.9688 (0.8990)\n",
      "\u001b[32m[2020-07-19 18:56:41] __main__ INFO: \u001b[0mElapsed 224.38\n",
      "\u001b[32m[2020-07-19 18:56:41] __main__ INFO: \u001b[0mVal 120\n",
      "\u001b[32m[2020-07-19 18:56:49] __main__ INFO: \u001b[0mEpoch 120 loss 0.3049 acc@1 0.8966 acc@5 0.9964\n",
      "\u001b[32m[2020-07-19 18:56:49] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-19 18:56:49] __main__ INFO: \u001b[0mTrain 121 84360\n",
      "\u001b[32m[2020-07-19 18:57:21] __main__ INFO: \u001b[0mEpoch 121 Step 100/703 lr 0.100000 loss 0.8112 (0.7920) acc@1 0.7188 (0.7048) acc@5 0.8750 (0.8995)\n",
      "\u001b[32m[2020-07-19 18:57:53] __main__ INFO: \u001b[0mEpoch 121 Step 200/703 lr 0.100000 loss 0.6827 (0.8062) acc@1 0.7344 (0.7013) acc@5 0.9531 (0.8986)\n",
      "\u001b[32m[2020-07-19 18:58:25] __main__ INFO: \u001b[0mEpoch 121 Step 300/703 lr 0.100000 loss 1.0090 (0.8149) acc@1 0.6562 (0.6963) acc@5 0.8438 (0.9010)\n",
      "\u001b[32m[2020-07-19 18:58:57] __main__ INFO: \u001b[0mEpoch 121 Step 400/703 lr 0.100000 loss 0.8725 (0.8164) acc@1 0.6562 (0.6959) acc@5 0.9219 (0.9008)\n",
      "\u001b[32m[2020-07-19 18:59:29] __main__ INFO: \u001b[0mEpoch 121 Step 500/703 lr 0.100000 loss 0.7960 (0.8214) acc@1 0.6875 (0.6942) acc@5 0.9062 (0.9009)\n",
      "\u001b[32m[2020-07-19 19:00:01] __main__ INFO: \u001b[0mEpoch 121 Step 600/703 lr 0.100000 loss 0.9189 (0.8226) acc@1 0.6719 (0.6936) acc@5 0.8906 (0.9020)\n",
      "\u001b[32m[2020-07-19 19:00:33] __main__ INFO: \u001b[0mEpoch 121 Step 700/703 lr 0.100000 loss 0.6097 (0.8282) acc@1 0.7656 (0.6919) acc@5 0.9219 (0.9015)\n",
      "\u001b[32m[2020-07-19 19:00:34] __main__ INFO: \u001b[0mEpoch 121 Step 703/703 lr 0.100000 loss 0.9557 (0.8282) acc@1 0.6406 (0.6919) acc@5 0.9062 (0.9014)\n",
      "\u001b[32m[2020-07-19 19:00:34] __main__ INFO: \u001b[0mElapsed 225.07\n",
      "\u001b[32m[2020-07-19 19:00:34] __main__ INFO: \u001b[0mVal 121\n",
      "\u001b[32m[2020-07-19 19:00:42] __main__ INFO: \u001b[0mEpoch 121 loss 0.2977 acc@1 0.8976 acc@5 0.9960\n",
      "\u001b[32m[2020-07-19 19:00:42] __main__ INFO: \u001b[0mElapsed 7.74\n",
      "\u001b[32m[2020-07-19 19:00:42] __main__ INFO: \u001b[0mTrain 122 85063\n",
      "\u001b[32m[2020-07-19 19:01:14] __main__ INFO: \u001b[0mEpoch 122 Step 100/703 lr 0.100000 loss 1.0320 (0.7863) acc@1 0.6250 (0.7080) acc@5 0.7656 (0.9005)\n",
      "\u001b[32m[2020-07-19 19:01:46] __main__ INFO: \u001b[0mEpoch 122 Step 200/703 lr 0.100000 loss 1.0822 (0.7997) acc@1 0.5938 (0.7021) acc@5 0.8281 (0.8966)\n",
      "\u001b[32m[2020-07-19 19:02:18] __main__ INFO: \u001b[0mEpoch 122 Step 300/703 lr 0.100000 loss 0.8349 (0.8049) acc@1 0.7031 (0.7001) acc@5 0.9219 (0.8968)\n",
      "\u001b[32m[2020-07-19 19:02:50] __main__ INFO: \u001b[0mEpoch 122 Step 400/703 lr 0.100000 loss 0.7852 (0.8089) acc@1 0.7188 (0.6973) acc@5 0.9062 (0.8973)\n",
      "\u001b[32m[2020-07-19 19:03:22] __main__ INFO: \u001b[0mEpoch 122 Step 500/703 lr 0.100000 loss 0.7161 (0.8178) acc@1 0.7344 (0.6953) acc@5 0.8594 (0.8991)\n",
      "\u001b[32m[2020-07-19 19:03:54] __main__ INFO: \u001b[0mEpoch 122 Step 600/703 lr 0.100000 loss 0.9431 (0.8189) acc@1 0.6406 (0.6945) acc@5 0.8594 (0.8985)\n",
      "\u001b[32m[2020-07-19 19:04:26] __main__ INFO: \u001b[0mEpoch 122 Step 700/703 lr 0.100000 loss 0.9505 (0.8280) acc@1 0.6562 (0.6913) acc@5 0.8594 (0.8980)\n",
      "\u001b[32m[2020-07-19 19:04:27] __main__ INFO: \u001b[0mEpoch 122 Step 703/703 lr 0.100000 loss 1.1190 (0.8287) acc@1 0.5781 (0.6909) acc@5 0.8281 (0.8979)\n",
      "\u001b[32m[2020-07-19 19:04:27] __main__ INFO: \u001b[0mElapsed 224.55\n",
      "\u001b[32m[2020-07-19 19:04:27] __main__ INFO: \u001b[0mVal 122\n",
      "\u001b[32m[2020-07-19 19:04:34] __main__ INFO: \u001b[0mEpoch 122 loss 0.3982 acc@1 0.8650 acc@5 0.9948\n",
      "\u001b[32m[2020-07-19 19:04:34] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-19 19:04:34] __main__ INFO: \u001b[0mTrain 123 85766\n",
      "\u001b[32m[2020-07-19 19:05:06] __main__ INFO: \u001b[0mEpoch 123 Step 100/703 lr 0.100000 loss 0.8297 (0.7870) acc@1 0.6719 (0.7103) acc@5 0.8594 (0.9087)\n",
      "\u001b[32m[2020-07-19 19:05:38] __main__ INFO: \u001b[0mEpoch 123 Step 200/703 lr 0.100000 loss 0.7708 (0.7982) acc@1 0.7031 (0.7036) acc@5 0.9219 (0.9045)\n",
      "\u001b[32m[2020-07-19 19:06:10] __main__ INFO: \u001b[0mEpoch 123 Step 300/703 lr 0.100000 loss 0.5942 (0.8023) acc@1 0.8281 (0.7033) acc@5 0.9062 (0.9040)\n",
      "\u001b[32m[2020-07-19 19:06:42] __main__ INFO: \u001b[0mEpoch 123 Step 400/703 lr 0.100000 loss 1.1248 (0.8122) acc@1 0.5781 (0.6977) acc@5 0.8750 (0.9009)\n",
      "\u001b[32m[2020-07-19 19:07:14] __main__ INFO: \u001b[0mEpoch 123 Step 500/703 lr 0.100000 loss 0.8377 (0.8181) acc@1 0.6875 (0.6965) acc@5 0.8750 (0.9019)\n",
      "\u001b[32m[2020-07-19 19:07:46] __main__ INFO: \u001b[0mEpoch 123 Step 600/703 lr 0.100000 loss 0.7444 (0.8217) acc@1 0.6875 (0.6952) acc@5 0.9062 (0.9010)\n",
      "\u001b[32m[2020-07-19 19:08:18] __main__ INFO: \u001b[0mEpoch 123 Step 700/703 lr 0.100000 loss 0.5703 (0.8272) acc@1 0.7656 (0.6926) acc@5 0.9531 (0.8995)\n",
      "\u001b[32m[2020-07-19 19:08:19] __main__ INFO: \u001b[0mEpoch 123 Step 703/703 lr 0.100000 loss 0.9229 (0.8274) acc@1 0.6875 (0.6927) acc@5 0.9219 (0.8995)\n",
      "\u001b[32m[2020-07-19 19:08:19] __main__ INFO: \u001b[0mElapsed 224.54\n",
      "\u001b[32m[2020-07-19 19:08:19] __main__ INFO: \u001b[0mVal 123\n",
      "\u001b[32m[2020-07-19 19:08:27] __main__ INFO: \u001b[0mEpoch 123 loss 0.3472 acc@1 0.8888 acc@5 0.9970\n",
      "\u001b[32m[2020-07-19 19:08:27] __main__ INFO: \u001b[0mElapsed 7.75\n",
      "\u001b[32m[2020-07-19 19:08:27] __main__ INFO: \u001b[0mTrain 124 86469\n",
      "\u001b[32m[2020-07-19 19:08:59] __main__ INFO: \u001b[0mEpoch 124 Step 100/703 lr 0.100000 loss 0.8994 (0.8072) acc@1 0.6562 (0.6984) acc@5 0.8438 (0.9025)\n",
      "\u001b[32m[2020-07-19 19:09:31] __main__ INFO: \u001b[0mEpoch 124 Step 200/703 lr 0.100000 loss 0.7060 (0.8104) acc@1 0.7344 (0.6987) acc@5 0.8594 (0.9030)\n",
      "\u001b[32m[2020-07-19 19:10:03] __main__ INFO: \u001b[0mEpoch 124 Step 300/703 lr 0.100000 loss 0.8760 (0.8188) acc@1 0.7344 (0.6939) acc@5 0.9062 (0.9005)\n",
      "\u001b[32m[2020-07-19 19:10:35] __main__ INFO: \u001b[0mEpoch 124 Step 400/703 lr 0.100000 loss 0.7252 (0.8182) acc@1 0.7656 (0.6940) acc@5 0.9062 (0.8998)\n",
      "\u001b[32m[2020-07-19 19:11:07] __main__ INFO: \u001b[0mEpoch 124 Step 500/703 lr 0.100000 loss 0.7672 (0.8159) acc@1 0.7188 (0.6960) acc@5 0.9219 (0.9001)\n",
      "\u001b[32m[2020-07-19 19:11:39] __main__ INFO: \u001b[0mEpoch 124 Step 600/703 lr 0.100000 loss 0.7995 (0.8240) acc@1 0.7344 (0.6937) acc@5 0.8906 (0.8993)\n",
      "\u001b[32m[2020-07-19 19:12:11] __main__ INFO: \u001b[0mEpoch 124 Step 700/703 lr 0.100000 loss 0.9173 (0.8303) acc@1 0.6875 (0.6918) acc@5 0.9219 (0.8992)\n",
      "\u001b[32m[2020-07-19 19:12:11] __main__ INFO: \u001b[0mEpoch 124 Step 703/703 lr 0.100000 loss 0.8888 (0.8305) acc@1 0.6875 (0.6918) acc@5 0.8906 (0.8992)\n",
      "\u001b[32m[2020-07-19 19:12:12] __main__ INFO: \u001b[0mElapsed 224.90\n",
      "\u001b[32m[2020-07-19 19:12:12] __main__ INFO: \u001b[0mVal 124\n",
      "\u001b[32m[2020-07-19 19:12:19] __main__ INFO: \u001b[0mEpoch 124 loss 0.3545 acc@1 0.8810 acc@5 0.9972\n",
      "\u001b[32m[2020-07-19 19:12:19] __main__ INFO: \u001b[0mElapsed 7.72\n",
      "\u001b[32m[2020-07-19 19:12:19] __main__ INFO: \u001b[0mTrain 125 87172\n",
      "\u001b[32m[2020-07-19 19:12:51] __main__ INFO: \u001b[0mEpoch 125 Step 100/703 lr 0.100000 loss 1.0535 (0.7829) acc@1 0.5938 (0.7073) acc@5 0.8750 (0.9058)\n",
      "\u001b[32m[2020-07-19 19:13:23] __main__ INFO: \u001b[0mEpoch 125 Step 200/703 lr 0.100000 loss 1.1443 (0.7866) acc@1 0.5938 (0.7059) acc@5 0.8438 (0.9044)\n",
      "\u001b[32m[2020-07-19 19:13:55] __main__ INFO: \u001b[0mEpoch 125 Step 300/703 lr 0.100000 loss 1.0236 (0.8068) acc@1 0.6406 (0.6983) acc@5 0.8906 (0.8993)\n",
      "\u001b[32m[2020-07-19 19:14:27] __main__ INFO: \u001b[0mEpoch 125 Step 400/703 lr 0.100000 loss 0.7582 (0.8112) acc@1 0.7031 (0.6973) acc@5 0.9219 (0.8997)\n",
      "\u001b[32m[2020-07-19 19:14:59] __main__ INFO: \u001b[0mEpoch 125 Step 500/703 lr 0.100000 loss 1.0258 (0.8177) acc@1 0.6406 (0.6955) acc@5 0.9062 (0.9001)\n",
      "\u001b[32m[2020-07-19 19:15:31] __main__ INFO: \u001b[0mEpoch 125 Step 600/703 lr 0.100000 loss 0.6497 (0.8226) acc@1 0.7344 (0.6934) acc@5 0.9062 (0.9000)\n",
      "\u001b[32m[2020-07-19 19:16:03] __main__ INFO: \u001b[0mEpoch 125 Step 700/703 lr 0.100000 loss 0.8813 (0.8281) acc@1 0.6406 (0.6917) acc@5 0.8906 (0.8991)\n",
      "\u001b[32m[2020-07-19 19:16:04] __main__ INFO: \u001b[0mEpoch 125 Step 703/703 lr 0.100000 loss 0.9003 (0.8285) acc@1 0.6406 (0.6915) acc@5 0.8750 (0.8990)\n",
      "\u001b[32m[2020-07-19 19:16:04] __main__ INFO: \u001b[0mElapsed 224.86\n",
      "\u001b[32m[2020-07-19 19:16:04] __main__ INFO: \u001b[0mVal 125\n",
      "\u001b[32m[2020-07-19 19:16:12] __main__ INFO: \u001b[0mEpoch 125 loss 0.4042 acc@1 0.8660 acc@5 0.9954\n",
      "\u001b[32m[2020-07-19 19:16:12] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-19 19:16:12] __main__ INFO: \u001b[0mTrain 126 87875\n",
      "\u001b[32m[2020-07-19 19:16:44] __main__ INFO: \u001b[0mEpoch 126 Step 100/703 lr 0.100000 loss 0.7943 (0.7814) acc@1 0.7188 (0.7087) acc@5 0.9531 (0.9058)\n",
      "\u001b[32m[2020-07-19 19:17:16] __main__ INFO: \u001b[0mEpoch 126 Step 200/703 lr 0.100000 loss 0.7342 (0.7906) acc@1 0.7031 (0.7041) acc@5 0.9688 (0.9071)\n",
      "\u001b[32m[2020-07-19 19:17:48] __main__ INFO: \u001b[0mEpoch 126 Step 300/703 lr 0.100000 loss 1.0639 (0.8028) acc@1 0.5625 (0.6993) acc@5 0.8438 (0.9033)\n",
      "\u001b[32m[2020-07-19 19:18:20] __main__ INFO: \u001b[0mEpoch 126 Step 400/703 lr 0.100000 loss 0.9275 (0.8128) acc@1 0.6406 (0.6963) acc@5 0.8438 (0.9012)\n",
      "\u001b[32m[2020-07-19 19:18:52] __main__ INFO: \u001b[0mEpoch 126 Step 500/703 lr 0.100000 loss 0.6803 (0.8191) acc@1 0.7344 (0.6948) acc@5 0.9062 (0.9007)\n",
      "\u001b[32m[2020-07-19 19:19:23] __main__ INFO: \u001b[0mEpoch 126 Step 600/703 lr 0.100000 loss 0.7095 (0.8220) acc@1 0.7031 (0.6936) acc@5 0.9531 (0.9008)\n",
      "\u001b[32m[2020-07-19 19:19:55] __main__ INFO: \u001b[0mEpoch 126 Step 700/703 lr 0.100000 loss 0.9146 (0.8243) acc@1 0.6406 (0.6930) acc@5 0.8594 (0.9014)\n",
      "\u001b[32m[2020-07-19 19:19:56] __main__ INFO: \u001b[0mEpoch 126 Step 703/703 lr 0.100000 loss 0.7729 (0.8245) acc@1 0.7500 (0.6930) acc@5 0.8906 (0.9013)\n",
      "\u001b[32m[2020-07-19 19:19:56] __main__ INFO: \u001b[0mElapsed 224.45\n",
      "\u001b[32m[2020-07-19 19:19:56] __main__ INFO: \u001b[0mVal 126\n",
      "\u001b[32m[2020-07-19 19:20:04] __main__ INFO: \u001b[0mEpoch 126 loss 0.3458 acc@1 0.8910 acc@5 0.9964\n",
      "\u001b[32m[2020-07-19 19:20:04] __main__ INFO: \u001b[0mElapsed 7.73\n",
      "\u001b[32m[2020-07-19 19:20:04] __main__ INFO: \u001b[0mTrain 127 88578\n",
      "\u001b[32m[2020-07-19 19:20:36] __main__ INFO: \u001b[0mEpoch 127 Step 100/703 lr 0.100000 loss 0.6798 (0.7785) acc@1 0.7500 (0.7106) acc@5 0.8750 (0.9028)\n",
      "\u001b[32m[2020-07-19 19:21:08] __main__ INFO: \u001b[0mEpoch 127 Step 200/703 lr 0.100000 loss 0.7008 (0.7960) acc@1 0.7344 (0.7063) acc@5 0.9375 (0.9008)\n",
      "\u001b[32m[2020-07-19 19:21:40] __main__ INFO: \u001b[0mEpoch 127 Step 300/703 lr 0.100000 loss 0.9724 (0.8047) acc@1 0.6562 (0.7028) acc@5 0.9219 (0.9022)\n",
      "\u001b[32m[2020-07-19 19:22:12] __main__ INFO: \u001b[0mEpoch 127 Step 400/703 lr 0.100000 loss 0.7408 (0.8124) acc@1 0.7031 (0.6997) acc@5 0.8594 (0.9004)\n",
      "\u001b[32m[2020-07-19 19:22:44] __main__ INFO: \u001b[0mEpoch 127 Step 500/703 lr 0.100000 loss 0.7666 (0.8165) acc@1 0.7656 (0.6976) acc@5 0.8750 (0.9013)\n",
      "\u001b[32m[2020-07-19 19:23:15] __main__ INFO: \u001b[0mEpoch 127 Step 600/703 lr 0.100000 loss 0.9878 (0.8234) acc@1 0.6719 (0.6952) acc@5 0.8594 (0.9005)\n",
      "\u001b[32m[2020-07-19 19:23:47] __main__ INFO: \u001b[0mEpoch 127 Step 700/703 lr 0.100000 loss 0.9732 (0.8272) acc@1 0.6094 (0.6940) acc@5 0.9219 (0.9003)\n",
      "\u001b[32m[2020-07-19 19:23:48] __main__ INFO: \u001b[0mEpoch 127 Step 703/703 lr 0.100000 loss 0.9275 (0.8276) acc@1 0.6406 (0.6938) acc@5 0.8438 (0.9002)\n",
      "\u001b[32m[2020-07-19 19:23:48] __main__ INFO: \u001b[0mElapsed 224.24\n",
      "\u001b[32m[2020-07-19 19:23:48] __main__ INFO: \u001b[0mVal 127\n",
      "\u001b[32m[2020-07-19 19:23:56] __main__ INFO: \u001b[0mEpoch 127 loss 0.3285 acc@1 0.8860 acc@5 0.9974\n",
      "\u001b[32m[2020-07-19 19:23:56] __main__ INFO: \u001b[0mElapsed 7.73\n",
      "\u001b[32m[2020-07-19 19:23:56] __main__ INFO: \u001b[0mTrain 128 89281\n",
      "\u001b[32m[2020-07-19 19:24:28] __main__ INFO: \u001b[0mEpoch 128 Step 100/703 lr 0.100000 loss 0.8821 (0.8088) acc@1 0.6406 (0.6989) acc@5 0.8750 (0.9000)\n",
      "\u001b[32m[2020-07-19 19:25:00] __main__ INFO: \u001b[0mEpoch 128 Step 200/703 lr 0.100000 loss 0.6026 (0.7935) acc@1 0.7500 (0.7036) acc@5 0.9531 (0.9026)\n",
      "\u001b[32m[2020-07-19 19:25:32] __main__ INFO: \u001b[0mEpoch 128 Step 300/703 lr 0.100000 loss 0.6445 (0.7990) acc@1 0.7969 (0.7014) acc@5 0.8906 (0.9008)\n",
      "\u001b[32m[2020-07-19 19:26:04] __main__ INFO: \u001b[0mEpoch 128 Step 400/703 lr 0.100000 loss 0.8585 (0.8136) acc@1 0.6562 (0.6977) acc@5 0.9219 (0.9003)\n",
      "\u001b[32m[2020-07-19 19:26:36] __main__ INFO: \u001b[0mEpoch 128 Step 500/703 lr 0.100000 loss 0.8124 (0.8197) acc@1 0.6719 (0.6959) acc@5 0.9375 (0.9003)\n",
      "\u001b[32m[2020-07-19 19:27:08] __main__ INFO: \u001b[0mEpoch 128 Step 600/703 lr 0.100000 loss 0.9094 (0.8206) acc@1 0.6719 (0.6962) acc@5 0.9219 (0.9005)\n",
      "\u001b[32m[2020-07-19 19:27:40] __main__ INFO: \u001b[0mEpoch 128 Step 700/703 lr 0.100000 loss 0.8743 (0.8237) acc@1 0.6406 (0.6949) acc@5 0.9062 (0.9000)\n",
      "\u001b[32m[2020-07-19 19:27:40] __main__ INFO: \u001b[0mEpoch 128 Step 703/703 lr 0.100000 loss 0.7659 (0.8237) acc@1 0.7188 (0.6949) acc@5 0.8906 (0.8999)\n",
      "\u001b[32m[2020-07-19 19:27:40] __main__ INFO: \u001b[0mElapsed 224.46\n",
      "\u001b[32m[2020-07-19 19:27:40] __main__ INFO: \u001b[0mVal 128\n",
      "\u001b[32m[2020-07-19 19:27:48] __main__ INFO: \u001b[0mEpoch 128 loss 0.3456 acc@1 0.8832 acc@5 0.9960\n",
      "\u001b[32m[2020-07-19 19:27:48] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-19 19:27:48] __main__ INFO: \u001b[0mTrain 129 89984\n",
      "\u001b[32m[2020-07-19 19:28:20] __main__ INFO: \u001b[0mEpoch 129 Step 100/703 lr 0.100000 loss 0.7072 (0.7891) acc@1 0.7344 (0.7077) acc@5 0.9375 (0.9028)\n",
      "\u001b[32m[2020-07-19 19:28:52] __main__ INFO: \u001b[0mEpoch 129 Step 200/703 lr 0.100000 loss 0.6473 (0.7952) acc@1 0.7344 (0.7020) acc@5 0.9375 (0.9041)\n",
      "\u001b[32m[2020-07-19 19:29:24] __main__ INFO: \u001b[0mEpoch 129 Step 300/703 lr 0.100000 loss 0.6288 (0.8044) acc@1 0.7500 (0.6992) acc@5 0.9219 (0.9018)\n",
      "\u001b[32m[2020-07-19 19:29:56] __main__ INFO: \u001b[0mEpoch 129 Step 400/703 lr 0.100000 loss 1.0231 (0.8178) acc@1 0.6250 (0.6953) acc@5 0.8750 (0.9019)\n",
      "\u001b[32m[2020-07-19 19:30:28] __main__ INFO: \u001b[0mEpoch 129 Step 500/703 lr 0.100000 loss 1.0097 (0.8172) acc@1 0.5938 (0.6967) acc@5 0.8594 (0.9017)\n",
      "\u001b[32m[2020-07-19 19:31:00] __main__ INFO: \u001b[0mEpoch 129 Step 600/703 lr 0.100000 loss 0.8207 (0.8205) acc@1 0.7188 (0.6951) acc@5 0.9375 (0.9020)\n",
      "\u001b[32m[2020-07-19 19:31:32] __main__ INFO: \u001b[0mEpoch 129 Step 700/703 lr 0.100000 loss 1.0693 (0.8281) acc@1 0.5781 (0.6935) acc@5 0.8438 (0.9015)\n",
      "\u001b[32m[2020-07-19 19:31:33] __main__ INFO: \u001b[0mEpoch 129 Step 703/703 lr 0.100000 loss 0.8376 (0.8285) acc@1 0.6406 (0.6932) acc@5 0.8906 (0.9014)\n",
      "\u001b[32m[2020-07-19 19:31:33] __main__ INFO: \u001b[0mElapsed 224.38\n",
      "\u001b[32m[2020-07-19 19:31:33] __main__ INFO: \u001b[0mVal 129\n",
      "\u001b[32m[2020-07-19 19:31:40] __main__ INFO: \u001b[0mEpoch 129 loss 0.3611 acc@1 0.8834 acc@5 0.9964\n",
      "\u001b[32m[2020-07-19 19:31:40] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-19 19:31:40] __main__ INFO: \u001b[0mTrain 130 90687\n",
      "\u001b[32m[2020-07-19 19:32:12] __main__ INFO: \u001b[0mEpoch 130 Step 100/703 lr 0.100000 loss 0.8216 (0.7883) acc@1 0.7031 (0.7073) acc@5 0.9062 (0.9017)\n",
      "\u001b[32m[2020-07-19 19:32:44] __main__ INFO: \u001b[0mEpoch 130 Step 200/703 lr 0.100000 loss 0.6692 (0.8019) acc@1 0.7344 (0.7016) acc@5 0.9375 (0.9028)\n",
      "\u001b[32m[2020-07-19 19:33:16] __main__ INFO: \u001b[0mEpoch 130 Step 300/703 lr 0.100000 loss 0.7786 (0.8090) acc@1 0.6875 (0.6997) acc@5 0.8750 (0.9007)\n",
      "\u001b[32m[2020-07-19 19:33:48] __main__ INFO: \u001b[0mEpoch 130 Step 400/703 lr 0.100000 loss 0.6341 (0.8153) acc@1 0.7812 (0.6977) acc@5 0.8594 (0.9020)\n",
      "\u001b[32m[2020-07-19 19:34:20] __main__ INFO: \u001b[0mEpoch 130 Step 500/703 lr 0.100000 loss 0.8556 (0.8194) acc@1 0.7031 (0.6963) acc@5 0.8750 (0.9010)\n",
      "\u001b[32m[2020-07-19 19:34:52] __main__ INFO: \u001b[0mEpoch 130 Step 600/703 lr 0.100000 loss 0.6723 (0.8224) acc@1 0.7344 (0.6950) acc@5 0.9219 (0.9005)\n",
      "\u001b[32m[2020-07-19 19:35:24] __main__ INFO: \u001b[0mEpoch 130 Step 700/703 lr 0.100000 loss 0.6749 (0.8235) acc@1 0.7344 (0.6948) acc@5 0.9062 (0.8997)\n",
      "\u001b[32m[2020-07-19 19:35:25] __main__ INFO: \u001b[0mEpoch 130 Step 703/703 lr 0.100000 loss 0.7880 (0.8234) acc@1 0.6406 (0.6948) acc@5 0.8750 (0.8997)\n",
      "\u001b[32m[2020-07-19 19:35:25] __main__ INFO: \u001b[0mElapsed 224.43\n",
      "\u001b[32m[2020-07-19 19:35:25] __main__ INFO: \u001b[0mVal 130\n",
      "\u001b[32m[2020-07-19 19:35:33] __main__ INFO: \u001b[0mEpoch 130 loss 0.3633 acc@1 0.8844 acc@5 0.9982\n",
      "\u001b[32m[2020-07-19 19:35:33] __main__ INFO: \u001b[0mElapsed 7.75\n",
      "\u001b[32m[2020-07-19 19:35:33] __main__ INFO: \u001b[0mTrain 131 91390\n",
      "\u001b[32m[2020-07-19 19:36:04] __main__ INFO: \u001b[0mEpoch 131 Step 100/703 lr 0.100000 loss 0.7565 (0.8212) acc@1 0.6875 (0.6973) acc@5 0.9219 (0.8975)\n",
      "\u001b[32m[2020-07-19 19:36:36] __main__ INFO: \u001b[0mEpoch 131 Step 200/703 lr 0.100000 loss 0.6731 (0.8231) acc@1 0.7656 (0.6960) acc@5 0.9219 (0.9003)\n",
      "\u001b[32m[2020-07-19 19:37:08] __main__ INFO: \u001b[0mEpoch 131 Step 300/703 lr 0.100000 loss 0.8669 (0.8280) acc@1 0.6875 (0.6948) acc@5 0.8594 (0.9000)\n",
      "\u001b[32m[2020-07-19 19:37:40] __main__ INFO: \u001b[0mEpoch 131 Step 400/703 lr 0.100000 loss 1.0064 (0.8220) acc@1 0.6250 (0.6967) acc@5 0.8594 (0.9013)\n",
      "\u001b[32m[2020-07-19 19:38:12] __main__ INFO: \u001b[0mEpoch 131 Step 500/703 lr 0.100000 loss 0.7582 (0.8244) acc@1 0.7188 (0.6955) acc@5 0.9062 (0.9005)\n",
      "\u001b[32m[2020-07-19 19:38:44] __main__ INFO: \u001b[0mEpoch 131 Step 600/703 lr 0.100000 loss 0.8500 (0.8251) acc@1 0.6875 (0.6946) acc@5 0.9062 (0.9013)\n",
      "\u001b[32m[2020-07-19 19:39:16] __main__ INFO: \u001b[0mEpoch 131 Step 700/703 lr 0.100000 loss 1.0120 (0.8272) acc@1 0.5938 (0.6933) acc@5 0.8438 (0.9013)\n",
      "\u001b[32m[2020-07-19 19:39:17] __main__ INFO: \u001b[0mEpoch 131 Step 703/703 lr 0.100000 loss 0.7616 (0.8270) acc@1 0.7500 (0.6935) acc@5 0.9219 (0.9013)\n",
      "\u001b[32m[2020-07-19 19:39:17] __main__ INFO: \u001b[0mElapsed 224.20\n",
      "\u001b[32m[2020-07-19 19:39:17] __main__ INFO: \u001b[0mVal 131\n",
      "\u001b[32m[2020-07-19 19:39:24] __main__ INFO: \u001b[0mEpoch 131 loss 0.4023 acc@1 0.8760 acc@5 0.9956\n",
      "\u001b[32m[2020-07-19 19:39:24] __main__ INFO: \u001b[0mElapsed 7.70\n",
      "\u001b[32m[2020-07-19 19:39:24] __main__ INFO: \u001b[0mTrain 132 92093\n",
      "\u001b[32m[2020-07-19 19:39:56] __main__ INFO: \u001b[0mEpoch 132 Step 100/703 lr 0.100000 loss 0.8663 (0.8056) acc@1 0.7031 (0.6966) acc@5 0.9531 (0.9002)\n",
      "\u001b[32m[2020-07-19 19:40:28] __main__ INFO: \u001b[0mEpoch 132 Step 200/703 lr 0.100000 loss 0.7048 (0.8107) acc@1 0.7344 (0.6973) acc@5 0.9375 (0.8993)\n",
      "\u001b[32m[2020-07-19 19:41:00] __main__ INFO: \u001b[0mEpoch 132 Step 300/703 lr 0.100000 loss 0.7120 (0.8192) acc@1 0.7656 (0.6947) acc@5 0.9375 (0.9013)\n",
      "\u001b[32m[2020-07-19 19:41:32] __main__ INFO: \u001b[0mEpoch 132 Step 400/703 lr 0.100000 loss 0.5982 (0.8173) acc@1 0.8438 (0.6966) acc@5 0.9688 (0.9021)\n",
      "\u001b[32m[2020-07-19 19:42:04] __main__ INFO: \u001b[0mEpoch 132 Step 500/703 lr 0.100000 loss 0.8732 (0.8202) acc@1 0.6719 (0.6944) acc@5 0.9375 (0.9001)\n",
      "\u001b[32m[2020-07-19 19:42:36] __main__ INFO: \u001b[0mEpoch 132 Step 600/703 lr 0.100000 loss 0.7387 (0.8256) acc@1 0.7344 (0.6927) acc@5 0.9062 (0.9001)\n",
      "\u001b[32m[2020-07-19 19:43:08] __main__ INFO: \u001b[0mEpoch 132 Step 700/703 lr 0.100000 loss 0.8705 (0.8268) acc@1 0.6250 (0.6927) acc@5 0.9062 (0.9004)\n",
      "\u001b[32m[2020-07-19 19:43:09] __main__ INFO: \u001b[0mEpoch 132 Step 703/703 lr 0.100000 loss 0.7769 (0.8267) acc@1 0.7500 (0.6929) acc@5 0.9219 (0.9005)\n",
      "\u001b[32m[2020-07-19 19:43:09] __main__ INFO: \u001b[0mElapsed 224.28\n",
      "\u001b[32m[2020-07-19 19:43:09] __main__ INFO: \u001b[0mVal 132\n",
      "\u001b[32m[2020-07-19 19:43:16] __main__ INFO: \u001b[0mEpoch 132 loss 0.3321 acc@1 0.8888 acc@5 0.9966\n",
      "\u001b[32m[2020-07-19 19:43:16] __main__ INFO: \u001b[0mElapsed 7.71\n",
      "\u001b[32m[2020-07-19 19:43:16] __main__ INFO: \u001b[0mTrain 133 92796\n",
      "\u001b[32m[2020-07-19 19:43:49] __main__ INFO: \u001b[0mEpoch 133 Step 100/703 lr 0.100000 loss 0.8109 (0.7707) acc@1 0.6875 (0.7158) acc@5 0.8594 (0.9081)\n",
      "\u001b[32m[2020-07-19 19:44:21] __main__ INFO: \u001b[0mEpoch 133 Step 200/703 lr 0.100000 loss 0.6796 (0.7948) acc@1 0.7500 (0.7038) acc@5 0.9375 (0.9031)\n",
      "\u001b[32m[2020-07-19 19:44:53] __main__ INFO: \u001b[0mEpoch 133 Step 300/703 lr 0.100000 loss 0.9759 (0.8087) acc@1 0.6562 (0.7002) acc@5 0.9219 (0.9014)\n",
      "\u001b[32m[2020-07-19 19:45:24] __main__ INFO: \u001b[0mEpoch 133 Step 400/703 lr 0.100000 loss 0.7957 (0.8113) acc@1 0.7031 (0.6991) acc@5 0.8906 (0.9014)\n",
      "\u001b[32m[2020-07-19 19:45:56] __main__ INFO: \u001b[0mEpoch 133 Step 500/703 lr 0.100000 loss 0.8358 (0.8167) acc@1 0.7656 (0.6972) acc@5 0.9062 (0.9003)\n",
      "\u001b[32m[2020-07-19 19:46:28] __main__ INFO: \u001b[0mEpoch 133 Step 600/703 lr 0.100000 loss 0.8171 (0.8197) acc@1 0.6875 (0.6959) acc@5 0.9375 (0.8993)\n",
      "\u001b[32m[2020-07-19 19:47:00] __main__ INFO: \u001b[0mEpoch 133 Step 700/703 lr 0.100000 loss 0.7925 (0.8221) acc@1 0.7188 (0.6952) acc@5 0.8750 (0.8995)\n",
      "\u001b[32m[2020-07-19 19:47:01] __main__ INFO: \u001b[0mEpoch 133 Step 703/703 lr 0.100000 loss 0.7887 (0.8220) acc@1 0.7031 (0.6952) acc@5 0.9531 (0.8995)\n",
      "\u001b[32m[2020-07-19 19:47:01] __main__ INFO: \u001b[0mElapsed 224.52\n",
      "\u001b[32m[2020-07-19 19:47:01] __main__ INFO: \u001b[0mVal 133\n",
      "\u001b[32m[2020-07-19 19:47:09] __main__ INFO: \u001b[0mEpoch 133 loss 0.3248 acc@1 0.8932 acc@5 0.9964\n",
      "\u001b[32m[2020-07-19 19:47:09] __main__ INFO: \u001b[0mElapsed 7.72\n",
      "\u001b[32m[2020-07-19 19:47:09] __main__ INFO: \u001b[0mTrain 134 93499\n",
      "\u001b[32m[2020-07-19 19:47:41] __main__ INFO: \u001b[0mEpoch 134 Step 100/703 lr 0.100000 loss 0.7118 (0.7984) acc@1 0.7344 (0.7002) acc@5 0.9062 (0.9016)\n",
      "\u001b[32m[2020-07-19 19:48:12] __main__ INFO: \u001b[0mEpoch 134 Step 200/703 lr 0.100000 loss 0.7398 (0.8085) acc@1 0.7188 (0.6995) acc@5 0.9062 (0.9000)\n",
      "\u001b[32m[2020-07-19 19:48:44] __main__ INFO: \u001b[0mEpoch 134 Step 300/703 lr 0.100000 loss 0.7438 (0.8117) acc@1 0.7500 (0.6981) acc@5 0.9062 (0.8986)\n",
      "\u001b[32m[2020-07-19 19:49:16] __main__ INFO: \u001b[0mEpoch 134 Step 400/703 lr 0.100000 loss 0.6845 (0.8139) acc@1 0.7500 (0.6979) acc@5 0.9531 (0.8991)\n",
      "\u001b[32m[2020-07-19 19:49:48] __main__ INFO: \u001b[0mEpoch 134 Step 500/703 lr 0.100000 loss 0.6007 (0.8210) acc@1 0.8281 (0.6955) acc@5 0.9375 (0.8982)\n",
      "\u001b[32m[2020-07-19 19:50:20] __main__ INFO: \u001b[0mEpoch 134 Step 600/703 lr 0.100000 loss 0.8822 (0.8180) acc@1 0.6719 (0.6967) acc@5 0.8906 (0.8997)\n",
      "\u001b[32m[2020-07-19 19:50:52] __main__ INFO: \u001b[0mEpoch 134 Step 700/703 lr 0.100000 loss 0.5895 (0.8211) acc@1 0.7656 (0.6955) acc@5 0.9531 (0.8997)\n",
      "\u001b[32m[2020-07-19 19:50:53] __main__ INFO: \u001b[0mEpoch 134 Step 703/703 lr 0.100000 loss 1.1770 (0.8219) acc@1 0.5781 (0.6953) acc@5 0.8281 (0.8997)\n",
      "\u001b[32m[2020-07-19 19:50:53] __main__ INFO: \u001b[0mElapsed 224.46\n",
      "\u001b[32m[2020-07-19 19:50:53] __main__ INFO: \u001b[0mVal 134\n",
      "\u001b[32m[2020-07-19 19:51:01] __main__ INFO: \u001b[0mEpoch 134 loss 0.3544 acc@1 0.8902 acc@5 0.9952\n",
      "\u001b[32m[2020-07-19 19:51:01] __main__ INFO: \u001b[0mElapsed 7.73\n",
      "\u001b[32m[2020-07-19 19:51:01] __main__ INFO: \u001b[0mTrain 135 94202\n",
      "\u001b[32m[2020-07-19 19:51:33] __main__ INFO: \u001b[0mEpoch 135 Step 100/703 lr 0.100000 loss 0.9235 (0.8044) acc@1 0.6719 (0.7027) acc@5 0.9062 (0.9022)\n",
      "\u001b[32m[2020-07-19 19:52:05] __main__ INFO: \u001b[0mEpoch 135 Step 200/703 lr 0.100000 loss 0.8366 (0.8073) acc@1 0.7031 (0.7008) acc@5 0.8906 (0.8994)\n",
      "\u001b[32m[2020-07-19 19:52:37] __main__ INFO: \u001b[0mEpoch 135 Step 300/703 lr 0.100000 loss 0.7045 (0.8083) acc@1 0.7500 (0.7010) acc@5 0.8594 (0.8997)\n",
      "\u001b[32m[2020-07-19 19:53:09] __main__ INFO: \u001b[0mEpoch 135 Step 400/703 lr 0.100000 loss 0.4265 (0.8131) acc@1 0.8594 (0.7005) acc@5 0.9844 (0.9003)\n",
      "\u001b[32m[2020-07-19 19:53:41] __main__ INFO: \u001b[0mEpoch 135 Step 500/703 lr 0.100000 loss 0.7498 (0.8135) acc@1 0.7656 (0.7002) acc@5 0.8906 (0.9013)\n",
      "\u001b[32m[2020-07-19 19:54:12] __main__ INFO: \u001b[0mEpoch 135 Step 600/703 lr 0.100000 loss 0.8076 (0.8170) acc@1 0.6562 (0.6991) acc@5 0.8438 (0.8996)\n",
      "\u001b[32m[2020-07-19 19:54:44] __main__ INFO: \u001b[0mEpoch 135 Step 700/703 lr 0.100000 loss 0.9250 (0.8218) acc@1 0.5938 (0.6966) acc@5 0.8906 (0.8998)\n",
      "\u001b[32m[2020-07-19 19:54:45] __main__ INFO: \u001b[0mEpoch 135 Step 703/703 lr 0.100000 loss 0.7591 (0.8219) acc@1 0.7188 (0.6965) acc@5 0.8750 (0.8997)\n",
      "\u001b[32m[2020-07-19 19:54:45] __main__ INFO: \u001b[0mElapsed 224.20\n",
      "\u001b[32m[2020-07-19 19:54:45] __main__ INFO: \u001b[0mVal 135\n",
      "\u001b[32m[2020-07-19 19:54:53] __main__ INFO: \u001b[0mEpoch 135 loss 0.3639 acc@1 0.8774 acc@5 0.9954\n",
      "\u001b[32m[2020-07-19 19:54:53] __main__ INFO: \u001b[0mElapsed 7.72\n",
      "\u001b[32m[2020-07-19 19:54:53] __main__ INFO: \u001b[0mTrain 136 94905\n",
      "\u001b[32m[2020-07-19 19:55:25] __main__ INFO: \u001b[0mEpoch 136 Step 100/703 lr 0.100000 loss 0.7778 (0.8097) acc@1 0.7188 (0.6967) acc@5 0.9219 (0.8977)\n",
      "\u001b[32m[2020-07-19 19:55:57] __main__ INFO: \u001b[0mEpoch 136 Step 200/703 lr 0.100000 loss 0.7214 (0.7973) acc@1 0.7344 (0.7038) acc@5 0.8906 (0.8978)\n",
      "\u001b[32m[2020-07-19 19:56:29] __main__ INFO: \u001b[0mEpoch 136 Step 300/703 lr 0.100000 loss 0.7633 (0.7971) acc@1 0.7188 (0.7034) acc@5 0.9375 (0.8998)\n",
      "\u001b[32m[2020-07-19 19:57:00] __main__ INFO: \u001b[0mEpoch 136 Step 400/703 lr 0.100000 loss 0.8106 (0.8042) acc@1 0.6719 (0.7009) acc@5 0.9062 (0.8994)\n",
      "\u001b[32m[2020-07-19 19:57:32] __main__ INFO: \u001b[0mEpoch 136 Step 500/703 lr 0.100000 loss 0.7135 (0.8102) acc@1 0.7344 (0.6988) acc@5 0.8594 (0.8992)\n",
      "\u001b[32m[2020-07-19 19:58:04] __main__ INFO: \u001b[0mEpoch 136 Step 600/703 lr 0.100000 loss 0.8475 (0.8163) acc@1 0.6250 (0.6974) acc@5 0.8906 (0.8986)\n",
      "\u001b[32m[2020-07-19 19:58:36] __main__ INFO: \u001b[0mEpoch 136 Step 700/703 lr 0.100000 loss 0.6119 (0.8192) acc@1 0.8125 (0.6964) acc@5 0.9375 (0.8982)\n",
      "\u001b[32m[2020-07-19 19:58:37] __main__ INFO: \u001b[0mEpoch 136 Step 703/703 lr 0.100000 loss 0.7970 (0.8194) acc@1 0.7188 (0.6963) acc@5 0.8906 (0.8980)\n",
      "\u001b[32m[2020-07-19 19:58:37] __main__ INFO: \u001b[0mElapsed 224.35\n",
      "\u001b[32m[2020-07-19 19:58:37] __main__ INFO: \u001b[0mVal 136\n",
      "\u001b[32m[2020-07-19 19:58:45] __main__ INFO: \u001b[0mEpoch 136 loss 0.2937 acc@1 0.9034 acc@5 0.9976\n",
      "\u001b[32m[2020-07-19 19:58:45] __main__ INFO: \u001b[0mElapsed 7.70\n",
      "\u001b[32m[2020-07-19 19:58:45] __main__ INFO: \u001b[0mTrain 137 95608\n",
      "\u001b[32m[2020-07-19 19:59:17] __main__ INFO: \u001b[0mEpoch 137 Step 100/703 lr 0.100000 loss 0.7602 (0.7710) acc@1 0.7188 (0.7142) acc@5 0.9062 (0.9064)\n",
      "\u001b[32m[2020-07-19 19:59:49] __main__ INFO: \u001b[0mEpoch 137 Step 200/703 lr 0.100000 loss 0.8027 (0.7949) acc@1 0.7344 (0.7034) acc@5 0.9219 (0.9054)\n",
      "\u001b[32m[2020-07-19 20:00:21] __main__ INFO: \u001b[0mEpoch 137 Step 300/703 lr 0.100000 loss 1.0753 (0.8104) acc@1 0.5938 (0.6970) acc@5 0.9219 (0.9012)\n",
      "\u001b[32m[2020-07-19 20:00:53] __main__ INFO: \u001b[0mEpoch 137 Step 400/703 lr 0.100000 loss 0.7988 (0.8130) acc@1 0.7188 (0.6968) acc@5 0.9531 (0.9020)\n",
      "\u001b[32m[2020-07-19 20:01:25] __main__ INFO: \u001b[0mEpoch 137 Step 500/703 lr 0.100000 loss 0.9244 (0.8185) acc@1 0.6562 (0.6956) acc@5 0.9062 (0.9018)\n",
      "\u001b[32m[2020-07-19 20:01:57] __main__ INFO: \u001b[0mEpoch 137 Step 600/703 lr 0.100000 loss 0.8044 (0.8216) acc@1 0.7031 (0.6948) acc@5 0.8906 (0.9014)\n",
      "\u001b[32m[2020-07-19 20:02:29] __main__ INFO: \u001b[0mEpoch 137 Step 700/703 lr 0.100000 loss 0.6516 (0.8189) acc@1 0.7031 (0.6961) acc@5 0.9062 (0.9021)\n",
      "\u001b[32m[2020-07-19 20:02:30] __main__ INFO: \u001b[0mEpoch 137 Step 703/703 lr 0.100000 loss 0.5834 (0.8191) acc@1 0.7656 (0.6960) acc@5 0.9062 (0.9021)\n",
      "\u001b[32m[2020-07-19 20:02:30] __main__ INFO: \u001b[0mElapsed 224.85\n",
      "\u001b[32m[2020-07-19 20:02:30] __main__ INFO: \u001b[0mVal 137\n",
      "\u001b[32m[2020-07-19 20:02:38] __main__ INFO: \u001b[0mEpoch 137 loss 0.3558 acc@1 0.8852 acc@5 0.9972\n",
      "\u001b[32m[2020-07-19 20:02:38] __main__ INFO: \u001b[0mElapsed 7.74\n",
      "\u001b[32m[2020-07-19 20:02:38] __main__ INFO: \u001b[0mTrain 138 96311\n",
      "\u001b[32m[2020-07-19 20:03:09] __main__ INFO: \u001b[0mEpoch 138 Step 100/703 lr 0.100000 loss 0.7094 (0.7948) acc@1 0.6719 (0.7013) acc@5 0.9375 (0.8997)\n",
      "\u001b[32m[2020-07-19 20:03:41] __main__ INFO: \u001b[0mEpoch 138 Step 200/703 lr 0.100000 loss 0.8508 (0.8043) acc@1 0.7031 (0.7005) acc@5 0.9219 (0.9027)\n",
      "\u001b[32m[2020-07-19 20:04:13] __main__ INFO: \u001b[0mEpoch 138 Step 300/703 lr 0.100000 loss 0.5573 (0.8130) acc@1 0.8281 (0.6967) acc@5 0.9531 (0.9002)\n",
      "\u001b[32m[2020-07-19 20:04:45] __main__ INFO: \u001b[0mEpoch 138 Step 400/703 lr 0.100000 loss 0.7195 (0.8139) acc@1 0.7656 (0.6966) acc@5 0.9688 (0.9006)\n",
      "\u001b[32m[2020-07-19 20:05:17] __main__ INFO: \u001b[0mEpoch 138 Step 500/703 lr 0.100000 loss 0.7931 (0.8145) acc@1 0.6719 (0.6970) acc@5 0.8438 (0.9008)\n",
      "\u001b[32m[2020-07-19 20:05:49] __main__ INFO: \u001b[0mEpoch 138 Step 600/703 lr 0.100000 loss 1.2000 (0.8173) acc@1 0.5625 (0.6960) acc@5 0.8594 (0.9003)\n",
      "\u001b[32m[2020-07-19 20:06:21] __main__ INFO: \u001b[0mEpoch 138 Step 700/703 lr 0.100000 loss 0.8439 (0.8208) acc@1 0.6406 (0.6946) acc@5 0.8281 (0.9007)\n",
      "\u001b[32m[2020-07-19 20:06:22] __main__ INFO: \u001b[0mEpoch 138 Step 703/703 lr 0.100000 loss 0.8008 (0.8212) acc@1 0.7344 (0.6945) acc@5 0.8906 (0.9006)\n",
      "\u001b[32m[2020-07-19 20:06:22] __main__ INFO: \u001b[0mElapsed 224.35\n",
      "\u001b[32m[2020-07-19 20:06:22] __main__ INFO: \u001b[0mVal 138\n",
      "\u001b[32m[2020-07-19 20:06:30] __main__ INFO: \u001b[0mEpoch 138 loss 0.3539 acc@1 0.8826 acc@5 0.9980\n",
      "\u001b[32m[2020-07-19 20:06:30] __main__ INFO: \u001b[0mElapsed 7.73\n",
      "\u001b[32m[2020-07-19 20:06:30] __main__ INFO: \u001b[0mTrain 139 97014\n",
      "\u001b[32m[2020-07-19 20:07:02] __main__ INFO: \u001b[0mEpoch 139 Step 100/703 lr 0.100000 loss 0.8650 (0.7601) acc@1 0.7031 (0.7192) acc@5 0.9375 (0.9045)\n",
      "\u001b[32m[2020-07-19 20:07:34] __main__ INFO: \u001b[0mEpoch 139 Step 200/703 lr 0.100000 loss 0.8757 (0.7983) acc@1 0.6875 (0.7007) acc@5 0.9219 (0.8993)\n",
      "\u001b[32m[2020-07-19 20:08:06] __main__ INFO: \u001b[0mEpoch 139 Step 300/703 lr 0.100000 loss 0.8781 (0.8127) acc@1 0.6406 (0.6958) acc@5 0.8906 (0.8964)\n",
      "\u001b[32m[2020-07-19 20:08:38] __main__ INFO: \u001b[0mEpoch 139 Step 400/703 lr 0.100000 loss 0.8930 (0.8116) acc@1 0.6094 (0.6971) acc@5 0.8750 (0.8975)\n",
      "\u001b[32m[2020-07-19 20:09:09] __main__ INFO: \u001b[0mEpoch 139 Step 500/703 lr 0.100000 loss 0.5428 (0.8113) acc@1 0.7969 (0.6971) acc@5 0.9844 (0.8982)\n",
      "\u001b[32m[2020-07-19 20:09:41] __main__ INFO: \u001b[0mEpoch 139 Step 600/703 lr 0.100000 loss 0.9348 (0.8149) acc@1 0.6562 (0.6964) acc@5 0.8594 (0.8988)\n",
      "\u001b[32m[2020-07-19 20:10:13] __main__ INFO: \u001b[0mEpoch 139 Step 700/703 lr 0.100000 loss 0.8011 (0.8198) acc@1 0.6719 (0.6943) acc@5 0.9219 (0.8987)\n",
      "\u001b[32m[2020-07-19 20:10:14] __main__ INFO: \u001b[0mEpoch 139 Step 703/703 lr 0.100000 loss 0.9406 (0.8200) acc@1 0.6250 (0.6941) acc@5 0.8281 (0.8986)\n",
      "\u001b[32m[2020-07-19 20:10:14] __main__ INFO: \u001b[0mElapsed 224.57\n",
      "\u001b[32m[2020-07-19 20:10:14] __main__ INFO: \u001b[0mVal 139\n",
      "\u001b[32m[2020-07-19 20:10:22] __main__ INFO: \u001b[0mEpoch 139 loss 0.3572 acc@1 0.8826 acc@5 0.9962\n",
      "\u001b[32m[2020-07-19 20:10:22] __main__ INFO: \u001b[0mElapsed 7.73\n",
      "\u001b[32m[2020-07-19 20:10:22] __main__ INFO: \u001b[0mTrain 140 97717\n",
      "\u001b[32m[2020-07-19 20:10:54] __main__ INFO: \u001b[0mEpoch 140 Step 100/703 lr 0.100000 loss 0.6810 (0.7783) acc@1 0.7344 (0.7092) acc@5 0.8906 (0.9011)\n",
      "\u001b[32m[2020-07-19 20:11:26] __main__ INFO: \u001b[0mEpoch 140 Step 200/703 lr 0.100000 loss 1.1008 (0.8040) acc@1 0.5625 (0.6992) acc@5 0.8750 (0.9008)\n",
      "\u001b[32m[2020-07-19 20:11:58] __main__ INFO: \u001b[0mEpoch 140 Step 300/703 lr 0.100000 loss 0.5893 (0.8129) acc@1 0.8125 (0.6959) acc@5 0.9219 (0.9002)\n",
      "\u001b[32m[2020-07-19 20:12:29] __main__ INFO: \u001b[0mEpoch 140 Step 400/703 lr 0.100000 loss 0.8896 (0.8155) acc@1 0.6719 (0.6960) acc@5 0.9219 (0.9015)\n",
      "\u001b[32m[2020-07-19 20:13:01] __main__ INFO: \u001b[0mEpoch 140 Step 500/703 lr 0.100000 loss 0.7313 (0.8181) acc@1 0.7031 (0.6951) acc@5 0.9219 (0.9019)\n",
      "\u001b[32m[2020-07-19 20:13:33] __main__ INFO: \u001b[0mEpoch 140 Step 600/703 lr 0.100000 loss 0.9184 (0.8251) acc@1 0.6562 (0.6925) acc@5 0.9062 (0.9010)\n",
      "\u001b[32m[2020-07-19 20:14:05] __main__ INFO: \u001b[0mEpoch 140 Step 700/703 lr 0.100000 loss 0.6258 (0.8244) acc@1 0.7656 (0.6923) acc@5 0.9062 (0.9011)\n",
      "\u001b[32m[2020-07-19 20:14:06] __main__ INFO: \u001b[0mEpoch 140 Step 703/703 lr 0.100000 loss 1.0235 (0.8244) acc@1 0.6094 (0.6923) acc@5 0.8906 (0.9012)\n",
      "\u001b[32m[2020-07-19 20:14:06] __main__ INFO: \u001b[0mElapsed 224.29\n",
      "\u001b[32m[2020-07-19 20:14:06] __main__ INFO: \u001b[0mVal 140\n",
      "\u001b[32m[2020-07-19 20:14:14] __main__ INFO: \u001b[0mEpoch 140 loss 0.3543 acc@1 0.8808 acc@5 0.9966\n",
      "\u001b[32m[2020-07-19 20:14:14] __main__ INFO: \u001b[0mElapsed 7.71\n",
      "\u001b[32m[2020-07-19 20:14:14] __main__ INFO: \u001b[0mTrain 141 98420\n",
      "\u001b[32m[2020-07-19 20:14:46] __main__ INFO: \u001b[0mEpoch 141 Step 100/703 lr 0.100000 loss 0.7703 (0.8048) acc@1 0.6719 (0.7006) acc@5 0.9062 (0.8931)\n",
      "\u001b[32m[2020-07-19 20:15:18] __main__ INFO: \u001b[0mEpoch 141 Step 200/703 lr 0.100000 loss 0.7137 (0.8047) acc@1 0.7500 (0.7022) acc@5 0.8906 (0.8970)\n",
      "\u001b[32m[2020-07-19 20:15:50] __main__ INFO: \u001b[0mEpoch 141 Step 300/703 lr 0.100000 loss 0.5372 (0.8077) acc@1 0.7969 (0.7006) acc@5 0.9375 (0.8992)\n",
      "\u001b[32m[2020-07-19 20:16:22] __main__ INFO: \u001b[0mEpoch 141 Step 400/703 lr 0.100000 loss 0.8788 (0.8132) acc@1 0.6406 (0.6989) acc@5 0.9219 (0.8998)\n",
      "\u001b[32m[2020-07-19 20:16:54] __main__ INFO: \u001b[0mEpoch 141 Step 500/703 lr 0.100000 loss 0.8875 (0.8164) acc@1 0.6406 (0.6967) acc@5 0.8906 (0.9004)\n",
      "\u001b[32m[2020-07-19 20:17:25] __main__ INFO: \u001b[0mEpoch 141 Step 600/703 lr 0.100000 loss 0.7431 (0.8148) acc@1 0.7344 (0.6982) acc@5 0.9219 (0.9009)\n",
      "\u001b[32m[2020-07-19 20:17:57] __main__ INFO: \u001b[0mEpoch 141 Step 700/703 lr 0.100000 loss 0.8122 (0.8193) acc@1 0.7031 (0.6961) acc@5 0.8906 (0.9001)\n",
      "\u001b[32m[2020-07-19 20:17:58] __main__ INFO: \u001b[0mEpoch 141 Step 703/703 lr 0.100000 loss 1.0039 (0.8193) acc@1 0.6562 (0.6961) acc@5 0.9219 (0.9002)\n",
      "\u001b[32m[2020-07-19 20:17:58] __main__ INFO: \u001b[0mElapsed 224.49\n",
      "\u001b[32m[2020-07-19 20:17:58] __main__ INFO: \u001b[0mVal 141\n",
      "\u001b[32m[2020-07-19 20:18:06] __main__ INFO: \u001b[0mEpoch 141 loss 0.3329 acc@1 0.8902 acc@5 0.9972\n",
      "\u001b[32m[2020-07-19 20:18:06] __main__ INFO: \u001b[0mElapsed 7.73\n",
      "\u001b[32m[2020-07-19 20:18:06] __main__ INFO: \u001b[0mTrain 142 99123\n",
      "\u001b[32m[2020-07-19 20:18:38] __main__ INFO: \u001b[0mEpoch 142 Step 100/703 lr 0.100000 loss 0.6053 (0.7703) acc@1 0.8125 (0.7087) acc@5 0.9531 (0.9033)\n",
      "\u001b[32m[2020-07-19 20:20:46] __main__ INFO: \u001b[0mEpoch 142 Step 500/703 lr 0.100000 loss 0.7432 (0.8068) acc@1 0.7188 (0.6985) acc@5 0.8906 (0.8992)\n",
      "\u001b[32m[2020-07-19 20:21:18] __main__ INFO: \u001b[0mEpoch 142 Step 600/703 lr 0.100000 loss 0.7554 (0.8072) acc@1 0.7031 (0.6983) acc@5 0.9219 (0.9001)\n",
      "\u001b[32m[2020-07-19 20:21:50] __main__ INFO: \u001b[0mEpoch 142 Step 700/703 lr 0.100000 loss 0.6181 (0.8148) acc@1 0.8125 (0.6962) acc@5 0.9688 (0.8992)\n",
      "\u001b[32m[2020-07-19 20:21:50] __main__ INFO: \u001b[0mEpoch 142 Step 703/703 lr 0.100000 loss 1.0493 (0.8150) acc@1 0.5781 (0.6961) acc@5 0.8594 (0.8992)\n",
      "\u001b[32m[2020-07-19 20:21:51] __main__ INFO: \u001b[0mElapsed 224.39\n",
      "\u001b[32m[2020-07-19 20:21:51] __main__ INFO: \u001b[0mVal 142\n",
      "\u001b[32m[2020-07-19 20:21:58] __main__ INFO: \u001b[0mEpoch 142 loss 0.3441 acc@1 0.8892 acc@5 0.9976\n",
      "\u001b[32m[2020-07-19 20:21:58] __main__ INFO: \u001b[0mElapsed 7.71\n",
      "\u001b[32m[2020-07-19 20:21:58] __main__ INFO: \u001b[0mTrain 143 99826\n",
      "\u001b[32m[2020-07-19 20:22:30] __main__ INFO: \u001b[0mEpoch 143 Step 100/703 lr 0.100000 loss 0.7441 (0.7876) acc@1 0.7656 (0.7094) acc@5 0.9062 (0.9067)\n",
      "\u001b[32m[2020-07-19 20:23:02] __main__ INFO: \u001b[0mEpoch 143 Step 200/703 lr 0.100000 loss 0.8774 (0.7976) acc@1 0.6406 (0.7027) acc@5 0.8594 (0.9048)\n",
      "\u001b[32m[2020-07-19 20:23:34] __main__ INFO: \u001b[0mEpoch 143 Step 300/703 lr 0.100000 loss 1.1619 (0.8109) acc@1 0.5781 (0.6990) acc@5 0.8438 (0.9028)\n",
      "\u001b[32m[2020-07-19 20:24:06] __main__ INFO: \u001b[0mEpoch 143 Step 400/703 lr 0.100000 loss 1.1040 (0.8119) acc@1 0.6562 (0.6991) acc@5 0.8438 (0.9034)\n",
      "\u001b[32m[2020-07-19 20:24:38] __main__ INFO: \u001b[0mEpoch 143 Step 500/703 lr 0.100000 loss 0.8459 (0.8125) acc@1 0.6875 (0.6988) acc@5 0.8750 (0.9032)\n",
      "\u001b[32m[2020-07-19 20:25:10] __main__ INFO: \u001b[0mEpoch 143 Step 600/703 lr 0.100000 loss 1.1559 (0.8155) acc@1 0.5938 (0.6979) acc@5 0.8750 (0.9016)\n",
      "\u001b[32m[2020-07-19 20:25:42] __main__ INFO: \u001b[0mEpoch 143 Step 700/703 lr 0.100000 loss 1.0429 (0.8190) acc@1 0.6094 (0.6965) acc@5 0.9375 (0.9025)\n",
      "\u001b[32m[2020-07-19 20:25:42] __main__ INFO: \u001b[0mEpoch 143 Step 703/703 lr 0.100000 loss 0.8857 (0.8192) acc@1 0.7344 (0.6965) acc@5 0.9844 (0.9026)\n",
      "\u001b[32m[2020-07-19 20:25:42] __main__ INFO: \u001b[0mElapsed 224.26\n",
      "\u001b[32m[2020-07-19 20:25:43] __main__ INFO: \u001b[0mVal 143\n",
      "\u001b[32m[2020-07-19 20:25:50] __main__ INFO: \u001b[0mEpoch 143 loss 0.4592 acc@1 0.8606 acc@5 0.9956\n",
      "\u001b[32m[2020-07-19 20:25:50] __main__ INFO: \u001b[0mElapsed 7.73\n",
      "\u001b[32m[2020-07-19 20:25:50] __main__ INFO: \u001b[0mTrain 144 100529\n",
      "\u001b[32m[2020-07-19 20:26:22] __main__ INFO: \u001b[0mEpoch 144 Step 100/703 lr 0.100000 loss 0.6200 (0.8027) acc@1 0.7656 (0.7033) acc@5 0.9062 (0.9000)\n",
      "\u001b[32m[2020-07-19 20:26:54] __main__ INFO: \u001b[0mEpoch 144 Step 200/703 lr 0.100000 loss 0.6317 (0.7962) acc@1 0.7969 (0.7043) acc@5 0.9531 (0.9025)\n",
      "\u001b[32m[2020-07-19 20:27:26] __main__ INFO: \u001b[0mEpoch 144 Step 300/703 lr 0.100000 loss 0.9109 (0.8116) acc@1 0.6406 (0.6989) acc@5 0.8438 (0.9028)\n",
      "\u001b[32m[2020-07-19 20:27:58] __main__ INFO: \u001b[0mEpoch 144 Step 400/703 lr 0.100000 loss 0.7387 (0.8142) acc@1 0.7188 (0.6977) acc@5 0.9375 (0.9021)\n",
      "\u001b[32m[2020-07-19 20:28:30] __main__ INFO: \u001b[0mEpoch 144 Step 500/703 lr 0.100000 loss 0.8090 (0.8165) acc@1 0.7031 (0.6964) acc@5 0.8594 (0.9005)\n",
      "\u001b[32m[2020-07-19 20:29:02] __main__ INFO: \u001b[0mEpoch 144 Step 600/703 lr 0.100000 loss 1.3035 (0.8158) acc@1 0.4844 (0.6967) acc@5 0.7969 (0.9003)\n",
      "\u001b[32m[2020-07-19 20:29:34] __main__ INFO: \u001b[0mEpoch 144 Step 700/703 lr 0.100000 loss 0.9679 (0.8201) acc@1 0.6406 (0.6949) acc@5 0.8594 (0.8998)\n",
      "\u001b[32m[2020-07-19 20:29:35] __main__ INFO: \u001b[0mEpoch 144 Step 703/703 lr 0.100000 loss 0.7683 (0.8199) acc@1 0.7344 (0.6949) acc@5 0.9219 (0.8998)\n",
      "\u001b[32m[2020-07-19 20:29:35] __main__ INFO: \u001b[0mElapsed 224.36\n",
      "\u001b[32m[2020-07-19 20:29:35] __main__ INFO: \u001b[0mVal 144\n",
      "\u001b[32m[2020-07-19 20:29:42] __main__ INFO: \u001b[0mEpoch 144 loss 0.3472 acc@1 0.8812 acc@5 0.9970\n",
      "\u001b[32m[2020-07-19 20:29:42] __main__ INFO: \u001b[0mElapsed 7.72\n",
      "\u001b[32m[2020-07-19 20:29:42] __main__ INFO: \u001b[0mTrain 145 101232\n",
      "\u001b[32m[2020-07-19 20:30:14] __main__ INFO: \u001b[0mEpoch 145 Step 100/703 lr 0.100000 loss 0.8789 (0.8026) acc@1 0.6875 (0.7020) acc@5 0.8750 (0.9022)\n",
      "\u001b[32m[2020-07-19 20:30:46] __main__ INFO: \u001b[0mEpoch 145 Step 200/703 lr 0.100000 loss 0.6127 (0.8015) acc@1 0.8125 (0.7013) acc@5 0.9844 (0.9003)\n",
      "\u001b[32m[2020-07-19 20:31:18] __main__ INFO: \u001b[0mEpoch 145 Step 300/703 lr 0.100000 loss 0.7311 (0.7956) acc@1 0.6875 (0.7023) acc@5 0.9688 (0.9029)\n",
      "\u001b[32m[2020-07-19 20:31:50] __main__ INFO: \u001b[0mEpoch 145 Step 400/703 lr 0.100000 loss 0.9927 (0.8012) acc@1 0.6250 (0.7000) acc@5 0.8906 (0.9019)\n",
      "\u001b[32m[2020-07-19 20:32:22] __main__ INFO: \u001b[0mEpoch 145 Step 500/703 lr 0.100000 loss 0.8108 (0.8084) acc@1 0.6562 (0.6982) acc@5 0.9219 (0.9003)\n",
      "\u001b[32m[2020-07-19 20:32:54] __main__ INFO: \u001b[0mEpoch 145 Step 600/703 lr 0.100000 loss 0.7617 (0.8152) acc@1 0.7031 (0.6957) acc@5 0.9219 (0.8991)\n",
      "\u001b[32m[2020-07-19 20:33:25] __main__ INFO: \u001b[0mEpoch 145 Step 700/703 lr 0.100000 loss 0.7114 (0.8184) acc@1 0.7344 (0.6954) acc@5 0.8906 (0.8993)\n",
      "\u001b[32m[2020-07-19 20:33:26] __main__ INFO: \u001b[0mEpoch 145 Step 703/703 lr 0.100000 loss 1.0446 (0.8187) acc@1 0.6406 (0.6952) acc@5 0.8750 (0.8992)\n",
      "\u001b[32m[2020-07-19 20:33:26] __main__ INFO: \u001b[0mElapsed 224.11\n",
      "\u001b[32m[2020-07-19 20:33:26] __main__ INFO: \u001b[0mVal 145\n",
      "\u001b[32m[2020-07-19 20:33:34] __main__ INFO: \u001b[0mEpoch 145 loss 0.4469 acc@1 0.8584 acc@5 0.9962\n",
      "\u001b[32m[2020-07-19 20:33:34] __main__ INFO: \u001b[0mElapsed 7.70\n",
      "\u001b[32m[2020-07-19 20:33:34] __main__ INFO: \u001b[0mTrain 146 101935\n",
      "\u001b[32m[2020-07-19 20:34:06] __main__ INFO: \u001b[0mEpoch 146 Step 100/703 lr 0.100000 loss 0.9025 (0.8097) acc@1 0.6406 (0.6963) acc@5 0.8438 (0.9012)\n",
      "\u001b[32m[2020-07-19 20:34:38] __main__ INFO: \u001b[0mEpoch 146 Step 200/703 lr 0.100000 loss 0.6889 (0.8145) acc@1 0.7188 (0.6947) acc@5 0.8906 (0.9006)\n",
      "\u001b[32m[2020-07-19 20:35:10] __main__ INFO: \u001b[0mEpoch 146 Step 300/703 lr 0.100000 loss 0.8516 (0.8110) acc@1 0.7344 (0.6962) acc@5 0.9062 (0.9011)\n",
      "\u001b[32m[2020-07-19 20:35:42] __main__ INFO: \u001b[0mEpoch 146 Step 400/703 lr 0.100000 loss 0.8399 (0.8106) acc@1 0.6875 (0.6964) acc@5 0.8906 (0.9020)\n",
      "\u001b[32m[2020-07-19 20:36:14] __main__ INFO: \u001b[0mEpoch 146 Step 500/703 lr 0.100000 loss 0.8112 (0.8180) acc@1 0.7031 (0.6940) acc@5 0.8906 (0.9003)\n",
      "\u001b[32m[2020-07-19 20:36:46] __main__ INFO: \u001b[0mEpoch 146 Step 600/703 lr 0.100000 loss 0.9774 (0.8194) acc@1 0.6406 (0.6942) acc@5 0.9219 (0.9008)\n",
      "\u001b[32m[2020-07-19 20:37:18] __main__ INFO: \u001b[0mEpoch 146 Step 700/703 lr 0.100000 loss 0.7662 (0.8211) acc@1 0.6875 (0.6941) acc@5 0.9062 (0.9001)\n",
      "\u001b[32m[2020-07-19 20:37:19] __main__ INFO: \u001b[0mEpoch 146 Step 703/703 lr 0.100000 loss 0.8874 (0.8210) acc@1 0.6406 (0.6941) acc@5 0.9531 (0.9002)\n",
      "\u001b[32m[2020-07-19 20:37:19] __main__ INFO: \u001b[0mElapsed 224.48\n",
      "\u001b[32m[2020-07-19 20:37:19] __main__ INFO: \u001b[0mVal 146\n",
      "\u001b[32m[2020-07-19 20:37:26] __main__ INFO: \u001b[0mEpoch 146 loss 0.4286 acc@1 0.8594 acc@5 0.9956\n",
      "\u001b[32m[2020-07-19 20:37:26] __main__ INFO: \u001b[0mElapsed 7.74\n",
      "\u001b[32m[2020-07-19 20:37:26] __main__ INFO: \u001b[0mTrain 147 102638\n",
      "\u001b[32m[2020-07-19 20:37:58] __main__ INFO: \u001b[0mEpoch 147 Step 100/703 lr 0.100000 loss 0.7488 (0.7925) acc@1 0.7188 (0.7070) acc@5 0.9062 (0.9009)\n",
      "\u001b[32m[2020-07-19 20:38:30] __main__ INFO: \u001b[0mEpoch 147 Step 200/703 lr 0.100000 loss 0.8983 (0.8003) acc@1 0.6562 (0.7026) acc@5 0.9062 (0.8999)\n",
      "\u001b[32m[2020-07-19 20:39:02] __main__ INFO: \u001b[0mEpoch 147 Step 300/703 lr 0.100000 loss 0.9385 (0.8049) acc@1 0.7031 (0.7004) acc@5 0.9219 (0.8998)\n",
      "\u001b[32m[2020-07-19 20:39:34] __main__ INFO: \u001b[0mEpoch 147 Step 400/703 lr 0.100000 loss 0.8557 (0.8084) acc@1 0.6719 (0.6993) acc@5 0.8594 (0.8999)\n",
      "\u001b[32m[2020-07-19 20:40:06] __main__ INFO: \u001b[0mEpoch 147 Step 500/703 lr 0.100000 loss 0.5928 (0.8139) acc@1 0.7344 (0.6970) acc@5 0.9375 (0.8992)\n",
      "\u001b[32m[2020-07-19 20:40:38] __main__ INFO: \u001b[0mEpoch 147 Step 600/703 lr 0.100000 loss 0.8540 (0.8181) acc@1 0.6875 (0.6943) acc@5 0.9375 (0.8991)\n",
      "\u001b[32m[2020-07-19 20:41:10] __main__ INFO: \u001b[0mEpoch 147 Step 700/703 lr 0.100000 loss 0.6398 (0.8172) acc@1 0.7812 (0.6954) acc@5 0.9375 (0.8990)\n",
      "\u001b[32m[2020-07-19 20:41:11] __main__ INFO: \u001b[0mEpoch 147 Step 703/703 lr 0.100000 loss 1.0136 (0.8174) acc@1 0.6406 (0.6953) acc@5 0.7812 (0.8989)\n",
      "\u001b[32m[2020-07-19 20:41:11] __main__ INFO: \u001b[0mElapsed 224.70\n",
      "\u001b[32m[2020-07-19 20:41:11] __main__ INFO: \u001b[0mVal 147\n",
      "\u001b[32m[2020-07-19 20:41:19] __main__ INFO: \u001b[0mEpoch 147 loss 0.3803 acc@1 0.8730 acc@5 0.9966\n",
      "\u001b[32m[2020-07-19 20:41:19] __main__ INFO: \u001b[0mElapsed 7.75\n",
      "\u001b[32m[2020-07-19 20:41:19] __main__ INFO: \u001b[0mTrain 148 103341\n",
      "\u001b[32m[2020-07-19 20:41:51] __main__ INFO: \u001b[0mEpoch 148 Step 100/703 lr 0.100000 loss 0.5802 (0.7617) acc@1 0.8125 (0.7205) acc@5 0.9062 (0.9052)\n",
      "\u001b[32m[2020-07-19 20:42:23] __main__ INFO: \u001b[0mEpoch 148 Step 200/703 lr 0.100000 loss 0.7584 (0.7731) acc@1 0.7031 (0.7134) acc@5 0.9375 (0.9012)\n",
      "\u001b[32m[2020-07-19 20:42:54] __main__ INFO: \u001b[0mEpoch 148 Step 300/703 lr 0.100000 loss 0.7911 (0.7886) acc@1 0.7188 (0.7074) acc@5 0.9062 (0.9015)\n",
      "\u001b[32m[2020-07-19 20:43:26] __main__ INFO: \u001b[0mEpoch 148 Step 400/703 lr 0.100000 loss 0.7122 (0.8056) acc@1 0.7656 (0.7004) acc@5 0.9375 (0.8984)\n",
      "\u001b[32m[2020-07-19 20:43:58] __main__ INFO: \u001b[0mEpoch 148 Step 500/703 lr 0.100000 loss 0.8627 (0.8113) acc@1 0.6406 (0.6977) acc@5 0.9219 (0.8989)\n",
      "\u001b[32m[2020-07-19 20:44:30] __main__ INFO: \u001b[0mEpoch 148 Step 600/703 lr 0.100000 loss 0.7722 (0.8102) acc@1 0.7188 (0.6987) acc@5 0.9375 (0.8998)\n",
      "\u001b[32m[2020-07-19 20:45:02] __main__ INFO: \u001b[0mEpoch 148 Step 700/703 lr 0.100000 loss 0.7206 (0.8155) acc@1 0.7812 (0.6963) acc@5 0.9531 (0.8996)\n",
      "\u001b[32m[2020-07-19 20:45:03] __main__ INFO: \u001b[0mEpoch 148 Step 703/703 lr 0.100000 loss 0.6432 (0.8154) acc@1 0.7969 (0.6963) acc@5 0.9219 (0.8996)\n",
      "\u001b[32m[2020-07-19 20:45:03] __main__ INFO: \u001b[0mElapsed 224.16\n",
      "\u001b[32m[2020-07-19 20:45:03] __main__ INFO: \u001b[0mVal 148\n",
      "\u001b[32m[2020-07-19 20:45:11] __main__ INFO: \u001b[0mEpoch 148 loss 0.3133 acc@1 0.8946 acc@5 0.9976\n",
      "\u001b[32m[2020-07-19 20:45:11] __main__ INFO: \u001b[0mElapsed 7.72\n",
      "\u001b[32m[2020-07-19 20:45:11] __main__ INFO: \u001b[0mTrain 149 104044\n",
      "\u001b[32m[2020-07-19 20:45:43] __main__ INFO: \u001b[0mEpoch 149 Step 100/703 lr 0.100000 loss 0.8802 (0.7626) acc@1 0.6094 (0.7173) acc@5 0.8438 (0.9023)\n",
      "\u001b[32m[2020-07-19 20:46:15] __main__ INFO: \u001b[0mEpoch 149 Step 200/703 lr 0.100000 loss 0.8180 (0.7902) acc@1 0.7344 (0.7045) acc@5 0.9219 (0.8985)\n",
      "\u001b[32m[2020-07-19 20:46:47] __main__ INFO: \u001b[0mEpoch 149 Step 300/703 lr 0.100000 loss 1.0023 (0.7988) acc@1 0.6250 (0.7019) acc@5 0.8750 (0.8983)\n",
      "\u001b[32m[2020-07-19 20:47:19] __main__ INFO: \u001b[0mEpoch 149 Step 400/703 lr 0.100000 loss 0.8780 (0.8060) acc@1 0.6562 (0.7006) acc@5 0.8906 (0.8986)\n",
      "\u001b[32m[2020-07-19 20:47:50] __main__ INFO: \u001b[0mEpoch 149 Step 500/703 lr 0.100000 loss 0.8515 (0.8127) acc@1 0.7188 (0.6982) acc@5 0.9375 (0.8982)\n",
      "\u001b[32m[2020-07-19 20:48:22] __main__ INFO: \u001b[0mEpoch 149 Step 600/703 lr 0.100000 loss 0.5601 (0.8151) acc@1 0.7656 (0.6968) acc@5 0.8906 (0.8989)\n",
      "\u001b[32m[2020-07-19 20:48:54] __main__ INFO: \u001b[0mEpoch 149 Step 700/703 lr 0.100000 loss 0.7846 (0.8178) acc@1 0.6562 (0.6964) acc@5 0.8906 (0.8985)\n",
      "\u001b[32m[2020-07-19 20:48:55] __main__ INFO: \u001b[0mEpoch 149 Step 703/703 lr 0.100000 loss 0.8587 (0.8182) acc@1 0.7031 (0.6962) acc@5 0.8594 (0.8984)\n",
      "\u001b[32m[2020-07-19 20:48:55] __main__ INFO: \u001b[0mElapsed 224.69\n",
      "\u001b[32m[2020-07-19 20:48:55] __main__ INFO: \u001b[0mVal 149\n",
      "\u001b[32m[2020-07-19 20:49:03] __main__ INFO: \u001b[0mEpoch 149 loss 0.3889 acc@1 0.8772 acc@5 0.9920\n",
      "\u001b[32m[2020-07-19 20:49:03] __main__ INFO: \u001b[0mElapsed 7.73\n",
      "\u001b[32m[2020-07-19 20:49:03] __main__ INFO: \u001b[0mTrain 150 104747\n",
      "\u001b[32m[2020-07-19 20:49:35] __main__ INFO: \u001b[0mEpoch 150 Step 100/703 lr 0.100000 loss 0.5646 (0.7951) acc@1 0.7812 (0.7064) acc@5 0.9062 (0.8991)\n",
      "\u001b[32m[2020-07-19 20:50:07] __main__ INFO: \u001b[0mEpoch 150 Step 200/703 lr 0.100000 loss 0.9976 (0.8035) acc@1 0.6094 (0.6986) acc@5 0.8125 (0.8993)\n",
      "\u001b[32m[2020-07-19 20:50:39] __main__ INFO: \u001b[0mEpoch 150 Step 300/703 lr 0.100000 loss 0.7220 (0.8068) acc@1 0.7500 (0.6963) acc@5 0.8438 (0.8969)\n",
      "\u001b[32m[2020-07-19 20:51:11] __main__ INFO: \u001b[0mEpoch 150 Step 400/703 lr 0.100000 loss 0.8756 (0.8069) acc@1 0.7188 (0.6973) acc@5 0.8906 (0.8995)\n",
      "\u001b[32m[2020-07-19 20:51:43] __main__ INFO: \u001b[0mEpoch 150 Step 500/703 lr 0.100000 loss 0.7786 (0.8075) acc@1 0.6875 (0.6974) acc@5 0.9375 (0.8995)\n",
      "\u001b[32m[2020-07-19 20:52:15] __main__ INFO: \u001b[0mEpoch 150 Step 600/703 lr 0.100000 loss 0.7730 (0.8166) acc@1 0.7031 (0.6945) acc@5 0.9219 (0.8996)\n",
      "\u001b[32m[2020-07-19 20:52:47] __main__ INFO: \u001b[0mEpoch 150 Step 700/703 lr 0.100000 loss 0.7659 (0.8207) acc@1 0.7188 (0.6936) acc@5 0.9062 (0.8994)\n",
      "\u001b[32m[2020-07-19 20:52:48] __main__ INFO: \u001b[0mEpoch 150 Step 703/703 lr 0.100000 loss 0.7428 (0.8208) acc@1 0.7188 (0.6936) acc@5 0.9375 (0.8993)\n",
      "\u001b[32m[2020-07-19 20:52:48] __main__ INFO: \u001b[0mElapsed 224.67\n",
      "\u001b[32m[2020-07-19 20:52:48] __main__ INFO: \u001b[0mVal 150\n",
      "\u001b[32m[2020-07-19 20:52:56] __main__ INFO: \u001b[0mEpoch 150 loss 0.3124 acc@1 0.8980 acc@5 0.9966\n",
      "\u001b[32m[2020-07-19 20:52:56] __main__ INFO: \u001b[0mElapsed 7.74\n",
      "\u001b[32m[2020-07-19 20:52:56] __main__ INFO: \u001b[0mTrain 151 105450\n",
      "\u001b[32m[2020-07-19 20:53:28] __main__ INFO: \u001b[0mEpoch 151 Step 100/703 lr 0.010000 loss 0.7340 (0.7394) acc@1 0.7188 (0.7270) acc@5 0.9375 (0.9017)\n",
      "\u001b[32m[2020-07-19 20:54:00] __main__ INFO: \u001b[0mEpoch 151 Step 200/703 lr 0.010000 loss 0.6487 (0.7080) acc@1 0.7500 (0.7382) acc@5 0.8594 (0.9030)\n",
      "\u001b[32m[2020-07-19 20:54:32] __main__ INFO: \u001b[0mEpoch 151 Step 300/703 lr 0.010000 loss 0.5581 (0.6969) acc@1 0.7812 (0.7422) acc@5 0.9062 (0.9032)\n",
      "\u001b[32m[2020-07-19 20:55:03] __main__ INFO: \u001b[0mEpoch 151 Step 400/703 lr 0.010000 loss 0.8276 (0.6870) acc@1 0.7188 (0.7446) acc@5 0.8125 (0.9036)\n",
      "\u001b[32m[2020-07-19 20:55:35] __main__ INFO: \u001b[0mEpoch 151 Step 500/703 lr 0.010000 loss 0.7282 (0.6766) acc@1 0.7188 (0.7488) acc@5 0.8438 (0.9033)\n",
      "\u001b[32m[2020-07-19 20:56:07] __main__ INFO: \u001b[0mEpoch 151 Step 600/703 lr 0.010000 loss 0.5294 (0.6725) acc@1 0.7656 (0.7500) acc@5 0.8750 (0.9036)\n",
      "\u001b[32m[2020-07-19 20:56:39] __main__ INFO: \u001b[0mEpoch 151 Step 700/703 lr 0.010000 loss 0.5503 (0.6660) acc@1 0.8125 (0.7522) acc@5 0.9375 (0.9042)\n",
      "\u001b[32m[2020-07-19 20:56:40] __main__ INFO: \u001b[0mEpoch 151 Step 703/703 lr 0.010000 loss 0.5939 (0.6657) acc@1 0.7656 (0.7523) acc@5 0.8906 (0.9042)\n",
      "\u001b[32m[2020-07-19 20:56:40] __main__ INFO: \u001b[0mElapsed 224.39\n",
      "\u001b[32m[2020-07-19 20:56:40] __main__ INFO: \u001b[0mVal 151\n",
      "\u001b[32m[2020-07-19 20:56:48] __main__ INFO: \u001b[0mEpoch 151 loss 0.1917 acc@1 0.9372 acc@5 0.9990\n",
      "\u001b[32m[2020-07-19 20:56:48] __main__ INFO: \u001b[0mElapsed 7.75\n",
      "\u001b[32m[2020-07-19 20:56:48] __main__ INFO: \u001b[0mTrain 152 106153\n",
      "\u001b[32m[2020-07-19 20:57:20] __main__ INFO: \u001b[0mEpoch 152 Step 100/703 lr 0.010000 loss 0.5224 (0.6223) acc@1 0.8125 (0.7709) acc@5 0.9062 (0.9081)\n",
      "\u001b[32m[2020-07-19 20:57:52] __main__ INFO: \u001b[0mEpoch 152 Step 200/703 lr 0.010000 loss 0.4997 (0.6253) acc@1 0.8438 (0.7681) acc@5 0.9219 (0.9062)\n",
      "\u001b[32m[2020-07-19 20:58:24] __main__ INFO: \u001b[0mEpoch 152 Step 300/703 lr 0.010000 loss 0.7248 (0.6228) acc@1 0.7344 (0.7681) acc@5 0.9062 (0.9069)\n",
      "\u001b[32m[2020-07-19 20:58:56] __main__ INFO: \u001b[0mEpoch 152 Step 400/703 lr 0.010000 loss 0.5953 (0.6205) acc@1 0.7656 (0.7684) acc@5 0.8594 (0.9059)\n",
      "\u001b[32m[2020-07-19 20:59:28] __main__ INFO: \u001b[0mEpoch 152 Step 500/703 lr 0.010000 loss 0.7175 (0.6146) acc@1 0.7188 (0.7707) acc@5 0.8438 (0.9062)\n",
      "\u001b[32m[2020-07-19 20:59:59] __main__ INFO: \u001b[0mEpoch 152 Step 600/703 lr 0.010000 loss 0.6807 (0.6160) acc@1 0.7812 (0.7699) acc@5 0.9219 (0.9060)\n",
      "\u001b[32m[2020-07-19 21:00:31] __main__ INFO: \u001b[0mEpoch 152 Step 700/703 lr 0.010000 loss 0.5255 (0.6114) acc@1 0.8281 (0.7715) acc@5 0.8594 (0.9060)\n",
      "\u001b[32m[2020-07-19 21:00:32] __main__ INFO: \u001b[0mEpoch 152 Step 703/703 lr 0.010000 loss 0.5998 (0.6115) acc@1 0.7812 (0.7715) acc@5 0.8438 (0.9058)\n",
      "\u001b[32m[2020-07-19 21:00:32] __main__ INFO: \u001b[0mElapsed 224.64\n",
      "\u001b[32m[2020-07-19 21:00:32] __main__ INFO: \u001b[0mVal 152\n",
      "\u001b[32m[2020-07-19 21:00:40] __main__ INFO: \u001b[0mEpoch 152 loss 0.1815 acc@1 0.9416 acc@5 0.9990\n",
      "\u001b[32m[2020-07-19 21:00:40] __main__ INFO: \u001b[0mElapsed 7.73\n",
      "\u001b[32m[2020-07-19 21:00:40] __main__ INFO: \u001b[0mTrain 153 106856\n",
      "\u001b[32m[2020-07-19 21:01:12] __main__ INFO: \u001b[0mEpoch 153 Step 100/703 lr 0.010000 loss 0.7057 (0.5964) acc@1 0.7500 (0.7741) acc@5 0.8750 (0.9036)\n",
      "\u001b[32m[2020-07-19 21:01:44] __main__ INFO: \u001b[0mEpoch 153 Step 200/703 lr 0.010000 loss 0.4913 (0.5956) acc@1 0.7812 (0.7769) acc@5 0.9062 (0.9045)\n",
      "\u001b[32m[2020-07-19 21:02:16] __main__ INFO: \u001b[0mEpoch 153 Step 300/703 lr 0.010000 loss 0.6356 (0.5937) acc@1 0.7188 (0.7779) acc@5 0.8594 (0.9061)\n",
      "\u001b[32m[2020-07-19 21:02:48] __main__ INFO: \u001b[0mEpoch 153 Step 400/703 lr 0.010000 loss 0.5143 (0.5927) acc@1 0.7969 (0.7773) acc@5 0.9062 (0.9058)\n",
      "\u001b[32m[2020-07-19 21:03:20] __main__ INFO: \u001b[0mEpoch 153 Step 500/703 lr 0.010000 loss 0.5306 (0.5899) acc@1 0.7812 (0.7785) acc@5 0.9219 (0.9059)\n",
      "\u001b[32m[2020-07-19 21:03:52] __main__ INFO: \u001b[0mEpoch 153 Step 600/703 lr 0.010000 loss 0.5442 (0.5890) acc@1 0.7812 (0.7787) acc@5 0.8906 (0.9059)\n",
      "\u001b[32m[2020-07-19 21:04:24] __main__ INFO: \u001b[0mEpoch 153 Step 700/703 lr 0.010000 loss 0.5724 (0.5891) acc@1 0.7656 (0.7781) acc@5 0.9062 (0.9051)\n",
      "\u001b[32m[2020-07-19 21:04:25] __main__ INFO: \u001b[0mEpoch 153 Step 703/703 lr 0.010000 loss 0.7566 (0.5893) acc@1 0.7188 (0.7781) acc@5 0.9219 (0.9052)\n",
      "\u001b[32m[2020-07-19 21:04:25] __main__ INFO: \u001b[0mElapsed 224.48\n",
      "\u001b[32m[2020-07-19 21:04:25] __main__ INFO: \u001b[0mVal 153\n",
      "\u001b[32m[2020-07-19 21:04:32] __main__ INFO: \u001b[0mEpoch 153 loss 0.1810 acc@1 0.9422 acc@5 0.9988\n",
      "\u001b[32m[2020-07-19 21:04:32] __main__ INFO: \u001b[0mElapsed 7.74\n",
      "\u001b[32m[2020-07-19 21:04:32] __main__ INFO: \u001b[0mTrain 154 107559\n",
      "\u001b[32m[2020-07-19 21:05:04] __main__ INFO: \u001b[0mEpoch 154 Step 100/703 lr 0.010000 loss 0.6622 (0.5780) acc@1 0.7188 (0.7833) acc@5 0.9531 (0.9073)\n",
      "\u001b[32m[2020-07-19 21:05:36] __main__ INFO: \u001b[0mEpoch 154 Step 200/703 lr 0.010000 loss 0.5696 (0.5765) acc@1 0.8125 (0.7830) acc@5 0.9219 (0.9070)\n",
      "\u001b[32m[2020-07-19 21:06:08] __main__ INFO: \u001b[0mEpoch 154 Step 300/703 lr 0.010000 loss 0.4947 (0.5755) acc@1 0.8125 (0.7832) acc@5 0.8906 (0.9078)\n",
      "\u001b[32m[2020-07-19 21:06:40] __main__ INFO: \u001b[0mEpoch 154 Step 400/703 lr 0.010000 loss 0.5526 (0.5750) acc@1 0.7969 (0.7837) acc@5 0.9062 (0.9067)\n",
      "\u001b[32m[2020-07-19 21:07:12] __main__ INFO: \u001b[0mEpoch 154 Step 500/703 lr 0.010000 loss 0.5539 (0.5741) acc@1 0.7969 (0.7834) acc@5 0.8906 (0.9069)\n",
      "\u001b[32m[2020-07-19 21:07:44] __main__ INFO: \u001b[0mEpoch 154 Step 600/703 lr 0.010000 loss 0.4992 (0.5755) acc@1 0.7969 (0.7825) acc@5 0.9062 (0.9064)\n",
      "\u001b[32m[2020-07-19 21:08:16] __main__ INFO: \u001b[0mEpoch 154 Step 700/703 lr 0.010000 loss 0.5714 (0.5752) acc@1 0.7500 (0.7829) acc@5 0.8594 (0.9062)\n",
      "\u001b[32m[2020-07-19 21:08:17] __main__ INFO: \u001b[0mEpoch 154 Step 703/703 lr 0.010000 loss 0.8505 (0.5753) acc@1 0.7031 (0.7829) acc@5 0.8594 (0.9062)\n",
      "\u001b[32m[2020-07-19 21:08:17] __main__ INFO: \u001b[0mElapsed 224.55\n",
      "\u001b[32m[2020-07-19 21:08:17] __main__ INFO: \u001b[0mVal 154\n",
      "\u001b[32m[2020-07-19 21:08:25] __main__ INFO: \u001b[0mEpoch 154 loss 0.1864 acc@1 0.9418 acc@5 0.9988\n",
      "\u001b[32m[2020-07-19 21:08:25] __main__ INFO: \u001b[0mElapsed 7.74\n",
      "\u001b[32m[2020-07-19 21:08:25] __main__ INFO: \u001b[0mTrain 155 108262\n",
      "\u001b[32m[2020-07-19 21:08:57] __main__ INFO: \u001b[0mEpoch 155 Step 100/703 lr 0.010000 loss 0.7448 (0.5722) acc@1 0.6875 (0.7861) acc@5 0.8906 (0.9089)\n",
      "\u001b[32m[2020-07-19 21:09:28] __main__ INFO: \u001b[0mEpoch 155 Step 200/703 lr 0.010000 loss 0.5700 (0.5741) acc@1 0.7500 (0.7853) acc@5 0.9062 (0.9055)\n",
      "\u001b[32m[2020-07-19 21:10:00] __main__ INFO: \u001b[0mEpoch 155 Step 300/703 lr 0.010000 loss 0.5369 (0.5728) acc@1 0.8281 (0.7850) acc@5 0.8750 (0.9055)\n",
      "\u001b[32m[2020-07-19 21:10:32] __main__ INFO: \u001b[0mEpoch 155 Step 400/703 lr 0.010000 loss 0.5318 (0.5642) acc@1 0.7969 (0.7870) acc@5 0.9062 (0.9057)\n",
      "\u001b[32m[2020-07-19 21:11:04] __main__ INFO: \u001b[0mEpoch 155 Step 500/703 lr 0.010000 loss 0.4947 (0.5628) acc@1 0.7812 (0.7879) acc@5 0.8750 (0.9059)\n",
      "\u001b[32m[2020-07-19 21:11:36] __main__ INFO: \u001b[0mEpoch 155 Step 600/703 lr 0.010000 loss 0.7861 (0.5611) acc@1 0.7188 (0.7887) acc@5 0.8906 (0.9069)\n",
      "\u001b[32m[2020-07-19 21:12:08] __main__ INFO: \u001b[0mEpoch 155 Step 700/703 lr 0.010000 loss 0.4461 (0.5614) acc@1 0.8281 (0.7882) acc@5 0.9062 (0.9072)\n",
      "\u001b[32m[2020-07-19 21:12:09] __main__ INFO: \u001b[0mEpoch 155 Step 703/703 lr 0.010000 loss 0.4671 (0.5613) acc@1 0.8281 (0.7882) acc@5 0.8906 (0.9072)\n",
      "\u001b[32m[2020-07-19 21:12:09] __main__ INFO: \u001b[0mElapsed 224.48\n",
      "\u001b[32m[2020-07-19 21:12:09] __main__ INFO: \u001b[0mVal 155\n",
      "\u001b[32m[2020-07-19 21:12:17] __main__ INFO: \u001b[0mEpoch 155 loss 0.1851 acc@1 0.9460 acc@5 0.9990\n",
      "\u001b[32m[2020-07-19 21:12:17] __main__ INFO: \u001b[0mElapsed 7.75\n",
      "\u001b[32m[2020-07-19 21:12:17] __main__ INFO: \u001b[0mTrain 156 108965\n",
      "\u001b[32m[2020-07-19 21:12:49] __main__ INFO: \u001b[0mEpoch 156 Step 100/703 lr 0.010000 loss 0.5356 (0.5472) acc@1 0.7969 (0.7920) acc@5 0.9219 (0.9069)\n",
      "\u001b[32m[2020-07-19 21:13:21] __main__ INFO: \u001b[0mEpoch 156 Step 200/703 lr 0.010000 loss 0.8376 (0.5378) acc@1 0.7031 (0.7963) acc@5 0.8750 (0.9084)\n",
      "\u001b[32m[2020-07-19 21:13:53] __main__ INFO: \u001b[0mEpoch 156 Step 300/703 lr 0.010000 loss 0.5784 (0.5474) acc@1 0.7500 (0.7922) acc@5 0.9062 (0.9077)\n",
      "\u001b[32m[2020-07-19 21:14:25] __main__ INFO: \u001b[0mEpoch 156 Step 400/703 lr 0.010000 loss 0.4977 (0.5434) acc@1 0.8125 (0.7935) acc@5 0.9375 (0.9077)\n",
      "\u001b[32m[2020-07-19 21:14:57] __main__ INFO: \u001b[0mEpoch 156 Step 500/703 lr 0.010000 loss 0.3878 (0.5493) acc@1 0.8906 (0.7914) acc@5 0.9375 (0.9068)\n",
      "\u001b[32m[2020-07-19 21:15:29] __main__ INFO: \u001b[0mEpoch 156 Step 600/703 lr 0.010000 loss 0.5205 (0.5476) acc@1 0.7969 (0.7919) acc@5 0.8438 (0.9066)\n",
      "\u001b[32m[2020-07-19 21:16:01] __main__ INFO: \u001b[0mEpoch 156 Step 700/703 lr 0.010000 loss 0.3739 (0.5499) acc@1 0.8594 (0.7909) acc@5 0.9375 (0.9063)\n",
      "\u001b[32m[2020-07-19 21:16:02] __main__ INFO: \u001b[0mEpoch 156 Step 703/703 lr 0.010000 loss 0.4504 (0.5497) acc@1 0.8281 (0.7910) acc@5 0.9062 (0.9064)\n",
      "\u001b[32m[2020-07-19 21:16:02] __main__ INFO: \u001b[0mElapsed 224.86\n",
      "\u001b[32m[2020-07-19 21:16:02] __main__ INFO: \u001b[0mVal 156\n",
      "\u001b[32m[2020-07-19 21:16:09] __main__ INFO: \u001b[0mEpoch 156 loss 0.1900 acc@1 0.9420 acc@5 0.9990\n",
      "\u001b[32m[2020-07-19 21:16:09] __main__ INFO: \u001b[0mElapsed 7.75\n",
      "\u001b[32m[2020-07-19 21:16:09] __main__ INFO: \u001b[0mTrain 157 109668\n",
      "\u001b[32m[2020-07-19 21:16:42] __main__ INFO: \u001b[0mEpoch 157 Step 100/703 lr 0.010000 loss 0.4406 (0.5382) acc@1 0.8594 (0.7980) acc@5 0.9688 (0.9061)\n",
      "\u001b[32m[2020-07-19 21:17:13] __main__ INFO: \u001b[0mEpoch 157 Step 200/703 lr 0.010000 loss 0.4495 (0.5400) acc@1 0.8125 (0.7962) acc@5 0.9531 (0.9074)\n",
      "\u001b[32m[2020-07-19 21:17:45] __main__ INFO: \u001b[0mEpoch 157 Step 300/703 lr 0.010000 loss 0.5773 (0.5423) acc@1 0.7656 (0.7954) acc@5 0.9219 (0.9065)\n",
      "\u001b[32m[2020-07-19 21:18:17] __main__ INFO: \u001b[0mEpoch 157 Step 400/703 lr 0.010000 loss 0.5587 (0.5435) acc@1 0.7812 (0.7952) acc@5 0.9062 (0.9071)\n",
      "\u001b[32m[2020-07-19 21:18:49] __main__ INFO: \u001b[0mEpoch 157 Step 500/703 lr 0.010000 loss 0.4759 (0.5427) acc@1 0.8438 (0.7953) acc@5 0.8906 (0.9074)\n",
      "\u001b[32m[2020-07-19 21:19:21] __main__ INFO: \u001b[0mEpoch 157 Step 600/703 lr 0.010000 loss 0.7512 (0.5450) acc@1 0.7188 (0.7935) acc@5 0.8906 (0.9066)\n",
      "\u001b[32m[2020-07-19 21:19:53] __main__ INFO: \u001b[0mEpoch 157 Step 700/703 lr 0.010000 loss 0.6348 (0.5439) acc@1 0.7344 (0.7940) acc@5 0.8594 (0.9062)\n",
      "\u001b[32m[2020-07-19 21:19:54] __main__ INFO: \u001b[0mEpoch 157 Step 703/703 lr 0.010000 loss 0.7033 (0.5440) acc@1 0.7188 (0.7940) acc@5 0.8594 (0.9062)\n",
      "\u001b[32m[2020-07-19 21:19:54] __main__ INFO: \u001b[0mElapsed 224.94\n",
      "\u001b[32m[2020-07-19 21:19:54] __main__ INFO: \u001b[0mVal 157\n",
      "\u001b[32m[2020-07-19 21:20:02] __main__ INFO: \u001b[0mEpoch 157 loss 0.1898 acc@1 0.9430 acc@5 0.9986\n",
      "\u001b[32m[2020-07-19 21:20:02] __main__ INFO: \u001b[0mElapsed 7.75\n",
      "\u001b[32m[2020-07-19 21:20:02] __main__ INFO: \u001b[0mTrain 158 110371\n",
      "\u001b[32m[2020-07-19 21:20:34] __main__ INFO: \u001b[0mEpoch 158 Step 100/703 lr 0.010000 loss 0.4723 (0.5405) acc@1 0.7969 (0.7945) acc@5 0.9531 (0.9041)\n",
      "\u001b[32m[2020-07-19 21:21:06] __main__ INFO: \u001b[0mEpoch 158 Step 200/703 lr 0.010000 loss 0.6705 (0.5396) acc@1 0.7656 (0.7955) acc@5 0.9375 (0.9046)\n",
      "\u001b[32m[2020-07-19 21:21:38] __main__ INFO: \u001b[0mEpoch 158 Step 300/703 lr 0.010000 loss 0.6987 (0.5367) acc@1 0.7188 (0.7951) acc@5 0.8594 (0.9060)\n",
      "\u001b[32m[2020-07-19 21:22:10] __main__ INFO: \u001b[0mEpoch 158 Step 400/703 lr 0.010000 loss 0.4772 (0.5382) acc@1 0.8125 (0.7943) acc@5 0.9219 (0.9061)\n",
      "\u001b[32m[2020-07-19 21:22:42] __main__ INFO: \u001b[0mEpoch 158 Step 500/703 lr 0.010000 loss 0.7386 (0.5341) acc@1 0.6875 (0.7967) acc@5 0.8438 (0.9082)\n",
      "\u001b[32m[2020-07-19 21:23:14] __main__ INFO: \u001b[0mEpoch 158 Step 600/703 lr 0.010000 loss 0.8856 (0.5350) acc@1 0.6250 (0.7958) acc@5 0.8594 (0.9086)\n",
      "\u001b[32m[2020-07-19 21:23:46] __main__ INFO: \u001b[0mEpoch 158 Step 700/703 lr 0.010000 loss 0.5550 (0.5372) acc@1 0.8125 (0.7948) acc@5 0.9219 (0.9079)\n",
      "\u001b[32m[2020-07-19 21:23:47] __main__ INFO: \u001b[0mEpoch 158 Step 703/703 lr 0.010000 loss 0.4872 (0.5371) acc@1 0.8438 (0.7950) acc@5 0.9531 (0.9080)\n",
      "\u001b[32m[2020-07-19 21:23:47] __main__ INFO: \u001b[0mElapsed 225.04\n",
      "\u001b[32m[2020-07-19 21:23:47] __main__ INFO: \u001b[0mVal 158\n",
      "\u001b[32m[2020-07-19 21:23:55] __main__ INFO: \u001b[0mEpoch 158 loss 0.1834 acc@1 0.9442 acc@5 0.9988\n",
      "\u001b[32m[2020-07-19 21:23:55] __main__ INFO: \u001b[0mElapsed 7.74\n",
      "\u001b[32m[2020-07-19 21:23:55] __main__ INFO: \u001b[0mTrain 159 111074\n",
      "\u001b[32m[2020-07-19 21:24:27] __main__ INFO: \u001b[0mEpoch 159 Step 100/703 lr 0.010000 loss 0.5167 (0.5155) acc@1 0.7969 (0.8055) acc@5 0.8594 (0.9095)\n",
      "\u001b[32m[2020-07-19 21:24:59] __main__ INFO: \u001b[0mEpoch 159 Step 200/703 lr 0.010000 loss 0.4701 (0.5206) acc@1 0.8594 (0.8038) acc@5 0.9375 (0.9084)\n",
      "\u001b[32m[2020-07-19 21:25:31] __main__ INFO: \u001b[0mEpoch 159 Step 300/703 lr 0.010000 loss 0.7440 (0.5190) acc@1 0.7500 (0.8037) acc@5 0.8906 (0.9072)\n",
      "\u001b[32m[2020-07-19 21:26:03] __main__ INFO: \u001b[0mEpoch 159 Step 400/703 lr 0.010000 loss 0.5967 (0.5220) acc@1 0.7656 (0.8033) acc@5 0.9219 (0.9069)\n",
      "\u001b[32m[2020-07-19 21:26:35] __main__ INFO: \u001b[0mEpoch 159 Step 500/703 lr 0.010000 loss 0.6014 (0.5279) acc@1 0.7656 (0.8005) acc@5 0.8906 (0.9061)\n"
     ]
    }
   ],
   "source": [
    "# Train the model per the settings specified in the original paper\n",
    "os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "!python train.py --config configs/cifar/densenet.yaml \\\n",
    "    model.densenet.depth 100 \\\n",
    "    model.densenet.growth_rate 12 \\\n",
    "    train.batch_size 64 \\\n",
    "    train.base_lr 0.1 \\\n",
    "    dataset.name CIFAR10_RA_1_20 \\\n",
    "    train.output_dir /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_1_20_c10val/exp00 \\\n",
    "    scheduler.epochs 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refine the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-20 14:35:54] __main__ INFO: \u001b[0mdevice: cuda\n",
      "cudnn:\n",
      "  benchmark: True\n",
      "  deterministic: False\n",
      "dataset:\n",
      "  name: CIFAR10\n",
      "  dataset_dir: ~/.torch/datasets/CIFAR10\n",
      "  image_size: 32\n",
      "  n_channels: 3\n",
      "  n_classes: 10\n",
      "model:\n",
      "  type: cifar\n",
      "  name: densenet\n",
      "  init_mode: kaiming_fan_out\n",
      "  vgg:\n",
      "    n_channels: [64, 128, 256, 512, 512]\n",
      "    n_layers: [2, 2, 3, 3, 3]\n",
      "    use_bn: True\n",
      "  resnet:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "  resnet_preact:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "  wrn:\n",
      "    depth: 28\n",
      "    initial_channels: 16\n",
      "    widening_factor: 10\n",
      "    drop_rate: 0.0\n",
      "  densenet:\n",
      "    depth: 100\n",
      "    n_blocks: [6, 12, 24, 16]\n",
      "    block_type: bottleneck\n",
      "    growth_rate: 12\n",
      "    drop_rate: 0.0\n",
      "    compression_rate: 0.5\n",
      "  pyramidnet:\n",
      "    depth: 272\n",
      "    n_blocks: [3, 24, 36, 3]\n",
      "    initial_channels: 16\n",
      "    block_type: bottleneck\n",
      "    alpha: 200\n",
      "  resnext:\n",
      "    depth: 29\n",
      "    n_blocks: [3, 4, 6, 3]\n",
      "    initial_channels: 64\n",
      "    cardinality: 8\n",
      "    base_channels: 4\n",
      "  shake_shake:\n",
      "    depth: 26\n",
      "    initial_channels: 96\n",
      "    shake_forward: True\n",
      "    shake_backward: True\n",
      "    shake_image: True\n",
      "  se_resnet_preact:\n",
      "    depth: 110\n",
      "    initial_channels: 16\n",
      "    se_reduction: 16\n",
      "    block_type: basic\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "train:\n",
      "  checkpoint: /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_1_20_c10val/exp00/checkpoint_00400.pth\n",
      "  resume: False\n",
      "  precision: O0\n",
      "  batch_size: 64\n",
      "  subdivision: 1\n",
      "  optimizer: sgd\n",
      "  base_lr: 0.001\n",
      "  momentum: 0.9\n",
      "  nesterov: True\n",
      "  weight_decay: 0.0001\n",
      "  no_weight_decay_on_bn: False\n",
      "  gradient_clip: 0\n",
      "  start_epoch: 0\n",
      "  seed: 0\n",
      "  val_first: True\n",
      "  val_period: 1\n",
      "  val_ratio: 0.1\n",
      "  use_test_as_val: False\n",
      "  output_dir: /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_1_20_c10val/exp00_resume400_50\n",
      "  log_period: 100\n",
      "  checkpoint_period: 100\n",
      "  use_tensorboard: True\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: True\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "  distributed: False\n",
      "  dist:\n",
      "    backend: nccl\n",
      "    init_method: env://\n",
      "    world_size: -1\n",
      "    node_rank: -1\n",
      "    local_rank: 0\n",
      "    use_sync_bn: False\n",
      "tensorboard:\n",
      "  train_images: False\n",
      "  val_images: False\n",
      "  model_params: False\n",
      "optim:\n",
      "  adam:\n",
      "    betas: (0.9, 0.999)\n",
      "  lars:\n",
      "    eps: 1e-09\n",
      "    threshold: 0.01\n",
      "  adabound:\n",
      "    betas: (0.9, 0.999)\n",
      "    final_lr: 0.1\n",
      "    gamma: 0.001\n",
      "scheduler:\n",
      "  epochs: 50\n",
      "  warmup:\n",
      "    type: none\n",
      "    epochs: 0\n",
      "    start_factor: 0.001\n",
      "    exponent: 4\n",
      "  type: multistep\n",
      "  milestones: [150, 225]\n",
      "  lr_decay: 0.1\n",
      "  lr_min_factor: 0.001\n",
      "  T0: 10\n",
      "  T_mul: 1.0\n",
      "validation:\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: False\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "augmentation:\n",
      "  use_random_crop: True\n",
      "  use_random_horizontal_flip: True\n",
      "  use_cutout: False\n",
      "  use_random_erasing: False\n",
      "  use_dual_cutout: False\n",
      "  use_mixup: False\n",
      "  use_ricap: False\n",
      "  use_cutmix: False\n",
      "  use_label_smoothing: False\n",
      "  random_crop:\n",
      "    padding: 4\n",
      "    fill: 0\n",
      "    padding_mode: constant\n",
      "  random_horizontal_flip:\n",
      "    prob: 0.5\n",
      "  cutout:\n",
      "    prob: 1.0\n",
      "    mask_size: 16\n",
      "    cut_inside: False\n",
      "    mask_color: 0\n",
      "    dual_cutout_alpha: 0.1\n",
      "  random_erasing:\n",
      "    prob: 0.5\n",
      "    area_ratio_range: [0.02, 0.4]\n",
      "    min_aspect_ratio: 0.3\n",
      "    max_attempt: 20\n",
      "  mixup:\n",
      "    alpha: 1.0\n",
      "  ricap:\n",
      "    beta: 0.3\n",
      "  cutmix:\n",
      "    alpha: 1.0\n",
      "  label_smoothing:\n",
      "    epsilon: 0.1\n",
      "tta:\n",
      "  use_resize: False\n",
      "  use_center_crop: False\n",
      "  resize: 256\n",
      "test:\n",
      "  checkpoint: ''\n",
      "  output_dir: ''\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    pin_memory: False\n",
      "\u001b[32m[2020-07-20 14:35:54] __main__ INFO: \u001b[0menv_info:\n",
      "  pytorch_version: 1.4.0\n",
      "  cuda_version: 10.1\n",
      "  cudnn_version: 7603\n",
      "  num_gpus: 1\n",
      "  gpu_name: Tesla K80\n",
      "  gpu_capability: 3.7\n",
      "Files already downloaded and verified\n",
      "\u001b[32m[2020-07-20 14:35:57] __main__ INFO: \u001b[0mMACs  : 296.49M\n",
      "\u001b[32m[2020-07-20 14:35:57] __main__ INFO: \u001b[0m#params: 769.16K\n",
      "Selected optimization level O0:  Pure FP32 training.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n",
      "\u001b[32m[2020-07-20 14:35:57] __main__ INFO: \u001b[0mVal 0\n",
      "\u001b[32m[2020-07-20 14:36:09] __main__ INFO: \u001b[0mEpoch 0 loss 0.5727 acc@1 0.8818 acc@5 0.9932\n",
      "\u001b[32m[2020-07-20 14:36:09] __main__ INFO: \u001b[0mElapsed 11.41\n",
      "\u001b[32m[2020-07-20 14:36:09] __main__ INFO: \u001b[0mTrain 1 0\n",
      "\u001b[32m[2020-07-20 14:36:42] __main__ INFO: \u001b[0mEpoch 1 Step 100/703 lr 0.001000 loss 0.0885 (0.2089) acc@1 0.9844 (0.9427) acc@5 1.0000 (0.9977)\n",
      "\u001b[32m[2020-07-20 14:37:14] __main__ INFO: \u001b[0mEpoch 1 Step 200/703 lr 0.001000 loss 0.2387 (0.1907) acc@1 0.9375 (0.9457) acc@5 1.0000 (0.9983)\n",
      "\u001b[32m[2020-07-20 14:37:46] __main__ INFO: \u001b[0mEpoch 1 Step 300/703 lr 0.001000 loss 0.3811 (0.1852) acc@1 0.9219 (0.9471) acc@5 0.9844 (0.9984)\n",
      "\u001b[32m[2020-07-20 14:38:18] __main__ INFO: \u001b[0mEpoch 1 Step 400/703 lr 0.001000 loss 0.0640 (0.1784) acc@1 0.9844 (0.9489) acc@5 1.0000 (0.9985)\n",
      "\u001b[32m[2020-07-20 14:38:50] __main__ INFO: \u001b[0mEpoch 1 Step 500/703 lr 0.001000 loss 0.0507 (0.1736) acc@1 0.9844 (0.9497) acc@5 1.0000 (0.9986)\n",
      "\u001b[32m[2020-07-20 14:39:22] __main__ INFO: \u001b[0mEpoch 1 Step 600/703 lr 0.001000 loss 0.2886 (0.1695) acc@1 0.9531 (0.9504) acc@5 1.0000 (0.9987)\n",
      "\u001b[32m[2020-07-20 14:39:53] __main__ INFO: \u001b[0mEpoch 1 Step 700/703 lr 0.001000 loss 0.1208 (0.1645) acc@1 0.9688 (0.9513) acc@5 1.0000 (0.9987)\n",
      "\u001b[32m[2020-07-20 14:39:54] __main__ INFO: \u001b[0mEpoch 1 Step 703/703 lr 0.001000 loss 0.3317 (0.1645) acc@1 0.9062 (0.9513) acc@5 1.0000 (0.9987)\n",
      "\u001b[32m[2020-07-20 14:39:54] __main__ INFO: \u001b[0mElapsed 225.62\n",
      "\u001b[32m[2020-07-20 14:39:54] __main__ INFO: \u001b[0mVal 1\n",
      "\u001b[32m[2020-07-20 14:40:02] __main__ INFO: \u001b[0mEpoch 1 loss 0.2944 acc@1 0.9200 acc@5 0.9976\n",
      "\u001b[32m[2020-07-20 14:40:02] __main__ INFO: \u001b[0mElapsed 7.73\n",
      "\u001b[32m[2020-07-20 14:40:02] __main__ INFO: \u001b[0mTrain 2 703\n",
      "\u001b[32m[2020-07-20 14:40:34] __main__ INFO: \u001b[0mEpoch 2 Step 100/703 lr 0.001000 loss 0.1100 (0.1229) acc@1 0.9844 (0.9622) acc@5 0.9844 (0.9988)\n",
      "\u001b[32m[2020-07-20 14:41:06] __main__ INFO: \u001b[0mEpoch 2 Step 200/703 lr 0.001000 loss 0.0913 (0.1190) acc@1 0.9688 (0.9624) acc@5 1.0000 (0.9990)\n",
      "\u001b[32m[2020-07-20 14:41:38] __main__ INFO: \u001b[0mEpoch 2 Step 300/703 lr 0.001000 loss 0.1123 (0.1205) acc@1 0.9531 (0.9617) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-07-20 14:42:10] __main__ INFO: \u001b[0mEpoch 2 Step 400/703 lr 0.001000 loss 0.1342 (0.1212) acc@1 0.9375 (0.9614) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-07-20 14:42:42] __main__ INFO: \u001b[0mEpoch 2 Step 500/703 lr 0.001000 loss 0.0679 (0.1230) acc@1 0.9844 (0.9609) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-07-20 14:43:14] __main__ INFO: \u001b[0mEpoch 2 Step 600/703 lr 0.001000 loss 0.1260 (0.1213) acc@1 0.9531 (0.9611) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-07-20 14:43:46] __main__ INFO: \u001b[0mEpoch 2 Step 700/703 lr 0.001000 loss 0.0714 (0.1203) acc@1 0.9688 (0.9615) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-07-20 14:43:47] __main__ INFO: \u001b[0mEpoch 2 Step 703/703 lr 0.001000 loss 0.1900 (0.1203) acc@1 0.9375 (0.9614) acc@5 1.0000 (0.9993)\n",
      "\u001b[32m[2020-07-20 14:43:47] __main__ INFO: \u001b[0mElapsed 224.80\n",
      "\u001b[32m[2020-07-20 14:43:47] __main__ INFO: \u001b[0mVal 2\n",
      "\u001b[32m[2020-07-20 14:43:55] __main__ INFO: \u001b[0mEpoch 2 loss 0.2748 acc@1 0.9236 acc@5 0.9978\n",
      "\u001b[32m[2020-07-20 14:43:55] __main__ INFO: \u001b[0mElapsed 7.71\n",
      "\u001b[32m[2020-07-20 14:43:55] __main__ INFO: \u001b[0mTrain 3 1406\n",
      "\u001b[32m[2020-07-20 14:44:27] __main__ INFO: \u001b[0mEpoch 3 Step 100/703 lr 0.001000 loss 0.0826 (0.0997) acc@1 0.9688 (0.9689) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-07-20 14:44:59] __main__ INFO: \u001b[0mEpoch 3 Step 200/703 lr 0.001000 loss 0.0228 (0.1038) acc@1 1.0000 (0.9666) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-20 14:45:31] __main__ INFO: \u001b[0mEpoch 3 Step 300/703 lr 0.001000 loss 0.1943 (0.1044) acc@1 0.9219 (0.9665) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-20 14:46:03] __main__ INFO: \u001b[0mEpoch 3 Step 400/703 lr 0.001000 loss 0.1640 (0.1014) acc@1 0.9531 (0.9670) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-20 14:46:35] __main__ INFO: \u001b[0mEpoch 3 Step 500/703 lr 0.001000 loss 0.0747 (0.0997) acc@1 0.9688 (0.9674) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-20 14:47:07] __main__ INFO: \u001b[0mEpoch 3 Step 600/703 lr 0.001000 loss 0.0482 (0.1020) acc@1 0.9844 (0.9669) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-20 14:47:39] __main__ INFO: \u001b[0mEpoch 3 Step 700/703 lr 0.001000 loss 0.1683 (0.1026) acc@1 0.8906 (0.9665) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-20 14:47:40] __main__ INFO: \u001b[0mEpoch 3 Step 703/703 lr 0.001000 loss 0.0543 (0.1025) acc@1 0.9688 (0.9665) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-20 14:47:40] __main__ INFO: \u001b[0mElapsed 224.95\n",
      "\u001b[32m[2020-07-20 14:47:40] __main__ INFO: \u001b[0mVal 3\n",
      "\u001b[32m[2020-07-20 14:47:47] __main__ INFO: \u001b[0mEpoch 3 loss 0.2673 acc@1 0.9218 acc@5 0.9984\n",
      "\u001b[32m[2020-07-20 14:47:47] __main__ INFO: \u001b[0mElapsed 7.71\n",
      "\u001b[32m[2020-07-20 14:47:47] __main__ INFO: \u001b[0mTrain 4 2109\n",
      "\u001b[32m[2020-07-20 14:48:19] __main__ INFO: \u001b[0mEpoch 4 Step 100/703 lr 0.001000 loss 0.1299 (0.0977) acc@1 0.9375 (0.9678) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-20 14:48:51] __main__ INFO: \u001b[0mEpoch 4 Step 200/703 lr 0.001000 loss 0.1764 (0.0935) acc@1 0.9375 (0.9684) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-20 14:49:23] __main__ INFO: \u001b[0mEpoch 4 Step 300/703 lr 0.001000 loss 0.0840 (0.0923) acc@1 0.9531 (0.9683) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-20 14:49:55] __main__ INFO: \u001b[0mEpoch 4 Step 400/703 lr 0.001000 loss 0.0929 (0.0929) acc@1 0.9688 (0.9688) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-20 14:50:27] __main__ INFO: \u001b[0mEpoch 4 Step 500/703 lr 0.001000 loss 0.1639 (0.0907) acc@1 0.9688 (0.9695) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-20 14:50:59] __main__ INFO: \u001b[0mEpoch 4 Step 600/703 lr 0.001000 loss 0.1429 (0.0918) acc@1 0.9375 (0.9693) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-20 14:51:31] __main__ INFO: \u001b[0mEpoch 4 Step 700/703 lr 0.001000 loss 0.1813 (0.0925) acc@1 0.9219 (0.9689) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-20 14:51:31] __main__ INFO: \u001b[0mEpoch 4 Step 703/703 lr 0.001000 loss 0.0483 (0.0925) acc@1 0.9688 (0.9689) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-20 14:51:32] __main__ INFO: \u001b[0mElapsed 224.11\n",
      "\u001b[32m[2020-07-20 14:51:32] __main__ INFO: \u001b[0mVal 4\n",
      "\u001b[32m[2020-07-20 14:51:39] __main__ INFO: \u001b[0mEpoch 4 loss 0.2615 acc@1 0.9242 acc@5 0.9984\n",
      "\u001b[32m[2020-07-20 14:51:39] __main__ INFO: \u001b[0mElapsed 7.74\n",
      "\u001b[32m[2020-07-20 14:51:39] __main__ INFO: \u001b[0mTrain 5 2812\n",
      "\u001b[32m[2020-07-20 14:52:11] __main__ INFO: \u001b[0mEpoch 5 Step 100/703 lr 0.001000 loss 0.0255 (0.0847) acc@1 0.9844 (0.9731) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-20 14:52:43] __main__ INFO: \u001b[0mEpoch 5 Step 200/703 lr 0.001000 loss 0.0306 (0.0841) acc@1 1.0000 (0.9730) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-20 14:53:15] __main__ INFO: \u001b[0mEpoch 5 Step 300/703 lr 0.001000 loss 0.0438 (0.0837) acc@1 1.0000 (0.9726) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-20 14:53:47] __main__ INFO: \u001b[0mEpoch 5 Step 400/703 lr 0.001000 loss 0.0675 (0.0844) acc@1 0.9688 (0.9723) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-20 14:54:19] __main__ INFO: \u001b[0mEpoch 5 Step 500/703 lr 0.001000 loss 0.2188 (0.0857) acc@1 0.9688 (0.9724) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-20 14:54:51] __main__ INFO: \u001b[0mEpoch 5 Step 600/703 lr 0.001000 loss 0.0809 (0.0852) acc@1 0.9844 (0.9720) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-20 14:55:23] __main__ INFO: \u001b[0mEpoch 5 Step 700/703 lr 0.001000 loss 0.0716 (0.0862) acc@1 0.9688 (0.9715) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-20 14:55:24] __main__ INFO: \u001b[0mEpoch 5 Step 703/703 lr 0.001000 loss 0.0914 (0.0862) acc@1 0.9531 (0.9715) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-20 14:55:24] __main__ INFO: \u001b[0mElapsed 224.33\n",
      "\u001b[32m[2020-07-20 14:55:24] __main__ INFO: \u001b[0mVal 5\n",
      "\u001b[32m[2020-07-20 14:55:31] __main__ INFO: \u001b[0mEpoch 5 loss 0.2570 acc@1 0.9264 acc@5 0.9986\n",
      "\u001b[32m[2020-07-20 14:55:31] __main__ INFO: \u001b[0mElapsed 7.73\n",
      "\u001b[32m[2020-07-20 14:55:31] __main__ INFO: \u001b[0mTrain 6 3515\n",
      "\u001b[32m[2020-07-20 14:56:03] __main__ INFO: \u001b[0mEpoch 6 Step 100/703 lr 0.001000 loss 0.0979 (0.0760) acc@1 0.9688 (0.9736) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-20 14:56:35] __main__ INFO: \u001b[0mEpoch 6 Step 200/703 lr 0.001000 loss 0.0366 (0.0719) acc@1 0.9844 (0.9745) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-20 14:57:07] __main__ INFO: \u001b[0mEpoch 6 Step 300/703 lr 0.001000 loss 0.0437 (0.0750) acc@1 0.9844 (0.9725) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-20 14:57:39] __main__ INFO: \u001b[0mEpoch 6 Step 400/703 lr 0.001000 loss 0.0952 (0.0753) acc@1 0.9844 (0.9725) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-20 14:58:11] __main__ INFO: \u001b[0mEpoch 6 Step 500/703 lr 0.001000 loss 0.1106 (0.0776) acc@1 0.9688 (0.9723) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-20 14:58:43] __main__ INFO: \u001b[0mEpoch 6 Step 600/703 lr 0.001000 loss 0.0176 (0.0785) acc@1 1.0000 (0.9724) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-20 14:59:15] __main__ INFO: \u001b[0mEpoch 6 Step 700/703 lr 0.001000 loss 0.0393 (0.0779) acc@1 0.9844 (0.9726) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-20 14:59:16] __main__ INFO: \u001b[0mEpoch 6 Step 703/703 lr 0.001000 loss 0.0169 (0.0781) acc@1 1.0000 (0.9725) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-20 14:59:16] __main__ INFO: \u001b[0mElapsed 224.60\n",
      "\u001b[32m[2020-07-20 14:59:16] __main__ INFO: \u001b[0mVal 6\n",
      "\u001b[32m[2020-07-20 14:59:24] __main__ INFO: \u001b[0mEpoch 6 loss 0.2560 acc@1 0.9246 acc@5 0.9984\n",
      "\u001b[32m[2020-07-20 14:59:24] __main__ INFO: \u001b[0mElapsed 7.74\n",
      "\u001b[32m[2020-07-20 14:59:24] __main__ INFO: \u001b[0mTrain 7 4218\n",
      "\u001b[32m[2020-07-20 14:59:56] __main__ INFO: \u001b[0mEpoch 7 Step 100/703 lr 0.001000 loss 0.1239 (0.0681) acc@1 0.9375 (0.9773) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-20 15:00:28] __main__ INFO: \u001b[0mEpoch 7 Step 200/703 lr 0.001000 loss 0.0657 (0.0670) acc@1 0.9844 (0.9776) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-20 15:01:00] __main__ INFO: \u001b[0mEpoch 7 Step 300/703 lr 0.001000 loss 0.0167 (0.0685) acc@1 1.0000 (0.9774) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-20 15:01:31] __main__ INFO: \u001b[0mEpoch 7 Step 400/703 lr 0.001000 loss 0.1202 (0.0691) acc@1 0.9531 (0.9770) acc@5 0.9844 (0.9999)\n",
      "\u001b[32m[2020-07-20 15:02:03] __main__ INFO: \u001b[0mEpoch 7 Step 500/703 lr 0.001000 loss 0.0761 (0.0703) acc@1 0.9844 (0.9764) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-20 15:02:35] __main__ INFO: \u001b[0mEpoch 7 Step 600/703 lr 0.001000 loss 0.0389 (0.0706) acc@1 0.9688 (0.9765) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-20 15:03:07] __main__ INFO: \u001b[0mEpoch 7 Step 700/703 lr 0.001000 loss 0.1204 (0.0722) acc@1 0.9531 (0.9760) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-20 15:03:08] __main__ INFO: \u001b[0mEpoch 7 Step 703/703 lr 0.001000 loss 0.0894 (0.0721) acc@1 0.9688 (0.9760) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-20 15:03:08] __main__ INFO: \u001b[0mElapsed 224.60\n",
      "\u001b[32m[2020-07-20 15:03:08] __main__ INFO: \u001b[0mVal 7\n",
      "\u001b[32m[2020-07-20 15:03:16] __main__ INFO: \u001b[0mEpoch 7 loss 0.2540 acc@1 0.9282 acc@5 0.9990\n",
      "\u001b[32m[2020-07-20 15:03:16] __main__ INFO: \u001b[0mElapsed 7.73\n",
      "\u001b[32m[2020-07-20 15:03:16] __main__ INFO: \u001b[0mTrain 8 4921\n",
      "\u001b[32m[2020-07-20 15:03:48] __main__ INFO: \u001b[0mEpoch 8 Step 100/703 lr 0.001000 loss 0.0699 (0.0731) acc@1 0.9844 (0.9766) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-20 15:04:20] __main__ INFO: \u001b[0mEpoch 8 Step 200/703 lr 0.001000 loss 0.0151 (0.0702) acc@1 1.0000 (0.9770) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-20 15:04:52] __main__ INFO: \u001b[0mEpoch 8 Step 300/703 lr 0.001000 loss 0.1117 (0.0679) acc@1 0.9531 (0.9773) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-20 15:05:24] __main__ INFO: \u001b[0mEpoch 8 Step 400/703 lr 0.001000 loss 0.1002 (0.0686) acc@1 0.9844 (0.9768) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-20 15:05:56] __main__ INFO: \u001b[0mEpoch 8 Step 500/703 lr 0.001000 loss 0.0592 (0.0677) acc@1 0.9844 (0.9773) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-20 15:06:28] __main__ INFO: \u001b[0mEpoch 8 Step 600/703 lr 0.001000 loss 0.0990 (0.0679) acc@1 0.9531 (0.9771) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-20 15:06:59] __main__ INFO: \u001b[0mEpoch 8 Step 700/703 lr 0.001000 loss 0.0355 (0.0674) acc@1 0.9844 (0.9771) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-20 15:07:00] __main__ INFO: \u001b[0mEpoch 8 Step 703/703 lr 0.001000 loss 0.1551 (0.0676) acc@1 0.9688 (0.9771) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-20 15:07:00] __main__ INFO: \u001b[0mElapsed 224.36\n",
      "\u001b[32m[2020-07-20 15:07:00] __main__ INFO: \u001b[0mVal 8\n",
      "\u001b[32m[2020-07-20 15:07:08] __main__ INFO: \u001b[0mEpoch 8 loss 0.2524 acc@1 0.9280 acc@5 0.9984\n",
      "\u001b[32m[2020-07-20 15:07:08] __main__ INFO: \u001b[0mElapsed 7.75\n",
      "\u001b[32m[2020-07-20 15:07:08] __main__ INFO: \u001b[0mTrain 9 5624\n",
      "\u001b[32m[2020-07-20 15:07:40] __main__ INFO: \u001b[0mEpoch 9 Step 100/703 lr 0.001000 loss 0.0927 (0.0594) acc@1 0.9688 (0.9794) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-20 15:08:12] __main__ INFO: \u001b[0mEpoch 9 Step 200/703 lr 0.001000 loss 0.0585 (0.0578) acc@1 0.9688 (0.9800) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-20 15:08:44] __main__ INFO: \u001b[0mEpoch 9 Step 300/703 lr 0.001000 loss 0.0101 (0.0619) acc@1 1.0000 (0.9786) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-20 15:09:16] __main__ INFO: \u001b[0mEpoch 9 Step 400/703 lr 0.001000 loss 0.0954 (0.0621) acc@1 0.9531 (0.9782) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-20 15:09:48] __main__ INFO: \u001b[0mEpoch 9 Step 500/703 lr 0.001000 loss 0.0076 (0.0620) acc@1 1.0000 (0.9785) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-20 15:10:20] __main__ INFO: \u001b[0mEpoch 9 Step 600/703 lr 0.001000 loss 0.0209 (0.0631) acc@1 0.9844 (0.9780) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-20 15:10:51] __main__ INFO: \u001b[0mEpoch 9 Step 700/703 lr 0.001000 loss 0.0662 (0.0631) acc@1 0.9844 (0.9779) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-20 15:10:52] __main__ INFO: \u001b[0mEpoch 9 Step 703/703 lr 0.001000 loss 0.0291 (0.0630) acc@1 1.0000 (0.9780) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-20 15:10:52] __main__ INFO: \u001b[0mElapsed 224.35\n",
      "\u001b[32m[2020-07-20 15:10:52] __main__ INFO: \u001b[0mVal 9\n",
      "\u001b[32m[2020-07-20 15:11:00] __main__ INFO: \u001b[0mEpoch 9 loss 0.2496 acc@1 0.9288 acc@5 0.9984\n",
      "\u001b[32m[2020-07-20 15:11:00] __main__ INFO: \u001b[0mElapsed 7.73\n",
      "\u001b[32m[2020-07-20 15:11:00] __main__ INFO: \u001b[0mTrain 10 6327\n",
      "\u001b[32m[2020-07-20 15:11:32] __main__ INFO: \u001b[0mEpoch 10 Step 100/703 lr 0.001000 loss 0.1123 (0.0555) acc@1 0.9688 (0.9798) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-20 15:12:04] __main__ INFO: \u001b[0mEpoch 10 Step 200/703 lr 0.001000 loss 0.0541 (0.0533) acc@1 0.9844 (0.9805) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-20 15:12:36] __main__ INFO: \u001b[0mEpoch 10 Step 300/703 lr 0.001000 loss 0.0779 (0.0545) acc@1 0.9844 (0.9807) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-20 15:13:08] __main__ INFO: \u001b[0mEpoch 10 Step 400/703 lr 0.001000 loss 0.0666 (0.0569) acc@1 0.9844 (0.9802) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-20 15:13:40] __main__ INFO: \u001b[0mEpoch 10 Step 500/703 lr 0.001000 loss 0.1859 (0.0571) acc@1 0.9531 (0.9803) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-20 15:14:12] __main__ INFO: \u001b[0mEpoch 10 Step 600/703 lr 0.001000 loss 0.1066 (0.0578) acc@1 0.9531 (0.9799) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-20 15:14:44] __main__ INFO: \u001b[0mEpoch 10 Step 700/703 lr 0.001000 loss 0.0899 (0.0578) acc@1 0.9531 (0.9803) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-20 15:14:45] __main__ INFO: \u001b[0mEpoch 10 Step 703/703 lr 0.001000 loss 0.1576 (0.0579) acc@1 0.9531 (0.9802) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-20 15:14:45] __main__ INFO: \u001b[0mElapsed 224.58\n",
      "\u001b[32m[2020-07-20 15:14:45] __main__ INFO: \u001b[0mVal 10\n",
      "\u001b[32m[2020-07-20 15:14:53] __main__ INFO: \u001b[0mEpoch 10 loss 0.2515 acc@1 0.9274 acc@5 0.9986\n",
      "\u001b[32m[2020-07-20 15:14:53] __main__ INFO: \u001b[0mElapsed 7.79\n",
      "\u001b[32m[2020-07-20 15:14:53] __main__ INFO: \u001b[0mTrain 11 7030\n",
      "\u001b[32m[2020-07-20 15:15:25] __main__ INFO: \u001b[0mEpoch 11 Step 100/703 lr 0.001000 loss 0.0606 (0.0589) acc@1 0.9688 (0.9798) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-20 15:15:56] __main__ INFO: \u001b[0mEpoch 11 Step 200/703 lr 0.001000 loss 0.0263 (0.0568) acc@1 1.0000 (0.9807) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-20 15:16:28] __main__ INFO: \u001b[0mEpoch 11 Step 300/703 lr 0.001000 loss 0.1007 (0.0573) acc@1 0.9688 (0.9799) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-20 15:17:00] __main__ INFO: \u001b[0mEpoch 11 Step 400/703 lr 0.001000 loss 0.0143 (0.0556) acc@1 1.0000 (0.9813) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-20 15:17:32] __main__ INFO: \u001b[0mEpoch 11 Step 500/703 lr 0.001000 loss 0.0461 (0.0557) acc@1 1.0000 (0.9810) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-20 15:18:04] __main__ INFO: \u001b[0mEpoch 11 Step 600/703 lr 0.001000 loss 0.0306 (0.0547) acc@1 1.0000 (0.9812) acc@5 1.0000 (0.9999)\n"
     ]
    }
   ],
   "source": [
    "# Resume training with the un-augmented data\n",
    "os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "!python train.py --config /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_1_20_c10val/exp00/config.yaml \\\n",
    "    train.checkpoint /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_1_20_c10val/exp00/checkpoint_00400.pth \\\n",
    "    dataset.name CIFAR10 \\\n",
    "    train.base_lr .001 \\\n",
    "    train.output_dir /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_1_20_c10val/exp00_resume400_50 \\\n",
    "    scheduler.epochs 50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-20 23:02:57] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_1_20_c10val/exp00_resume400_50/checkpoint_00050.pth\n",
      "Files already downloaded and verified\n",
      "100%|| 157/157 [00:19<00:00,  8.22it/s]\n",
      "\u001b[32m[2020-07-20 23:03:18] __main__ INFO: \u001b[0mElapsed 19.10\n",
      "\u001b[32m[2020-07-20 23:03:18] __main__ INFO: \u001b[0mLoss 0.2574 Accuracy 0.9345\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10 test dataset \n",
    "# Write the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/densenet.yaml \\\n",
    "   model.densenet.depth 100 \\\n",
    "   model.densenet.growth_rate 12 \\\n",
    "   test.batch_size 64 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_1_20_c10val/exp00_resume400_50/checkpoint_00050.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_1_20_c10val/exp00_resume400_50/test_results_0050_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-20 23:03:51] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_1_20_c10val/exp00/checkpoint_00400.pth\n",
      "Files already downloaded and verified\n",
      "100%|| 157/157 [00:18<00:00,  8.29it/s]\n",
      "\u001b[32m[2020-07-20 23:04:11] __main__ INFO: \u001b[0mElapsed 18.94\n",
      "\u001b[32m[2020-07-20 23:04:11] __main__ INFO: \u001b[0mLoss 0.5418 Accuracy 0.8866\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10 test dataset \n",
    "# Write the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/densenet.yaml \\\n",
    "   model.densenet.depth 100 \\\n",
    "   model.densenet.growth_rate 12 \\\n",
    "   test.batch_size 64 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_1_20_c10val/exp00/checkpoint_00400.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_1_20_c10val/exp00/test_results_0400_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-20 23:04:29] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_1_20_c10val/exp00_resume400_50/checkpoint_00050.pth\n",
      "CIFAR 10.1\n",
      "100%|| 32/32 [00:04<00:00,  7.69it/s]\n",
      "\u001b[32m[2020-07-20 23:04:34] __main__ INFO: \u001b[0mElapsed 4.16\n",
      "\u001b[32m[2020-07-20 23:04:34] __main__ INFO: \u001b[0mLoss 0.6161 Accuracy 0.8530\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10.1 test dataset \n",
    "# Write the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/densenet.yaml \\\n",
    "   model.densenet.depth 100 \\\n",
    "   model.densenet.growth_rate 12 \\\n",
    "   test.batch_size 64 \\\n",
    "   dataset.name CIFAR101 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_1_20_c10val/exp00_resume400_50/checkpoint_00050.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_1_20_c10val/exp00_resume400_50/test_results_0050_cifar101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-20 23:04:54] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_1_20_c10val/exp00/checkpoint_00400.pth\n",
      "CIFAR 10.1\n",
      "100%|| 32/32 [00:04<00:00,  7.96it/s]\n",
      "\u001b[32m[2020-07-20 23:04:59] __main__ INFO: \u001b[0mElapsed 4.02\n",
      "\u001b[32m[2020-07-20 23:04:59] __main__ INFO: \u001b[0mLoss 1.0834 Accuracy 0.7875\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10.1 test dataset \n",
    "# Write the results to the test output directory specified.\n",
    "os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "!python evaluate.py --config configs/cifar/densenet.yaml \\\n",
    "    model.densenet.depth 100 \\\n",
    "    model.densenet.growth_rate 12 \\\n",
    "    test.batch_size 64 \\\n",
    "    dataset.name CIFAR101 \\\n",
    "    test.checkpoint /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_1_20_c10val/exp00/checkpoint_00400.pth \\\n",
    "    test.output_dir /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_1_20_c10val/exp00/test_results_0400_cifar101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Record the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Testset</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Original_Accuracy</th>\n",
       "      <th>Original_CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>densenet_BC_100_12_ra_1_20_c10val</td>\n",
       "      <td>400</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>0.5418</td>\n",
       "      <td>0.8866</td>\n",
       "      <td>95.5</td>\n",
       "      <td>(95.1, 95.9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>densenet_BC_100_12_ra_1_20_c10val</td>\n",
       "      <td>400</td>\n",
       "      <td>cifar10.1</td>\n",
       "      <td>1.0834</td>\n",
       "      <td>0.7875</td>\n",
       "      <td>87.6</td>\n",
       "      <td>(86.1, 89.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>densenet_BC_100_12_ra_1_20_c10val_refined400</td>\n",
       "      <td>50</td>\n",
       "      <td>cifar10.1</td>\n",
       "      <td>0.6161</td>\n",
       "      <td>0.853</td>\n",
       "      <td>87.6</td>\n",
       "      <td>(86.1, 89.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>densenet_BC_100_12_ra_1_20_c10val_refined400</td>\n",
       "      <td>50</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>0.2574</td>\n",
       "      <td>0.9345</td>\n",
       "      <td>95.5</td>\n",
       "      <td>(95.1, 95.9)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Model Epoch    Testset    Loss  \\\n",
       "0             densenet_BC_100_12_ra_1_20_c10val   400    cifar10  0.5418   \n",
       "1             densenet_BC_100_12_ra_1_20_c10val   400  cifar10.1  1.0834   \n",
       "2  densenet_BC_100_12_ra_1_20_c10val_refined400    50  cifar10.1  0.6161   \n",
       "3  densenet_BC_100_12_ra_1_20_c10val_refined400    50    cifar10  0.2574   \n",
       "\n",
       "  Accuracy  Original_Accuracy   Original_CI  \n",
       "0   0.8866               95.5  (95.1, 95.9)  \n",
       "1   0.7875               87.6  (86.1, 89.0)  \n",
       "2    0.853               87.6  (86.1, 89.0)  \n",
       "3   0.9345               95.5  (95.1, 95.9)  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "model = 'densenet_BC_100_12_ra_1_20_c10val'\n",
    "model_refined = model + '_refined400'\n",
    "\n",
    "a = pd.Series([model, 400, 'cifar10', 0.5418, 0.8866])\n",
    "c = pd.Series([model, 400, 'cifar10.1', 1.0834, 0.7875])\n",
    "\n",
    "e = pd.Series([model_refined, 50, 'cifar10.1', 0.6161, 0.8530])\n",
    "f = pd.Series([model_refined, 50, 'cifar10', 0.2574, 0.9345])\n",
    "               \n",
    "df_results = pd.concat([a,c,e,f], axis=1).T\n",
    "df_results.columns = ['Model', 'Epoch', 'Testset', 'Loss', 'Accuracy']\n",
    "\n",
    "df_results['Original_Accuracy'] = df_results.apply((lambda row: 95.5 if row[2] == 'cifar10' else 87.6), axis=1)\n",
    "df_results['Original_CI'] = df_results.apply((lambda row: (95.1, 95.9) if row[2] == 'cifar10' else (86.1, 89.0)), axis=1)\n",
    "\n",
    "df_results.to_csv('/home/ec2-user/SageMaker/experiments/' + model + '/results.csv')\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the model checkpoints, configs, and results to S3 \n",
    "bucket='sagemaker-may29'\n",
    "prefix = 'sagemaker/results/original-models/densenet_BC_100_12_ra_1_20_c10val'\n",
    "path = '/home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_1_20_c10val'\n",
    "\n",
    "s3_resource = boto3.resource(\"s3\", region_name=\"us-east-2\")\n",
    "\n",
    "def uploadDirectory(local_path,bucket_name,s3_prefix):\n",
    "\n",
    "    my_bucket = s3_resource.Bucket(bucket_name)\n",
    "    \n",
    "    for path, subdirs, files in os.walk(local_path):\n",
    "        path = path.replace(\"\\\\\",\"/\")\n",
    "        directory_name = path.replace(local_path,\"\")\n",
    "        for file in files:\n",
    "            #print(\"Local File:\", os.path.join(path, file))\n",
    "            #print(\"      Dest:\", s3_prefix+directory_name+'/'+file)\n",
    "            my_bucket.upload_file(os.path.join(path, file), s3_prefix+directory_name+'/'+file)\n",
    "    \n",
    "uploadDirectory(path,bucket,prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
