{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DenseNet\n",
    "\n",
    " - Training Dataset:  RandAugment, N=1, M=20\n",
    "   Validation with Unaugmented Data\n",
    " - Sagemaker Notebook must be of type, conda_pytorch_p36\n",
    " \n",
    "#### Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy \n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 1)) (1.18.1)\n",
      "Requirement already satisfied: torch>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 2)) (1.4.0)\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 3)) (0.5.0)\n",
      "Requirement already satisfied: fvcore in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (0.1.1.post20200711)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 5)) (4.44.1)\n",
      "Requirement already satisfied: yacs in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 6)) (0.1.7)\n",
      "Requirement already satisfied: apex from git+https://github.com/NVIDIA/apex.git#egg=apex in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 7)) (0.1)\n",
      "Requirement already satisfied: termcolor in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 8)) (1.1.0)\n",
      "Requirement already satisfied: thop<0.0.31.post2004070130 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 9)) (0.0.31.post2001170342)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 3)) (1.14.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 3)) (7.0.0)\n",
      "Requirement already satisfied: portalocker in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from fvcore->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (1.7.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from fvcore->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (5.3.1)\n",
      "Requirement already satisfied: tabulate in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from fvcore->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (0.8.7)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: tensorboard in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (2.2.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.14.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.18.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.18.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.7.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.30.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (2.23.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.34.2)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (3.12.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.9.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.4.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (46.1.3.post20200330)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (3.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.1.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard) (3.4.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.4.5.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (1.25.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (1.5.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard) (2.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r '/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt'\n",
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-15 15:42:25] __main__ INFO: \u001b[0mdevice: cuda\n",
      "cudnn:\n",
      "  benchmark: True\n",
      "  deterministic: False\n",
      "dataset:\n",
      "  name: CIFAR10_RA_1_20\n",
      "  dataset_dir: ''\n",
      "  image_size: 32\n",
      "  n_channels: 3\n",
      "  n_classes: 10\n",
      "model:\n",
      "  type: cifar\n",
      "  name: densenet\n",
      "  init_mode: kaiming_fan_out\n",
      "  vgg:\n",
      "    n_channels: [64, 128, 256, 512, 512]\n",
      "    n_layers: [2, 2, 3, 3, 3]\n",
      "    use_bn: True\n",
      "  resnet:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "  resnet_preact:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "  wrn:\n",
      "    depth: 28\n",
      "    initial_channels: 16\n",
      "    widening_factor: 10\n",
      "    drop_rate: 0.0\n",
      "  densenet:\n",
      "    depth: 100\n",
      "    n_blocks: [6, 12, 24, 16]\n",
      "    block_type: bottleneck\n",
      "    growth_rate: 12\n",
      "    drop_rate: 0.0\n",
      "    compression_rate: 0.5\n",
      "  pyramidnet:\n",
      "    depth: 272\n",
      "    n_blocks: [3, 24, 36, 3]\n",
      "    initial_channels: 16\n",
      "    block_type: bottleneck\n",
      "    alpha: 200\n",
      "  resnext:\n",
      "    depth: 29\n",
      "    n_blocks: [3, 4, 6, 3]\n",
      "    initial_channels: 64\n",
      "    cardinality: 8\n",
      "    base_channels: 4\n",
      "  shake_shake:\n",
      "    depth: 26\n",
      "    initial_channels: 96\n",
      "    shake_forward: True\n",
      "    shake_backward: True\n",
      "    shake_image: True\n",
      "  se_resnet_preact:\n",
      "    depth: 110\n",
      "    initial_channels: 16\n",
      "    se_reduction: 16\n",
      "    block_type: basic\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "train:\n",
      "  checkpoint: ''\n",
      "  resume: False\n",
      "  precision: O0\n",
      "  batch_size: 64\n",
      "  subdivision: 1\n",
      "  optimizer: sgd\n",
      "  base_lr: 0.1\n",
      "  momentum: 0.9\n",
      "  nesterov: True\n",
      "  weight_decay: 0.0001\n",
      "  no_weight_decay_on_bn: False\n",
      "  gradient_clip: 0\n",
      "  start_epoch: 0\n",
      "  seed: 0\n",
      "  val_first: True\n",
      "  val_period: 1\n",
      "  val_ratio: 0.1\n",
      "  use_test_as_val: False\n",
      "  output_dir: /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_1_20_c10val/exp00\n",
      "  log_period: 100\n",
      "  checkpoint_period: 100\n",
      "  use_tensorboard: True\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: True\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "  distributed: False\n",
      "  dist:\n",
      "    backend: nccl\n",
      "    init_method: env://\n",
      "    world_size: -1\n",
      "    node_rank: -1\n",
      "    local_rank: 0\n",
      "    use_sync_bn: False\n",
      "tensorboard:\n",
      "  train_images: False\n",
      "  val_images: False\n",
      "  model_params: False\n",
      "optim:\n",
      "  adam:\n",
      "    betas: (0.9, 0.999)\n",
      "  lars:\n",
      "    eps: 1e-09\n",
      "    threshold: 0.01\n",
      "  adabound:\n",
      "    betas: (0.9, 0.999)\n",
      "    final_lr: 0.1\n",
      "    gamma: 0.001\n",
      "scheduler:\n",
      "  epochs: 400\n",
      "  warmup:\n",
      "    type: none\n",
      "    epochs: 0\n",
      "    start_factor: 0.001\n",
      "    exponent: 4\n",
      "  type: multistep\n",
      "  milestones: [150, 225]\n",
      "  lr_decay: 0.1\n",
      "  lr_min_factor: 0.001\n",
      "  T0: 10\n",
      "  T_mul: 1.0\n",
      "validation:\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: False\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "augmentation:\n",
      "  use_random_crop: True\n",
      "  use_random_horizontal_flip: True\n",
      "  use_cutout: False\n",
      "  use_random_erasing: False\n",
      "  use_dual_cutout: False\n",
      "  use_mixup: False\n",
      "  use_ricap: False\n",
      "  use_cutmix: False\n",
      "  use_label_smoothing: False\n",
      "  random_crop:\n",
      "    padding: 4\n",
      "    fill: 0\n",
      "    padding_mode: constant\n",
      "  random_horizontal_flip:\n",
      "    prob: 0.5\n",
      "  cutout:\n",
      "    prob: 1.0\n",
      "    mask_size: 16\n",
      "    cut_inside: False\n",
      "    mask_color: 0\n",
      "    dual_cutout_alpha: 0.1\n",
      "  random_erasing:\n",
      "    prob: 0.5\n",
      "    area_ratio_range: [0.02, 0.4]\n",
      "    min_aspect_ratio: 0.3\n",
      "    max_attempt: 20\n",
      "  mixup:\n",
      "    alpha: 1.0\n",
      "  ricap:\n",
      "    beta: 0.3\n",
      "  cutmix:\n",
      "    alpha: 1.0\n",
      "  label_smoothing:\n",
      "    epsilon: 0.1\n",
      "tta:\n",
      "  use_resize: False\n",
      "  use_center_crop: False\n",
      "  resize: 256\n",
      "test:\n",
      "  checkpoint: ''\n",
      "  output_dir: ''\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    pin_memory: False\n",
      "\u001b[32m[2020-07-15 15:42:25] __main__ INFO: \u001b[0menv_info:\n",
      "  pytorch_version: 1.4.0\n",
      "  cuda_version: 10.1\n",
      "  cudnn_version: 7603\n",
      "  num_gpus: 1\n",
      "  gpu_name: Tesla K80\n",
      "  gpu_capability: 3.7\n",
      "\u001b[32m[2020-07-15 15:42:30] __main__ INFO: \u001b[0mMACs  : 296.49M\n",
      "\u001b[32m[2020-07-15 15:42:30] __main__ INFO: \u001b[0m#params: 769.16K\n",
      "Selected optimization level O0:  Pure FP32 training.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n",
      "\u001b[32m[2020-07-15 15:42:30] __main__ INFO: \u001b[0mVal 0\n",
      "\u001b[32m[2020-07-15 15:42:42] __main__ INFO: \u001b[0mEpoch 0 loss 67454729.7920 acc@1 0.1008 acc@5 0.5028\n",
      "\u001b[32m[2020-07-15 15:42:42] __main__ INFO: \u001b[0mElapsed 11.37\n",
      "\u001b[32m[2020-07-15 15:42:42] __main__ INFO: \u001b[0mTrain 1 0\n",
      "\u001b[32m[2020-07-15 15:43:15] __main__ INFO: \u001b[0mEpoch 1 Step 100/703 lr 0.100000 loss 2.3359 (2.7415) acc@1 0.2344 (0.1278) acc@5 0.6250 (0.5436)\n",
      "\u001b[32m[2020-07-15 15:43:47] __main__ INFO: \u001b[0mEpoch 1 Step 200/703 lr 0.100000 loss 2.2482 (2.5485) acc@1 0.1406 (0.1319) acc@5 0.6875 (0.5670)\n",
      "\u001b[32m[2020-07-15 15:44:19] __main__ INFO: \u001b[0mEpoch 1 Step 300/703 lr 0.100000 loss 2.2503 (2.4614) acc@1 0.0469 (0.1381) acc@5 0.6406 (0.5835)\n",
      "\u001b[32m[2020-07-15 15:44:51] __main__ INFO: \u001b[0mEpoch 1 Step 400/703 lr 0.100000 loss 2.1427 (2.3988) acc@1 0.1719 (0.1476) acc@5 0.7344 (0.6008)\n",
      "\u001b[32m[2020-07-15 15:45:23] __main__ INFO: \u001b[0mEpoch 1 Step 500/703 lr 0.100000 loss 2.0728 (2.3539) acc@1 0.1719 (0.1553) acc@5 0.7031 (0.6147)\n",
      "\u001b[32m[2020-07-15 15:45:55] __main__ INFO: \u001b[0mEpoch 1 Step 600/703 lr 0.100000 loss 2.1635 (2.3183) acc@1 0.2812 (0.1631) acc@5 0.6875 (0.6271)\n",
      "\u001b[32m[2020-07-15 15:46:27] __main__ INFO: \u001b[0mEpoch 1 Step 700/703 lr 0.100000 loss 2.1873 (2.2870) acc@1 0.1406 (0.1700) acc@5 0.6562 (0.6404)\n",
      "\u001b[32m[2020-07-15 15:46:28] __main__ INFO: \u001b[0mEpoch 1 Step 703/703 lr 0.100000 loss 2.2207 (2.2866) acc@1 0.2188 (0.1702) acc@5 0.6406 (0.6404)\n",
      "\u001b[32m[2020-07-15 15:46:28] __main__ INFO: \u001b[0mElapsed 226.58\n",
      "\u001b[32m[2020-07-15 15:46:28] __main__ INFO: \u001b[0mVal 1\n",
      "\u001b[32m[2020-07-15 15:46:36] __main__ INFO: \u001b[0mEpoch 1 loss 2.1040 acc@1 0.2068 acc@5 0.7068\n",
      "\u001b[32m[2020-07-15 15:46:36] __main__ INFO: \u001b[0mElapsed 7.84\n",
      "\u001b[32m[2020-07-15 15:46:36] __main__ INFO: \u001b[0mTrain 2 703\n",
      "\u001b[32m[2020-07-15 15:47:08] __main__ INFO: \u001b[0mEpoch 2 Step 100/703 lr 0.100000 loss 1.9866 (2.0787) acc@1 0.2656 (0.2252) acc@5 0.7656 (0.7173)\n",
      "\u001b[32m[2020-07-15 15:47:40] __main__ INFO: \u001b[0mEpoch 2 Step 200/703 lr 0.100000 loss 2.0033 (2.0600) acc@1 0.2188 (0.2348) acc@5 0.7344 (0.7272)\n",
      "\u001b[32m[2020-07-15 15:48:12] __main__ INFO: \u001b[0mEpoch 2 Step 300/703 lr 0.100000 loss 1.9760 (2.0515) acc@1 0.2656 (0.2361) acc@5 0.8594 (0.7309)\n",
      "\u001b[32m[2020-07-15 15:48:44] __main__ INFO: \u001b[0mEpoch 2 Step 400/703 lr 0.100000 loss 2.1801 (2.0366) acc@1 0.1406 (0.2387) acc@5 0.7188 (0.7361)\n",
      "\u001b[32m[2020-07-15 15:49:17] __main__ INFO: \u001b[0mEpoch 2 Step 500/703 lr 0.100000 loss 2.1783 (2.0244) acc@1 0.2031 (0.2442) acc@5 0.6562 (0.7392)\n",
      "\u001b[32m[2020-07-15 15:49:49] __main__ INFO: \u001b[0mEpoch 2 Step 600/703 lr 0.100000 loss 1.8138 (2.0094) acc@1 0.3750 (0.2515) acc@5 0.8438 (0.7453)\n",
      "\u001b[32m[2020-07-15 15:50:21] __main__ INFO: \u001b[0mEpoch 2 Step 700/703 lr 0.100000 loss 1.9799 (1.9956) acc@1 0.2656 (0.2569) acc@5 0.7188 (0.7492)\n",
      "\u001b[32m[2020-07-15 15:50:22] __main__ INFO: \u001b[0mEpoch 2 Step 703/703 lr 0.100000 loss 1.9601 (1.9955) acc@1 0.2344 (0.2567) acc@5 0.7656 (0.7490)\n",
      "\u001b[32m[2020-07-15 15:50:22] __main__ INFO: \u001b[0mElapsed 225.98\n",
      "\u001b[32m[2020-07-15 15:50:22] __main__ INFO: \u001b[0mVal 2\n",
      "\u001b[32m[2020-07-15 15:50:30] __main__ INFO: \u001b[0mEpoch 2 loss 1.9395 acc@1 0.2818 acc@5 0.7780\n",
      "\u001b[32m[2020-07-15 15:50:30] __main__ INFO: \u001b[0mElapsed 7.73\n",
      "\u001b[32m[2020-07-15 15:50:30] __main__ INFO: \u001b[0mTrain 3 1406\n",
      "\u001b[32m[2020-07-15 15:51:02] __main__ INFO: \u001b[0mEpoch 3 Step 100/703 lr 0.100000 loss 1.9851 (1.8649) acc@1 0.3281 (0.3139) acc@5 0.7344 (0.7828)\n",
      "\u001b[32m[2020-07-15 15:51:34] __main__ INFO: \u001b[0mEpoch 3 Step 200/703 lr 0.100000 loss 1.7745 (1.8625) acc@1 0.3281 (0.3166) acc@5 0.8125 (0.7840)\n",
      "\u001b[32m[2020-07-15 15:52:06] __main__ INFO: \u001b[0mEpoch 3 Step 300/703 lr 0.100000 loss 2.2243 (1.8572) acc@1 0.2500 (0.3168) acc@5 0.6250 (0.7860)\n",
      "\u001b[32m[2020-07-15 15:52:38] __main__ INFO: \u001b[0mEpoch 3 Step 400/703 lr 0.100000 loss 1.7110 (1.8432) acc@1 0.4219 (0.3250) acc@5 0.8594 (0.7905)\n",
      "\u001b[32m[2020-07-15 15:53:10] __main__ INFO: \u001b[0mEpoch 3 Step 500/703 lr 0.100000 loss 1.8211 (1.8340) acc@1 0.3125 (0.3293) acc@5 0.7500 (0.7910)\n",
      "\u001b[32m[2020-07-15 15:53:43] __main__ INFO: \u001b[0mEpoch 3 Step 600/703 lr 0.100000 loss 1.6812 (1.8225) acc@1 0.3906 (0.3323) acc@5 0.8281 (0.7935)\n",
      "\u001b[32m[2020-07-15 15:54:15] __main__ INFO: \u001b[0mEpoch 3 Step 700/703 lr 0.100000 loss 1.8223 (1.8098) acc@1 0.3750 (0.3363) acc@5 0.7656 (0.7961)\n",
      "\u001b[32m[2020-07-15 15:54:16] __main__ INFO: \u001b[0mEpoch 3 Step 703/703 lr 0.100000 loss 1.7304 (1.8100) acc@1 0.4219 (0.3363) acc@5 0.8281 (0.7961)\n",
      "\u001b[32m[2020-07-15 15:54:16] __main__ INFO: \u001b[0mElapsed 226.16\n",
      "\u001b[32m[2020-07-15 15:54:16] __main__ INFO: \u001b[0mVal 3\n",
      "\u001b[32m[2020-07-15 15:54:24] __main__ INFO: \u001b[0mEpoch 3 loss 1.8391 acc@1 0.3530 acc@5 0.7810\n",
      "\u001b[32m[2020-07-15 15:54:24] __main__ INFO: \u001b[0mElapsed 7.81\n",
      "\u001b[32m[2020-07-15 15:54:24] __main__ INFO: \u001b[0mTrain 4 2109\n",
      "\u001b[32m[2020-07-15 15:54:56] __main__ INFO: \u001b[0mEpoch 4 Step 100/703 lr 0.100000 loss 1.7327 (1.7010) acc@1 0.3750 (0.3730) acc@5 0.8281 (0.8219)\n",
      "\u001b[32m[2020-07-15 15:55:28] __main__ INFO: \u001b[0mEpoch 4 Step 200/703 lr 0.100000 loss 1.7016 (1.6975) acc@1 0.2969 (0.3782) acc@5 0.8438 (0.8202)\n",
      "\u001b[32m[2020-07-15 15:56:00] __main__ INFO: \u001b[0mEpoch 4 Step 300/703 lr 0.100000 loss 1.4267 (1.6789) acc@1 0.4531 (0.3849) acc@5 0.8750 (0.8229)\n",
      "\u001b[32m[2020-07-15 15:56:33] __main__ INFO: \u001b[0mEpoch 4 Step 400/703 lr 0.100000 loss 1.7048 (1.6630) acc@1 0.4219 (0.3925) acc@5 0.8281 (0.8247)\n",
      "\u001b[32m[2020-07-15 15:57:05] __main__ INFO: \u001b[0mEpoch 4 Step 500/703 lr 0.100000 loss 1.8409 (1.6529) acc@1 0.2969 (0.3969) acc@5 0.7500 (0.8258)\n",
      "\u001b[32m[2020-07-15 15:57:37] __main__ INFO: \u001b[0mEpoch 4 Step 600/703 lr 0.100000 loss 1.8640 (1.6433) acc@1 0.3438 (0.3996) acc@5 0.7656 (0.8278)\n",
      "\u001b[32m[2020-07-15 15:58:09] __main__ INFO: \u001b[0mEpoch 4 Step 700/703 lr 0.100000 loss 1.7791 (1.6324) acc@1 0.3281 (0.4033) acc@5 0.8438 (0.8288)\n",
      "\u001b[32m[2020-07-15 15:58:10] __main__ INFO: \u001b[0mEpoch 4 Step 703/703 lr 0.100000 loss 1.2383 (1.6316) acc@1 0.5625 (0.4036) acc@5 0.8594 (0.8289)\n",
      "\u001b[32m[2020-07-15 15:58:10] __main__ INFO: \u001b[0mElapsed 226.50\n",
      "\u001b[32m[2020-07-15 15:58:10] __main__ INFO: \u001b[0mVal 4\n",
      "\u001b[32m[2020-07-15 15:58:18] __main__ INFO: \u001b[0mEpoch 4 loss 1.6921 acc@1 0.4076 acc@5 0.8142\n",
      "\u001b[32m[2020-07-15 15:58:18] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-15 15:58:18] __main__ INFO: \u001b[0mTrain 5 2812\n",
      "\u001b[32m[2020-07-15 15:58:50] __main__ INFO: \u001b[0mEpoch 5 Step 100/703 lr 0.100000 loss 1.3226 (1.5238) acc@1 0.4844 (0.4516) acc@5 0.8906 (0.8458)\n",
      "\u001b[32m[2020-07-15 15:59:22] __main__ INFO: \u001b[0mEpoch 5 Step 200/703 lr 0.100000 loss 1.4784 (1.5058) acc@1 0.3750 (0.4547) acc@5 0.8906 (0.8505)\n",
      "\u001b[32m[2020-07-15 15:59:54] __main__ INFO: \u001b[0mEpoch 5 Step 300/703 lr 0.100000 loss 1.6083 (1.5175) acc@1 0.4375 (0.4485) acc@5 0.8281 (0.8484)\n",
      "\u001b[32m[2020-07-15 16:00:27] __main__ INFO: \u001b[0mEpoch 5 Step 400/703 lr 0.100000 loss 1.5601 (1.5139) acc@1 0.4062 (0.4490) acc@5 0.8438 (0.8472)\n",
      "\u001b[32m[2020-07-15 16:00:59] __main__ INFO: \u001b[0mEpoch 5 Step 500/703 lr 0.100000 loss 1.6138 (1.5093) acc@1 0.4688 (0.4499) acc@5 0.8281 (0.8477)\n",
      "\u001b[32m[2020-07-15 16:01:31] __main__ INFO: \u001b[0mEpoch 5 Step 600/703 lr 0.100000 loss 1.5721 (1.5028) acc@1 0.4375 (0.4532) acc@5 0.8750 (0.8485)\n",
      "\u001b[32m[2020-07-15 16:02:03] __main__ INFO: \u001b[0mEpoch 5 Step 700/703 lr 0.100000 loss 1.4972 (1.4969) acc@1 0.4844 (0.4551) acc@5 0.8906 (0.8489)\n",
      "\u001b[32m[2020-07-15 16:02:04] __main__ INFO: \u001b[0mEpoch 5 Step 703/703 lr 0.100000 loss 1.3728 (1.4969) acc@1 0.5625 (0.4553) acc@5 0.9062 (0.8491)\n",
      "\u001b[32m[2020-07-15 16:02:04] __main__ INFO: \u001b[0mElapsed 226.03\n",
      "\u001b[32m[2020-07-15 16:02:04] __main__ INFO: \u001b[0mVal 5\n",
      "\u001b[32m[2020-07-15 16:02:12] __main__ INFO: \u001b[0mEpoch 5 loss 1.5782 acc@1 0.4472 acc@5 0.8428\n",
      "\u001b[32m[2020-07-15 16:02:12] __main__ INFO: \u001b[0mElapsed 7.83\n",
      "\u001b[32m[2020-07-15 16:02:12] __main__ INFO: \u001b[0mTrain 6 3515\n",
      "\u001b[32m[2020-07-15 16:02:44] __main__ INFO: \u001b[0mEpoch 6 Step 100/703 lr 0.100000 loss 1.3636 (1.4092) acc@1 0.5000 (0.4898) acc@5 0.9062 (0.8681)\n",
      "\u001b[32m[2020-07-15 16:03:16] __main__ INFO: \u001b[0mEpoch 6 Step 200/703 lr 0.100000 loss 1.3930 (1.4000) acc@1 0.5312 (0.4949) acc@5 0.8594 (0.8608)\n",
      "\u001b[32m[2020-07-15 16:03:48] __main__ INFO: \u001b[0mEpoch 6 Step 300/703 lr 0.100000 loss 1.6404 (1.4030) acc@1 0.3906 (0.4922) acc@5 0.8438 (0.8596)\n",
      "\u001b[32m[2020-07-15 16:04:21] __main__ INFO: \u001b[0mEpoch 6 Step 400/703 lr 0.100000 loss 1.3694 (1.4012) acc@1 0.5312 (0.4923) acc@5 0.8906 (0.8600)\n",
      "\u001b[32m[2020-07-15 16:04:53] __main__ INFO: \u001b[0mEpoch 6 Step 500/703 lr 0.100000 loss 1.3025 (1.4050) acc@1 0.5312 (0.4917) acc@5 0.8750 (0.8583)\n",
      "\u001b[32m[2020-07-15 16:05:25] __main__ INFO: \u001b[0mEpoch 6 Step 600/703 lr 0.100000 loss 1.4492 (1.4013) acc@1 0.4844 (0.4930) acc@5 0.8125 (0.8590)\n",
      "\u001b[32m[2020-07-15 16:05:57] __main__ INFO: \u001b[0mEpoch 6 Step 700/703 lr 0.100000 loss 1.4711 (1.3996) acc@1 0.4844 (0.4930) acc@5 0.7812 (0.8595)\n",
      "\u001b[32m[2020-07-15 16:05:58] __main__ INFO: \u001b[0mEpoch 6 Step 703/703 lr 0.100000 loss 1.3976 (1.3994) acc@1 0.4531 (0.4930) acc@5 0.8594 (0.8596)\n",
      "\u001b[32m[2020-07-15 16:05:58] __main__ INFO: \u001b[0mElapsed 226.11\n",
      "\u001b[32m[2020-07-15 16:05:58] __main__ INFO: \u001b[0mVal 6\n",
      "\u001b[32m[2020-07-15 16:06:06] __main__ INFO: \u001b[0mEpoch 6 loss 1.4945 acc@1 0.4770 acc@5 0.8472\n",
      "\u001b[32m[2020-07-15 16:06:06] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-15 16:06:06] __main__ INFO: \u001b[0mTrain 7 4218\n",
      "\u001b[32m[2020-07-15 16:06:38] __main__ INFO: \u001b[0mEpoch 7 Step 100/703 lr 0.100000 loss 1.0920 (1.3608) acc@1 0.6094 (0.5077) acc@5 0.8906 (0.8583)\n",
      "\u001b[32m[2020-07-15 16:07:10] __main__ INFO: \u001b[0mEpoch 7 Step 200/703 lr 0.100000 loss 1.5068 (1.3499) acc@1 0.4375 (0.5112) acc@5 0.7812 (0.8626)\n",
      "\u001b[32m[2020-07-15 16:07:42] __main__ INFO: \u001b[0mEpoch 7 Step 300/703 lr 0.100000 loss 1.2768 (1.3524) acc@1 0.5781 (0.5100) acc@5 0.9062 (0.8635)\n",
      "\u001b[32m[2020-07-15 16:08:14] __main__ INFO: \u001b[0mEpoch 7 Step 400/703 lr 0.100000 loss 1.3465 (1.3446) acc@1 0.5000 (0.5114) acc@5 0.8594 (0.8645)\n",
      "\u001b[32m[2020-07-15 16:08:46] __main__ INFO: \u001b[0mEpoch 7 Step 500/703 lr 0.100000 loss 1.1942 (1.3411) acc@1 0.5625 (0.5134) acc@5 0.8750 (0.8649)\n",
      "\u001b[32m[2020-07-15 16:09:19] __main__ INFO: \u001b[0mEpoch 7 Step 600/703 lr 0.100000 loss 0.9986 (1.3389) acc@1 0.6250 (0.5139) acc@5 0.9531 (0.8653)\n",
      "\u001b[32m[2020-07-15 16:09:51] __main__ INFO: \u001b[0mEpoch 7 Step 700/703 lr 0.100000 loss 1.4655 (1.3358) acc@1 0.4688 (0.5150) acc@5 0.8438 (0.8656)\n",
      "\u001b[32m[2020-07-15 16:09:52] __main__ INFO: \u001b[0mEpoch 7 Step 703/703 lr 0.100000 loss 0.9965 (1.3349) acc@1 0.6562 (0.5154) acc@5 0.9219 (0.8657)\n",
      "\u001b[32m[2020-07-15 16:09:52] __main__ INFO: \u001b[0mElapsed 225.94\n",
      "\u001b[32m[2020-07-15 16:09:52] __main__ INFO: \u001b[0mVal 7\n",
      "\u001b[32m[2020-07-15 16:09:59] __main__ INFO: \u001b[0mEpoch 7 loss 1.3331 acc@1 0.5170 acc@5 0.8630\n",
      "\u001b[32m[2020-07-15 16:09:59] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-15 16:09:59] __main__ INFO: \u001b[0mTrain 8 4921\n",
      "\u001b[32m[2020-07-15 16:10:32] __main__ INFO: \u001b[0mEpoch 8 Step 100/703 lr 0.100000 loss 1.0360 (1.2800) acc@1 0.6562 (0.5416) acc@5 0.9375 (0.8772)\n",
      "\u001b[32m[2020-07-15 16:11:04] __main__ INFO: \u001b[0mEpoch 8 Step 200/703 lr 0.100000 loss 0.8234 (1.2792) acc@1 0.7812 (0.5359) acc@5 0.9219 (0.8760)\n",
      "\u001b[32m[2020-07-15 16:11:36] __main__ INFO: \u001b[0mEpoch 8 Step 300/703 lr 0.100000 loss 1.0446 (1.2846) acc@1 0.6250 (0.5331) acc@5 0.8906 (0.8737)\n",
      "\u001b[32m[2020-07-15 16:12:08] __main__ INFO: \u001b[0mEpoch 8 Step 400/703 lr 0.100000 loss 0.9709 (1.2844) acc@1 0.6719 (0.5332) acc@5 0.9531 (0.8738)\n",
      "\u001b[32m[2020-07-15 16:12:40] __main__ INFO: \u001b[0mEpoch 8 Step 500/703 lr 0.100000 loss 1.3439 (1.2786) acc@1 0.4844 (0.5349) acc@5 0.8438 (0.8744)\n",
      "\u001b[32m[2020-07-15 16:13:12] __main__ INFO: \u001b[0mEpoch 8 Step 600/703 lr 0.100000 loss 1.3238 (1.2810) acc@1 0.4531 (0.5336) acc@5 0.8750 (0.8746)\n",
      "\u001b[32m[2020-07-15 16:13:44] __main__ INFO: \u001b[0mEpoch 8 Step 700/703 lr 0.100000 loss 1.1785 (1.2802) acc@1 0.5469 (0.5333) acc@5 0.8594 (0.8731)\n",
      "\u001b[32m[2020-07-15 16:13:45] __main__ INFO: \u001b[0mEpoch 8 Step 703/703 lr 0.100000 loss 1.3803 (1.2801) acc@1 0.4688 (0.5332) acc@5 0.8594 (0.8731)\n",
      "\u001b[32m[2020-07-15 16:13:45] __main__ INFO: \u001b[0mElapsed 226.03\n",
      "\u001b[32m[2020-07-15 16:13:45] __main__ INFO: \u001b[0mVal 8\n",
      "\u001b[32m[2020-07-15 16:13:53] __main__ INFO: \u001b[0mEpoch 8 loss 1.3029 acc@1 0.5222 acc@5 0.8690\n",
      "\u001b[32m[2020-07-15 16:13:53] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-15 16:13:53] __main__ INFO: \u001b[0mTrain 9 5624\n",
      "\u001b[32m[2020-07-15 16:14:25] __main__ INFO: \u001b[0mEpoch 9 Step 100/703 lr 0.100000 loss 1.2183 (1.2431) acc@1 0.5000 (0.5527) acc@5 0.8438 (0.8725)\n",
      "\u001b[32m[2020-07-15 16:14:57] __main__ INFO: \u001b[0mEpoch 9 Step 200/703 lr 0.100000 loss 1.3695 (1.2441) acc@1 0.4688 (0.5490) acc@5 0.8906 (0.8756)\n",
      "\u001b[32m[2020-07-15 16:15:30] __main__ INFO: \u001b[0mEpoch 9 Step 300/703 lr 0.100000 loss 1.0579 (1.2412) acc@1 0.6094 (0.5498) acc@5 0.9062 (0.8754)\n",
      "\u001b[32m[2020-07-15 16:16:02] __main__ INFO: \u001b[0mEpoch 9 Step 400/703 lr 0.100000 loss 1.4030 (1.2366) acc@1 0.5312 (0.5504) acc@5 0.8125 (0.8758)\n",
      "\u001b[32m[2020-07-15 16:16:34] __main__ INFO: \u001b[0mEpoch 9 Step 500/703 lr 0.100000 loss 1.2532 (1.2337) acc@1 0.5312 (0.5510) acc@5 0.7969 (0.8757)\n",
      "\u001b[32m[2020-07-15 16:17:06] __main__ INFO: \u001b[0mEpoch 9 Step 600/703 lr 0.100000 loss 0.9420 (1.2390) acc@1 0.6094 (0.5489) acc@5 0.9375 (0.8750)\n",
      "\u001b[32m[2020-07-15 16:17:38] __main__ INFO: \u001b[0mEpoch 9 Step 700/703 lr 0.100000 loss 1.2209 (1.2440) acc@1 0.5469 (0.5469) acc@5 0.8906 (0.8735)\n",
      "\u001b[32m[2020-07-15 16:17:39] __main__ INFO: \u001b[0mEpoch 9 Step 703/703 lr 0.100000 loss 1.2801 (1.2438) acc@1 0.5469 (0.5470) acc@5 0.9531 (0.8736)\n",
      "\u001b[32m[2020-07-15 16:17:39] __main__ INFO: \u001b[0mElapsed 225.82\n",
      "\u001b[32m[2020-07-15 16:17:39] __main__ INFO: \u001b[0mVal 9\n",
      "\u001b[32m[2020-07-15 16:17:47] __main__ INFO: \u001b[0mEpoch 9 loss 1.2960 acc@1 0.5358 acc@5 0.8712\n",
      "\u001b[32m[2020-07-15 16:17:47] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-15 16:17:47] __main__ INFO: \u001b[0mTrain 10 6327\n",
      "\u001b[32m[2020-07-15 16:18:19] __main__ INFO: \u001b[0mEpoch 10 Step 100/703 lr 0.100000 loss 1.1187 (1.2145) acc@1 0.6562 (0.5594) acc@5 0.9531 (0.8755)\n",
      "\u001b[32m[2020-07-15 16:18:51] __main__ INFO: \u001b[0mEpoch 10 Step 200/703 lr 0.100000 loss 1.4326 (1.2156) acc@1 0.4844 (0.5588) acc@5 0.9688 (0.8791)\n",
      "\u001b[32m[2020-07-15 16:19:23] __main__ INFO: \u001b[0mEpoch 10 Step 300/703 lr 0.100000 loss 1.3109 (1.2196) acc@1 0.5000 (0.5572) acc@5 0.8594 (0.8786)\n",
      "\u001b[32m[2020-07-15 16:19:55] __main__ INFO: \u001b[0mEpoch 10 Step 400/703 lr 0.100000 loss 1.4066 (1.2203) acc@1 0.5312 (0.5574) acc@5 0.8906 (0.8788)\n",
      "\u001b[32m[2020-07-15 16:20:28] __main__ INFO: \u001b[0mEpoch 10 Step 500/703 lr 0.100000 loss 1.2378 (1.2193) acc@1 0.5625 (0.5588) acc@5 0.9219 (0.8770)\n",
      "\u001b[32m[2020-07-15 16:21:00] __main__ INFO: \u001b[0mEpoch 10 Step 600/703 lr 0.100000 loss 1.3196 (1.2158) acc@1 0.4688 (0.5606) acc@5 0.8906 (0.8771)\n",
      "\u001b[32m[2020-07-15 16:21:32] __main__ INFO: \u001b[0mEpoch 10 Step 700/703 lr 0.100000 loss 1.1567 (1.2112) acc@1 0.5469 (0.5619) acc@5 0.8125 (0.8773)\n",
      "\u001b[32m[2020-07-15 16:21:33] __main__ INFO: \u001b[0mEpoch 10 Step 703/703 lr 0.100000 loss 1.1165 (1.2112) acc@1 0.5938 (0.5618) acc@5 0.8594 (0.8774)\n",
      "\u001b[32m[2020-07-15 16:21:33] __main__ INFO: \u001b[0mElapsed 226.14\n",
      "\u001b[32m[2020-07-15 16:21:33] __main__ INFO: \u001b[0mVal 10\n",
      "\u001b[32m[2020-07-15 16:21:41] __main__ INFO: \u001b[0mEpoch 10 loss 1.2614 acc@1 0.5524 acc@5 0.8710\n",
      "\u001b[32m[2020-07-15 16:21:41] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-15 16:21:41] __main__ INFO: \u001b[0mTrain 11 7030\n",
      "\u001b[32m[2020-07-15 16:22:13] __main__ INFO: \u001b[0mEpoch 11 Step 100/703 lr 0.100000 loss 1.2761 (1.1578) acc@1 0.5312 (0.5770) acc@5 0.8594 (0.8872)\n",
      "\u001b[32m[2020-07-15 16:22:45] __main__ INFO: \u001b[0mEpoch 11 Step 200/703 lr 0.100000 loss 1.3742 (1.1738) acc@1 0.4688 (0.5713) acc@5 0.8438 (0.8823)\n",
      "\u001b[32m[2020-07-15 16:23:17] __main__ INFO: \u001b[0mEpoch 11 Step 300/703 lr 0.100000 loss 1.1134 (1.1869) acc@1 0.5625 (0.5666) acc@5 0.9375 (0.8806)\n",
      "\u001b[32m[2020-07-15 16:23:49] __main__ INFO: \u001b[0mEpoch 11 Step 400/703 lr 0.100000 loss 1.1675 (1.1827) acc@1 0.6094 (0.5679) acc@5 0.9375 (0.8803)\n",
      "\u001b[32m[2020-07-15 16:24:22] __main__ INFO: \u001b[0mEpoch 11 Step 500/703 lr 0.100000 loss 1.3052 (1.1873) acc@1 0.5000 (0.5666) acc@5 0.9062 (0.8800)\n",
      "\u001b[32m[2020-07-15 16:24:54] __main__ INFO: \u001b[0mEpoch 11 Step 600/703 lr 0.100000 loss 1.3093 (1.1871) acc@1 0.5156 (0.5665) acc@5 0.8750 (0.8809)\n",
      "\u001b[32m[2020-07-15 16:25:26] __main__ INFO: \u001b[0mEpoch 11 Step 700/703 lr 0.100000 loss 1.0887 (1.1877) acc@1 0.6094 (0.5663) acc@5 0.8594 (0.8798)\n",
      "\u001b[32m[2020-07-15 16:25:27] __main__ INFO: \u001b[0mEpoch 11 Step 703/703 lr 0.100000 loss 1.0932 (1.1877) acc@1 0.6250 (0.5664) acc@5 0.9062 (0.8798)\n",
      "\u001b[32m[2020-07-15 16:25:27] __main__ INFO: \u001b[0mElapsed 225.92\n",
      "\u001b[32m[2020-07-15 16:25:27] __main__ INFO: \u001b[0mVal 11\n",
      "\u001b[32m[2020-07-15 16:25:34] __main__ INFO: \u001b[0mEpoch 11 loss 1.3752 acc@1 0.5222 acc@5 0.8676\n",
      "\u001b[32m[2020-07-15 16:25:34] __main__ INFO: \u001b[0mElapsed 7.75\n",
      "\u001b[32m[2020-07-15 16:25:34] __main__ INFO: \u001b[0mTrain 12 7733\n",
      "\u001b[32m[2020-07-15 16:26:06] __main__ INFO: \u001b[0mEpoch 12 Step 100/703 lr 0.100000 loss 1.2071 (1.1347) acc@1 0.4531 (0.5816) acc@5 0.8438 (0.8783)\n",
      "\u001b[32m[2020-07-15 16:26:39] __main__ INFO: \u001b[0mEpoch 12 Step 200/703 lr 0.100000 loss 1.1465 (1.1510) acc@1 0.5781 (0.5789) acc@5 0.8906 (0.8799)\n",
      "\u001b[32m[2020-07-15 16:27:11] __main__ INFO: \u001b[0mEpoch 12 Step 300/703 lr 0.100000 loss 1.4571 (1.1593) acc@1 0.4062 (0.5780) acc@5 0.7969 (0.8807)\n",
      "\u001b[32m[2020-07-15 16:27:43] __main__ INFO: \u001b[0mEpoch 12 Step 400/703 lr 0.100000 loss 1.2852 (1.1599) acc@1 0.5000 (0.5793) acc@5 0.8594 (0.8826)\n",
      "\u001b[32m[2020-07-15 16:28:15] __main__ INFO: \u001b[0mEpoch 12 Step 500/703 lr 0.100000 loss 1.1296 (1.1633) acc@1 0.6562 (0.5785) acc@5 0.8906 (0.8818)\n",
      "\u001b[32m[2020-07-15 16:28:47] __main__ INFO: \u001b[0mEpoch 12 Step 600/703 lr 0.100000 loss 0.9429 (1.1639) acc@1 0.6562 (0.5795) acc@5 0.8906 (0.8813)\n",
      "\u001b[32m[2020-07-15 16:29:19] __main__ INFO: \u001b[0mEpoch 12 Step 700/703 lr 0.100000 loss 1.1337 (1.1627) acc@1 0.5938 (0.5797) acc@5 0.8438 (0.8807)\n",
      "\u001b[32m[2020-07-15 16:29:20] __main__ INFO: \u001b[0mEpoch 12 Step 703/703 lr 0.100000 loss 1.2132 (1.1630) acc@1 0.5625 (0.5796) acc@5 0.8281 (0.8805)\n",
      "\u001b[32m[2020-07-15 16:29:20] __main__ INFO: \u001b[0mElapsed 225.40\n",
      "\u001b[32m[2020-07-15 16:29:20] __main__ INFO: \u001b[0mVal 12\n",
      "\u001b[32m[2020-07-15 16:29:28] __main__ INFO: \u001b[0mEpoch 12 loss 1.2640 acc@1 0.5442 acc@5 0.8730\n",
      "\u001b[32m[2020-07-15 16:29:28] __main__ INFO: \u001b[0mElapsed 7.74\n",
      "\u001b[32m[2020-07-15 16:29:28] __main__ INFO: \u001b[0mTrain 13 8436\n",
      "\u001b[32m[2020-07-15 16:30:00] __main__ INFO: \u001b[0mEpoch 13 Step 100/703 lr 0.100000 loss 1.1480 (1.1338) acc@1 0.5781 (0.5867) acc@5 0.9062 (0.8838)\n",
      "\u001b[32m[2020-07-15 16:30:32] __main__ INFO: \u001b[0mEpoch 13 Step 200/703 lr 0.100000 loss 1.2326 (1.1401) acc@1 0.5469 (0.5820) acc@5 0.9219 (0.8838)\n",
      "\u001b[32m[2020-07-15 16:31:04] __main__ INFO: \u001b[0mEpoch 13 Step 300/703 lr 0.100000 loss 0.9672 (1.1480) acc@1 0.7031 (0.5786) acc@5 0.9062 (0.8816)\n",
      "\u001b[32m[2020-07-15 16:31:36] __main__ INFO: \u001b[0mEpoch 13 Step 400/703 lr 0.100000 loss 1.0724 (1.1444) acc@1 0.5781 (0.5813) acc@5 0.8594 (0.8809)\n",
      "\u001b[32m[2020-07-15 16:32:08] __main__ INFO: \u001b[0mEpoch 13 Step 500/703 lr 0.100000 loss 0.8754 (1.1463) acc@1 0.6875 (0.5817) acc@5 0.9062 (0.8815)\n",
      "\u001b[32m[2020-07-15 16:32:40] __main__ INFO: \u001b[0mEpoch 13 Step 600/703 lr 0.100000 loss 1.2790 (1.1428) acc@1 0.5312 (0.5841) acc@5 0.8750 (0.8823)\n",
      "\u001b[32m[2020-07-15 16:33:12] __main__ INFO: \u001b[0mEpoch 13 Step 700/703 lr 0.100000 loss 1.4277 (1.1473) acc@1 0.4844 (0.5821) acc@5 0.8125 (0.8814)\n",
      "\u001b[32m[2020-07-15 16:33:13] __main__ INFO: \u001b[0mEpoch 13 Step 703/703 lr 0.100000 loss 1.1858 (1.1480) acc@1 0.5938 (0.5819) acc@5 0.8594 (0.8813)\n",
      "\u001b[32m[2020-07-15 16:33:13] __main__ INFO: \u001b[0mElapsed 225.44\n",
      "\u001b[32m[2020-07-15 16:33:13] __main__ INFO: \u001b[0mVal 13\n",
      "\u001b[32m[2020-07-15 16:33:21] __main__ INFO: \u001b[0mEpoch 13 loss 1.2661 acc@1 0.5454 acc@5 0.8770\n",
      "\u001b[32m[2020-07-15 16:33:21] __main__ INFO: \u001b[0mElapsed 7.74\n",
      "\u001b[32m[2020-07-15 16:33:21] __main__ INFO: \u001b[0mTrain 14 9139\n",
      "\u001b[32m[2020-07-15 16:33:53] __main__ INFO: \u001b[0mEpoch 14 Step 100/703 lr 0.100000 loss 1.1377 (1.1326) acc@1 0.6562 (0.5830) acc@5 0.8906 (0.8827)\n",
      "\u001b[32m[2020-07-15 16:34:25] __main__ INFO: \u001b[0mEpoch 14 Step 200/703 lr 0.100000 loss 1.3167 (1.1350) acc@1 0.5000 (0.5861) acc@5 0.8281 (0.8800)\n",
      "\u001b[32m[2020-07-15 16:34:57] __main__ INFO: \u001b[0mEpoch 14 Step 300/703 lr 0.100000 loss 1.1051 (1.1325) acc@1 0.5469 (0.5871) acc@5 0.9062 (0.8810)\n",
      "\u001b[32m[2020-07-15 16:35:29] __main__ INFO: \u001b[0mEpoch 14 Step 400/703 lr 0.100000 loss 1.0783 (1.1306) acc@1 0.6250 (0.5886) acc@5 0.9219 (0.8809)\n",
      "\u001b[32m[2020-07-15 16:36:01] __main__ INFO: \u001b[0mEpoch 14 Step 500/703 lr 0.100000 loss 1.0312 (1.1339) acc@1 0.6406 (0.5883) acc@5 0.8906 (0.8812)\n",
      "\u001b[32m[2020-07-15 16:36:33] __main__ INFO: \u001b[0mEpoch 14 Step 600/703 lr 0.100000 loss 1.1005 (1.1352) acc@1 0.5938 (0.5889) acc@5 0.8438 (0.8813)\n",
      "\u001b[32m[2020-07-15 16:37:05] __main__ INFO: \u001b[0mEpoch 14 Step 700/703 lr 0.100000 loss 0.8922 (1.1339) acc@1 0.7031 (0.5884) acc@5 0.9531 (0.8822)\n",
      "\u001b[32m[2020-07-15 16:37:06] __main__ INFO: \u001b[0mEpoch 14 Step 703/703 lr 0.100000 loss 1.0019 (1.1336) acc@1 0.6406 (0.5886) acc@5 0.9375 (0.8822)\n",
      "\u001b[32m[2020-07-15 16:37:06] __main__ INFO: \u001b[0mElapsed 225.77\n",
      "\u001b[32m[2020-07-15 16:37:06] __main__ INFO: \u001b[0mVal 14\n",
      "\u001b[32m[2020-07-15 16:37:14] __main__ INFO: \u001b[0mEpoch 14 loss 1.1694 acc@1 0.5802 acc@5 0.8770\n",
      "\u001b[32m[2020-07-15 16:37:14] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-15 16:37:14] __main__ INFO: \u001b[0mTrain 15 9842\n",
      "\u001b[32m[2020-07-15 16:37:46] __main__ INFO: \u001b[0mEpoch 15 Step 100/703 lr 0.100000 loss 0.8926 (1.0909) acc@1 0.7188 (0.6005) acc@5 0.9375 (0.8891)\n",
      "\u001b[32m[2020-07-15 16:38:18] __main__ INFO: \u001b[0mEpoch 15 Step 200/703 lr 0.100000 loss 1.2131 (1.1055) acc@1 0.5625 (0.5973) acc@5 0.8125 (0.8858)\n",
      "\u001b[32m[2020-07-15 16:38:50] __main__ INFO: \u001b[0mEpoch 15 Step 300/703 lr 0.100000 loss 1.1848 (1.1057) acc@1 0.5938 (0.5976) acc@5 0.8125 (0.8865)\n",
      "\u001b[32m[2020-07-15 16:39:22] __main__ INFO: \u001b[0mEpoch 15 Step 400/703 lr 0.100000 loss 0.9572 (1.1070) acc@1 0.6250 (0.5968) acc@5 0.9375 (0.8846)\n",
      "\u001b[32m[2020-07-15 16:39:54] __main__ INFO: \u001b[0mEpoch 15 Step 500/703 lr 0.100000 loss 1.1411 (1.1127) acc@1 0.5625 (0.5951) acc@5 0.8750 (0.8842)\n",
      "\u001b[32m[2020-07-15 16:40:26] __main__ INFO: \u001b[0mEpoch 15 Step 600/703 lr 0.100000 loss 0.9572 (1.1184) acc@1 0.6406 (0.5931) acc@5 0.9062 (0.8845)\n",
      "\u001b[32m[2020-07-15 16:40:58] __main__ INFO: \u001b[0mEpoch 15 Step 700/703 lr 0.100000 loss 1.1734 (1.1158) acc@1 0.6250 (0.5932) acc@5 0.8750 (0.8850)\n",
      "\u001b[32m[2020-07-15 16:40:59] __main__ INFO: \u001b[0mEpoch 15 Step 703/703 lr 0.100000 loss 1.0989 (1.1162) acc@1 0.5781 (0.5930) acc@5 0.8750 (0.8849)\n",
      "\u001b[32m[2020-07-15 16:40:59] __main__ INFO: \u001b[0mElapsed 225.23\n",
      "\u001b[32m[2020-07-15 16:40:59] __main__ INFO: \u001b[0mVal 15\n",
      "\u001b[32m[2020-07-15 16:41:07] __main__ INFO: \u001b[0mEpoch 15 loss 1.3050 acc@1 0.5364 acc@5 0.8628\n",
      "\u001b[32m[2020-07-15 16:41:07] __main__ INFO: \u001b[0mElapsed 7.70\n",
      "\u001b[32m[2020-07-15 16:41:07] __main__ INFO: \u001b[0mTrain 16 10545\n",
      "\u001b[32m[2020-07-15 16:41:39] __main__ INFO: \u001b[0mEpoch 16 Step 100/703 lr 0.100000 loss 1.0557 (1.0723) acc@1 0.6094 (0.6141) acc@5 0.9375 (0.8898)\n",
      "\u001b[32m[2020-07-15 16:42:11] __main__ INFO: \u001b[0mEpoch 16 Step 200/703 lr 0.100000 loss 1.1083 (1.0682) acc@1 0.5938 (0.6098) acc@5 0.9219 (0.8870)\n",
      "\u001b[32m[2020-07-15 16:42:43] __main__ INFO: \u001b[0mEpoch 16 Step 300/703 lr 0.100000 loss 1.1784 (1.0850) acc@1 0.5781 (0.6036) acc@5 0.8750 (0.8852)\n",
      "\u001b[32m[2020-07-15 16:43:15] __main__ INFO: \u001b[0mEpoch 16 Step 400/703 lr 0.100000 loss 1.3001 (1.0916) acc@1 0.5781 (0.6016) acc@5 0.9219 (0.8848)\n",
      "\u001b[32m[2020-07-15 16:43:47] __main__ INFO: \u001b[0mEpoch 16 Step 500/703 lr 0.100000 loss 1.1493 (1.0921) acc@1 0.5469 (0.6013) acc@5 0.9062 (0.8857)\n",
      "\u001b[32m[2020-07-15 16:44:19] __main__ INFO: \u001b[0mEpoch 16 Step 600/703 lr 0.100000 loss 1.3945 (1.0975) acc@1 0.5625 (0.5990) acc@5 0.9062 (0.8858)\n",
      "\u001b[32m[2020-07-15 16:44:51] __main__ INFO: \u001b[0mEpoch 16 Step 700/703 lr 0.100000 loss 1.2005 (1.1034) acc@1 0.5312 (0.5969) acc@5 0.8594 (0.8846)\n",
      "\u001b[32m[2020-07-15 16:44:52] __main__ INFO: \u001b[0mEpoch 16 Step 703/703 lr 0.100000 loss 1.4095 (1.1042) acc@1 0.4219 (0.5965) acc@5 0.7656 (0.8843)\n",
      "\u001b[32m[2020-07-15 16:44:52] __main__ INFO: \u001b[0mElapsed 225.16\n",
      "\u001b[32m[2020-07-15 16:44:52] __main__ INFO: \u001b[0mVal 16\n",
      "\u001b[32m[2020-07-15 16:45:00] __main__ INFO: \u001b[0mEpoch 16 loss 1.2118 acc@1 0.5716 acc@5 0.8828\n",
      "\u001b[32m[2020-07-15 16:45:00] __main__ INFO: \u001b[0mElapsed 7.72\n",
      "\u001b[32m[2020-07-15 16:45:00] __main__ INFO: \u001b[0mTrain 17 11248\n",
      "\u001b[32m[2020-07-15 16:45:32] __main__ INFO: \u001b[0mEpoch 17 Step 100/703 lr 0.100000 loss 1.2321 (1.0391) acc@1 0.5625 (0.6258) acc@5 0.8906 (0.8889)\n",
      "\u001b[32m[2020-07-15 16:46:04] __main__ INFO: \u001b[0mEpoch 17 Step 200/703 lr 0.100000 loss 1.2221 (1.0577) acc@1 0.5312 (0.6169) acc@5 0.8594 (0.8892)\n",
      "\u001b[32m[2020-07-15 16:46:36] __main__ INFO: \u001b[0mEpoch 17 Step 300/703 lr 0.100000 loss 0.9651 (1.0688) acc@1 0.6406 (0.6095) acc@5 0.9375 (0.8910)\n",
      "\u001b[32m[2020-07-15 16:47:08] __main__ INFO: \u001b[0mEpoch 17 Step 400/703 lr 0.100000 loss 0.9105 (1.0765) acc@1 0.6719 (0.6077) acc@5 0.8750 (0.8901)\n",
      "\u001b[32m[2020-07-15 16:47:40] __main__ INFO: \u001b[0mEpoch 17 Step 500/703 lr 0.100000 loss 1.1492 (1.0830) acc@1 0.5781 (0.6050) acc@5 0.8594 (0.8910)\n",
      "\u001b[32m[2020-07-15 16:48:12] __main__ INFO: \u001b[0mEpoch 17 Step 600/703 lr 0.100000 loss 1.1223 (1.0899) acc@1 0.5625 (0.6027) acc@5 0.8750 (0.8896)\n",
      "\u001b[32m[2020-07-15 16:48:44] __main__ INFO: \u001b[0mEpoch 17 Step 700/703 lr 0.100000 loss 1.1922 (1.0931) acc@1 0.5469 (0.6017) acc@5 0.9219 (0.8884)\n",
      "\u001b[32m[2020-07-15 16:48:45] __main__ INFO: \u001b[0mEpoch 17 Step 703/703 lr 0.100000 loss 1.1957 (1.0927) acc@1 0.5000 (0.6017) acc@5 0.8594 (0.8885)\n",
      "\u001b[32m[2020-07-15 16:48:45] __main__ INFO: \u001b[0mElapsed 225.40\n",
      "\u001b[32m[2020-07-15 16:48:45] __main__ INFO: \u001b[0mVal 17\n",
      "\u001b[32m[2020-07-15 16:48:53] __main__ INFO: \u001b[0mEpoch 17 loss 1.2070 acc@1 0.5690 acc@5 0.8750\n",
      "\u001b[32m[2020-07-15 16:48:53] __main__ INFO: \u001b[0mElapsed 7.73\n",
      "\u001b[32m[2020-07-15 16:48:53] __main__ INFO: \u001b[0mTrain 18 11951\n",
      "\u001b[32m[2020-07-15 16:49:25] __main__ INFO: \u001b[0mEpoch 18 Step 100/703 lr 0.100000 loss 1.3119 (1.0751) acc@1 0.4844 (0.6052) acc@5 0.8906 (0.8870)\n",
      "\u001b[32m[2020-07-15 16:49:57] __main__ INFO: \u001b[0mEpoch 18 Step 200/703 lr 0.100000 loss 0.8940 (1.0745) acc@1 0.6406 (0.6055) acc@5 0.8906 (0.8874)\n",
      "\u001b[32m[2020-07-15 16:50:29] __main__ INFO: \u001b[0mEpoch 18 Step 300/703 lr 0.100000 loss 1.1564 (1.0806) acc@1 0.5469 (0.6036) acc@5 0.9219 (0.8870)\n",
      "\u001b[32m[2020-07-15 16:51:01] __main__ INFO: \u001b[0mEpoch 18 Step 400/703 lr 0.100000 loss 1.1904 (1.0744) acc@1 0.5312 (0.6068) acc@5 0.8906 (0.8896)\n",
      "\u001b[32m[2020-07-15 16:51:33] __main__ INFO: \u001b[0mEpoch 18 Step 500/703 lr 0.100000 loss 1.2468 (1.0767) acc@1 0.5469 (0.6067) acc@5 0.8125 (0.8892)\n",
      "\u001b[32m[2020-07-15 16:52:05] __main__ INFO: \u001b[0mEpoch 18 Step 600/703 lr 0.100000 loss 1.1953 (1.0800) acc@1 0.5469 (0.6055) acc@5 0.8438 (0.8878)\n",
      "\u001b[32m[2020-07-15 16:52:37] __main__ INFO: \u001b[0mEpoch 18 Step 700/703 lr 0.100000 loss 0.8298 (1.0818) acc@1 0.7031 (0.6049) acc@5 0.9375 (0.8873)\n",
      "\u001b[32m[2020-07-15 16:52:38] __main__ INFO: \u001b[0mEpoch 18 Step 703/703 lr 0.100000 loss 0.9965 (1.0817) acc@1 0.5938 (0.6047) acc@5 0.9062 (0.8873)\n",
      "\u001b[32m[2020-07-15 16:52:38] __main__ INFO: \u001b[0mElapsed 225.15\n",
      "\u001b[32m[2020-07-15 16:52:38] __main__ INFO: \u001b[0mVal 18\n",
      "\u001b[32m[2020-07-15 16:52:46] __main__ INFO: \u001b[0mEpoch 18 loss 1.2983 acc@1 0.5462 acc@5 0.8634\n",
      "\u001b[32m[2020-07-15 16:52:46] __main__ INFO: \u001b[0mElapsed 7.74\n",
      "\u001b[32m[2020-07-15 16:52:46] __main__ INFO: \u001b[0mTrain 19 12654\n",
      "\u001b[32m[2020-07-15 16:53:18] __main__ INFO: \u001b[0mEpoch 19 Step 100/703 lr 0.100000 loss 0.8258 (1.0554) acc@1 0.7031 (0.6109) acc@5 0.9062 (0.8903)\n",
      "\u001b[32m[2020-07-15 16:53:50] __main__ INFO: \u001b[0mEpoch 19 Step 200/703 lr 0.100000 loss 1.1223 (1.0626) acc@1 0.5938 (0.6102) acc@5 0.9688 (0.8917)\n",
      "\u001b[32m[2020-07-15 16:54:22] __main__ INFO: \u001b[0mEpoch 19 Step 300/703 lr 0.100000 loss 1.2569 (1.0607) acc@1 0.5625 (0.6111) acc@5 0.8281 (0.8887)\n",
      "\u001b[32m[2020-07-15 16:54:54] __main__ INFO: \u001b[0mEpoch 19 Step 400/703 lr 0.100000 loss 0.9687 (1.0680) acc@1 0.6406 (0.6094) acc@5 0.9375 (0.8872)\n",
      "\u001b[32m[2020-07-15 16:55:26] __main__ INFO: \u001b[0mEpoch 19 Step 500/703 lr 0.100000 loss 1.0371 (1.0683) acc@1 0.6719 (0.6107) acc@5 0.8906 (0.8869)\n",
      "\u001b[32m[2020-07-15 16:55:58] __main__ INFO: \u001b[0mEpoch 19 Step 600/703 lr 0.100000 loss 0.8575 (1.0719) acc@1 0.7188 (0.6093) acc@5 0.8906 (0.8866)\n",
      "\u001b[32m[2020-07-15 16:56:30] __main__ INFO: \u001b[0mEpoch 19 Step 700/703 lr 0.100000 loss 0.9402 (1.0696) acc@1 0.6094 (0.6092) acc@5 0.8438 (0.8875)\n",
      "\u001b[32m[2020-07-15 16:56:31] __main__ INFO: \u001b[0mEpoch 19 Step 703/703 lr 0.100000 loss 0.9457 (1.0690) acc@1 0.6562 (0.6094) acc@5 0.8906 (0.8876)\n",
      "\u001b[32m[2020-07-15 16:56:31] __main__ INFO: \u001b[0mElapsed 224.70\n",
      "\u001b[32m[2020-07-15 16:56:31] __main__ INFO: \u001b[0mVal 19\n",
      "\u001b[32m[2020-07-15 16:56:38] __main__ INFO: \u001b[0mEpoch 19 loss 1.1678 acc@1 0.5772 acc@5 0.8802\n",
      "\u001b[32m[2020-07-15 16:56:38] __main__ INFO: \u001b[0mElapsed 7.72\n",
      "\u001b[32m[2020-07-15 16:56:38] __main__ INFO: \u001b[0mTrain 20 13357\n",
      "\u001b[32m[2020-07-15 16:57:11] __main__ INFO: \u001b[0mEpoch 20 Step 100/703 lr 0.100000 loss 1.3594 (1.0636) acc@1 0.4844 (0.6131) acc@5 0.8750 (0.8858)\n",
      "\u001b[32m[2020-07-15 16:57:43] __main__ INFO: \u001b[0mEpoch 20 Step 200/703 lr 0.100000 loss 0.8613 (1.0596) acc@1 0.6719 (0.6122) acc@5 0.9062 (0.8867)\n",
      "\u001b[32m[2020-07-15 16:58:15] __main__ INFO: \u001b[0mEpoch 20 Step 300/703 lr 0.100000 loss 0.6840 (1.0604) acc@1 0.7969 (0.6146) acc@5 0.9531 (0.8878)\n",
      "\u001b[32m[2020-07-15 16:58:47] __main__ INFO: \u001b[0mEpoch 20 Step 400/703 lr 0.100000 loss 1.0433 (1.0658) acc@1 0.5469 (0.6123) acc@5 0.8750 (0.8888)\n",
      "\u001b[32m[2020-07-15 16:59:19] __main__ INFO: \u001b[0mEpoch 20 Step 500/703 lr 0.100000 loss 0.7376 (1.0595) acc@1 0.7031 (0.6149) acc@5 0.9688 (0.8898)\n",
      "\u001b[32m[2020-07-15 16:59:51] __main__ INFO: \u001b[0mEpoch 20 Step 600/703 lr 0.100000 loss 1.2914 (1.0663) acc@1 0.5156 (0.6130) acc@5 0.9062 (0.8896)\n",
      "\u001b[32m[2020-07-15 17:00:23] __main__ INFO: \u001b[0mEpoch 20 Step 700/703 lr 0.100000 loss 1.1921 (1.0660) acc@1 0.5781 (0.6129) acc@5 0.9219 (0.8894)\n",
      "\u001b[32m[2020-07-15 17:00:23] __main__ INFO: \u001b[0mEpoch 20 Step 703/703 lr 0.100000 loss 0.9618 (1.0658) acc@1 0.6562 (0.6130) acc@5 0.9375 (0.8894)\n",
      "\u001b[32m[2020-07-15 17:00:24] __main__ INFO: \u001b[0mElapsed 225.00\n",
      "\u001b[32m[2020-07-15 17:00:24] __main__ INFO: \u001b[0mVal 20\n",
      "\u001b[32m[2020-07-15 17:00:31] __main__ INFO: \u001b[0mEpoch 20 loss 1.1984 acc@1 0.5750 acc@5 0.8816\n",
      "\u001b[32m[2020-07-15 17:00:31] __main__ INFO: \u001b[0mElapsed 7.74\n",
      "\u001b[32m[2020-07-15 17:00:31] __main__ INFO: \u001b[0mTrain 21 14060\n",
      "\u001b[32m[2020-07-15 17:01:03] __main__ INFO: \u001b[0mEpoch 21 Step 100/703 lr 0.100000 loss 1.0839 (1.0484) acc@1 0.5938 (0.6170) acc@5 0.9219 (0.8945)\n",
      "\u001b[32m[2020-07-15 17:01:35] __main__ INFO: \u001b[0mEpoch 21 Step 200/703 lr 0.100000 loss 1.0169 (1.0493) acc@1 0.6250 (0.6155) acc@5 0.9375 (0.8920)\n",
      "\u001b[32m[2020-07-15 17:02:07] __main__ INFO: \u001b[0mEpoch 21 Step 300/703 lr 0.100000 loss 1.0951 (1.0571) acc@1 0.5781 (0.6151) acc@5 0.9062 (0.8899)\n",
      "\u001b[32m[2020-07-15 17:02:40] __main__ INFO: \u001b[0mEpoch 21 Step 400/703 lr 0.100000 loss 0.9738 (1.0535) acc@1 0.6719 (0.6146) acc@5 0.9219 (0.8914)\n",
      "\u001b[32m[2020-07-15 17:03:12] __main__ INFO: \u001b[0mEpoch 21 Step 500/703 lr 0.100000 loss 0.9323 (1.0528) acc@1 0.6875 (0.6149) acc@5 0.9219 (0.8914)\n",
      "\u001b[32m[2020-07-15 17:03:44] __main__ INFO: \u001b[0mEpoch 21 Step 600/703 lr 0.100000 loss 0.8104 (1.0583) acc@1 0.7188 (0.6134) acc@5 0.9688 (0.8906)\n",
      "\u001b[32m[2020-07-15 17:04:16] __main__ INFO: \u001b[0mEpoch 21 Step 700/703 lr 0.100000 loss 1.0827 (1.0570) acc@1 0.6406 (0.6144) acc@5 0.9844 (0.8903)\n",
      "\u001b[32m[2020-07-15 17:04:17] __main__ INFO: \u001b[0mEpoch 21 Step 703/703 lr 0.100000 loss 1.4329 (1.0577) acc@1 0.4688 (0.6142) acc@5 0.8438 (0.8902)\n",
      "\u001b[32m[2020-07-15 17:04:17] __main__ INFO: \u001b[0mElapsed 225.29\n",
      "\u001b[32m[2020-07-15 17:04:17] __main__ INFO: \u001b[0mVal 21\n",
      "\u001b[32m[2020-07-15 17:04:24] __main__ INFO: \u001b[0mEpoch 21 loss 1.1978 acc@1 0.5778 acc@5 0.8772\n",
      "\u001b[32m[2020-07-15 17:04:24] __main__ INFO: \u001b[0mElapsed 7.75\n",
      "\u001b[32m[2020-07-15 17:04:24] __main__ INFO: \u001b[0mTrain 22 14763\n",
      "\u001b[32m[2020-07-15 17:04:56] __main__ INFO: \u001b[0mEpoch 22 Step 100/703 lr 0.100000 loss 0.9747 (1.0389) acc@1 0.6875 (0.6225) acc@5 0.9531 (0.8872)\n",
      "\u001b[32m[2020-07-15 17:05:29] __main__ INFO: \u001b[0mEpoch 22 Step 200/703 lr 0.100000 loss 0.8017 (1.0363) acc@1 0.6406 (0.6237) acc@5 0.9062 (0.8906)\n",
      "\u001b[32m[2020-07-15 17:06:01] __main__ INFO: \u001b[0mEpoch 22 Step 300/703 lr 0.100000 loss 1.2403 (1.0372) acc@1 0.5469 (0.6200) acc@5 0.7812 (0.8890)\n",
      "\u001b[32m[2020-07-15 17:06:33] __main__ INFO: \u001b[0mEpoch 22 Step 400/703 lr 0.100000 loss 1.1974 (1.0359) acc@1 0.6094 (0.6186) acc@5 0.8594 (0.8889)\n",
      "\u001b[32m[2020-07-15 17:07:05] __main__ INFO: \u001b[0mEpoch 22 Step 500/703 lr 0.100000 loss 1.1211 (1.0390) acc@1 0.6094 (0.6185) acc@5 0.9531 (0.8891)\n",
      "\u001b[32m[2020-07-15 17:07:37] __main__ INFO: \u001b[0mEpoch 22 Step 600/703 lr 0.100000 loss 1.1201 (1.0398) acc@1 0.5312 (0.6179) acc@5 0.8750 (0.8891)\n",
      "\u001b[32m[2020-07-15 17:08:09] __main__ INFO: \u001b[0mEpoch 22 Step 700/703 lr 0.100000 loss 0.8348 (1.0427) acc@1 0.6875 (0.6179) acc@5 0.8906 (0.8886)\n",
      "\u001b[32m[2020-07-15 17:08:10] __main__ INFO: \u001b[0mEpoch 22 Step 703/703 lr 0.100000 loss 1.0393 (1.0425) acc@1 0.5781 (0.6179) acc@5 0.8594 (0.8885)\n",
      "\u001b[32m[2020-07-15 17:08:10] __main__ INFO: \u001b[0mElapsed 225.36\n",
      "\u001b[32m[2020-07-15 17:08:10] __main__ INFO: \u001b[0mVal 22\n",
      "\u001b[32m[2020-07-15 17:08:17] __main__ INFO: \u001b[0mEpoch 22 loss 1.1818 acc@1 0.5732 acc@5 0.8830\n",
      "\u001b[32m[2020-07-15 17:08:17] __main__ INFO: \u001b[0mElapsed 7.75\n",
      "\u001b[32m[2020-07-15 17:08:17] __main__ INFO: \u001b[0mTrain 23 15466\n",
      "\u001b[32m[2020-07-15 17:08:49] __main__ INFO: \u001b[0mEpoch 23 Step 100/703 lr 0.100000 loss 1.1458 (1.0555) acc@1 0.5469 (0.6119) acc@5 0.8750 (0.8886)\n",
      "\u001b[32m[2020-07-15 17:09:21] __main__ INFO: \u001b[0mEpoch 23 Step 200/703 lr 0.100000 loss 0.9875 (1.0472) acc@1 0.6719 (0.6127) acc@5 0.8750 (0.8861)\n",
      "\u001b[32m[2020-07-15 17:09:53] __main__ INFO: \u001b[0mEpoch 23 Step 300/703 lr 0.100000 loss 0.9350 (1.0450) acc@1 0.7031 (0.6160) acc@5 0.8906 (0.8868)\n",
      "\u001b[32m[2020-07-15 17:10:26] __main__ INFO: \u001b[0mEpoch 23 Step 400/703 lr 0.100000 loss 1.1190 (1.0459) acc@1 0.6562 (0.6156) acc@5 0.8750 (0.8879)\n",
      "\u001b[32m[2020-07-15 17:10:58] __main__ INFO: \u001b[0mEpoch 23 Step 500/703 lr 0.100000 loss 1.0646 (1.0457) acc@1 0.6562 (0.6160) acc@5 0.8594 (0.8878)\n",
      "\u001b[32m[2020-07-15 17:11:30] __main__ INFO: \u001b[0mEpoch 23 Step 600/703 lr 0.100000 loss 0.8488 (1.0418) acc@1 0.6719 (0.6182) acc@5 0.9375 (0.8883)\n",
      "\u001b[32m[2020-07-15 17:12:02] __main__ INFO: \u001b[0mEpoch 23 Step 700/703 lr 0.100000 loss 1.0861 (1.0412) acc@1 0.5781 (0.6184) acc@5 0.9062 (0.8879)\n",
      "\u001b[32m[2020-07-15 17:12:03] __main__ INFO: \u001b[0mEpoch 23 Step 703/703 lr 0.100000 loss 1.0099 (1.0411) acc@1 0.6562 (0.6185) acc@5 0.9062 (0.8880)\n",
      "\u001b[32m[2020-07-15 17:12:03] __main__ INFO: \u001b[0mElapsed 225.66\n",
      "\u001b[32m[2020-07-15 17:12:03] __main__ INFO: \u001b[0mVal 23\n",
      "\u001b[32m[2020-07-15 17:12:11] __main__ INFO: \u001b[0mEpoch 23 loss 1.1956 acc@1 0.5772 acc@5 0.8788\n",
      "\u001b[32m[2020-07-15 17:12:11] __main__ INFO: \u001b[0mElapsed 7.74\n",
      "\u001b[32m[2020-07-15 17:12:11] __main__ INFO: \u001b[0mTrain 24 16169\n",
      "\u001b[32m[2020-07-15 17:12:43] __main__ INFO: \u001b[0mEpoch 24 Step 100/703 lr 0.100000 loss 1.4092 (1.0272) acc@1 0.4844 (0.6273) acc@5 0.8281 (0.8856)\n",
      "\u001b[32m[2020-07-15 17:13:15] __main__ INFO: \u001b[0mEpoch 24 Step 200/703 lr 0.100000 loss 0.9647 (1.0348) acc@1 0.7344 (0.6225) acc@5 0.8906 (0.8872)\n",
      "\u001b[32m[2020-07-15 17:13:47] __main__ INFO: \u001b[0mEpoch 24 Step 300/703 lr 0.100000 loss 0.9536 (1.0282) acc@1 0.6875 (0.6281) acc@5 0.8906 (0.8883)\n",
      "\u001b[32m[2020-07-15 17:14:19] __main__ INFO: \u001b[0mEpoch 24 Step 400/703 lr 0.100000 loss 1.0156 (1.0310) acc@1 0.5938 (0.6257) acc@5 0.9062 (0.8879)\n",
      "\u001b[32m[2020-07-15 17:14:51] __main__ INFO: \u001b[0mEpoch 24 Step 500/703 lr 0.100000 loss 1.0077 (1.0328) acc@1 0.6094 (0.6252) acc@5 0.9375 (0.8892)\n",
      "\u001b[32m[2020-07-15 17:15:23] __main__ INFO: \u001b[0mEpoch 24 Step 600/703 lr 0.100000 loss 1.0659 (1.0328) acc@1 0.6406 (0.6246) acc@5 0.8906 (0.8892)\n",
      "\u001b[32m[2020-07-15 17:15:55] __main__ INFO: \u001b[0mEpoch 24 Step 700/703 lr 0.100000 loss 1.2798 (1.0357) acc@1 0.5156 (0.6233) acc@5 0.8125 (0.8888)\n",
      "\u001b[32m[2020-07-15 17:15:56] __main__ INFO: \u001b[0mEpoch 24 Step 703/703 lr 0.100000 loss 0.8869 (1.0355) acc@1 0.6719 (0.6235) acc@5 0.9375 (0.8890)\n",
      "\u001b[32m[2020-07-15 17:15:56] __main__ INFO: \u001b[0mElapsed 225.29\n",
      "\u001b[32m[2020-07-15 17:15:56] __main__ INFO: \u001b[0mVal 24\n",
      "\u001b[32m[2020-07-15 17:16:04] __main__ INFO: \u001b[0mEpoch 24 loss 1.2763 acc@1 0.5538 acc@5 0.8740\n",
      "\u001b[32m[2020-07-15 17:16:04] __main__ INFO: \u001b[0mElapsed 7.72\n",
      "\u001b[32m[2020-07-15 17:16:04] __main__ INFO: \u001b[0mTrain 25 16872\n",
      "\u001b[32m[2020-07-15 17:16:36] __main__ INFO: \u001b[0mEpoch 25 Step 100/703 lr 0.100000 loss 1.0206 (1.0036) acc@1 0.5938 (0.6295) acc@5 0.8906 (0.8930)\n",
      "\u001b[32m[2020-07-15 17:17:08] __main__ INFO: \u001b[0mEpoch 25 Step 200/703 lr 0.100000 loss 1.2719 (1.0235) acc@1 0.4844 (0.6235) acc@5 0.8594 (0.8920)\n",
      "\u001b[32m[2020-07-15 17:17:40] __main__ INFO: \u001b[0mEpoch 25 Step 300/703 lr 0.100000 loss 0.8817 (1.0225) acc@1 0.6406 (0.6241) acc@5 0.9688 (0.8918)\n",
      "\u001b[32m[2020-07-15 17:18:12] __main__ INFO: \u001b[0mEpoch 25 Step 400/703 lr 0.100000 loss 1.2282 (1.0259) acc@1 0.6094 (0.6230) acc@5 0.8594 (0.8916)\n",
      "\u001b[32m[2020-07-15 17:18:44] __main__ INFO: \u001b[0mEpoch 25 Step 500/703 lr 0.100000 loss 1.0696 (1.0255) acc@1 0.6250 (0.6235) acc@5 0.9219 (0.8907)\n",
      "\u001b[32m[2020-07-15 17:19:16] __main__ INFO: \u001b[0mEpoch 25 Step 600/703 lr 0.100000 loss 0.8812 (1.0260) acc@1 0.6875 (0.6236) acc@5 0.8906 (0.8907)\n",
      "\u001b[32m[2020-07-15 17:19:48] __main__ INFO: \u001b[0mEpoch 25 Step 700/703 lr 0.100000 loss 0.9590 (1.0268) acc@1 0.6406 (0.6232) acc@5 0.8750 (0.8912)\n",
      "\u001b[32m[2020-07-15 17:19:49] __main__ INFO: \u001b[0mEpoch 25 Step 703/703 lr 0.100000 loss 1.0273 (1.0273) acc@1 0.6094 (0.6230) acc@5 0.9375 (0.8912)\n",
      "\u001b[32m[2020-07-15 17:19:49] __main__ INFO: \u001b[0mElapsed 224.85\n",
      "\u001b[32m[2020-07-15 17:19:49] __main__ INFO: \u001b[0mVal 25\n",
      "\u001b[32m[2020-07-15 17:19:56] __main__ INFO: \u001b[0mEpoch 25 loss 1.1785 acc@1 0.5740 acc@5 0.8768\n",
      "\u001b[32m[2020-07-15 17:19:56] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-15 17:19:56] __main__ INFO: \u001b[0mTrain 26 17575\n",
      "\u001b[32m[2020-07-15 17:20:28] __main__ INFO: \u001b[0mEpoch 26 Step 100/703 lr 0.100000 loss 1.0571 (0.9997) acc@1 0.5625 (0.6267) acc@5 0.8750 (0.8859)\n",
      "\u001b[32m[2020-07-15 17:21:00] __main__ INFO: \u001b[0mEpoch 26 Step 200/703 lr 0.100000 loss 1.1084 (1.0030) acc@1 0.5469 (0.6275) acc@5 0.8906 (0.8872)\n",
      "\u001b[32m[2020-07-15 17:21:33] __main__ INFO: \u001b[0mEpoch 26 Step 300/703 lr 0.100000 loss 1.2006 (1.0174) acc@1 0.5469 (0.6222) acc@5 0.9219 (0.8867)\n",
      "\u001b[32m[2020-07-15 17:22:05] __main__ INFO: \u001b[0mEpoch 26 Step 400/703 lr 0.100000 loss 1.0032 (1.0178) acc@1 0.6719 (0.6220) acc@5 0.9688 (0.8872)\n",
      "\u001b[32m[2020-07-15 17:22:37] __main__ INFO: \u001b[0mEpoch 26 Step 500/703 lr 0.100000 loss 1.4843 (1.0201) acc@1 0.5156 (0.6222) acc@5 0.8125 (0.8872)\n",
      "\u001b[32m[2020-07-15 17:23:09] __main__ INFO: \u001b[0mEpoch 26 Step 600/703 lr 0.100000 loss 0.9918 (1.0192) acc@1 0.6250 (0.6241) acc@5 0.9531 (0.8885)\n",
      "\u001b[32m[2020-07-15 17:23:41] __main__ INFO: \u001b[0mEpoch 26 Step 700/703 lr 0.100000 loss 0.9555 (1.0187) acc@1 0.6250 (0.6249) acc@5 0.8906 (0.8893)\n",
      "\u001b[32m[2020-07-15 17:23:42] __main__ INFO: \u001b[0mEpoch 26 Step 703/703 lr 0.100000 loss 1.0199 (1.0186) acc@1 0.5938 (0.6247) acc@5 0.8906 (0.8893)\n",
      "\u001b[32m[2020-07-15 17:23:42] __main__ INFO: \u001b[0mElapsed 225.25\n",
      "\u001b[32m[2020-07-15 17:23:42] __main__ INFO: \u001b[0mVal 26\n",
      "\u001b[32m[2020-07-15 17:23:49] __main__ INFO: \u001b[0mEpoch 26 loss 1.1760 acc@1 0.5836 acc@5 0.8774\n",
      "\u001b[32m[2020-07-15 17:23:49] __main__ INFO: \u001b[0mElapsed 7.73\n",
      "\u001b[32m[2020-07-15 17:23:49] __main__ INFO: \u001b[0mTrain 27 18278\n",
      "\u001b[32m[2020-07-15 17:24:21] __main__ INFO: \u001b[0mEpoch 27 Step 100/703 lr 0.100000 loss 1.0104 (1.0122) acc@1 0.5625 (0.6288) acc@5 0.9219 (0.8934)\n",
      "\u001b[32m[2020-07-15 17:24:53] __main__ INFO: \u001b[0mEpoch 27 Step 200/703 lr 0.100000 loss 1.1225 (1.0169) acc@1 0.6406 (0.6271) acc@5 0.9219 (0.8916)\n",
      "\u001b[32m[2020-07-15 17:25:25] __main__ INFO: \u001b[0mEpoch 27 Step 300/703 lr 0.100000 loss 0.9943 (1.0102) acc@1 0.6094 (0.6308) acc@5 0.9375 (0.8928)\n",
      "\u001b[32m[2020-07-15 17:25:57] __main__ INFO: \u001b[0mEpoch 27 Step 400/703 lr 0.100000 loss 1.2200 (1.0086) acc@1 0.5625 (0.6334) acc@5 0.8750 (0.8929)\n",
      "\u001b[32m[2020-07-15 17:26:29] __main__ INFO: \u001b[0mEpoch 27 Step 500/703 lr 0.100000 loss 0.8626 (1.0087) acc@1 0.7031 (0.6339) acc@5 0.9531 (0.8937)\n",
      "\u001b[32m[2020-07-15 17:27:01] __main__ INFO: \u001b[0mEpoch 27 Step 600/703 lr 0.100000 loss 1.2171 (1.0158) acc@1 0.5469 (0.6310) acc@5 0.8750 (0.8920)\n",
      "\u001b[32m[2020-07-15 17:27:33] __main__ INFO: \u001b[0mEpoch 27 Step 700/703 lr 0.100000 loss 0.8040 (1.0169) acc@1 0.6875 (0.6308) acc@5 0.8750 (0.8913)\n",
      "\u001b[32m[2020-07-15 17:27:34] __main__ INFO: \u001b[0mEpoch 27 Step 703/703 lr 0.100000 loss 1.0722 (1.0173) acc@1 0.5781 (0.6307) acc@5 0.8594 (0.8912)\n",
      "\u001b[32m[2020-07-15 17:27:34] __main__ INFO: \u001b[0mElapsed 225.03\n",
      "\u001b[32m[2020-07-15 17:27:34] __main__ INFO: \u001b[0mVal 27\n",
      "\u001b[32m[2020-07-15 17:27:42] __main__ INFO: \u001b[0mEpoch 27 loss 1.2052 acc@1 0.5694 acc@5 0.8834\n",
      "\u001b[32m[2020-07-15 17:27:42] __main__ INFO: \u001b[0mElapsed 7.70\n",
      "\u001b[32m[2020-07-15 17:27:42] __main__ INFO: \u001b[0mTrain 28 18981\n",
      "\u001b[32m[2020-07-15 17:28:14] __main__ INFO: \u001b[0mEpoch 28 Step 100/703 lr 0.100000 loss 1.1966 (1.0009) acc@1 0.5625 (0.6305) acc@5 0.9062 (0.8909)\n",
      "\u001b[32m[2020-07-15 17:28:46] __main__ INFO: \u001b[0mEpoch 28 Step 200/703 lr 0.100000 loss 1.1512 (1.0013) acc@1 0.5312 (0.6322) acc@5 0.8125 (0.8912)\n",
      "\u001b[32m[2020-07-15 17:29:18] __main__ INFO: \u001b[0mEpoch 28 Step 300/703 lr 0.100000 loss 1.0925 (1.0109) acc@1 0.5781 (0.6257) acc@5 0.9062 (0.8891)\n",
      "\u001b[32m[2020-07-15 17:29:50] __main__ INFO: \u001b[0mEpoch 28 Step 400/703 lr 0.100000 loss 0.7932 (1.0102) acc@1 0.7500 (0.6275) acc@5 0.9219 (0.8888)\n",
      "\u001b[32m[2020-07-15 17:30:22] __main__ INFO: \u001b[0mEpoch 28 Step 500/703 lr 0.100000 loss 1.0641 (1.0102) acc@1 0.6250 (0.6271) acc@5 0.8906 (0.8884)\n",
      "\u001b[32m[2020-07-15 17:30:54] __main__ INFO: \u001b[0mEpoch 28 Step 600/703 lr 0.100000 loss 0.9809 (1.0105) acc@1 0.6250 (0.6271) acc@5 0.9062 (0.8896)\n",
      "\u001b[32m[2020-07-15 17:31:26] __main__ INFO: \u001b[0mEpoch 28 Step 700/703 lr 0.100000 loss 1.1877 (1.0106) acc@1 0.5625 (0.6277) acc@5 0.8750 (0.8896)\n",
      "\u001b[32m[2020-07-15 17:31:27] __main__ INFO: \u001b[0mEpoch 28 Step 703/703 lr 0.100000 loss 1.1357 (1.0107) acc@1 0.5938 (0.6278) acc@5 0.8750 (0.8896)\n",
      "\u001b[32m[2020-07-15 17:31:27] __main__ INFO: \u001b[0mElapsed 224.95\n",
      "\u001b[32m[2020-07-15 17:31:27] __main__ INFO: \u001b[0mVal 28\n",
      "\u001b[32m[2020-07-15 17:31:35] __main__ INFO: \u001b[0mEpoch 28 loss 1.1464 acc@1 0.5970 acc@5 0.8838\n",
      "\u001b[32m[2020-07-15 17:31:35] __main__ INFO: \u001b[0mElapsed 7.72\n",
      "\u001b[32m[2020-07-15 17:31:35] __main__ INFO: \u001b[0mTrain 29 19684\n",
      "\u001b[32m[2020-07-15 17:32:07] __main__ INFO: \u001b[0mEpoch 29 Step 100/703 lr 0.100000 loss 1.1030 (0.9924) acc@1 0.5312 (0.6339) acc@5 0.9062 (0.8931)\n",
      "\u001b[32m[2020-07-15 17:32:39] __main__ INFO: \u001b[0mEpoch 29 Step 200/703 lr 0.100000 loss 0.9949 (0.9880) acc@1 0.6094 (0.6384) acc@5 0.8438 (0.8925)\n",
      "\u001b[32m[2020-07-15 17:33:11] __main__ INFO: \u001b[0mEpoch 29 Step 300/703 lr 0.100000 loss 0.7656 (0.9988) acc@1 0.7344 (0.6351) acc@5 0.9375 (0.8895)\n",
      "\u001b[32m[2020-07-15 17:33:43] __main__ INFO: \u001b[0mEpoch 29 Step 400/703 lr 0.100000 loss 0.9512 (0.9985) acc@1 0.6562 (0.6348) acc@5 0.8906 (0.8900)\n",
      "\u001b[32m[2020-07-15 17:34:15] __main__ INFO: \u001b[0mEpoch 29 Step 500/703 lr 0.100000 loss 1.1603 (1.0005) acc@1 0.5312 (0.6338) acc@5 0.9062 (0.8901)\n",
      "\u001b[32m[2020-07-15 17:34:47] __main__ INFO: \u001b[0mEpoch 29 Step 600/703 lr 0.100000 loss 1.1038 (0.9997) acc@1 0.5938 (0.6336) acc@5 0.9688 (0.8905)\n",
      "\u001b[32m[2020-07-15 17:35:19] __main__ INFO: \u001b[0mEpoch 29 Step 700/703 lr 0.100000 loss 0.9596 (1.0048) acc@1 0.6250 (0.6316) acc@5 0.9062 (0.8904)\n",
      "\u001b[32m[2020-07-15 17:35:20] __main__ INFO: \u001b[0mEpoch 29 Step 703/703 lr 0.100000 loss 1.0180 (1.0045) acc@1 0.6250 (0.6317) acc@5 0.8906 (0.8905)\n",
      "\u001b[32m[2020-07-15 17:35:20] __main__ INFO: \u001b[0mElapsed 225.27\n",
      "\u001b[32m[2020-07-15 17:35:20] __main__ INFO: \u001b[0mVal 29\n",
      "\u001b[32m[2020-07-15 17:35:28] __main__ INFO: \u001b[0mEpoch 29 loss 1.1771 acc@1 0.5888 acc@5 0.8712\n",
      "\u001b[32m[2020-07-15 17:35:28] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-15 17:35:28] __main__ INFO: \u001b[0mTrain 30 20387\n",
      "\u001b[32m[2020-07-15 17:36:00] __main__ INFO: \u001b[0mEpoch 30 Step 100/703 lr 0.100000 loss 1.0017 (0.9686) acc@1 0.5938 (0.6403) acc@5 0.8750 (0.8875)\n",
      "\u001b[32m[2020-07-15 17:36:32] __main__ INFO: \u001b[0mEpoch 30 Step 200/703 lr 0.100000 loss 0.9850 (0.9816) acc@1 0.6250 (0.6376) acc@5 0.9062 (0.8864)\n",
      "\u001b[32m[2020-07-15 17:37:04] __main__ INFO: \u001b[0mEpoch 30 Step 300/703 lr 0.100000 loss 1.0827 (0.9860) acc@1 0.5781 (0.6391) acc@5 0.8906 (0.8890)\n",
      "\u001b[32m[2020-07-15 17:37:36] __main__ INFO: \u001b[0mEpoch 30 Step 400/703 lr 0.100000 loss 1.0396 (0.9824) acc@1 0.6406 (0.6407) acc@5 0.8906 (0.8909)\n",
      "\u001b[32m[2020-07-15 17:38:08] __main__ INFO: \u001b[0mEpoch 30 Step 500/703 lr 0.100000 loss 1.0642 (0.9899) acc@1 0.6406 (0.6363) acc@5 0.8438 (0.8908)\n",
      "\u001b[32m[2020-07-15 17:38:40] __main__ INFO: \u001b[0mEpoch 30 Step 600/703 lr 0.100000 loss 0.9973 (0.9921) acc@1 0.6250 (0.6354) acc@5 0.9375 (0.8916)\n",
      "\u001b[32m[2020-07-15 17:39:12] __main__ INFO: \u001b[0mEpoch 30 Step 700/703 lr 0.100000 loss 0.9569 (0.9992) acc@1 0.6875 (0.6337) acc@5 0.9062 (0.8911)\n",
      "\u001b[32m[2020-07-15 17:39:13] __main__ INFO: \u001b[0mEpoch 30 Step 703/703 lr 0.100000 loss 0.9829 (0.9992) acc@1 0.6562 (0.6337) acc@5 0.8125 (0.8911)\n",
      "\u001b[32m[2020-07-15 17:39:13] __main__ INFO: \u001b[0mElapsed 224.81\n",
      "\u001b[32m[2020-07-15 17:39:13] __main__ INFO: \u001b[0mVal 30\n",
      "\u001b[32m[2020-07-15 17:39:20] __main__ INFO: \u001b[0mEpoch 30 loss 1.1480 acc@1 0.5832 acc@5 0.8800\n",
      "\u001b[32m[2020-07-15 17:39:20] __main__ INFO: \u001b[0mElapsed 7.72\n",
      "\u001b[32m[2020-07-15 17:39:20] __main__ INFO: \u001b[0mTrain 31 21090\n",
      "\u001b[32m[2020-07-15 17:39:52] __main__ INFO: \u001b[0mEpoch 31 Step 100/703 lr 0.100000 loss 1.2383 (0.9794) acc@1 0.5781 (0.6406) acc@5 0.8438 (0.8881)\n",
      "\u001b[32m[2020-07-15 17:40:24] __main__ INFO: \u001b[0mEpoch 31 Step 200/703 lr 0.100000 loss 0.9954 (0.9868) acc@1 0.6562 (0.6376) acc@5 0.8594 (0.8884)\n",
      "\u001b[32m[2020-07-15 17:40:56] __main__ INFO: \u001b[0mEpoch 31 Step 300/703 lr 0.100000 loss 1.1755 (0.9964) acc@1 0.6250 (0.6349) acc@5 0.9375 (0.8878)\n",
      "\u001b[32m[2020-07-15 17:41:28] __main__ INFO: \u001b[0mEpoch 31 Step 400/703 lr 0.100000 loss 1.0886 (0.9947) acc@1 0.6406 (0.6364) acc@5 0.8750 (0.8891)\n",
      "\u001b[32m[2020-07-15 17:42:01] __main__ INFO: \u001b[0mEpoch 31 Step 500/703 lr 0.100000 loss 0.7984 (0.9931) acc@1 0.6875 (0.6371) acc@5 0.9219 (0.8895)\n",
      "\u001b[32m[2020-07-15 17:42:32] __main__ INFO: \u001b[0mEpoch 31 Step 600/703 lr 0.100000 loss 1.0756 (0.9921) acc@1 0.6094 (0.6371) acc@5 0.9062 (0.8903)\n",
      "\u001b[32m[2020-07-15 17:43:04] __main__ INFO: \u001b[0mEpoch 31 Step 700/703 lr 0.100000 loss 1.0360 (0.9915) acc@1 0.6094 (0.6371) acc@5 0.8125 (0.8906)\n",
      "\u001b[32m[2020-07-15 17:43:05] __main__ INFO: \u001b[0mEpoch 31 Step 703/703 lr 0.100000 loss 0.8891 (0.9913) acc@1 0.6719 (0.6373) acc@5 0.9062 (0.8907)\n",
      "\u001b[32m[2020-07-15 17:43:05] __main__ INFO: \u001b[0mElapsed 225.01\n",
      "\u001b[32m[2020-07-15 17:43:05] __main__ INFO: \u001b[0mVal 31\n",
      "\u001b[32m[2020-07-15 17:43:13] __main__ INFO: \u001b[0mEpoch 31 loss 1.1766 acc@1 0.5862 acc@5 0.8798\n",
      "\u001b[32m[2020-07-15 17:43:13] __main__ INFO: \u001b[0mElapsed 7.71\n",
      "\u001b[32m[2020-07-15 17:43:13] __main__ INFO: \u001b[0mTrain 32 21793\n",
      "\u001b[32m[2020-07-15 17:43:45] __main__ INFO: \u001b[0mEpoch 32 Step 100/703 lr 0.100000 loss 1.1618 (0.9780) acc@1 0.5469 (0.6445) acc@5 0.8906 (0.8919)\n",
      "\u001b[32m[2020-07-15 17:44:17] __main__ INFO: \u001b[0mEpoch 32 Step 200/703 lr 0.100000 loss 1.0369 (0.9782) acc@1 0.6094 (0.6442) acc@5 0.9062 (0.8917)\n",
      "\u001b[32m[2020-07-15 17:44:49] __main__ INFO: \u001b[0mEpoch 32 Step 300/703 lr 0.100000 loss 0.7800 (0.9819) acc@1 0.6875 (0.6404) acc@5 0.9219 (0.8925)\n",
      "\u001b[32m[2020-07-15 17:45:21] __main__ INFO: \u001b[0mEpoch 32 Step 400/703 lr 0.100000 loss 0.8134 (0.9874) acc@1 0.7031 (0.6383) acc@5 0.9375 (0.8923)\n",
      "\u001b[32m[2020-07-15 17:45:53] __main__ INFO: \u001b[0mEpoch 32 Step 500/703 lr 0.100000 loss 1.0177 (0.9879) acc@1 0.5781 (0.6380) acc@5 0.8594 (0.8936)\n",
      "\u001b[32m[2020-07-15 17:46:25] __main__ INFO: \u001b[0mEpoch 32 Step 600/703 lr 0.100000 loss 0.9540 (0.9859) acc@1 0.6094 (0.6389) acc@5 0.8750 (0.8927)\n",
      "\u001b[32m[2020-07-15 17:46:57] __main__ INFO: \u001b[0mEpoch 32 Step 700/703 lr 0.100000 loss 0.9664 (0.9870) acc@1 0.6562 (0.6386) acc@5 0.9062 (0.8932)\n",
      "\u001b[32m[2020-07-15 17:46:58] __main__ INFO: \u001b[0mEpoch 32 Step 703/703 lr 0.100000 loss 1.0586 (0.9870) acc@1 0.5469 (0.6385) acc@5 0.8906 (0.8933)\n",
      "\u001b[32m[2020-07-15 17:46:58] __main__ INFO: \u001b[0mElapsed 225.02\n",
      "\u001b[32m[2020-07-15 17:46:58] __main__ INFO: \u001b[0mVal 32\n",
      "\u001b[32m[2020-07-15 17:47:06] __main__ INFO: \u001b[0mEpoch 32 loss 1.0988 acc@1 0.6102 acc@5 0.8800\n",
      "\u001b[32m[2020-07-15 17:47:06] __main__ INFO: \u001b[0mElapsed 7.71\n",
      "\u001b[32m[2020-07-15 17:47:06] __main__ INFO: \u001b[0mTrain 33 22496\n",
      "\u001b[32m[2020-07-15 17:47:38] __main__ INFO: \u001b[0mEpoch 33 Step 100/703 lr 0.100000 loss 1.0275 (0.9385) acc@1 0.6250 (0.6534) acc@5 0.8125 (0.9002)\n",
      "\u001b[32m[2020-07-15 17:48:10] __main__ INFO: \u001b[0mEpoch 33 Step 200/703 lr 0.100000 loss 0.7207 (0.9596) acc@1 0.7812 (0.6447) acc@5 0.9375 (0.8977)\n",
      "\u001b[32m[2020-07-15 17:48:42] __main__ INFO: \u001b[0mEpoch 33 Step 300/703 lr 0.100000 loss 0.8642 (0.9679) acc@1 0.6719 (0.6432) acc@5 0.8906 (0.8962)\n",
      "\u001b[32m[2020-07-15 17:49:14] __main__ INFO: \u001b[0mEpoch 33 Step 400/703 lr 0.100000 loss 1.0435 (0.9748) acc@1 0.6094 (0.6411) acc@5 0.9062 (0.8947)\n",
      "\u001b[32m[2020-07-15 17:49:46] __main__ INFO: \u001b[0mEpoch 33 Step 500/703 lr 0.100000 loss 1.0209 (0.9810) acc@1 0.6250 (0.6395) acc@5 0.8906 (0.8927)\n",
      "\u001b[32m[2020-07-15 17:50:18] __main__ INFO: \u001b[0mEpoch 33 Step 600/703 lr 0.100000 loss 1.0157 (0.9834) acc@1 0.6562 (0.6391) acc@5 0.9062 (0.8930)\n",
      "\u001b[32m[2020-07-15 17:50:50] __main__ INFO: \u001b[0mEpoch 33 Step 700/703 lr 0.100000 loss 0.9286 (0.9830) acc@1 0.6406 (0.6390) acc@5 0.8750 (0.8932)\n",
      "\u001b[32m[2020-07-15 17:50:51] __main__ INFO: \u001b[0mEpoch 33 Step 703/703 lr 0.100000 loss 1.0057 (0.9834) acc@1 0.6562 (0.6389) acc@5 0.9375 (0.8932)\n",
      "\u001b[32m[2020-07-15 17:50:51] __main__ INFO: \u001b[0mElapsed 224.78\n",
      "\u001b[32m[2020-07-15 17:50:51] __main__ INFO: \u001b[0mVal 33\n",
      "\u001b[32m[2020-07-15 17:50:58] __main__ INFO: \u001b[0mEpoch 33 loss 1.1438 acc@1 0.5990 acc@5 0.8800\n",
      "\u001b[32m[2020-07-15 17:50:58] __main__ INFO: \u001b[0mElapsed 7.69\n",
      "\u001b[32m[2020-07-15 17:50:58] __main__ INFO: \u001b[0mTrain 34 23199\n",
      "\u001b[32m[2020-07-15 17:51:30] __main__ INFO: \u001b[0mEpoch 34 Step 100/703 lr 0.100000 loss 0.9109 (0.9327) acc@1 0.6250 (0.6595) acc@5 0.9375 (0.8977)\n",
      "\u001b[32m[2020-07-15 17:52:02] __main__ INFO: \u001b[0mEpoch 34 Step 200/703 lr 0.100000 loss 0.8659 (0.9505) acc@1 0.6562 (0.6533) acc@5 0.9531 (0.8928)\n",
      "\u001b[32m[2020-07-15 17:52:34] __main__ INFO: \u001b[0mEpoch 34 Step 300/703 lr 0.100000 loss 1.1157 (0.9648) acc@1 0.5625 (0.6485) acc@5 0.9062 (0.8914)\n",
      "\u001b[32m[2020-07-15 17:53:06] __main__ INFO: \u001b[0mEpoch 34 Step 400/703 lr 0.100000 loss 1.1176 (0.9702) acc@1 0.6250 (0.6457) acc@5 0.9062 (0.8904)\n",
      "\u001b[32m[2020-07-15 17:53:38] __main__ INFO: \u001b[0mEpoch 34 Step 500/703 lr 0.100000 loss 0.9822 (0.9730) acc@1 0.6406 (0.6451) acc@5 0.9219 (0.8918)\n",
      "\u001b[32m[2020-07-15 17:54:11] __main__ INFO: \u001b[0mEpoch 34 Step 600/703 lr 0.100000 loss 0.7333 (0.9735) acc@1 0.7188 (0.6448) acc@5 0.8594 (0.8920)\n",
      "\u001b[32m[2020-07-15 17:54:42] __main__ INFO: \u001b[0mEpoch 34 Step 700/703 lr 0.100000 loss 1.2663 (0.9754) acc@1 0.5625 (0.6444) acc@5 0.7969 (0.8925)\n",
      "\u001b[32m[2020-07-15 17:54:43] __main__ INFO: \u001b[0mEpoch 34 Step 703/703 lr 0.100000 loss 0.9027 (0.9755) acc@1 0.6875 (0.6445) acc@5 0.9375 (0.8925)\n",
      "\u001b[32m[2020-07-15 17:54:43] __main__ INFO: \u001b[0mElapsed 224.99\n",
      "\u001b[32m[2020-07-15 17:54:43] __main__ INFO: \u001b[0mVal 34\n",
      "\u001b[32m[2020-07-15 17:54:51] __main__ INFO: \u001b[0mEpoch 34 loss 1.0715 acc@1 0.6142 acc@5 0.8876\n",
      "\u001b[32m[2020-07-15 17:54:51] __main__ INFO: \u001b[0mElapsed 7.72\n",
      "\u001b[32m[2020-07-15 17:54:51] __main__ INFO: \u001b[0mTrain 35 23902\n",
      "\u001b[32m[2020-07-15 17:55:23] __main__ INFO: \u001b[0mEpoch 35 Step 100/703 lr 0.100000 loss 0.8884 (0.9730) acc@1 0.7344 (0.6438) acc@5 0.9062 (0.8945)\n",
      "\u001b[32m[2020-07-15 17:55:55] __main__ INFO: \u001b[0mEpoch 35 Step 200/703 lr 0.100000 loss 0.6643 (0.9758) acc@1 0.8125 (0.6421) acc@5 0.9531 (0.8940)\n",
      "\u001b[32m[2020-07-15 17:56:27] __main__ INFO: \u001b[0mEpoch 35 Step 300/703 lr 0.100000 loss 0.8692 (0.9751) acc@1 0.7188 (0.6421) acc@5 0.9375 (0.8926)\n",
      "\u001b[32m[2020-07-15 17:56:59] __main__ INFO: \u001b[0mEpoch 35 Step 400/703 lr 0.100000 loss 0.8465 (0.9709) acc@1 0.7031 (0.6439) acc@5 0.8906 (0.8952)\n",
      "\u001b[32m[2020-07-15 17:57:31] __main__ INFO: \u001b[0mEpoch 35 Step 500/703 lr 0.100000 loss 1.0937 (0.9672) acc@1 0.5938 (0.6463) acc@5 0.8594 (0.8952)\n",
      "\u001b[32m[2020-07-15 17:58:03] __main__ INFO: \u001b[0mEpoch 35 Step 600/703 lr 0.100000 loss 0.9087 (0.9690) acc@1 0.7031 (0.6455) acc@5 0.9062 (0.8958)\n",
      "\u001b[32m[2020-07-15 17:58:35] __main__ INFO: \u001b[0mEpoch 35 Step 700/703 lr 0.100000 loss 1.0544 (0.9763) acc@1 0.7031 (0.6426) acc@5 0.8750 (0.8943)\n",
      "\u001b[32m[2020-07-15 17:58:36] __main__ INFO: \u001b[0mEpoch 35 Step 703/703 lr 0.100000 loss 1.1641 (0.9763) acc@1 0.6562 (0.6428) acc@5 0.9062 (0.8943)\n",
      "\u001b[32m[2020-07-15 17:58:36] __main__ INFO: \u001b[0mElapsed 224.90\n",
      "\u001b[32m[2020-07-15 17:58:36] __main__ INFO: \u001b[0mVal 35\n",
      "\u001b[32m[2020-07-15 17:58:44] __main__ INFO: \u001b[0mEpoch 35 loss 1.1909 acc@1 0.5756 acc@5 0.8818\n",
      "\u001b[32m[2020-07-15 17:58:44] __main__ INFO: \u001b[0mElapsed 7.73\n",
      "\u001b[32m[2020-07-15 17:58:44] __main__ INFO: \u001b[0mTrain 36 24605\n",
      "\u001b[32m[2020-07-15 17:59:16] __main__ INFO: \u001b[0mEpoch 36 Step 100/703 lr 0.100000 loss 0.9528 (0.9459) acc@1 0.6406 (0.6512) acc@5 0.9688 (0.8947)\n",
      "\u001b[32m[2020-07-15 17:59:48] __main__ INFO: \u001b[0mEpoch 36 Step 200/703 lr 0.100000 loss 0.9430 (0.9512) acc@1 0.6562 (0.6470) acc@5 0.8906 (0.8920)\n",
      "\u001b[32m[2020-07-15 18:00:20] __main__ INFO: \u001b[0mEpoch 36 Step 300/703 lr 0.100000 loss 0.8617 (0.9555) acc@1 0.6250 (0.6465) acc@5 0.8594 (0.8920)\n",
      "\u001b[32m[2020-07-15 18:00:52] __main__ INFO: \u001b[0mEpoch 36 Step 400/703 lr 0.100000 loss 1.1814 (0.9622) acc@1 0.5000 (0.6430) acc@5 0.8906 (0.8907)\n",
      "\u001b[32m[2020-07-15 18:01:24] __main__ INFO: \u001b[0mEpoch 36 Step 500/703 lr 0.100000 loss 0.8980 (0.9625) acc@1 0.6719 (0.6445) acc@5 0.9062 (0.8926)\n",
      "\u001b[32m[2020-07-15 18:01:56] __main__ INFO: \u001b[0mEpoch 36 Step 600/703 lr 0.100000 loss 1.1759 (0.9673) acc@1 0.5938 (0.6426) acc@5 0.9375 (0.8915)\n",
      "\u001b[32m[2020-07-15 18:02:28] __main__ INFO: \u001b[0mEpoch 36 Step 700/703 lr 0.100000 loss 0.8174 (0.9709) acc@1 0.6875 (0.6417) acc@5 0.9219 (0.8907)\n",
      "\u001b[32m[2020-07-15 18:02:29] __main__ INFO: \u001b[0mEpoch 36 Step 703/703 lr 0.100000 loss 1.0527 (0.9708) acc@1 0.6562 (0.6418) acc@5 0.9062 (0.8908)\n",
      "\u001b[32m[2020-07-15 18:02:29] __main__ INFO: \u001b[0mElapsed 225.13\n",
      "\u001b[32m[2020-07-15 18:02:29] __main__ INFO: \u001b[0mVal 36\n",
      "\u001b[32m[2020-07-15 18:02:37] __main__ INFO: \u001b[0mEpoch 36 loss 1.1288 acc@1 0.5972 acc@5 0.8848\n",
      "\u001b[32m[2020-07-15 18:02:37] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-15 18:02:37] __main__ INFO: \u001b[0mTrain 37 25308\n",
      "\u001b[32m[2020-07-15 18:03:09] __main__ INFO: \u001b[0mEpoch 37 Step 100/703 lr 0.100000 loss 0.9066 (0.9602) acc@1 0.6719 (0.6422) acc@5 0.8750 (0.8908)\n",
      "\u001b[32m[2020-07-15 18:03:41] __main__ INFO: \u001b[0mEpoch 37 Step 200/703 lr 0.100000 loss 0.9032 (0.9648) acc@1 0.6562 (0.6412) acc@5 0.9062 (0.8903)\n",
      "\u001b[32m[2020-07-15 18:04:13] __main__ INFO: \u001b[0mEpoch 37 Step 300/703 lr 0.100000 loss 1.1547 (0.9672) acc@1 0.5625 (0.6439) acc@5 0.8281 (0.8885)\n",
      "\u001b[32m[2020-07-15 18:04:45] __main__ INFO: \u001b[0mEpoch 37 Step 400/703 lr 0.100000 loss 1.1634 (0.9684) acc@1 0.6094 (0.6434) acc@5 0.7969 (0.8902)\n",
      "\u001b[32m[2020-07-15 18:05:17] __main__ INFO: \u001b[0mEpoch 37 Step 500/703 lr 0.100000 loss 0.6261 (0.9684) acc@1 0.7812 (0.6425) acc@5 0.9375 (0.8916)\n",
      "\u001b[32m[2020-07-15 18:05:49] __main__ INFO: \u001b[0mEpoch 37 Step 600/703 lr 0.100000 loss 0.9357 (0.9672) acc@1 0.6875 (0.6423) acc@5 0.9375 (0.8916)\n",
      "\u001b[32m[2020-07-15 18:06:21] __main__ INFO: \u001b[0mEpoch 37 Step 700/703 lr 0.100000 loss 0.8335 (0.9674) acc@1 0.6875 (0.6433) acc@5 0.9062 (0.8917)\n",
      "\u001b[32m[2020-07-15 18:06:22] __main__ INFO: \u001b[0mEpoch 37 Step 703/703 lr 0.100000 loss 1.0806 (0.9674) acc@1 0.6250 (0.6434) acc@5 0.9219 (0.8917)\n",
      "\u001b[32m[2020-07-15 18:06:22] __main__ INFO: \u001b[0mElapsed 225.26\n",
      "\u001b[32m[2020-07-15 18:06:22] __main__ INFO: \u001b[0mVal 37\n",
      "\u001b[32m[2020-07-15 18:06:30] __main__ INFO: \u001b[0mEpoch 37 loss 1.1368 acc@1 0.5926 acc@5 0.8802\n",
      "\u001b[32m[2020-07-15 18:06:30] __main__ INFO: \u001b[0mElapsed 7.79\n",
      "\u001b[32m[2020-07-15 18:06:30] __main__ INFO: \u001b[0mTrain 38 26011\n",
      "\u001b[32m[2020-07-15 18:07:02] __main__ INFO: \u001b[0mEpoch 38 Step 100/703 lr 0.100000 loss 0.9455 (0.9388) acc@1 0.6406 (0.6542) acc@5 0.9219 (0.8922)\n",
      "\u001b[32m[2020-07-15 18:07:34] __main__ INFO: \u001b[0mEpoch 38 Step 200/703 lr 0.100000 loss 0.7810 (0.9466) acc@1 0.7188 (0.6512) acc@5 0.9375 (0.8952)\n",
      "\u001b[32m[2020-07-15 18:08:06] __main__ INFO: \u001b[0mEpoch 38 Step 300/703 lr 0.100000 loss 1.1108 (0.9454) acc@1 0.5625 (0.6534) acc@5 0.9062 (0.8963)\n",
      "\u001b[32m[2020-07-15 18:08:38] __main__ INFO: \u001b[0mEpoch 38 Step 400/703 lr 0.100000 loss 1.0584 (0.9459) acc@1 0.5781 (0.6514) acc@5 0.8594 (0.8964)\n",
      "\u001b[32m[2020-07-15 18:09:10] __main__ INFO: \u001b[0mEpoch 38 Step 500/703 lr 0.100000 loss 0.9410 (0.9511) acc@1 0.5781 (0.6482) acc@5 0.8906 (0.8942)\n",
      "\u001b[32m[2020-07-15 18:09:42] __main__ INFO: \u001b[0mEpoch 38 Step 600/703 lr 0.100000 loss 1.0952 (0.9571) acc@1 0.5469 (0.6453) acc@5 0.9531 (0.8947)\n",
      "\u001b[32m[2020-07-15 18:10:14] __main__ INFO: \u001b[0mEpoch 38 Step 700/703 lr 0.100000 loss 1.0285 (0.9615) acc@1 0.6250 (0.6445) acc@5 0.9531 (0.8938)\n",
      "\u001b[32m[2020-07-15 18:10:15] __main__ INFO: \u001b[0mEpoch 38 Step 703/703 lr 0.100000 loss 0.8445 (0.9619) acc@1 0.7031 (0.6444) acc@5 0.9062 (0.8937)\n",
      "\u001b[32m[2020-07-15 18:10:15] __main__ INFO: \u001b[0mElapsed 225.19\n",
      "\u001b[32m[2020-07-15 18:10:15] __main__ INFO: \u001b[0mVal 38\n",
      "\u001b[32m[2020-07-15 18:10:23] __main__ INFO: \u001b[0mEpoch 38 loss 1.1513 acc@1 0.5916 acc@5 0.8856\n",
      "\u001b[32m[2020-07-15 18:10:23] __main__ INFO: \u001b[0mElapsed 7.74\n",
      "\u001b[32m[2020-07-15 18:10:23] __main__ INFO: \u001b[0mTrain 39 26714\n",
      "\u001b[32m[2020-07-15 18:10:55] __main__ INFO: \u001b[0mEpoch 39 Step 100/703 lr 0.100000 loss 0.9612 (0.9308) acc@1 0.6562 (0.6561) acc@5 0.9375 (0.8966)\n",
      "\u001b[32m[2020-07-15 18:11:27] __main__ INFO: \u001b[0mEpoch 39 Step 200/703 lr 0.100000 loss 0.7988 (0.9295) acc@1 0.7500 (0.6573) acc@5 0.8906 (0.8970)\n",
      "\u001b[32m[2020-07-15 18:11:59] __main__ INFO: \u001b[0mEpoch 39 Step 300/703 lr 0.100000 loss 0.8956 (0.9391) acc@1 0.6562 (0.6549) acc@5 0.8750 (0.8966)\n",
      "\u001b[32m[2020-07-15 18:12:31] __main__ INFO: \u001b[0mEpoch 39 Step 400/703 lr 0.100000 loss 0.9131 (0.9439) acc@1 0.7344 (0.6542) acc@5 0.9531 (0.8972)\n",
      "\u001b[32m[2020-07-15 18:13:03] __main__ INFO: \u001b[0mEpoch 39 Step 500/703 lr 0.100000 loss 1.0675 (0.9529) acc@1 0.5781 (0.6503) acc@5 0.8750 (0.8958)\n",
      "\u001b[32m[2020-07-15 18:13:35] __main__ INFO: \u001b[0mEpoch 39 Step 600/703 lr 0.100000 loss 0.8775 (0.9607) acc@1 0.6875 (0.6476) acc@5 0.8906 (0.8945)\n",
      "\u001b[32m[2020-07-15 18:14:07] __main__ INFO: \u001b[0mEpoch 39 Step 700/703 lr 0.100000 loss 0.8679 (0.9615) acc@1 0.7031 (0.6476) acc@5 0.9062 (0.8938)\n",
      "\u001b[32m[2020-07-15 18:14:08] __main__ INFO: \u001b[0mEpoch 39 Step 703/703 lr 0.100000 loss 1.4198 (0.9625) acc@1 0.5000 (0.6472) acc@5 0.8281 (0.8936)\n",
      "\u001b[32m[2020-07-15 18:14:08] __main__ INFO: \u001b[0mElapsed 225.11\n",
      "\u001b[32m[2020-07-15 18:14:08] __main__ INFO: \u001b[0mVal 39\n",
      "\u001b[32m[2020-07-15 18:14:15] __main__ INFO: \u001b[0mEpoch 39 loss 1.1305 acc@1 0.5998 acc@5 0.8858\n",
      "\u001b[32m[2020-07-15 18:14:15] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-15 18:14:15] __main__ INFO: \u001b[0mTrain 40 27417\n",
      "\u001b[32m[2020-07-15 18:14:48] __main__ INFO: \u001b[0mEpoch 40 Step 100/703 lr 0.100000 loss 1.0100 (0.9380) acc@1 0.6562 (0.6567) acc@5 0.8594 (0.8989)\n",
      "\u001b[32m[2020-07-15 18:15:20] __main__ INFO: \u001b[0mEpoch 40 Step 200/703 lr 0.100000 loss 0.7191 (0.9441) acc@1 0.7188 (0.6530) acc@5 0.8906 (0.8956)\n",
      "\u001b[32m[2020-07-15 18:15:52] __main__ INFO: \u001b[0mEpoch 40 Step 300/703 lr 0.100000 loss 1.0397 (0.9420) acc@1 0.5938 (0.6533) acc@5 0.8594 (0.8968)\n",
      "\u001b[32m[2020-07-15 18:16:24] __main__ INFO: \u001b[0mEpoch 40 Step 400/703 lr 0.100000 loss 0.8399 (0.9462) acc@1 0.6250 (0.6527) acc@5 0.9375 (0.8953)\n",
      "\u001b[32m[2020-07-15 18:16:56] __main__ INFO: \u001b[0mEpoch 40 Step 500/703 lr 0.100000 loss 1.0005 (0.9466) acc@1 0.6562 (0.6523) acc@5 0.8906 (0.8951)\n",
      "\u001b[32m[2020-07-15 18:17:28] __main__ INFO: \u001b[0mEpoch 40 Step 600/703 lr 0.100000 loss 1.1131 (0.9510) acc@1 0.5781 (0.6517) acc@5 0.8594 (0.8957)\n",
      "\u001b[32m[2020-07-15 18:18:00] __main__ INFO: \u001b[0mEpoch 40 Step 700/703 lr 0.100000 loss 0.9060 (0.9574) acc@1 0.7031 (0.6489) acc@5 0.9375 (0.8945)\n",
      "\u001b[32m[2020-07-15 18:18:01] __main__ INFO: \u001b[0mEpoch 40 Step 703/703 lr 0.100000 loss 0.8740 (0.9577) acc@1 0.7031 (0.6488) acc@5 0.9062 (0.8944)\n",
      "\u001b[32m[2020-07-15 18:18:01] __main__ INFO: \u001b[0mElapsed 225.55\n",
      "\u001b[32m[2020-07-15 18:18:01] __main__ INFO: \u001b[0mVal 40\n",
      "\u001b[32m[2020-07-15 18:18:09] __main__ INFO: \u001b[0mEpoch 40 loss 1.1768 acc@1 0.5818 acc@5 0.8776\n",
      "\u001b[32m[2020-07-15 18:18:09] __main__ INFO: \u001b[0mElapsed 7.73\n",
      "\u001b[32m[2020-07-15 18:18:09] __main__ INFO: \u001b[0mTrain 41 28120\n",
      "\u001b[32m[2020-07-15 18:18:41] __main__ INFO: \u001b[0mEpoch 41 Step 100/703 lr 0.100000 loss 1.1010 (0.9112) acc@1 0.5469 (0.6631) acc@5 0.8594 (0.8964)\n",
      "\u001b[32m[2020-07-15 18:19:13] __main__ INFO: \u001b[0mEpoch 41 Step 200/703 lr 0.100000 loss 1.0691 (0.9213) acc@1 0.5938 (0.6587) acc@5 0.9219 (0.8953)\n",
      "\u001b[32m[2020-07-15 18:19:45] __main__ INFO: \u001b[0mEpoch 41 Step 300/703 lr 0.100000 loss 1.1049 (0.9398) acc@1 0.5625 (0.6516) acc@5 0.8281 (0.8947)\n",
      "\u001b[32m[2020-07-15 18:20:17] __main__ INFO: \u001b[0mEpoch 41 Step 400/703 lr 0.100000 loss 0.7964 (0.9401) acc@1 0.7969 (0.6531) acc@5 0.8906 (0.8946)\n",
      "\u001b[32m[2020-07-15 18:20:49] __main__ INFO: \u001b[0mEpoch 41 Step 500/703 lr 0.100000 loss 0.8877 (0.9429) acc@1 0.7031 (0.6528) acc@5 0.9219 (0.8943)\n",
      "\u001b[32m[2020-07-15 18:21:21] __main__ INFO: \u001b[0mEpoch 41 Step 600/703 lr 0.100000 loss 0.8614 (0.9465) acc@1 0.6562 (0.6514) acc@5 0.8750 (0.8942)\n",
      "\u001b[32m[2020-07-15 18:21:53] __main__ INFO: \u001b[0mEpoch 41 Step 700/703 lr 0.100000 loss 0.8614 (0.9471) acc@1 0.7031 (0.6515) acc@5 0.9219 (0.8944)\n",
      "\u001b[32m[2020-07-15 18:21:54] __main__ INFO: \u001b[0mEpoch 41 Step 703/703 lr 0.100000 loss 1.0160 (0.9473) acc@1 0.5938 (0.6514) acc@5 0.9375 (0.8944)\n",
      "\u001b[32m[2020-07-15 18:21:54] __main__ INFO: \u001b[0mElapsed 225.33\n",
      "\u001b[32m[2020-07-15 18:21:54] __main__ INFO: \u001b[0mVal 41\n",
      "\u001b[32m[2020-07-15 18:22:02] __main__ INFO: \u001b[0mEpoch 41 loss 1.1379 acc@1 0.5936 acc@5 0.8794\n",
      "\u001b[32m[2020-07-15 18:22:02] __main__ INFO: \u001b[0mElapsed 7.74\n",
      "\u001b[32m[2020-07-15 18:22:02] __main__ INFO: \u001b[0mTrain 42 28823\n",
      "\u001b[32m[2020-07-15 18:22:34] __main__ INFO: \u001b[0mEpoch 42 Step 100/703 lr 0.100000 loss 0.8980 (0.9418) acc@1 0.6562 (0.6531) acc@5 0.9375 (0.8942)\n",
      "\u001b[32m[2020-07-15 18:23:06] __main__ INFO: \u001b[0mEpoch 42 Step 200/703 lr 0.100000 loss 0.9911 (0.9496) acc@1 0.5781 (0.6488) acc@5 0.8594 (0.8952)\n",
      "\u001b[32m[2020-07-15 18:23:38] __main__ INFO: \u001b[0mEpoch 42 Step 300/703 lr 0.100000 loss 1.1503 (0.9458) acc@1 0.5938 (0.6501) acc@5 0.8906 (0.8951)\n",
      "\u001b[32m[2020-07-15 18:24:10] __main__ INFO: \u001b[0mEpoch 42 Step 400/703 lr 0.100000 loss 0.9760 (0.9413) acc@1 0.6562 (0.6520) acc@5 0.9375 (0.8945)\n",
      "\u001b[32m[2020-07-15 18:24:42] __main__ INFO: \u001b[0mEpoch 42 Step 500/703 lr 0.100000 loss 1.0843 (0.9498) acc@1 0.6406 (0.6491) acc@5 0.8750 (0.8928)\n",
      "\u001b[32m[2020-07-15 18:25:14] __main__ INFO: \u001b[0mEpoch 42 Step 600/703 lr 0.100000 loss 0.8719 (0.9537) acc@1 0.6875 (0.6483) acc@5 0.8750 (0.8923)\n",
      "\u001b[32m[2020-07-15 18:25:46] __main__ INFO: \u001b[0mEpoch 42 Step 700/703 lr 0.100000 loss 0.7687 (0.9502) acc@1 0.6719 (0.6496) acc@5 0.9062 (0.8935)\n",
      "\u001b[32m[2020-07-15 18:25:47] __main__ INFO: \u001b[0mEpoch 42 Step 703/703 lr 0.100000 loss 0.8645 (0.9503) acc@1 0.6719 (0.6496) acc@5 0.8750 (0.8935)\n",
      "\u001b[32m[2020-07-15 18:25:47] __main__ INFO: \u001b[0mElapsed 225.32\n",
      "\u001b[32m[2020-07-15 18:25:47] __main__ INFO: \u001b[0mVal 42\n",
      "\u001b[32m[2020-07-15 18:25:55] __main__ INFO: \u001b[0mEpoch 42 loss 1.0836 acc@1 0.6118 acc@5 0.8768\n",
      "\u001b[32m[2020-07-15 18:25:55] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-15 18:25:55] __main__ INFO: \u001b[0mTrain 43 29526\n",
      "\u001b[32m[2020-07-15 18:26:27] __main__ INFO: \u001b[0mEpoch 43 Step 100/703 lr 0.100000 loss 0.9962 (0.9232) acc@1 0.6562 (0.6600) acc@5 0.9062 (0.8923)\n",
      "\u001b[32m[2020-07-15 18:26:59] __main__ INFO: \u001b[0mEpoch 43 Step 200/703 lr 0.100000 loss 0.9101 (0.9213) acc@1 0.6875 (0.6609) acc@5 0.9375 (0.8933)\n",
      "\u001b[32m[2020-07-15 18:27:31] __main__ INFO: \u001b[0mEpoch 43 Step 300/703 lr 0.100000 loss 0.9920 (0.9324) acc@1 0.6406 (0.6576) acc@5 0.9219 (0.8932)\n",
      "\u001b[32m[2020-07-15 18:28:03] __main__ INFO: \u001b[0mEpoch 43 Step 400/703 lr 0.100000 loss 1.0544 (0.9379) acc@1 0.5938 (0.6561) acc@5 0.8281 (0.8936)\n",
      "\u001b[32m[2020-07-15 18:28:35] __main__ INFO: \u001b[0mEpoch 43 Step 500/703 lr 0.100000 loss 0.9054 (0.9443) acc@1 0.6719 (0.6531) acc@5 0.8750 (0.8917)\n",
      "\u001b[32m[2020-07-15 18:29:07] __main__ INFO: \u001b[0mEpoch 43 Step 600/703 lr 0.100000 loss 1.0640 (0.9455) acc@1 0.6094 (0.6532) acc@5 0.8594 (0.8921)\n",
      "\u001b[32m[2020-07-15 18:29:39] __main__ INFO: \u001b[0mEpoch 43 Step 700/703 lr 0.100000 loss 1.0683 (0.9482) acc@1 0.5625 (0.6521) acc@5 0.8281 (0.8919)\n",
      "\u001b[32m[2020-07-15 18:29:40] __main__ INFO: \u001b[0mEpoch 43 Step 703/703 lr 0.100000 loss 1.0815 (0.9486) acc@1 0.5781 (0.6518) acc@5 0.8750 (0.8918)\n",
      "\u001b[32m[2020-07-15 18:29:40] __main__ INFO: \u001b[0mElapsed 225.00\n",
      "\u001b[32m[2020-07-15 18:29:40] __main__ INFO: \u001b[0mVal 43\n",
      "\u001b[32m[2020-07-15 18:29:48] __main__ INFO: \u001b[0mEpoch 43 loss 1.0837 acc@1 0.6072 acc@5 0.8860\n",
      "\u001b[32m[2020-07-15 18:29:48] __main__ INFO: \u001b[0mElapsed 7.71\n",
      "\u001b[32m[2020-07-15 18:29:48] __main__ INFO: \u001b[0mTrain 44 30229\n",
      "\u001b[32m[2020-07-15 18:30:20] __main__ INFO: \u001b[0mEpoch 44 Step 100/703 lr 0.100000 loss 1.0044 (0.9311) acc@1 0.6562 (0.6620) acc@5 0.9219 (0.8934)\n",
      "\u001b[32m[2020-07-15 18:30:52] __main__ INFO: \u001b[0mEpoch 44 Step 200/703 lr 0.100000 loss 0.8736 (0.9250) acc@1 0.6875 (0.6625) acc@5 0.8906 (0.8955)\n",
      "\u001b[32m[2020-07-15 18:31:24] __main__ INFO: \u001b[0mEpoch 44 Step 300/703 lr 0.100000 loss 0.8617 (0.9276) acc@1 0.6875 (0.6609) acc@5 0.9062 (0.8957)\n",
      "\u001b[32m[2020-07-15 18:31:56] __main__ INFO: \u001b[0mEpoch 44 Step 400/703 lr 0.100000 loss 0.9755 (0.9351) acc@1 0.5938 (0.6578) acc@5 0.8594 (0.8943)\n",
      "\u001b[32m[2020-07-15 18:32:28] __main__ INFO: \u001b[0mEpoch 44 Step 500/703 lr 0.100000 loss 1.0049 (0.9339) acc@1 0.6562 (0.6583) acc@5 0.9219 (0.8947)\n",
      "\u001b[32m[2020-07-15 18:33:00] __main__ INFO: \u001b[0mEpoch 44 Step 600/703 lr 0.100000 loss 1.0034 (0.9383) acc@1 0.5625 (0.6552) acc@5 0.8750 (0.8939)\n",
      "\u001b[32m[2020-07-15 18:33:32] __main__ INFO: \u001b[0mEpoch 44 Step 700/703 lr 0.100000 loss 0.9970 (0.9413) acc@1 0.6562 (0.6541) acc@5 0.9062 (0.8946)\n",
      "\u001b[32m[2020-07-15 18:33:33] __main__ INFO: \u001b[0mEpoch 44 Step 703/703 lr 0.100000 loss 0.9482 (0.9413) acc@1 0.5938 (0.6540) acc@5 0.9062 (0.8946)\n",
      "\u001b[32m[2020-07-15 18:33:33] __main__ INFO: \u001b[0mElapsed 224.91\n",
      "\u001b[32m[2020-07-15 18:33:33] __main__ INFO: \u001b[0mVal 44\n",
      "\u001b[32m[2020-07-15 18:33:40] __main__ INFO: \u001b[0mEpoch 44 loss 1.1146 acc@1 0.5962 acc@5 0.8816\n",
      "\u001b[32m[2020-07-15 18:33:40] __main__ INFO: \u001b[0mElapsed 7.73\n",
      "\u001b[32m[2020-07-15 18:33:40] __main__ INFO: \u001b[0mTrain 45 30932\n",
      "\u001b[32m[2020-07-15 18:34:12] __main__ INFO: \u001b[0mEpoch 45 Step 100/703 lr 0.100000 loss 0.9928 (0.9025) acc@1 0.6875 (0.6656) acc@5 0.8750 (0.8991)\n",
      "\u001b[32m[2020-07-15 18:34:44] __main__ INFO: \u001b[0mEpoch 45 Step 200/703 lr 0.100000 loss 1.1343 (0.9168) acc@1 0.5938 (0.6637) acc@5 0.8438 (0.8963)\n",
      "\u001b[32m[2020-07-15 18:35:16] __main__ INFO: \u001b[0mEpoch 45 Step 300/703 lr 0.100000 loss 1.1482 (0.9181) acc@1 0.5938 (0.6609) acc@5 0.7500 (0.8946)\n",
      "\u001b[32m[2020-07-15 18:35:48] __main__ INFO: \u001b[0mEpoch 45 Step 400/703 lr 0.100000 loss 1.0453 (0.9288) acc@1 0.6250 (0.6590) acc@5 0.8594 (0.8934)\n",
      "\u001b[32m[2020-07-15 18:36:20] __main__ INFO: \u001b[0mEpoch 45 Step 500/703 lr 0.100000 loss 0.6583 (0.9341) acc@1 0.7969 (0.6572) acc@5 0.9375 (0.8927)\n",
      "\u001b[32m[2020-07-15 18:36:52] __main__ INFO: \u001b[0mEpoch 45 Step 600/703 lr 0.100000 loss 0.9199 (0.9341) acc@1 0.6250 (0.6574) acc@5 0.9375 (0.8934)\n",
      "\u001b[32m[2020-07-15 18:37:24] __main__ INFO: \u001b[0mEpoch 45 Step 700/703 lr 0.100000 loss 0.8587 (0.9387) acc@1 0.6562 (0.6559) acc@5 0.9375 (0.8932)\n",
      "\u001b[32m[2020-07-15 18:37:25] __main__ INFO: \u001b[0mEpoch 45 Step 703/703 lr 0.100000 loss 1.0603 (0.9393) acc@1 0.5625 (0.6556) acc@5 0.9219 (0.8932)\n",
      "\u001b[32m[2020-07-15 18:37:25] __main__ INFO: \u001b[0mElapsed 225.00\n",
      "\u001b[32m[2020-07-15 18:37:25] __main__ INFO: \u001b[0mVal 45\n",
      "\u001b[32m[2020-07-15 18:37:33] __main__ INFO: \u001b[0mEpoch 45 loss 1.0621 acc@1 0.6226 acc@5 0.8810\n",
      "\u001b[32m[2020-07-15 18:37:33] __main__ INFO: \u001b[0mElapsed 7.71\n",
      "\u001b[32m[2020-07-15 18:37:33] __main__ INFO: \u001b[0mTrain 46 31635\n",
      "\u001b[32m[2020-07-15 18:38:05] __main__ INFO: \u001b[0mEpoch 46 Step 100/703 lr 0.100000 loss 0.8286 (0.9036) acc@1 0.7031 (0.6606) acc@5 0.9375 (0.9000)\n",
      "\u001b[32m[2020-07-15 18:38:37] __main__ INFO: \u001b[0mEpoch 46 Step 200/703 lr 0.100000 loss 0.9500 (0.9187) acc@1 0.6875 (0.6569) acc@5 0.8750 (0.8952)\n",
      "\u001b[32m[2020-07-15 18:39:09] __main__ INFO: \u001b[0mEpoch 46 Step 300/703 lr 0.100000 loss 0.8011 (0.9226) acc@1 0.7188 (0.6564) acc@5 0.9219 (0.8944)\n",
      "\u001b[32m[2020-07-15 18:39:41] __main__ INFO: \u001b[0mEpoch 46 Step 400/703 lr 0.100000 loss 1.1962 (0.9236) acc@1 0.5156 (0.6562) acc@5 0.8594 (0.8955)\n",
      "\u001b[32m[2020-07-15 18:40:13] __main__ INFO: \u001b[0mEpoch 46 Step 500/703 lr 0.100000 loss 1.1281 (0.9288) acc@1 0.4844 (0.6540) acc@5 0.8438 (0.8942)\n",
      "\u001b[32m[2020-07-15 18:40:45] __main__ INFO: \u001b[0mEpoch 46 Step 600/703 lr 0.100000 loss 0.9034 (0.9322) acc@1 0.6562 (0.6532) acc@5 0.8750 (0.8938)\n",
      "\u001b[32m[2020-07-15 18:41:17] __main__ INFO: \u001b[0mEpoch 46 Step 700/703 lr 0.100000 loss 1.0422 (0.9352) acc@1 0.6250 (0.6529) acc@5 0.9219 (0.8932)\n",
      "\u001b[32m[2020-07-15 18:41:18] __main__ INFO: \u001b[0mEpoch 46 Step 703/703 lr 0.100000 loss 0.8019 (0.9351) acc@1 0.7344 (0.6529) acc@5 0.9219 (0.8933)\n",
      "\u001b[32m[2020-07-15 18:41:18] __main__ INFO: \u001b[0mElapsed 224.73\n",
      "\u001b[32m[2020-07-15 18:41:18] __main__ INFO: \u001b[0mVal 46\n",
      "\u001b[32m[2020-07-15 18:41:25] __main__ INFO: \u001b[0mEpoch 46 loss 1.0956 acc@1 0.6032 acc@5 0.8818\n",
      "\u001b[32m[2020-07-15 18:41:25] __main__ INFO: \u001b[0mElapsed 7.69\n",
      "\u001b[32m[2020-07-15 18:41:25] __main__ INFO: \u001b[0mTrain 47 32338\n",
      "\u001b[32m[2020-07-15 18:41:57] __main__ INFO: \u001b[0mEpoch 47 Step 100/703 lr 0.100000 loss 0.8845 (0.9035) acc@1 0.6875 (0.6625) acc@5 0.8906 (0.9002)\n",
      "\u001b[32m[2020-07-15 18:42:29] __main__ INFO: \u001b[0mEpoch 47 Step 200/703 lr 0.100000 loss 0.9791 (0.9125) acc@1 0.6719 (0.6605) acc@5 0.9062 (0.8985)\n",
      "\u001b[32m[2020-07-15 18:43:01] __main__ INFO: \u001b[0mEpoch 47 Step 300/703 lr 0.100000 loss 0.8209 (0.9173) acc@1 0.7031 (0.6596) acc@5 0.9688 (0.8981)\n",
      "\u001b[32m[2020-07-15 18:43:33] __main__ INFO: \u001b[0mEpoch 47 Step 400/703 lr 0.100000 loss 1.0193 (0.9204) acc@1 0.5469 (0.6567) acc@5 0.8438 (0.8973)\n",
      "\u001b[32m[2020-07-15 18:44:05] __main__ INFO: \u001b[0mEpoch 47 Step 500/703 lr 0.100000 loss 0.9980 (0.9316) acc@1 0.6719 (0.6545) acc@5 0.9062 (0.8963)\n",
      "\u001b[32m[2020-07-15 18:44:37] __main__ INFO: \u001b[0mEpoch 47 Step 600/703 lr 0.100000 loss 1.1333 (0.9319) acc@1 0.5469 (0.6546) acc@5 0.8906 (0.8959)\n",
      "\u001b[32m[2020-07-15 18:45:09] __main__ INFO: \u001b[0mEpoch 47 Step 700/703 lr 0.100000 loss 0.6450 (0.9302) acc@1 0.7656 (0.6569) acc@5 0.8906 (0.8961)\n",
      "\u001b[32m[2020-07-15 18:45:10] __main__ INFO: \u001b[0mEpoch 47 Step 703/703 lr 0.100000 loss 1.5086 (0.9312) acc@1 0.4844 (0.6565) acc@5 0.9375 (0.8962)\n",
      "\u001b[32m[2020-07-15 18:45:10] __main__ INFO: \u001b[0mElapsed 224.53\n",
      "\u001b[32m[2020-07-15 18:45:10] __main__ INFO: \u001b[0mVal 47\n",
      "\u001b[32m[2020-07-15 18:45:18] __main__ INFO: \u001b[0mEpoch 47 loss 1.0816 acc@1 0.6140 acc@5 0.8792\n",
      "\u001b[32m[2020-07-15 18:45:18] __main__ INFO: \u001b[0mElapsed 7.73\n",
      "\u001b[32m[2020-07-15 18:45:18] __main__ INFO: \u001b[0mTrain 48 33041\n",
      "\u001b[32m[2020-07-15 18:45:50] __main__ INFO: \u001b[0mEpoch 48 Step 100/703 lr 0.100000 loss 0.8533 (0.9134) acc@1 0.7031 (0.6663) acc@5 0.8750 (0.8975)\n",
      "\u001b[32m[2020-07-15 18:46:22] __main__ INFO: \u001b[0mEpoch 48 Step 200/703 lr 0.100000 loss 1.2123 (0.9282) acc@1 0.5156 (0.6574) acc@5 0.8750 (0.8936)\n",
      "\u001b[32m[2020-07-15 18:46:54] __main__ INFO: \u001b[0mEpoch 48 Step 300/703 lr 0.100000 loss 0.9503 (0.9347) acc@1 0.6250 (0.6535) acc@5 0.8750 (0.8940)\n",
      "\u001b[32m[2020-07-15 18:47:26] __main__ INFO: \u001b[0mEpoch 48 Step 400/703 lr 0.100000 loss 1.2697 (0.9269) acc@1 0.6094 (0.6573) acc@5 0.9531 (0.8946)\n",
      "\u001b[32m[2020-07-15 18:47:58] __main__ INFO: \u001b[0mEpoch 48 Step 500/703 lr 0.100000 loss 0.9168 (0.9304) acc@1 0.6562 (0.6561) acc@5 0.9062 (0.8953)\n",
      "\u001b[32m[2020-07-15 18:48:30] __main__ INFO: \u001b[0mEpoch 48 Step 600/703 lr 0.100000 loss 1.0290 (0.9330) acc@1 0.6562 (0.6553) acc@5 0.9375 (0.8953)\n",
      "\u001b[32m[2020-07-15 18:49:02] __main__ INFO: \u001b[0mEpoch 48 Step 700/703 lr 0.100000 loss 0.9950 (0.9314) acc@1 0.6094 (0.6559) acc@5 0.9219 (0.8954)\n",
      "\u001b[32m[2020-07-15 18:49:02] __main__ INFO: \u001b[0mEpoch 48 Step 703/703 lr 0.100000 loss 0.8754 (0.9315) acc@1 0.6719 (0.6558) acc@5 0.8906 (0.8954)\n",
      "\u001b[32m[2020-07-15 18:49:02] __main__ INFO: \u001b[0mElapsed 224.80\n",
      "\u001b[32m[2020-07-15 18:49:02] __main__ INFO: \u001b[0mVal 48\n",
      "\u001b[32m[2020-07-15 18:49:10] __main__ INFO: \u001b[0mEpoch 48 loss 1.1590 acc@1 0.5944 acc@5 0.8790\n",
      "\u001b[32m[2020-07-15 18:49:10] __main__ INFO: \u001b[0mElapsed 7.74\n",
      "\u001b[32m[2020-07-15 18:49:10] __main__ INFO: \u001b[0mTrain 49 33744\n",
      "\u001b[32m[2020-07-15 18:49:42] __main__ INFO: \u001b[0mEpoch 49 Step 100/703 lr 0.100000 loss 0.9203 (0.8983) acc@1 0.6719 (0.6677) acc@5 0.9531 (0.8956)\n",
      "\u001b[32m[2020-07-15 18:50:14] __main__ INFO: \u001b[0mEpoch 49 Step 200/703 lr 0.100000 loss 0.9698 (0.9110) acc@1 0.6250 (0.6633) acc@5 0.8906 (0.8930)\n",
      "\u001b[32m[2020-07-15 18:50:46] __main__ INFO: \u001b[0mEpoch 49 Step 300/703 lr 0.100000 loss 0.8418 (0.9185) acc@1 0.6562 (0.6587) acc@5 0.9375 (0.8928)\n",
      "\u001b[32m[2020-07-15 18:51:18] __main__ INFO: \u001b[0mEpoch 49 Step 400/703 lr 0.100000 loss 0.6758 (0.9232) acc@1 0.7188 (0.6573) acc@5 0.8906 (0.8930)\n",
      "\u001b[32m[2020-07-15 18:51:51] __main__ INFO: \u001b[0mEpoch 49 Step 500/703 lr 0.100000 loss 1.1932 (0.9256) acc@1 0.5469 (0.6567) acc@5 0.8750 (0.8941)\n",
      "\u001b[32m[2020-07-15 18:52:23] __main__ INFO: \u001b[0mEpoch 49 Step 600/703 lr 0.100000 loss 1.0533 (0.9287) acc@1 0.6406 (0.6561) acc@5 0.9062 (0.8940)\n",
      "\u001b[32m[2020-07-15 18:52:54] __main__ INFO: \u001b[0mEpoch 49 Step 700/703 lr 0.100000 loss 0.8178 (0.9292) acc@1 0.6562 (0.6560) acc@5 0.8906 (0.8945)\n",
      "\u001b[32m[2020-07-15 18:52:55] __main__ INFO: \u001b[0mEpoch 49 Step 703/703 lr 0.100000 loss 0.9531 (0.9295) acc@1 0.6875 (0.6560) acc@5 0.8906 (0.8945)\n",
      "\u001b[32m[2020-07-15 18:52:55] __main__ INFO: \u001b[0mElapsed 225.20\n",
      "\u001b[32m[2020-07-15 18:52:55] __main__ INFO: \u001b[0mVal 49\n",
      "\u001b[32m[2020-07-15 18:53:03] __main__ INFO: \u001b[0mEpoch 49 loss 1.0820 acc@1 0.6154 acc@5 0.8876\n",
      "\u001b[32m[2020-07-15 18:53:03] __main__ INFO: \u001b[0mElapsed 7.73\n",
      "\u001b[32m[2020-07-15 18:53:03] __main__ INFO: \u001b[0mTrain 50 34447\n",
      "\u001b[32m[2020-07-15 18:53:35] __main__ INFO: \u001b[0mEpoch 50 Step 100/703 lr 0.100000 loss 0.9132 (0.8901) acc@1 0.6562 (0.6706) acc@5 0.9062 (0.9008)\n",
      "\u001b[32m[2020-07-15 18:54:07] __main__ INFO: \u001b[0mEpoch 50 Step 200/703 lr 0.100000 loss 0.8359 (0.9040) acc@1 0.7344 (0.6673) acc@5 0.9062 (0.8989)\n",
      "\u001b[32m[2020-07-15 18:54:39] __main__ INFO: \u001b[0mEpoch 50 Step 300/703 lr 0.100000 loss 0.9658 (0.9127) acc@1 0.6406 (0.6651) acc@5 0.9062 (0.8971)\n",
      "\u001b[32m[2020-07-15 18:55:11] __main__ INFO: \u001b[0mEpoch 50 Step 400/703 lr 0.100000 loss 1.0237 (0.9113) acc@1 0.5625 (0.6666) acc@5 0.9219 (0.8984)\n",
      "\u001b[32m[2020-07-15 18:55:43] __main__ INFO: \u001b[0mEpoch 50 Step 500/703 lr 0.100000 loss 0.9237 (0.9159) acc@1 0.6250 (0.6642) acc@5 0.8906 (0.8974)\n",
      "\u001b[32m[2020-07-15 18:56:15] __main__ INFO: \u001b[0mEpoch 50 Step 600/703 lr 0.100000 loss 1.0199 (0.9197) acc@1 0.6250 (0.6621) acc@5 0.8125 (0.8963)\n",
      "\u001b[32m[2020-07-15 18:56:47] __main__ INFO: \u001b[0mEpoch 50 Step 700/703 lr 0.100000 loss 1.0452 (0.9257) acc@1 0.6406 (0.6604) acc@5 0.8750 (0.8954)\n",
      "\u001b[32m[2020-07-15 18:56:48] __main__ INFO: \u001b[0mEpoch 50 Step 703/703 lr 0.100000 loss 1.3164 (0.9262) acc@1 0.5625 (0.6604) acc@5 0.8906 (0.8956)\n",
      "\u001b[32m[2020-07-15 18:56:48] __main__ INFO: \u001b[0mElapsed 224.68\n",
      "\u001b[32m[2020-07-15 18:56:48] __main__ INFO: \u001b[0mVal 50\n",
      "\u001b[32m[2020-07-15 18:56:56] __main__ INFO: \u001b[0mEpoch 50 loss 1.1505 acc@1 0.6016 acc@5 0.8768\n",
      "\u001b[32m[2020-07-15 18:56:56] __main__ INFO: \u001b[0mElapsed 7.73\n",
      "\u001b[32m[2020-07-15 18:56:56] __main__ INFO: \u001b[0mTrain 51 35150\n",
      "\u001b[32m[2020-07-15 18:57:28] __main__ INFO: \u001b[0mEpoch 51 Step 100/703 lr 0.100000 loss 0.6512 (0.8797) acc@1 0.7188 (0.6717) acc@5 0.9219 (0.8934)\n",
      "\u001b[32m[2020-07-15 18:57:59] __main__ INFO: \u001b[0mEpoch 51 Step 200/703 lr 0.100000 loss 0.8288 (0.8945) acc@1 0.6875 (0.6650) acc@5 0.9062 (0.8945)\n",
      "\u001b[32m[2020-07-15 18:58:31] __main__ INFO: \u001b[0mEpoch 51 Step 300/703 lr 0.100000 loss 0.7499 (0.9063) acc@1 0.7969 (0.6621) acc@5 0.8906 (0.8953)\n",
      "\u001b[32m[2020-07-15 18:59:03] __main__ INFO: \u001b[0mEpoch 51 Step 400/703 lr 0.100000 loss 0.8345 (0.9142) acc@1 0.6875 (0.6607) acc@5 0.8906 (0.8946)\n",
      "\u001b[32m[2020-07-15 18:59:35] __main__ INFO: \u001b[0mEpoch 51 Step 500/703 lr 0.100000 loss 0.7637 (0.9156) acc@1 0.7031 (0.6608) acc@5 0.9375 (0.8951)\n",
      "\u001b[32m[2020-07-15 19:00:07] __main__ INFO: \u001b[0mEpoch 51 Step 600/703 lr 0.100000 loss 0.7923 (0.9156) acc@1 0.7188 (0.6616) acc@5 0.9062 (0.8942)\n",
      "\u001b[32m[2020-07-15 19:00:39] __main__ INFO: \u001b[0mEpoch 51 Step 700/703 lr 0.100000 loss 0.9561 (0.9194) acc@1 0.6094 (0.6596) acc@5 0.9219 (0.8946)\n",
      "\u001b[32m[2020-07-15 19:00:40] __main__ INFO: \u001b[0mEpoch 51 Step 703/703 lr 0.100000 loss 0.9753 (0.9198) acc@1 0.6094 (0.6594) acc@5 0.9375 (0.8945)\n",
      "\u001b[32m[2020-07-15 19:00:40] __main__ INFO: \u001b[0mElapsed 224.68\n",
      "\u001b[32m[2020-07-15 19:00:40] __main__ INFO: \u001b[0mVal 51\n",
      "\u001b[32m[2020-07-15 19:00:48] __main__ INFO: \u001b[0mEpoch 51 loss 1.0590 acc@1 0.6218 acc@5 0.8874\n",
      "\u001b[32m[2020-07-15 19:00:48] __main__ INFO: \u001b[0mElapsed 7.70\n",
      "\u001b[32m[2020-07-15 19:00:48] __main__ INFO: \u001b[0mTrain 52 35853\n",
      "\u001b[32m[2020-07-15 19:01:20] __main__ INFO: \u001b[0mEpoch 52 Step 100/703 lr 0.100000 loss 0.7537 (0.8750) acc@1 0.6875 (0.6767) acc@5 0.9375 (0.9012)\n",
      "\u001b[32m[2020-07-15 19:01:52] __main__ INFO: \u001b[0mEpoch 52 Step 200/703 lr 0.100000 loss 0.7457 (0.9087) acc@1 0.7344 (0.6659) acc@5 0.9375 (0.8978)\n",
      "\u001b[32m[2020-07-15 19:02:24] __main__ INFO: \u001b[0mEpoch 52 Step 300/703 lr 0.100000 loss 0.7209 (0.9079) acc@1 0.7188 (0.6669) acc@5 0.9531 (0.8991)\n",
      "\u001b[32m[2020-07-15 19:02:56] __main__ INFO: \u001b[0mEpoch 52 Step 400/703 lr 0.100000 loss 0.8328 (0.9065) acc@1 0.7188 (0.6676) acc@5 0.8438 (0.8971)\n",
      "\u001b[32m[2020-07-15 19:03:28] __main__ INFO: \u001b[0mEpoch 52 Step 500/703 lr 0.100000 loss 0.9669 (0.9124) acc@1 0.6562 (0.6650) acc@5 0.9062 (0.8966)\n",
      "\u001b[32m[2020-07-15 19:04:00] __main__ INFO: \u001b[0mEpoch 52 Step 600/703 lr 0.100000 loss 0.9191 (0.9143) acc@1 0.7031 (0.6631) acc@5 0.9531 (0.8959)\n"
     ]
    }
   ],
   "source": [
    "# Train the model per the settings specified in the original paper\n",
    "os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "!python train.py --config configs/cifar/densenet.yaml \\\n",
    "    model.densenet.depth 100 \\\n",
    "    model.densenet.growth_rate 12 \\\n",
    "    train.batch_size 64 \\\n",
    "    train.base_lr 0.1 \\\n",
    "    dataset.name CIFAR10_RA_1_20 \\\n",
    "    train.output_dir /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_1_20_c10val/exp00 \\\n",
    "    scheduler.epochs 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refine the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-16 17:32:26] __main__ INFO: \u001b[0mdevice: cuda\n",
      "cudnn:\n",
      "  benchmark: True\n",
      "  deterministic: False\n",
      "dataset:\n",
      "  name: CIFAR10\n",
      "  dataset_dir: ~/.torch/datasets/CIFAR10\n",
      "  image_size: 32\n",
      "  n_channels: 3\n",
      "  n_classes: 10\n",
      "model:\n",
      "  type: cifar\n",
      "  name: densenet\n",
      "  init_mode: kaiming_fan_out\n",
      "  vgg:\n",
      "    n_channels: [64, 128, 256, 512, 512]\n",
      "    n_layers: [2, 2, 3, 3, 3]\n",
      "    use_bn: True\n",
      "  resnet:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "  resnet_preact:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "  wrn:\n",
      "    depth: 28\n",
      "    initial_channels: 16\n",
      "    widening_factor: 10\n",
      "    drop_rate: 0.0\n",
      "  densenet:\n",
      "    depth: 100\n",
      "    n_blocks: [6, 12, 24, 16]\n",
      "    block_type: bottleneck\n",
      "    growth_rate: 12\n",
      "    drop_rate: 0.0\n",
      "    compression_rate: 0.5\n",
      "  pyramidnet:\n",
      "    depth: 272\n",
      "    n_blocks: [3, 24, 36, 3]\n",
      "    initial_channels: 16\n",
      "    block_type: bottleneck\n",
      "    alpha: 200\n",
      "  resnext:\n",
      "    depth: 29\n",
      "    n_blocks: [3, 4, 6, 3]\n",
      "    initial_channels: 64\n",
      "    cardinality: 8\n",
      "    base_channels: 4\n",
      "  shake_shake:\n",
      "    depth: 26\n",
      "    initial_channels: 96\n",
      "    shake_forward: True\n",
      "    shake_backward: True\n",
      "    shake_image: True\n",
      "  se_resnet_preact:\n",
      "    depth: 110\n",
      "    initial_channels: 16\n",
      "    se_reduction: 16\n",
      "    block_type: basic\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "train:\n",
      "  checkpoint: /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_1_20_c10val/exp00/checkpoint_00400.pth\n",
      "  resume: False\n",
      "  precision: O0\n",
      "  batch_size: 64\n",
      "  subdivision: 1\n",
      "  optimizer: sgd\n",
      "  base_lr: 0.001\n",
      "  momentum: 0.9\n",
      "  nesterov: True\n",
      "  weight_decay: 0.0001\n",
      "  no_weight_decay_on_bn: False\n",
      "  gradient_clip: 0\n",
      "  start_epoch: 0\n",
      "  seed: 0\n",
      "  val_first: True\n",
      "  val_period: 1\n",
      "  val_ratio: 0.1\n",
      "  use_test_as_val: False\n",
      "  output_dir: /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_1_20_c10val/exp00_resume400_50\n",
      "  log_period: 100\n",
      "  checkpoint_period: 100\n",
      "  use_tensorboard: True\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: True\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "  distributed: False\n",
      "  dist:\n",
      "    backend: nccl\n",
      "    init_method: env://\n",
      "    world_size: -1\n",
      "    node_rank: -1\n",
      "    local_rank: 0\n",
      "    use_sync_bn: False\n",
      "tensorboard:\n",
      "  train_images: False\n",
      "  val_images: False\n",
      "  model_params: False\n",
      "optim:\n",
      "  adam:\n",
      "    betas: (0.9, 0.999)\n",
      "  lars:\n",
      "    eps: 1e-09\n",
      "    threshold: 0.01\n",
      "  adabound:\n",
      "    betas: (0.9, 0.999)\n",
      "    final_lr: 0.1\n",
      "    gamma: 0.001\n",
      "scheduler:\n",
      "  epochs: 50\n",
      "  warmup:\n",
      "    type: none\n",
      "    epochs: 0\n",
      "    start_factor: 0.001\n",
      "    exponent: 4\n",
      "  type: multistep\n",
      "  milestones: [150, 225]\n",
      "  lr_decay: 0.1\n",
      "  lr_min_factor: 0.001\n",
      "  T0: 10\n",
      "  T_mul: 1.0\n",
      "validation:\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: False\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "augmentation:\n",
      "  use_random_crop: True\n",
      "  use_random_horizontal_flip: True\n",
      "  use_cutout: False\n",
      "  use_random_erasing: False\n",
      "  use_dual_cutout: False\n",
      "  use_mixup: False\n",
      "  use_ricap: False\n",
      "  use_cutmix: False\n",
      "  use_label_smoothing: False\n",
      "  random_crop:\n",
      "    padding: 4\n",
      "    fill: 0\n",
      "    padding_mode: constant\n",
      "  random_horizontal_flip:\n",
      "    prob: 0.5\n",
      "  cutout:\n",
      "    prob: 1.0\n",
      "    mask_size: 16\n",
      "    cut_inside: False\n",
      "    mask_color: 0\n",
      "    dual_cutout_alpha: 0.1\n",
      "  random_erasing:\n",
      "    prob: 0.5\n",
      "    area_ratio_range: [0.02, 0.4]\n",
      "    min_aspect_ratio: 0.3\n",
      "    max_attempt: 20\n",
      "  mixup:\n",
      "    alpha: 1.0\n",
      "  ricap:\n",
      "    beta: 0.3\n",
      "  cutmix:\n",
      "    alpha: 1.0\n",
      "  label_smoothing:\n",
      "    epsilon: 0.1\n",
      "tta:\n",
      "  use_resize: False\n",
      "  use_center_crop: False\n",
      "  resize: 256\n",
      "test:\n",
      "  checkpoint: ''\n",
      "  output_dir: ''\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    pin_memory: False\n",
      "\u001b[32m[2020-07-16 17:32:26] __main__ INFO: \u001b[0menv_info:\n",
      "  pytorch_version: 1.4.0\n",
      "  cuda_version: 10.1\n",
      "  cudnn_version: 7603\n",
      "  num_gpus: 1\n",
      "  gpu_name: Tesla K80\n",
      "  gpu_capability: 3.7\n",
      "Files already downloaded and verified\n",
      "\u001b[32m[2020-07-16 17:32:29] __main__ INFO: \u001b[0mMACs  : 296.49M\n",
      "\u001b[32m[2020-07-16 17:32:29] __main__ INFO: \u001b[0m#params: 769.16K\n",
      "Selected optimization level O0:  Pure FP32 training.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n",
      "\u001b[32m[2020-07-16 17:32:29] __main__ INFO: \u001b[0mVal 0\n",
      "\u001b[32m[2020-07-16 17:32:41] __main__ INFO: \u001b[0mEpoch 0 loss 0.6245 acc@1 0.8720 acc@5 0.9914\n",
      "\u001b[32m[2020-07-16 17:32:41] __main__ INFO: \u001b[0mElapsed 11.49\n",
      "\u001b[32m[2020-07-16 17:32:41] __main__ INFO: \u001b[0mTrain 1 0\n",
      "\u001b[32m[2020-07-16 17:33:15] __main__ INFO: \u001b[0mEpoch 1 Step 100/703 lr 0.001000 loss 0.0981 (0.2112) acc@1 0.9688 (0.9359) acc@5 1.0000 (0.9972)\n",
      "\u001b[32m[2020-07-16 17:33:46] __main__ INFO: \u001b[0mEpoch 1 Step 200/703 lr 0.001000 loss 0.1715 (0.1972) acc@1 0.9531 (0.9411) acc@5 1.0000 (0.9977)\n",
      "\u001b[32m[2020-07-16 17:34:18] __main__ INFO: \u001b[0mEpoch 1 Step 300/703 lr 0.001000 loss 0.3546 (0.1932) acc@1 0.9219 (0.9422) acc@5 0.9844 (0.9982)\n",
      "\u001b[32m[2020-07-16 17:34:50] __main__ INFO: \u001b[0mEpoch 1 Step 400/703 lr 0.001000 loss 0.1169 (0.1863) acc@1 0.9531 (0.9446) acc@5 1.0000 (0.9982)\n",
      "\u001b[32m[2020-07-16 17:35:22] __main__ INFO: \u001b[0mEpoch 1 Step 500/703 lr 0.001000 loss 0.0050 (0.1791) acc@1 1.0000 (0.9464) acc@5 1.0000 (0.9983)\n",
      "\u001b[32m[2020-07-16 17:35:54] __main__ INFO: \u001b[0mEpoch 1 Step 600/703 lr 0.001000 loss 0.1412 (0.1764) acc@1 0.9375 (0.9473) acc@5 1.0000 (0.9984)\n",
      "\u001b[32m[2020-07-16 17:36:26] __main__ INFO: \u001b[0mEpoch 1 Step 700/703 lr 0.001000 loss 0.0336 (0.1736) acc@1 0.9844 (0.9482) acc@5 1.0000 (0.9984)\n",
      "\u001b[32m[2020-07-16 17:36:27] __main__ INFO: \u001b[0mEpoch 1 Step 703/703 lr 0.001000 loss 0.2619 (0.1737) acc@1 0.9062 (0.9482) acc@5 1.0000 (0.9984)\n",
      "\u001b[32m[2020-07-16 17:36:27] __main__ INFO: \u001b[0mElapsed 226.18\n",
      "\u001b[32m[2020-07-16 17:36:27] __main__ INFO: \u001b[0mVal 1\n",
      "\u001b[32m[2020-07-16 17:36:35] __main__ INFO: \u001b[0mEpoch 1 loss 0.2866 acc@1 0.9228 acc@5 0.9974\n",
      "\u001b[32m[2020-07-16 17:36:35] __main__ INFO: \u001b[0mElapsed 7.91\n",
      "\u001b[32m[2020-07-16 17:36:35] __main__ INFO: \u001b[0mTrain 2 703\n",
      "\u001b[32m[2020-07-16 17:37:07] __main__ INFO: \u001b[0mEpoch 2 Step 100/703 lr 0.001000 loss 0.1380 (0.1355) acc@1 0.9844 (0.9580) acc@5 0.9844 (0.9991)\n",
      "\u001b[32m[2020-07-16 17:37:39] __main__ INFO: \u001b[0mEpoch 2 Step 200/703 lr 0.001000 loss 0.1044 (0.1288) acc@1 0.9531 (0.9591) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-07-16 17:38:11] __main__ INFO: \u001b[0mEpoch 2 Step 300/703 lr 0.001000 loss 0.1396 (0.1299) acc@1 0.9688 (0.9593) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-07-16 17:38:43] __main__ INFO: \u001b[0mEpoch 2 Step 400/703 lr 0.001000 loss 0.1945 (0.1299) acc@1 0.9531 (0.9584) acc@5 0.9844 (0.9990)\n",
      "\u001b[32m[2020-07-16 17:39:16] __main__ INFO: \u001b[0mEpoch 2 Step 500/703 lr 0.001000 loss 0.1487 (0.1296) acc@1 0.9531 (0.9587) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-07-16 17:39:48] __main__ INFO: \u001b[0mEpoch 2 Step 600/703 lr 0.001000 loss 0.2051 (0.1298) acc@1 0.9531 (0.9590) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-07-16 17:40:19] __main__ INFO: \u001b[0mEpoch 2 Step 700/703 lr 0.001000 loss 0.0660 (0.1293) acc@1 0.9531 (0.9590) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-07-16 17:40:20] __main__ INFO: \u001b[0mEpoch 2 Step 703/703 lr 0.001000 loss 0.0849 (0.1293) acc@1 0.9688 (0.9590) acc@5 1.0000 (0.9991)\n",
      "\u001b[32m[2020-07-16 17:40:20] __main__ INFO: \u001b[0mElapsed 225.53\n",
      "\u001b[32m[2020-07-16 17:40:20] __main__ INFO: \u001b[0mVal 2\n",
      "\u001b[32m[2020-07-16 17:40:28] __main__ INFO: \u001b[0mEpoch 2 loss 0.2701 acc@1 0.9294 acc@5 0.9982\n",
      "\u001b[32m[2020-07-16 17:40:28] __main__ INFO: \u001b[0mElapsed 7.79\n",
      "\u001b[32m[2020-07-16 17:40:28] __main__ INFO: \u001b[0mTrain 3 1406\n",
      "\u001b[32m[2020-07-16 17:41:00] __main__ INFO: \u001b[0mEpoch 3 Step 100/703 lr 0.001000 loss 0.0375 (0.1031) acc@1 0.9844 (0.9647) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-07-16 17:41:33] __main__ INFO: \u001b[0mEpoch 3 Step 200/703 lr 0.001000 loss 0.0136 (0.1082) acc@1 1.0000 (0.9637) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-07-16 17:42:05] __main__ INFO: \u001b[0mEpoch 3 Step 300/703 lr 0.001000 loss 0.1383 (0.1039) acc@1 0.9219 (0.9650) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-07-16 17:42:37] __main__ INFO: \u001b[0mEpoch 3 Step 400/703 lr 0.001000 loss 0.1576 (0.1050) acc@1 0.9375 (0.9645) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-16 17:43:09] __main__ INFO: \u001b[0mEpoch 3 Step 500/703 lr 0.001000 loss 0.1624 (0.1047) acc@1 0.9375 (0.9645) acc@5 0.9844 (0.9996)\n",
      "\u001b[32m[2020-07-16 17:43:41] __main__ INFO: \u001b[0mEpoch 3 Step 600/703 lr 0.001000 loss 0.0245 (0.1065) acc@1 1.0000 (0.9645) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-07-16 17:44:13] __main__ INFO: \u001b[0mEpoch 3 Step 700/703 lr 0.001000 loss 0.1420 (0.1076) acc@1 0.9375 (0.9644) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-07-16 17:44:14] __main__ INFO: \u001b[0mEpoch 3 Step 703/703 lr 0.001000 loss 0.0966 (0.1075) acc@1 0.9688 (0.9644) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-07-16 17:44:14] __main__ INFO: \u001b[0mElapsed 225.68\n",
      "\u001b[32m[2020-07-16 17:44:14] __main__ INFO: \u001b[0mVal 3\n",
      "\u001b[32m[2020-07-16 17:44:22] __main__ INFO: \u001b[0mEpoch 3 loss 0.2606 acc@1 0.9290 acc@5 0.9980\n",
      "\u001b[32m[2020-07-16 17:44:22] __main__ INFO: \u001b[0mElapsed 7.80\n",
      "\u001b[32m[2020-07-16 17:44:22] __main__ INFO: \u001b[0mTrain 4 2109\n",
      "\u001b[32m[2020-07-16 17:44:54] __main__ INFO: \u001b[0mEpoch 4 Step 100/703 lr 0.001000 loss 0.0999 (0.1017) acc@1 0.9531 (0.9652) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-16 17:45:26] __main__ INFO: \u001b[0mEpoch 4 Step 200/703 lr 0.001000 loss 0.1794 (0.0977) acc@1 0.9531 (0.9674) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-16 17:45:58] __main__ INFO: \u001b[0mEpoch 4 Step 300/703 lr 0.001000 loss 0.1310 (0.0972) acc@1 0.9531 (0.9671) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-16 17:46:30] __main__ INFO: \u001b[0mEpoch 4 Step 400/703 lr 0.001000 loss 0.0802 (0.0963) acc@1 0.9844 (0.9670) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-16 17:47:02] __main__ INFO: \u001b[0mEpoch 4 Step 500/703 lr 0.001000 loss 0.1381 (0.0940) acc@1 0.9844 (0.9681) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-07-16 17:47:34] __main__ INFO: \u001b[0mEpoch 4 Step 600/703 lr 0.001000 loss 0.1790 (0.0950) acc@1 0.9688 (0.9679) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-07-16 17:48:06] __main__ INFO: \u001b[0mEpoch 4 Step 700/703 lr 0.001000 loss 0.1057 (0.0961) acc@1 0.9531 (0.9675) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-16 17:48:07] __main__ INFO: \u001b[0mEpoch 4 Step 703/703 lr 0.001000 loss 0.0891 (0.0960) acc@1 0.9531 (0.9675) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-16 17:48:07] __main__ INFO: \u001b[0mElapsed 225.54\n",
      "\u001b[32m[2020-07-16 17:48:07] __main__ INFO: \u001b[0mVal 4\n",
      "\u001b[32m[2020-07-16 17:48:15] __main__ INFO: \u001b[0mEpoch 4 loss 0.2500 acc@1 0.9318 acc@5 0.9982\n",
      "\u001b[32m[2020-07-16 17:48:15] __main__ INFO: \u001b[0mElapsed 7.81\n",
      "\u001b[32m[2020-07-16 17:48:15] __main__ INFO: \u001b[0mTrain 5 2812\n",
      "\u001b[32m[2020-07-16 17:48:47] __main__ INFO: \u001b[0mEpoch 5 Step 100/703 lr 0.001000 loss 0.0324 (0.0843) acc@1 0.9844 (0.9702) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-16 17:49:19] __main__ INFO: \u001b[0mEpoch 5 Step 200/703 lr 0.001000 loss 0.0971 (0.0895) acc@1 0.9531 (0.9679) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-16 17:49:51] __main__ INFO: \u001b[0mEpoch 5 Step 300/703 lr 0.001000 loss 0.0527 (0.0889) acc@1 0.9844 (0.9681) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-16 17:50:23] __main__ INFO: \u001b[0mEpoch 5 Step 400/703 lr 0.001000 loss 0.0636 (0.0897) acc@1 0.9844 (0.9679) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-16 17:50:55] __main__ INFO: \u001b[0mEpoch 5 Step 500/703 lr 0.001000 loss 0.1759 (0.0901) acc@1 0.9688 (0.9685) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-16 17:51:27] __main__ INFO: \u001b[0mEpoch 5 Step 600/703 lr 0.001000 loss 0.0635 (0.0906) acc@1 0.9688 (0.9683) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-16 17:51:59] __main__ INFO: \u001b[0mEpoch 5 Step 700/703 lr 0.001000 loss 0.0577 (0.0907) acc@1 0.9844 (0.9686) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-16 17:52:00] __main__ INFO: \u001b[0mEpoch 5 Step 703/703 lr 0.001000 loss 0.1333 (0.0907) acc@1 0.9531 (0.9685) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-16 17:52:00] __main__ INFO: \u001b[0mElapsed 224.96\n",
      "\u001b[32m[2020-07-16 17:52:00] __main__ INFO: \u001b[0mVal 5\n",
      "\u001b[32m[2020-07-16 17:52:08] __main__ INFO: \u001b[0mEpoch 5 loss 0.2533 acc@1 0.9294 acc@5 0.9986\n",
      "\u001b[32m[2020-07-16 17:52:08] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-16 17:52:08] __main__ INFO: \u001b[0mTrain 6 3515\n",
      "\u001b[32m[2020-07-16 17:52:40] __main__ INFO: \u001b[0mEpoch 6 Step 100/703 lr 0.001000 loss 0.0404 (0.0784) acc@1 0.9688 (0.9734) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-16 17:53:12] __main__ INFO: \u001b[0mEpoch 6 Step 200/703 lr 0.001000 loss 0.0057 (0.0792) acc@1 1.0000 (0.9734) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-16 17:53:44] __main__ INFO: \u001b[0mEpoch 6 Step 300/703 lr 0.001000 loss 0.0447 (0.0817) acc@1 0.9844 (0.9722) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-16 17:54:16] __main__ INFO: \u001b[0mEpoch 6 Step 400/703 lr 0.001000 loss 0.0893 (0.0809) acc@1 0.9688 (0.9721) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-16 17:54:48] __main__ INFO: \u001b[0mEpoch 6 Step 500/703 lr 0.001000 loss 0.1193 (0.0820) acc@1 0.9688 (0.9723) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-16 17:55:20] __main__ INFO: \u001b[0mEpoch 6 Step 600/703 lr 0.001000 loss 0.0525 (0.0816) acc@1 0.9844 (0.9725) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-16 17:55:52] __main__ INFO: \u001b[0mEpoch 6 Step 700/703 lr 0.001000 loss 0.1506 (0.0824) acc@1 0.9531 (0.9718) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-16 17:55:53] __main__ INFO: \u001b[0mEpoch 6 Step 703/703 lr 0.001000 loss 0.0115 (0.0826) acc@1 1.0000 (0.9717) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-16 17:55:53] __main__ INFO: \u001b[0mElapsed 224.78\n",
      "\u001b[32m[2020-07-16 17:55:53] __main__ INFO: \u001b[0mVal 6\n",
      "\u001b[32m[2020-07-16 17:56:00] __main__ INFO: \u001b[0mEpoch 6 loss 0.2501 acc@1 0.9314 acc@5 0.9984\n",
      "\u001b[32m[2020-07-16 17:56:00] __main__ INFO: \u001b[0mElapsed 7.75\n",
      "\u001b[32m[2020-07-16 17:56:00] __main__ INFO: \u001b[0mTrain 7 4218\n",
      "\u001b[32m[2020-07-16 17:56:32] __main__ INFO: \u001b[0mEpoch 7 Step 100/703 lr 0.001000 loss 0.0238 (0.0772) acc@1 1.0000 (0.9753) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 17:57:04] __main__ INFO: \u001b[0mEpoch 7 Step 200/703 lr 0.001000 loss 0.0329 (0.0757) acc@1 0.9844 (0.9751) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-16 17:57:36] __main__ INFO: \u001b[0mEpoch 7 Step 300/703 lr 0.001000 loss 0.0091 (0.0750) acc@1 1.0000 (0.9747) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-16 17:58:08] __main__ INFO: \u001b[0mEpoch 7 Step 400/703 lr 0.001000 loss 0.1011 (0.0766) acc@1 0.9688 (0.9738) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-16 17:58:40] __main__ INFO: \u001b[0mEpoch 7 Step 500/703 lr 0.001000 loss 0.0553 (0.0776) acc@1 0.9688 (0.9731) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-16 17:59:12] __main__ INFO: \u001b[0mEpoch 7 Step 600/703 lr 0.001000 loss 0.0082 (0.0774) acc@1 1.0000 (0.9733) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-16 17:59:44] __main__ INFO: \u001b[0mEpoch 7 Step 700/703 lr 0.001000 loss 0.1452 (0.0780) acc@1 0.9688 (0.9730) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-16 17:59:45] __main__ INFO: \u001b[0mEpoch 7 Step 703/703 lr 0.001000 loss 0.0685 (0.0780) acc@1 0.9531 (0.9730) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-16 17:59:45] __main__ INFO: \u001b[0mElapsed 224.93\n",
      "\u001b[32m[2020-07-16 17:59:45] __main__ INFO: \u001b[0mVal 7\n",
      "\u001b[32m[2020-07-16 17:59:53] __main__ INFO: \u001b[0mEpoch 7 loss 0.2544 acc@1 0.9336 acc@5 0.9990\n",
      "\u001b[32m[2020-07-16 17:59:53] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-16 17:59:53] __main__ INFO: \u001b[0mTrain 8 4921\n",
      "\u001b[32m[2020-07-16 18:00:25] __main__ INFO: \u001b[0mEpoch 8 Step 100/703 lr 0.001000 loss 0.1048 (0.0658) acc@1 0.9531 (0.9783) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-16 18:00:57] __main__ INFO: \u001b[0mEpoch 8 Step 200/703 lr 0.001000 loss 0.0350 (0.0682) acc@1 0.9688 (0.9779) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-16 18:01:29] __main__ INFO: \u001b[0mEpoch 8 Step 300/703 lr 0.001000 loss 0.0721 (0.0667) acc@1 0.9531 (0.9784) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-16 18:02:01] __main__ INFO: \u001b[0mEpoch 8 Step 400/703 lr 0.001000 loss 0.1326 (0.0686) acc@1 0.9688 (0.9778) acc@5 0.9844 (0.9995)\n",
      "\u001b[32m[2020-07-16 18:02:33] __main__ INFO: \u001b[0mEpoch 8 Step 500/703 lr 0.001000 loss 0.0795 (0.0680) acc@1 0.9688 (0.9779) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-16 18:03:05] __main__ INFO: \u001b[0mEpoch 8 Step 600/703 lr 0.001000 loss 0.0377 (0.0677) acc@1 1.0000 (0.9774) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-16 18:03:37] __main__ INFO: \u001b[0mEpoch 8 Step 700/703 lr 0.001000 loss 0.0379 (0.0681) acc@1 1.0000 (0.9772) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-16 18:03:38] __main__ INFO: \u001b[0mEpoch 8 Step 703/703 lr 0.001000 loss 0.1630 (0.0683) acc@1 0.9531 (0.9772) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-16 18:03:38] __main__ INFO: \u001b[0mElapsed 224.95\n",
      "\u001b[32m[2020-07-16 18:03:38] __main__ INFO: \u001b[0mVal 8\n",
      "\u001b[32m[2020-07-16 18:03:46] __main__ INFO: \u001b[0mEpoch 8 loss 0.2468 acc@1 0.9352 acc@5 0.9986\n",
      "\u001b[32m[2020-07-16 18:03:46] __main__ INFO: \u001b[0mElapsed 7.74\n",
      "\u001b[32m[2020-07-16 18:03:46] __main__ INFO: \u001b[0mTrain 9 5624\n",
      "\u001b[32m[2020-07-16 18:04:18] __main__ INFO: \u001b[0mEpoch 9 Step 100/703 lr 0.001000 loss 0.1236 (0.0569) acc@1 0.9219 (0.9811) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-16 18:04:50] __main__ INFO: \u001b[0mEpoch 9 Step 200/703 lr 0.001000 loss 0.2109 (0.0593) acc@1 0.9219 (0.9797) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-16 18:05:22] __main__ INFO: \u001b[0mEpoch 9 Step 300/703 lr 0.001000 loss 0.0548 (0.0635) acc@1 0.9844 (0.9783) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-16 18:05:54] __main__ INFO: \u001b[0mEpoch 9 Step 400/703 lr 0.001000 loss 0.0621 (0.0629) acc@1 0.9844 (0.9787) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-16 18:06:26] __main__ INFO: \u001b[0mEpoch 9 Step 500/703 lr 0.001000 loss 0.0073 (0.0647) acc@1 1.0000 (0.9779) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-16 18:06:57] __main__ INFO: \u001b[0mEpoch 9 Step 600/703 lr 0.001000 loss 0.0087 (0.0659) acc@1 1.0000 (0.9773) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-16 18:07:29] __main__ INFO: \u001b[0mEpoch 9 Step 700/703 lr 0.001000 loss 0.0578 (0.0667) acc@1 0.9844 (0.9771) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-16 18:07:30] __main__ INFO: \u001b[0mEpoch 9 Step 703/703 lr 0.001000 loss 0.0176 (0.0666) acc@1 1.0000 (0.9772) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-16 18:07:30] __main__ INFO: \u001b[0mElapsed 224.56\n",
      "\u001b[32m[2020-07-16 18:07:30] __main__ INFO: \u001b[0mVal 9\n",
      "\u001b[32m[2020-07-16 18:07:38] __main__ INFO: \u001b[0mEpoch 9 loss 0.2495 acc@1 0.9324 acc@5 0.9988\n",
      "\u001b[32m[2020-07-16 18:07:38] __main__ INFO: \u001b[0mElapsed 7.75\n",
      "\u001b[32m[2020-07-16 18:07:38] __main__ INFO: \u001b[0mTrain 10 6327\n",
      "\u001b[32m[2020-07-16 18:08:10] __main__ INFO: \u001b[0mEpoch 10 Step 100/703 lr 0.001000 loss 0.0263 (0.0558) acc@1 1.0000 (0.9817) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-16 18:08:42] __main__ INFO: \u001b[0mEpoch 10 Step 200/703 lr 0.001000 loss 0.0202 (0.0549) acc@1 1.0000 (0.9822) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-16 18:09:14] __main__ INFO: \u001b[0mEpoch 10 Step 300/703 lr 0.001000 loss 0.0209 (0.0574) acc@1 1.0000 (0.9807) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-16 18:09:46] __main__ INFO: \u001b[0mEpoch 10 Step 400/703 lr 0.001000 loss 0.0228 (0.0597) acc@1 1.0000 (0.9800) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-16 18:10:18] __main__ INFO: \u001b[0mEpoch 10 Step 500/703 lr 0.001000 loss 0.0604 (0.0611) acc@1 0.9844 (0.9792) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-16 18:10:50] __main__ INFO: \u001b[0mEpoch 10 Step 600/703 lr 0.001000 loss 0.0716 (0.0604) acc@1 0.9688 (0.9795) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-16 18:11:22] __main__ INFO: \u001b[0mEpoch 10 Step 700/703 lr 0.001000 loss 0.0423 (0.0617) acc@1 0.9844 (0.9789) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-16 18:11:23] __main__ INFO: \u001b[0mEpoch 10 Step 703/703 lr 0.001000 loss 0.0702 (0.0618) acc@1 0.9688 (0.9788) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-16 18:11:23] __main__ INFO: \u001b[0mElapsed 224.95\n",
      "\u001b[32m[2020-07-16 18:11:23] __main__ INFO: \u001b[0mVal 10\n",
      "\u001b[32m[2020-07-16 18:11:31] __main__ INFO: \u001b[0mEpoch 10 loss 0.2541 acc@1 0.9318 acc@5 0.9986\n",
      "\u001b[32m[2020-07-16 18:11:31] __main__ INFO: \u001b[0mElapsed 7.75\n",
      "\u001b[32m[2020-07-16 18:11:31] __main__ INFO: \u001b[0mTrain 11 7030\n",
      "\u001b[32m[2020-07-16 18:12:03] __main__ INFO: \u001b[0mEpoch 11 Step 100/703 lr 0.001000 loss 0.0722 (0.0595) acc@1 0.9688 (0.9800) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-16 18:12:35] __main__ INFO: \u001b[0mEpoch 11 Step 200/703 lr 0.001000 loss 0.0658 (0.0603) acc@1 0.9688 (0.9790) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-16 18:13:07] __main__ INFO: \u001b[0mEpoch 11 Step 300/703 lr 0.001000 loss 0.0335 (0.0605) acc@1 0.9844 (0.9794) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-16 18:13:39] __main__ INFO: \u001b[0mEpoch 11 Step 400/703 lr 0.001000 loss 0.0572 (0.0592) acc@1 0.9844 (0.9796) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-16 18:14:11] __main__ INFO: \u001b[0mEpoch 11 Step 500/703 lr 0.001000 loss 0.0956 (0.0595) acc@1 0.9688 (0.9796) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-16 18:14:43] __main__ INFO: \u001b[0mEpoch 11 Step 600/703 lr 0.001000 loss 0.0420 (0.0592) acc@1 1.0000 (0.9798) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-16 18:15:15] __main__ INFO: \u001b[0mEpoch 11 Step 700/703 lr 0.001000 loss 0.0352 (0.0598) acc@1 0.9844 (0.9798) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-16 18:15:16] __main__ INFO: \u001b[0mEpoch 11 Step 703/703 lr 0.001000 loss 0.0148 (0.0597) acc@1 1.0000 (0.9798) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-16 18:15:16] __main__ INFO: \u001b[0mElapsed 224.81\n",
      "\u001b[32m[2020-07-16 18:15:16] __main__ INFO: \u001b[0mVal 11\n",
      "\u001b[32m[2020-07-16 18:15:23] __main__ INFO: \u001b[0mEpoch 11 loss 0.2464 acc@1 0.9344 acc@5 0.9990\n",
      "\u001b[32m[2020-07-16 18:15:23] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-16 18:15:23] __main__ INFO: \u001b[0mTrain 12 7733\n",
      "\u001b[32m[2020-07-16 18:15:55] __main__ INFO: \u001b[0mEpoch 12 Step 100/703 lr 0.001000 loss 0.0323 (0.0559) acc@1 0.9844 (0.9809) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:16:28] __main__ INFO: \u001b[0mEpoch 12 Step 200/703 lr 0.001000 loss 0.0930 (0.0559) acc@1 0.9688 (0.9809) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:17:00] __main__ INFO: \u001b[0mEpoch 12 Step 300/703 lr 0.001000 loss 0.0516 (0.0571) acc@1 1.0000 (0.9801) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:17:32] __main__ INFO: \u001b[0mEpoch 12 Step 400/703 lr 0.001000 loss 0.0438 (0.0554) acc@1 0.9844 (0.9805) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:18:04] __main__ INFO: \u001b[0mEpoch 12 Step 500/703 lr 0.001000 loss 0.0689 (0.0549) acc@1 0.9531 (0.9812) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:18:36] __main__ INFO: \u001b[0mEpoch 12 Step 600/703 lr 0.001000 loss 0.0811 (0.0549) acc@1 0.9688 (0.9812) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:19:08] __main__ INFO: \u001b[0mEpoch 12 Step 700/703 lr 0.001000 loss 0.0303 (0.0548) acc@1 1.0000 (0.9812) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:19:09] __main__ INFO: \u001b[0mEpoch 12 Step 703/703 lr 0.001000 loss 0.0874 (0.0548) acc@1 0.9531 (0.9812) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:19:09] __main__ INFO: \u001b[0mElapsed 225.32\n",
      "\u001b[32m[2020-07-16 18:19:09] __main__ INFO: \u001b[0mVal 12\n",
      "\u001b[32m[2020-07-16 18:19:16] __main__ INFO: \u001b[0mEpoch 12 loss 0.2496 acc@1 0.9324 acc@5 0.9988\n",
      "\u001b[32m[2020-07-16 18:19:16] __main__ INFO: \u001b[0mElapsed 7.74\n",
      "\u001b[32m[2020-07-16 18:19:16] __main__ INFO: \u001b[0mTrain 13 8436\n",
      "\u001b[32m[2020-07-16 18:19:49] __main__ INFO: \u001b[0mEpoch 13 Step 100/703 lr 0.001000 loss 0.0811 (0.0489) acc@1 0.9844 (0.9848) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:20:21] __main__ INFO: \u001b[0mEpoch 13 Step 200/703 lr 0.001000 loss 0.0170 (0.0498) acc@1 1.0000 (0.9838) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:20:53] __main__ INFO: \u001b[0mEpoch 13 Step 300/703 lr 0.001000 loss 0.0403 (0.0506) acc@1 1.0000 (0.9831) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:21:25] __main__ INFO: \u001b[0mEpoch 13 Step 400/703 lr 0.001000 loss 0.1612 (0.0519) acc@1 0.9688 (0.9823) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:21:57] __main__ INFO: \u001b[0mEpoch 13 Step 500/703 lr 0.001000 loss 0.0160 (0.0532) acc@1 1.0000 (0.9815) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-16 18:22:29] __main__ INFO: \u001b[0mEpoch 13 Step 600/703 lr 0.001000 loss 0.0866 (0.0531) acc@1 0.9688 (0.9816) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-16 18:23:01] __main__ INFO: \u001b[0mEpoch 13 Step 700/703 lr 0.001000 loss 0.0369 (0.0535) acc@1 0.9844 (0.9815) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-16 18:23:02] __main__ INFO: \u001b[0mEpoch 13 Step 703/703 lr 0.001000 loss 0.0572 (0.0537) acc@1 0.9844 (0.9815) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-16 18:23:02] __main__ INFO: \u001b[0mElapsed 225.23\n",
      "\u001b[32m[2020-07-16 18:23:02] __main__ INFO: \u001b[0mVal 13\n",
      "\u001b[32m[2020-07-16 18:23:09] __main__ INFO: \u001b[0mEpoch 13 loss 0.2498 acc@1 0.9314 acc@5 0.9986\n",
      "\u001b[32m[2020-07-16 18:23:09] __main__ INFO: \u001b[0mElapsed 7.75\n",
      "\u001b[32m[2020-07-16 18:23:09] __main__ INFO: \u001b[0mTrain 14 9139\n",
      "\u001b[32m[2020-07-16 18:23:42] __main__ INFO: \u001b[0mEpoch 14 Step 100/703 lr 0.001000 loss 0.0589 (0.0512) acc@1 0.9844 (0.9834) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:24:14] __main__ INFO: \u001b[0mEpoch 14 Step 200/703 lr 0.001000 loss 0.0919 (0.0461) acc@1 0.9688 (0.9849) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:24:46] __main__ INFO: \u001b[0mEpoch 14 Step 300/703 lr 0.001000 loss 0.0641 (0.0468) acc@1 0.9531 (0.9843) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:25:18] __main__ INFO: \u001b[0mEpoch 14 Step 400/703 lr 0.001000 loss 0.0233 (0.0470) acc@1 1.0000 (0.9841) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:25:50] __main__ INFO: \u001b[0mEpoch 14 Step 500/703 lr 0.001000 loss 0.0279 (0.0477) acc@1 0.9844 (0.9842) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:26:22] __main__ INFO: \u001b[0mEpoch 14 Step 600/703 lr 0.001000 loss 0.0104 (0.0492) acc@1 1.0000 (0.9836) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:26:54] __main__ INFO: \u001b[0mEpoch 14 Step 700/703 lr 0.001000 loss 0.0081 (0.0484) acc@1 1.0000 (0.9840) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:26:55] __main__ INFO: \u001b[0mEpoch 14 Step 703/703 lr 0.001000 loss 0.0556 (0.0484) acc@1 0.9844 (0.9840) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:26:55] __main__ INFO: \u001b[0mElapsed 225.33\n",
      "\u001b[32m[2020-07-16 18:26:55] __main__ INFO: \u001b[0mVal 14\n",
      "\u001b[32m[2020-07-16 18:27:03] __main__ INFO: \u001b[0mEpoch 14 loss 0.2497 acc@1 0.9338 acc@5 0.9986\n",
      "\u001b[32m[2020-07-16 18:27:03] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-16 18:27:03] __main__ INFO: \u001b[0mTrain 15 9842\n",
      "\u001b[32m[2020-07-16 18:27:35] __main__ INFO: \u001b[0mEpoch 15 Step 100/703 lr 0.001000 loss 0.0584 (0.0436) acc@1 0.9844 (0.9855) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:28:07] __main__ INFO: \u001b[0mEpoch 15 Step 200/703 lr 0.001000 loss 0.0219 (0.0477) acc@1 1.0000 (0.9841) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:28:39] __main__ INFO: \u001b[0mEpoch 15 Step 300/703 lr 0.001000 loss 0.0337 (0.0464) acc@1 1.0000 (0.9850) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-16 18:29:11] __main__ INFO: \u001b[0mEpoch 15 Step 400/703 lr 0.001000 loss 0.0295 (0.0476) acc@1 0.9844 (0.9845) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-16 18:29:43] __main__ INFO: \u001b[0mEpoch 15 Step 500/703 lr 0.001000 loss 0.0407 (0.0475) acc@1 1.0000 (0.9846) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-16 18:30:15] __main__ INFO: \u001b[0mEpoch 15 Step 600/703 lr 0.001000 loss 0.0354 (0.0477) acc@1 0.9844 (0.9845) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-16 18:30:47] __main__ INFO: \u001b[0mEpoch 15 Step 700/703 lr 0.001000 loss 0.0047 (0.0482) acc@1 1.0000 (0.9842) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-16 18:30:48] __main__ INFO: \u001b[0mEpoch 15 Step 703/703 lr 0.001000 loss 0.0241 (0.0482) acc@1 1.0000 (0.9842) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-16 18:30:48] __main__ INFO: \u001b[0mElapsed 225.35\n",
      "\u001b[32m[2020-07-16 18:30:48] __main__ INFO: \u001b[0mVal 15\n",
      "\u001b[32m[2020-07-16 18:30:56] __main__ INFO: \u001b[0mEpoch 15 loss 0.2532 acc@1 0.9324 acc@5 0.9990\n",
      "\u001b[32m[2020-07-16 18:30:56] __main__ INFO: \u001b[0mElapsed 7.81\n",
      "\u001b[32m[2020-07-16 18:30:56] __main__ INFO: \u001b[0mTrain 16 10545\n",
      "\u001b[32m[2020-07-16 18:31:28] __main__ INFO: \u001b[0mEpoch 16 Step 100/703 lr 0.001000 loss 0.0442 (0.0447) acc@1 0.9844 (0.9866) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:32:00] __main__ INFO: \u001b[0mEpoch 16 Step 200/703 lr 0.001000 loss 0.0370 (0.0451) acc@1 1.0000 (0.9859) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:32:32] __main__ INFO: \u001b[0mEpoch 16 Step 300/703 lr 0.001000 loss 0.0253 (0.0454) acc@1 1.0000 (0.9861) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:33:04] __main__ INFO: \u001b[0mEpoch 16 Step 400/703 lr 0.001000 loss 0.0288 (0.0437) acc@1 0.9844 (0.9866) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-16 18:33:36] __main__ INFO: \u001b[0mEpoch 16 Step 500/703 lr 0.001000 loss 0.0183 (0.0438) acc@1 0.9844 (0.9866) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-16 18:34:08] __main__ INFO: \u001b[0mEpoch 16 Step 600/703 lr 0.001000 loss 0.0801 (0.0447) acc@1 0.9688 (0.9864) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-16 18:34:40] __main__ INFO: \u001b[0mEpoch 16 Step 700/703 lr 0.001000 loss 0.0188 (0.0445) acc@1 1.0000 (0.9865) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-16 18:34:41] __main__ INFO: \u001b[0mEpoch 16 Step 703/703 lr 0.001000 loss 0.0427 (0.0445) acc@1 0.9844 (0.9865) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-16 18:34:41] __main__ INFO: \u001b[0mElapsed 225.38\n",
      "\u001b[32m[2020-07-16 18:34:41] __main__ INFO: \u001b[0mVal 16\n",
      "\u001b[32m[2020-07-16 18:34:49] __main__ INFO: \u001b[0mEpoch 16 loss 0.2557 acc@1 0.9312 acc@5 0.9986\n",
      "\u001b[32m[2020-07-16 18:34:49] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-16 18:34:49] __main__ INFO: \u001b[0mTrain 17 11248\n",
      "\u001b[32m[2020-07-16 18:35:21] __main__ INFO: \u001b[0mEpoch 17 Step 100/703 lr 0.001000 loss 0.0316 (0.0419) acc@1 0.9844 (0.9878) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-16 18:35:53] __main__ INFO: \u001b[0mEpoch 17 Step 200/703 lr 0.001000 loss 0.0574 (0.0398) acc@1 0.9844 (0.9884) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-16 18:36:25] __main__ INFO: \u001b[0mEpoch 17 Step 300/703 lr 0.001000 loss 0.0262 (0.0404) acc@1 1.0000 (0.9880) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-16 18:36:57] __main__ INFO: \u001b[0mEpoch 17 Step 400/703 lr 0.001000 loss 0.0064 (0.0409) acc@1 1.0000 (0.9875) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-16 18:37:29] __main__ INFO: \u001b[0mEpoch 17 Step 500/703 lr 0.001000 loss 0.0424 (0.0411) acc@1 0.9844 (0.9873) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-16 18:38:01] __main__ INFO: \u001b[0mEpoch 17 Step 600/703 lr 0.001000 loss 0.0432 (0.0421) acc@1 0.9688 (0.9868) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-16 18:38:34] __main__ INFO: \u001b[0mEpoch 17 Step 700/703 lr 0.001000 loss 0.0559 (0.0422) acc@1 0.9531 (0.9867) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-16 18:38:34] __main__ INFO: \u001b[0mEpoch 17 Step 703/703 lr 0.001000 loss 0.0672 (0.0423) acc@1 0.9688 (0.9866) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-16 18:38:34] __main__ INFO: \u001b[0mElapsed 225.57\n",
      "\u001b[32m[2020-07-16 18:38:34] __main__ INFO: \u001b[0mVal 17\n",
      "\u001b[32m[2020-07-16 18:38:42] __main__ INFO: \u001b[0mEpoch 17 loss 0.2587 acc@1 0.9340 acc@5 0.9984\n",
      "\u001b[32m[2020-07-16 18:38:42] __main__ INFO: \u001b[0mElapsed 7.79\n",
      "\u001b[32m[2020-07-16 18:38:42] __main__ INFO: \u001b[0mTrain 18 11951\n",
      "\u001b[32m[2020-07-16 18:39:14] __main__ INFO: \u001b[0mEpoch 18 Step 100/703 lr 0.001000 loss 0.0483 (0.0378) acc@1 0.9844 (0.9884) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-16 18:39:46] __main__ INFO: \u001b[0mEpoch 18 Step 200/703 lr 0.001000 loss 0.0252 (0.0383) acc@1 1.0000 (0.9884) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-16 18:40:18] __main__ INFO: \u001b[0mEpoch 18 Step 300/703 lr 0.001000 loss 0.0535 (0.0392) acc@1 0.9688 (0.9877) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-16 18:40:50] __main__ INFO: \u001b[0mEpoch 18 Step 400/703 lr 0.001000 loss 0.0322 (0.0404) acc@1 0.9844 (0.9869) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-16 18:41:22] __main__ INFO: \u001b[0mEpoch 18 Step 500/703 lr 0.001000 loss 0.0330 (0.0406) acc@1 1.0000 (0.9868) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-16 18:41:54] __main__ INFO: \u001b[0mEpoch 18 Step 600/703 lr 0.001000 loss 0.0194 (0.0404) acc@1 1.0000 (0.9868) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-16 18:42:26] __main__ INFO: \u001b[0mEpoch 18 Step 700/703 lr 0.001000 loss 0.0338 (0.0404) acc@1 1.0000 (0.9868) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:42:27] __main__ INFO: \u001b[0mEpoch 18 Step 703/703 lr 0.001000 loss 0.0180 (0.0403) acc@1 1.0000 (0.9868) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:42:27] __main__ INFO: \u001b[0mElapsed 225.13\n",
      "\u001b[32m[2020-07-16 18:42:27] __main__ INFO: \u001b[0mVal 18\n",
      "\u001b[32m[2020-07-16 18:42:35] __main__ INFO: \u001b[0mEpoch 18 loss 0.2575 acc@1 0.9336 acc@5 0.9980\n",
      "\u001b[32m[2020-07-16 18:42:35] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-16 18:42:35] __main__ INFO: \u001b[0mTrain 19 12654\n",
      "\u001b[32m[2020-07-16 18:43:07] __main__ INFO: \u001b[0mEpoch 19 Step 100/703 lr 0.001000 loss 0.0534 (0.0397) acc@1 0.9844 (0.9869) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:43:39] __main__ INFO: \u001b[0mEpoch 19 Step 200/703 lr 0.001000 loss 0.0386 (0.0373) acc@1 1.0000 (0.9885) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:44:11] __main__ INFO: \u001b[0mEpoch 19 Step 300/703 lr 0.001000 loss 0.0542 (0.0369) acc@1 0.9844 (0.9888) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-16 18:44:43] __main__ INFO: \u001b[0mEpoch 19 Step 400/703 lr 0.001000 loss 0.0147 (0.0371) acc@1 1.0000 (0.9882) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:45:16] __main__ INFO: \u001b[0mEpoch 19 Step 500/703 lr 0.001000 loss 0.0080 (0.0378) acc@1 1.0000 (0.9879) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-16 18:45:48] __main__ INFO: \u001b[0mEpoch 19 Step 600/703 lr 0.001000 loss 0.0163 (0.0384) acc@1 0.9844 (0.9875) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-16 18:46:20] __main__ INFO: \u001b[0mEpoch 19 Step 700/703 lr 0.001000 loss 0.0385 (0.0382) acc@1 0.9844 (0.9877) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:46:21] __main__ INFO: \u001b[0mEpoch 19 Step 703/703 lr 0.001000 loss 0.0081 (0.0382) acc@1 1.0000 (0.9877) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:46:21] __main__ INFO: \u001b[0mElapsed 225.61\n",
      "\u001b[32m[2020-07-16 18:46:21] __main__ INFO: \u001b[0mVal 19\n",
      "\u001b[32m[2020-07-16 18:46:29] __main__ INFO: \u001b[0mEpoch 19 loss 0.2575 acc@1 0.9332 acc@5 0.9986\n",
      "\u001b[32m[2020-07-16 18:46:29] __main__ INFO: \u001b[0mElapsed 7.86\n",
      "\u001b[32m[2020-07-16 18:46:29] __main__ INFO: \u001b[0mTrain 20 13357\n",
      "\u001b[32m[2020-07-16 18:47:01] __main__ INFO: \u001b[0mEpoch 20 Step 100/703 lr 0.001000 loss 0.0286 (0.0350) acc@1 1.0000 (0.9886) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:47:33] __main__ INFO: \u001b[0mEpoch 20 Step 200/703 lr 0.001000 loss 0.0232 (0.0364) acc@1 0.9844 (0.9881) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:48:05] __main__ INFO: \u001b[0mEpoch 20 Step 300/703 lr 0.001000 loss 0.0146 (0.0359) acc@1 1.0000 (0.9885) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:48:37] __main__ INFO: \u001b[0mEpoch 20 Step 400/703 lr 0.001000 loss 0.0224 (0.0357) acc@1 0.9844 (0.9889) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-16 18:49:09] __main__ INFO: \u001b[0mEpoch 20 Step 500/703 lr 0.001000 loss 0.0540 (0.0364) acc@1 0.9688 (0.9888) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-16 18:49:41] __main__ INFO: \u001b[0mEpoch 20 Step 600/703 lr 0.001000 loss 0.0997 (0.0370) acc@1 0.9531 (0.9884) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-16 18:50:13] __main__ INFO: \u001b[0mEpoch 20 Step 700/703 lr 0.001000 loss 0.0491 (0.0369) acc@1 0.9688 (0.9885) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-16 18:50:14] __main__ INFO: \u001b[0mEpoch 20 Step 703/703 lr 0.001000 loss 0.0485 (0.0369) acc@1 0.9844 (0.9885) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-16 18:50:14] __main__ INFO: \u001b[0mElapsed 225.22\n",
      "\u001b[32m[2020-07-16 18:50:14] __main__ INFO: \u001b[0mVal 20\n",
      "\u001b[32m[2020-07-16 18:50:22] __main__ INFO: \u001b[0mEpoch 20 loss 0.2609 acc@1 0.9320 acc@5 0.9982\n",
      "\u001b[32m[2020-07-16 18:50:22] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-16 18:50:22] __main__ INFO: \u001b[0mTrain 21 14060\n",
      "\u001b[32m[2020-07-16 18:50:54] __main__ INFO: \u001b[0mEpoch 21 Step 100/703 lr 0.001000 loss 0.0109 (0.0370) acc@1 1.0000 (0.9884) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:51:26] __main__ INFO: \u001b[0mEpoch 21 Step 200/703 lr 0.001000 loss 0.0761 (0.0341) acc@1 0.9844 (0.9896) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:51:58] __main__ INFO: \u001b[0mEpoch 21 Step 300/703 lr 0.001000 loss 0.0127 (0.0352) acc@1 1.0000 (0.9891) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:52:30] __main__ INFO: \u001b[0mEpoch 21 Step 400/703 lr 0.001000 loss 0.0264 (0.0346) acc@1 0.9844 (0.9896) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:53:02] __main__ INFO: \u001b[0mEpoch 21 Step 500/703 lr 0.001000 loss 0.0731 (0.0350) acc@1 0.9688 (0.9893) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:53:34] __main__ INFO: \u001b[0mEpoch 21 Step 600/703 lr 0.001000 loss 0.0096 (0.0352) acc@1 1.0000 (0.9893) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:54:06] __main__ INFO: \u001b[0mEpoch 21 Step 700/703 lr 0.001000 loss 0.0128 (0.0353) acc@1 1.0000 (0.9892) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:54:07] __main__ INFO: \u001b[0mEpoch 21 Step 703/703 lr 0.001000 loss 0.0458 (0.0353) acc@1 0.9844 (0.9892) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:54:07] __main__ INFO: \u001b[0mElapsed 225.11\n",
      "\u001b[32m[2020-07-16 18:54:07] __main__ INFO: \u001b[0mVal 21\n",
      "\u001b[32m[2020-07-16 18:54:15] __main__ INFO: \u001b[0mEpoch 21 loss 0.2628 acc@1 0.9330 acc@5 0.9984\n",
      "\u001b[32m[2020-07-16 18:54:15] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-16 18:54:15] __main__ INFO: \u001b[0mTrain 22 14763\n",
      "\u001b[32m[2020-07-16 18:54:47] __main__ INFO: \u001b[0mEpoch 22 Step 100/703 lr 0.001000 loss 0.0641 (0.0319) acc@1 0.9531 (0.9909) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:55:19] __main__ INFO: \u001b[0mEpoch 22 Step 200/703 lr 0.001000 loss 0.0097 (0.0317) acc@1 1.0000 (0.9912) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:55:51] __main__ INFO: \u001b[0mEpoch 22 Step 300/703 lr 0.001000 loss 0.0375 (0.0317) acc@1 0.9844 (0.9911) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:56:23] __main__ INFO: \u001b[0mEpoch 22 Step 400/703 lr 0.001000 loss 0.0170 (0.0321) acc@1 1.0000 (0.9907) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:56:55] __main__ INFO: \u001b[0mEpoch 22 Step 500/703 lr 0.001000 loss 0.0066 (0.0324) acc@1 1.0000 (0.9905) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:57:27] __main__ INFO: \u001b[0mEpoch 22 Step 600/703 lr 0.001000 loss 0.0385 (0.0321) acc@1 0.9844 (0.9904) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:57:59] __main__ INFO: \u001b[0mEpoch 22 Step 700/703 lr 0.001000 loss 0.0162 (0.0328) acc@1 1.0000 (0.9902) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:57:59] __main__ INFO: \u001b[0mEpoch 22 Step 703/703 lr 0.001000 loss 0.0102 (0.0327) acc@1 1.0000 (0.9902) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:58:00] __main__ INFO: \u001b[0mElapsed 224.96\n",
      "\u001b[32m[2020-07-16 18:58:00] __main__ INFO: \u001b[0mVal 22\n",
      "\u001b[32m[2020-07-16 18:58:07] __main__ INFO: \u001b[0mEpoch 22 loss 0.2615 acc@1 0.9318 acc@5 0.9982\n",
      "\u001b[32m[2020-07-16 18:58:07] __main__ INFO: \u001b[0mElapsed 7.74\n",
      "\u001b[32m[2020-07-16 18:58:07] __main__ INFO: \u001b[0mTrain 23 15466\n",
      "\u001b[32m[2020-07-16 18:58:39] __main__ INFO: \u001b[0mEpoch 23 Step 100/703 lr 0.001000 loss 0.0244 (0.0327) acc@1 0.9844 (0.9898) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:59:11] __main__ INFO: \u001b[0mEpoch 23 Step 200/703 lr 0.001000 loss 0.0162 (0.0314) acc@1 1.0000 (0.9905) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 18:59:43] __main__ INFO: \u001b[0mEpoch 23 Step 300/703 lr 0.001000 loss 0.0403 (0.0312) acc@1 0.9844 (0.9906) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:00:15] __main__ INFO: \u001b[0mEpoch 23 Step 400/703 lr 0.001000 loss 0.0168 (0.0323) acc@1 0.9844 (0.9900) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:00:47] __main__ INFO: \u001b[0mEpoch 23 Step 500/703 lr 0.001000 loss 0.0307 (0.0318) acc@1 0.9844 (0.9902) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:01:19] __main__ INFO: \u001b[0mEpoch 23 Step 600/703 lr 0.001000 loss 0.0156 (0.0325) acc@1 1.0000 (0.9902) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:01:51] __main__ INFO: \u001b[0mEpoch 23 Step 700/703 lr 0.001000 loss 0.0462 (0.0333) acc@1 0.9688 (0.9899) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:01:52] __main__ INFO: \u001b[0mEpoch 23 Step 703/703 lr 0.001000 loss 0.0054 (0.0333) acc@1 1.0000 (0.9899) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:01:52] __main__ INFO: \u001b[0mElapsed 224.55\n",
      "\u001b[32m[2020-07-16 19:01:52] __main__ INFO: \u001b[0mVal 23\n",
      "\u001b[32m[2020-07-16 19:02:00] __main__ INFO: \u001b[0mEpoch 23 loss 0.2634 acc@1 0.9340 acc@5 0.9984\n",
      "\u001b[32m[2020-07-16 19:02:00] __main__ INFO: \u001b[0mElapsed 7.75\n",
      "\u001b[32m[2020-07-16 19:02:00] __main__ INFO: \u001b[0mTrain 24 16169\n",
      "\u001b[32m[2020-07-16 19:02:32] __main__ INFO: \u001b[0mEpoch 24 Step 100/703 lr 0.001000 loss 0.0372 (0.0325) acc@1 1.0000 (0.9898) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:03:04] __main__ INFO: \u001b[0mEpoch 24 Step 200/703 lr 0.001000 loss 0.0307 (0.0311) acc@1 0.9844 (0.9910) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:03:36] __main__ INFO: \u001b[0mEpoch 24 Step 300/703 lr 0.001000 loss 0.0653 (0.0311) acc@1 0.9688 (0.9905) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:04:08] __main__ INFO: \u001b[0mEpoch 24 Step 400/703 lr 0.001000 loss 0.0603 (0.0328) acc@1 0.9844 (0.9896) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:04:40] __main__ INFO: \u001b[0mEpoch 24 Step 500/703 lr 0.001000 loss 0.0253 (0.0326) acc@1 1.0000 (0.9898) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:05:12] __main__ INFO: \u001b[0mEpoch 24 Step 600/703 lr 0.001000 loss 0.0972 (0.0319) acc@1 0.9531 (0.9901) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:05:44] __main__ INFO: \u001b[0mEpoch 24 Step 700/703 lr 0.001000 loss 0.0046 (0.0317) acc@1 1.0000 (0.9901) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:05:45] __main__ INFO: \u001b[0mEpoch 24 Step 703/703 lr 0.001000 loss 0.0184 (0.0316) acc@1 1.0000 (0.9902) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:05:45] __main__ INFO: \u001b[0mElapsed 225.00\n",
      "\u001b[32m[2020-07-16 19:05:45] __main__ INFO: \u001b[0mVal 24\n",
      "\u001b[32m[2020-07-16 19:05:52] __main__ INFO: \u001b[0mEpoch 24 loss 0.2643 acc@1 0.9334 acc@5 0.9984\n",
      "\u001b[32m[2020-07-16 19:05:52] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-16 19:05:52] __main__ INFO: \u001b[0mTrain 25 16872\n",
      "\u001b[32m[2020-07-16 19:06:24] __main__ INFO: \u001b[0mEpoch 25 Step 100/703 lr 0.001000 loss 0.0502 (0.0299) acc@1 0.9844 (0.9909) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:06:56] __main__ INFO: \u001b[0mEpoch 25 Step 200/703 lr 0.001000 loss 0.0284 (0.0283) acc@1 1.0000 (0.9916) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:07:28] __main__ INFO: \u001b[0mEpoch 25 Step 300/703 lr 0.001000 loss 0.0349 (0.0292) acc@1 1.0000 (0.9911) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:08:00] __main__ INFO: \u001b[0mEpoch 25 Step 400/703 lr 0.001000 loss 0.0467 (0.0297) acc@1 0.9844 (0.9911) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:08:32] __main__ INFO: \u001b[0mEpoch 25 Step 500/703 lr 0.001000 loss 0.0238 (0.0294) acc@1 1.0000 (0.9914) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:09:04] __main__ INFO: \u001b[0mEpoch 25 Step 600/703 lr 0.001000 loss 0.0734 (0.0305) acc@1 0.9844 (0.9908) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:09:36] __main__ INFO: \u001b[0mEpoch 25 Step 700/703 lr 0.001000 loss 0.0249 (0.0314) acc@1 0.9844 (0.9904) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:09:37] __main__ INFO: \u001b[0mEpoch 25 Step 703/703 lr 0.001000 loss 0.0307 (0.0315) acc@1 1.0000 (0.9904) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:09:37] __main__ INFO: \u001b[0mElapsed 224.75\n",
      "\u001b[32m[2020-07-16 19:09:37] __main__ INFO: \u001b[0mVal 25\n",
      "\u001b[32m[2020-07-16 19:09:45] __main__ INFO: \u001b[0mEpoch 25 loss 0.2605 acc@1 0.9324 acc@5 0.9986\n",
      "\u001b[32m[2020-07-16 19:09:45] __main__ INFO: \u001b[0mElapsed 7.75\n",
      "\u001b[32m[2020-07-16 19:09:45] __main__ INFO: \u001b[0mTrain 26 17575\n",
      "\u001b[32m[2020-07-16 19:10:17] __main__ INFO: \u001b[0mEpoch 26 Step 100/703 lr 0.001000 loss 0.0233 (0.0235) acc@1 1.0000 (0.9948) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:10:49] __main__ INFO: \u001b[0mEpoch 26 Step 200/703 lr 0.001000 loss 0.0231 (0.0267) acc@1 1.0000 (0.9928) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:11:21] __main__ INFO: \u001b[0mEpoch 26 Step 300/703 lr 0.001000 loss 0.0742 (0.0266) acc@1 0.9688 (0.9926) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:11:53] __main__ INFO: \u001b[0mEpoch 26 Step 400/703 lr 0.001000 loss 0.0249 (0.0266) acc@1 0.9844 (0.9926) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:12:25] __main__ INFO: \u001b[0mEpoch 26 Step 500/703 lr 0.001000 loss 0.0703 (0.0276) acc@1 0.9844 (0.9921) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:12:57] __main__ INFO: \u001b[0mEpoch 26 Step 600/703 lr 0.001000 loss 0.0111 (0.0277) acc@1 1.0000 (0.9921) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:13:29] __main__ INFO: \u001b[0mEpoch 26 Step 700/703 lr 0.001000 loss 0.0755 (0.0281) acc@1 0.9531 (0.9918) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:13:30] __main__ INFO: \u001b[0mEpoch 26 Step 703/703 lr 0.001000 loss 0.0151 (0.0281) acc@1 1.0000 (0.9918) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:13:30] __main__ INFO: \u001b[0mElapsed 224.72\n",
      "\u001b[32m[2020-07-16 19:13:30] __main__ INFO: \u001b[0mVal 26\n",
      "\u001b[32m[2020-07-16 19:13:37] __main__ INFO: \u001b[0mEpoch 26 loss 0.2610 acc@1 0.9318 acc@5 0.9984\n",
      "\u001b[32m[2020-07-16 19:13:37] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-16 19:13:37] __main__ INFO: \u001b[0mTrain 27 18278\n",
      "\u001b[32m[2020-07-16 19:14:09] __main__ INFO: \u001b[0mEpoch 27 Step 100/703 lr 0.001000 loss 0.0184 (0.0276) acc@1 1.0000 (0.9930) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:14:41] __main__ INFO: \u001b[0mEpoch 27 Step 200/703 lr 0.001000 loss 0.0354 (0.0280) acc@1 1.0000 (0.9929) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:15:13] __main__ INFO: \u001b[0mEpoch 27 Step 300/703 lr 0.001000 loss 0.0921 (0.0295) acc@1 0.9844 (0.9918) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:15:45] __main__ INFO: \u001b[0mEpoch 27 Step 400/703 lr 0.001000 loss 0.0258 (0.0288) acc@1 0.9844 (0.9918) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:16:17] __main__ INFO: \u001b[0mEpoch 27 Step 500/703 lr 0.001000 loss 0.0242 (0.0287) acc@1 1.0000 (0.9920) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:16:49] __main__ INFO: \u001b[0mEpoch 27 Step 600/703 lr 0.001000 loss 0.0750 (0.0282) acc@1 0.9688 (0.9923) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:17:21] __main__ INFO: \u001b[0mEpoch 27 Step 700/703 lr 0.001000 loss 0.0302 (0.0284) acc@1 1.0000 (0.9921) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:17:22] __main__ INFO: \u001b[0mEpoch 27 Step 703/703 lr 0.001000 loss 0.0692 (0.0285) acc@1 0.9844 (0.9921) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:17:22] __main__ INFO: \u001b[0mElapsed 224.52\n",
      "\u001b[32m[2020-07-16 19:17:22] __main__ INFO: \u001b[0mVal 27\n",
      "\u001b[32m[2020-07-16 19:17:30] __main__ INFO: \u001b[0mEpoch 27 loss 0.2629 acc@1 0.9334 acc@5 0.9984\n",
      "\u001b[32m[2020-07-16 19:17:30] __main__ INFO: \u001b[0mElapsed 7.74\n",
      "\u001b[32m[2020-07-16 19:17:30] __main__ INFO: \u001b[0mTrain 28 18981\n",
      "\u001b[32m[2020-07-16 19:18:02] __main__ INFO: \u001b[0mEpoch 28 Step 100/703 lr 0.001000 loss 0.0301 (0.0273) acc@1 1.0000 (0.9919) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:18:33] __main__ INFO: \u001b[0mEpoch 28 Step 200/703 lr 0.001000 loss 0.0147 (0.0270) acc@1 1.0000 (0.9922) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:19:05] __main__ INFO: \u001b[0mEpoch 28 Step 300/703 lr 0.001000 loss 0.0296 (0.0260) acc@1 0.9844 (0.9927) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:19:37] __main__ INFO: \u001b[0mEpoch 28 Step 400/703 lr 0.001000 loss 0.0169 (0.0253) acc@1 1.0000 (0.9929) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:20:09] __main__ INFO: \u001b[0mEpoch 28 Step 500/703 lr 0.001000 loss 0.0292 (0.0252) acc@1 0.9844 (0.9931) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:20:41] __main__ INFO: \u001b[0mEpoch 28 Step 600/703 lr 0.001000 loss 0.0337 (0.0257) acc@1 1.0000 (0.9930) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:21:13] __main__ INFO: \u001b[0mEpoch 28 Step 700/703 lr 0.001000 loss 0.0308 (0.0258) acc@1 1.0000 (0.9931) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:21:14] __main__ INFO: \u001b[0mEpoch 28 Step 703/703 lr 0.001000 loss 0.0115 (0.0258) acc@1 1.0000 (0.9931) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:21:14] __main__ INFO: \u001b[0mElapsed 224.43\n",
      "\u001b[32m[2020-07-16 19:21:14] __main__ INFO: \u001b[0mVal 28\n",
      "\u001b[32m[2020-07-16 19:21:22] __main__ INFO: \u001b[0mEpoch 28 loss 0.2631 acc@1 0.9358 acc@5 0.9984\n",
      "\u001b[32m[2020-07-16 19:21:22] __main__ INFO: \u001b[0mElapsed 7.78\n",
      "\u001b[32m[2020-07-16 19:21:22] __main__ INFO: \u001b[0mTrain 29 19684\n",
      "\u001b[32m[2020-07-16 19:21:54] __main__ INFO: \u001b[0mEpoch 29 Step 100/703 lr 0.001000 loss 0.0043 (0.0247) acc@1 1.0000 (0.9930) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:22:26] __main__ INFO: \u001b[0mEpoch 29 Step 200/703 lr 0.001000 loss 0.0083 (0.0250) acc@1 1.0000 (0.9927) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:22:58] __main__ INFO: \u001b[0mEpoch 29 Step 300/703 lr 0.001000 loss 0.0121 (0.0256) acc@1 1.0000 (0.9924) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:23:30] __main__ INFO: \u001b[0mEpoch 29 Step 400/703 lr 0.001000 loss 0.0194 (0.0250) acc@1 1.0000 (0.9924) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:24:01] __main__ INFO: \u001b[0mEpoch 29 Step 500/703 lr 0.001000 loss 0.0195 (0.0254) acc@1 1.0000 (0.9923) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:24:33] __main__ INFO: \u001b[0mEpoch 29 Step 600/703 lr 0.001000 loss 0.0158 (0.0260) acc@1 1.0000 (0.9921) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:25:05] __main__ INFO: \u001b[0mEpoch 29 Step 700/703 lr 0.001000 loss 0.0391 (0.0257) acc@1 0.9844 (0.9922) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:25:06] __main__ INFO: \u001b[0mEpoch 29 Step 703/703 lr 0.001000 loss 0.0134 (0.0257) acc@1 1.0000 (0.9922) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:25:06] __main__ INFO: \u001b[0mElapsed 224.61\n",
      "\u001b[32m[2020-07-16 19:25:06] __main__ INFO: \u001b[0mVal 29\n",
      "\u001b[32m[2020-07-16 19:25:14] __main__ INFO: \u001b[0mEpoch 29 loss 0.2753 acc@1 0.9322 acc@5 0.9986\n",
      "\u001b[32m[2020-07-16 19:25:14] __main__ INFO: \u001b[0mElapsed 7.74\n",
      "\u001b[32m[2020-07-16 19:25:14] __main__ INFO: \u001b[0mTrain 30 20387\n",
      "\u001b[32m[2020-07-16 19:25:46] __main__ INFO: \u001b[0mEpoch 30 Step 100/703 lr 0.001000 loss 0.0425 (0.0228) acc@1 0.9844 (0.9938) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:26:18] __main__ INFO: \u001b[0mEpoch 30 Step 200/703 lr 0.001000 loss 0.0479 (0.0245) acc@1 0.9844 (0.9930) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:26:50] __main__ INFO: \u001b[0mEpoch 30 Step 300/703 lr 0.001000 loss 0.0367 (0.0247) acc@1 0.9844 (0.9927) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:27:22] __main__ INFO: \u001b[0mEpoch 30 Step 400/703 lr 0.001000 loss 0.0226 (0.0246) acc@1 1.0000 (0.9926) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:27:54] __main__ INFO: \u001b[0mEpoch 30 Step 500/703 lr 0.001000 loss 0.0422 (0.0250) acc@1 0.9688 (0.9926) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:28:26] __main__ INFO: \u001b[0mEpoch 30 Step 600/703 lr 0.001000 loss 0.0096 (0.0250) acc@1 1.0000 (0.9928) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:28:58] __main__ INFO: \u001b[0mEpoch 30 Step 700/703 lr 0.001000 loss 0.0221 (0.0251) acc@1 1.0000 (0.9929) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:28:59] __main__ INFO: \u001b[0mEpoch 30 Step 703/703 lr 0.001000 loss 0.0055 (0.0250) acc@1 1.0000 (0.9929) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:28:59] __main__ INFO: \u001b[0mElapsed 225.13\n",
      "\u001b[32m[2020-07-16 19:28:59] __main__ INFO: \u001b[0mVal 30\n",
      "\u001b[32m[2020-07-16 19:29:07] __main__ INFO: \u001b[0mEpoch 30 loss 0.2677 acc@1 0.9338 acc@5 0.9986\n",
      "\u001b[32m[2020-07-16 19:29:07] __main__ INFO: \u001b[0mElapsed 7.73\n",
      "\u001b[32m[2020-07-16 19:29:07] __main__ INFO: \u001b[0mTrain 31 21090\n",
      "\u001b[32m[2020-07-16 19:29:39] __main__ INFO: \u001b[0mEpoch 31 Step 100/703 lr 0.001000 loss 0.0116 (0.0248) acc@1 1.0000 (0.9923) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:30:11] __main__ INFO: \u001b[0mEpoch 31 Step 200/703 lr 0.001000 loss 0.0038 (0.0253) acc@1 1.0000 (0.9926) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:30:43] __main__ INFO: \u001b[0mEpoch 31 Step 300/703 lr 0.001000 loss 0.0217 (0.0256) acc@1 1.0000 (0.9920) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:31:15] __main__ INFO: \u001b[0mEpoch 31 Step 400/703 lr 0.001000 loss 0.0449 (0.0251) acc@1 0.9844 (0.9921) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:31:47] __main__ INFO: \u001b[0mEpoch 31 Step 500/703 lr 0.001000 loss 0.0326 (0.0250) acc@1 0.9844 (0.9923) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:32:19] __main__ INFO: \u001b[0mEpoch 31 Step 600/703 lr 0.001000 loss 0.0133 (0.0249) acc@1 1.0000 (0.9923) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:32:51] __main__ INFO: \u001b[0mEpoch 31 Step 700/703 lr 0.001000 loss 0.0061 (0.0250) acc@1 1.0000 (0.9923) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:32:52] __main__ INFO: \u001b[0mEpoch 31 Step 703/703 lr 0.001000 loss 0.0211 (0.0250) acc@1 1.0000 (0.9923) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:32:52] __main__ INFO: \u001b[0mElapsed 224.89\n",
      "\u001b[32m[2020-07-16 19:32:52] __main__ INFO: \u001b[0mVal 31\n",
      "\u001b[32m[2020-07-16 19:33:00] __main__ INFO: \u001b[0mEpoch 31 loss 0.2645 acc@1 0.9350 acc@5 0.9984\n",
      "\u001b[32m[2020-07-16 19:33:00] __main__ INFO: \u001b[0mElapsed 7.72\n",
      "\u001b[32m[2020-07-16 19:33:00] __main__ INFO: \u001b[0mTrain 32 21793\n",
      "\u001b[32m[2020-07-16 19:33:32] __main__ INFO: \u001b[0mEpoch 32 Step 100/703 lr 0.001000 loss 0.0089 (0.0215) acc@1 1.0000 (0.9944) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:34:04] __main__ INFO: \u001b[0mEpoch 32 Step 200/703 lr 0.001000 loss 0.0414 (0.0203) acc@1 0.9844 (0.9948) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:34:36] __main__ INFO: \u001b[0mEpoch 32 Step 300/703 lr 0.001000 loss 0.0222 (0.0214) acc@1 0.9844 (0.9942) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:35:07] __main__ INFO: \u001b[0mEpoch 32 Step 400/703 lr 0.001000 loss 0.0122 (0.0207) acc@1 1.0000 (0.9946) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:35:39] __main__ INFO: \u001b[0mEpoch 32 Step 500/703 lr 0.001000 loss 0.0110 (0.0214) acc@1 1.0000 (0.9942) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:36:11] __main__ INFO: \u001b[0mEpoch 32 Step 600/703 lr 0.001000 loss 0.0067 (0.0219) acc@1 1.0000 (0.9939) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:36:43] __main__ INFO: \u001b[0mEpoch 32 Step 700/703 lr 0.001000 loss 0.0246 (0.0222) acc@1 0.9844 (0.9937) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:36:44] __main__ INFO: \u001b[0mEpoch 32 Step 703/703 lr 0.001000 loss 0.0373 (0.0223) acc@1 0.9844 (0.9937) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:36:44] __main__ INFO: \u001b[0mElapsed 224.65\n",
      "\u001b[32m[2020-07-16 19:36:44] __main__ INFO: \u001b[0mVal 32\n",
      "\u001b[32m[2020-07-16 19:36:52] __main__ INFO: \u001b[0mEpoch 32 loss 0.2726 acc@1 0.9312 acc@5 0.9986\n",
      "\u001b[32m[2020-07-16 19:36:52] __main__ INFO: \u001b[0mElapsed 7.73\n",
      "\u001b[32m[2020-07-16 19:36:52] __main__ INFO: \u001b[0mTrain 33 22496\n",
      "\u001b[32m[2020-07-16 19:37:24] __main__ INFO: \u001b[0mEpoch 33 Step 100/703 lr 0.001000 loss 0.0079 (0.0233) acc@1 1.0000 (0.9942) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:37:56] __main__ INFO: \u001b[0mEpoch 33 Step 200/703 lr 0.001000 loss 0.0056 (0.0219) acc@1 1.0000 (0.9948) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:38:28] __main__ INFO: \u001b[0mEpoch 33 Step 300/703 lr 0.001000 loss 0.0077 (0.0222) acc@1 1.0000 (0.9947) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:39:00] __main__ INFO: \u001b[0mEpoch 33 Step 400/703 lr 0.001000 loss 0.1001 (0.0226) acc@1 0.9688 (0.9943) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:39:32] __main__ INFO: \u001b[0mEpoch 33 Step 500/703 lr 0.001000 loss 0.0287 (0.0232) acc@1 0.9844 (0.9940) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:40:04] __main__ INFO: \u001b[0mEpoch 33 Step 600/703 lr 0.001000 loss 0.0240 (0.0228) acc@1 1.0000 (0.9941) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:40:36] __main__ INFO: \u001b[0mEpoch 33 Step 700/703 lr 0.001000 loss 0.0121 (0.0231) acc@1 1.0000 (0.9940) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:40:37] __main__ INFO: \u001b[0mEpoch 33 Step 703/703 lr 0.001000 loss 0.0263 (0.0231) acc@1 0.9844 (0.9940) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:40:37] __main__ INFO: \u001b[0mElapsed 224.51\n",
      "\u001b[32m[2020-07-16 19:40:37] __main__ INFO: \u001b[0mVal 33\n",
      "\u001b[32m[2020-07-16 19:40:44] __main__ INFO: \u001b[0mEpoch 33 loss 0.2700 acc@1 0.9338 acc@5 0.9984\n",
      "\u001b[32m[2020-07-16 19:40:44] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-16 19:40:44] __main__ INFO: \u001b[0mTrain 34 23199\n",
      "\u001b[32m[2020-07-16 19:41:16] __main__ INFO: \u001b[0mEpoch 34 Step 100/703 lr 0.001000 loss 0.0121 (0.0220) acc@1 1.0000 (0.9945) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:41:48] __main__ INFO: \u001b[0mEpoch 34 Step 200/703 lr 0.001000 loss 0.0411 (0.0212) acc@1 0.9844 (0.9944) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:42:20] __main__ INFO: \u001b[0mEpoch 34 Step 300/703 lr 0.001000 loss 0.0058 (0.0220) acc@1 1.0000 (0.9938) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:42:52] __main__ INFO: \u001b[0mEpoch 34 Step 400/703 lr 0.001000 loss 0.0094 (0.0224) acc@1 1.0000 (0.9938) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:43:25] __main__ INFO: \u001b[0mEpoch 34 Step 500/703 lr 0.001000 loss 0.0055 (0.0224) acc@1 1.0000 (0.9939) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:43:57] __main__ INFO: \u001b[0mEpoch 34 Step 600/703 lr 0.001000 loss 0.0095 (0.0228) acc@1 1.0000 (0.9937) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:44:28] __main__ INFO: \u001b[0mEpoch 34 Step 700/703 lr 0.001000 loss 0.0171 (0.0229) acc@1 1.0000 (0.9935) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:44:29] __main__ INFO: \u001b[0mEpoch 34 Step 703/703 lr 0.001000 loss 0.0178 (0.0229) acc@1 1.0000 (0.9936) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:44:29] __main__ INFO: \u001b[0mElapsed 225.10\n",
      "\u001b[32m[2020-07-16 19:44:29] __main__ INFO: \u001b[0mVal 34\n",
      "\u001b[32m[2020-07-16 19:44:37] __main__ INFO: \u001b[0mEpoch 34 loss 0.2704 acc@1 0.9346 acc@5 0.9984\n",
      "\u001b[32m[2020-07-16 19:44:37] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-16 19:44:37] __main__ INFO: \u001b[0mTrain 35 23902\n",
      "\u001b[32m[2020-07-16 19:45:09] __main__ INFO: \u001b[0mEpoch 35 Step 100/703 lr 0.001000 loss 0.0126 (0.0207) acc@1 1.0000 (0.9947) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:45:41] __main__ INFO: \u001b[0mEpoch 35 Step 200/703 lr 0.001000 loss 0.0250 (0.0215) acc@1 1.0000 (0.9945) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:46:13] __main__ INFO: \u001b[0mEpoch 35 Step 300/703 lr 0.001000 loss 0.0240 (0.0216) acc@1 0.9844 (0.9941) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:46:45] __main__ INFO: \u001b[0mEpoch 35 Step 400/703 lr 0.001000 loss 0.0190 (0.0210) acc@1 1.0000 (0.9943) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:47:17] __main__ INFO: \u001b[0mEpoch 35 Step 500/703 lr 0.001000 loss 0.0372 (0.0207) acc@1 0.9844 (0.9943) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-16 19:47:49] __main__ INFO: \u001b[0mEpoch 35 Step 600/703 lr 0.001000 loss 0.0202 (0.0209) acc@1 1.0000 (0.9943) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-16 19:48:21] __main__ INFO: \u001b[0mEpoch 35 Step 700/703 lr 0.001000 loss 0.0223 (0.0208) acc@1 1.0000 (0.9943) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:48:22] __main__ INFO: \u001b[0mEpoch 35 Step 703/703 lr 0.001000 loss 0.0146 (0.0208) acc@1 1.0000 (0.9943) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:48:22] __main__ INFO: \u001b[0mElapsed 224.86\n",
      "\u001b[32m[2020-07-16 19:48:22] __main__ INFO: \u001b[0mVal 35\n",
      "\u001b[32m[2020-07-16 19:48:30] __main__ INFO: \u001b[0mEpoch 35 loss 0.2732 acc@1 0.9348 acc@5 0.9982\n",
      "\u001b[32m[2020-07-16 19:48:30] __main__ INFO: \u001b[0mElapsed 7.73\n",
      "\u001b[32m[2020-07-16 19:48:30] __main__ INFO: \u001b[0mTrain 36 24605\n",
      "\u001b[32m[2020-07-16 19:49:02] __main__ INFO: \u001b[0mEpoch 36 Step 100/703 lr 0.001000 loss 0.0575 (0.0225) acc@1 0.9844 (0.9942) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:49:34] __main__ INFO: \u001b[0mEpoch 36 Step 200/703 lr 0.001000 loss 0.0292 (0.0218) acc@1 0.9844 (0.9938) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:50:06] __main__ INFO: \u001b[0mEpoch 36 Step 300/703 lr 0.001000 loss 0.0100 (0.0207) acc@1 1.0000 (0.9944) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:50:38] __main__ INFO: \u001b[0mEpoch 36 Step 400/703 lr 0.001000 loss 0.0130 (0.0211) acc@1 1.0000 (0.9945) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:51:10] __main__ INFO: \u001b[0mEpoch 36 Step 500/703 lr 0.001000 loss 0.0173 (0.0206) acc@1 1.0000 (0.9947) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:51:42] __main__ INFO: \u001b[0mEpoch 36 Step 600/703 lr 0.001000 loss 0.0597 (0.0208) acc@1 0.9688 (0.9944) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:52:14] __main__ INFO: \u001b[0mEpoch 36 Step 700/703 lr 0.001000 loss 0.0136 (0.0212) acc@1 1.0000 (0.9941) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:52:15] __main__ INFO: \u001b[0mEpoch 36 Step 703/703 lr 0.001000 loss 0.0492 (0.0212) acc@1 0.9844 (0.9941) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:52:15] __main__ INFO: \u001b[0mElapsed 225.16\n",
      "\u001b[32m[2020-07-16 19:52:15] __main__ INFO: \u001b[0mVal 36\n",
      "\u001b[32m[2020-07-16 19:52:23] __main__ INFO: \u001b[0mEpoch 36 loss 0.2724 acc@1 0.9334 acc@5 0.9982\n",
      "\u001b[32m[2020-07-16 19:52:23] __main__ INFO: \u001b[0mElapsed 7.75\n",
      "\u001b[32m[2020-07-16 19:52:23] __main__ INFO: \u001b[0mTrain 37 25308\n",
      "\u001b[32m[2020-07-16 19:52:55] __main__ INFO: \u001b[0mEpoch 37 Step 100/703 lr 0.001000 loss 0.0083 (0.0203) acc@1 1.0000 (0.9942) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:53:27] __main__ INFO: \u001b[0mEpoch 37 Step 200/703 lr 0.001000 loss 0.0444 (0.0196) acc@1 0.9688 (0.9946) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:53:59] __main__ INFO: \u001b[0mEpoch 37 Step 300/703 lr 0.001000 loss 0.0121 (0.0208) acc@1 1.0000 (0.9942) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:54:30] __main__ INFO: \u001b[0mEpoch 37 Step 400/703 lr 0.001000 loss 0.0150 (0.0202) acc@1 1.0000 (0.9946) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:55:02] __main__ INFO: \u001b[0mEpoch 37 Step 500/703 lr 0.001000 loss 0.0059 (0.0203) acc@1 1.0000 (0.9945) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:55:35] __main__ INFO: \u001b[0mEpoch 37 Step 600/703 lr 0.001000 loss 0.0317 (0.0205) acc@1 1.0000 (0.9946) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:56:07] __main__ INFO: \u001b[0mEpoch 37 Step 700/703 lr 0.001000 loss 0.0282 (0.0202) acc@1 1.0000 (0.9948) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:56:08] __main__ INFO: \u001b[0mEpoch 37 Step 703/703 lr 0.001000 loss 0.0259 (0.0202) acc@1 0.9844 (0.9948) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:56:08] __main__ INFO: \u001b[0mElapsed 224.98\n",
      "\u001b[32m[2020-07-16 19:56:08] __main__ INFO: \u001b[0mVal 37\n",
      "\u001b[32m[2020-07-16 19:56:15] __main__ INFO: \u001b[0mEpoch 37 loss 0.2741 acc@1 0.9336 acc@5 0.9982\n",
      "\u001b[32m[2020-07-16 19:56:15] __main__ INFO: \u001b[0mElapsed 7.77\n",
      "\u001b[32m[2020-07-16 19:56:15] __main__ INFO: \u001b[0mTrain 38 26011\n",
      "\u001b[32m[2020-07-16 19:56:48] __main__ INFO: \u001b[0mEpoch 38 Step 100/703 lr 0.001000 loss 0.0072 (0.0186) acc@1 1.0000 (0.9953) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:57:20] __main__ INFO: \u001b[0mEpoch 38 Step 200/703 lr 0.001000 loss 0.0020 (0.0191) acc@1 1.0000 (0.9948) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:57:52] __main__ INFO: \u001b[0mEpoch 38 Step 300/703 lr 0.001000 loss 0.0344 (0.0187) acc@1 0.9844 (0.9952) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:58:24] __main__ INFO: \u001b[0mEpoch 38 Step 400/703 lr 0.001000 loss 0.0552 (0.0189) acc@1 0.9844 (0.9952) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:58:56] __main__ INFO: \u001b[0mEpoch 38 Step 500/703 lr 0.001000 loss 0.0115 (0.0187) acc@1 1.0000 (0.9953) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 19:59:28] __main__ INFO: \u001b[0mEpoch 38 Step 600/703 lr 0.001000 loss 0.0136 (0.0192) acc@1 1.0000 (0.9951) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:00:00] __main__ INFO: \u001b[0mEpoch 38 Step 700/703 lr 0.001000 loss 0.0108 (0.0192) acc@1 1.0000 (0.9950) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:00:01] __main__ INFO: \u001b[0mEpoch 38 Step 703/703 lr 0.001000 loss 0.0255 (0.0192) acc@1 1.0000 (0.9950) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:00:01] __main__ INFO: \u001b[0mElapsed 225.25\n",
      "\u001b[32m[2020-07-16 20:00:01] __main__ INFO: \u001b[0mVal 38\n",
      "\u001b[32m[2020-07-16 20:00:08] __main__ INFO: \u001b[0mEpoch 38 loss 0.2785 acc@1 0.9326 acc@5 0.9982\n",
      "\u001b[32m[2020-07-16 20:00:08] __main__ INFO: \u001b[0mElapsed 7.80\n",
      "\u001b[32m[2020-07-16 20:00:08] __main__ INFO: \u001b[0mTrain 39 26714\n",
      "\u001b[32m[2020-07-16 20:00:41] __main__ INFO: \u001b[0mEpoch 39 Step 100/703 lr 0.001000 loss 0.0086 (0.0161) acc@1 1.0000 (0.9962) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:01:13] __main__ INFO: \u001b[0mEpoch 39 Step 200/703 lr 0.001000 loss 0.0042 (0.0172) acc@1 1.0000 (0.9954) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:01:45] __main__ INFO: \u001b[0mEpoch 39 Step 300/703 lr 0.001000 loss 0.0144 (0.0169) acc@1 1.0000 (0.9955) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:02:16] __main__ INFO: \u001b[0mEpoch 39 Step 400/703 lr 0.001000 loss 0.0431 (0.0179) acc@1 0.9844 (0.9950) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:02:48] __main__ INFO: \u001b[0mEpoch 39 Step 500/703 lr 0.001000 loss 0.0242 (0.0192) acc@1 1.0000 (0.9945) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:03:20] __main__ INFO: \u001b[0mEpoch 39 Step 600/703 lr 0.001000 loss 0.0118 (0.0192) acc@1 1.0000 (0.9946) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:03:52] __main__ INFO: \u001b[0mEpoch 39 Step 700/703 lr 0.001000 loss 0.0016 (0.0193) acc@1 1.0000 (0.9945) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:03:53] __main__ INFO: \u001b[0mEpoch 39 Step 703/703 lr 0.001000 loss 0.0161 (0.0193) acc@1 1.0000 (0.9945) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:03:53] __main__ INFO: \u001b[0mElapsed 224.98\n",
      "\u001b[32m[2020-07-16 20:03:53] __main__ INFO: \u001b[0mVal 39\n",
      "\u001b[32m[2020-07-16 20:04:01] __main__ INFO: \u001b[0mEpoch 39 loss 0.2755 acc@1 0.9320 acc@5 0.9982\n",
      "\u001b[32m[2020-07-16 20:04:01] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-16 20:04:01] __main__ INFO: \u001b[0mTrain 40 27417\n",
      "\u001b[32m[2020-07-16 20:04:33] __main__ INFO: \u001b[0mEpoch 40 Step 100/703 lr 0.001000 loss 0.0101 (0.0157) acc@1 1.0000 (0.9962) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:05:05] __main__ INFO: \u001b[0mEpoch 40 Step 200/703 lr 0.001000 loss 0.0284 (0.0172) acc@1 0.9844 (0.9960) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:05:37] __main__ INFO: \u001b[0mEpoch 40 Step 300/703 lr 0.001000 loss 0.0051 (0.0177) acc@1 1.0000 (0.9958) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:06:09] __main__ INFO: \u001b[0mEpoch 40 Step 400/703 lr 0.001000 loss 0.0092 (0.0183) acc@1 1.0000 (0.9954) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:06:41] __main__ INFO: \u001b[0mEpoch 40 Step 500/703 lr 0.001000 loss 0.0099 (0.0189) acc@1 1.0000 (0.9951) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:07:13] __main__ INFO: \u001b[0mEpoch 40 Step 600/703 lr 0.001000 loss 0.0075 (0.0191) acc@1 1.0000 (0.9948) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:07:45] __main__ INFO: \u001b[0mEpoch 40 Step 700/703 lr 0.001000 loss 0.0195 (0.0189) acc@1 1.0000 (0.9950) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:07:46] __main__ INFO: \u001b[0mEpoch 40 Step 703/703 lr 0.001000 loss 0.0079 (0.0189) acc@1 1.0000 (0.9950) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:07:46] __main__ INFO: \u001b[0mElapsed 224.95\n",
      "\u001b[32m[2020-07-16 20:07:46] __main__ INFO: \u001b[0mVal 40\n",
      "\u001b[32m[2020-07-16 20:07:54] __main__ INFO: \u001b[0mEpoch 40 loss 0.2809 acc@1 0.9320 acc@5 0.9980\n",
      "\u001b[32m[2020-07-16 20:07:54] __main__ INFO: \u001b[0mElapsed 7.75\n",
      "\u001b[32m[2020-07-16 20:07:54] __main__ INFO: \u001b[0mTrain 41 28120\n",
      "\u001b[32m[2020-07-16 20:08:26] __main__ INFO: \u001b[0mEpoch 41 Step 100/703 lr 0.001000 loss 0.0086 (0.0184) acc@1 1.0000 (0.9948) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:08:58] __main__ INFO: \u001b[0mEpoch 41 Step 200/703 lr 0.001000 loss 0.0311 (0.0176) acc@1 1.0000 (0.9955) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:09:30] __main__ INFO: \u001b[0mEpoch 41 Step 300/703 lr 0.001000 loss 0.0324 (0.0177) acc@1 0.9844 (0.9955) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:10:02] __main__ INFO: \u001b[0mEpoch 41 Step 400/703 lr 0.001000 loss 0.0103 (0.0178) acc@1 1.0000 (0.9956) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:10:34] __main__ INFO: \u001b[0mEpoch 41 Step 500/703 lr 0.001000 loss 0.0118 (0.0178) acc@1 1.0000 (0.9955) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:11:06] __main__ INFO: \u001b[0mEpoch 41 Step 600/703 lr 0.001000 loss 0.0120 (0.0177) acc@1 1.0000 (0.9955) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:11:37] __main__ INFO: \u001b[0mEpoch 41 Step 700/703 lr 0.001000 loss 0.0306 (0.0177) acc@1 0.9844 (0.9955) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:11:38] __main__ INFO: \u001b[0mEpoch 41 Step 703/703 lr 0.001000 loss 0.0210 (0.0178) acc@1 0.9844 (0.9954) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:11:38] __main__ INFO: \u001b[0mElapsed 224.49\n",
      "\u001b[32m[2020-07-16 20:11:38] __main__ INFO: \u001b[0mVal 41\n",
      "\u001b[32m[2020-07-16 20:11:46] __main__ INFO: \u001b[0mEpoch 41 loss 0.2747 acc@1 0.9344 acc@5 0.9980\n",
      "\u001b[32m[2020-07-16 20:11:46] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-16 20:11:46] __main__ INFO: \u001b[0mTrain 42 28823\n",
      "\u001b[32m[2020-07-16 20:12:18] __main__ INFO: \u001b[0mEpoch 42 Step 100/703 lr 0.001000 loss 0.0047 (0.0178) acc@1 1.0000 (0.9948) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:12:50] __main__ INFO: \u001b[0mEpoch 42 Step 200/703 lr 0.001000 loss 0.0069 (0.0185) acc@1 1.0000 (0.9945) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:13:22] __main__ INFO: \u001b[0mEpoch 42 Step 300/703 lr 0.001000 loss 0.0912 (0.0187) acc@1 0.9531 (0.9944) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:13:54] __main__ INFO: \u001b[0mEpoch 42 Step 400/703 lr 0.001000 loss 0.0102 (0.0178) acc@1 1.0000 (0.9950) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:14:26] __main__ INFO: \u001b[0mEpoch 42 Step 500/703 lr 0.001000 loss 0.0814 (0.0180) acc@1 0.9688 (0.9949) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:14:58] __main__ INFO: \u001b[0mEpoch 42 Step 600/703 lr 0.001000 loss 0.0024 (0.0181) acc@1 1.0000 (0.9948) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:15:30] __main__ INFO: \u001b[0mEpoch 42 Step 700/703 lr 0.001000 loss 0.0056 (0.0184) acc@1 1.0000 (0.9946) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:15:31] __main__ INFO: \u001b[0mEpoch 42 Step 703/703 lr 0.001000 loss 0.0020 (0.0184) acc@1 1.0000 (0.9946) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:15:31] __main__ INFO: \u001b[0mElapsed 225.02\n",
      "\u001b[32m[2020-07-16 20:15:31] __main__ INFO: \u001b[0mVal 42\n",
      "\u001b[32m[2020-07-16 20:15:39] __main__ INFO: \u001b[0mEpoch 42 loss 0.2781 acc@1 0.9330 acc@5 0.9982\n",
      "\u001b[32m[2020-07-16 20:15:39] __main__ INFO: \u001b[0mElapsed 7.76\n",
      "\u001b[32m[2020-07-16 20:15:39] __main__ INFO: \u001b[0mTrain 43 29526\n",
      "\u001b[32m[2020-07-16 20:16:11] __main__ INFO: \u001b[0mEpoch 43 Step 100/703 lr 0.001000 loss 0.0095 (0.0175) acc@1 1.0000 (0.9950) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:16:43] __main__ INFO: \u001b[0mEpoch 43 Step 200/703 lr 0.001000 loss 0.0032 (0.0175) acc@1 1.0000 (0.9950) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:17:15] __main__ INFO: \u001b[0mEpoch 43 Step 300/703 lr 0.001000 loss 0.0127 (0.0176) acc@1 1.0000 (0.9952) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:17:47] __main__ INFO: \u001b[0mEpoch 43 Step 400/703 lr 0.001000 loss 0.0602 (0.0180) acc@1 0.9688 (0.9950) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:18:19] __main__ INFO: \u001b[0mEpoch 43 Step 500/703 lr 0.001000 loss 0.0186 (0.0180) acc@1 1.0000 (0.9952) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:18:51] __main__ INFO: \u001b[0mEpoch 43 Step 600/703 lr 0.001000 loss 0.0504 (0.0182) acc@1 0.9844 (0.9951) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:19:23] __main__ INFO: \u001b[0mEpoch 43 Step 700/703 lr 0.001000 loss 0.0237 (0.0183) acc@1 0.9844 (0.9950) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:19:24] __main__ INFO: \u001b[0mEpoch 43 Step 703/703 lr 0.001000 loss 0.0037 (0.0183) acc@1 1.0000 (0.9951) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:19:24] __main__ INFO: \u001b[0mElapsed 224.75\n",
      "\u001b[32m[2020-07-16 20:19:24] __main__ INFO: \u001b[0mVal 43\n",
      "\u001b[32m[2020-07-16 20:19:31] __main__ INFO: \u001b[0mEpoch 43 loss 0.2747 acc@1 0.9324 acc@5 0.9984\n",
      "\u001b[32m[2020-07-16 20:19:31] __main__ INFO: \u001b[0mElapsed 7.74\n",
      "\u001b[32m[2020-07-16 20:19:31] __main__ INFO: \u001b[0mTrain 44 30229\n",
      "\u001b[32m[2020-07-16 20:20:04] __main__ INFO: \u001b[0mEpoch 44 Step 100/703 lr 0.001000 loss 0.0070 (0.0157) acc@1 1.0000 (0.9962) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:20:35] __main__ INFO: \u001b[0mEpoch 44 Step 200/703 lr 0.001000 loss 0.0054 (0.0171) acc@1 1.0000 (0.9956) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:21:07] __main__ INFO: \u001b[0mEpoch 44 Step 300/703 lr 0.001000 loss 0.0024 (0.0175) acc@1 1.0000 (0.9953) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:21:39] __main__ INFO: \u001b[0mEpoch 44 Step 400/703 lr 0.001000 loss 0.0144 (0.0175) acc@1 1.0000 (0.9952) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:22:11] __main__ INFO: \u001b[0mEpoch 44 Step 500/703 lr 0.001000 loss 0.0312 (0.0176) acc@1 0.9844 (0.9952) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:22:43] __main__ INFO: \u001b[0mEpoch 44 Step 600/703 lr 0.001000 loss 0.0064 (0.0182) acc@1 1.0000 (0.9951) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:23:15] __main__ INFO: \u001b[0mEpoch 44 Step 700/703 lr 0.001000 loss 0.0020 (0.0179) acc@1 1.0000 (0.9951) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:23:16] __main__ INFO: \u001b[0mEpoch 44 Step 703/703 lr 0.001000 loss 0.0317 (0.0179) acc@1 0.9844 (0.9950) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:23:16] __main__ INFO: \u001b[0mElapsed 224.61\n",
      "\u001b[32m[2020-07-16 20:23:16] __main__ INFO: \u001b[0mVal 44\n",
      "\u001b[32m[2020-07-16 20:23:24] __main__ INFO: \u001b[0mEpoch 44 loss 0.2784 acc@1 0.9332 acc@5 0.9984\n",
      "\u001b[32m[2020-07-16 20:23:24] __main__ INFO: \u001b[0mElapsed 7.73\n",
      "\u001b[32m[2020-07-16 20:23:24] __main__ INFO: \u001b[0mTrain 45 30932\n",
      "\u001b[32m[2020-07-16 20:23:56] __main__ INFO: \u001b[0mEpoch 45 Step 100/703 lr 0.001000 loss 0.0427 (0.0185) acc@1 0.9844 (0.9950) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:24:28] __main__ INFO: \u001b[0mEpoch 45 Step 200/703 lr 0.001000 loss 0.0185 (0.0176) acc@1 1.0000 (0.9958) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:25:00] __main__ INFO: \u001b[0mEpoch 45 Step 300/703 lr 0.001000 loss 0.0387 (0.0166) acc@1 0.9844 (0.9960) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:25:32] __main__ INFO: \u001b[0mEpoch 45 Step 400/703 lr 0.001000 loss 0.0452 (0.0164) acc@1 0.9844 (0.9961) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:26:03] __main__ INFO: \u001b[0mEpoch 45 Step 500/703 lr 0.001000 loss 0.0087 (0.0166) acc@1 1.0000 (0.9959) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:26:35] __main__ INFO: \u001b[0mEpoch 45 Step 600/703 lr 0.001000 loss 0.0102 (0.0165) acc@1 1.0000 (0.9959) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:27:07] __main__ INFO: \u001b[0mEpoch 45 Step 700/703 lr 0.001000 loss 0.0404 (0.0162) acc@1 0.9844 (0.9960) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:27:08] __main__ INFO: \u001b[0mEpoch 45 Step 703/703 lr 0.001000 loss 0.0525 (0.0162) acc@1 0.9844 (0.9960) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-16 20:27:08] __main__ INFO: \u001b[0mElapsed 224.40\n",
      "\u001b[32m[2020-07-16 20:27:08] __main__ INFO: \u001b[0mVal 45\n",
      "\u001b[32m[2020-07-16 20:27:16] __main__ INFO: \u001b[0mEpoch 45 loss 0.2781 acc@1 0.9346 acc@5 0.9982\n",
      "\u001b[32m[2020-07-16 20:27:16] __main__ INFO: \u001b[0mElapsed 7.74\n",
      "\u001b[32m[2020-07-16 20:27:16] __main__ INFO: \u001b[0mTrain 46 31635\n",
      "\u001b[32m[2020-07-16 20:27:48] __main__ INFO: \u001b[0mEpoch 46 Step 100/703 lr 0.001000 loss 0.0197 (0.0163) acc@1 1.0000 (0.9970) acc@5 1.0000 (1.0000)\n"
     ]
    }
   ],
   "source": [
    "# Resume training with the un-augmented data\n",
    "os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "!python train.py --config /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_1_20_c10val/exp00/config.yaml \\\n",
    "    train.checkpoint /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_1_20_c10val/exp00/checkpoint_00400.pth \\\n",
    "    dataset.name CIFAR10 \\\n",
    "    train.base_lr .001 \\\n",
    "    train.output_dir /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_1_20_c10val/exp00_resume400_50 \\\n",
    "    scheduler.epochs 50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-02 12:22:41] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_2_20_c10val/exp00_resume400_50/checkpoint_00050.pth\n",
      "Files already downloaded and verified\n",
      "100%|| 157/157 [00:19<00:00,  8.17it/s]\n",
      "\u001b[32m[2020-07-02 12:23:01] __main__ INFO: \u001b[0mElapsed 19.22\n",
      "\u001b[32m[2020-07-02 12:23:01] __main__ INFO: \u001b[0mLoss 0.3482 Accuracy 0.9123\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10 test dataset \n",
    "# Write the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/densenet.yaml \\\n",
    "   model.densenet.depth 100 \\\n",
    "   model.densenet.growth_rate 12 \\\n",
    "   test.batch_size 64 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_1_20_c10val/exp00_resume400_50/checkpoint_00050.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_1_20_c10val/exp00_resume400_50/test_results_0050_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-02 12:24:06] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_2_20_c10val/exp00/checkpoint_00400.pth\n",
      "Files already downloaded and verified\n",
      "100%|| 157/157 [00:19<00:00,  8.21it/s]\n",
      "\u001b[32m[2020-07-02 12:24:26] __main__ INFO: \u001b[0mElapsed 19.13\n",
      "\u001b[32m[2020-07-02 12:24:26] __main__ INFO: \u001b[0mLoss 1.0119 Accuracy 0.8154\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10 test dataset \n",
    "# Write the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/densenet.yaml \\\n",
    "   model.densenet.depth 100 \\\n",
    "   model.densenet.growth_rate 12 \\\n",
    "   test.batch_size 64 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_1_20_c10val/exp00/checkpoint_00400.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_1_20_c10val/exp00/test_results_0400_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-02 12:25:26] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_2_20_c10val/exp00_resume400_50/checkpoint_00050.pth\n",
      "CIFAR 10.1\n",
      "100%|| 32/32 [00:04<00:00,  7.67it/s]\n",
      "\u001b[32m[2020-07-02 12:25:31] __main__ INFO: \u001b[0mElapsed 4.17\n",
      "\u001b[32m[2020-07-02 12:25:31] __main__ INFO: \u001b[0mLoss 0.7125 Accuracy 0.8315\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10.1 test dataset \n",
    "# Write the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/densenet.yaml \\\n",
    "   model.densenet.depth 100 \\\n",
    "   model.densenet.growth_rate 12 \\\n",
    "   test.batch_size 64 \\\n",
    "   dataset.name CIFAR101 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_1_20_c10val/exp00_resume400_50/checkpoint_00050.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_1_20_c10val/exp00_resume400_50/test_results_0050_cifar101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-02 12:28:28] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_2_20_c10val/exp00/checkpoint_00400.pth\n",
      "CIFAR 10.1\n",
      "100%|| 32/32 [00:04<00:00,  7.64it/s]\n",
      "\u001b[32m[2020-07-02 12:28:33] __main__ INFO: \u001b[0mElapsed 4.19\n",
      "\u001b[32m[2020-07-02 12:28:33] __main__ INFO: \u001b[0mLoss 1.8176 Accuracy 0.6815\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10.1 test dataset \n",
    "# Write the results to the test output directory specified.\n",
    "os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "!python evaluate.py --config configs/cifar/densenet.yaml \\\n",
    "    model.densenet.depth 100 \\\n",
    "    model.densenet.growth_rate 12 \\\n",
    "    test.batch_size 64 \\\n",
    "    dataset.name CIFAR101 \\\n",
    "    test.checkpoint /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_1_20_c10val/exp00/checkpoint_00400.pth \\\n",
    "    test.output_dir /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_1_20_c10val/exp00/test_results_0400_cifar101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-02 12:29:35] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_2_20_c10val/exp00/checkpoint_00300.pth\n",
      "Files already downloaded and verified\n",
      "100%|| 157/157 [00:19<00:00,  8.19it/s]\n",
      "\u001b[32m[2020-07-02 12:29:55] __main__ INFO: \u001b[0mElapsed 19.18\n",
      "\u001b[32m[2020-07-02 12:29:55] __main__ INFO: \u001b[0mLoss 0.9771 Accuracy 0.8119\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10 test dataset \n",
    "# Write the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/densenet.yaml \\\n",
    "   model.densenet.depth 100 \\\n",
    "   model.densenet.growth_rate 12 \\\n",
    "   test.batch_size 64 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_1_20_c10val/exp00/checkpoint_00300.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_1_20_c10val/exp00/test_results_0300_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-02 12:30:19] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_2_20_c10val/exp00/checkpoint_00300.pth\n",
      "CIFAR 10.1\n",
      "100%|| 32/32 [00:04<00:00,  7.64it/s]\n",
      "\u001b[32m[2020-07-02 12:30:23] __main__ INFO: \u001b[0mElapsed 4.19\n",
      "\u001b[32m[2020-07-02 12:30:23] __main__ INFO: \u001b[0mLoss 1.7810 Accuracy 0.6745\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10 test dataset \n",
    "# Write the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/densenet.yaml \\\n",
    "   model.densenet.depth 100 \\\n",
    "   model.densenet.growth_rate 12 \\\n",
    "   test.batch_size 64 \\\n",
    "   dataset.name CIFAR101 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_1_20_c10val/exp00/checkpoint_00300.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_1_20_c10val/exp00/test_results_0300_cifar101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Record the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "model = 'densenet_BC_100_12_ra_1_20_c10val'\n",
    "model_refined = model + '_refined400'\n",
    "\n",
    "a = pd.Series([model, 400, 'cifar10', ])\n",
    "c = pd.Series([model, 400, 'cifar10.1', ])\n",
    "\n",
    "e = pd.Series([model_refined, 50, 'cifar10.1', ])\n",
    "f = pd.Series([model_refined, 50, 'cifar10', ])\n",
    "               \n",
    "df_results = pd.concat([a,c,e,f], axis=1).T\n",
    "df_results.columns = ['Model', 'Epoch', 'Testset', 'Loss', 'Accuracy']\n",
    "\n",
    "df_results['Original_Accuracy'] = df_results.apply((lambda row: 95.5 if row[2] == 'cifar10' else 87.6), axis=1)\n",
    "df_results['Original_CI'] = df_results.apply((lambda row: (95.1, 95.9) if row[2] == 'cifar10' else (86.1, 89.0)), axis=1)\n",
    "\n",
    "df_results.to_csv('/home/ec2-user/SageMaker/experiments/' + model + '/results.csv')\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the model checkpoints, configs, and results to S3 \n",
    "bucket='sagemaker-june29'\n",
    "prefix = 'sagemaker/results/original-models/densenet_BC_100_12_ra_1_20_c10val'\n",
    "path = '/home/ec2-user/SageMaker/experiments/densenet_BC_100_12_ra_1_20_c10val'\n",
    "\n",
    "s3_resource = boto3.resource(\"s3\", region_name=\"us-east-2\")\n",
    "\n",
    "def uploadDirectory(local_path,bucket_name,s3_prefix):\n",
    "\n",
    "    my_bucket = s3_resource.Bucket(bucket_name)\n",
    "    \n",
    "    for path, subdirs, files in os.walk(local_path):\n",
    "        path = path.replace(\"\\\\\",\"/\")\n",
    "        directory_name = path.replace(local_path,\"\")\n",
    "        for file in files:\n",
    "            #print(\"Local File:\", os.path.join(path, file))\n",
    "            #print(\"      Dest:\", s3_prefix+directory_name+'/'+file)\n",
    "            my_bucket.upload_file(os.path.join(path, file), s3_prefix+directory_name+'/'+file)\n",
    "    \n",
    "uploadDirectory(path,bucket,prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
