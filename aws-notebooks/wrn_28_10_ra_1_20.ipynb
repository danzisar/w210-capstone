{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wide Residual Net 29 4x64\n",
    "- Training Dataset: RandAugment, N=1, M=20\n",
    "- Sagemaker Notebook must be of type, conda_pytorch_p36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy \n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 1)) (1.18.1)\n",
      "Requirement already satisfied: torch>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 2)) (1.4.0)\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 3)) (0.5.0)\n",
      "Requirement already satisfied: fvcore in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (0.1.1.post20200704)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 5)) (4.44.1)\n",
      "Requirement already satisfied: yacs in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 6)) (0.1.7)\n",
      "Requirement already satisfied: apex from git+https://github.com/NVIDIA/apex.git#egg=apex in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 7)) (0.1)\n",
      "Requirement already satisfied: termcolor in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 8)) (1.1.0)\n",
      "Requirement already satisfied: thop<0.0.31.post2004070130 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 9)) (0.0.31.post2001170342)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 3)) (1.14.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 3)) (7.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from fvcore->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (5.3.1)\n",
      "Requirement already satisfied: tabulate in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from fvcore->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (0.8.7)\n",
      "Requirement already satisfied: portalocker in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from fvcore->-r /home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt (line 4)) (1.7.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Sagemaker Notebook must be of type conda_pytorch_p36\n",
    "\n",
    "!pip install -r '/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/requirements.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (2.2.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.18.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (3.12.2)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.30.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.4.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.7.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.18.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (46.1.3.post20200330)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (3.2.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.14.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.34.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.9.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (2.23.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard) (3.4.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.1.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (1.5.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.4.5.2)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (1.25.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.9)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard) (2.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Need to add this to requirements.txt\n",
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-11 15:53:31] __main__ INFO: \u001b[0mdevice: cuda\n",
      "cudnn:\n",
      "  benchmark: True\n",
      "  deterministic: False\n",
      "dataset:\n",
      "  name: CIFAR10_RA_1_20\n",
      "  dataset_dir: ''\n",
      "  image_size: 32\n",
      "  n_channels: 3\n",
      "  n_classes: 10\n",
      "model:\n",
      "  type: cifar\n",
      "  name: wrn\n",
      "  init_mode: kaiming_fan_in\n",
      "  vgg:\n",
      "    n_channels: [64, 128, 256, 512, 512]\n",
      "    n_layers: [2, 2, 3, 3, 3]\n",
      "    use_bn: True\n",
      "  resnet:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "  resnet_preact:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "  wrn:\n",
      "    depth: 28\n",
      "    initial_channels: 16\n",
      "    widening_factor: 10\n",
      "    drop_rate: 0.0\n",
      "  densenet:\n",
      "    depth: 100\n",
      "    n_blocks: [6, 12, 24, 16]\n",
      "    block_type: bottleneck\n",
      "    growth_rate: 12\n",
      "    drop_rate: 0.0\n",
      "    compression_rate: 0.5\n",
      "  pyramidnet:\n",
      "    depth: 272\n",
      "    n_blocks: [3, 24, 36, 3]\n",
      "    initial_channels: 16\n",
      "    block_type: bottleneck\n",
      "    alpha: 200\n",
      "  resnext:\n",
      "    depth: 29\n",
      "    n_blocks: [3, 4, 6, 3]\n",
      "    initial_channels: 64\n",
      "    cardinality: 8\n",
      "    base_channels: 4\n",
      "  shake_shake:\n",
      "    depth: 26\n",
      "    initial_channels: 96\n",
      "    shake_forward: True\n",
      "    shake_backward: True\n",
      "    shake_image: True\n",
      "  se_resnet_preact:\n",
      "    depth: 110\n",
      "    initial_channels: 16\n",
      "    se_reduction: 16\n",
      "    block_type: basic\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "train:\n",
      "  checkpoint: ''\n",
      "  resume: False\n",
      "  precision: O0\n",
      "  batch_size: 128\n",
      "  subdivision: 1\n",
      "  optimizer: sgd\n",
      "  base_lr: 0.1\n",
      "  momentum: 0.9\n",
      "  nesterov: True\n",
      "  weight_decay: 0.0005\n",
      "  no_weight_decay_on_bn: False\n",
      "  gradient_clip: 0\n",
      "  start_epoch: 0\n",
      "  seed: 0\n",
      "  val_first: True\n",
      "  val_period: 1\n",
      "  val_ratio: 0.1\n",
      "  use_test_as_val: False\n",
      "  output_dir: /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_1_20/exp00\n",
      "  log_period: 100\n",
      "  checkpoint_period: 100\n",
      "  use_tensorboard: True\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: True\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "  distributed: False\n",
      "  dist:\n",
      "    backend: nccl\n",
      "    init_method: env://\n",
      "    world_size: -1\n",
      "    node_rank: -1\n",
      "    local_rank: 0\n",
      "    use_sync_bn: False\n",
      "tensorboard:\n",
      "  train_images: False\n",
      "  val_images: False\n",
      "  model_params: False\n",
      "optim:\n",
      "  adam:\n",
      "    betas: (0.9, 0.999)\n",
      "  lars:\n",
      "    eps: 1e-09\n",
      "    threshold: 0.01\n",
      "  adabound:\n",
      "    betas: (0.9, 0.999)\n",
      "    final_lr: 0.1\n",
      "    gamma: 0.001\n",
      "scheduler:\n",
      "  epochs: 400\n",
      "  warmup:\n",
      "    type: none\n",
      "    epochs: 0\n",
      "    start_factor: 0.001\n",
      "    exponent: 4\n",
      "  type: multistep\n",
      "  milestones: [60, 120, 160]\n",
      "  lr_decay: 0.2\n",
      "  lr_min_factor: 0.001\n",
      "  T0: 10\n",
      "  T_mul: 1.0\n",
      "validation:\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: False\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "augmentation:\n",
      "  use_random_crop: True\n",
      "  use_random_horizontal_flip: True\n",
      "  use_cutout: False\n",
      "  use_random_erasing: False\n",
      "  use_dual_cutout: False\n",
      "  use_mixup: False\n",
      "  use_ricap: False\n",
      "  use_cutmix: False\n",
      "  use_label_smoothing: False\n",
      "  random_crop:\n",
      "    padding: 4\n",
      "    fill: 0\n",
      "    padding_mode: constant\n",
      "  random_horizontal_flip:\n",
      "    prob: 0.5\n",
      "  cutout:\n",
      "    prob: 1.0\n",
      "    mask_size: 16\n",
      "    cut_inside: False\n",
      "    mask_color: 0\n",
      "    dual_cutout_alpha: 0.1\n",
      "  random_erasing:\n",
      "    prob: 0.5\n",
      "    area_ratio_range: [0.02, 0.4]\n",
      "    min_aspect_ratio: 0.3\n",
      "    max_attempt: 20\n",
      "  mixup:\n",
      "    alpha: 1.0\n",
      "  ricap:\n",
      "    beta: 0.3\n",
      "  cutmix:\n",
      "    alpha: 1.0\n",
      "  label_smoothing:\n",
      "    epsilon: 0.1\n",
      "tta:\n",
      "  use_resize: False\n",
      "  use_center_crop: False\n",
      "  resize: 256\n",
      "test:\n",
      "  checkpoint: ''\n",
      "  output_dir: ''\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    pin_memory: False\n",
      "\u001b[32m[2020-07-11 15:53:31] __main__ INFO: \u001b[0menv_info:\n",
      "  pytorch_version: 1.4.0\n",
      "  cuda_version: 10.1\n",
      "  cudnn_version: 7603\n",
      "  num_gpus: 1\n",
      "  gpu_name: Tesla K80\n",
      "  gpu_capability: 3.7\n",
      "\u001b[32m[2020-07-11 15:53:36] __main__ INFO: \u001b[0mMACs  : 5.25G\n",
      "\u001b[32m[2020-07-11 15:53:36] __main__ INFO: \u001b[0m#params: 36.48M\n",
      "Selected optimization level O0:  Pure FP32 training.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n",
      "\u001b[32m[2020-07-11 15:53:36] __main__ INFO: \u001b[0mVal 0\n",
      "\u001b[32m[2020-07-11 15:53:56] __main__ INFO: \u001b[0mEpoch 0 loss 239.3287 acc@1 0.1016 acc@5 0.4966\n",
      "\u001b[32m[2020-07-11 15:53:56] __main__ INFO: \u001b[0mElapsed 19.56\n",
      "\u001b[32m[2020-07-11 15:53:56] __main__ INFO: \u001b[0mTrain 1 0\n",
      "\u001b[32m[2020-07-11 15:55:52] __main__ INFO: \u001b[0mEpoch 1 Step 100/351 lr 0.100000 loss 2.0489 (2.3085) acc@1 0.2734 (0.1668) acc@5 0.6875 (0.6350)\n",
      "\u001b[32m[2020-07-11 15:57:43] __main__ INFO: \u001b[0mEpoch 1 Step 200/351 lr 0.100000 loss 1.9828 (2.1810) acc@1 0.2188 (0.1968) acc@5 0.7891 (0.6847)\n",
      "\u001b[32m[2020-07-11 15:59:35] __main__ INFO: \u001b[0mEpoch 1 Step 300/351 lr 0.100000 loss 1.8365 (2.1097) acc@1 0.2734 (0.2210) acc@5 0.8047 (0.7094)\n",
      "\u001b[32m[2020-07-11 16:00:32] __main__ INFO: \u001b[0mEpoch 1 Step 351/351 lr 0.100000 loss 1.8688 (2.0816) acc@1 0.3516 (0.2318) acc@5 0.7891 (0.7172)\n",
      "\u001b[32m[2020-07-11 16:00:32] __main__ INFO: \u001b[0mElapsed 396.28\n",
      "\u001b[32m[2020-07-11 16:00:32] __main__ INFO: \u001b[0mVal 1\n",
      "\u001b[32m[2020-07-11 16:00:45] __main__ INFO: \u001b[0mEpoch 1 loss 1.9493 acc@1 0.2872 acc@5 0.7784\n",
      "\u001b[32m[2020-07-11 16:00:45] __main__ INFO: \u001b[0mElapsed 13.18\n",
      "\u001b[32m[2020-07-11 16:00:45] __main__ INFO: \u001b[0mTrain 2 351\n",
      "\u001b[32m[2020-07-11 16:02:37] __main__ INFO: \u001b[0mEpoch 2 Step 100/351 lr 0.100000 loss 1.8233 (1.8363) acc@1 0.3047 (0.3231) acc@5 0.7656 (0.7852)\n",
      "\u001b[32m[2020-07-11 16:04:29] __main__ INFO: \u001b[0mEpoch 2 Step 200/351 lr 0.100000 loss 1.6066 (1.8029) acc@1 0.3672 (0.3366) acc@5 0.8516 (0.7959)\n",
      "\u001b[32m[2020-07-11 16:06:21] __main__ INFO: \u001b[0mEpoch 2 Step 300/351 lr 0.100000 loss 1.7055 (1.7668) acc@1 0.4219 (0.3513) acc@5 0.8281 (0.8016)\n",
      "\u001b[32m[2020-07-11 16:07:18] __main__ INFO: \u001b[0mEpoch 2 Step 351/351 lr 0.100000 loss 1.7289 (1.7509) acc@1 0.4297 (0.3577) acc@5 0.7734 (0.8048)\n",
      "\u001b[32m[2020-07-11 16:07:18] __main__ INFO: \u001b[0mElapsed 392.47\n",
      "\u001b[32m[2020-07-11 16:07:18] __main__ INFO: \u001b[0mVal 2\n",
      "\u001b[32m[2020-07-11 16:07:31] __main__ INFO: \u001b[0mEpoch 2 loss 1.8250 acc@1 0.3512 acc@5 0.7966\n",
      "\u001b[32m[2020-07-11 16:07:31] __main__ INFO: \u001b[0mElapsed 13.19\n",
      "\u001b[32m[2020-07-11 16:07:31] __main__ INFO: \u001b[0mTrain 3 702\n",
      "\u001b[32m[2020-07-11 16:09:23] __main__ INFO: \u001b[0mEpoch 3 Step 100/351 lr 0.100000 loss 1.4661 (1.5950) acc@1 0.4219 (0.4195) acc@5 0.8359 (0.8375)\n",
      "\u001b[32m[2020-07-11 16:11:15] __main__ INFO: \u001b[0mEpoch 3 Step 200/351 lr 0.100000 loss 1.4160 (1.5778) acc@1 0.5078 (0.4261) acc@5 0.8594 (0.8355)\n",
      "\u001b[32m[2020-07-11 16:13:06] __main__ INFO: \u001b[0mEpoch 3 Step 300/351 lr 0.100000 loss 1.6114 (1.5632) acc@1 0.4297 (0.4312) acc@5 0.8047 (0.8383)\n",
      "\u001b[32m[2020-07-11 16:14:03] __main__ INFO: \u001b[0mEpoch 3 Step 351/351 lr 0.100000 loss 1.5227 (1.5559) acc@1 0.4609 (0.4340) acc@5 0.8047 (0.8383)\n",
      "\u001b[32m[2020-07-11 16:14:03] __main__ INFO: \u001b[0mElapsed 392.53\n",
      "\u001b[32m[2020-07-11 16:14:03] __main__ INFO: \u001b[0mVal 3\n",
      "\u001b[32m[2020-07-11 16:14:17] __main__ INFO: \u001b[0mEpoch 3 loss 1.5765 acc@1 0.4324 acc@5 0.8394\n",
      "\u001b[32m[2020-07-11 16:14:17] __main__ INFO: \u001b[0mElapsed 13.17\n",
      "\u001b[32m[2020-07-11 16:14:17] __main__ INFO: \u001b[0mTrain 4 1053\n",
      "\u001b[32m[2020-07-11 16:16:08] __main__ INFO: \u001b[0mEpoch 4 Step 100/351 lr 0.100000 loss 1.4893 (1.4591) acc@1 0.5000 (0.4677) acc@5 0.8984 (0.8558)\n",
      "\u001b[32m[2020-07-11 16:18:00] __main__ INFO: \u001b[0mEpoch 4 Step 200/351 lr 0.100000 loss 1.5350 (1.4479) acc@1 0.4688 (0.4737) acc@5 0.8672 (0.8561)\n",
      "\u001b[32m[2020-07-11 16:19:52] __main__ INFO: \u001b[0mEpoch 4 Step 300/351 lr 0.100000 loss 1.3794 (1.4261) acc@1 0.5391 (0.4813) acc@5 0.8984 (0.8598)\n",
      "\u001b[32m[2020-07-11 16:20:49] __main__ INFO: \u001b[0mEpoch 4 Step 351/351 lr 0.100000 loss 1.4491 (1.4213) acc@1 0.4844 (0.4834) acc@5 0.8750 (0.8611)\n",
      "\u001b[32m[2020-07-11 16:20:49] __main__ INFO: \u001b[0mElapsed 392.44\n",
      "\u001b[32m[2020-07-11 16:20:49] __main__ INFO: \u001b[0mVal 4\n",
      "\u001b[32m[2020-07-11 16:21:02] __main__ INFO: \u001b[0mEpoch 4 loss 1.8160 acc@1 0.3924 acc@5 0.7980\n",
      "\u001b[32m[2020-07-11 16:21:02] __main__ INFO: \u001b[0mElapsed 13.21\n",
      "\u001b[32m[2020-07-11 16:21:02] __main__ INFO: \u001b[0mTrain 5 1404\n",
      "\u001b[32m[2020-07-11 16:22:54] __main__ INFO: \u001b[0mEpoch 5 Step 100/351 lr 0.100000 loss 1.3833 (1.3506) acc@1 0.4766 (0.5115) acc@5 0.8516 (0.8670)\n",
      "\u001b[32m[2020-07-11 16:24:46] __main__ INFO: \u001b[0mEpoch 5 Step 200/351 lr 0.100000 loss 1.4156 (1.3521) acc@1 0.4922 (0.5092) acc@5 0.8750 (0.8647)\n",
      "\u001b[32m[2020-07-11 16:26:38] __main__ INFO: \u001b[0mEpoch 5 Step 300/351 lr 0.100000 loss 1.3458 (1.3497) acc@1 0.5312 (0.5102) acc@5 0.8906 (0.8658)\n",
      "\u001b[32m[2020-07-11 16:27:35] __main__ INFO: \u001b[0mEpoch 5 Step 351/351 lr 0.100000 loss 1.2960 (1.3454) acc@1 0.5000 (0.5118) acc@5 0.8906 (0.8654)\n",
      "\u001b[32m[2020-07-11 16:27:35] __main__ INFO: \u001b[0mElapsed 392.38\n",
      "\u001b[32m[2020-07-11 16:27:35] __main__ INFO: \u001b[0mVal 5\n",
      "\u001b[32m[2020-07-11 16:27:48] __main__ INFO: \u001b[0mEpoch 5 loss 1.4214 acc@1 0.4854 acc@5 0.8492\n",
      "\u001b[32m[2020-07-11 16:27:48] __main__ INFO: \u001b[0mElapsed 13.15\n",
      "\u001b[32m[2020-07-11 16:27:48] __main__ INFO: \u001b[0mTrain 6 1755\n",
      "\u001b[32m[2020-07-11 16:29:40] __main__ INFO: \u001b[0mEpoch 6 Step 100/351 lr 0.100000 loss 1.2523 (1.2861) acc@1 0.5703 (0.5290) acc@5 0.8828 (0.8717)\n",
      "\u001b[32m[2020-07-11 16:31:31] __main__ INFO: \u001b[0mEpoch 6 Step 200/351 lr 0.100000 loss 1.3515 (1.2871) acc@1 0.5547 (0.5308) acc@5 0.8359 (0.8716)\n",
      "\u001b[32m[2020-07-11 16:33:23] __main__ INFO: \u001b[0mEpoch 6 Step 300/351 lr 0.100000 loss 1.2861 (1.2836) acc@1 0.5156 (0.5307) acc@5 0.8750 (0.8723)\n",
      "\u001b[32m[2020-07-11 16:34:20] __main__ INFO: \u001b[0mEpoch 6 Step 351/351 lr 0.100000 loss 1.2928 (1.2834) acc@1 0.5234 (0.5313) acc@5 0.8984 (0.8725)\n",
      "\u001b[32m[2020-07-11 16:34:20] __main__ INFO: \u001b[0mElapsed 392.74\n",
      "\u001b[32m[2020-07-11 16:34:20] __main__ INFO: \u001b[0mVal 6\n",
      "\u001b[32m[2020-07-11 16:34:34] __main__ INFO: \u001b[0mEpoch 6 loss 1.5373 acc@1 0.4518 acc@5 0.8394\n",
      "\u001b[32m[2020-07-11 16:34:34] __main__ INFO: \u001b[0mElapsed 13.20\n",
      "\u001b[32m[2020-07-11 16:34:34] __main__ INFO: \u001b[0mTrain 7 2106\n",
      "\u001b[32m[2020-07-11 16:36:26] __main__ INFO: \u001b[0mEpoch 7 Step 100/351 lr 0.100000 loss 1.0335 (1.2521) acc@1 0.6406 (0.5433) acc@5 0.8906 (0.8716)\n",
      "\u001b[32m[2020-07-11 16:38:17] __main__ INFO: \u001b[0mEpoch 7 Step 200/351 lr 0.100000 loss 1.2559 (1.2532) acc@1 0.5000 (0.5451) acc@5 0.8281 (0.8734)\n",
      "\u001b[32m[2020-07-11 16:40:09] __main__ INFO: \u001b[0mEpoch 7 Step 300/351 lr 0.100000 loss 1.2075 (1.2452) acc@1 0.5703 (0.5478) acc@5 0.8828 (0.8745)\n",
      "\u001b[32m[2020-07-11 16:41:06] __main__ INFO: \u001b[0mEpoch 7 Step 351/351 lr 0.100000 loss 1.1969 (1.2441) acc@1 0.5547 (0.5478) acc@5 0.8672 (0.8749)\n",
      "\u001b[32m[2020-07-11 16:41:06] __main__ INFO: \u001b[0mElapsed 392.46\n",
      "\u001b[32m[2020-07-11 16:41:06] __main__ INFO: \u001b[0mVal 7\n",
      "\u001b[32m[2020-07-11 16:41:19] __main__ INFO: \u001b[0mEpoch 7 loss 1.7860 acc@1 0.4038 acc@5 0.7918\n",
      "\u001b[32m[2020-07-11 16:41:19] __main__ INFO: \u001b[0mElapsed 13.17\n",
      "\u001b[32m[2020-07-11 16:41:19] __main__ INFO: \u001b[0mTrain 8 2457\n",
      "\u001b[32m[2020-07-11 16:43:11] __main__ INFO: \u001b[0mEpoch 8 Step 100/351 lr 0.100000 loss 1.3092 (1.1999) acc@1 0.5078 (0.5631) acc@5 0.8594 (0.8815)\n",
      "\u001b[32m[2020-07-11 16:45:03] __main__ INFO: \u001b[0mEpoch 8 Step 200/351 lr 0.100000 loss 1.2515 (1.2140) acc@1 0.5469 (0.5569) acc@5 0.8438 (0.8762)\n",
      "\u001b[32m[2020-07-11 16:46:54] __main__ INFO: \u001b[0mEpoch 8 Step 300/351 lr 0.100000 loss 1.1480 (1.2140) acc@1 0.5859 (0.5572) acc@5 0.8750 (0.8760)\n",
      "\u001b[32m[2020-07-11 16:47:51] __main__ INFO: \u001b[0mEpoch 8 Step 351/351 lr 0.100000 loss 1.1858 (1.2124) acc@1 0.5938 (0.5579) acc@5 0.8750 (0.8752)\n",
      "\u001b[32m[2020-07-11 16:47:51] __main__ INFO: \u001b[0mElapsed 392.14\n",
      "\u001b[32m[2020-07-11 16:47:51] __main__ INFO: \u001b[0mVal 8\n",
      "\u001b[32m[2020-07-11 16:48:05] __main__ INFO: \u001b[0mEpoch 8 loss 1.3443 acc@1 0.5216 acc@5 0.8566\n",
      "\u001b[32m[2020-07-11 16:48:05] __main__ INFO: \u001b[0mElapsed 13.14\n",
      "\u001b[32m[2020-07-11 16:48:05] __main__ INFO: \u001b[0mTrain 9 2808\n",
      "\u001b[32m[2020-07-11 16:49:56] __main__ INFO: \u001b[0mEpoch 9 Step 100/351 lr 0.100000 loss 1.1541 (1.1887) acc@1 0.5938 (0.5672) acc@5 0.8672 (0.8773)\n",
      "\u001b[32m[2020-07-11 16:51:48] __main__ INFO: \u001b[0mEpoch 9 Step 200/351 lr 0.100000 loss 1.0816 (1.1874) acc@1 0.6016 (0.5658) acc@5 0.8750 (0.8759)\n",
      "\u001b[32m[2020-07-11 16:53:40] __main__ INFO: \u001b[0mEpoch 9 Step 300/351 lr 0.100000 loss 1.1698 (1.1856) acc@1 0.5938 (0.5666) acc@5 0.9141 (0.8780)\n",
      "\u001b[32m[2020-07-11 16:54:37] __main__ INFO: \u001b[0mEpoch 9 Step 351/351 lr 0.100000 loss 1.3075 (1.1851) acc@1 0.5391 (0.5670) acc@5 0.8672 (0.8786)\n",
      "\u001b[32m[2020-07-11 16:54:37] __main__ INFO: \u001b[0mElapsed 391.95\n",
      "\u001b[32m[2020-07-11 16:54:37] __main__ INFO: \u001b[0mVal 9\n",
      "\u001b[32m[2020-07-11 16:54:50] __main__ INFO: \u001b[0mEpoch 9 loss 1.3381 acc@1 0.5146 acc@5 0.8662\n",
      "\u001b[32m[2020-07-11 16:54:50] __main__ INFO: \u001b[0mElapsed 13.16\n",
      "\u001b[32m[2020-07-11 16:54:50] __main__ INFO: \u001b[0mTrain 10 3159\n",
      "\u001b[32m[2020-07-11 16:56:41] __main__ INFO: \u001b[0mEpoch 10 Step 100/351 lr 0.100000 loss 1.3800 (1.1648) acc@1 0.5000 (0.5784) acc@5 0.8672 (0.8789)\n",
      "\u001b[32m[2020-07-11 16:58:33] __main__ INFO: \u001b[0mEpoch 10 Step 200/351 lr 0.100000 loss 1.2034 (1.1639) acc@1 0.5391 (0.5769) acc@5 0.8594 (0.8797)\n",
      "\u001b[32m[2020-07-11 17:00:25] __main__ INFO: \u001b[0mEpoch 10 Step 300/351 lr 0.100000 loss 1.0705 (1.1643) acc@1 0.6484 (0.5763) acc@5 0.9297 (0.8804)\n",
      "\u001b[32m[2020-07-11 17:01:22] __main__ INFO: \u001b[0mEpoch 10 Step 351/351 lr 0.100000 loss 1.1643 (1.1657) acc@1 0.6016 (0.5756) acc@5 0.8594 (0.8801)\n",
      "\u001b[32m[2020-07-11 17:01:22] __main__ INFO: \u001b[0mElapsed 391.94\n",
      "\u001b[32m[2020-07-11 17:01:22] __main__ INFO: \u001b[0mVal 10\n",
      "\u001b[32m[2020-07-11 17:01:35] __main__ INFO: \u001b[0mEpoch 10 loss 1.3162 acc@1 0.5250 acc@5 0.8718\n",
      "\u001b[32m[2020-07-11 17:01:35] __main__ INFO: \u001b[0mElapsed 13.17\n",
      "\u001b[32m[2020-07-11 17:01:35] __main__ INFO: \u001b[0mTrain 11 3510\n",
      "\u001b[32m[2020-07-11 17:03:27] __main__ INFO: \u001b[0mEpoch 11 Step 100/351 lr 0.100000 loss 1.1553 (1.1372) acc@1 0.5703 (0.5822) acc@5 0.8203 (0.8857)\n",
      "\u001b[32m[2020-07-11 17:05:18] __main__ INFO: \u001b[0mEpoch 11 Step 200/351 lr 0.100000 loss 1.1859 (1.1455) acc@1 0.5469 (0.5822) acc@5 0.8594 (0.8834)\n",
      "\u001b[32m[2020-07-11 17:07:10] __main__ INFO: \u001b[0mEpoch 11 Step 300/351 lr 0.100000 loss 1.2315 (1.1470) acc@1 0.5312 (0.5825) acc@5 0.8750 (0.8824)\n",
      "\u001b[32m[2020-07-11 17:08:07] __main__ INFO: \u001b[0mEpoch 11 Step 351/351 lr 0.100000 loss 1.0966 (1.1507) acc@1 0.6250 (0.5824) acc@5 0.8672 (0.8814)\n",
      "\u001b[32m[2020-07-11 17:08:07] __main__ INFO: \u001b[0mElapsed 391.92\n",
      "\u001b[32m[2020-07-11 17:08:07] __main__ INFO: \u001b[0mVal 11\n",
      "\u001b[32m[2020-07-11 17:08:20] __main__ INFO: \u001b[0mEpoch 11 loss 1.7068 acc@1 0.4404 acc@5 0.8304\n",
      "\u001b[32m[2020-07-11 17:08:20] __main__ INFO: \u001b[0mElapsed 13.12\n",
      "\u001b[32m[2020-07-11 17:08:20] __main__ INFO: \u001b[0mTrain 12 3861\n",
      "\u001b[32m[2020-07-11 17:10:12] __main__ INFO: \u001b[0mEpoch 12 Step 100/351 lr 0.100000 loss 1.2688 (1.1268) acc@1 0.5391 (0.5917) acc@5 0.8672 (0.8830)\n",
      "\u001b[32m[2020-07-11 17:12:03] __main__ INFO: \u001b[0mEpoch 12 Step 200/351 lr 0.100000 loss 1.1872 (1.1408) acc@1 0.5312 (0.5837) acc@5 0.8594 (0.8810)\n",
      "\u001b[32m[2020-07-11 17:13:55] __main__ INFO: \u001b[0mEpoch 12 Step 300/351 lr 0.100000 loss 1.0250 (1.1369) acc@1 0.5859 (0.5848) acc@5 0.9375 (0.8823)\n",
      "\u001b[32m[2020-07-11 17:14:52] __main__ INFO: \u001b[0mEpoch 12 Step 351/351 lr 0.100000 loss 1.2562 (1.1382) acc@1 0.5156 (0.5848) acc@5 0.8516 (0.8819)\n",
      "\u001b[32m[2020-07-11 17:14:52] __main__ INFO: \u001b[0mElapsed 391.74\n",
      "\u001b[32m[2020-07-11 17:14:52] __main__ INFO: \u001b[0mVal 12\n",
      "\u001b[32m[2020-07-11 17:15:05] __main__ INFO: \u001b[0mEpoch 12 loss 1.3648 acc@1 0.5218 acc@5 0.8688\n",
      "\u001b[32m[2020-07-11 17:15:05] __main__ INFO: \u001b[0mElapsed 13.14\n",
      "\u001b[32m[2020-07-11 17:15:05] __main__ INFO: \u001b[0mTrain 13 4212\n",
      "\u001b[32m[2020-07-11 17:16:56] __main__ INFO: \u001b[0mEpoch 13 Step 100/351 lr 0.100000 loss 1.2450 (1.1153) acc@1 0.5234 (0.5959) acc@5 0.8203 (0.8850)\n",
      "\u001b[32m[2020-07-11 17:18:48] __main__ INFO: \u001b[0mEpoch 13 Step 200/351 lr 0.100000 loss 1.1739 (1.1310) acc@1 0.5547 (0.5901) acc@5 0.8984 (0.8823)\n",
      "\u001b[32m[2020-07-11 17:20:40] __main__ INFO: \u001b[0mEpoch 13 Step 300/351 lr 0.100000 loss 1.0745 (1.1253) acc@1 0.5781 (0.5917) acc@5 0.8984 (0.8838)\n",
      "\u001b[32m[2020-07-11 17:21:37] __main__ INFO: \u001b[0mEpoch 13 Step 351/351 lr 0.100000 loss 1.2989 (1.1234) acc@1 0.5859 (0.5920) acc@5 0.8438 (0.8833)\n",
      "\u001b[32m[2020-07-11 17:21:37] __main__ INFO: \u001b[0mElapsed 391.81\n",
      "\u001b[32m[2020-07-11 17:21:37] __main__ INFO: \u001b[0mVal 13\n",
      "\u001b[32m[2020-07-11 17:21:50] __main__ INFO: \u001b[0mEpoch 13 loss 1.2902 acc@1 0.5402 acc@5 0.8726\n",
      "\u001b[32m[2020-07-11 17:21:50] __main__ INFO: \u001b[0mElapsed 13.15\n",
      "\u001b[32m[2020-07-11 17:21:50] __main__ INFO: \u001b[0mTrain 14 4563\n",
      "\u001b[32m[2020-07-11 17:23:41] __main__ INFO: \u001b[0mEpoch 14 Step 100/351 lr 0.100000 loss 1.1669 (1.1012) acc@1 0.5938 (0.5991) acc@5 0.8438 (0.8832)\n",
      "\u001b[32m[2020-07-11 17:25:33] __main__ INFO: \u001b[0mEpoch 14 Step 200/351 lr 0.100000 loss 1.0031 (1.1035) acc@1 0.6016 (0.6000) acc@5 0.8828 (0.8836)\n",
      "\u001b[32m[2020-07-11 17:27:24] __main__ INFO: \u001b[0mEpoch 14 Step 300/351 lr 0.100000 loss 1.1584 (1.1038) acc@1 0.5938 (0.5988) acc@5 0.8906 (0.8855)\n",
      "\u001b[32m[2020-07-11 17:28:21] __main__ INFO: \u001b[0mEpoch 14 Step 351/351 lr 0.100000 loss 1.0197 (1.1087) acc@1 0.6016 (0.5974) acc@5 0.8828 (0.8853)\n",
      "\u001b[32m[2020-07-11 17:28:21] __main__ INFO: \u001b[0mElapsed 391.71\n",
      "\u001b[32m[2020-07-11 17:28:21] __main__ INFO: \u001b[0mVal 14\n",
      "\u001b[32m[2020-07-11 17:28:35] __main__ INFO: \u001b[0mEpoch 14 loss 1.2610 acc@1 0.5508 acc@5 0.8638\n",
      "\u001b[32m[2020-07-11 17:28:35] __main__ INFO: \u001b[0mElapsed 13.12\n",
      "\u001b[32m[2020-07-11 17:28:35] __main__ INFO: \u001b[0mTrain 15 4914\n",
      "\u001b[32m[2020-07-11 17:30:26] __main__ INFO: \u001b[0mEpoch 15 Step 100/351 lr 0.100000 loss 0.9225 (1.0944) acc@1 0.7031 (0.6059) acc@5 0.9062 (0.8878)\n",
      "\u001b[32m[2020-07-11 17:32:18] __main__ INFO: \u001b[0mEpoch 15 Step 200/351 lr 0.100000 loss 1.1161 (1.1018) acc@1 0.5859 (0.5989) acc@5 0.8750 (0.8834)\n",
      "\u001b[32m[2020-07-11 17:34:09] __main__ INFO: \u001b[0mEpoch 15 Step 300/351 lr 0.100000 loss 1.1230 (1.0952) acc@1 0.5938 (0.6028) acc@5 0.8672 (0.8838)\n",
      "\u001b[32m[2020-07-11 17:35:06] __main__ INFO: \u001b[0mEpoch 15 Step 351/351 lr 0.100000 loss 1.1828 (1.1001) acc@1 0.5781 (0.6005) acc@5 0.8438 (0.8833)\n",
      "\u001b[32m[2020-07-11 17:35:06] __main__ INFO: \u001b[0mElapsed 391.74\n",
      "\u001b[32m[2020-07-11 17:35:06] __main__ INFO: \u001b[0mVal 15\n",
      "\u001b[32m[2020-07-11 17:35:19] __main__ INFO: \u001b[0mEpoch 15 loss 1.3234 acc@1 0.5350 acc@5 0.8532\n",
      "\u001b[32m[2020-07-11 17:35:19] __main__ INFO: \u001b[0mElapsed 13.15\n",
      "\u001b[32m[2020-07-11 17:35:19] __main__ INFO: \u001b[0mTrain 16 5265\n",
      "\u001b[32m[2020-07-11 17:37:11] __main__ INFO: \u001b[0mEpoch 16 Step 100/351 lr 0.100000 loss 1.2097 (1.0668) acc@1 0.5469 (0.6130) acc@5 0.8594 (0.8867)\n",
      "\u001b[32m[2020-07-11 17:39:03] __main__ INFO: \u001b[0mEpoch 16 Step 200/351 lr 0.100000 loss 1.1873 (1.0714) acc@1 0.5781 (0.6114) acc@5 0.8750 (0.8868)\n",
      "\u001b[32m[2020-07-11 17:40:54] __main__ INFO: \u001b[0mEpoch 16 Step 300/351 lr 0.100000 loss 1.0608 (1.0776) acc@1 0.6016 (0.6089) acc@5 0.8516 (0.8860)\n",
      "\u001b[32m[2020-07-11 17:41:51] __main__ INFO: \u001b[0mEpoch 16 Step 351/351 lr 0.100000 loss 0.9932 (1.0828) acc@1 0.6250 (0.6064) acc@5 0.8984 (0.8847)\n",
      "\u001b[32m[2020-07-11 17:41:51] __main__ INFO: \u001b[0mElapsed 391.72\n",
      "\u001b[32m[2020-07-11 17:41:51] __main__ INFO: \u001b[0mVal 16\n",
      "\u001b[32m[2020-07-11 17:42:04] __main__ INFO: \u001b[0mEpoch 16 loss 1.4609 acc@1 0.5454 acc@5 0.8712\n",
      "\u001b[32m[2020-07-11 17:42:04] __main__ INFO: \u001b[0mElapsed 13.11\n",
      "\u001b[32m[2020-07-11 17:42:04] __main__ INFO: \u001b[0mTrain 17 5616\n",
      "\u001b[32m[2020-07-11 17:43:56] __main__ INFO: \u001b[0mEpoch 17 Step 100/351 lr 0.100000 loss 1.1940 (1.0545) acc@1 0.5938 (0.6202) acc@5 0.8516 (0.8895)\n",
      "\u001b[32m[2020-07-11 17:45:47] __main__ INFO: \u001b[0mEpoch 17 Step 200/351 lr 0.100000 loss 1.2161 (1.0724) acc@1 0.5312 (0.6103) acc@5 0.9219 (0.8864)\n",
      "\u001b[32m[2020-07-11 17:47:39] __main__ INFO: \u001b[0mEpoch 17 Step 300/351 lr 0.100000 loss 1.1062 (1.0718) acc@1 0.5938 (0.6110) acc@5 0.8750 (0.8860)\n",
      "\u001b[32m[2020-07-11 17:48:36] __main__ INFO: \u001b[0mEpoch 17 Step 351/351 lr 0.100000 loss 1.0190 (1.0728) acc@1 0.6328 (0.6104) acc@5 0.9141 (0.8857)\n",
      "\u001b[32m[2020-07-11 17:48:36] __main__ INFO: \u001b[0mElapsed 391.47\n",
      "\u001b[32m[2020-07-11 17:48:36] __main__ INFO: \u001b[0mVal 17\n",
      "\u001b[32m[2020-07-11 17:48:49] __main__ INFO: \u001b[0mEpoch 17 loss 1.2509 acc@1 0.5580 acc@5 0.8652\n",
      "\u001b[32m[2020-07-11 17:48:49] __main__ INFO: \u001b[0mElapsed 13.10\n",
      "\u001b[32m[2020-07-11 17:48:49] __main__ INFO: \u001b[0mTrain 18 5967\n",
      "\u001b[32m[2020-07-11 17:50:40] __main__ INFO: \u001b[0mEpoch 18 Step 100/351 lr 0.100000 loss 0.9818 (1.0552) acc@1 0.6250 (0.6159) acc@5 0.8906 (0.8895)\n",
      "\u001b[32m[2020-07-11 17:52:32] __main__ INFO: \u001b[0mEpoch 18 Step 200/351 lr 0.100000 loss 0.9917 (1.0596) acc@1 0.6562 (0.6127) acc@5 0.9141 (0.8893)\n",
      "\u001b[32m[2020-07-11 17:54:23] __main__ INFO: \u001b[0mEpoch 18 Step 300/351 lr 0.100000 loss 1.1594 (1.0661) acc@1 0.6016 (0.6111) acc@5 0.8906 (0.8883)\n",
      "\u001b[32m[2020-07-11 17:55:20] __main__ INFO: \u001b[0mEpoch 18 Step 351/351 lr 0.100000 loss 1.0848 (1.0674) acc@1 0.6172 (0.6097) acc@5 0.9062 (0.8885)\n",
      "\u001b[32m[2020-07-11 17:55:20] __main__ INFO: \u001b[0mElapsed 391.52\n",
      "\u001b[32m[2020-07-11 17:55:20] __main__ INFO: \u001b[0mVal 18\n",
      "\u001b[32m[2020-07-11 17:55:33] __main__ INFO: \u001b[0mEpoch 18 loss 1.2236 acc@1 0.5674 acc@5 0.8744\n",
      "\u001b[32m[2020-07-11 17:55:33] __main__ INFO: \u001b[0mElapsed 13.12\n",
      "\u001b[32m[2020-07-11 17:55:33] __main__ INFO: \u001b[0mTrain 19 6318\n",
      "\u001b[32m[2020-07-11 17:57:25] __main__ INFO: \u001b[0mEpoch 19 Step 100/351 lr 0.100000 loss 1.2006 (1.0502) acc@1 0.6250 (0.6162) acc@5 0.9062 (0.8902)\n",
      "\u001b[32m[2020-07-11 17:59:16] __main__ INFO: \u001b[0mEpoch 19 Step 200/351 lr 0.100000 loss 1.0617 (1.0579) acc@1 0.5781 (0.6138) acc@5 0.9297 (0.8888)\n",
      "\u001b[32m[2020-07-11 18:01:08] __main__ INFO: \u001b[0mEpoch 19 Step 300/351 lr 0.100000 loss 1.1090 (1.0608) acc@1 0.5859 (0.6139) acc@5 0.8281 (0.8873)\n",
      "\u001b[32m[2020-07-11 18:02:05] __main__ INFO: \u001b[0mEpoch 19 Step 351/351 lr 0.100000 loss 0.9251 (1.0603) acc@1 0.6641 (0.6138) acc@5 0.8906 (0.8874)\n",
      "\u001b[32m[2020-07-11 18:02:05] __main__ INFO: \u001b[0mElapsed 391.40\n",
      "\u001b[32m[2020-07-11 18:02:05] __main__ INFO: \u001b[0mVal 19\n",
      "\u001b[32m[2020-07-11 18:02:18] __main__ INFO: \u001b[0mEpoch 19 loss 1.3296 acc@1 0.5150 acc@5 0.8716\n",
      "\u001b[32m[2020-07-11 18:02:18] __main__ INFO: \u001b[0mElapsed 13.11\n",
      "\u001b[32m[2020-07-11 18:02:18] __main__ INFO: \u001b[0mTrain 20 6669\n",
      "\u001b[32m[2020-07-11 18:04:10] __main__ INFO: \u001b[0mEpoch 20 Step 100/351 lr 0.100000 loss 1.1443 (1.0486) acc@1 0.5703 (0.6169) acc@5 0.8359 (0.8834)\n",
      "\u001b[32m[2020-07-11 18:06:01] __main__ INFO: \u001b[0mEpoch 20 Step 200/351 lr 0.100000 loss 0.9319 (1.0426) acc@1 0.6406 (0.6191) acc@5 0.8750 (0.8884)\n",
      "\u001b[32m[2020-07-11 18:07:53] __main__ INFO: \u001b[0mEpoch 20 Step 300/351 lr 0.100000 loss 1.1359 (1.0449) acc@1 0.5859 (0.6182) acc@5 0.8984 (0.8883)\n",
      "\u001b[32m[2020-07-11 18:08:50] __main__ INFO: \u001b[0mEpoch 20 Step 351/351 lr 0.100000 loss 1.0084 (1.0486) acc@1 0.6719 (0.6169) acc@5 0.8984 (0.8883)\n",
      "\u001b[32m[2020-07-11 18:08:50] __main__ INFO: \u001b[0mElapsed 391.54\n",
      "\u001b[32m[2020-07-11 18:08:50] __main__ INFO: \u001b[0mVal 20\n",
      "\u001b[32m[2020-07-11 18:09:03] __main__ INFO: \u001b[0mEpoch 20 loss 1.3009 acc@1 0.5348 acc@5 0.8748\n",
      "\u001b[32m[2020-07-11 18:09:03] __main__ INFO: \u001b[0mElapsed 13.11\n",
      "\u001b[32m[2020-07-11 18:09:03] __main__ INFO: \u001b[0mTrain 21 7020\n",
      "\u001b[32m[2020-07-11 18:10:54] __main__ INFO: \u001b[0mEpoch 21 Step 100/351 lr 0.100000 loss 1.0801 (1.0209) acc@1 0.6016 (0.6266) acc@5 0.8984 (0.8940)\n",
      "\u001b[32m[2020-07-11 18:12:46] __main__ INFO: \u001b[0mEpoch 21 Step 200/351 lr 0.100000 loss 1.1057 (1.0374) acc@1 0.6016 (0.6238) acc@5 0.8906 (0.8889)\n",
      "\u001b[32m[2020-07-11 18:14:37] __main__ INFO: \u001b[0mEpoch 21 Step 300/351 lr 0.100000 loss 0.8104 (1.0380) acc@1 0.6953 (0.6235) acc@5 0.8984 (0.8878)\n",
      "\u001b[32m[2020-07-11 18:15:34] __main__ INFO: \u001b[0mEpoch 21 Step 351/351 lr 0.100000 loss 1.1537 (1.0424) acc@1 0.5703 (0.6209) acc@5 0.8906 (0.8868)\n",
      "\u001b[32m[2020-07-11 18:15:34] __main__ INFO: \u001b[0mElapsed 391.52\n",
      "\u001b[32m[2020-07-11 18:15:34] __main__ INFO: \u001b[0mVal 21\n",
      "\u001b[32m[2020-07-11 18:15:47] __main__ INFO: \u001b[0mEpoch 21 loss 1.1930 acc@1 0.5712 acc@5 0.8856\n",
      "\u001b[32m[2020-07-11 18:15:47] __main__ INFO: \u001b[0mElapsed 13.12\n",
      "\u001b[32m[2020-07-11 18:15:47] __main__ INFO: \u001b[0mTrain 22 7371\n",
      "\u001b[32m[2020-07-11 18:17:39] __main__ INFO: \u001b[0mEpoch 22 Step 100/351 lr 0.100000 loss 1.0486 (1.0177) acc@1 0.5938 (0.6273) acc@5 0.8906 (0.8878)\n",
      "\u001b[32m[2020-07-11 18:19:30] __main__ INFO: \u001b[0mEpoch 22 Step 200/351 lr 0.100000 loss 1.0455 (1.0267) acc@1 0.6250 (0.6236) acc@5 0.8984 (0.8871)\n",
      "\u001b[32m[2020-07-11 18:21:22] __main__ INFO: \u001b[0mEpoch 22 Step 300/351 lr 0.100000 loss 1.0938 (1.0370) acc@1 0.6406 (0.6205) acc@5 0.8828 (0.8883)\n",
      "\u001b[32m[2020-07-11 18:22:19] __main__ INFO: \u001b[0mEpoch 22 Step 351/351 lr 0.100000 loss 1.0240 (1.0356) acc@1 0.6484 (0.6216) acc@5 0.9297 (0.8895)\n",
      "\u001b[32m[2020-07-11 18:22:19] __main__ INFO: \u001b[0mElapsed 391.45\n",
      "\u001b[32m[2020-07-11 18:22:19] __main__ INFO: \u001b[0mVal 22\n",
      "\u001b[32m[2020-07-11 18:22:32] __main__ INFO: \u001b[0mEpoch 22 loss 1.2366 acc@1 0.5650 acc@5 0.8734\n",
      "\u001b[32m[2020-07-11 18:22:32] __main__ INFO: \u001b[0mElapsed 13.09\n",
      "\u001b[32m[2020-07-11 18:22:32] __main__ INFO: \u001b[0mTrain 23 7722\n",
      "\u001b[32m[2020-07-11 18:24:23] __main__ INFO: \u001b[0mEpoch 23 Step 100/351 lr 0.100000 loss 1.0557 (1.0178) acc@1 0.6250 (0.6326) acc@5 0.8594 (0.8901)\n",
      "\u001b[32m[2020-07-11 18:26:15] __main__ INFO: \u001b[0mEpoch 23 Step 200/351 lr 0.100000 loss 0.8989 (1.0261) acc@1 0.6719 (0.6279) acc@5 0.8750 (0.8876)\n",
      "\u001b[32m[2020-07-11 18:49:17] __main__ INFO: \u001b[0mEpoch 26 Step 351/351 lr 0.100000 loss 1.0275 (1.0108) acc@1 0.6094 (0.6304) acc@5 0.8906 (0.8887)\n",
      "\u001b[32m[2020-07-11 18:49:17] __main__ INFO: \u001b[0mElapsed 391.38\n",
      "\u001b[32m[2020-07-11 18:49:17] __main__ INFO: \u001b[0mVal 26\n",
      "\u001b[32m[2020-07-11 18:49:30] __main__ INFO: \u001b[0mEpoch 26 loss 1.1928 acc@1 0.5712 acc@5 0.8802\n",
      "\u001b[32m[2020-07-11 18:49:30] __main__ INFO: \u001b[0mElapsed 13.12\n",
      "\u001b[32m[2020-07-11 18:49:30] __main__ INFO: \u001b[0mTrain 27 9126\n",
      "\u001b[32m[2020-07-11 18:51:22] __main__ INFO: \u001b[0mEpoch 27 Step 100/351 lr 0.100000 loss 1.1333 (1.0007) acc@1 0.6094 (0.6339) acc@5 0.8203 (0.8934)\n",
      "\u001b[32m[2020-07-11 18:53:13] __main__ INFO: \u001b[0mEpoch 27 Step 200/351 lr 0.100000 loss 1.1967 (0.9998) acc@1 0.5703 (0.6357) acc@5 0.8750 (0.8913)\n",
      "\u001b[32m[2020-07-11 18:55:05] __main__ INFO: \u001b[0mEpoch 27 Step 300/351 lr 0.100000 loss 1.0849 (1.0042) acc@1 0.5781 (0.6321) acc@5 0.8281 (0.8901)\n",
      "\u001b[32m[2020-07-11 18:56:01] __main__ INFO: \u001b[0mEpoch 27 Step 351/351 lr 0.100000 loss 0.9515 (1.0059) acc@1 0.6484 (0.6309) acc@5 0.8906 (0.8905)\n",
      "\u001b[32m[2020-07-11 18:56:01] __main__ INFO: \u001b[0mElapsed 391.48\n",
      "\u001b[32m[2020-07-11 18:56:01] __main__ INFO: \u001b[0mVal 27\n",
      "\u001b[32m[2020-07-11 18:56:15] __main__ INFO: \u001b[0mEpoch 27 loss 1.2238 acc@1 0.5726 acc@5 0.8684\n",
      "\u001b[32m[2020-07-11 18:56:15] __main__ INFO: \u001b[0mElapsed 13.10\n",
      "\u001b[32m[2020-07-11 18:56:15] __main__ INFO: \u001b[0mTrain 28 9477\n",
      "\u001b[32m[2020-07-11 18:58:06] __main__ INFO: \u001b[0mEpoch 28 Step 100/351 lr 0.100000 loss 1.0864 (0.9859) acc@1 0.5781 (0.6423) acc@5 0.8750 (0.8930)\n",
      "\u001b[32m[2020-07-11 18:59:58] __main__ INFO: \u001b[0mEpoch 28 Step 200/351 lr 0.100000 loss 1.1005 (0.9906) acc@1 0.6016 (0.6401) acc@5 0.8906 (0.8927)\n",
      "\u001b[32m[2020-07-11 19:01:49] __main__ INFO: \u001b[0mEpoch 28 Step 300/351 lr 0.100000 loss 0.9383 (0.9908) acc@1 0.6484 (0.6394) acc@5 0.9062 (0.8914)\n",
      "\u001b[32m[2020-07-11 19:02:46] __main__ INFO: \u001b[0mEpoch 28 Step 351/351 lr 0.100000 loss 1.0391 (0.9959) acc@1 0.6250 (0.6368) acc@5 0.9219 (0.8910)\n",
      "\u001b[32m[2020-07-11 19:02:46] __main__ INFO: \u001b[0mElapsed 391.42\n",
      "\u001b[32m[2020-07-11 19:02:46] __main__ INFO: \u001b[0mVal 28\n",
      "\u001b[32m[2020-07-11 19:02:59] __main__ INFO: \u001b[0mEpoch 28 loss 1.2245 acc@1 0.5658 acc@5 0.8650\n",
      "\u001b[32m[2020-07-11 19:02:59] __main__ INFO: \u001b[0mElapsed 13.10\n",
      "\u001b[32m[2020-07-11 19:02:59] __main__ INFO: \u001b[0mTrain 29 9828\n",
      "\u001b[32m[2020-07-11 19:04:51] __main__ INFO: \u001b[0mEpoch 29 Step 100/351 lr 0.100000 loss 1.1576 (0.9933) acc@1 0.5625 (0.6362) acc@5 0.8359 (0.8886)\n",
      "\u001b[32m[2020-07-11 19:06:42] __main__ INFO: \u001b[0mEpoch 29 Step 200/351 lr 0.100000 loss 1.0002 (0.9956) acc@1 0.6250 (0.6346) acc@5 0.9062 (0.8894)\n",
      "\u001b[32m[2020-07-11 19:08:34] __main__ INFO: \u001b[0mEpoch 29 Step 300/351 lr 0.100000 loss 0.9736 (0.9953) acc@1 0.6641 (0.6356) acc@5 0.9141 (0.8911)\n",
      "\u001b[32m[2020-07-11 19:09:31] __main__ INFO: \u001b[0mEpoch 29 Step 351/351 lr 0.100000 loss 0.9281 (0.9956) acc@1 0.6484 (0.6353) acc@5 0.9297 (0.8919)\n",
      "\u001b[32m[2020-07-11 19:09:31] __main__ INFO: \u001b[0mElapsed 391.40\n",
      "\u001b[32m[2020-07-11 19:09:31] __main__ INFO: \u001b[0mVal 29\n",
      "\u001b[32m[2020-07-11 19:09:44] __main__ INFO: \u001b[0mEpoch 29 loss 1.2307 acc@1 0.5716 acc@5 0.8756\n",
      "\u001b[32m[2020-07-11 19:09:44] __main__ INFO: \u001b[0mElapsed 13.10\n",
      "\u001b[32m[2020-07-11 19:09:44] __main__ INFO: \u001b[0mTrain 30 10179\n",
      "\u001b[32m[2020-07-11 19:11:35] __main__ INFO: \u001b[0mEpoch 30 Step 100/351 lr 0.100000 loss 1.1414 (0.9811) acc@1 0.5547 (0.6377) acc@5 0.8750 (0.8950)\n",
      "\u001b[32m[2020-07-11 19:13:27] __main__ INFO: \u001b[0mEpoch 30 Step 200/351 lr 0.100000 loss 1.0408 (0.9814) acc@1 0.5938 (0.6377) acc@5 0.8906 (0.8917)\n",
      "\u001b[32m[2020-07-11 19:15:18] __main__ INFO: \u001b[0mEpoch 30 Step 300/351 lr 0.100000 loss 0.9936 (0.9882) acc@1 0.6719 (0.6371) acc@5 0.9141 (0.8904)\n",
      "\u001b[32m[2020-07-11 19:16:15] __main__ INFO: \u001b[0mEpoch 30 Step 351/351 lr 0.100000 loss 0.9516 (0.9887) acc@1 0.6875 (0.6372) acc@5 0.9141 (0.8908)\n",
      "\u001b[32m[2020-07-11 19:16:15] __main__ INFO: \u001b[0mElapsed 391.41\n",
      "\u001b[32m[2020-07-11 19:16:15] __main__ INFO: \u001b[0mVal 30\n",
      "\u001b[32m[2020-07-11 19:16:28] __main__ INFO: \u001b[0mEpoch 30 loss 1.2425 acc@1 0.5628 acc@5 0.8676\n",
      "\u001b[32m[2020-07-11 19:16:28] __main__ INFO: \u001b[0mElapsed 13.09\n",
      "\u001b[32m[2020-07-11 19:16:28] __main__ INFO: \u001b[0mTrain 31 10530\n",
      "\u001b[32m[2020-07-11 19:18:20] __main__ INFO: \u001b[0mEpoch 31 Step 100/351 lr 0.100000 loss 0.9604 (0.9716) acc@1 0.6484 (0.6459) acc@5 0.9297 (0.8943)\n",
      "\u001b[32m[2020-07-11 19:20:11] __main__ INFO: \u001b[0mEpoch 31 Step 200/351 lr 0.100000 loss 0.8700 (0.9751) acc@1 0.6875 (0.6441) acc@5 0.9219 (0.8912)\n",
      "\u001b[32m[2020-07-11 19:22:03] __main__ INFO: \u001b[0mEpoch 31 Step 300/351 lr 0.100000 loss 1.0708 (0.9817) acc@1 0.5781 (0.6420) acc@5 0.9219 (0.8893)\n",
      "\u001b[32m[2020-07-11 19:22:59] __main__ INFO: \u001b[0mEpoch 31 Step 351/351 lr 0.100000 loss 0.8508 (0.9860) acc@1 0.6797 (0.6404) acc@5 0.9219 (0.8902)\n",
      "\u001b[32m[2020-07-11 19:22:59] __main__ INFO: \u001b[0mElapsed 391.35\n",
      "\u001b[32m[2020-07-11 19:22:59] __main__ INFO: \u001b[0mVal 31\n",
      "\u001b[32m[2020-07-11 19:23:13] __main__ INFO: \u001b[0mEpoch 31 loss 1.2061 acc@1 0.5668 acc@5 0.8696\n",
      "\u001b[32m[2020-07-11 19:23:13] __main__ INFO: \u001b[0mElapsed 13.11\n",
      "\u001b[32m[2020-07-11 19:23:13] __main__ INFO: \u001b[0mTrain 32 10881\n",
      "\u001b[32m[2020-07-11 19:25:04] __main__ INFO: \u001b[0mEpoch 32 Step 100/351 lr 0.100000 loss 1.0195 (0.9931) acc@1 0.6094 (0.6371) acc@5 0.8984 (0.8907)\n",
      "\u001b[32m[2020-07-11 19:26:56] __main__ INFO: \u001b[0mEpoch 32 Step 200/351 lr 0.100000 loss 0.7188 (0.9827) acc@1 0.7266 (0.6402) acc@5 0.9375 (0.8923)\n",
      "\u001b[32m[2020-07-11 19:28:47] __main__ INFO: \u001b[0mEpoch 32 Step 300/351 lr 0.100000 loss 1.2366 (0.9827) acc@1 0.5469 (0.6414) acc@5 0.8750 (0.8924)\n",
      "\u001b[32m[2020-07-11 19:29:44] __main__ INFO: \u001b[0mEpoch 32 Step 351/351 lr 0.100000 loss 0.9641 (0.9833) acc@1 0.6562 (0.6414) acc@5 0.8984 (0.8925)\n",
      "\u001b[32m[2020-07-11 19:29:44] __main__ INFO: \u001b[0mElapsed 391.34\n",
      "\u001b[32m[2020-07-11 19:29:44] __main__ INFO: \u001b[0mVal 32\n",
      "\u001b[32m[2020-07-11 19:29:57] __main__ INFO: \u001b[0mEpoch 32 loss 1.3421 acc@1 0.5726 acc@5 0.8718\n",
      "\u001b[32m[2020-07-11 19:29:57] __main__ INFO: \u001b[0mElapsed 13.10\n",
      "\u001b[32m[2020-07-11 19:29:57] __main__ INFO: \u001b[0mTrain 33 11232\n",
      "\u001b[32m[2020-07-11 19:31:49] __main__ INFO: \u001b[0mEpoch 33 Step 100/351 lr 0.100000 loss 1.0701 (0.9460) acc@1 0.6250 (0.6530) acc@5 0.8672 (0.8977)\n",
      "\u001b[32m[2020-07-11 19:33:40] __main__ INFO: \u001b[0mEpoch 33 Step 200/351 lr 0.100000 loss 1.0874 (0.9640) acc@1 0.6172 (0.6459) acc@5 0.8906 (0.8941)\n",
      "\u001b[32m[2020-07-11 19:35:32] __main__ INFO: \u001b[0mEpoch 33 Step 300/351 lr 0.100000 loss 1.0859 (0.9718) acc@1 0.5859 (0.6430) acc@5 0.8594 (0.8923)\n",
      "\u001b[32m[2020-07-11 19:36:28] __main__ INFO: \u001b[0mEpoch 33 Step 351/351 lr 0.100000 loss 0.9492 (0.9735) acc@1 0.6562 (0.6435) acc@5 0.8906 (0.8927)\n",
      "\u001b[32m[2020-07-11 19:36:28] __main__ INFO: \u001b[0mElapsed 391.37\n",
      "\u001b[32m[2020-07-11 19:36:28] __main__ INFO: \u001b[0mVal 33\n",
      "\u001b[32m[2020-07-11 19:36:42] __main__ INFO: \u001b[0mEpoch 33 loss 1.1403 acc@1 0.5960 acc@5 0.8844\n",
      "\u001b[32m[2020-07-11 19:36:42] __main__ INFO: \u001b[0mElapsed 13.11\n",
      "\u001b[32m[2020-07-11 19:36:42] __main__ INFO: \u001b[0mTrain 34 11583\n",
      "\u001b[32m[2020-07-11 19:38:33] __main__ INFO: \u001b[0mEpoch 34 Step 100/351 lr 0.100000 loss 1.0882 (0.9470) acc@1 0.6406 (0.6512) acc@5 0.9062 (0.8982)\n",
      "\u001b[32m[2020-07-11 19:40:25] __main__ INFO: \u001b[0mEpoch 34 Step 200/351 lr 0.100000 loss 0.9831 (0.9654) acc@1 0.6406 (0.6428) acc@5 0.8672 (0.8932)\n",
      "\u001b[32m[2020-07-11 19:42:16] __main__ INFO: \u001b[0mEpoch 34 Step 300/351 lr 0.100000 loss 0.8986 (0.9681) acc@1 0.6641 (0.6438) acc@5 0.9219 (0.8946)\n",
      "\u001b[32m[2020-07-11 19:43:13] __main__ INFO: \u001b[0mEpoch 34 Step 351/351 lr 0.100000 loss 1.0688 (0.9730) acc@1 0.6406 (0.6423) acc@5 0.8672 (0.8935)\n",
      "\u001b[32m[2020-07-11 19:43:13] __main__ INFO: \u001b[0mElapsed 391.32\n",
      "\u001b[32m[2020-07-11 19:43:13] __main__ INFO: \u001b[0mVal 34\n",
      "\u001b[32m[2020-07-11 19:43:26] __main__ INFO: \u001b[0mEpoch 34 loss 1.3561 acc@1 0.5362 acc@5 0.8582\n",
      "\u001b[32m[2020-07-11 19:43:26] __main__ INFO: \u001b[0mElapsed 13.11\n",
      "\u001b[32m[2020-07-11 19:43:26] __main__ INFO: \u001b[0mTrain 35 11934\n",
      "\u001b[32m[2020-07-11 19:45:17] __main__ INFO: \u001b[0mEpoch 35 Step 100/351 lr 0.100000 loss 1.0713 (0.9632) acc@1 0.5625 (0.6495) acc@5 0.8906 (0.8870)\n",
      "\u001b[32m[2020-07-11 19:47:09] __main__ INFO: \u001b[0mEpoch 35 Step 200/351 lr 0.100000 loss 0.9275 (0.9684) acc@1 0.6172 (0.6467) acc@5 0.8672 (0.8893)\n",
      "\u001b[32m[2020-07-11 19:49:00] __main__ INFO: \u001b[0mEpoch 35 Step 300/351 lr 0.100000 loss 0.7668 (0.9775) acc@1 0.7266 (0.6441) acc@5 0.9297 (0.8902)\n",
      "\u001b[32m[2020-07-11 19:49:57] __main__ INFO: \u001b[0mEpoch 35 Step 351/351 lr 0.100000 loss 1.0977 (0.9776) acc@1 0.6016 (0.6444) acc@5 0.8984 (0.8908)\n",
      "\u001b[32m[2020-07-11 19:49:57] __main__ INFO: \u001b[0mElapsed 391.31\n",
      "\u001b[32m[2020-07-11 19:49:57] __main__ INFO: \u001b[0mVal 35\n",
      "\u001b[32m[2020-07-11 19:50:10] __main__ INFO: \u001b[0mEpoch 35 loss 1.2539 acc@1 0.5664 acc@5 0.8774\n",
      "\u001b[32m[2020-07-11 19:50:10] __main__ INFO: \u001b[0mElapsed 13.10\n",
      "\u001b[32m[2020-07-11 19:50:10] __main__ INFO: \u001b[0mTrain 36 12285\n",
      "\u001b[32m[2020-07-11 19:52:02] __main__ INFO: \u001b[0mEpoch 36 Step 100/351 lr 0.100000 loss 0.9114 (0.9479) acc@1 0.6328 (0.6504) acc@5 0.9141 (0.8920)\n",
      "\u001b[32m[2020-07-11 19:53:53] __main__ INFO: \u001b[0mEpoch 36 Step 200/351 lr 0.100000 loss 1.0394 (0.9602) acc@1 0.6641 (0.6479) acc@5 0.8516 (0.8932)\n",
      "\u001b[32m[2020-07-11 19:55:45] __main__ INFO: \u001b[0mEpoch 36 Step 300/351 lr 0.100000 loss 1.0771 (0.9703) acc@1 0.6094 (0.6446) acc@5 0.8281 (0.8923)\n",
      "\u001b[32m[2020-07-11 19:56:42] __main__ INFO: \u001b[0mEpoch 36 Step 351/351 lr 0.100000 loss 1.0383 (0.9713) acc@1 0.6328 (0.6445) acc@5 0.8906 (0.8922)\n",
      "\u001b[32m[2020-07-11 19:56:42] __main__ INFO: \u001b[0mElapsed 391.34\n",
      "\u001b[32m[2020-07-11 19:56:42] __main__ INFO: \u001b[0mVal 36\n",
      "\u001b[32m[2020-07-11 19:56:55] __main__ INFO: \u001b[0mEpoch 36 loss 1.1949 acc@1 0.5700 acc@5 0.8776\n",
      "\u001b[32m[2020-07-11 19:56:55] __main__ INFO: \u001b[0mElapsed 13.11\n",
      "\u001b[32m[2020-07-11 19:56:55] __main__ INFO: \u001b[0mTrain 37 12636\n",
      "\u001b[32m[2020-07-11 19:58:46] __main__ INFO: \u001b[0mEpoch 37 Step 100/351 lr 0.100000 loss 1.1080 (0.9411) acc@1 0.5859 (0.6555) acc@5 0.8359 (0.8932)\n",
      "\u001b[32m[2020-07-11 20:00:38] __main__ INFO: \u001b[0mEpoch 37 Step 200/351 lr 0.100000 loss 1.0918 (0.9476) acc@1 0.5703 (0.6532) acc@5 0.9062 (0.8941)\n",
      "\u001b[32m[2020-07-11 20:02:29] __main__ INFO: \u001b[0mEpoch 37 Step 300/351 lr 0.100000 loss 0.9550 (0.9621) acc@1 0.6328 (0.6489) acc@5 0.8906 (0.8923)\n",
      "\u001b[32m[2020-07-11 20:03:26] __main__ INFO: \u001b[0mEpoch 37 Step 351/351 lr 0.100000 loss 0.9595 (0.9632) acc@1 0.6719 (0.6481) acc@5 0.8906 (0.8923)\n",
      "\u001b[32m[2020-07-11 20:03:26] __main__ INFO: \u001b[0mElapsed 391.30\n",
      "\u001b[32m[2020-07-11 20:03:26] __main__ INFO: \u001b[0mVal 37\n",
      "\u001b[32m[2020-07-11 20:03:39] __main__ INFO: \u001b[0mEpoch 37 loss 1.2526 acc@1 0.5646 acc@5 0.8716\n",
      "\u001b[32m[2020-07-11 20:03:39] __main__ INFO: \u001b[0mElapsed 13.06\n",
      "\u001b[32m[2020-07-11 20:03:39] __main__ INFO: \u001b[0mTrain 38 12987\n",
      "\u001b[32m[2020-07-11 20:05:31] __main__ INFO: \u001b[0mEpoch 38 Step 100/351 lr 0.100000 loss 0.9657 (0.9504) acc@1 0.6406 (0.6504) acc@5 0.8750 (0.8951)\n",
      "\u001b[32m[2020-07-11 20:07:22] __main__ INFO: \u001b[0mEpoch 38 Step 200/351 lr 0.100000 loss 0.9233 (0.9588) acc@1 0.6875 (0.6497) acc@5 0.9531 (0.8938)\n",
      "\u001b[32m[2020-07-11 20:09:14] __main__ INFO: \u001b[0mEpoch 38 Step 300/351 lr 0.100000 loss 1.0970 (0.9654) acc@1 0.5703 (0.6467) acc@5 0.8984 (0.8928)\n",
      "\u001b[32m[2020-07-11 20:10:10] __main__ INFO: \u001b[0mEpoch 38 Step 351/351 lr 0.100000 loss 0.9381 (0.9672) acc@1 0.6797 (0.6457) acc@5 0.8516 (0.8927)\n",
      "\u001b[32m[2020-07-11 20:10:10] __main__ INFO: \u001b[0mElapsed 391.23\n",
      "\u001b[32m[2020-07-11 20:10:10] __main__ INFO: \u001b[0mVal 38\n",
      "\u001b[32m[2020-07-11 20:10:24] __main__ INFO: \u001b[0mEpoch 38 loss 1.1669 acc@1 0.5806 acc@5 0.8716\n",
      "\u001b[32m[2020-07-11 20:10:24] __main__ INFO: \u001b[0mElapsed 13.10\n",
      "\u001b[32m[2020-07-11 20:10:24] __main__ INFO: \u001b[0mTrain 39 13338\n",
      "\u001b[32m[2020-07-11 20:12:15] __main__ INFO: \u001b[0mEpoch 39 Step 100/351 lr 0.100000 loss 1.0580 (0.9366) acc@1 0.6094 (0.6540) acc@5 0.8594 (0.8933)\n",
      "\u001b[32m[2020-07-11 20:14:06] __main__ INFO: \u001b[0mEpoch 39 Step 200/351 lr 0.100000 loss 1.0521 (0.9457) acc@1 0.6094 (0.6514) acc@5 0.9219 (0.8925)\n",
      "\u001b[32m[2020-07-11 20:15:58] __main__ INFO: \u001b[0mEpoch 39 Step 300/351 lr 0.100000 loss 1.1263 (0.9579) acc@1 0.6250 (0.6477) acc@5 0.8672 (0.8906)\n",
      "\u001b[32m[2020-07-11 20:16:55] __main__ INFO: \u001b[0mEpoch 39 Step 351/351 lr 0.100000 loss 1.0505 (0.9613) acc@1 0.5938 (0.6472) acc@5 0.8984 (0.8914)\n",
      "\u001b[32m[2020-07-11 20:16:55] __main__ INFO: \u001b[0mElapsed 391.13\n",
      "\u001b[32m[2020-07-11 20:16:55] __main__ INFO: \u001b[0mVal 39\n",
      "\u001b[32m[2020-07-11 20:17:08] __main__ INFO: \u001b[0mEpoch 39 loss 1.1576 acc@1 0.5880 acc@5 0.8748\n",
      "\u001b[32m[2020-07-11 20:17:08] __main__ INFO: \u001b[0mElapsed 13.11\n",
      "\u001b[32m[2020-07-11 20:17:08] __main__ INFO: \u001b[0mTrain 40 13689\n",
      "\u001b[32m[2020-07-11 20:18:59] __main__ INFO: \u001b[0mEpoch 40 Step 100/351 lr 0.100000 loss 0.7964 (0.9342) acc@1 0.7266 (0.6605) acc@5 0.8984 (0.8953)\n",
      "\u001b[32m[2020-07-11 20:20:51] __main__ INFO: \u001b[0mEpoch 40 Step 200/351 lr 0.100000 loss 0.9448 (0.9481) acc@1 0.6641 (0.6537) acc@5 0.8906 (0.8937)\n",
      "\u001b[32m[2020-07-11 20:22:42] __main__ INFO: \u001b[0mEpoch 40 Step 300/351 lr 0.100000 loss 0.9761 (0.9566) acc@1 0.6562 (0.6499) acc@5 0.8594 (0.8934)\n",
      "\u001b[32m[2020-07-11 20:23:39] __main__ INFO: \u001b[0mEpoch 40 Step 351/351 lr 0.100000 loss 0.9825 (0.9594) acc@1 0.6797 (0.6491) acc@5 0.8906 (0.8934)\n",
      "\u001b[32m[2020-07-11 20:23:39] __main__ INFO: \u001b[0mElapsed 391.06\n",
      "\u001b[32m[2020-07-11 20:23:39] __main__ INFO: \u001b[0mVal 40\n",
      "\u001b[32m[2020-07-11 20:23:52] __main__ INFO: \u001b[0mEpoch 40 loss 1.3497 acc@1 0.5492 acc@5 0.8624\n",
      "\u001b[32m[2020-07-11 20:23:52] __main__ INFO: \u001b[0mElapsed 13.08\n",
      "\u001b[32m[2020-07-11 20:23:52] __main__ INFO: \u001b[0mTrain 41 14040\n",
      "\u001b[32m[2020-07-11 20:25:43] __main__ INFO: \u001b[0mEpoch 41 Step 100/351 lr 0.100000 loss 1.1096 (0.9360) acc@1 0.5547 (0.6573) acc@5 0.8594 (0.8912)\n",
      "\u001b[32m[2020-07-11 20:27:35] __main__ INFO: \u001b[0mEpoch 41 Step 200/351 lr 0.100000 loss 1.0027 (0.9474) acc@1 0.6406 (0.6533) acc@5 0.8906 (0.8934)\n",
      "\u001b[32m[2020-07-11 20:29:26] __main__ INFO: \u001b[0mEpoch 41 Step 300/351 lr 0.100000 loss 0.9072 (0.9495) acc@1 0.6797 (0.6523) acc@5 0.8750 (0.8920)\n",
      "\u001b[32m[2020-07-11 20:30:23] __main__ INFO: \u001b[0mEpoch 41 Step 351/351 lr 0.100000 loss 0.8530 (0.9529) acc@1 0.7031 (0.6506) acc@5 0.8906 (0.8916)\n",
      "\u001b[32m[2020-07-11 20:30:23] __main__ INFO: \u001b[0mElapsed 391.08\n",
      "\u001b[32m[2020-07-11 20:30:23] __main__ INFO: \u001b[0mVal 41\n",
      "\u001b[32m[2020-07-11 20:30:36] __main__ INFO: \u001b[0mEpoch 41 loss 1.6863 acc@1 0.4972 acc@5 0.8274\n",
      "\u001b[32m[2020-07-11 20:30:36] __main__ INFO: \u001b[0mElapsed 13.11\n",
      "\u001b[32m[2020-07-11 20:30:36] __main__ INFO: \u001b[0mTrain 42 14391\n",
      "\u001b[32m[2020-07-11 20:32:28] __main__ INFO: \u001b[0mEpoch 42 Step 100/351 lr 0.100000 loss 0.8646 (0.9198) acc@1 0.6875 (0.6613) acc@5 0.8906 (0.8957)\n",
      "\u001b[32m[2020-07-11 20:34:19] __main__ INFO: \u001b[0mEpoch 42 Step 200/351 lr 0.100000 loss 0.9098 (0.9337) acc@1 0.6719 (0.6561) acc@5 0.8750 (0.8924)\n",
      "\u001b[32m[2020-07-11 20:36:10] __main__ INFO: \u001b[0mEpoch 42 Step 300/351 lr 0.100000 loss 0.9099 (0.9475) acc@1 0.6719 (0.6511) acc@5 0.8750 (0.8920)\n",
      "\u001b[32m[2020-07-11 20:37:07] __main__ INFO: \u001b[0mEpoch 42 Step 351/351 lr 0.100000 loss 0.9801 (0.9493) acc@1 0.6797 (0.6511) acc@5 0.9141 (0.8922)\n",
      "\u001b[32m[2020-07-11 20:37:07] __main__ INFO: \u001b[0mElapsed 391.25\n",
      "\u001b[32m[2020-07-11 20:37:07] __main__ INFO: \u001b[0mVal 42\n",
      "\u001b[32m[2020-07-11 20:37:20] __main__ INFO: \u001b[0mEpoch 42 loss 1.2301 acc@1 0.5688 acc@5 0.8718\n",
      "\u001b[32m[2020-07-11 20:37:20] __main__ INFO: \u001b[0mElapsed 13.11\n",
      "\u001b[32m[2020-07-11 20:37:20] __main__ INFO: \u001b[0mTrain 43 14742\n",
      "\u001b[32m[2020-07-11 20:39:12] __main__ INFO: \u001b[0mEpoch 43 Step 100/351 lr 0.100000 loss 0.9687 (0.9314) acc@1 0.6797 (0.6565) acc@5 0.8516 (0.8934)\n",
      "\u001b[32m[2020-07-11 20:41:03] __main__ INFO: \u001b[0mEpoch 43 Step 200/351 lr 0.100000 loss 0.9081 (0.9335) acc@1 0.6719 (0.6568) acc@5 0.9062 (0.8946)\n",
      "\u001b[32m[2020-07-11 20:42:55] __main__ INFO: \u001b[0mEpoch 43 Step 300/351 lr 0.100000 loss 0.9554 (0.9468) acc@1 0.6641 (0.6538) acc@5 0.9062 (0.8949)\n",
      "\u001b[32m[2020-07-11 20:43:52] __main__ INFO: \u001b[0mEpoch 43 Step 351/351 lr 0.100000 loss 0.9405 (0.9509) acc@1 0.6328 (0.6518) acc@5 0.8594 (0.8938)\n",
      "\u001b[32m[2020-07-11 20:43:52] __main__ INFO: \u001b[0mElapsed 391.21\n",
      "\u001b[32m[2020-07-11 20:43:52] __main__ INFO: \u001b[0mVal 43\n",
      "\u001b[32m[2020-07-11 20:44:05] __main__ INFO: \u001b[0mEpoch 43 loss 1.2406 acc@1 0.5626 acc@5 0.8748\n",
      "\u001b[32m[2020-07-11 20:44:05] __main__ INFO: \u001b[0mElapsed 13.08\n",
      "\u001b[32m[2020-07-11 20:44:05] __main__ INFO: \u001b[0mTrain 44 15093\n",
      "\u001b[32m[2020-07-11 20:45:56] __main__ INFO: \u001b[0mEpoch 44 Step 100/351 lr 0.100000 loss 0.9901 (0.9317) acc@1 0.6328 (0.6609) acc@5 0.8984 (0.8939)\n",
      "\u001b[32m[2020-07-11 20:47:48] __main__ INFO: \u001b[0mEpoch 44 Step 200/351 lr 0.100000 loss 1.0505 (0.9421) acc@1 0.6484 (0.6570) acc@5 0.9062 (0.8932)\n",
      "\u001b[32m[2020-07-11 20:49:39] __main__ INFO: \u001b[0mEpoch 44 Step 300/351 lr 0.100000 loss 1.1849 (0.9454) acc@1 0.6016 (0.6552) acc@5 0.8594 (0.8932)\n",
      "\u001b[32m[2020-07-11 20:50:36] __main__ INFO: \u001b[0mEpoch 44 Step 351/351 lr 0.100000 loss 1.1246 (0.9496) acc@1 0.5703 (0.6543) acc@5 0.8828 (0.8936)\n",
      "\u001b[32m[2020-07-11 20:50:36] __main__ INFO: \u001b[0mElapsed 391.41\n",
      "\u001b[32m[2020-07-11 20:50:36] __main__ INFO: \u001b[0mVal 44\n",
      "\u001b[32m[2020-07-11 20:50:49] __main__ INFO: \u001b[0mEpoch 44 loss 1.3210 acc@1 0.5428 acc@5 0.8656\n",
      "\u001b[32m[2020-07-11 20:50:49] __main__ INFO: \u001b[0mElapsed 13.13\n",
      "\u001b[32m[2020-07-11 20:50:49] __main__ INFO: \u001b[0mTrain 45 15444\n",
      "\u001b[32m[2020-07-11 20:52:41] __main__ INFO: \u001b[0mEpoch 45 Step 100/351 lr 0.100000 loss 0.9103 (0.9177) acc@1 0.6875 (0.6682) acc@5 0.9062 (0.8948)\n",
      "\u001b[32m[2020-07-11 20:54:32] __main__ INFO: \u001b[0mEpoch 45 Step 200/351 lr 0.100000 loss 0.9434 (0.9403) acc@1 0.6719 (0.6562) acc@5 0.8906 (0.8936)\n",
      "\u001b[32m[2020-07-11 20:56:24] __main__ INFO: \u001b[0mEpoch 45 Step 300/351 lr 0.100000 loss 0.9113 (0.9462) acc@1 0.6562 (0.6540) acc@5 0.8828 (0.8928)\n",
      "\u001b[32m[2020-07-11 20:57:21] __main__ INFO: \u001b[0mEpoch 45 Step 351/351 lr 0.100000 loss 0.9315 (0.9453) acc@1 0.6562 (0.6537) acc@5 0.8906 (0.8936)\n",
      "\u001b[32m[2020-07-11 20:57:21] __main__ INFO: \u001b[0mElapsed 391.56\n",
      "\u001b[32m[2020-07-11 20:57:21] __main__ INFO: \u001b[0mVal 45\n",
      "\u001b[32m[2020-07-11 20:57:34] __main__ INFO: \u001b[0mEpoch 45 loss 1.2255 acc@1 0.5680 acc@5 0.8734\n",
      "\u001b[32m[2020-07-11 20:57:34] __main__ INFO: \u001b[0mElapsed 13.10\n",
      "\u001b[32m[2020-07-11 20:57:34] __main__ INFO: \u001b[0mTrain 46 15795\n",
      "\u001b[32m[2020-07-11 20:59:26] __main__ INFO: \u001b[0mEpoch 46 Step 100/351 lr 0.100000 loss 1.0164 (0.9300) acc@1 0.6250 (0.6636) acc@5 0.8828 (0.8930)\n",
      "\u001b[32m[2020-07-11 21:01:17] __main__ INFO: \u001b[0mEpoch 46 Step 200/351 lr 0.100000 loss 0.9930 (0.9392) acc@1 0.6797 (0.6564) acc@5 0.8984 (0.8955)\n",
      "\u001b[32m[2020-07-11 21:03:09] __main__ INFO: \u001b[0mEpoch 46 Step 300/351 lr 0.100000 loss 0.8604 (0.9404) acc@1 0.6875 (0.6569) acc@5 0.9375 (0.8946)\n",
      "\u001b[32m[2020-07-11 21:04:05] __main__ INFO: \u001b[0mEpoch 46 Step 351/351 lr 0.100000 loss 1.0510 (0.9421) acc@1 0.5547 (0.6560) acc@5 0.8906 (0.8948)\n",
      "\u001b[32m[2020-07-11 21:04:05] __main__ INFO: \u001b[0mElapsed 391.55\n",
      "\u001b[32m[2020-07-11 21:04:05] __main__ INFO: \u001b[0mVal 46\n",
      "\u001b[32m[2020-07-11 21:04:19] __main__ INFO: \u001b[0mEpoch 46 loss 1.2024 acc@1 0.5800 acc@5 0.8708\n",
      "\u001b[32m[2020-07-11 21:04:19] __main__ INFO: \u001b[0mElapsed 13.09\n",
      "\u001b[32m[2020-07-11 21:04:19] __main__ INFO: \u001b[0mTrain 47 16146\n",
      "\u001b[32m[2020-07-11 21:06:10] __main__ INFO: \u001b[0mEpoch 47 Step 100/351 lr 0.100000 loss 0.8519 (0.9035) acc@1 0.6797 (0.6677) acc@5 0.8984 (0.8986)\n",
      "\u001b[32m[2020-07-11 21:08:02] __main__ INFO: \u001b[0mEpoch 47 Step 200/351 lr 0.100000 loss 1.1080 (0.9265) acc@1 0.5547 (0.6591) acc@5 0.8828 (0.8964)\n",
      "\u001b[32m[2020-07-11 21:09:53] __main__ INFO: \u001b[0mEpoch 47 Step 300/351 lr 0.100000 loss 0.9936 (0.9387) acc@1 0.6641 (0.6560) acc@5 0.8906 (0.8952)\n",
      "\u001b[32m[2020-07-11 21:10:50] __main__ INFO: \u001b[0mEpoch 47 Step 351/351 lr 0.100000 loss 0.9020 (0.9418) acc@1 0.6719 (0.6549) acc@5 0.9141 (0.8946)\n",
      "\u001b[32m[2020-07-11 21:10:50] __main__ INFO: \u001b[0mElapsed 391.57\n",
      "\u001b[32m[2020-07-11 21:10:50] __main__ INFO: \u001b[0mVal 47\n",
      "\u001b[32m[2020-07-11 21:11:03] __main__ INFO: \u001b[0mEpoch 47 loss 1.1836 acc@1 0.5808 acc@5 0.8776\n",
      "\u001b[32m[2020-07-11 21:11:03] __main__ INFO: \u001b[0mElapsed 13.14\n",
      "\u001b[32m[2020-07-11 21:11:03] __main__ INFO: \u001b[0mTrain 48 16497\n",
      "\u001b[32m[2020-07-11 21:12:55] __main__ INFO: \u001b[0mEpoch 48 Step 100/351 lr 0.100000 loss 0.8792 (0.9149) acc@1 0.6562 (0.6653) acc@5 0.8906 (0.8940)\n",
      "\u001b[32m[2020-07-11 21:14:46] __main__ INFO: \u001b[0mEpoch 48 Step 200/351 lr 0.100000 loss 1.1125 (0.9325) acc@1 0.5703 (0.6586) acc@5 0.8750 (0.8913)\n",
      "\u001b[32m[2020-07-11 21:16:38] __main__ INFO: \u001b[0mEpoch 48 Step 300/351 lr 0.100000 loss 0.9597 (0.9399) acc@1 0.6797 (0.6554) acc@5 0.9219 (0.8921)\n",
      "\u001b[32m[2020-07-11 21:17:35] __main__ INFO: \u001b[0mEpoch 48 Step 351/351 lr 0.100000 loss 0.7821 (0.9396) acc@1 0.7422 (0.6561) acc@5 0.9219 (0.8929)\n",
      "\u001b[32m[2020-07-11 21:17:35] __main__ INFO: \u001b[0mElapsed 391.47\n",
      "\u001b[32m[2020-07-11 21:17:35] __main__ INFO: \u001b[0mVal 48\n",
      "\u001b[32m[2020-07-11 21:17:48] __main__ INFO: \u001b[0mEpoch 48 loss 1.2239 acc@1 0.5686 acc@5 0.8808\n",
      "\u001b[32m[2020-07-11 21:17:48] __main__ INFO: \u001b[0mElapsed 13.09\n",
      "\u001b[32m[2020-07-11 21:17:48] __main__ INFO: \u001b[0mTrain 49 16848\n",
      "\u001b[32m[2020-07-11 21:19:39] __main__ INFO: \u001b[0mEpoch 49 Step 100/351 lr 0.100000 loss 0.7594 (0.9165) acc@1 0.7188 (0.6611) acc@5 0.9062 (0.8984)\n",
      "\u001b[32m[2020-07-11 21:21:31] __main__ INFO: \u001b[0mEpoch 49 Step 200/351 lr 0.100000 loss 0.9015 (0.9243) acc@1 0.6641 (0.6602) acc@5 0.8984 (0.8955)\n",
      "\u001b[32m[2020-07-11 21:23:23] __main__ INFO: \u001b[0mEpoch 49 Step 300/351 lr 0.100000 loss 0.9621 (0.9314) acc@1 0.6719 (0.6582) acc@5 0.8750 (0.8965)\n",
      "\u001b[32m[2020-07-11 21:24:19] __main__ INFO: \u001b[0mEpoch 49 Step 351/351 lr 0.100000 loss 0.7813 (0.9363) acc@1 0.7031 (0.6569) acc@5 0.9141 (0.8955)\n",
      "\u001b[32m[2020-07-11 21:24:19] __main__ INFO: \u001b[0mElapsed 391.53\n",
      "\u001b[32m[2020-07-11 21:24:19] __main__ INFO: \u001b[0mVal 49\n",
      "\u001b[32m[2020-07-11 21:24:32] __main__ INFO: \u001b[0mEpoch 49 loss 1.1434 acc@1 0.5872 acc@5 0.8794\n",
      "\u001b[32m[2020-07-11 21:24:32] __main__ INFO: \u001b[0mElapsed 13.10\n",
      "\u001b[32m[2020-07-11 21:24:32] __main__ INFO: \u001b[0mTrain 50 17199\n",
      "\u001b[32m[2020-07-11 21:26:24] __main__ INFO: \u001b[0mEpoch 50 Step 100/351 lr 0.100000 loss 0.8631 (0.9223) acc@1 0.6953 (0.6637) acc@5 0.8828 (0.8945)\n",
      "\u001b[32m[2020-07-11 21:28:16] __main__ INFO: \u001b[0mEpoch 50 Step 200/351 lr 0.100000 loss 1.0068 (0.9386) acc@1 0.6406 (0.6578) acc@5 0.8906 (0.8930)\n",
      "\u001b[32m[2020-07-11 21:30:07] __main__ INFO: \u001b[0mEpoch 50 Step 300/351 lr 0.100000 loss 1.0194 (0.9395) acc@1 0.6328 (0.6562) acc@5 0.8906 (0.8934)\n",
      "\u001b[32m[2020-07-11 21:31:04] __main__ INFO: \u001b[0mEpoch 50 Step 351/351 lr 0.100000 loss 1.0218 (0.9399) acc@1 0.6406 (0.6572) acc@5 0.8906 (0.8932)\n",
      "\u001b[32m[2020-07-11 21:31:04] __main__ INFO: \u001b[0mElapsed 391.48\n",
      "\u001b[32m[2020-07-11 21:31:04] __main__ INFO: \u001b[0mVal 50\n",
      "\u001b[32m[2020-07-11 21:31:17] __main__ INFO: \u001b[0mEpoch 50 loss 1.3250 acc@1 0.5458 acc@5 0.8684\n",
      "\u001b[32m[2020-07-11 21:31:17] __main__ INFO: \u001b[0mElapsed 13.08\n",
      "\u001b[32m[2020-07-11 21:31:17] __main__ INFO: \u001b[0mTrain 51 17550\n",
      "\u001b[32m[2020-07-11 21:33:09] __main__ INFO: \u001b[0mEpoch 51 Step 100/351 lr 0.100000 loss 0.9370 (0.8978) acc@1 0.6562 (0.6696) acc@5 0.9141 (0.8932)\n",
      "\u001b[32m[2020-07-11 21:35:00] __main__ INFO: \u001b[0mEpoch 51 Step 200/351 lr 0.100000 loss 0.9248 (0.9152) acc@1 0.6719 (0.6624) acc@5 0.9141 (0.8934)\n",
      "\u001b[32m[2020-07-11 21:36:52] __main__ INFO: \u001b[0mEpoch 51 Step 300/351 lr 0.100000 loss 0.8174 (0.9278) acc@1 0.6875 (0.6591) acc@5 0.8906 (0.8929)\n",
      "\u001b[32m[2020-07-11 21:37:48] __main__ INFO: \u001b[0mEpoch 51 Step 351/351 lr 0.100000 loss 1.0964 (0.9340) acc@1 0.5938 (0.6572) acc@5 0.8672 (0.8921)\n",
      "\u001b[32m[2020-07-11 21:37:48] __main__ INFO: \u001b[0mElapsed 391.45\n",
      "\u001b[32m[2020-07-11 21:37:48] __main__ INFO: \u001b[0mVal 51\n",
      "\u001b[32m[2020-07-11 21:38:02] __main__ INFO: \u001b[0mEpoch 51 loss 1.2427 acc@1 0.5732 acc@5 0.8752\n",
      "\u001b[32m[2020-07-11 21:38:02] __main__ INFO: \u001b[0mElapsed 13.08\n",
      "\u001b[32m[2020-07-11 21:38:02] __main__ INFO: \u001b[0mTrain 52 17901\n",
      "\u001b[32m[2020-07-11 21:39:53] __main__ INFO: \u001b[0mEpoch 52 Step 100/351 lr 0.100000 loss 1.0241 (0.9134) acc@1 0.6406 (0.6652) acc@5 0.8828 (0.8945)\n",
      "\u001b[32m[2020-07-11 21:41:45] __main__ INFO: \u001b[0mEpoch 52 Step 200/351 lr 0.100000 loss 0.9030 (0.9221) acc@1 0.6719 (0.6620) acc@5 0.9375 (0.8960)\n",
      "\u001b[32m[2020-07-11 21:43:36] __main__ INFO: \u001b[0mEpoch 52 Step 300/351 lr 0.100000 loss 0.9836 (0.9294) acc@1 0.6250 (0.6592) acc@5 0.9297 (0.8948)\n",
      "\u001b[32m[2020-07-11 21:44:33] __main__ INFO: \u001b[0mEpoch 52 Step 351/351 lr 0.100000 loss 0.8242 (0.9324) acc@1 0.7188 (0.6585) acc@5 0.9062 (0.8947)\n",
      "\u001b[32m[2020-07-11 21:44:33] __main__ INFO: \u001b[0mElapsed 391.09\n",
      "\u001b[32m[2020-07-11 21:44:33] __main__ INFO: \u001b[0mVal 52\n",
      "\u001b[32m[2020-07-11 21:44:46] __main__ INFO: \u001b[0mEpoch 52 loss 1.1876 acc@1 0.5804 acc@5 0.8746\n",
      "\u001b[32m[2020-07-11 21:44:46] __main__ INFO: \u001b[0mElapsed 13.08\n",
      "\u001b[32m[2020-07-11 21:44:46] __main__ INFO: \u001b[0mTrain 53 18252\n",
      "\u001b[32m[2020-07-11 21:46:37] __main__ INFO: \u001b[0mEpoch 53 Step 100/351 lr 0.100000 loss 0.8417 (0.9155) acc@1 0.6875 (0.6635) acc@5 0.8672 (0.8959)\n",
      "\u001b[32m[2020-07-11 21:48:29] __main__ INFO: \u001b[0mEpoch 53 Step 200/351 lr 0.100000 loss 0.9121 (0.9140) acc@1 0.6484 (0.6648) acc@5 0.8906 (0.8962)\n",
      "\u001b[32m[2020-07-11 21:50:20] __main__ INFO: \u001b[0mEpoch 53 Step 300/351 lr 0.100000 loss 0.8232 (0.9257) acc@1 0.6797 (0.6598) acc@5 0.8984 (0.8937)\n",
      "\u001b[32m[2020-07-11 21:51:17] __main__ INFO: \u001b[0mEpoch 53 Step 351/351 lr 0.100000 loss 0.9440 (0.9277) acc@1 0.6562 (0.6595) acc@5 0.8828 (0.8946)\n",
      "\u001b[32m[2020-07-11 21:51:17] __main__ INFO: \u001b[0mElapsed 391.04\n",
      "\u001b[32m[2020-07-11 21:51:17] __main__ INFO: \u001b[0mVal 53\n",
      "\u001b[32m[2020-07-11 21:51:30] __main__ INFO: \u001b[0mEpoch 53 loss 1.1711 acc@1 0.5842 acc@5 0.8754\n",
      "\u001b[32m[2020-07-11 21:51:30] __main__ INFO: \u001b[0mElapsed 13.09\n",
      "\u001b[32m[2020-07-11 21:51:30] __main__ INFO: \u001b[0mTrain 54 18603\n",
      "\u001b[32m[2020-07-11 21:53:21] __main__ INFO: \u001b[0mEpoch 54 Step 100/351 lr 0.100000 loss 1.0182 (0.9118) acc@1 0.6250 (0.6644) acc@5 0.8906 (0.8943)\n",
      "\u001b[32m[2020-07-11 21:55:13] __main__ INFO: \u001b[0mEpoch 54 Step 200/351 lr 0.100000 loss 0.9442 (0.9224) acc@1 0.6094 (0.6603) acc@5 0.9297 (0.8949)\n",
      "\u001b[32m[2020-07-11 21:57:04] __main__ INFO: \u001b[0mEpoch 54 Step 300/351 lr 0.100000 loss 0.8511 (0.9323) acc@1 0.6562 (0.6574) acc@5 0.9297 (0.8943)\n",
      "\u001b[32m[2020-07-11 21:58:01] __main__ INFO: \u001b[0mEpoch 54 Step 351/351 lr 0.100000 loss 0.8673 (0.9351) acc@1 0.6562 (0.6570) acc@5 0.8984 (0.8938)\n",
      "\u001b[32m[2020-07-11 21:58:01] __main__ INFO: \u001b[0mElapsed 391.02\n",
      "\u001b[32m[2020-07-11 21:58:01] __main__ INFO: \u001b[0mVal 54\n",
      "\u001b[32m[2020-07-11 21:58:14] __main__ INFO: \u001b[0mEpoch 54 loss 1.2571 acc@1 0.5670 acc@5 0.8590\n",
      "\u001b[32m[2020-07-11 21:58:14] __main__ INFO: \u001b[0mElapsed 13.09\n",
      "\u001b[32m[2020-07-11 21:58:14] __main__ INFO: \u001b[0mTrain 55 18954\n",
      "\u001b[32m[2020-07-11 22:00:05] __main__ INFO: \u001b[0mEpoch 55 Step 100/351 lr 0.100000 loss 0.9881 (0.9043) acc@1 0.6016 (0.6698) acc@5 0.8750 (0.8969)\n",
      "\u001b[32m[2020-07-11 22:01:57] __main__ INFO: \u001b[0mEpoch 55 Step 200/351 lr 0.100000 loss 0.7919 (0.9202) acc@1 0.7031 (0.6630) acc@5 0.9375 (0.8932)\n",
      "\u001b[32m[2020-07-11 22:03:48] __main__ INFO: \u001b[0mEpoch 55 Step 300/351 lr 0.100000 loss 0.7585 (0.9200) acc@1 0.7266 (0.6640) acc@5 0.8828 (0.8940)\n",
      "\u001b[32m[2020-07-11 22:04:45] __main__ INFO: \u001b[0mEpoch 55 Step 351/351 lr 0.100000 loss 0.9487 (0.9238) acc@1 0.6328 (0.6622) acc@5 0.8984 (0.8941)\n",
      "\u001b[32m[2020-07-11 22:04:45] __main__ INFO: \u001b[0mElapsed 390.93\n",
      "\u001b[32m[2020-07-11 22:04:45] __main__ INFO: \u001b[0mVal 55\n",
      "\u001b[32m[2020-07-11 22:04:58] __main__ INFO: \u001b[0mEpoch 55 loss 1.1327 acc@1 0.5962 acc@5 0.8824\n",
      "\u001b[32m[2020-07-11 22:04:58] __main__ INFO: \u001b[0mElapsed 13.08\n",
      "\u001b[32m[2020-07-11 22:04:58] __main__ INFO: \u001b[0mTrain 56 19305\n",
      "\u001b[32m[2020-07-11 22:06:49] __main__ INFO: \u001b[0mEpoch 56 Step 100/351 lr 0.100000 loss 1.0175 (0.9242) acc@1 0.6406 (0.6590) acc@5 0.8750 (0.8903)\n",
      "\u001b[32m[2020-07-11 22:08:41] __main__ INFO: \u001b[0mEpoch 56 Step 200/351 lr 0.100000 loss 0.9939 (0.9242) acc@1 0.6250 (0.6617) acc@5 0.8828 (0.8944)\n",
      "\u001b[32m[2020-07-11 22:10:32] __main__ INFO: \u001b[0mEpoch 56 Step 300/351 lr 0.100000 loss 0.8928 (0.9264) acc@1 0.6484 (0.6600) acc@5 0.8828 (0.8948)\n",
      "\u001b[32m[2020-07-11 22:11:29] __main__ INFO: \u001b[0mEpoch 56 Step 351/351 lr 0.100000 loss 0.9647 (0.9294) acc@1 0.6719 (0.6596) acc@5 0.9219 (0.8945)\n",
      "\u001b[32m[2020-07-11 22:11:29] __main__ INFO: \u001b[0mElapsed 390.85\n",
      "\u001b[32m[2020-07-11 22:11:29] __main__ INFO: \u001b[0mVal 56\n",
      "\u001b[32m[2020-07-11 22:11:42] __main__ INFO: \u001b[0mEpoch 56 loss 1.2647 acc@1 0.5676 acc@5 0.8720\n",
      "\u001b[32m[2020-07-11 22:11:42] __main__ INFO: \u001b[0mElapsed 13.11\n",
      "\u001b[32m[2020-07-11 22:11:42] __main__ INFO: \u001b[0mTrain 57 19656\n",
      "\u001b[32m[2020-07-11 22:13:33] __main__ INFO: \u001b[0mEpoch 57 Step 100/351 lr 0.100000 loss 0.8602 (0.9026) acc@1 0.6719 (0.6704) acc@5 0.9062 (0.8973)\n",
      "\u001b[32m[2020-07-11 22:15:25] __main__ INFO: \u001b[0mEpoch 57 Step 200/351 lr 0.100000 loss 1.0543 (0.9239) acc@1 0.5938 (0.6612) acc@5 0.8672 (0.8946)\n",
      "\u001b[32m[2020-07-11 22:17:16] __main__ INFO: \u001b[0mEpoch 57 Step 300/351 lr 0.100000 loss 0.8978 (0.9263) acc@1 0.6797 (0.6615) acc@5 0.8672 (0.8941)\n",
      "\u001b[32m[2020-07-11 22:18:13] __main__ INFO: \u001b[0mEpoch 57 Step 351/351 lr 0.100000 loss 0.8807 (0.9302) acc@1 0.6719 (0.6598) acc@5 0.8906 (0.8935)\n",
      "\u001b[32m[2020-07-11 22:18:13] __main__ INFO: \u001b[0mElapsed 390.80\n",
      "\u001b[32m[2020-07-11 22:18:13] __main__ INFO: \u001b[0mVal 57\n",
      "\u001b[32m[2020-07-11 22:18:26] __main__ INFO: \u001b[0mEpoch 57 loss 1.1500 acc@1 0.6014 acc@5 0.8782\n",
      "\u001b[32m[2020-07-11 22:18:26] __main__ INFO: \u001b[0mElapsed 13.06\n",
      "\u001b[32m[2020-07-11 22:18:26] __main__ INFO: \u001b[0mTrain 58 20007\n",
      "\u001b[32m[2020-07-11 22:20:17] __main__ INFO: \u001b[0mEpoch 58 Step 100/351 lr 0.100000 loss 0.9501 (0.9037) acc@1 0.6641 (0.6688) acc@5 0.9062 (0.8968)\n",
      "\u001b[32m[2020-07-11 22:22:09] __main__ INFO: \u001b[0mEpoch 58 Step 200/351 lr 0.100000 loss 1.0345 (0.9132) acc@1 0.6562 (0.6649) acc@5 0.8984 (0.8968)\n",
      "\u001b[32m[2020-07-11 22:24:00] __main__ INFO: \u001b[0mEpoch 58 Step 300/351 lr 0.100000 loss 0.9580 (0.9214) acc@1 0.6328 (0.6618) acc@5 0.8984 (0.8953)\n",
      "\u001b[32m[2020-07-11 22:24:57] __main__ INFO: \u001b[0mEpoch 58 Step 351/351 lr 0.100000 loss 0.8247 (0.9254) acc@1 0.7031 (0.6609) acc@5 0.9141 (0.8952)\n",
      "\u001b[32m[2020-07-11 22:24:57] __main__ INFO: \u001b[0mElapsed 390.94\n",
      "\u001b[32m[2020-07-11 22:24:57] __main__ INFO: \u001b[0mVal 58\n",
      "\u001b[32m[2020-07-11 22:25:10] __main__ INFO: \u001b[0mEpoch 58 loss 1.0838 acc@1 0.6098 acc@5 0.8866\n",
      "\u001b[32m[2020-07-11 22:25:10] __main__ INFO: \u001b[0mElapsed 13.08\n",
      "\u001b[32m[2020-07-11 22:25:10] __main__ INFO: \u001b[0mTrain 59 20358\n",
      "\u001b[32m[2020-07-11 22:27:01] __main__ INFO: \u001b[0mEpoch 59 Step 100/351 lr 0.100000 loss 0.9549 (0.9040) acc@1 0.6641 (0.6667) acc@5 0.8906 (0.8948)\n",
      "\u001b[32m[2020-07-11 22:28:53] __main__ INFO: \u001b[0mEpoch 59 Step 200/351 lr 0.100000 loss 0.9455 (0.9234) acc@1 0.6562 (0.6621) acc@5 0.8516 (0.8935)\n",
      "\u001b[32m[2020-07-11 22:30:44] __main__ INFO: \u001b[0mEpoch 59 Step 300/351 lr 0.100000 loss 0.9987 (0.9198) acc@1 0.6328 (0.6638) acc@5 0.8594 (0.8947)\n",
      "\u001b[32m[2020-07-11 22:31:41] __main__ INFO: \u001b[0mEpoch 59 Step 351/351 lr 0.100000 loss 1.0250 (0.9218) acc@1 0.5938 (0.6624) acc@5 0.8359 (0.8943)\n",
      "\u001b[32m[2020-07-11 22:31:41] __main__ INFO: \u001b[0mElapsed 390.80\n",
      "\u001b[32m[2020-07-11 22:31:41] __main__ INFO: \u001b[0mVal 59\n",
      "\u001b[32m[2020-07-11 22:31:54] __main__ INFO: \u001b[0mEpoch 59 loss 1.0784 acc@1 0.6110 acc@5 0.8854\n",
      "\u001b[32m[2020-07-11 22:31:54] __main__ INFO: \u001b[0mElapsed 13.08\n",
      "\u001b[32m[2020-07-11 22:31:54] __main__ INFO: \u001b[0mTrain 60 20709\n",
      "\u001b[32m[2020-07-11 22:33:45] __main__ INFO: \u001b[0mEpoch 60 Step 100/351 lr 0.100000 loss 0.9045 (0.8922) acc@1 0.6641 (0.6728) acc@5 0.9062 (0.8971)\n",
      "\u001b[32m[2020-07-11 22:35:36] __main__ INFO: \u001b[0mEpoch 60 Step 200/351 lr 0.100000 loss 1.0110 (0.9075) acc@1 0.6250 (0.6659) acc@5 0.9219 (0.8962)\n",
      "\u001b[32m[2020-07-11 22:37:28] __main__ INFO: \u001b[0mEpoch 60 Step 300/351 lr 0.100000 loss 1.0569 (0.9197) acc@1 0.6328 (0.6625) acc@5 0.9141 (0.8938)\n",
      "\u001b[32m[2020-07-11 22:38:24] __main__ INFO: \u001b[0mEpoch 60 Step 351/351 lr 0.100000 loss 1.0044 (0.9207) acc@1 0.6406 (0.6622) acc@5 0.9141 (0.8948)\n",
      "\u001b[32m[2020-07-11 22:38:25] __main__ INFO: \u001b[0mElapsed 390.78\n",
      "\u001b[32m[2020-07-11 22:38:25] __main__ INFO: \u001b[0mVal 60\n",
      "\u001b[32m[2020-07-11 22:38:38] __main__ INFO: \u001b[0mEpoch 60 loss 1.2693 acc@1 0.5722 acc@5 0.8710\n",
      "\u001b[32m[2020-07-11 22:38:38] __main__ INFO: \u001b[0mElapsed 13.11\n",
      "\u001b[32m[2020-07-11 22:38:38] __main__ INFO: \u001b[0mTrain 61 21060\n",
      "\u001b[32m[2020-07-11 22:40:29] __main__ INFO: \u001b[0mEpoch 61 Step 100/351 lr 0.020000 loss 0.7253 (0.7756) acc@1 0.7734 (0.7156) acc@5 0.9062 (0.8995)\n",
      "\u001b[32m[2020-07-11 22:42:20] __main__ INFO: \u001b[0mEpoch 61 Step 200/351 lr 0.020000 loss 0.7506 (0.7400) acc@1 0.7344 (0.7278) acc@5 0.8672 (0.9027)\n",
      "\u001b[32m[2020-07-11 22:44:12] __main__ INFO: \u001b[0mEpoch 61 Step 300/351 lr 0.020000 loss 0.7450 (0.7228) acc@1 0.7578 (0.7323) acc@5 0.9141 (0.9023)\n",
      "\u001b[32m[2020-07-11 22:45:08] __main__ INFO: \u001b[0mEpoch 61 Step 351/351 lr 0.020000 loss 0.6884 (0.7188) acc@1 0.7266 (0.7334) acc@5 0.9141 (0.9025)\n",
      "\u001b[32m[2020-07-11 22:45:08] __main__ INFO: \u001b[0mElapsed 390.79\n",
      "\u001b[32m[2020-07-11 22:45:08] __main__ INFO: \u001b[0mVal 61\n",
      "\u001b[32m[2020-07-11 22:45:22] __main__ INFO: \u001b[0mEpoch 61 loss 0.8791 acc@1 0.6820 acc@5 0.8948\n",
      "\u001b[32m[2020-07-11 22:45:22] __main__ INFO: \u001b[0mElapsed 13.10\n",
      "\u001b[32m[2020-07-11 22:45:22] __main__ INFO: \u001b[0mTrain 62 21411\n",
      "\u001b[32m[2020-07-11 22:47:13] __main__ INFO: \u001b[0mEpoch 62 Step 100/351 lr 0.020000 loss 0.5720 (0.6460) acc@1 0.7969 (0.7623) acc@5 0.9297 (0.9070)\n",
      "\u001b[32m[2020-07-11 22:49:04] __main__ INFO: \u001b[0mEpoch 62 Step 200/351 lr 0.020000 loss 0.7645 (0.6485) acc@1 0.7109 (0.7589) acc@5 0.8594 (0.9053)\n",
      "\u001b[32m[2020-07-11 22:50:55] __main__ INFO: \u001b[0mEpoch 62 Step 300/351 lr 0.020000 loss 0.5134 (0.6462) acc@1 0.8047 (0.7595) acc@5 0.9141 (0.9052)\n",
      "\u001b[32m[2020-07-11 22:51:52] __main__ INFO: \u001b[0mEpoch 62 Step 351/351 lr 0.020000 loss 0.5508 (0.6512) acc@1 0.7734 (0.7574) acc@5 0.9297 (0.9045)\n",
      "\u001b[32m[2020-07-11 22:51:52] __main__ INFO: \u001b[0mElapsed 390.70\n",
      "\u001b[32m[2020-07-11 22:51:52] __main__ INFO: \u001b[0mVal 62\n",
      "\u001b[32m[2020-07-11 22:52:05] __main__ INFO: \u001b[0mEpoch 62 loss 0.9027 acc@1 0.6796 acc@5 0.8978\n",
      "\u001b[32m[2020-07-11 22:52:05] __main__ INFO: \u001b[0mElapsed 13.09\n",
      "\u001b[32m[2020-07-11 22:52:05] __main__ INFO: \u001b[0mTrain 63 21762\n",
      "\u001b[32m[2020-07-11 22:53:57] __main__ INFO: \u001b[0mEpoch 63 Step 100/351 lr 0.020000 loss 0.5256 (0.6100) acc@1 0.8203 (0.7703) acc@5 0.9219 (0.9082)\n",
      "\u001b[32m[2020-07-11 22:55:48] __main__ INFO: \u001b[0mEpoch 63 Step 200/351 lr 0.020000 loss 0.6780 (0.6099) acc@1 0.7266 (0.7715) acc@5 0.9219 (0.9079)\n",
      "\u001b[32m[2020-07-11 22:57:39] __main__ INFO: \u001b[0mEpoch 63 Step 300/351 lr 0.020000 loss 0.7087 (0.6192) acc@1 0.7266 (0.7667) acc@5 0.9219 (0.9068)\n",
      "\u001b[32m[2020-07-11 22:58:36] __main__ INFO: \u001b[0mEpoch 63 Step 351/351 lr 0.020000 loss 0.6322 (0.6220) acc@1 0.7578 (0.7659) acc@5 0.9141 (0.9059)\n",
      "\u001b[32m[2020-07-11 22:58:36] __main__ INFO: \u001b[0mElapsed 390.70\n",
      "\u001b[32m[2020-07-11 22:58:36] __main__ INFO: \u001b[0mVal 63\n",
      "\u001b[32m[2020-07-11 22:58:49] __main__ INFO: \u001b[0mEpoch 63 loss 0.9079 acc@1 0.6784 acc@5 0.8962\n",
      "\u001b[32m[2020-07-11 22:58:49] __main__ INFO: \u001b[0mElapsed 13.12\n",
      "\u001b[32m[2020-07-11 22:58:49] __main__ INFO: \u001b[0mTrain 64 22113\n",
      "\u001b[32m[2020-07-11 23:00:40] __main__ INFO: \u001b[0mEpoch 64 Step 100/351 lr 0.020000 loss 0.5796 (0.6026) acc@1 0.7656 (0.7747) acc@5 0.9141 (0.9027)\n",
      "\u001b[32m[2020-07-11 23:02:32] __main__ INFO: \u001b[0mEpoch 64 Step 200/351 lr 0.020000 loss 0.6274 (0.6005) acc@1 0.7422 (0.7732) acc@5 0.8750 (0.9040)\n",
      "\u001b[32m[2020-07-11 23:04:23] __main__ INFO: \u001b[0mEpoch 64 Step 300/351 lr 0.020000 loss 0.4841 (0.6028) acc@1 0.7969 (0.7732) acc@5 0.9062 (0.9057)\n",
      "\u001b[32m[2020-07-11 23:05:20] __main__ INFO: \u001b[0mEpoch 64 Step 351/351 lr 0.020000 loss 0.5076 (0.6067) acc@1 0.8047 (0.7720) acc@5 0.9453 (0.9052)\n",
      "\u001b[32m[2020-07-11 23:05:20] __main__ INFO: \u001b[0mElapsed 390.97\n",
      "\u001b[32m[2020-07-11 23:05:20] __main__ INFO: \u001b[0mVal 64\n",
      "\u001b[32m[2020-07-11 23:05:33] __main__ INFO: \u001b[0mEpoch 64 loss 0.9333 acc@1 0.6754 acc@5 0.8956\n",
      "\u001b[32m[2020-07-11 23:05:33] __main__ INFO: \u001b[0mElapsed 13.09\n",
      "\u001b[32m[2020-07-11 23:05:33] __main__ INFO: \u001b[0mTrain 65 22464\n",
      "\u001b[32m[2020-07-11 23:07:25] __main__ INFO: \u001b[0mEpoch 65 Step 100/351 lr 0.020000 loss 0.6748 (0.5818) acc@1 0.7578 (0.7816) acc@5 0.9141 (0.9047)\n",
      "\u001b[32m[2020-07-11 23:09:16] __main__ INFO: \u001b[0mEpoch 65 Step 200/351 lr 0.020000 loss 0.6420 (0.5858) acc@1 0.7500 (0.7793) acc@5 0.8750 (0.9051)\n",
      "\u001b[32m[2020-07-11 23:11:08] __main__ INFO: \u001b[0mEpoch 65 Step 300/351 lr 0.020000 loss 0.6108 (0.5886) acc@1 0.7812 (0.7780) acc@5 0.9375 (0.9065)\n",
      "\u001b[32m[2020-07-11 23:12:04] __main__ INFO: \u001b[0mEpoch 65 Step 351/351 lr 0.020000 loss 0.6015 (0.5925) acc@1 0.7656 (0.7762) acc@5 0.8906 (0.9056)\n",
      "\u001b[32m[2020-07-11 23:12:04] __main__ INFO: \u001b[0mElapsed 391.22\n",
      "\u001b[32m[2020-07-11 23:12:04] __main__ INFO: \u001b[0mVal 65\n",
      "\u001b[32m[2020-07-11 23:12:18] __main__ INFO: \u001b[0mEpoch 65 loss 0.9624 acc@1 0.6744 acc@5 0.8898\n",
      "\u001b[32m[2020-07-11 23:12:18] __main__ INFO: \u001b[0mElapsed 13.11\n",
      "\u001b[32m[2020-07-11 23:12:18] __main__ INFO: \u001b[0mTrain 66 22815\n",
      "\u001b[32m[2020-07-11 23:14:09] __main__ INFO: \u001b[0mEpoch 66 Step 100/351 lr 0.020000 loss 0.5848 (0.5609) acc@1 0.7812 (0.7859) acc@5 0.9141 (0.9127)\n",
      "\u001b[32m[2020-07-11 23:16:00] __main__ INFO: \u001b[0mEpoch 66 Step 200/351 lr 0.020000 loss 0.5553 (0.5869) acc@1 0.8125 (0.7759) acc@5 0.9219 (0.9057)\n",
      "\u001b[32m[2020-07-11 23:17:52] __main__ INFO: \u001b[0mEpoch 66 Step 300/351 lr 0.020000 loss 0.6669 (0.5926) acc@1 0.7578 (0.7747) acc@5 0.8672 (0.9069)\n",
      "\u001b[32m[2020-07-11 23:18:49] __main__ INFO: \u001b[0mEpoch 66 Step 351/351 lr 0.020000 loss 0.4655 (0.5939) acc@1 0.8281 (0.7739) acc@5 0.8984 (0.9064)\n",
      "\u001b[32m[2020-07-11 23:18:49] __main__ INFO: \u001b[0mElapsed 391.09\n",
      "\u001b[32m[2020-07-11 23:18:49] __main__ INFO: \u001b[0mVal 66\n",
      "\u001b[32m[2020-07-11 23:19:02] __main__ INFO: \u001b[0mEpoch 66 loss 0.9605 acc@1 0.6692 acc@5 0.8922\n",
      "\u001b[32m[2020-07-11 23:19:02] __main__ INFO: \u001b[0mElapsed 13.08\n",
      "\u001b[32m[2020-07-11 23:19:02] __main__ INFO: \u001b[0mTrain 67 23166\n",
      "\u001b[32m[2020-07-11 23:20:53] __main__ INFO: \u001b[0mEpoch 67 Step 100/351 lr 0.020000 loss 0.5496 (0.5627) acc@1 0.8047 (0.7895) acc@5 0.8906 (0.9046)\n",
      "\u001b[32m[2020-07-11 23:22:45] __main__ INFO: \u001b[0mEpoch 67 Step 200/351 lr 0.020000 loss 0.3832 (0.5752) acc@1 0.8359 (0.7836) acc@5 0.9219 (0.9050)\n",
      "\u001b[32m[2020-07-11 23:24:36] __main__ INFO: \u001b[0mEpoch 67 Step 300/351 lr 0.020000 loss 0.6484 (0.5796) acc@1 0.7344 (0.7812) acc@5 0.9062 (0.9055)\n",
      "\u001b[32m[2020-07-11 23:25:33] __main__ INFO: \u001b[0mEpoch 67 Step 351/351 lr 0.020000 loss 0.4999 (0.5822) acc@1 0.7734 (0.7806) acc@5 0.9141 (0.9060)\n",
      "\u001b[32m[2020-07-11 23:25:33] __main__ INFO: \u001b[0mElapsed 391.19\n",
      "\u001b[32m[2020-07-11 23:25:33] __main__ INFO: \u001b[0mVal 67\n",
      "\u001b[32m[2020-07-11 23:25:46] __main__ INFO: \u001b[0mEpoch 67 loss 0.9389 acc@1 0.6804 acc@5 0.8922\n",
      "\u001b[32m[2020-07-11 23:25:46] __main__ INFO: \u001b[0mElapsed 13.10\n",
      "\u001b[32m[2020-07-11 23:25:46] __main__ INFO: \u001b[0mTrain 68 23517\n",
      "\u001b[32m[2020-07-11 23:27:37] __main__ INFO: \u001b[0mEpoch 68 Step 100/351 lr 0.020000 loss 0.7633 (0.5887) acc@1 0.7266 (0.7793) acc@5 0.8984 (0.9063)\n",
      "\u001b[32m[2020-07-11 23:29:29] __main__ INFO: \u001b[0mEpoch 68 Step 200/351 lr 0.020000 loss 0.5541 (0.5784) acc@1 0.8125 (0.7814) acc@5 0.9141 (0.9072)\n",
      "\u001b[32m[2020-07-11 23:31:20] __main__ INFO: \u001b[0mEpoch 68 Step 300/351 lr 0.020000 loss 0.4495 (0.5794) acc@1 0.8359 (0.7806) acc@5 0.9297 (0.9065)\n",
      "\u001b[32m[2020-07-11 23:32:17] __main__ INFO: \u001b[0mEpoch 68 Step 351/351 lr 0.020000 loss 0.7284 (0.5808) acc@1 0.7344 (0.7798) acc@5 0.8984 (0.9067)\n",
      "\u001b[32m[2020-07-11 23:32:17] __main__ INFO: \u001b[0mElapsed 391.13\n",
      "\u001b[32m[2020-07-11 23:32:17] __main__ INFO: \u001b[0mVal 68\n",
      "\u001b[32m[2020-07-11 23:32:30] __main__ INFO: \u001b[0mEpoch 68 loss 1.0124 acc@1 0.6612 acc@5 0.8928\n",
      "\u001b[32m[2020-07-11 23:32:30] __main__ INFO: \u001b[0mElapsed 13.12\n",
      "\u001b[32m[2020-07-11 23:32:30] __main__ INFO: \u001b[0mTrain 69 23868\n",
      "\u001b[32m[2020-07-11 23:34:22] __main__ INFO: \u001b[0mEpoch 69 Step 100/351 lr 0.020000 loss 0.6436 (0.5545) acc@1 0.7266 (0.7899) acc@5 0.8281 (0.9103)\n",
      "\u001b[32m[2020-07-11 23:36:13] __main__ INFO: \u001b[0mEpoch 69 Step 200/351 lr 0.020000 loss 0.6222 (0.5755) acc@1 0.7422 (0.7826) acc@5 0.9219 (0.9070)\n",
      "\u001b[32m[2020-07-11 23:38:05] __main__ INFO: \u001b[0mEpoch 69 Step 300/351 lr 0.020000 loss 0.4143 (0.5779) acc@1 0.8438 (0.7811) acc@5 0.9453 (0.9076)\n",
      "\u001b[32m[2020-07-11 23:39:01] __main__ INFO: \u001b[0mEpoch 69 Step 351/351 lr 0.020000 loss 0.7542 (0.5827) acc@1 0.6797 (0.7791) acc@5 0.8984 (0.9072)\n",
      "\u001b[32m[2020-07-11 23:39:01] __main__ INFO: \u001b[0mElapsed 391.16\n",
      "\u001b[32m[2020-07-11 23:39:01] __main__ INFO: \u001b[0mVal 69\n",
      "\u001b[32m[2020-07-11 23:39:15] __main__ INFO: \u001b[0mEpoch 69 loss 1.0948 acc@1 0.6474 acc@5 0.8864\n",
      "\u001b[32m[2020-07-11 23:39:15] __main__ INFO: \u001b[0mElapsed 13.10\n",
      "\u001b[32m[2020-07-11 23:39:15] __main__ INFO: \u001b[0mTrain 70 24219\n",
      "\u001b[32m[2020-07-11 23:41:06] __main__ INFO: \u001b[0mEpoch 70 Step 100/351 lr 0.020000 loss 0.5086 (0.5703) acc@1 0.7969 (0.7857) acc@5 0.9609 (0.9077)\n",
      "\u001b[32m[2020-07-11 23:42:57] __main__ INFO: \u001b[0mEpoch 70 Step 200/351 lr 0.020000 loss 0.5659 (0.5824) acc@1 0.7891 (0.7815) acc@5 0.9141 (0.9064)\n",
      "\u001b[32m[2020-07-11 23:44:49] __main__ INFO: \u001b[0mEpoch 70 Step 300/351 lr 0.020000 loss 0.6842 (0.5853) acc@1 0.7656 (0.7803) acc@5 0.9297 (0.9059)\n",
      "\u001b[32m[2020-07-11 23:45:46] __main__ INFO: \u001b[0mEpoch 70 Step 351/351 lr 0.020000 loss 0.5135 (0.5856) acc@1 0.7891 (0.7798) acc@5 0.8984 (0.9057)\n",
      "\u001b[32m[2020-07-11 23:45:46] __main__ INFO: \u001b[0mElapsed 391.11\n",
      "\u001b[32m[2020-07-11 23:45:46] __main__ INFO: \u001b[0mVal 70\n",
      "\u001b[32m[2020-07-11 23:45:59] __main__ INFO: \u001b[0mEpoch 70 loss 0.9984 acc@1 0.6632 acc@5 0.8922\n",
      "\u001b[32m[2020-07-11 23:45:59] __main__ INFO: \u001b[0mElapsed 13.07\n",
      "\u001b[32m[2020-07-11 23:45:59] __main__ INFO: \u001b[0mTrain 71 24570\n",
      "\u001b[32m[2020-07-11 23:47:50] __main__ INFO: \u001b[0mEpoch 71 Step 100/351 lr 0.020000 loss 0.5730 (0.5651) acc@1 0.8125 (0.7863) acc@5 0.9219 (0.9074)\n",
      "\u001b[32m[2020-07-11 23:49:42] __main__ INFO: \u001b[0mEpoch 71 Step 200/351 lr 0.020000 loss 0.6003 (0.5694) acc@1 0.7812 (0.7848) acc@5 0.9141 (0.9064)\n",
      "\u001b[32m[2020-07-11 23:51:33] __main__ INFO: \u001b[0mEpoch 71 Step 300/351 lr 0.020000 loss 0.4479 (0.5722) acc@1 0.8359 (0.7841) acc@5 0.9297 (0.9071)\n",
      "\u001b[32m[2020-07-11 23:52:30] __main__ INFO: \u001b[0mEpoch 71 Step 351/351 lr 0.020000 loss 0.5192 (0.5736) acc@1 0.7812 (0.7833) acc@5 0.9375 (0.9069)\n",
      "\u001b[32m[2020-07-11 23:52:30] __main__ INFO: \u001b[0mElapsed 391.15\n",
      "\u001b[32m[2020-07-11 23:52:30] __main__ INFO: \u001b[0mVal 71\n",
      "\u001b[32m[2020-07-11 23:52:43] __main__ INFO: \u001b[0mEpoch 71 loss 1.0574 acc@1 0.6576 acc@5 0.8894\n",
      "\u001b[32m[2020-07-11 23:52:43] __main__ INFO: \u001b[0mElapsed 13.09\n",
      "\u001b[32m[2020-07-11 23:52:43] __main__ INFO: \u001b[0mTrain 72 24921\n",
      "\u001b[32m[2020-07-11 23:54:34] __main__ INFO: \u001b[0mEpoch 72 Step 100/351 lr 0.020000 loss 0.6556 (0.5584) acc@1 0.7500 (0.7880) acc@5 0.8984 (0.9089)\n",
      "\u001b[32m[2020-07-11 23:56:26] __main__ INFO: \u001b[0mEpoch 72 Step 200/351 lr 0.020000 loss 0.5146 (0.5663) acc@1 0.8125 (0.7850) acc@5 0.9141 (0.9086)\n",
      "\u001b[32m[2020-07-11 23:58:17] __main__ INFO: \u001b[0mEpoch 72 Step 300/351 lr 0.020000 loss 0.6744 (0.5778) acc@1 0.7266 (0.7807) acc@5 0.8984 (0.9077)\n",
      "\u001b[32m[2020-07-11 23:59:14] __main__ INFO: \u001b[0mEpoch 72 Step 351/351 lr 0.020000 loss 0.4778 (0.5787) acc@1 0.8203 (0.7806) acc@5 0.8984 (0.9080)\n",
      "\u001b[32m[2020-07-11 23:59:14] __main__ INFO: \u001b[0mElapsed 391.17\n",
      "\u001b[32m[2020-07-11 23:59:14] __main__ INFO: \u001b[0mVal 72\n",
      "\u001b[32m[2020-07-11 23:59:27] __main__ INFO: \u001b[0mEpoch 72 loss 1.0646 acc@1 0.6554 acc@5 0.8850\n",
      "\u001b[32m[2020-07-11 23:59:27] __main__ INFO: \u001b[0mElapsed 13.08\n",
      "\u001b[32m[2020-07-11 23:59:27] __main__ INFO: \u001b[0mTrain 73 25272\n",
      "\u001b[32m[2020-07-12 00:01:19] __main__ INFO: \u001b[0mEpoch 73 Step 100/351 lr 0.020000 loss 0.5860 (0.5701) acc@1 0.7656 (0.7816) acc@5 0.8906 (0.9042)\n",
      "\u001b[32m[2020-07-12 00:03:10] __main__ INFO: \u001b[0mEpoch 73 Step 200/351 lr 0.020000 loss 0.6396 (0.5744) acc@1 0.7266 (0.7807) acc@5 0.9141 (0.9071)\n",
      "\u001b[32m[2020-07-12 00:05:01] __main__ INFO: \u001b[0mEpoch 73 Step 300/351 lr 0.020000 loss 0.5136 (0.5767) acc@1 0.7891 (0.7805) acc@5 0.8906 (0.9067)\n",
      "\u001b[32m[2020-07-12 00:05:58] __main__ INFO: \u001b[0mEpoch 73 Step 351/351 lr 0.020000 loss 0.6418 (0.5784) acc@1 0.7500 (0.7800) acc@5 0.8672 (0.9070)\n",
      "\u001b[32m[2020-07-12 00:05:58] __main__ INFO: \u001b[0mElapsed 391.01\n",
      "\u001b[32m[2020-07-12 00:05:58] __main__ INFO: \u001b[0mVal 73\n",
      "\u001b[32m[2020-07-12 00:06:11] __main__ INFO: \u001b[0mEpoch 73 loss 1.0736 acc@1 0.6558 acc@5 0.8838\n",
      "\u001b[32m[2020-07-12 00:06:11] __main__ INFO: \u001b[0mElapsed 13.09\n",
      "\u001b[32m[2020-07-12 00:06:11] __main__ INFO: \u001b[0mTrain 74 25623\n",
      "\u001b[32m[2020-07-12 00:08:03] __main__ INFO: \u001b[0mEpoch 74 Step 100/351 lr 0.020000 loss 0.5465 (0.5762) acc@1 0.7969 (0.7817) acc@5 0.9609 (0.9060)\n",
      "\u001b[32m[2020-07-12 00:09:54] __main__ INFO: \u001b[0mEpoch 74 Step 200/351 lr 0.020000 loss 0.5795 (0.5770) acc@1 0.7812 (0.7813) acc@5 0.8828 (0.9059)\n",
      "\u001b[32m[2020-07-12 00:11:46] __main__ INFO: \u001b[0mEpoch 74 Step 300/351 lr 0.020000 loss 0.5414 (0.5790) acc@1 0.8125 (0.7803) acc@5 0.9062 (0.9066)\n",
      "\u001b[32m[2020-07-12 00:12:42] __main__ INFO: \u001b[0mEpoch 74 Step 351/351 lr 0.020000 loss 0.6434 (0.5824) acc@1 0.7578 (0.7790) acc@5 0.8984 (0.9069)\n",
      "\u001b[32m[2020-07-12 00:12:42] __main__ INFO: \u001b[0mElapsed 391.04\n",
      "\u001b[32m[2020-07-12 00:12:42] __main__ INFO: \u001b[0mVal 74\n",
      "\u001b[32m[2020-07-12 00:12:55] __main__ INFO: \u001b[0mEpoch 74 loss 1.0917 acc@1 0.6472 acc@5 0.8908\n",
      "\u001b[32m[2020-07-12 00:12:55] __main__ INFO: \u001b[0mElapsed 13.10\n",
      "\u001b[32m[2020-07-12 00:12:55] __main__ INFO: \u001b[0mTrain 75 25974\n",
      "\u001b[32m[2020-07-12 00:14:47] __main__ INFO: \u001b[0mEpoch 75 Step 100/351 lr 0.020000 loss 0.5911 (0.5734) acc@1 0.7656 (0.7813) acc@5 0.8984 (0.9074)\n",
      "\u001b[32m[2020-07-12 00:16:38] __main__ INFO: \u001b[0mEpoch 75 Step 200/351 lr 0.020000 loss 0.6934 (0.5822) acc@1 0.7188 (0.7788) acc@5 0.9219 (0.9054)\n",
      "\u001b[32m[2020-07-12 00:18:30] __main__ INFO: \u001b[0mEpoch 75 Step 300/351 lr 0.020000 loss 0.5729 (0.5818) acc@1 0.7578 (0.7786) acc@5 0.8672 (0.9067)\n",
      "\u001b[32m[2020-07-12 00:19:26] __main__ INFO: \u001b[0mEpoch 75 Step 351/351 lr 0.020000 loss 0.6076 (0.5835) acc@1 0.7578 (0.7778) acc@5 0.8828 (0.9066)\n",
      "\u001b[32m[2020-07-12 00:19:27] __main__ INFO: \u001b[0mElapsed 391.07\n",
      "\u001b[32m[2020-07-12 00:19:27] __main__ INFO: \u001b[0mVal 75\n",
      "\u001b[32m[2020-07-12 00:19:40] __main__ INFO: \u001b[0mEpoch 75 loss 1.1029 acc@1 0.6412 acc@5 0.8898\n",
      "\u001b[32m[2020-07-12 00:19:40] __main__ INFO: \u001b[0mElapsed 13.09\n",
      "\u001b[32m[2020-07-12 00:19:40] __main__ INFO: \u001b[0mTrain 76 26325\n",
      "\u001b[32m[2020-07-12 00:21:31] __main__ INFO: \u001b[0mEpoch 76 Step 100/351 lr 0.020000 loss 0.4960 (0.5553) acc@1 0.8281 (0.7906) acc@5 0.9375 (0.9095)\n",
      "\u001b[32m[2020-07-12 00:23:22] __main__ INFO: \u001b[0mEpoch 76 Step 200/351 lr 0.020000 loss 0.5398 (0.5619) acc@1 0.8125 (0.7870) acc@5 0.9297 (0.9082)\n",
      "\u001b[32m[2020-07-12 00:25:14] __main__ INFO: \u001b[0mEpoch 76 Step 300/351 lr 0.020000 loss 0.7710 (0.5716) acc@1 0.7109 (0.7828) acc@5 0.8906 (0.9061)\n",
      "\u001b[32m[2020-07-12 00:26:11] __main__ INFO: \u001b[0mEpoch 76 Step 351/351 lr 0.020000 loss 0.7443 (0.5746) acc@1 0.7031 (0.7824) acc@5 0.8438 (0.9068)\n",
      "\u001b[32m[2020-07-12 00:26:11] __main__ INFO: \u001b[0mElapsed 391.02\n",
      "\u001b[32m[2020-07-12 00:26:11] __main__ INFO: \u001b[0mVal 76\n",
      "\u001b[32m[2020-07-12 00:26:24] __main__ INFO: \u001b[0mEpoch 76 loss 1.1350 acc@1 0.6416 acc@5 0.8870\n",
      "\u001b[32m[2020-07-12 00:26:24] __main__ INFO: \u001b[0mElapsed 13.08\n",
      "\u001b[32m[2020-07-12 00:26:24] __main__ INFO: \u001b[0mTrain 77 26676\n",
      "\u001b[32m[2020-07-12 00:28:15] __main__ INFO: \u001b[0mEpoch 77 Step 100/351 lr 0.020000 loss 0.5628 (0.5518) acc@1 0.7734 (0.7920) acc@5 0.9375 (0.9106)\n",
      "\u001b[32m[2020-07-12 00:30:06] __main__ INFO: \u001b[0mEpoch 77 Step 200/351 lr 0.020000 loss 0.4872 (0.5701) acc@1 0.7891 (0.7832) acc@5 0.9219 (0.9074)\n",
      "\u001b[32m[2020-07-12 00:31:58] __main__ INFO: \u001b[0mEpoch 77 Step 300/351 lr 0.020000 loss 0.5763 (0.5766) acc@1 0.7969 (0.7817) acc@5 0.9297 (0.9067)\n",
      "\u001b[32m[2020-07-12 00:32:54] __main__ INFO: \u001b[0mEpoch 77 Step 351/351 lr 0.020000 loss 0.6431 (0.5776) acc@1 0.7734 (0.7815) acc@5 0.8828 (0.9066)\n",
      "\u001b[32m[2020-07-12 00:32:54] __main__ INFO: \u001b[0mElapsed 390.63\n",
      "\u001b[32m[2020-07-12 00:32:54] __main__ INFO: \u001b[0mVal 77\n",
      "\u001b[32m[2020-07-12 00:33:07] __main__ INFO: \u001b[0mEpoch 77 loss 1.0668 acc@1 0.6584 acc@5 0.8850\n",
      "\u001b[32m[2020-07-12 00:33:07] __main__ INFO: \u001b[0mElapsed 13.09\n",
      "\u001b[32m[2020-07-12 00:33:07] __main__ INFO: \u001b[0mTrain 78 27027\n",
      "\u001b[32m[2020-07-12 00:34:59] __main__ INFO: \u001b[0mEpoch 78 Step 100/351 lr 0.020000 loss 0.4257 (0.5494) acc@1 0.8438 (0.7913) acc@5 0.9141 (0.9102)\n",
      "\u001b[32m[2020-07-12 00:36:50] __main__ INFO: \u001b[0mEpoch 78 Step 200/351 lr 0.020000 loss 0.6740 (0.5602) acc@1 0.7500 (0.7877) acc@5 0.8750 (0.9075)\n",
      "\u001b[32m[2020-07-12 00:38:41] __main__ INFO: \u001b[0mEpoch 78 Step 300/351 lr 0.020000 loss 0.6441 (0.5702) acc@1 0.7266 (0.7831) acc@5 0.8906 (0.9063)\n",
      "\u001b[32m[2020-07-12 00:39:38] __main__ INFO: \u001b[0mEpoch 78 Step 351/351 lr 0.020000 loss 0.5031 (0.5756) acc@1 0.8125 (0.7818) acc@5 0.9297 (0.9065)\n",
      "\u001b[32m[2020-07-12 00:39:38] __main__ INFO: \u001b[0mElapsed 390.61\n",
      "\u001b[32m[2020-07-12 00:39:38] __main__ INFO: \u001b[0mVal 78\n",
      "\u001b[32m[2020-07-12 00:39:51] __main__ INFO: \u001b[0mEpoch 78 loss 1.0306 acc@1 0.6548 acc@5 0.8892\n",
      "\u001b[32m[2020-07-12 00:39:51] __main__ INFO: \u001b[0mElapsed 13.07\n",
      "\u001b[32m[2020-07-12 00:39:51] __main__ INFO: \u001b[0mTrain 79 27378\n",
      "\u001b[32m[2020-07-12 00:41:42] __main__ INFO: \u001b[0mEpoch 79 Step 100/351 lr 0.020000 loss 0.4765 (0.5581) acc@1 0.8281 (0.7872) acc@5 0.9375 (0.9080)\n",
      "\u001b[32m[2020-07-12 00:43:34] __main__ INFO: \u001b[0mEpoch 79 Step 200/351 lr 0.020000 loss 0.7362 (0.5642) acc@1 0.6953 (0.7850) acc@5 0.8438 (0.9099)\n",
      "\u001b[32m[2020-07-12 00:45:25] __main__ INFO: \u001b[0mEpoch 79 Step 300/351 lr 0.020000 loss 0.6904 (0.5706) acc@1 0.7422 (0.7828) acc@5 0.8906 (0.9074)\n",
      "\u001b[32m[2020-07-12 00:46:22] __main__ INFO: \u001b[0mEpoch 79 Step 351/351 lr 0.020000 loss 0.6167 (0.5692) acc@1 0.7422 (0.7832) acc@5 0.8984 (0.9081)\n",
      "\u001b[32m[2020-07-12 00:46:22] __main__ INFO: \u001b[0mElapsed 390.53\n",
      "\u001b[32m[2020-07-12 00:46:22] __main__ INFO: \u001b[0mVal 79\n",
      "\u001b[32m[2020-07-12 00:46:35] __main__ INFO: \u001b[0mEpoch 79 loss 1.0500 acc@1 0.6562 acc@5 0.8916\n",
      "\u001b[32m[2020-07-12 00:46:35] __main__ INFO: \u001b[0mElapsed 13.10\n",
      "\u001b[32m[2020-07-12 00:46:35] __main__ INFO: \u001b[0mTrain 80 27729\n",
      "\u001b[32m[2020-07-12 00:48:26] __main__ INFO: \u001b[0mEpoch 80 Step 100/351 lr 0.020000 loss 0.4536 (0.5784) acc@1 0.8281 (0.7784) acc@5 0.9141 (0.9042)\n",
      "\u001b[32m[2020-07-12 00:50:18] __main__ INFO: \u001b[0mEpoch 80 Step 200/351 lr 0.020000 loss 0.4969 (0.5769) acc@1 0.8203 (0.7811) acc@5 0.9531 (0.9050)\n",
      "\u001b[32m[2020-07-12 00:52:09] __main__ INFO: \u001b[0mEpoch 80 Step 300/351 lr 0.020000 loss 0.7103 (0.5742) acc@1 0.6953 (0.7818) acc@5 0.9141 (0.9062)\n",
      "\u001b[32m[2020-07-12 00:53:06] __main__ INFO: \u001b[0mEpoch 80 Step 351/351 lr 0.020000 loss 0.6613 (0.5765) acc@1 0.7656 (0.7808) acc@5 0.8984 (0.9060)\n",
      "\u001b[32m[2020-07-12 00:53:06] __main__ INFO: \u001b[0mElapsed 391.05\n",
      "\u001b[32m[2020-07-12 00:53:06] __main__ INFO: \u001b[0mVal 80\n",
      "\u001b[32m[2020-07-12 00:53:19] __main__ INFO: \u001b[0mEpoch 80 loss 1.0925 acc@1 0.6578 acc@5 0.8830\n",
      "\u001b[32m[2020-07-12 00:53:19] __main__ INFO: \u001b[0mElapsed 13.08\n",
      "\u001b[32m[2020-07-12 00:53:19] __main__ INFO: \u001b[0mTrain 81 28080\n",
      "\u001b[32m[2020-07-12 00:55:10] __main__ INFO: \u001b[0mEpoch 81 Step 100/351 lr 0.020000 loss 0.5523 (0.5572) acc@1 0.8047 (0.7900) acc@5 0.9375 (0.9123)\n",
      "\u001b[32m[2020-07-12 00:57:02] __main__ INFO: \u001b[0mEpoch 81 Step 200/351 lr 0.020000 loss 0.6075 (0.5682) acc@1 0.7656 (0.7853) acc@5 0.8750 (0.9101)\n",
      "\u001b[32m[2020-07-12 00:58:53] __main__ INFO: \u001b[0mEpoch 81 Step 300/351 lr 0.020000 loss 0.6246 (0.5744) acc@1 0.7578 (0.7833) acc@5 0.9219 (0.9087)\n",
      "\u001b[32m[2020-07-12 00:59:50] __main__ INFO: \u001b[0mEpoch 81 Step 351/351 lr 0.020000 loss 0.5569 (0.5773) acc@1 0.7812 (0.7821) acc@5 0.8984 (0.9089)\n",
      "\u001b[32m[2020-07-12 00:59:50] __main__ INFO: \u001b[0mElapsed 390.74\n",
      "\u001b[32m[2020-07-12 00:59:50] __main__ INFO: \u001b[0mVal 81\n",
      "\u001b[32m[2020-07-12 01:00:03] __main__ INFO: \u001b[0mEpoch 81 loss 1.1838 acc@1 0.6306 acc@5 0.8886\n",
      "\u001b[32m[2020-07-12 01:00:03] __main__ INFO: \u001b[0mElapsed 13.07\n",
      "\u001b[32m[2020-07-12 01:00:03] __main__ INFO: \u001b[0mTrain 82 28431\n",
      "\u001b[32m[2020-07-12 01:01:54] __main__ INFO: \u001b[0mEpoch 82 Step 100/351 lr 0.020000 loss 0.5863 (0.5599) acc@1 0.7812 (0.7909) acc@5 0.8906 (0.9062)\n",
      "\u001b[32m[2020-07-12 01:03:45] __main__ INFO: \u001b[0mEpoch 82 Step 200/351 lr 0.020000 loss 0.5624 (0.5606) acc@1 0.8047 (0.7898) acc@5 0.8672 (0.9067)\n",
      "\u001b[32m[2020-07-12 01:05:37] __main__ INFO: \u001b[0mEpoch 82 Step 300/351 lr 0.020000 loss 0.6725 (0.5695) acc@1 0.7656 (0.7850) acc@5 0.8516 (0.9061)\n",
      "\u001b[32m[2020-07-12 01:06:33] __main__ INFO: \u001b[0mEpoch 82 Step 351/351 lr 0.020000 loss 0.5717 (0.5733) acc@1 0.7812 (0.7829) acc@5 0.9141 (0.9060)\n",
      "\u001b[32m[2020-07-12 01:06:33] __main__ INFO: \u001b[0mElapsed 390.65\n",
      "\u001b[32m[2020-07-12 01:06:33] __main__ INFO: \u001b[0mVal 82\n",
      "\u001b[32m[2020-07-12 01:06:46] __main__ INFO: \u001b[0mEpoch 82 loss 1.1107 acc@1 0.6408 acc@5 0.8900\n",
      "\u001b[32m[2020-07-12 01:06:46] __main__ INFO: \u001b[0mElapsed 13.06\n",
      "\u001b[32m[2020-07-12 01:06:46] __main__ INFO: \u001b[0mTrain 83 28782\n",
      "\u001b[32m[2020-07-12 01:08:38] __main__ INFO: \u001b[0mEpoch 83 Step 100/351 lr 0.020000 loss 0.5354 (0.5560) acc@1 0.8125 (0.7897) acc@5 0.9219 (0.9036)\n",
      "\u001b[32m[2020-07-12 01:10:29] __main__ INFO: \u001b[0mEpoch 83 Step 200/351 lr 0.020000 loss 0.6994 (0.5661) acc@1 0.7188 (0.7852) acc@5 0.9297 (0.9057)\n",
      "\u001b[32m[2020-07-12 01:12:20] __main__ INFO: \u001b[0mEpoch 83 Step 300/351 lr 0.020000 loss 0.5131 (0.5699) acc@1 0.7734 (0.7851) acc@5 0.9062 (0.9050)\n",
      "\u001b[32m[2020-07-12 01:13:17] __main__ INFO: \u001b[0mEpoch 83 Step 351/351 lr 0.020000 loss 0.3817 (0.5700) acc@1 0.8438 (0.7844) acc@5 0.9531 (0.9061)\n",
      "\u001b[32m[2020-07-12 01:13:17] __main__ INFO: \u001b[0mElapsed 390.52\n",
      "\u001b[32m[2020-07-12 01:13:17] __main__ INFO: \u001b[0mVal 83\n",
      "\u001b[32m[2020-07-12 01:13:30] __main__ INFO: \u001b[0mEpoch 83 loss 1.0921 acc@1 0.6636 acc@5 0.8898\n",
      "\u001b[32m[2020-07-12 01:13:30] __main__ INFO: \u001b[0mElapsed 13.10\n",
      "\u001b[32m[2020-07-12 01:13:30] __main__ INFO: \u001b[0mTrain 84 29133\n",
      "\u001b[32m[2020-07-12 01:15:21] __main__ INFO: \u001b[0mEpoch 84 Step 100/351 lr 0.020000 loss 0.5215 (0.5762) acc@1 0.7891 (0.7817) acc@5 0.9062 (0.9052)\n",
      "\u001b[32m[2020-07-12 01:17:13] __main__ INFO: \u001b[0mEpoch 84 Step 200/351 lr 0.020000 loss 0.4690 (0.5704) acc@1 0.8203 (0.7846) acc@5 0.9297 (0.9075)\n",
      "\u001b[32m[2020-07-12 01:19:04] __main__ INFO: \u001b[0mEpoch 84 Step 300/351 lr 0.020000 loss 0.5161 (0.5711) acc@1 0.7812 (0.7845) acc@5 0.9219 (0.9076)\n",
      "\u001b[32m[2020-07-12 01:20:01] __main__ INFO: \u001b[0mEpoch 84 Step 351/351 lr 0.020000 loss 0.4599 (0.5734) acc@1 0.8281 (0.7839) acc@5 0.9531 (0.9073)\n",
      "\u001b[32m[2020-07-12 01:20:01] __main__ INFO: \u001b[0mElapsed 390.93\n",
      "\u001b[32m[2020-07-12 01:20:01] __main__ INFO: \u001b[0mVal 84\n",
      "\u001b[32m[2020-07-12 01:20:14] __main__ INFO: \u001b[0mEpoch 84 loss 1.0891 acc@1 0.6492 acc@5 0.8882\n",
      "\u001b[32m[2020-07-12 01:20:14] __main__ INFO: \u001b[0mElapsed 13.10\n",
      "\u001b[32m[2020-07-12 01:20:14] __main__ INFO: \u001b[0mTrain 85 29484\n",
      "\u001b[32m[2020-07-12 01:22:05] __main__ INFO: \u001b[0mEpoch 85 Step 100/351 lr 0.020000 loss 0.5481 (0.5369) acc@1 0.7891 (0.7963) acc@5 0.9141 (0.9068)\n",
      "\u001b[32m[2020-07-12 01:23:57] __main__ INFO: \u001b[0mEpoch 85 Step 200/351 lr 0.020000 loss 0.4270 (0.5487) acc@1 0.8281 (0.7917) acc@5 0.9141 (0.9069)\n",
      "\u001b[32m[2020-07-12 01:25:48] __main__ INFO: \u001b[0mEpoch 85 Step 300/351 lr 0.020000 loss 0.5085 (0.5551) acc@1 0.8047 (0.7898) acc@5 0.9062 (0.9066)\n",
      "\u001b[32m[2020-07-12 01:26:45] __main__ INFO: \u001b[0mEpoch 85 Step 351/351 lr 0.020000 loss 0.5305 (0.5604) acc@1 0.7969 (0.7876) acc@5 0.9141 (0.9058)\n",
      "\u001b[32m[2020-07-12 01:26:45] __main__ INFO: \u001b[0mElapsed 390.55\n",
      "\u001b[32m[2020-07-12 01:26:45] __main__ INFO: \u001b[0mVal 85\n",
      "\u001b[32m[2020-07-12 01:26:58] __main__ INFO: \u001b[0mEpoch 85 loss 1.0631 acc@1 0.6478 acc@5 0.8814\n",
      "\u001b[32m[2020-07-12 01:26:58] __main__ INFO: \u001b[0mElapsed 13.07\n",
      "\u001b[32m[2020-07-12 01:26:58] __main__ INFO: \u001b[0mTrain 86 29835\n",
      "\u001b[32m[2020-07-12 01:28:49] __main__ INFO: \u001b[0mEpoch 86 Step 100/351 lr 0.020000 loss 0.6220 (0.5510) acc@1 0.7734 (0.7914) acc@5 0.8984 (0.9058)\n",
      "\u001b[32m[2020-07-12 01:30:40] __main__ INFO: \u001b[0mEpoch 86 Step 200/351 lr 0.020000 loss 0.6683 (0.5580) acc@1 0.7422 (0.7903) acc@5 0.9062 (0.9086)\n",
      "\u001b[32m[2020-07-12 01:32:31] __main__ INFO: \u001b[0mEpoch 86 Step 300/351 lr 0.020000 loss 0.4954 (0.5649) acc@1 0.8125 (0.7872) acc@5 0.8984 (0.9086)\n",
      "\u001b[32m[2020-07-12 01:33:28] __main__ INFO: \u001b[0mEpoch 86 Step 351/351 lr 0.020000 loss 0.5495 (0.5696) acc@1 0.8203 (0.7856) acc@5 0.9297 (0.9078)\n",
      "\u001b[32m[2020-07-12 01:33:28] __main__ INFO: \u001b[0mElapsed 390.51\n",
      "\u001b[32m[2020-07-12 01:33:28] __main__ INFO: \u001b[0mVal 86\n",
      "\u001b[32m[2020-07-12 01:33:41] __main__ INFO: \u001b[0mEpoch 86 loss 1.1785 acc@1 0.6370 acc@5 0.8872\n",
      "\u001b[32m[2020-07-12 01:33:41] __main__ INFO: \u001b[0mElapsed 13.09\n",
      "\u001b[32m[2020-07-12 01:33:41] __main__ INFO: \u001b[0mTrain 87 30186\n",
      "\u001b[32m[2020-07-12 01:35:33] __main__ INFO: \u001b[0mEpoch 87 Step 100/351 lr 0.020000 loss 0.5723 (0.5620) acc@1 0.7812 (0.7864) acc@5 0.9219 (0.9054)\n",
      "\u001b[32m[2020-07-12 01:37:24] __main__ INFO: \u001b[0mEpoch 87 Step 200/351 lr 0.020000 loss 0.4787 (0.5615) acc@1 0.8438 (0.7876) acc@5 0.9375 (0.9070)\n",
      "\u001b[32m[2020-07-12 01:39:15] __main__ INFO: \u001b[0mEpoch 87 Step 300/351 lr 0.020000 loss 0.4248 (0.5616) acc@1 0.8516 (0.7881) acc@5 0.9219 (0.9080)\n",
      "\u001b[32m[2020-07-12 01:40:12] __main__ INFO: \u001b[0mEpoch 87 Step 351/351 lr 0.020000 loss 0.5003 (0.5650) acc@1 0.8125 (0.7864) acc@5 0.9141 (0.9072)\n",
      "\u001b[32m[2020-07-12 01:40:12] __main__ INFO: \u001b[0mElapsed 390.61\n",
      "\u001b[32m[2020-07-12 01:40:12] __main__ INFO: \u001b[0mVal 87\n",
      "\u001b[32m[2020-07-12 01:40:25] __main__ INFO: \u001b[0mEpoch 87 loss 1.1030 acc@1 0.6518 acc@5 0.8888\n",
      "\u001b[32m[2020-07-12 01:40:25] __main__ INFO: \u001b[0mElapsed 13.08\n",
      "\u001b[32m[2020-07-12 01:40:25] __main__ INFO: \u001b[0mTrain 88 30537\n",
      "\u001b[32m[2020-07-12 01:42:16] __main__ INFO: \u001b[0mEpoch 88 Step 100/351 lr 0.020000 loss 0.4318 (0.5498) acc@1 0.8672 (0.7932) acc@5 0.9297 (0.9087)\n",
      "\u001b[32m[2020-07-12 01:44:08] __main__ INFO: \u001b[0mEpoch 88 Step 200/351 lr 0.020000 loss 0.5519 (0.5569) acc@1 0.7969 (0.7890) acc@5 0.9297 (0.9071)\n",
      "\u001b[32m[2020-07-12 01:45:59] __main__ INFO: \u001b[0mEpoch 88 Step 300/351 lr 0.020000 loss 0.7386 (0.5658) acc@1 0.7031 (0.7854) acc@5 0.8828 (0.9072)\n",
      "\u001b[32m[2020-07-12 01:46:55] __main__ INFO: \u001b[0mEpoch 88 Step 351/351 lr 0.020000 loss 0.6396 (0.5679) acc@1 0.7812 (0.7849) acc@5 0.9297 (0.9070)\n",
      "\u001b[32m[2020-07-12 01:46:55] __main__ INFO: \u001b[0mElapsed 390.53\n",
      "\u001b[32m[2020-07-12 01:46:55] __main__ INFO: \u001b[0mVal 88\n",
      "\u001b[32m[2020-07-12 01:47:09] __main__ INFO: \u001b[0mEpoch 88 loss 1.0990 acc@1 0.6452 acc@5 0.8958\n",
      "\u001b[32m[2020-07-12 01:47:09] __main__ INFO: \u001b[0mElapsed 13.09\n",
      "\u001b[32m[2020-07-12 01:47:09] __main__ INFO: \u001b[0mTrain 89 30888\n",
      "\u001b[32m[2020-07-12 01:49:00] __main__ INFO: \u001b[0mEpoch 89 Step 100/351 lr 0.020000 loss 0.6223 (0.5488) acc@1 0.8125 (0.7934) acc@5 0.9453 (0.9080)\n",
      "\u001b[32m[2020-07-12 01:50:51] __main__ INFO: \u001b[0mEpoch 89 Step 200/351 lr 0.020000 loss 0.6752 (0.5476) acc@1 0.7188 (0.7927) acc@5 0.8828 (0.9087)\n",
      "\u001b[32m[2020-07-12 01:52:42] __main__ INFO: \u001b[0mEpoch 89 Step 300/351 lr 0.020000 loss 0.5580 (0.5572) acc@1 0.7500 (0.7884) acc@5 0.9297 (0.9070)\n",
      "\u001b[32m[2020-07-12 01:53:39] __main__ INFO: \u001b[0mEpoch 89 Step 351/351 lr 0.020000 loss 0.5261 (0.5628) acc@1 0.8359 (0.7859) acc@5 0.9297 (0.9073)\n",
      "\u001b[32m[2020-07-12 01:53:39] __main__ INFO: \u001b[0mElapsed 390.49\n",
      "\u001b[32m[2020-07-12 01:53:39] __main__ INFO: \u001b[0mVal 89\n",
      "\u001b[32m[2020-07-12 01:53:52] __main__ INFO: \u001b[0mEpoch 89 loss 1.1296 acc@1 0.6384 acc@5 0.8900\n",
      "\u001b[32m[2020-07-12 01:53:52] __main__ INFO: \u001b[0mElapsed 13.07\n",
      "\u001b[32m[2020-07-12 01:53:52] __main__ INFO: \u001b[0mTrain 90 31239\n",
      "\u001b[32m[2020-07-12 01:55:43] __main__ INFO: \u001b[0mEpoch 90 Step 100/351 lr 0.020000 loss 0.5478 (0.5617) acc@1 0.7812 (0.7866) acc@5 0.9219 (0.9070)\n",
      "\u001b[32m[2020-07-12 01:57:35] __main__ INFO: \u001b[0mEpoch 90 Step 200/351 lr 0.020000 loss 0.5542 (0.5632) acc@1 0.7812 (0.7875) acc@5 0.9062 (0.9082)\n",
      "\u001b[32m[2020-07-12 01:59:26] __main__ INFO: \u001b[0mEpoch 90 Step 300/351 lr 0.020000 loss 0.5240 (0.5705) acc@1 0.8047 (0.7841) acc@5 0.9297 (0.9069)\n",
      "\u001b[32m[2020-07-12 02:00:23] __main__ INFO: \u001b[0mEpoch 90 Step 351/351 lr 0.020000 loss 0.5320 (0.5721) acc@1 0.8125 (0.7835) acc@5 0.9219 (0.9064)\n",
      "\u001b[32m[2020-07-12 02:00:23] __main__ INFO: \u001b[0mElapsed 390.50\n",
      "\u001b[32m[2020-07-12 02:00:23] __main__ INFO: \u001b[0mVal 90\n",
      "\u001b[32m[2020-07-12 02:00:36] __main__ INFO: \u001b[0mEpoch 90 loss 1.0800 acc@1 0.6628 acc@5 0.8888\n",
      "\u001b[32m[2020-07-12 02:00:36] __main__ INFO: \u001b[0mElapsed 13.09\n",
      "\u001b[32m[2020-07-12 02:00:36] __main__ INFO: \u001b[0mTrain 91 31590\n",
      "\u001b[32m[2020-07-12 02:02:27] __main__ INFO: \u001b[0mEpoch 91 Step 100/351 lr 0.020000 loss 0.6572 (0.5385) acc@1 0.7500 (0.7937) acc@5 0.8750 (0.9074)\n",
      "\u001b[32m[2020-07-12 02:04:18] __main__ INFO: \u001b[0mEpoch 91 Step 200/351 lr 0.020000 loss 0.6051 (0.5560) acc@1 0.7812 (0.7880) acc@5 0.8984 (0.9058)\n",
      "\u001b[32m[2020-07-12 02:06:09] __main__ INFO: \u001b[0mEpoch 91 Step 300/351 lr 0.020000 loss 0.5865 (0.5529) acc@1 0.7734 (0.7901) acc@5 0.9062 (0.9069)\n",
      "\u001b[32m[2020-07-12 02:07:06] __main__ INFO: \u001b[0mEpoch 91 Step 351/351 lr 0.020000 loss 0.5496 (0.5567) acc@1 0.8125 (0.7891) acc@5 0.9375 (0.9073)\n",
      "\u001b[32m[2020-07-12 02:07:06] __main__ INFO: \u001b[0mElapsed 390.11\n",
      "\u001b[32m[2020-07-12 02:07:06] __main__ INFO: \u001b[0mVal 91\n",
      "\u001b[32m[2020-07-12 02:07:19] __main__ INFO: \u001b[0mEpoch 91 loss 1.2443 acc@1 0.6276 acc@5 0.8826\n",
      "\u001b[32m[2020-07-12 02:07:19] __main__ INFO: \u001b[0mElapsed 13.09\n",
      "\u001b[32m[2020-07-12 02:07:19] __main__ INFO: \u001b[0mTrain 92 31941\n",
      "\u001b[32m[2020-07-12 02:09:10] __main__ INFO: \u001b[0mEpoch 92 Step 100/351 lr 0.020000 loss 0.3334 (0.5367) acc@1 0.8672 (0.7957) acc@5 0.9375 (0.9119)\n",
      "\u001b[32m[2020-07-12 02:11:01] __main__ INFO: \u001b[0mEpoch 92 Step 200/351 lr 0.020000 loss 0.3669 (0.5501) acc@1 0.8516 (0.7920) acc@5 0.9297 (0.9091)\n",
      "\u001b[32m[2020-07-12 02:12:52] __main__ INFO: \u001b[0mEpoch 92 Step 300/351 lr 0.020000 loss 0.5016 (0.5624) acc@1 0.7812 (0.7874) acc@5 0.9062 (0.9070)\n",
      "\u001b[32m[2020-07-12 02:13:49] __main__ INFO: \u001b[0mEpoch 92 Step 351/351 lr 0.020000 loss 0.6625 (0.5617) acc@1 0.7344 (0.7881) acc@5 0.9062 (0.9079)\n",
      "\u001b[32m[2020-07-12 02:13:49] __main__ INFO: \u001b[0mElapsed 390.17\n",
      "\u001b[32m[2020-07-12 02:13:49] __main__ INFO: \u001b[0mVal 92\n",
      "\u001b[32m[2020-07-12 02:14:02] __main__ INFO: \u001b[0mEpoch 92 loss 1.1199 acc@1 0.6480 acc@5 0.8940\n",
      "\u001b[32m[2020-07-12 02:14:02] __main__ INFO: \u001b[0mElapsed 13.10\n",
      "\u001b[32m[2020-07-12 02:14:02] __main__ INFO: \u001b[0mTrain 93 32292\n",
      "\u001b[32m[2020-07-12 02:15:53] __main__ INFO: \u001b[0mEpoch 93 Step 100/351 lr 0.020000 loss 0.4809 (0.5389) acc@1 0.8125 (0.7973) acc@5 0.9141 (0.9110)\n",
      "\u001b[32m[2020-07-12 02:17:45] __main__ INFO: \u001b[0mEpoch 93 Step 200/351 lr 0.020000 loss 0.6748 (0.5481) acc@1 0.7266 (0.7912) acc@5 0.9062 (0.9079)\n",
      "\u001b[32m[2020-07-12 02:19:36] __main__ INFO: \u001b[0mEpoch 93 Step 300/351 lr 0.020000 loss 0.6764 (0.5611) acc@1 0.7578 (0.7866) acc@5 0.9375 (0.9062)\n",
      "\u001b[32m[2020-07-12 02:20:32] __main__ INFO: \u001b[0mEpoch 93 Step 351/351 lr 0.020000 loss 0.5470 (0.5632) acc@1 0.7969 (0.7866) acc@5 0.9297 (0.9068)\n",
      "\u001b[32m[2020-07-12 02:20:32] __main__ INFO: \u001b[0mElapsed 390.13\n",
      "\u001b[32m[2020-07-12 02:20:32] __main__ INFO: \u001b[0mVal 93\n",
      "\u001b[32m[2020-07-12 02:20:45] __main__ INFO: \u001b[0mEpoch 93 loss 1.0502 acc@1 0.6620 acc@5 0.8936\n",
      "\u001b[32m[2020-07-12 02:20:45] __main__ INFO: \u001b[0mElapsed 13.09\n",
      "\u001b[32m[2020-07-12 02:20:45] __main__ INFO: \u001b[0mTrain 94 32643\n",
      "\u001b[32m[2020-07-12 02:22:37] __main__ INFO: \u001b[0mEpoch 94 Step 100/351 lr 0.020000 loss 0.5819 (0.5567) acc@1 0.7812 (0.7907) acc@5 0.8828 (0.9052)\n",
      "\u001b[32m[2020-07-12 02:24:28] __main__ INFO: \u001b[0mEpoch 94 Step 200/351 lr 0.020000 loss 0.3989 (0.5583) acc@1 0.8750 (0.7902) acc@5 0.9297 (0.9061)\n",
      "\u001b[32m[2020-07-12 02:26:19] __main__ INFO: \u001b[0mEpoch 94 Step 300/351 lr 0.020000 loss 0.5884 (0.5626) acc@1 0.7812 (0.7874) acc@5 0.8906 (0.9071)\n",
      "\u001b[32m[2020-07-12 02:27:16] __main__ INFO: \u001b[0mEpoch 94 Step 351/351 lr 0.020000 loss 0.5400 (0.5646) acc@1 0.7891 (0.7862) acc@5 0.9141 (0.9071)\n",
      "\u001b[32m[2020-07-12 02:27:16] __main__ INFO: \u001b[0mElapsed 390.24\n",
      "\u001b[32m[2020-07-12 02:27:16] __main__ INFO: \u001b[0mVal 94\n",
      "\u001b[32m[2020-07-12 02:27:29] __main__ INFO: \u001b[0mEpoch 94 loss 1.1125 acc@1 0.6552 acc@5 0.8920\n",
      "\u001b[32m[2020-07-12 02:27:29] __main__ INFO: \u001b[0mElapsed 13.07\n",
      "\u001b[32m[2020-07-12 02:27:29] __main__ INFO: \u001b[0mTrain 95 32994\n",
      "\u001b[32m[2020-07-12 02:29:20] __main__ INFO: \u001b[0mEpoch 95 Step 100/351 lr 0.020000 loss 0.5353 (0.5436) acc@1 0.7891 (0.7939) acc@5 0.9375 (0.9052)\n",
      "\u001b[32m[2020-07-12 02:31:11] __main__ INFO: \u001b[0mEpoch 95 Step 200/351 lr 0.020000 loss 0.6194 (0.5528) acc@1 0.7500 (0.7907) acc@5 0.9219 (0.9062)\n",
      "\u001b[32m[2020-07-12 02:33:02] __main__ INFO: \u001b[0mEpoch 95 Step 300/351 lr 0.020000 loss 0.6598 (0.5570) acc@1 0.7422 (0.7894) acc@5 0.9219 (0.9073)\n",
      "\u001b[32m[2020-07-12 02:33:59] __main__ INFO: \u001b[0mEpoch 95 Step 351/351 lr 0.020000 loss 0.5541 (0.5594) acc@1 0.7969 (0.7883) acc@5 0.9141 (0.9072)\n",
      "\u001b[32m[2020-07-12 02:33:59] __main__ INFO: \u001b[0mElapsed 390.24\n",
      "\u001b[32m[2020-07-12 02:33:59] __main__ INFO: \u001b[0mVal 95\n",
      "\u001b[32m[2020-07-12 02:34:12] __main__ INFO: \u001b[0mEpoch 95 loss 1.0836 acc@1 0.6518 acc@5 0.8888\n",
      "\u001b[32m[2020-07-12 02:34:12] __main__ INFO: \u001b[0mElapsed 13.07\n",
      "\u001b[32m[2020-07-12 02:34:12] __main__ INFO: \u001b[0mTrain 96 33345\n",
      "\u001b[32m[2020-07-12 02:36:03] __main__ INFO: \u001b[0mEpoch 96 Step 100/351 lr 0.020000 loss 0.5894 (0.5568) acc@1 0.7734 (0.7875) acc@5 0.9141 (0.9039)\n",
      "\u001b[32m[2020-07-12 02:37:54] __main__ INFO: \u001b[0mEpoch 96 Step 200/351 lr 0.020000 loss 0.5670 (0.5496) acc@1 0.7812 (0.7920) acc@5 0.9141 (0.9075)\n",
      "\u001b[32m[2020-07-12 02:39:46] __main__ INFO: \u001b[0mEpoch 96 Step 300/351 lr 0.020000 loss 0.6318 (0.5519) acc@1 0.7656 (0.7912) acc@5 0.8750 (0.9069)\n",
      "\u001b[32m[2020-07-12 02:40:42] __main__ INFO: \u001b[0mEpoch 96 Step 351/351 lr 0.020000 loss 0.7892 (0.5522) acc@1 0.7188 (0.7913) acc@5 0.8594 (0.9077)\n",
      "\u001b[32m[2020-07-12 02:40:42] __main__ INFO: \u001b[0mElapsed 390.14\n",
      "\u001b[32m[2020-07-12 02:40:42] __main__ INFO: \u001b[0mVal 96\n",
      "\u001b[32m[2020-07-12 02:40:55] __main__ INFO: \u001b[0mEpoch 96 loss 1.1385 acc@1 0.6444 acc@5 0.8908\n",
      "\u001b[32m[2020-07-12 02:40:55] __main__ INFO: \u001b[0mElapsed 13.06\n",
      "\u001b[32m[2020-07-12 02:40:55] __main__ INFO: \u001b[0mTrain 97 33696\n",
      "\u001b[32m[2020-07-12 02:42:46] __main__ INFO: \u001b[0mEpoch 97 Step 100/351 lr 0.020000 loss 0.5188 (0.5378) acc@1 0.8281 (0.7966) acc@5 0.9141 (0.9085)\n",
      "\u001b[32m[2020-07-12 02:44:38] __main__ INFO: \u001b[0mEpoch 97 Step 200/351 lr 0.020000 loss 0.6559 (0.5522) acc@1 0.7578 (0.7898) acc@5 0.9062 (0.9044)\n",
      "\u001b[32m[2020-07-12 02:46:29] __main__ INFO: \u001b[0mEpoch 97 Step 300/351 lr 0.020000 loss 0.5251 (0.5517) acc@1 0.8047 (0.7904) acc@5 0.9141 (0.9066)\n",
      "\u001b[32m[2020-07-12 02:47:26] __main__ INFO: \u001b[0mEpoch 97 Step 351/351 lr 0.020000 loss 0.4698 (0.5578) acc@1 0.8672 (0.7884) acc@5 0.9531 (0.9064)\n",
      "\u001b[32m[2020-07-12 02:47:26] __main__ INFO: \u001b[0mElapsed 390.31\n",
      "\u001b[32m[2020-07-12 02:47:26] __main__ INFO: \u001b[0mVal 97\n",
      "\u001b[32m[2020-07-12 02:47:39] __main__ INFO: \u001b[0mEpoch 97 loss 1.0825 acc@1 0.6480 acc@5 0.8934\n",
      "\u001b[32m[2020-07-12 02:47:39] __main__ INFO: \u001b[0mElapsed 13.06\n",
      "\u001b[32m[2020-07-12 02:47:39] __main__ INFO: \u001b[0mTrain 98 34047\n",
      "\u001b[32m[2020-07-12 02:49:30] __main__ INFO: \u001b[0mEpoch 98 Step 100/351 lr 0.020000 loss 0.4071 (0.5512) acc@1 0.8438 (0.7944) acc@5 0.9219 (0.9062)\n",
      "\u001b[32m[2020-07-12 02:51:21] __main__ INFO: \u001b[0mEpoch 98 Step 200/351 lr 0.020000 loss 0.5454 (0.5536) acc@1 0.7812 (0.7920) acc@5 0.9141 (0.9075)\n",
      "\u001b[32m[2020-07-12 02:53:12] __main__ INFO: \u001b[0mEpoch 98 Step 300/351 lr 0.020000 loss 0.5611 (0.5546) acc@1 0.7891 (0.7909) acc@5 0.9219 (0.9084)\n",
      "\u001b[32m[2020-07-12 02:54:09] __main__ INFO: \u001b[0mEpoch 98 Step 351/351 lr 0.020000 loss 0.6708 (0.5561) acc@1 0.7422 (0.7906) acc@5 0.9219 (0.9089)\n",
      "\u001b[32m[2020-07-12 02:54:09] __main__ INFO: \u001b[0mElapsed 390.55\n",
      "\u001b[32m[2020-07-12 02:54:09] __main__ INFO: \u001b[0mVal 98\n",
      "\u001b[32m[2020-07-12 02:54:22] __main__ INFO: \u001b[0mEpoch 98 loss 1.1154 acc@1 0.6352 acc@5 0.8866\n",
      "\u001b[32m[2020-07-12 02:54:22] __main__ INFO: \u001b[0mElapsed 13.06\n",
      "\u001b[32m[2020-07-12 02:54:22] __main__ INFO: \u001b[0mTrain 99 34398\n",
      "\u001b[32m[2020-07-12 02:56:14] __main__ INFO: \u001b[0mEpoch 99 Step 100/351 lr 0.020000 loss 0.7317 (0.5404) acc@1 0.7500 (0.7960) acc@5 0.8828 (0.9116)\n",
      "\u001b[32m[2020-07-12 02:58:05] __main__ INFO: \u001b[0mEpoch 99 Step 200/351 lr 0.020000 loss 0.6476 (0.5470) acc@1 0.7500 (0.7932) acc@5 0.9219 (0.9121)\n",
      "\u001b[32m[2020-07-12 02:59:56] __main__ INFO: \u001b[0mEpoch 99 Step 300/351 lr 0.020000 loss 0.6087 (0.5507) acc@1 0.7656 (0.7915) acc@5 0.8984 (0.9098)\n",
      "\u001b[32m[2020-07-12 03:00:53] __main__ INFO: \u001b[0mEpoch 99 Step 351/351 lr 0.020000 loss 0.4918 (0.5546) acc@1 0.8203 (0.7900) acc@5 0.9219 (0.9091)\n",
      "\u001b[32m[2020-07-12 03:00:53] __main__ INFO: \u001b[0mElapsed 390.61\n",
      "\u001b[32m[2020-07-12 03:00:53] __main__ INFO: \u001b[0mVal 99\n",
      "\u001b[32m[2020-07-12 03:01:06] __main__ INFO: \u001b[0mEpoch 99 loss 1.0951 acc@1 0.6524 acc@5 0.8880\n",
      "\u001b[32m[2020-07-12 03:01:06] __main__ INFO: \u001b[0mElapsed 13.07\n",
      "\u001b[32m[2020-07-12 03:01:06] __main__ INFO: \u001b[0mTrain 100 34749\n",
      "\u001b[32m[2020-07-12 03:02:57] __main__ INFO: \u001b[0mEpoch 100 Step 100/351 lr 0.020000 loss 0.5386 (0.5449) acc@1 0.7969 (0.7948) acc@5 0.9297 (0.9086)\n",
      "\u001b[32m[2020-07-12 03:04:49] __main__ INFO: \u001b[0mEpoch 100 Step 200/351 lr 0.020000 loss 0.5856 (0.5451) acc@1 0.7812 (0.7934) acc@5 0.8984 (0.9076)\n",
      "\u001b[32m[2020-07-12 03:06:40] __main__ INFO: \u001b[0mEpoch 100 Step 300/351 lr 0.020000 loss 0.5800 (0.5546) acc@1 0.7656 (0.7894) acc@5 0.9141 (0.9076)\n",
      "\u001b[32m[2020-07-12 03:07:37] __main__ INFO: \u001b[0mEpoch 100 Step 351/351 lr 0.020000 loss 0.4292 (0.5548) acc@1 0.8516 (0.7891) acc@5 0.9531 (0.9075)\n",
      "\u001b[32m[2020-07-12 03:07:37] __main__ INFO: \u001b[0mElapsed 390.75\n",
      "\u001b[32m[2020-07-12 03:07:37] __main__ INFO: \u001b[0mVal 100\n",
      "\u001b[32m[2020-07-12 03:07:50] __main__ INFO: \u001b[0mEpoch 100 loss 1.0891 acc@1 0.6520 acc@5 0.8862\n",
      "\u001b[32m[2020-07-12 03:07:50] __main__ INFO: \u001b[0mElapsed 13.09\n",
      "\u001b[32m[2020-07-12 03:07:50] fvcore.common.checkpoint INFO: \u001b[0mSaving checkpoint to /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_1_20/exp00/checkpoint_00100.pth\n",
      "\u001b[32m[2020-07-12 03:07:50] __main__ INFO: \u001b[0mTrain 101 35100\n",
      "\u001b[32m[2020-07-12 03:09:42] __main__ INFO: \u001b[0mEpoch 101 Step 100/351 lr 0.020000 loss 0.5469 (0.5527) acc@1 0.7891 (0.7930) acc@5 0.8984 (0.9040)\n",
      "\u001b[32m[2020-07-12 03:11:33] __main__ INFO: \u001b[0mEpoch 101 Step 200/351 lr 0.020000 loss 0.5602 (0.5508) acc@1 0.7891 (0.7926) acc@5 0.8984 (0.9055)\n",
      "\u001b[32m[2020-07-12 03:13:24] __main__ INFO: \u001b[0mEpoch 101 Step 300/351 lr 0.020000 loss 0.5307 (0.5510) acc@1 0.7891 (0.7928) acc@5 0.8906 (0.9058)\n",
      "\u001b[32m[2020-07-12 03:14:21] __main__ INFO: \u001b[0mEpoch 101 Step 351/351 lr 0.020000 loss 0.6245 (0.5498) acc@1 0.7734 (0.7930) acc@5 0.8594 (0.9063)\n",
      "\u001b[32m[2020-07-12 03:14:21] __main__ INFO: \u001b[0mElapsed 390.80\n",
      "\u001b[32m[2020-07-12 03:14:21] __main__ INFO: \u001b[0mVal 101\n",
      "\u001b[32m[2020-07-12 03:14:34] __main__ INFO: \u001b[0mEpoch 101 loss 1.3018 acc@1 0.6140 acc@5 0.8842\n",
      "\u001b[32m[2020-07-12 03:14:34] __main__ INFO: \u001b[0mElapsed 13.06\n",
      "\u001b[32m[2020-07-12 03:14:34] __main__ INFO: \u001b[0mTrain 102 35451\n",
      "\u001b[32m[2020-07-12 03:16:25] __main__ INFO: \u001b[0mEpoch 102 Step 100/351 lr 0.020000 loss 0.6616 (0.5230) acc@1 0.7266 (0.8002) acc@5 0.8516 (0.9079)\n",
      "\u001b[32m[2020-07-12 03:18:16] __main__ INFO: \u001b[0mEpoch 102 Step 200/351 lr 0.020000 loss 0.5176 (0.5261) acc@1 0.7812 (0.7995) acc@5 0.9219 (0.9088)\n",
      "\u001b[32m[2020-07-12 03:20:08] __main__ INFO: \u001b[0mEpoch 102 Step 300/351 lr 0.020000 loss 0.5015 (0.5400) acc@1 0.8281 (0.7948) acc@5 0.9219 (0.9083)\n",
      "\u001b[32m[2020-07-12 03:21:04] __main__ INFO: \u001b[0mEpoch 102 Step 351/351 lr 0.020000 loss 0.6652 (0.5465) acc@1 0.7422 (0.7926) acc@5 0.8828 (0.9075)\n",
      "\u001b[32m[2020-07-12 03:21:04] __main__ INFO: \u001b[0mElapsed 390.51\n",
      "\u001b[32m[2020-07-12 03:21:04] __main__ INFO: \u001b[0mVal 102\n",
      "\u001b[32m[2020-07-12 03:21:18] __main__ INFO: \u001b[0mEpoch 102 loss 1.0738 acc@1 0.6592 acc@5 0.8904\n",
      "\u001b[32m[2020-07-12 03:21:18] __main__ INFO: \u001b[0mElapsed 13.09\n",
      "\u001b[32m[2020-07-12 03:21:18] __main__ INFO: \u001b[0mTrain 103 35802\n",
      "\u001b[32m[2020-07-12 03:23:09] __main__ INFO: \u001b[0mEpoch 103 Step 100/351 lr 0.020000 loss 0.5562 (0.5513) acc@1 0.7812 (0.7935) acc@5 0.8984 (0.9068)\n",
      "\u001b[32m[2020-07-12 03:25:00] __main__ INFO: \u001b[0mEpoch 103 Step 200/351 lr 0.020000 loss 0.6280 (0.5479) acc@1 0.7734 (0.7952) acc@5 0.9141 (0.9088)\n",
      "\u001b[32m[2020-07-12 03:26:51] __main__ INFO: \u001b[0mEpoch 103 Step 300/351 lr 0.020000 loss 0.6738 (0.5493) acc@1 0.7578 (0.7935) acc@5 0.8984 (0.9089)\n",
      "\u001b[32m[2020-07-12 03:27:48] __main__ INFO: \u001b[0mEpoch 103 Step 351/351 lr 0.020000 loss 0.5623 (0.5524) acc@1 0.7656 (0.7917) acc@5 0.8984 (0.9079)\n",
      "\u001b[32m[2020-07-12 03:27:48] __main__ INFO: \u001b[0mElapsed 390.56\n",
      "\u001b[32m[2020-07-12 03:27:48] __main__ INFO: \u001b[0mVal 103\n",
      "\u001b[32m[2020-07-12 03:28:01] __main__ INFO: \u001b[0mEpoch 103 loss 1.1007 acc@1 0.6476 acc@5 0.8898\n",
      "\u001b[32m[2020-07-12 03:28:01] __main__ INFO: \u001b[0mElapsed 13.08\n",
      "\u001b[32m[2020-07-12 03:28:01] __main__ INFO: \u001b[0mTrain 104 36153\n"
     ]
    }
   ],
   "source": [
    "# Train the model per the settings specified in the original paper, but using augmented data\n",
    "os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "!python train.py --config configs/cifar/wrn.yaml \\\n",
    "    model.wrn.depth 28 \\\n",
    "    model.wrn.widening_factor 10 \\\n",
    "    train.batch_size 128 \\\n",
    "    train.base_lr 0.1 \\\n",
    "    dataset.name CIFAR10_RA_1_20 \\\n",
    "    train.output_dir /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_1_20/exp00 \\\n",
    "    scheduler.epochs 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-13 23:06:22] __main__ INFO: \u001b[0mdevice: cuda\n",
      "cudnn:\n",
      "  benchmark: True\n",
      "  deterministic: False\n",
      "dataset:\n",
      "  name: CIFAR10\n",
      "  dataset_dir: ~/.torch/datasets/CIFAR10\n",
      "  image_size: 32\n",
      "  n_channels: 3\n",
      "  n_classes: 10\n",
      "model:\n",
      "  type: cifar\n",
      "  name: wrn\n",
      "  init_mode: kaiming_fan_in\n",
      "  vgg:\n",
      "    n_channels: [64, 128, 256, 512, 512]\n",
      "    n_layers: [2, 2, 3, 3, 3]\n",
      "    use_bn: True\n",
      "  resnet:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "  resnet_preact:\n",
      "    depth: 110\n",
      "    n_blocks: [2, 2, 2, 2]\n",
      "    block_type: basic\n",
      "    initial_channels: 16\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "  wrn:\n",
      "    depth: 28\n",
      "    initial_channels: 16\n",
      "    widening_factor: 10\n",
      "    drop_rate: 0.0\n",
      "  densenet:\n",
      "    depth: 100\n",
      "    n_blocks: [6, 12, 24, 16]\n",
      "    block_type: bottleneck\n",
      "    growth_rate: 12\n",
      "    drop_rate: 0.0\n",
      "    compression_rate: 0.5\n",
      "  pyramidnet:\n",
      "    depth: 272\n",
      "    n_blocks: [3, 24, 36, 3]\n",
      "    initial_channels: 16\n",
      "    block_type: bottleneck\n",
      "    alpha: 200\n",
      "  resnext:\n",
      "    depth: 29\n",
      "    n_blocks: [3, 4, 6, 3]\n",
      "    initial_channels: 64\n",
      "    cardinality: 8\n",
      "    base_channels: 4\n",
      "  shake_shake:\n",
      "    depth: 26\n",
      "    initial_channels: 96\n",
      "    shake_forward: True\n",
      "    shake_backward: True\n",
      "    shake_image: True\n",
      "  se_resnet_preact:\n",
      "    depth: 110\n",
      "    initial_channels: 16\n",
      "    se_reduction: 16\n",
      "    block_type: basic\n",
      "    remove_first_relu: False\n",
      "    add_last_bn: False\n",
      "    preact_stage: [True, True, True]\n",
      "train:\n",
      "  checkpoint: /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_1_20/exp00/checkpoint_00400.pth\n",
      "  resume: False\n",
      "  precision: O0\n",
      "  batch_size: 128\n",
      "  subdivision: 1\n",
      "  optimizer: sgd\n",
      "  base_lr: 0.001\n",
      "  momentum: 0.9\n",
      "  nesterov: True\n",
      "  weight_decay: 0.0005\n",
      "  no_weight_decay_on_bn: False\n",
      "  gradient_clip: 0\n",
      "  start_epoch: 0\n",
      "  seed: 0\n",
      "  val_first: True\n",
      "  val_period: 1\n",
      "  val_ratio: 0.1\n",
      "  use_test_as_val: False\n",
      "  output_dir: /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_1_20/exp00_resume400_50\n",
      "  log_period: 100\n",
      "  checkpoint_period: 100\n",
      "  use_tensorboard: True\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: True\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "  distributed: False\n",
      "  dist:\n",
      "    backend: nccl\n",
      "    init_method: env://\n",
      "    world_size: -1\n",
      "    node_rank: -1\n",
      "    local_rank: 0\n",
      "    use_sync_bn: False\n",
      "tensorboard:\n",
      "  train_images: False\n",
      "  val_images: False\n",
      "  model_params: False\n",
      "optim:\n",
      "  adam:\n",
      "    betas: (0.9, 0.999)\n",
      "  lars:\n",
      "    eps: 1e-09\n",
      "    threshold: 0.01\n",
      "  adabound:\n",
      "    betas: (0.9, 0.999)\n",
      "    final_lr: 0.1\n",
      "    gamma: 0.001\n",
      "scheduler:\n",
      "  epochs: 50\n",
      "  warmup:\n",
      "    type: none\n",
      "    epochs: 0\n",
      "    start_factor: 0.001\n",
      "    exponent: 4\n",
      "  type: multistep\n",
      "  milestones: [60, 120, 160]\n",
      "  lr_decay: 0.2\n",
      "  lr_min_factor: 0.001\n",
      "  T0: 10\n",
      "  T_mul: 1.0\n",
      "validation:\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    drop_last: False\n",
      "    pin_memory: False\n",
      "    non_blocking: False\n",
      "augmentation:\n",
      "  use_random_crop: True\n",
      "  use_random_horizontal_flip: True\n",
      "  use_cutout: False\n",
      "  use_random_erasing: False\n",
      "  use_dual_cutout: False\n",
      "  use_mixup: False\n",
      "  use_ricap: False\n",
      "  use_cutmix: False\n",
      "  use_label_smoothing: False\n",
      "  random_crop:\n",
      "    padding: 4\n",
      "    fill: 0\n",
      "    padding_mode: constant\n",
      "  random_horizontal_flip:\n",
      "    prob: 0.5\n",
      "  cutout:\n",
      "    prob: 1.0\n",
      "    mask_size: 16\n",
      "    cut_inside: False\n",
      "    mask_color: 0\n",
      "    dual_cutout_alpha: 0.1\n",
      "  random_erasing:\n",
      "    prob: 0.5\n",
      "    area_ratio_range: [0.02, 0.4]\n",
      "    min_aspect_ratio: 0.3\n",
      "    max_attempt: 20\n",
      "  mixup:\n",
      "    alpha: 1.0\n",
      "  ricap:\n",
      "    beta: 0.3\n",
      "  cutmix:\n",
      "    alpha: 1.0\n",
      "  label_smoothing:\n",
      "    epsilon: 0.1\n",
      "tta:\n",
      "  use_resize: False\n",
      "  use_center_crop: False\n",
      "  resize: 256\n",
      "test:\n",
      "  checkpoint: ''\n",
      "  output_dir: ''\n",
      "  batch_size: 256\n",
      "  dataloader:\n",
      "    num_workers: 2\n",
      "    pin_memory: False\n",
      "\u001b[32m[2020-07-13 23:06:22] __main__ INFO: \u001b[0menv_info:\n",
      "  pytorch_version: 1.4.0\n",
      "  cuda_version: 10.1\n",
      "  cudnn_version: 7603\n",
      "  num_gpus: 1\n",
      "  gpu_name: Tesla K80\n",
      "  gpu_capability: 3.7\n",
      "Files already downloaded and verified\n",
      "\u001b[32m[2020-07-13 23:06:26] __main__ INFO: \u001b[0mMACs  : 5.25G\n",
      "\u001b[32m[2020-07-13 23:06:26] __main__ INFO: \u001b[0m#params: 36.48M\n",
      "Selected optimization level O0:  Pure FP32 training.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n",
      "\u001b[32m[2020-07-13 23:06:26] __main__ INFO: \u001b[0mVal 0\n",
      "\u001b[32m[2020-07-13 23:06:46] __main__ INFO: \u001b[0mEpoch 0 loss 0.4166 acc@1 0.9076 acc@5 0.9958\n",
      "\u001b[32m[2020-07-13 23:06:46] __main__ INFO: \u001b[0mElapsed 19.50\n",
      "\u001b[32m[2020-07-13 23:06:46] __main__ INFO: \u001b[0mTrain 1 0\n",
      "\u001b[32m[2020-07-13 23:08:42] __main__ INFO: \u001b[0mEpoch 1 Step 100/351 lr 0.001000 loss 0.0823 (0.1501) acc@1 0.9688 (0.9578) acc@5 1.0000 (0.9989)\n",
      "\u001b[32m[2020-07-13 23:10:33] __main__ INFO: \u001b[0mEpoch 1 Step 200/351 lr 0.001000 loss 0.1494 (0.1382) acc@1 0.9375 (0.9598) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-07-13 23:12:25] __main__ INFO: \u001b[0mEpoch 1 Step 300/351 lr 0.001000 loss 0.0833 (0.1300) acc@1 0.9766 (0.9616) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-07-13 23:13:21] __main__ INFO: \u001b[0mEpoch 1 Step 351/351 lr 0.001000 loss 0.1619 (0.1291) acc@1 0.9609 (0.9613) acc@5 1.0000 (0.9992)\n",
      "\u001b[32m[2020-07-13 23:13:21] __main__ INFO: \u001b[0mElapsed 395.84\n",
      "\u001b[32m[2020-07-13 23:13:21] __main__ INFO: \u001b[0mVal 1\n",
      "\u001b[32m[2020-07-13 23:13:35] __main__ INFO: \u001b[0mEpoch 1 loss 0.2297 acc@1 0.9298 acc@5 0.9986\n",
      "\u001b[32m[2020-07-13 23:13:35] __main__ INFO: \u001b[0mElapsed 13.21\n",
      "\u001b[32m[2020-07-13 23:13:35] __main__ INFO: \u001b[0mTrain 2 351\n",
      "\u001b[32m[2020-07-13 23:15:26] __main__ INFO: \u001b[0mEpoch 2 Step 100/351 lr 0.001000 loss 0.0828 (0.0810) acc@1 0.9688 (0.9766) acc@5 1.0000 (0.9994)\n",
      "\u001b[32m[2020-07-13 23:17:18] __main__ INFO: \u001b[0mEpoch 2 Step 200/351 lr 0.001000 loss 0.0289 (0.0811) acc@1 1.0000 (0.9766) acc@5 1.0000 (0.9995)\n",
      "\u001b[32m[2020-07-13 23:19:09] __main__ INFO: \u001b[0mEpoch 2 Step 300/351 lr 0.001000 loss 0.0777 (0.0815) acc@1 0.9688 (0.9762) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-13 23:20:06] __main__ INFO: \u001b[0mEpoch 2 Step 351/351 lr 0.001000 loss 0.0750 (0.0809) acc@1 0.9844 (0.9763) acc@5 1.0000 (0.9996)\n",
      "\u001b[32m[2020-07-13 23:20:06] __main__ INFO: \u001b[0mElapsed 391.61\n",
      "\u001b[32m[2020-07-13 23:20:06] __main__ INFO: \u001b[0mVal 2\n",
      "\u001b[32m[2020-07-13 23:20:19] __main__ INFO: \u001b[0mEpoch 2 loss 0.2227 acc@1 0.9346 acc@5 0.9980\n",
      "\u001b[32m[2020-07-13 23:20:19] __main__ INFO: \u001b[0mElapsed 13.18\n",
      "\u001b[32m[2020-07-13 23:20:19] __main__ INFO: \u001b[0mTrain 3 702\n",
      "\u001b[32m[2020-07-13 23:22:11] __main__ INFO: \u001b[0mEpoch 3 Step 100/351 lr 0.001000 loss 0.0373 (0.0610) acc@1 0.9844 (0.9829) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-13 23:24:02] __main__ INFO: \u001b[0mEpoch 3 Step 200/351 lr 0.001000 loss 0.0314 (0.0600) acc@1 0.9922 (0.9833) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-13 23:25:54] __main__ INFO: \u001b[0mEpoch 3 Step 300/351 lr 0.001000 loss 0.1050 (0.0601) acc@1 0.9609 (0.9833) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-13 23:26:50] __main__ INFO: \u001b[0mEpoch 3 Step 351/351 lr 0.001000 loss 0.0721 (0.0619) acc@1 0.9688 (0.9825) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-13 23:26:50] __main__ INFO: \u001b[0mElapsed 391.06\n",
      "\u001b[32m[2020-07-13 23:26:50] __main__ INFO: \u001b[0mVal 3\n",
      "\u001b[32m[2020-07-13 23:27:04] __main__ INFO: \u001b[0mEpoch 3 loss 0.2243 acc@1 0.9342 acc@5 0.9984\n",
      "\u001b[32m[2020-07-13 23:27:04] __main__ INFO: \u001b[0mElapsed 13.22\n",
      "\u001b[32m[2020-07-13 23:27:04] __main__ INFO: \u001b[0mTrain 4 1053\n",
      "\u001b[32m[2020-07-13 23:28:55] __main__ INFO: \u001b[0mEpoch 4 Step 100/351 lr 0.001000 loss 0.0272 (0.0467) acc@1 1.0000 (0.9873) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-13 23:30:47] __main__ INFO: \u001b[0mEpoch 4 Step 200/351 lr 0.001000 loss 0.0855 (0.0442) acc@1 0.9766 (0.9885) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-13 23:32:38] __main__ INFO: \u001b[0mEpoch 4 Step 300/351 lr 0.001000 loss 0.0398 (0.0445) acc@1 0.9922 (0.9881) acc@5 1.0000 (0.9997)\n",
      "\u001b[32m[2020-07-13 23:33:35] __main__ INFO: \u001b[0mEpoch 4 Step 351/351 lr 0.001000 loss 0.0530 (0.0452) acc@1 0.9766 (0.9880) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-13 23:33:35] __main__ INFO: \u001b[0mElapsed 391.41\n",
      "\u001b[32m[2020-07-13 23:33:35] __main__ INFO: \u001b[0mVal 4\n",
      "\u001b[32m[2020-07-13 23:33:48] __main__ INFO: \u001b[0mEpoch 4 loss 0.2141 acc@1 0.9416 acc@5 0.9984\n",
      "\u001b[32m[2020-07-13 23:33:48] __main__ INFO: \u001b[0mElapsed 13.24\n",
      "\u001b[32m[2020-07-13 23:33:48] __main__ INFO: \u001b[0mTrain 5 1404\n",
      "\u001b[32m[2020-07-13 23:35:40] __main__ INFO: \u001b[0mEpoch 5 Step 100/351 lr 0.001000 loss 0.0364 (0.0362) acc@1 0.9844 (0.9905) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 23:37:31] __main__ INFO: \u001b[0mEpoch 5 Step 200/351 lr 0.001000 loss 0.0162 (0.0358) acc@1 1.0000 (0.9907) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-13 23:39:22] __main__ INFO: \u001b[0mEpoch 5 Step 300/351 lr 0.001000 loss 0.0256 (0.0363) acc@1 0.9844 (0.9907) acc@5 1.0000 (0.9998)\n",
      "\u001b[32m[2020-07-13 23:40:19] __main__ INFO: \u001b[0mEpoch 5 Step 351/351 lr 0.001000 loss 0.1053 (0.0369) acc@1 0.9766 (0.9905) acc@5 0.9922 (0.9998)\n",
      "\u001b[32m[2020-07-13 23:40:19] __main__ INFO: \u001b[0mElapsed 390.84\n",
      "\u001b[32m[2020-07-13 23:40:19] __main__ INFO: \u001b[0mVal 5\n",
      "\u001b[32m[2020-07-13 23:40:32] __main__ INFO: \u001b[0mEpoch 5 loss 0.2241 acc@1 0.9362 acc@5 0.9982\n",
      "\u001b[32m[2020-07-13 23:40:32] __main__ INFO: \u001b[0mElapsed 13.14\n",
      "\u001b[32m[2020-07-13 23:40:32] __main__ INFO: \u001b[0mTrain 6 1755\n",
      "\u001b[32m[2020-07-13 23:42:23] __main__ INFO: \u001b[0mEpoch 6 Step 100/351 lr 0.001000 loss 0.0286 (0.0273) acc@1 0.9922 (0.9933) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-13 23:44:14] __main__ INFO: \u001b[0mEpoch 6 Step 200/351 lr 0.001000 loss 0.0673 (0.0291) acc@1 0.9766 (0.9925) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 23:46:06] __main__ INFO: \u001b[0mEpoch 6 Step 300/351 lr 0.001000 loss 0.0079 (0.0298) acc@1 1.0000 (0.9924) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-13 23:47:02] __main__ INFO: \u001b[0mEpoch 6 Step 351/351 lr 0.001000 loss 0.0110 (0.0296) acc@1 1.0000 (0.9925) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-13 23:47:02] __main__ INFO: \u001b[0mElapsed 389.97\n",
      "\u001b[32m[2020-07-13 23:47:02] __main__ INFO: \u001b[0mVal 6\n",
      "\u001b[32m[2020-07-13 23:47:15] __main__ INFO: \u001b[0mEpoch 6 loss 0.2224 acc@1 0.9396 acc@5 0.9982\n",
      "\u001b[32m[2020-07-13 23:47:15] __main__ INFO: \u001b[0mElapsed 13.13\n",
      "\u001b[32m[2020-07-13 23:47:15] __main__ INFO: \u001b[0mTrain 7 2106\n",
      "\u001b[32m[2020-07-13 23:49:06] __main__ INFO: \u001b[0mEpoch 7 Step 100/351 lr 0.001000 loss 0.0210 (0.0249) acc@1 0.9922 (0.9938) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-13 23:50:58] __main__ INFO: \u001b[0mEpoch 7 Step 200/351 lr 0.001000 loss 0.0323 (0.0274) acc@1 0.9844 (0.9934) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-13 23:52:49] __main__ INFO: \u001b[0mEpoch 7 Step 300/351 lr 0.001000 loss 0.0182 (0.0262) acc@1 0.9922 (0.9935) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-13 23:53:45] __main__ INFO: \u001b[0mEpoch 7 Step 351/351 lr 0.001000 loss 0.0407 (0.0268) acc@1 0.9922 (0.9933) acc@5 0.9922 (0.9999)\n",
      "\u001b[32m[2020-07-13 23:53:45] __main__ INFO: \u001b[0mElapsed 389.99\n",
      "\u001b[32m[2020-07-13 23:53:45] __main__ INFO: \u001b[0mVal 7\n",
      "\u001b[32m[2020-07-13 23:53:59] __main__ INFO: \u001b[0mEpoch 7 loss 0.2416 acc@1 0.9360 acc@5 0.9990\n",
      "\u001b[32m[2020-07-13 23:53:59] __main__ INFO: \u001b[0mElapsed 13.18\n",
      "\u001b[32m[2020-07-13 23:53:59] __main__ INFO: \u001b[0mTrain 8 2457\n",
      "\u001b[32m[2020-07-13 23:55:50] __main__ INFO: \u001b[0mEpoch 8 Step 100/351 lr 0.001000 loss 0.0131 (0.0218) acc@1 1.0000 (0.9947) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-13 23:57:41] __main__ INFO: \u001b[0mEpoch 8 Step 200/351 lr 0.001000 loss 0.0608 (0.0215) acc@1 0.9922 (0.9949) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-13 23:59:32] __main__ INFO: \u001b[0mEpoch 8 Step 300/351 lr 0.001000 loss 0.0203 (0.0219) acc@1 0.9922 (0.9947) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-14 00:00:28] __main__ INFO: \u001b[0mEpoch 8 Step 351/351 lr 0.001000 loss 0.0084 (0.0217) acc@1 1.0000 (0.9949) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-14 00:00:28] __main__ INFO: \u001b[0mElapsed 389.74\n",
      "\u001b[32m[2020-07-14 00:00:28] __main__ INFO: \u001b[0mVal 8\n",
      "\u001b[32m[2020-07-14 00:00:41] __main__ INFO: \u001b[0mEpoch 8 loss 0.2331 acc@1 0.9364 acc@5 0.9978\n",
      "\u001b[32m[2020-07-14 00:00:41] __main__ INFO: \u001b[0mElapsed 13.11\n",
      "\u001b[32m[2020-07-14 00:00:41] __main__ INFO: \u001b[0mTrain 9 2808\n",
      "\u001b[32m[2020-07-14 00:02:33] __main__ INFO: \u001b[0mEpoch 9 Step 100/351 lr 0.001000 loss 0.0098 (0.0217) acc@1 1.0000 (0.9947) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 00:04:24] __main__ INFO: \u001b[0mEpoch 9 Step 200/351 lr 0.001000 loss 0.0300 (0.0215) acc@1 0.9844 (0.9943) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 00:06:15] __main__ INFO: \u001b[0mEpoch 9 Step 300/351 lr 0.001000 loss 0.0361 (0.0210) acc@1 0.9844 (0.9947) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 00:07:11] __main__ INFO: \u001b[0mEpoch 9 Step 351/351 lr 0.001000 loss 0.0217 (0.0208) acc@1 0.9922 (0.9947) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 00:07:11] __main__ INFO: \u001b[0mElapsed 389.94\n",
      "\u001b[32m[2020-07-14 00:07:11] __main__ INFO: \u001b[0mVal 9\n",
      "\u001b[32m[2020-07-14 00:07:24] __main__ INFO: \u001b[0mEpoch 9 loss 0.2312 acc@1 0.9388 acc@5 0.9980\n",
      "\u001b[32m[2020-07-14 00:07:24] __main__ INFO: \u001b[0mElapsed 13.13\n",
      "\u001b[32m[2020-07-14 00:07:24] __main__ INFO: \u001b[0mTrain 10 3159\n",
      "\u001b[32m[2020-07-14 00:09:16] __main__ INFO: \u001b[0mEpoch 10 Step 100/351 lr 0.001000 loss 0.0197 (0.0176) acc@1 0.9922 (0.9958) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 00:11:07] __main__ INFO: \u001b[0mEpoch 10 Step 200/351 lr 0.001000 loss 0.0061 (0.0177) acc@1 1.0000 (0.9962) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 00:12:58] __main__ INFO: \u001b[0mEpoch 10 Step 300/351 lr 0.001000 loss 0.0130 (0.0167) acc@1 1.0000 (0.9965) acc@5 1.0000 (0.9999)\n",
      "\u001b[32m[2020-07-14 00:13:54] __main__ INFO: \u001b[0mEpoch 10 Step 351/351 lr 0.001000 loss 0.0078 (0.0169) acc@1 1.0000 (0.9965) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 00:13:54] __main__ INFO: \u001b[0mElapsed 389.85\n",
      "\u001b[32m[2020-07-14 00:13:54] __main__ INFO: \u001b[0mVal 10\n",
      "\u001b[32m[2020-07-14 00:14:07] __main__ INFO: \u001b[0mEpoch 10 loss 0.2372 acc@1 0.9392 acc@5 0.9976\n",
      "\u001b[32m[2020-07-14 00:14:07] __main__ INFO: \u001b[0mElapsed 13.13\n",
      "\u001b[32m[2020-07-14 00:14:07] __main__ INFO: \u001b[0mTrain 11 3510\n",
      "\u001b[32m[2020-07-14 00:15:59] __main__ INFO: \u001b[0mEpoch 11 Step 100/351 lr 0.001000 loss 0.0094 (0.0127) acc@1 1.0000 (0.9976) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 00:17:50] __main__ INFO: \u001b[0mEpoch 11 Step 200/351 lr 0.001000 loss 0.0038 (0.0138) acc@1 1.0000 (0.9973) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 00:19:41] __main__ INFO: \u001b[0mEpoch 11 Step 300/351 lr 0.001000 loss 0.0211 (0.0144) acc@1 0.9844 (0.9970) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 00:20:37] __main__ INFO: \u001b[0mEpoch 11 Step 351/351 lr 0.001000 loss 0.0091 (0.0141) acc@1 1.0000 (0.9971) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 00:20:37] __main__ INFO: \u001b[0mElapsed 389.87\n",
      "\u001b[32m[2020-07-14 00:20:37] __main__ INFO: \u001b[0mVal 11\n",
      "\u001b[32m[2020-07-14 00:20:51] __main__ INFO: \u001b[0mEpoch 11 loss 0.2353 acc@1 0.9398 acc@5 0.9972\n",
      "\u001b[32m[2020-07-14 00:20:51] __main__ INFO: \u001b[0mElapsed 13.19\n",
      "\u001b[32m[2020-07-14 00:20:51] __main__ INFO: \u001b[0mTrain 12 3861\n",
      "\u001b[32m[2020-07-14 00:22:42] __main__ INFO: \u001b[0mEpoch 12 Step 100/351 lr 0.001000 loss 0.0143 (0.0123) acc@1 0.9922 (0.9979) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 00:24:33] __main__ INFO: \u001b[0mEpoch 12 Step 200/351 lr 0.001000 loss 0.0059 (0.0128) acc@1 1.0000 (0.9977) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 00:26:25] __main__ INFO: \u001b[0mEpoch 12 Step 300/351 lr 0.001000 loss 0.0034 (0.0130) acc@1 1.0000 (0.9974) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 00:27:22] __main__ INFO: \u001b[0mEpoch 12 Step 351/351 lr 0.001000 loss 0.0054 (0.0130) acc@1 1.0000 (0.9973) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 00:27:22] __main__ INFO: \u001b[0mElapsed 391.31\n",
      "\u001b[32m[2020-07-14 00:27:22] __main__ INFO: \u001b[0mVal 12\n",
      "\u001b[32m[2020-07-14 00:27:35] __main__ INFO: \u001b[0mEpoch 12 loss 0.2390 acc@1 0.9414 acc@5 0.9976\n",
      "\u001b[32m[2020-07-14 00:27:35] __main__ INFO: \u001b[0mElapsed 13.23\n",
      "\u001b[32m[2020-07-14 00:27:35] __main__ INFO: \u001b[0mTrain 13 4212\n",
      "\u001b[32m[2020-07-14 00:29:27] __main__ INFO: \u001b[0mEpoch 13 Step 100/351 lr 0.001000 loss 0.0197 (0.0120) acc@1 0.9844 (0.9977) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 00:31:18] __main__ INFO: \u001b[0mEpoch 13 Step 200/351 lr 0.001000 loss 0.0050 (0.0124) acc@1 1.0000 (0.9975) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 00:33:09] __main__ INFO: \u001b[0mEpoch 13 Step 300/351 lr 0.001000 loss 0.0042 (0.0125) acc@1 1.0000 (0.9974) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 00:34:06] __main__ INFO: \u001b[0mEpoch 13 Step 351/351 lr 0.001000 loss 0.0070 (0.0125) acc@1 1.0000 (0.9974) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 00:34:06] __main__ INFO: \u001b[0mElapsed 390.64\n",
      "\u001b[32m[2020-07-14 00:34:06] __main__ INFO: \u001b[0mVal 13\n",
      "\u001b[32m[2020-07-14 00:34:19] __main__ INFO: \u001b[0mEpoch 13 loss 0.2365 acc@1 0.9422 acc@5 0.9980\n",
      "\u001b[32m[2020-07-14 00:34:19] __main__ INFO: \u001b[0mElapsed 13.19\n",
      "\u001b[32m[2020-07-14 00:34:19] __main__ INFO: \u001b[0mTrain 14 4563\n",
      "\u001b[32m[2020-07-14 00:36:10] __main__ INFO: \u001b[0mEpoch 14 Step 100/351 lr 0.001000 loss 0.0131 (0.0107) acc@1 0.9922 (0.9980) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 00:38:02] __main__ INFO: \u001b[0mEpoch 14 Step 200/351 lr 0.001000 loss 0.0044 (0.0112) acc@1 1.0000 (0.9975) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 00:39:53] __main__ INFO: \u001b[0mEpoch 14 Step 300/351 lr 0.001000 loss 0.0211 (0.0115) acc@1 0.9922 (0.9974) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 00:40:50] __main__ INFO: \u001b[0mEpoch 14 Step 351/351 lr 0.001000 loss 0.0040 (0.0119) acc@1 1.0000 (0.9973) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 00:40:50] __main__ INFO: \u001b[0mElapsed 391.32\n",
      "\u001b[32m[2020-07-14 00:40:50] __main__ INFO: \u001b[0mVal 14\n",
      "\u001b[32m[2020-07-14 00:41:03] __main__ INFO: \u001b[0mEpoch 14 loss 0.2466 acc@1 0.9384 acc@5 0.9980\n",
      "\u001b[32m[2020-07-14 00:41:03] __main__ INFO: \u001b[0mElapsed 13.22\n",
      "\u001b[32m[2020-07-14 00:41:03] __main__ INFO: \u001b[0mTrain 15 4914\n",
      "\u001b[32m[2020-07-14 00:42:55] __main__ INFO: \u001b[0mEpoch 15 Step 100/351 lr 0.001000 loss 0.0168 (0.0107) acc@1 0.9922 (0.9975) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 00:44:47] __main__ INFO: \u001b[0mEpoch 15 Step 200/351 lr 0.001000 loss 0.0132 (0.0105) acc@1 1.0000 (0.9979) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 00:46:38] __main__ INFO: \u001b[0mEpoch 15 Step 300/351 lr 0.001000 loss 0.0391 (0.0104) acc@1 0.9922 (0.9979) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 00:47:35] __main__ INFO: \u001b[0mEpoch 15 Step 351/351 lr 0.001000 loss 0.0079 (0.0104) acc@1 1.0000 (0.9979) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 00:47:35] __main__ INFO: \u001b[0mElapsed 391.44\n",
      "\u001b[32m[2020-07-14 00:47:35] __main__ INFO: \u001b[0mVal 15\n",
      "\u001b[32m[2020-07-14 00:47:48] __main__ INFO: \u001b[0mEpoch 15 loss 0.2468 acc@1 0.9408 acc@5 0.9976\n",
      "\u001b[32m[2020-07-14 00:47:48] __main__ INFO: \u001b[0mElapsed 13.21\n",
      "\u001b[32m[2020-07-14 00:47:48] __main__ INFO: \u001b[0mTrain 16 5265\n",
      "\u001b[32m[2020-07-14 00:49:40] __main__ INFO: \u001b[0mEpoch 16 Step 100/351 lr 0.001000 loss 0.0063 (0.0089) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 00:51:31] __main__ INFO: \u001b[0mEpoch 16 Step 200/351 lr 0.001000 loss 0.0057 (0.0092) acc@1 1.0000 (0.9982) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 00:53:22] __main__ INFO: \u001b[0mEpoch 16 Step 300/351 lr 0.001000 loss 0.0029 (0.0099) acc@1 1.0000 (0.9979) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 00:54:19] __main__ INFO: \u001b[0mEpoch 16 Step 351/351 lr 0.001000 loss 0.0034 (0.0099) acc@1 1.0000 (0.9979) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 00:54:19] __main__ INFO: \u001b[0mElapsed 391.20\n",
      "\u001b[32m[2020-07-14 00:54:19] __main__ INFO: \u001b[0mVal 16\n",
      "\u001b[32m[2020-07-14 00:54:32] __main__ INFO: \u001b[0mEpoch 16 loss 0.2468 acc@1 0.9406 acc@5 0.9976\n",
      "\u001b[32m[2020-07-14 00:54:32] __main__ INFO: \u001b[0mElapsed 13.17\n",
      "\u001b[32m[2020-07-14 00:54:33] __main__ INFO: \u001b[0mTrain 17 5616\n",
      "\u001b[32m[2020-07-14 00:56:24] __main__ INFO: \u001b[0mEpoch 17 Step 100/351 lr 0.001000 loss 0.0070 (0.0071) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 00:58:15] __main__ INFO: \u001b[0mEpoch 17 Step 200/351 lr 0.001000 loss 0.0244 (0.0084) acc@1 0.9922 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 01:00:06] __main__ INFO: \u001b[0mEpoch 17 Step 300/351 lr 0.001000 loss 0.0038 (0.0083) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 01:01:02] __main__ INFO: \u001b[0mEpoch 17 Step 351/351 lr 0.001000 loss 0.0104 (0.0084) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 01:01:02] __main__ INFO: \u001b[0mElapsed 389.98\n",
      "\u001b[32m[2020-07-14 01:01:02] __main__ INFO: \u001b[0mVal 17\n",
      "\u001b[32m[2020-07-14 01:01:16] __main__ INFO: \u001b[0mEpoch 17 loss 0.2527 acc@1 0.9410 acc@5 0.9980\n",
      "\u001b[32m[2020-07-14 01:01:16] __main__ INFO: \u001b[0mElapsed 13.13\n",
      "\u001b[32m[2020-07-14 01:01:16] __main__ INFO: \u001b[0mTrain 18 5967\n",
      "\u001b[32m[2020-07-14 01:03:07] __main__ INFO: \u001b[0mEpoch 18 Step 100/351 lr 0.001000 loss 0.0029 (0.0068) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 01:04:58] __main__ INFO: \u001b[0mEpoch 18 Step 200/351 lr 0.001000 loss 0.0093 (0.0073) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 01:06:49] __main__ INFO: \u001b[0mEpoch 18 Step 300/351 lr 0.001000 loss 0.0050 (0.0081) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 01:07:46] __main__ INFO: \u001b[0mEpoch 18 Step 351/351 lr 0.001000 loss 0.0087 (0.0082) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 01:07:46] __main__ INFO: \u001b[0mElapsed 389.91\n",
      "\u001b[32m[2020-07-14 01:07:46] __main__ INFO: \u001b[0mVal 18\n",
      "\u001b[32m[2020-07-14 01:07:59] __main__ INFO: \u001b[0mEpoch 18 loss 0.2467 acc@1 0.9412 acc@5 0.9974\n",
      "\u001b[32m[2020-07-14 01:07:59] __main__ INFO: \u001b[0mElapsed 13.10\n",
      "\u001b[32m[2020-07-14 01:07:59] __main__ INFO: \u001b[0mTrain 19 6318\n",
      "\u001b[32m[2020-07-14 01:09:50] __main__ INFO: \u001b[0mEpoch 19 Step 100/351 lr 0.001000 loss 0.0184 (0.0077) acc@1 0.9922 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 01:11:41] __main__ INFO: \u001b[0mEpoch 19 Step 200/351 lr 0.001000 loss 0.0037 (0.0075) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 01:13:33] __main__ INFO: \u001b[0mEpoch 19 Step 300/351 lr 0.001000 loss 0.0043 (0.0075) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 01:14:29] __main__ INFO: \u001b[0mEpoch 19 Step 351/351 lr 0.001000 loss 0.0055 (0.0074) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 01:14:29] __main__ INFO: \u001b[0mElapsed 390.72\n",
      "\u001b[32m[2020-07-14 01:14:29] __main__ INFO: \u001b[0mVal 19\n",
      "\u001b[32m[2020-07-14 01:14:43] __main__ INFO: \u001b[0mEpoch 19 loss 0.2499 acc@1 0.9418 acc@5 0.9982\n",
      "\u001b[32m[2020-07-14 01:14:43] __main__ INFO: \u001b[0mElapsed 13.17\n",
      "\u001b[32m[2020-07-14 01:14:43] __main__ INFO: \u001b[0mTrain 20 6669\n",
      "\u001b[32m[2020-07-14 01:16:34] __main__ INFO: \u001b[0mEpoch 20 Step 100/351 lr 0.001000 loss 0.0027 (0.0073) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 01:18:25] __main__ INFO: \u001b[0mEpoch 20 Step 200/351 lr 0.001000 loss 0.0025 (0.0071) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 01:20:17] __main__ INFO: \u001b[0mEpoch 20 Step 300/351 lr 0.001000 loss 0.0110 (0.0068) acc@1 0.9922 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 01:21:14] __main__ INFO: \u001b[0mEpoch 20 Step 351/351 lr 0.001000 loss 0.0187 (0.0071) acc@1 0.9922 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 01:21:14] __main__ INFO: \u001b[0mElapsed 391.25\n",
      "\u001b[32m[2020-07-14 01:21:14] __main__ INFO: \u001b[0mVal 20\n",
      "\u001b[32m[2020-07-14 01:21:27] __main__ INFO: \u001b[0mEpoch 20 loss 0.2609 acc@1 0.9396 acc@5 0.9980\n",
      "\u001b[32m[2020-07-14 01:21:27] __main__ INFO: \u001b[0mElapsed 13.18\n",
      "\u001b[32m[2020-07-14 01:21:27] __main__ INFO: \u001b[0mTrain 21 7020\n",
      "\u001b[32m[2020-07-14 01:23:18] __main__ INFO: \u001b[0mEpoch 21 Step 100/351 lr 0.001000 loss 0.0069 (0.0083) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 01:25:10] __main__ INFO: \u001b[0mEpoch 21 Step 200/351 lr 0.001000 loss 0.0030 (0.0077) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 01:27:02] __main__ INFO: \u001b[0mEpoch 21 Step 300/351 lr 0.001000 loss 0.0020 (0.0070) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 01:27:58] __main__ INFO: \u001b[0mEpoch 21 Step 351/351 lr 0.001000 loss 0.0044 (0.0072) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 01:27:58] __main__ INFO: \u001b[0mElapsed 391.31\n",
      "\u001b[32m[2020-07-14 01:27:58] __main__ INFO: \u001b[0mVal 21\n",
      "\u001b[32m[2020-07-14 01:28:11] __main__ INFO: \u001b[0mEpoch 21 loss 0.2506 acc@1 0.9420 acc@5 0.9984\n",
      "\u001b[32m[2020-07-14 01:28:11] __main__ INFO: \u001b[0mElapsed 13.11\n",
      "\u001b[32m[2020-07-14 01:28:11] __main__ INFO: \u001b[0mTrain 22 7371\n",
      "\u001b[32m[2020-07-14 01:30:03] __main__ INFO: \u001b[0mEpoch 22 Step 100/351 lr 0.001000 loss 0.0048 (0.0085) acc@1 1.0000 (0.9980) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 01:31:54] __main__ INFO: \u001b[0mEpoch 22 Step 200/351 lr 0.001000 loss 0.0069 (0.0079) acc@1 1.0000 (0.9983) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 01:33:46] __main__ INFO: \u001b[0mEpoch 22 Step 300/351 lr 0.001000 loss 0.0047 (0.0078) acc@1 1.0000 (0.9983) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 01:34:43] __main__ INFO: \u001b[0mEpoch 22 Step 351/351 lr 0.001000 loss 0.0152 (0.0078) acc@1 0.9922 (0.9982) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 01:34:43] __main__ INFO: \u001b[0mElapsed 391.54\n",
      "\u001b[32m[2020-07-14 01:34:43] __main__ INFO: \u001b[0mVal 22\n",
      "\u001b[32m[2020-07-14 01:34:56] __main__ INFO: \u001b[0mEpoch 22 loss 0.2624 acc@1 0.9380 acc@5 0.9974\n",
      "\u001b[32m[2020-07-14 01:34:56] __main__ INFO: \u001b[0mElapsed 13.18\n",
      "\u001b[32m[2020-07-14 01:34:56] __main__ INFO: \u001b[0mTrain 23 7722\n",
      "\u001b[32m[2020-07-14 01:36:48] __main__ INFO: \u001b[0mEpoch 23 Step 100/351 lr 0.001000 loss 0.0045 (0.0084) acc@1 1.0000 (0.9983) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 01:38:39] __main__ INFO: \u001b[0mEpoch 23 Step 200/351 lr 0.001000 loss 0.0032 (0.0082) acc@1 1.0000 (0.9983) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 01:40:30] __main__ INFO: \u001b[0mEpoch 23 Step 300/351 lr 0.001000 loss 0.0047 (0.0078) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 01:41:27] __main__ INFO: \u001b[0mEpoch 23 Step 351/351 lr 0.001000 loss 0.0038 (0.0076) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 01:41:27] __main__ INFO: \u001b[0mElapsed 391.36\n",
      "\u001b[32m[2020-07-14 01:41:27] __main__ INFO: \u001b[0mVal 23\n",
      "\u001b[32m[2020-07-14 01:41:41] __main__ INFO: \u001b[0mEpoch 23 loss 0.2580 acc@1 0.9396 acc@5 0.9976\n",
      "\u001b[32m[2020-07-14 01:41:41] __main__ INFO: \u001b[0mElapsed 13.18\n",
      "\u001b[32m[2020-07-14 01:41:41] __main__ INFO: \u001b[0mTrain 24 8073\n",
      "\u001b[32m[2020-07-14 01:43:32] __main__ INFO: \u001b[0mEpoch 24 Step 100/351 lr 0.001000 loss 0.0083 (0.0066) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 01:45:23] __main__ INFO: \u001b[0mEpoch 24 Step 200/351 lr 0.001000 loss 0.0069 (0.0064) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 01:47:15] __main__ INFO: \u001b[0mEpoch 24 Step 300/351 lr 0.001000 loss 0.0086 (0.0072) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 01:48:12] __main__ INFO: \u001b[0mEpoch 24 Step 351/351 lr 0.001000 loss 0.0027 (0.0072) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 01:48:12] __main__ INFO: \u001b[0mElapsed 391.64\n",
      "\u001b[32m[2020-07-14 01:48:12] __main__ INFO: \u001b[0mVal 24\n",
      "\u001b[32m[2020-07-14 01:48:25] __main__ INFO: \u001b[0mEpoch 24 loss 0.2532 acc@1 0.9420 acc@5 0.9974\n",
      "\u001b[32m[2020-07-14 01:48:25] __main__ INFO: \u001b[0mElapsed 13.19\n",
      "\u001b[32m[2020-07-14 01:48:25] __main__ INFO: \u001b[0mTrain 25 8424\n",
      "\u001b[32m[2020-07-14 01:50:17] __main__ INFO: \u001b[0mEpoch 25 Step 100/351 lr 0.001000 loss 0.0061 (0.0076) acc@1 1.0000 (0.9982) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 01:52:08] __main__ INFO: \u001b[0mEpoch 25 Step 200/351 lr 0.001000 loss 0.0083 (0.0063) acc@1 0.9922 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 01:54:00] __main__ INFO: \u001b[0mEpoch 25 Step 300/351 lr 0.001000 loss 0.0177 (0.0068) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 01:54:56] __main__ INFO: \u001b[0mEpoch 25 Step 351/351 lr 0.001000 loss 0.0036 (0.0068) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 01:54:56] __main__ INFO: \u001b[0mElapsed 390.90\n",
      "\u001b[32m[2020-07-14 01:54:56] __main__ INFO: \u001b[0mVal 25\n",
      "\u001b[32m[2020-07-14 01:55:09] __main__ INFO: \u001b[0mEpoch 25 loss 0.2534 acc@1 0.9426 acc@5 0.9982\n",
      "\u001b[32m[2020-07-14 01:55:09] __main__ INFO: \u001b[0mElapsed 13.09\n",
      "\u001b[32m[2020-07-14 01:55:09] __main__ INFO: \u001b[0mTrain 26 8775\n",
      "\u001b[32m[2020-07-14 01:57:01] __main__ INFO: \u001b[0mEpoch 26 Step 100/351 lr 0.001000 loss 0.0031 (0.0057) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 01:58:52] __main__ INFO: \u001b[0mEpoch 26 Step 200/351 lr 0.001000 loss 0.0127 (0.0066) acc@1 0.9922 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 02:00:43] __main__ INFO: \u001b[0mEpoch 26 Step 300/351 lr 0.001000 loss 0.0029 (0.0067) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 02:01:40] __main__ INFO: \u001b[0mEpoch 26 Step 351/351 lr 0.001000 loss 0.0026 (0.0068) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 02:01:40] __main__ INFO: \u001b[0mElapsed 390.59\n",
      "\u001b[32m[2020-07-14 02:01:40] __main__ INFO: \u001b[0mVal 26\n",
      "\u001b[32m[2020-07-14 02:01:53] __main__ INFO: \u001b[0mEpoch 26 loss 0.2539 acc@1 0.9438 acc@5 0.9980\n",
      "\u001b[32m[2020-07-14 02:01:53] __main__ INFO: \u001b[0mElapsed 13.31\n",
      "\u001b[32m[2020-07-14 02:01:53] __main__ INFO: \u001b[0mTrain 27 9126\n",
      "\u001b[32m[2020-07-14 02:03:45] __main__ INFO: \u001b[0mEpoch 27 Step 100/351 lr 0.001000 loss 0.0048 (0.0058) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 02:05:37] __main__ INFO: \u001b[0mEpoch 27 Step 200/351 lr 0.001000 loss 0.0041 (0.0055) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 02:07:28] __main__ INFO: \u001b[0mEpoch 27 Step 300/351 lr 0.001000 loss 0.0101 (0.0057) acc@1 0.9922 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 02:08:25] __main__ INFO: \u001b[0mEpoch 27 Step 351/351 lr 0.001000 loss 0.0071 (0.0058) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 02:08:25] __main__ INFO: \u001b[0mElapsed 391.54\n",
      "\u001b[32m[2020-07-14 02:08:25] __main__ INFO: \u001b[0mVal 27\n",
      "\u001b[32m[2020-07-14 02:08:38] __main__ INFO: \u001b[0mEpoch 27 loss 0.2709 acc@1 0.9380 acc@5 0.9978\n",
      "\u001b[32m[2020-07-14 02:08:38] __main__ INFO: \u001b[0mElapsed 13.19\n",
      "\u001b[32m[2020-07-14 02:08:38] __main__ INFO: \u001b[0mTrain 28 9477\n",
      "\u001b[32m[2020-07-14 02:10:30] __main__ INFO: \u001b[0mEpoch 28 Step 100/351 lr 0.001000 loss 0.0038 (0.0068) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 02:12:21] __main__ INFO: \u001b[0mEpoch 28 Step 200/351 lr 0.001000 loss 0.0037 (0.0063) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 02:14:13] __main__ INFO: \u001b[0mEpoch 28 Step 300/351 lr 0.001000 loss 0.0045 (0.0060) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 02:15:09] __main__ INFO: \u001b[0mEpoch 28 Step 351/351 lr 0.001000 loss 0.0044 (0.0058) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 02:15:09] __main__ INFO: \u001b[0mElapsed 391.28\n",
      "\u001b[32m[2020-07-14 02:15:09] __main__ INFO: \u001b[0mVal 28\n",
      "\u001b[32m[2020-07-14 02:15:23] __main__ INFO: \u001b[0mEpoch 28 loss 0.2602 acc@1 0.9396 acc@5 0.9978\n",
      "\u001b[32m[2020-07-14 02:15:23] __main__ INFO: \u001b[0mElapsed 13.16\n",
      "\u001b[32m[2020-07-14 02:15:23] __main__ INFO: \u001b[0mTrain 29 9828\n",
      "\u001b[32m[2020-07-14 02:17:14] __main__ INFO: \u001b[0mEpoch 29 Step 100/351 lr 0.001000 loss 0.0055 (0.0058) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 02:19:05] __main__ INFO: \u001b[0mEpoch 29 Step 200/351 lr 0.001000 loss 0.0089 (0.0061) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 02:20:57] __main__ INFO: \u001b[0mEpoch 29 Step 300/351 lr 0.001000 loss 0.0024 (0.0062) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 02:21:53] __main__ INFO: \u001b[0mEpoch 29 Step 351/351 lr 0.001000 loss 0.0033 (0.0058) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 02:21:53] __main__ INFO: \u001b[0mElapsed 390.80\n",
      "\u001b[32m[2020-07-14 02:21:53] __main__ INFO: \u001b[0mVal 29\n",
      "\u001b[32m[2020-07-14 02:22:06] __main__ INFO: \u001b[0mEpoch 29 loss 0.2534 acc@1 0.9418 acc@5 0.9976\n",
      "\u001b[32m[2020-07-14 02:22:06] __main__ INFO: \u001b[0mElapsed 13.14\n",
      "\u001b[32m[2020-07-14 02:22:06] __main__ INFO: \u001b[0mTrain 30 10179\n",
      "\u001b[32m[2020-07-14 02:23:58] __main__ INFO: \u001b[0mEpoch 30 Step 100/351 lr 0.001000 loss 0.0071 (0.0045) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 02:25:49] __main__ INFO: \u001b[0mEpoch 30 Step 200/351 lr 0.001000 loss 0.0029 (0.0045) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 02:27:41] __main__ INFO: \u001b[0mEpoch 30 Step 300/351 lr 0.001000 loss 0.0039 (0.0043) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 02:28:37] __main__ INFO: \u001b[0mEpoch 30 Step 351/351 lr 0.001000 loss 0.0021 (0.0043) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 02:28:37] __main__ INFO: \u001b[0mElapsed 390.91\n",
      "\u001b[32m[2020-07-14 02:28:37] __main__ INFO: \u001b[0mVal 30\n",
      "\u001b[32m[2020-07-14 02:28:51] __main__ INFO: \u001b[0mEpoch 30 loss 0.2553 acc@1 0.9420 acc@5 0.9984\n",
      "\u001b[32m[2020-07-14 02:28:51] __main__ INFO: \u001b[0mElapsed 13.16\n",
      "\u001b[32m[2020-07-14 02:28:51] __main__ INFO: \u001b[0mTrain 31 10530\n",
      "\u001b[32m[2020-07-14 02:30:42] __main__ INFO: \u001b[0mEpoch 31 Step 100/351 lr 0.001000 loss 0.0023 (0.0047) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 02:32:33] __main__ INFO: \u001b[0mEpoch 31 Step 200/351 lr 0.001000 loss 0.0047 (0.0044) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 02:34:25] __main__ INFO: \u001b[0mEpoch 31 Step 300/351 lr 0.001000 loss 0.0034 (0.0043) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 02:35:22] __main__ INFO: \u001b[0mEpoch 31 Step 351/351 lr 0.001000 loss 0.0031 (0.0045) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 02:35:22] __main__ INFO: \u001b[0mElapsed 391.19\n",
      "\u001b[32m[2020-07-14 02:35:22] __main__ INFO: \u001b[0mVal 31\n",
      "\u001b[32m[2020-07-14 02:35:35] __main__ INFO: \u001b[0mEpoch 31 loss 0.2573 acc@1 0.9438 acc@5 0.9980\n",
      "\u001b[32m[2020-07-14 02:35:35] __main__ INFO: \u001b[0mElapsed 13.18\n",
      "\u001b[32m[2020-07-14 02:35:35] __main__ INFO: \u001b[0mTrain 32 10881\n",
      "\u001b[32m[2020-07-14 02:37:26] __main__ INFO: \u001b[0mEpoch 32 Step 100/351 lr 0.001000 loss 0.0029 (0.0051) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 02:39:18] __main__ INFO: \u001b[0mEpoch 32 Step 200/351 lr 0.001000 loss 0.0025 (0.0045) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 02:41:09] __main__ INFO: \u001b[0mEpoch 32 Step 300/351 lr 0.001000 loss 0.0031 (0.0048) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 02:42:05] __main__ INFO: \u001b[0mEpoch 32 Step 351/351 lr 0.001000 loss 0.0050 (0.0048) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 02:42:05] __main__ INFO: \u001b[0mElapsed 390.50\n",
      "\u001b[32m[2020-07-14 02:42:05] __main__ INFO: \u001b[0mVal 32\n",
      "\u001b[32m[2020-07-14 02:42:19] __main__ INFO: \u001b[0mEpoch 32 loss 0.2631 acc@1 0.9396 acc@5 0.9982\n",
      "\u001b[32m[2020-07-14 02:42:19] __main__ INFO: \u001b[0mElapsed 13.15\n",
      "\u001b[32m[2020-07-14 02:42:19] __main__ INFO: \u001b[0mTrain 33 11232\n",
      "\u001b[32m[2020-07-14 02:44:10] __main__ INFO: \u001b[0mEpoch 33 Step 100/351 lr 0.001000 loss 0.0020 (0.0055) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 02:46:01] __main__ INFO: \u001b[0mEpoch 33 Step 200/351 lr 0.001000 loss 0.0055 (0.0048) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 02:47:52] __main__ INFO: \u001b[0mEpoch 33 Step 300/351 lr 0.001000 loss 0.0035 (0.0046) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 02:48:49] __main__ INFO: \u001b[0mEpoch 33 Step 351/351 lr 0.001000 loss 0.0020 (0.0045) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 02:48:49] __main__ INFO: \u001b[0mElapsed 390.32\n",
      "\u001b[32m[2020-07-14 02:48:49] __main__ INFO: \u001b[0mVal 33\n",
      "\u001b[32m[2020-07-14 02:49:02] __main__ INFO: \u001b[0mEpoch 33 loss 0.2625 acc@1 0.9406 acc@5 0.9978\n",
      "\u001b[32m[2020-07-14 02:49:02] __main__ INFO: \u001b[0mElapsed 13.16\n",
      "\u001b[32m[2020-07-14 02:49:02] __main__ INFO: \u001b[0mTrain 34 11583\n",
      "\u001b[32m[2020-07-14 02:50:53] __main__ INFO: \u001b[0mEpoch 34 Step 100/351 lr 0.001000 loss 0.0026 (0.0036) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 02:52:44] __main__ INFO: \u001b[0mEpoch 34 Step 200/351 lr 0.001000 loss 0.0023 (0.0043) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 02:54:36] __main__ INFO: \u001b[0mEpoch 34 Step 300/351 lr 0.001000 loss 0.0051 (0.0044) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 02:55:32] __main__ INFO: \u001b[0mEpoch 34 Step 351/351 lr 0.001000 loss 0.0033 (0.0046) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 02:55:32] __main__ INFO: \u001b[0mElapsed 390.31\n",
      "\u001b[32m[2020-07-14 02:55:32] __main__ INFO: \u001b[0mVal 34\n",
      "\u001b[32m[2020-07-14 02:55:46] __main__ INFO: \u001b[0mEpoch 34 loss 0.2661 acc@1 0.9384 acc@5 0.9980\n",
      "\u001b[32m[2020-07-14 02:55:46] __main__ INFO: \u001b[0mElapsed 13.17\n",
      "\u001b[32m[2020-07-14 02:55:46] __main__ INFO: \u001b[0mTrain 35 11934\n",
      "\u001b[32m[2020-07-14 02:57:37] __main__ INFO: \u001b[0mEpoch 35 Step 100/351 lr 0.001000 loss 0.0031 (0.0039) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 02:59:28] __main__ INFO: \u001b[0mEpoch 35 Step 200/351 lr 0.001000 loss 0.0028 (0.0041) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 03:01:19] __main__ INFO: \u001b[0mEpoch 35 Step 300/351 lr 0.001000 loss 0.0035 (0.0048) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 03:02:16] __main__ INFO: \u001b[0mEpoch 35 Step 351/351 lr 0.001000 loss 0.0112 (0.0049) acc@1 0.9922 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 03:02:16] __main__ INFO: \u001b[0mElapsed 390.16\n",
      "\u001b[32m[2020-07-14 03:02:16] __main__ INFO: \u001b[0mVal 35\n",
      "\u001b[32m[2020-07-14 03:02:29] __main__ INFO: \u001b[0mEpoch 35 loss 0.2651 acc@1 0.9358 acc@5 0.9976\n",
      "\u001b[32m[2020-07-14 03:02:29] __main__ INFO: \u001b[0mElapsed 13.17\n",
      "\u001b[32m[2020-07-14 03:02:29] __main__ INFO: \u001b[0mTrain 36 12285\n",
      "\u001b[32m[2020-07-14 03:04:20] __main__ INFO: \u001b[0mEpoch 36 Step 100/351 lr 0.001000 loss 0.0033 (0.0051) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 03:06:11] __main__ INFO: \u001b[0mEpoch 36 Step 200/351 lr 0.001000 loss 0.0038 (0.0049) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 03:08:03] __main__ INFO: \u001b[0mEpoch 36 Step 300/351 lr 0.001000 loss 0.0026 (0.0049) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 03:08:59] __main__ INFO: \u001b[0mEpoch 36 Step 351/351 lr 0.001000 loss 0.0294 (0.0049) acc@1 0.9922 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 03:08:59] __main__ INFO: \u001b[0mElapsed 390.42\n",
      "\u001b[32m[2020-07-14 03:08:59] __main__ INFO: \u001b[0mVal 36\n",
      "\u001b[32m[2020-07-14 03:09:12] __main__ INFO: \u001b[0mEpoch 36 loss 0.2696 acc@1 0.9406 acc@5 0.9978\n",
      "\u001b[32m[2020-07-14 03:09:12] __main__ INFO: \u001b[0mElapsed 13.15\n",
      "\u001b[32m[2020-07-14 03:09:12] __main__ INFO: \u001b[0mTrain 37 12636\n",
      "\u001b[32m[2020-07-14 03:11:04] __main__ INFO: \u001b[0mEpoch 37 Step 100/351 lr 0.001000 loss 0.0024 (0.0056) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 03:12:55] __main__ INFO: \u001b[0mEpoch 37 Step 200/351 lr 0.001000 loss 0.0114 (0.0052) acc@1 0.9922 (0.9990) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 03:14:46] __main__ INFO: \u001b[0mEpoch 37 Step 300/351 lr 0.001000 loss 0.0054 (0.0050) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 03:15:42] __main__ INFO: \u001b[0mEpoch 37 Step 351/351 lr 0.001000 loss 0.0036 (0.0048) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 03:15:42] __main__ INFO: \u001b[0mElapsed 389.83\n",
      "\u001b[32m[2020-07-14 03:15:42] __main__ INFO: \u001b[0mVal 37\n",
      "\u001b[32m[2020-07-14 03:15:55] __main__ INFO: \u001b[0mEpoch 37 loss 0.2695 acc@1 0.9406 acc@5 0.9982\n",
      "\u001b[32m[2020-07-14 03:15:55] __main__ INFO: \u001b[0mElapsed 13.14\n",
      "\u001b[32m[2020-07-14 03:15:55] __main__ INFO: \u001b[0mTrain 38 12987\n",
      "\u001b[32m[2020-07-14 03:17:47] __main__ INFO: \u001b[0mEpoch 38 Step 100/351 lr 0.001000 loss 0.0027 (0.0041) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 03:19:38] __main__ INFO: \u001b[0mEpoch 38 Step 200/351 lr 0.001000 loss 0.0041 (0.0046) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 03:21:28] __main__ INFO: \u001b[0mEpoch 38 Step 300/351 lr 0.001000 loss 0.0029 (0.0045) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 03:22:25] __main__ INFO: \u001b[0mEpoch 38 Step 351/351 lr 0.001000 loss 0.0018 (0.0046) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 03:22:25] __main__ INFO: \u001b[0mElapsed 389.71\n",
      "\u001b[32m[2020-07-14 03:22:25] __main__ INFO: \u001b[0mVal 38\n",
      "\u001b[32m[2020-07-14 03:22:38] __main__ INFO: \u001b[0mEpoch 38 loss 0.2664 acc@1 0.9404 acc@5 0.9986\n",
      "\u001b[32m[2020-07-14 03:22:38] __main__ INFO: \u001b[0mElapsed 13.14\n",
      "\u001b[32m[2020-07-14 03:22:38] __main__ INFO: \u001b[0mTrain 39 13338\n",
      "\u001b[32m[2020-07-14 03:24:29] __main__ INFO: \u001b[0mEpoch 39 Step 100/351 lr 0.001000 loss 0.0027 (0.0037) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 03:26:20] __main__ INFO: \u001b[0mEpoch 39 Step 200/351 lr 0.001000 loss 0.0019 (0.0033) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 03:28:11] __main__ INFO: \u001b[0mEpoch 39 Step 300/351 lr 0.001000 loss 0.0032 (0.0036) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 03:29:08] __main__ INFO: \u001b[0mEpoch 39 Step 351/351 lr 0.001000 loss 0.0044 (0.0038) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 03:29:08] __main__ INFO: \u001b[0mElapsed 389.54\n",
      "\u001b[32m[2020-07-14 03:29:08] __main__ INFO: \u001b[0mVal 39\n",
      "\u001b[32m[2020-07-14 03:29:21] __main__ INFO: \u001b[0mEpoch 39 loss 0.2729 acc@1 0.9408 acc@5 0.9984\n",
      "\u001b[32m[2020-07-14 03:29:21] __main__ INFO: \u001b[0mElapsed 13.12\n",
      "\u001b[32m[2020-07-14 03:29:21] __main__ INFO: \u001b[0mTrain 40 13689\n",
      "\u001b[32m[2020-07-14 03:31:12] __main__ INFO: \u001b[0mEpoch 40 Step 100/351 lr 0.001000 loss 0.0018 (0.0035) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 03:33:03] __main__ INFO: \u001b[0mEpoch 40 Step 200/351 lr 0.001000 loss 0.0019 (0.0034) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 03:34:54] __main__ INFO: \u001b[0mEpoch 40 Step 300/351 lr 0.001000 loss 0.0023 (0.0032) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 03:35:50] __main__ INFO: \u001b[0mEpoch 40 Step 351/351 lr 0.001000 loss 0.0027 (0.0034) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 03:35:50] __main__ INFO: \u001b[0mElapsed 389.54\n",
      "\u001b[32m[2020-07-14 03:35:50] __main__ INFO: \u001b[0mVal 40\n",
      "\u001b[32m[2020-07-14 03:36:04] __main__ INFO: \u001b[0mEpoch 40 loss 0.2695 acc@1 0.9400 acc@5 0.9982\n",
      "\u001b[32m[2020-07-14 03:36:04] __main__ INFO: \u001b[0mElapsed 13.16\n",
      "\u001b[32m[2020-07-14 03:36:04] __main__ INFO: \u001b[0mTrain 41 14040\n",
      "\u001b[32m[2020-07-14 03:37:55] __main__ INFO: \u001b[0mEpoch 41 Step 100/351 lr 0.001000 loss 0.0021 (0.0040) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 03:39:46] __main__ INFO: \u001b[0mEpoch 41 Step 200/351 lr 0.001000 loss 0.0137 (0.0041) acc@1 0.9922 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 03:41:37] __main__ INFO: \u001b[0mEpoch 41 Step 300/351 lr 0.001000 loss 0.0019 (0.0038) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 03:42:34] __main__ INFO: \u001b[0mEpoch 41 Step 351/351 lr 0.001000 loss 0.0017 (0.0037) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 03:42:34] __main__ INFO: \u001b[0mElapsed 389.94\n",
      "\u001b[32m[2020-07-14 03:42:34] __main__ INFO: \u001b[0mVal 41\n",
      "\u001b[32m[2020-07-14 03:42:47] __main__ INFO: \u001b[0mEpoch 41 loss 0.2718 acc@1 0.9390 acc@5 0.9984\n",
      "\u001b[32m[2020-07-14 03:42:47] __main__ INFO: \u001b[0mElapsed 13.18\n",
      "\u001b[32m[2020-07-14 03:42:47] __main__ INFO: \u001b[0mTrain 42 14391\n",
      "\u001b[32m[2020-07-14 03:44:38] __main__ INFO: \u001b[0mEpoch 42 Step 100/351 lr 0.001000 loss 0.0020 (0.0029) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 03:46:29] __main__ INFO: \u001b[0mEpoch 42 Step 200/351 lr 0.001000 loss 0.0019 (0.0032) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 03:48:20] __main__ INFO: \u001b[0mEpoch 42 Step 300/351 lr 0.001000 loss 0.0027 (0.0036) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 03:49:17] __main__ INFO: \u001b[0mEpoch 42 Step 351/351 lr 0.001000 loss 0.0019 (0.0037) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 03:49:17] __main__ INFO: \u001b[0mElapsed 389.97\n",
      "\u001b[32m[2020-07-14 03:49:17] __main__ INFO: \u001b[0mVal 42\n",
      "\u001b[32m[2020-07-14 03:49:30] __main__ INFO: \u001b[0mEpoch 42 loss 0.2719 acc@1 0.9400 acc@5 0.9978\n",
      "\u001b[32m[2020-07-14 03:49:30] __main__ INFO: \u001b[0mElapsed 13.10\n",
      "\u001b[32m[2020-07-14 03:49:30] __main__ INFO: \u001b[0mTrain 43 14742\n",
      "\u001b[32m[2020-07-14 03:51:21] __main__ INFO: \u001b[0mEpoch 43 Step 100/351 lr 0.001000 loss 0.0044 (0.0046) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 03:53:12] __main__ INFO: \u001b[0mEpoch 43 Step 200/351 lr 0.001000 loss 0.0023 (0.0049) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 03:55:03] __main__ INFO: \u001b[0mEpoch 43 Step 300/351 lr 0.001000 loss 0.0020 (0.0047) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 03:56:00] __main__ INFO: \u001b[0mEpoch 43 Step 351/351 lr 0.001000 loss 0.0037 (0.0046) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 03:56:00] __main__ INFO: \u001b[0mElapsed 389.77\n",
      "\u001b[32m[2020-07-14 03:56:00] __main__ INFO: \u001b[0mVal 43\n",
      "\u001b[32m[2020-07-14 03:56:13] __main__ INFO: \u001b[0mEpoch 43 loss 0.2668 acc@1 0.9414 acc@5 0.9978\n",
      "\u001b[32m[2020-07-14 03:56:13] __main__ INFO: \u001b[0mElapsed 13.16\n",
      "\u001b[32m[2020-07-14 03:56:13] __main__ INFO: \u001b[0mTrain 44 15093\n",
      "\u001b[32m[2020-07-14 03:58:04] __main__ INFO: \u001b[0mEpoch 44 Step 100/351 lr 0.001000 loss 0.0042 (0.0043) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 03:59:55] __main__ INFO: \u001b[0mEpoch 44 Step 200/351 lr 0.001000 loss 0.0019 (0.0038) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 04:01:46] __main__ INFO: \u001b[0mEpoch 44 Step 300/351 lr 0.001000 loss 0.0296 (0.0041) acc@1 0.9922 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 04:02:43] __main__ INFO: \u001b[0mEpoch 44 Step 351/351 lr 0.001000 loss 0.0026 (0.0039) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 04:02:43] __main__ INFO: \u001b[0mElapsed 389.97\n",
      "\u001b[32m[2020-07-14 04:02:43] __main__ INFO: \u001b[0mVal 44\n",
      "\u001b[32m[2020-07-14 04:02:56] __main__ INFO: \u001b[0mEpoch 44 loss 0.2643 acc@1 0.9420 acc@5 0.9982\n",
      "\u001b[32m[2020-07-14 04:02:56] __main__ INFO: \u001b[0mElapsed 13.14\n",
      "\u001b[32m[2020-07-14 04:02:56] __main__ INFO: \u001b[0mTrain 45 15444\n",
      "\u001b[32m[2020-07-14 04:04:47] __main__ INFO: \u001b[0mEpoch 45 Step 100/351 lr 0.001000 loss 0.0015 (0.0035) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 04:06:38] __main__ INFO: \u001b[0mEpoch 45 Step 200/351 lr 0.001000 loss 0.0027 (0.0036) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 04:08:30] __main__ INFO: \u001b[0mEpoch 45 Step 300/351 lr 0.001000 loss 0.0017 (0.0043) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 04:09:26] __main__ INFO: \u001b[0mEpoch 45 Step 351/351 lr 0.001000 loss 0.0026 (0.0042) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 04:09:26] __main__ INFO: \u001b[0mElapsed 390.45\n",
      "\u001b[32m[2020-07-14 04:09:26] __main__ INFO: \u001b[0mVal 45\n",
      "\u001b[32m[2020-07-14 04:09:40] __main__ INFO: \u001b[0mEpoch 45 loss 0.2753 acc@1 0.9400 acc@5 0.9982\n",
      "\u001b[32m[2020-07-14 04:09:40] __main__ INFO: \u001b[0mElapsed 13.19\n",
      "\u001b[32m[2020-07-14 04:09:40] __main__ INFO: \u001b[0mTrain 46 15795\n",
      "\u001b[32m[2020-07-14 04:11:31] __main__ INFO: \u001b[0mEpoch 46 Step 100/351 lr 0.001000 loss 0.0038 (0.0037) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 04:13:22] __main__ INFO: \u001b[0mEpoch 46 Step 200/351 lr 0.001000 loss 0.0029 (0.0038) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 04:15:14] __main__ INFO: \u001b[0mEpoch 46 Step 300/351 lr 0.001000 loss 0.0019 (0.0036) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 04:16:10] __main__ INFO: \u001b[0mEpoch 46 Step 351/351 lr 0.001000 loss 0.0090 (0.0036) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 04:16:10] __main__ INFO: \u001b[0mElapsed 390.88\n",
      "\u001b[32m[2020-07-14 04:16:10] __main__ INFO: \u001b[0mVal 46\n",
      "\u001b[32m[2020-07-14 04:16:24] __main__ INFO: \u001b[0mEpoch 46 loss 0.2658 acc@1 0.9384 acc@5 0.9988\n",
      "\u001b[32m[2020-07-14 04:16:24] __main__ INFO: \u001b[0mElapsed 13.16\n",
      "\u001b[32m[2020-07-14 04:16:24] __main__ INFO: \u001b[0mTrain 47 16146\n",
      "\u001b[32m[2020-07-14 04:18:15] __main__ INFO: \u001b[0mEpoch 47 Step 100/351 lr 0.001000 loss 0.0017 (0.0029) acc@1 1.0000 (0.9997) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 04:20:06] __main__ INFO: \u001b[0mEpoch 47 Step 200/351 lr 0.001000 loss 0.0032 (0.0032) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 04:21:58] __main__ INFO: \u001b[0mEpoch 47 Step 300/351 lr 0.001000 loss 0.0035 (0.0035) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 04:22:55] __main__ INFO: \u001b[0mEpoch 47 Step 351/351 lr 0.001000 loss 0.0025 (0.0035) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 04:22:55] __main__ INFO: \u001b[0mElapsed 391.04\n",
      "\u001b[32m[2020-07-14 04:22:55] __main__ INFO: \u001b[0mVal 47\n",
      "\u001b[32m[2020-07-14 04:23:08] __main__ INFO: \u001b[0mEpoch 47 loss 0.2588 acc@1 0.9404 acc@5 0.9978\n",
      "\u001b[32m[2020-07-14 04:23:08] __main__ INFO: \u001b[0mElapsed 13.21\n",
      "\u001b[32m[2020-07-14 04:23:08] __main__ INFO: \u001b[0mTrain 48 16497\n",
      "\u001b[32m[2020-07-14 04:24:59] __main__ INFO: \u001b[0mEpoch 48 Step 100/351 lr 0.001000 loss 0.0021 (0.0031) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 04:26:50] __main__ INFO: \u001b[0mEpoch 48 Step 200/351 lr 0.001000 loss 0.0020 (0.0031) acc@1 1.0000 (0.9998) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 04:28:41] __main__ INFO: \u001b[0mEpoch 48 Step 300/351 lr 0.001000 loss 0.0036 (0.0034) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 04:29:38] __main__ INFO: \u001b[0mEpoch 48 Step 351/351 lr 0.001000 loss 0.0039 (0.0034) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 04:29:38] __main__ INFO: \u001b[0mElapsed 390.06\n",
      "\u001b[32m[2020-07-14 04:29:38] __main__ INFO: \u001b[0mVal 48\n",
      "\u001b[32m[2020-07-14 04:29:51] __main__ INFO: \u001b[0mEpoch 48 loss 0.2721 acc@1 0.9392 acc@5 0.9980\n",
      "\u001b[32m[2020-07-14 04:29:51] __main__ INFO: \u001b[0mElapsed 13.20\n",
      "\u001b[32m[2020-07-14 04:29:51] __main__ INFO: \u001b[0mTrain 49 16848\n",
      "\u001b[32m[2020-07-14 04:31:43] __main__ INFO: \u001b[0mEpoch 49 Step 100/351 lr 0.001000 loss 0.0043 (0.0038) acc@1 1.0000 (0.9996) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 04:33:34] __main__ INFO: \u001b[0mEpoch 49 Step 200/351 lr 0.001000 loss 0.0041 (0.0041) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 04:35:25] __main__ INFO: \u001b[0mEpoch 49 Step 300/351 lr 0.001000 loss 0.0017 (0.0040) acc@1 1.0000 (0.9995) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 04:36:22] __main__ INFO: \u001b[0mEpoch 49 Step 351/351 lr 0.001000 loss 0.0029 (0.0040) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 04:36:22] __main__ INFO: \u001b[0mElapsed 390.58\n",
      "\u001b[32m[2020-07-14 04:36:22] __main__ INFO: \u001b[0mVal 49\n",
      "\u001b[32m[2020-07-14 04:36:35] __main__ INFO: \u001b[0mEpoch 49 loss 0.2646 acc@1 0.9400 acc@5 0.9980\n",
      "\u001b[32m[2020-07-14 04:36:35] __main__ INFO: \u001b[0mElapsed 13.10\n",
      "\u001b[32m[2020-07-14 04:36:35] __main__ INFO: \u001b[0mTrain 50 17199\n",
      "\u001b[32m[2020-07-14 04:38:26] __main__ INFO: \u001b[0mEpoch 50 Step 100/351 lr 0.001000 loss 0.0029 (0.0052) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 04:40:17] __main__ INFO: \u001b[0mEpoch 50 Step 200/351 lr 0.001000 loss 0.0318 (0.0051) acc@1 0.9922 (0.9991) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 04:42:08] __main__ INFO: \u001b[0mEpoch 50 Step 300/351 lr 0.001000 loss 0.0016 (0.0045) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 04:43:05] __main__ INFO: \u001b[0mEpoch 50 Step 351/351 lr 0.001000 loss 0.0021 (0.0043) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)\n",
      "\u001b[32m[2020-07-14 04:43:05] __main__ INFO: \u001b[0mElapsed 390.19\n",
      "\u001b[32m[2020-07-14 04:43:05] __main__ INFO: \u001b[0mVal 50\n",
      "\u001b[32m[2020-07-14 04:43:18] __main__ INFO: \u001b[0mEpoch 50 loss 0.2517 acc@1 0.9452 acc@5 0.9978\n",
      "\u001b[32m[2020-07-14 04:43:18] __main__ INFO: \u001b[0mElapsed 13.11\n",
      "\u001b[32m[2020-07-14 04:43:18] fvcore.common.checkpoint INFO: \u001b[0mSaving checkpoint to /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_1_20/exp00_resume400_50/checkpoint_00050.pth\n"
     ]
    }
   ],
   "source": [
    "# Resume training with the un-augmented data\n",
    "\n",
    "#### Set LEARNING RATE based on ending learning rate \n",
    "os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "#!python train.py --config configs/cifar/resnet.yaml \\\n",
    "!python train.py --config /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_1_20/exp00/config.yaml \\\n",
    "    train.checkpoint /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_1_20/exp00/checkpoint_00400.pth \\\n",
    "    dataset.name CIFAR10 \\\n",
    "    train.base_lr .001 \\\n",
    "    train.output_dir /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_1_20/exp00_resume400_50 \\\n",
    "    scheduler.epochs 50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect model predictions and performance metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-18 18:14:54] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_1_20/exp00_resume400_50/checkpoint_00050.pth\n",
      "Files already downloaded and verified\n",
      "100%|| 79/79 [00:26<00:00,  2.98it/s]\n",
      "\u001b[32m[2020-07-18 18:15:22] __main__ INFO: \u001b[0mElapsed 26.53\n",
      "\u001b[32m[2020-07-18 18:15:22] __main__ INFO: \u001b[0mLoss 0.2292 Accuracy 0.9463\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10 test dataset \n",
    "# write the results to the test output directory specified\n",
    "!python evaluate.py --config configs/cifar/wrn.yaml \\\n",
    "   model.resnet.depth 32 \\\n",
    "   test.batch_size 128 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_1_20/exp00_resume400_50/checkpoint_00050.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_1_20/exp00_resume400_50/test_results_0050_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-18 18:15:52] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_1_20/exp00_resume400_50/checkpoint_00050.pth\n",
      "CIFAR 10.1\n",
      "100%|| 16/16 [00:05<00:00,  2.87it/s]\n",
      "\u001b[32m[2020-07-18 18:15:58] __main__ INFO: \u001b[0mElapsed 5.58\n",
      "\u001b[32m[2020-07-18 18:15:58] __main__ INFO: \u001b[0mLoss 0.5373 Accuracy 0.8905\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10.1 test dataset \n",
    "# Right the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/wrn.yaml \\\n",
    "   model.resnet.depth 32 \\\n",
    "   test.batch_size 128 \\\n",
    "   dataset.name CIFAR101 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_1_20/exp00_resume400_50/checkpoint_00050.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_1_20/exp00_resume400_50/test_results_0050_cifar101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-18 18:16:51] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_1_20/exp00/checkpoint_00400.pth\n",
      "Files already downloaded and verified\n",
      "100%|| 79/79 [00:26<00:00,  2.98it/s]\n",
      "\u001b[32m[2020-07-18 18:17:18] __main__ INFO: \u001b[0mElapsed 26.48\n",
      "\u001b[32m[2020-07-18 18:17:18] __main__ INFO: \u001b[0mLoss 0.4205 Accuracy 0.9037\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10 test dataset \n",
    "# write the results to the test output directory specified.\n",
    "!python evaluate.py --config configs/cifar/wrn.yaml \\\n",
    "   model.resnet.depth 32 \\\n",
    "   test.batch_size 128 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_1_20/exp00/checkpoint_00400.pth \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_1_20/exp00/test_results_0400_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-07-18 18:17:35] fvcore.common.checkpoint INFO: \u001b[0mLoading checkpoint from /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_1_20/exp00/checkpoint_00400.pth\n",
      "CIFAR 10.1\n",
      "100%|| 16/16 [00:05<00:00,  2.84it/s]\n",
      "\u001b[32m[2020-07-18 18:17:41] __main__ INFO: \u001b[0mElapsed 5.63\n",
      "\u001b[32m[2020-07-18 18:17:41] __main__ INFO: \u001b[0mLoss 0.8154 Accuracy 0.8275\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the trained, saved model using the CIFAR 10.1 test dataset \n",
    "# write the results to the test output directory specified.\n",
    "os.chdir('/home/ec2-user/SageMaker/w210-capstone/models/pytorch_imageclass/')\n",
    "!python evaluate.py --config configs/cifar/wrn.yaml \\\n",
    "   model.resnet.depth 32 \\\n",
    "   test.batch_size 128 \\\n",
    "   test.checkpoint /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_1_20/exp00/checkpoint_00400.pth \\\n",
    "   dataset.name CIFAR101 \\\n",
    "   test.output_dir /home/ec2-user/SageMaker/experiments/wrn_28_10_ra_1_20/exp00/test_results_0400_cifar101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Testset</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Original_Accuracy</th>\n",
       "      <th>Original_CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wrn_28_10_ra_1_20</td>\n",
       "      <td>400</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>0.4205</td>\n",
       "      <td>0.9037</td>\n",
       "      <td>95.9</td>\n",
       "      <td>(95.5, 96.3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wrn_28_10_ra_1_20</td>\n",
       "      <td>400</td>\n",
       "      <td>cifar10.1</td>\n",
       "      <td>0.8154</td>\n",
       "      <td>0.8275</td>\n",
       "      <td>89.7</td>\n",
       "      <td>(88.3, 91.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wrn_28_10_ra_1_20_refined400</td>\n",
       "      <td>50</td>\n",
       "      <td>cifar10.1</td>\n",
       "      <td>0.5373</td>\n",
       "      <td>0.8905</td>\n",
       "      <td>89.7</td>\n",
       "      <td>(88.3, 91.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wrn_28_10_ra_1_20_refined400</td>\n",
       "      <td>50</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>0.2292</td>\n",
       "      <td>0.9463</td>\n",
       "      <td>95.9</td>\n",
       "      <td>(95.5, 96.3)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model Epoch    Testset    Loss Accuracy  \\\n",
       "0             wrn_28_10_ra_1_20   400    cifar10  0.4205   0.9037   \n",
       "1             wrn_28_10_ra_1_20   400  cifar10.1  0.8154   0.8275   \n",
       "2  wrn_28_10_ra_1_20_refined400    50  cifar10.1  0.5373   0.8905   \n",
       "3  wrn_28_10_ra_1_20_refined400    50    cifar10  0.2292   0.9463   \n",
       "\n",
       "   Original_Accuracy   Original_CI  \n",
       "0               95.9  (95.5, 96.3)  \n",
       "1               89.7  (88.3, 91.0)  \n",
       "2               89.7  (88.3, 91.0)  \n",
       "3               95.9  (95.5, 96.3)  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "a = pd.Series(['wrn_28_10_ra_1_20', 400, 'cifar10', 0.4205, 0.9037]) #Loss 0.4205 Accuracy 0.9037\n",
    "c = pd.Series(['wrn_28_10_ra_1_20', 400, 'cifar10.1', 0.8154, 0.8275]) #Loss 0.8154 Accuracy 0.8275\n",
    "\n",
    "\n",
    "e = pd.Series(['wrn_28_10_ra_1_20_refined400', 50, 'cifar10.1', 0.5373, 0.8905]) #Loss 0.5373 Accuracy 0.8905\n",
    "f = pd.Series(['wrn_28_10_ra_1_20_refined400', 50, 'cifar10', 0.2292,0.9463]) #Loss 0.2292 Accuracy 0.9463\n",
    "               \n",
    "df_results = pd.concat([a,c,e,f], axis=1).T\n",
    "df_results.columns = ['Model', 'Epoch', 'Testset', 'Loss', 'Accuracy']\n",
    "\n",
    "df_results['Original_Accuracy'] = df_results.apply((lambda row: 95.9 if row[2] == 'cifar10' else 89.7), axis=1)\n",
    "df_results['Original_CI'] = df_results.apply((lambda row: (95.5, 96.3) if row[2] == 'cifar10' else (88.3, 91.0)), axis=1)\n",
    "\n",
    "df_results.to_csv('/home/ec2-user/SageMaker/experiments/wrn_28_10_ra_1_20/results.csv')\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['preds', 'probs', 'labels', 'loss', 'acc']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.6346034e+00, -1.6786125e+00, -5.5114478e-01, ...,\n",
       "        -1.3655751e+00, -9.7406626e-01, -2.0390615e+00],\n",
       "       [ 1.4603181e-01, -5.1087286e-02, -1.2974702e+00, ...,\n",
       "        -2.0043511e+00,  1.0846609e+01, -1.3743297e+00],\n",
       "       [-3.3679867e-01, -6.3276786e-01, -7.7840930e-01, ...,\n",
       "        -1.8309350e+00,  7.5045228e+00,  6.6094440e-01],\n",
       "       ...,\n",
       "       [-1.5556248e+00, -1.7238193e+00, -6.5844554e-01, ...,\n",
       "        -7.4209386e-01, -1.6280203e+00, -3.8239390e-01],\n",
       "       [ 9.8031856e-02,  8.8812132e+00, -1.9066744e-03, ...,\n",
       "        -1.7034054e+00, -7.0803320e-01, -7.0997417e-01],\n",
       "       [-1.2500942e+00, -1.3773537e+00, -1.1949891e+00, ...,\n",
       "         8.8070650e+00, -1.4133977e+00, -9.2784518e-01]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Peak inside the output file for predictions\n",
    "import numpy as np\n",
    "output = '/home/ec2-user/SageMaker/experiments/wrn_28_10_ra_2_20/exp00/test_results_0400_cifar10/predictions.npz'\n",
    "npzfile = np.load(output)\n",
    "print(npzfile.files)\n",
    "npzfile['preds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the model checkpoints, configs, and results to S3 \n",
    "bucket='sagemaker-may29'\n",
    "prefix = 'sagemaker/results/original-models/wrn_28_10_ra_1_20'\n",
    "path = '/home/ec2-user/SageMaker/experiments/wrn_28_10_ra_1_20'\n",
    "\n",
    "s3_resource = boto3.resource(\"s3\", region_name=\"us-east-2\")\n",
    "\n",
    "def uploadDirectory(local_path,bucket_name,s3_prefix):\n",
    "\n",
    "    my_bucket = s3_resource.Bucket(bucket_name)\n",
    "    \n",
    "    for path, subdirs, files in os.walk(local_path):\n",
    "        path = path.replace(\"\\\\\",\"/\")\n",
    "        directory_name = path.replace(local_path,\"\")\n",
    "        for file in files:\n",
    "            #print(\"Local File:\", os.path.join(path, file))\n",
    "            #print(\"      Dest:\", s3_prefix+directory_name+'/'+file)\n",
    "            my_bucket.upload_file(os.path.join(path, file), s3_prefix+directory_name+'/'+file)\n",
    "    \n",
    "uploadDirectory(path,bucket,prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
